[
    {
        "id": "4cdbb2a802",
        "title": "A Guide to Learning Arithmetic Circuits",
        "site": "https://proceedings.mlr.press/v49/volkovich16.html",
        "author": "Ilya Volkovich",
        "abstract": "An \\empharithmetic circuit is a directed acyclic graph in which the operations are {+,\\times}. In this paper, we exhibit several connections between learning algorithms for arithmetic circuits and other problems. In particular, we show that: \\beginitemize \\item Efficient learning algorithms for arithmetic circuit classes imply explicit exponential lower bounds. \\item General circuits and formulas can be learned efficiently with membership and equivalence queries iff they can be learned efficiently with membership queries only. \\item Low-query learning algorithms for certain classes of circuits imply explicit rigid matrices. \\item Learning algorithms for multilinear depth-3 and depth-4 circuits must compute square roots. \\enditemize",
        "bibtex": "@InProceedings{pmlr-v49-volkovich16,\n  title = \t {A Guide to Learning Arithmetic Circuits},\n  author = \t {Volkovich, Ilya},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1540--1561},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/volkovich16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/volkovich16.html},\n  abstract = \t {An \\empharithmetic circuit is a directed acyclic graph in which the operations are {+,\\times}. In this paper, we exhibit several connections between learning algorithms for arithmetic circuits and other problems. In particular, we show that: \\beginitemize \\item Efficient learning algorithms for arithmetic circuit classes imply explicit exponential lower bounds. \\item General circuits and formulas can be learned efficiently with membership and equivalence queries iff they can be learned efficiently with membership queries only. \\item Low-query learning algorithms for certain classes of circuits imply explicit rigid matrices. \\item Learning algorithms for multilinear depth-3 and depth-4 circuits must compute square roots. \\enditemize}\n}",
        "pdf": "http://proceedings.mlr.press/v49/volkovich16.pdf",
        "supp": "",
        "pdf_size": 459907,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2029171221214257507&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of EECS, CSE Division, University of Michigan, Ann Arbor, MI",
        "aff_domain": "umich.edu",
        "email": "umich.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of EECS, CSE Division",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8000fd0017",
        "title": "A Light Touch for Heavily Constrained SGD",
        "site": "https://proceedings.mlr.press/v49/cotter16.html",
        "author": "Andrew Cotter; Maya Gupta; Jan Pfeifer",
        "abstract": "Minimizing empirical risk subject to a set of constraints can be a useful strategy for learning restricted classes of functions, such as monotonic functions, submodular functions, classifiers that guarantee a certain class label for some subset of examples, etc. However, these restrictions may result in a very large number of constraints. Projected stochastic gradient descent (SGD) is often the default choice for large-scale optimization in machine learning, but requires a projection after each update. For heavily-constrained objectives, we propose an efficient extension of SGD that stays close to the feasible region while only applying constraints probabilistically at each iteration. Theoretical analysis shows a compelling trade-off between per-iteration work and the number of iterations needed on problems with a large number of constraints.",
        "bibtex": "@InProceedings{pmlr-v49-cotter16,\n  title = \t {A Light Touch for Heavily Constrained SGD},\n  author = \t {Cotter, Andrew and Gupta, Maya and Pfeifer, Jan},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {729--771},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/cotter16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/cotter16.html},\n  abstract = \t {Minimizing empirical risk subject to a set of constraints can be a useful strategy for learning restricted classes of functions, such as monotonic functions, submodular functions, classifiers that guarantee a certain class label for some subset of examples, etc. However, these restrictions may result in a very large number of constraints. Projected stochastic gradient descent (SGD) is often the default choice for large-scale optimization in machine learning, but requires a projection after each update. For heavily-constrained objectives, we propose an efficient extension of SGD that stays close to the feasible region while only applying constraints probabilistically at each iteration. Theoretical analysis shows a compelling trade-off between per-iteration work and the number of iterations needed on problems with a large number of constraints.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/cotter16.pdf",
        "supp": "",
        "pdf_size": 437718,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=977899310010219345&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 13,
        "aff": "Google; Google; Google",
        "aff_domain": "google.com;google.com;google.com",
        "email": "google.com;google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2377a01c47",
        "title": "Adaptive Learning with Robust Generalization Guarantees",
        "site": "https://proceedings.mlr.press/v49/cummings16.html",
        "author": "Rachel Cummings; Katrina Ligett; Kobbi Nissim; Aaron Roth; Zhiwei Steven Wu",
        "abstract": "The traditional notion of \\emphgeneralization\u2014i.e., learning a hypothesis whose empirical error is close to its true error\u2014is surprisingly brittle. As has recently been noted [Dwork et al. 2015], even if several algorithms have this guarantee in isolation, the guarantee need not hold if the algorithms are composed adaptively. In this paper, we study three notions of generalization\u2014increasing in strength\u2014that are \\emphrobust to postprocessing and amenable to adaptive composition, and examine the relationships between them.  We call the weakest such notion \\emphRobust Generalization. A second, intermediate, notion is the stability guarantee known as \\emphdifferential privacy. The strongest guarantee we consider we call \\emphPerfect Generalization. We prove that every hypothesis class that is PAC learnable is also PAC learnable in a robustly generalizing fashion, with almost the same sample complexity. It was previously known that differentially private algorithms satisfy robust generalization. In this paper, we show that robust generalization is a strictly weaker concept, and that there is a learning task that can be carried out subject to robust generalization guarantees, yet cannot be carried out subject to differential privacy. We also show that perfect generalization is a strictly stronger guarantee than differential privacy, but that, nevertheless, many learning tasks can be carried out subject to the guarantees of perfect generalization.",
        "bibtex": "@InProceedings{pmlr-v49-cummings16,\n  title = \t {Adaptive Learning with Robust Generalization Guarantees},\n  author = \t {Cummings, Rachel and Ligett, Katrina and Nissim, Kobbi and Roth, Aaron and Wu, Zhiwei Steven},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {772--814},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/cummings16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/cummings16.html},\n  abstract = \t {The traditional notion of \\emphgeneralization\u2014i.e., learning a hypothesis whose empirical error is close to its true error\u2014is surprisingly brittle. As has recently been noted [Dwork et al. 2015], even if several algorithms have this guarantee in isolation, the guarantee need not hold if the algorithms are composed adaptively. In this paper, we study three notions of generalization\u2014increasing in strength\u2014that are \\emphrobust to postprocessing and amenable to adaptive composition, and examine the relationships between them.  We call the weakest such notion \\emphRobust Generalization. A second, intermediate, notion is the stability guarantee known as \\emphdifferential privacy. The strongest guarantee we consider we call \\emphPerfect Generalization. We prove that every hypothesis class that is PAC learnable is also PAC learnable in a robustly generalizing fashion, with almost the same sample complexity. It was previously known that differentially private algorithms satisfy robust generalization. In this paper, we show that robust generalization is a strictly weaker concept, and that there is a learning task that can be carried out subject to robust generalization guarantees, yet cannot be carried out subject to differential privacy. We also show that perfect generalization is a strictly stronger guarantee than differential privacy, but that, nevertheless, many learning tasks can be carried out subject to the guarantees of perfect generalization.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/cummings16.pdf",
        "supp": "",
        "pdf_size": 360130,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6286050964865474218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "aff": "California Institute of Technology; California Institute of Technology+Hebrew University of Jerusalem; Ben-Gurion University+Harvard University; University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "CALTECH.EDU;CALTECH.EDU;SEAS.HARVARD.EDU;CIS.UPENN.EDU;CIS.UPENN.EDU",
        "email": "CALTECH.EDU;CALTECH.EDU;SEAS.HARVARD.EDU;CIS.UPENN.EDU;CIS.UPENN.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;2+3;4;4",
        "aff_unique_norm": "California Institute of Technology;Hebrew University of Jerusalem;Ben-Gurion University of the Negev;Harvard University;University of Pennsylvania",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.caltech.edu;https://www.huji.ac.il;https://www.bgu.ac.il;https://www.harvard.edu;https://www.upenn.edu",
        "aff_unique_abbr": "Caltech;HUJI;BGU;Harvard;UPenn",
        "aff_campus_unique_index": "0;0+1;",
        "aff_campus_unique": "Pasadena;Jerusalem;",
        "aff_country_unique_index": "0;0+1;1+0;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "17e7ae64bd",
        "title": "Aggregation of supports along the Lasso path",
        "site": "https://proceedings.mlr.press/v49/bellec16.html",
        "author": "Pierre C. Bellec",
        "abstract": "In linear regression with fixed design, we propose two procedures that aggregate a data-driven collection of supports. The collection is a subset of the 2^p possible supports and both its cardinality and its elements can depend on the data. The procedures satisfy oracle inequalities with no assumption on the design matrix. Then we use these procedures to aggregate the supports that appear on the regularization path of the Lasso in order to construct an estimator that mimics the best Lasso estimator. If the restricted eigenvalue condition on the design matrix is satisfied, then this estimator achieves optimal prediction bounds. Finally, we discuss the computational cost of these procedures.",
        "bibtex": "@InProceedings{pmlr-v49-bellec16,\n  title = \t {Aggregation of supports along the Lasso path},\n  author = \t {Bellec, Pierre C.},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {488--529},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/bellec16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/bellec16.html},\n  abstract = \t {In linear regression with fixed design, we propose two procedures that aggregate a data-driven collection of supports. The collection is a subset of the 2^p possible supports and both its cardinality and its elements can depend on the data. The procedures satisfy oracle inequalities with no assumption on the design matrix. Then we use these procedures to aggregate the supports that appear on the regularization path of the Lasso in order to construct an estimator that mimics the best Lasso estimator. If the restricted eigenvalue condition on the design matrix is satisfied, then this estimator achieves optimal prediction bounds. Finally, we discuss the computational cost of these procedures. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/bellec16.pdf",
        "supp": "",
        "pdf_size": 270388,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6983763188290882004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "CREST-ENSAE, 3 avenue Pierre Larousse, 92245 Malako\ufb00 Cedex, France",
        "aff_domain": "ensae.fr",
        "email": "ensae.fr",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "CREST-ENSAE",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "3705d6dfba",
        "title": "An Improved Gap-Dependency Analysis of the Noisy Power Method",
        "site": "https://proceedings.mlr.press/v49/balcan16a.html",
        "author": "Maria-Florina Balcan; Simon Shaolei Du; Yining Wang; Adams Wei Yu",
        "abstract": "We consider the \\emphnoisy power method algorithm, which has wide applications in machine learning and statistics, especially those related to principal component analysis (PCA) under resource (communication, memory or privacy) constraints. Existing analysis of the noisy power method shows an unsatisfactory dependency over the \u201cconsecutive\" spectral gap (\\sigma_k-\\sigma_k+1) of an input data matrix, which could be very small and hence limits the algorithm\u2019s applicability. In this paper, we present a new analysis of the noisy power method that achieves improved gap dependency for both sample complexity and noise tolerance bounds. More specifically, we improve the dependency over (\\sigma_k-\\sigma_k+1) to dependency over (\\sigma_k-\\sigma_q+1), where q is an intermediate algorithm parameter and could be much larger than the target rank k. Our proofs are built upon a novel characterization of proximity between two subspaces that differ from canonical angle characterizations analyzed in previous works. Finally, we apply our improved bounds to distributed private PCA and memory-efficient streaming PCA and obtain bounds that are superior to existing results in the literature.",
        "bibtex": "@InProceedings{pmlr-v49-balcan16a,\n  title = \t {An Improved Gap-Dependency Analysis of the Noisy Power Method},\n  author = \t {Balcan, Maria-Florina and Du, Simon Shaolei and Wang, Yining and Yu, Adams Wei},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {284--309},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/balcan16a.pdf},\n  url = \t {https://proceedings.mlr.press/v49/balcan16a.html},\n  abstract = \t {We consider the \\emphnoisy power method algorithm, which has wide applications in machine learning and statistics, especially those related to principal component analysis (PCA) under resource (communication, memory or privacy) constraints. Existing analysis of the noisy power method shows an unsatisfactory dependency over the \u201cconsecutive\" spectral gap (\\sigma_k-\\sigma_k+1) of an input data matrix, which could be very small and hence limits the algorithm\u2019s applicability. In this paper, we present a new analysis of the noisy power method that achieves improved gap dependency for both sample complexity and noise tolerance bounds. More specifically, we improve the dependency over (\\sigma_k-\\sigma_k+1) to dependency over (\\sigma_k-\\sigma_q+1), where q is an intermediate algorithm parameter and could be much larger than the target rank k. Our proofs are built upon a novel characterization of proximity between two subspaces that differ from canonical angle characterizations analyzed in previous works. Finally, we apply our improved bounds to distributed private PCA and memory-efficient streaming PCA and obtain bounds that are superior to existing results in the literature.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/balcan16a.pdf",
        "supp": "",
        "pdf_size": 384435,
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5133212830857800487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Machine Learning Department, School of Computer Science, Carnegie Mellon University; Machine Learning Department, School of Computer Science, Carnegie Mellon University; Machine Learning Department, School of Computer Science, Carnegie Mellon University; Machine Learning Department, School of Computer Science, Carnegie Mellon University",
        "aff_domain": "CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU",
        "email": "CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1d6e670608",
        "title": "An algorithm with nearly optimal pseudo-regret for both stochastic and adversarial bandits",
        "site": "https://proceedings.mlr.press/v49/auer16.html",
        "author": "Peter Auer; Chao-Kai Chiang",
        "abstract": "We present an algorithm that achieves almost optimal pseudo-regret bounds against adversarial and stochastic bandits. Against adversarial bandits the pseudo-regret is O(K\\sqrtn \\log n) and against stochastic bandits the pseudo-regret is O(\\sum_i (\\log n)/\\Delta_i). We also show that no algorithm with O(\\log n) pseudo-regret against stochastic bandits can achieve \\tildeO(\\sqrtn) expected regret against adaptive adversarial bandits. This complements previous results of Bubeck and Slivkins (2012) that show \\tildeO(\\sqrtn) expected adversarial regret with O((\\log n)^2) stochastic pseudo-regret.",
        "bibtex": "@InProceedings{pmlr-v49-auer16,\n  title = \t {An algorithm with nearly optimal pseudo-regret for both stochastic and adversarial bandits},\n  author = \t {Auer, Peter and Chiang, Chao-Kai},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {116--120},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/auer16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/auer16.html},\n  abstract = \t {We present an algorithm that achieves almost optimal pseudo-regret bounds against adversarial and stochastic bandits. Against adversarial bandits the pseudo-regret is O(K\\sqrtn \\log n) and against stochastic bandits the pseudo-regret is O(\\sum_i (\\log n)/\\Delta_i). We also show that no algorithm with O(\\log n) pseudo-regret against stochastic bandits can achieve \\tildeO(\\sqrtn) expected regret against adaptive adversarial bandits. This complements previous results of Bubeck and Slivkins (2012) that show \\tildeO(\\sqrtn) expected adversarial regret with O((\\log n)^2) stochastic pseudo-regret. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/auer16.pdf",
        "supp": "",
        "pdf_size": 191566,
        "gs_citation": 139,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14347632724292724462&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Montanuniversitaet Leoben; University of California, Los Angeles",
        "aff_domain": "unileoben.ac.at;gmail.com",
        "email": "unileoben.ac.at;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Montanuniversitaet Leoben;University of California, Los Angeles",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.montanuni-leoben.at;https://www.ucla.edu",
        "aff_unique_abbr": "MUL;UCLA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "69c3e867fc",
        "title": "An efficient algorithm for contextual bandits with knapsacks, and an extension to concave objectives",
        "site": "https://proceedings.mlr.press/v49/agrawal16.html",
        "author": "Shipra Agrawal; Nikhil R. Devanur; Lihong Li",
        "abstract": "We consider a contextual version of multi-armed bandit problem with global knapsack constraints. In each round, the outcome of pulling an arm is a scalar reward and a resource consumption vector, both dependent on the context, and the global knapsack constraints require the total consumption for each resource to be below some pre-fixed budget. The learning agent competes with an arbitrary set of context-dependent policies. This problem was introduced by Badanidiyuru et al., who gave a computationally inefficient algorithm with near-optimal regret bounds for it.  We give a \\emphcomputationally efficient algorithm for this problem with slightly better regret bounds, by generalizing the approach of Dudik et al. for the non-constrained version of the problem. The computational time of our algorithm scales \\emphlogarithmically in the size of the policy space. This answers the main open question of Badanidiyuru et al. We also extend our results to a variant where there are no knapsack constraints but the objective is an arbitrary Lipschitz concave function of the sum of outcome vectors.",
        "bibtex": "@InProceedings{pmlr-v49-agrawal16,\n  title = \t {An efficient algorithm for contextual bandits with knapsacks, and an extension to concave objectives},\n  author = \t {Agrawal, Shipra and Devanur, Nikhil R. and Li, Lihong},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {4--18},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/agrawal16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/agrawal16.html},\n  abstract = \t {We consider a contextual version of multi-armed bandit problem with global knapsack constraints. In each round, the outcome of pulling an arm is a scalar reward and a resource consumption vector, both dependent on the context, and the global knapsack constraints require the total consumption for each resource to be below some pre-fixed budget. The learning agent competes with an arbitrary set of context-dependent policies. This problem was introduced by Badanidiyuru et al., who gave a computationally inefficient algorithm with near-optimal regret bounds for it.  We give a \\emphcomputationally efficient algorithm for this problem with slightly better regret bounds, by generalizing the approach of Dudik et al. for the non-constrained version of the problem. The computational time of our algorithm scales \\emphlogarithmically in the size of the policy space. This answers the main open question of Badanidiyuru et al. We also extend our results to a variant where there are no knapsack constraints but the objective is an arbitrary Lipschitz concave function of the sum of outcome vectors. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/agrawal16.pdf",
        "supp": "",
        "pdf_size": 358663,
        "gs_citation": 115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13970150346682965637&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Columbia University; Microsoft Research; Microsoft Research",
        "aff_domain": "IEOR.COLUMBIA.EDU;MICROSOFT.COM;MICROSOFT.COM",
        "email": "IEOR.COLUMBIA.EDU;MICROSOFT.COM;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Columbia University;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.columbia.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Columbia;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "041ecbf39c",
        "title": "Asymptotic behavior of \\ell_p-based Laplacian regularization in semi-supervised learning",
        "site": "https://proceedings.mlr.press/v49/elalaoui16.html",
        "author": "Ahmed El Alaoui; Xiang Cheng; Aaditya Ramdas; Martin J. Wainwright; Michael I. Jordan",
        "abstract": "Given a weighted graph with N vertices, consider a real-valued regression problem in a semi-supervised setting, where one observes n labeled vertices, and the task is to label the remaining ones. We present a theoretical study of \\ell_p-based Laplacian regularization under a d-dimensional geometric random graph model. We provide a variational characterization of the performance of this regularized learner as N grows to infinity while n stays constant; the associated optimality conditions lead to a partial differential equation that must be satisfied by the associated function estimate \\widehatf.  From this formulation we derive several predictions on the limiting behavior the function \\fhat, including (a) a phase transition in its smoothness at the threshold p = d + 1; and (b) a tradeoff between smoothness and sensitivity to the underlying unlabeled data distribution P.  Thus, over the range p \u2264d, the function estimate \\widehatf is degenerate and \u201cspiky,\u201d whereas for p\u2265d+1, the function estimate \\fhat is smooth.  We show that the effect of the underlying density vanishes monotonically with p, such that in the limit p = \u221e, corresponding to the so-called Absolutely Minimal Lipschitz Extension, the estimate \\widehatf is independent of the distribution P. Under the assumption of semi-supervised smoothness, ignoring P can lead to poor statistical performance; in particular, we construct a specific example for d=1 to demonstrate that p=2 has lower risk than p=\u221edue to the former penalty adapting to P and the latter ignoring it.  We also provide simulations that verify the accuracy of our predictions for finite sample sizes.  Together, these properties show that p = d+1 is an optimal choice, yielding a function estimate \\fhat that is both smooth and non-degenerate, while remaining maximally sensitive to P.",
        "bibtex": "@InProceedings{pmlr-v49-elalaoui16,\n  title = \t {Asymptotic behavior of $\\ell_p$-based {L}aplacian regularization in semi-supervised learning},\n  author = \t {El Alaoui, Ahmed and Cheng, Xiang and Ramdas, Aaditya and Wainwright, Martin J. and Jordan, Michael I.},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {879--906},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/elalaoui16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/elalaoui16.html},\n  abstract = \t {Given a weighted graph with N vertices, consider a real-valued regression problem in a semi-supervised setting, where one observes n labeled vertices, and the task is to label the remaining ones. We present a theoretical study of \\ell_p-based Laplacian regularization under a d-dimensional geometric random graph model. We provide a variational characterization of the performance of this regularized learner as N grows to infinity while n stays constant; the associated optimality conditions lead to a partial differential equation that must be satisfied by the associated function estimate \\widehatf.  From this formulation we derive several predictions on the limiting behavior the function \\fhat, including (a) a phase transition in its smoothness at the threshold p = d + 1; and (b) a tradeoff between smoothness and sensitivity to the underlying unlabeled data distribution P.  Thus, over the range p \u2264d, the function estimate \\widehatf is degenerate and \u201cspiky,\u201d whereas for p\u2265d+1, the function estimate \\fhat is smooth.  We show that the effect of the underlying density vanishes monotonically with p, such that in the limit p = \u221e, corresponding to the so-called Absolutely Minimal Lipschitz Extension, the estimate \\widehatf is independent of the distribution P. Under the assumption of semi-supervised smoothness, ignoring P can lead to poor statistical performance; in particular, we construct a specific example for d=1 to demonstrate that p=2 has lower risk than p=\u221edue to the former penalty adapting to P and the latter ignoring it.  We also provide simulations that verify the accuracy of our predictions for finite sample sizes.  Together, these properties show that p = d+1 is an optimal choice, yielding a function estimate \\fhat that is both smooth and non-degenerate, while remaining maximally sensitive to P. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/elalaoui16.pdf",
        "supp": "",
        "pdf_size": 456395,
        "gs_citation": 123,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13964923966375049336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7c626df6d5",
        "title": "Basis Learning as an Algorithmic Primitive",
        "site": "https://proceedings.mlr.press/v49/belkin16.html",
        "author": "Mikhail Belkin; Luis Rademacher; James Voss",
        "abstract": "A number of important problems in theoretical computer science and machine learning can be interpreted as recovering a certain basis. These include  symmetric matrix eigendecomposition, certain tensor decompositions, Independent Component Analysis (ICA), spectral clustering and Gaussian mixture learning. Each of these problems reduces to an instance of our general model, which we call a \u201cBasis Encoding Function\" (BEF). We show that learning a basis within this model can then be provably and efficiently achieved using a first order  iteration algorithm (gradient iteration). Our algorithm goes beyond tensor methods while generalizing a number of existing algorithms\u2014e.g., the power method for symmetric matrices, the tensor power iteration for orthogonal decomposable tensors, and cumulant-based FastICA\u2014all within a broader function-based dynamical systems framework. Our framework also unifies the unusual phenomenon observed in these domains that they can be solved using efficient non-convex optimization. Specifically, we describe a class of BEFs such that their local maxima on the unit sphere are in one-to-one correspondence with the basis elements. This description relies on a certain \u201chidden convexity\" property of these functions. We provide a complete theoretical analysis of the gradient iteration even when the BEF is perturbed. We show convergence and complexity bounds polynomial in dimension and other relevant parameters, such as perturbation size. Our perturbation results can be considered as a  non-linear version of the classical Davis-Kahan theorem for perturbations of eigenvectors of symmetric matrices. In addition we show that   our algorithm exhibits fast (superlinear) convergence and relate the speed of convergence to the properties of the BEF. Moreover, the gradient iteration algorithm can be easily and efficiently implemented in practice.",
        "bibtex": "@InProceedings{pmlr-v49-belkin16,\n  title = \t {Basis Learning as an Algorithmic Primitive},\n  author = \t {Belkin, Mikhail and Rademacher, Luis and Voss, James},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {446--487},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/belkin16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/belkin16.html},\n  abstract = \t {A number of important problems in theoretical computer science and machine learning can be interpreted as recovering a certain basis. These include  symmetric matrix eigendecomposition, certain tensor decompositions, Independent Component Analysis (ICA), spectral clustering and Gaussian mixture learning. Each of these problems reduces to an instance of our general model, which we call a \u201cBasis Encoding Function\" (BEF). We show that learning a basis within this model can then be provably and efficiently achieved using a first order  iteration algorithm (gradient iteration). Our algorithm goes beyond tensor methods while generalizing a number of existing algorithms\u2014e.g., the power method for symmetric matrices, the tensor power iteration for orthogonal decomposable tensors, and cumulant-based FastICA\u2014all within a broader function-based dynamical systems framework. Our framework also unifies the unusual phenomenon observed in these domains that they can be solved using efficient non-convex optimization. Specifically, we describe a class of BEFs such that their local maxima on the unit sphere are in one-to-one correspondence with the basis elements. This description relies on a certain \u201chidden convexity\" property of these functions. We provide a complete theoretical analysis of the gradient iteration even when the BEF is perturbed. We show convergence and complexity bounds polynomial in dimension and other relevant parameters, such as perturbation size. Our perturbation results can be considered as a  non-linear version of the classical Davis-Kahan theorem for perturbations of eigenvectors of symmetric matrices. In addition we show that   our algorithm exhibits fast (superlinear) convergence and relate the speed of convergence to the properties of the BEF. Moreover, the gradient iteration algorithm can be easily and efficiently implemented in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/belkin16.pdf",
        "supp": "",
        "pdf_size": 557835,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5255224991064723904&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "The Ohio State University; The Ohio State University; The Ohio State University",
        "aff_domain": "CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU",
        "email": "CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9a1a2a9739",
        "title": "Best-of-K-bandits",
        "site": "https://proceedings.mlr.press/v49/simchowitz16.html",
        "author": "Max Simchowitz; Kevin Jamieson; Benjamin Recht",
        "abstract": "This paper studies the Best-of-K Bandit game: At each time the player chooses a subset S among all N-choose-K possible options and observes reward max(X(i) : i in S) where X is a random vector drawn from a joint distribution. The objective is to identify the subset that achieves the highest expected reward with high probability using as few queries as possible. We present distribution-dependent lower bounds based on a particular construction which force a learner to consider all N-choose-K subsets, and match naive extensions of known upper bounds in the bandit setting obtained by treating each subset as a separate arm. Nevertheless, we present evidence that exhaustive search may be avoided for certain, favorable distributions because the influence of high-order order correlations may be dominated by lower order statistics. Finally, we present an algorithm and analysis for independent arms, which mitigates the surprising non-trivial information occlusion that occurs due to only observing the max in the subset. This may inform strategies for more general dependent measures, and we complement these result with independent-arm lower bounds.",
        "bibtex": "@InProceedings{pmlr-v49-simchowitz16,\n  title = \t {Best-of-K-bandits},\n  author = \t {Simchowitz, Max and Jamieson, Kevin and Recht, Benjamin},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1440--1489},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/simchowitz16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/simchowitz16.html},\n  abstract = \t {This paper studies the Best-of-K Bandit game: At each time the player chooses a subset S among all N-choose-K possible options and observes reward max(X(i) : i in S) where X is a random vector drawn from a joint distribution. The objective is to identify the subset that achieves the highest expected reward with high probability using as few queries as possible. We present distribution-dependent lower bounds based on a particular construction which force a learner to consider all N-choose-K subsets, and match naive extensions of known upper bounds in the bandit setting obtained by treating each subset as a separate arm. Nevertheless, we present evidence that exhaustive search may be avoided for certain, favorable distributions because the influence of high-order order correlations may be dominated by lower order statistics. Finally, we present an algorithm and analysis for independent arms, which mitigates the surprising non-trivial information occlusion that occurs due to only observing the max in the subset. This may inform strategies for more general dependent measures, and we complement these result with independent-arm lower bounds. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/simchowitz16.pdf",
        "supp": "",
        "pdf_size": 474280,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6869012523929690588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, Berkeley, CA 94720 USA; University of California, Berkeley, CA 94720 USA; University of California, Berkeley, CA 94720 USA",
        "aff_domain": "BERKELEY.EDU;EECS.BERKELEY.EDU;EECS.BERKELEY.EDU",
        "email": "BERKELEY.EDU;EECS.BERKELEY.EDU;EECS.BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2b67bae0cb",
        "title": "Complexity Theoretic Limitations on Learning DNF\u2019s",
        "site": "https://proceedings.mlr.press/v49/daniely16.html",
        "author": "Amit Daniely; Shai Shalev-Shwartz",
        "abstract": "Using the recently developed framework of Daniely, Linial and Shalev-Shwartz, we show that under a natural assumption on the complexity of random K-SAT, learning DNF formulas is hard. Furthermore, the same assumption implies the hardness of various learning problems, including intersections of logarithmically many halfspaces, agnostically learning conjunctions, as well as virtually all (distribution free) learning problems that were previously shown hard (under various complexity assumptions).",
        "bibtex": "@InProceedings{pmlr-v49-daniely16,\n  title = \t {Complexity Theoretic Limitations on Learning DNF's},\n  author = \t {Daniely, Amit and Shalev-Shwartz, Shai},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {815--830},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/daniely16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/daniely16.html},\n  abstract = \t {Using the recently developed framework of Daniely, Linial and Shalev-Shwartz, we show that under a natural assumption on the complexity of random K-SAT, learning DNF formulas is hard. Furthermore, the same assumption implies the hardness of various learning problems, including intersections of logarithmically many halfspaces, agnostically learning conjunctions, as well as virtually all (distribution free) learning problems that were previously shown hard (under various complexity assumptions). }\n}",
        "pdf": "http://proceedings.mlr.press/v49/daniely16.pdf",
        "supp": "",
        "pdf_size": 302820,
        "gs_citation": 123,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6769471339154635801&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Google Inc, Mountain-View, California; School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel",
        "aff_domain": "GOOGLE.COM;CS.HUJI.AC.IL",
        "email": "GOOGLE.COM;CS.HUJI.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Google;Hebrew University",
        "aff_unique_dep": "Google;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.google.com;http://www.huji.ac.il",
        "aff_unique_abbr": "Google;HUJI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Mountain View;Jerusalem",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "dd668758f4",
        "title": "Conference on Learning Theory 2016: Preface",
        "site": "https://proceedings.mlr.press/v49/preface.html",
        "author": "Vitaly Feldman; Alexander Rakhlin",
        "abstract": "Preface to COLT 2016",
        "bibtex": "@InProceedings{pmlr-v49-preface,\n  title = \t {Conference on Learning Theory 2016: Preface},\n  author = \t {Feldman, Vitaly and Rakhlin, Alexander},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1--3},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/preface.pdf},\n  url = \t {https://proceedings.mlr.press/v49/preface.html},\n  abstract = \t {Preface to COLT 2016}\n}",
        "pdf": "http://proceedings.mlr.press/v49/preface.pdf",
        "supp": "",
        "pdf_size": 71965,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:lbydHh_aJ_IJ:scholar.google.com/&scioq=Conference+on+Learning+Theory+2016:+Preface&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "IBM Research \u2013 Almaden; Department of Statistics, University of Pennsylvania",
        "aff_domain": "POST.HARVARD.EDU;WHARTON.UPENN.EDU",
        "email": "POST.HARVARD.EDU;WHARTON.UPENN.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "IBM;University of Pennsylvania",
        "aff_unique_dep": "IBM Research;Department of Statistics",
        "aff_unique_url": "https://www.ibm.com/research;https://www.upenn.edu",
        "aff_unique_abbr": "IBM;UPenn",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Almaden;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3fdca298b1",
        "title": "Cortical Computation via Iterative Constructions",
        "site": "https://proceedings.mlr.press/v49/papadimitriou16.html",
        "author": "Christos Papadimitriou; Samantha Petti; Santosh Vempala",
        "abstract": "We study Boolean functions of an arbitrary number of input variables that can be realized by simple iterative constructions based on constant-size primitives. This restricted type of construction needs little global coordination or control and thus is a candidate for neurally feasible computation. Valiant\u2019s construction of a majority function can be realized in this manner and, as we show, can be generalized to any uniform threshold function. We study the rate of convergence, finding that while linear convergence to the correct function can be achieved for any threshold using a fixed set of primitives, for quadratic convergence, the size of the primitives must grow as the threshold approaches 0 or 1. We also study finite realizations of this process and the learnability of the functions realized. We show that the constructions realized are accurate outside a small interval near the target threshold, where the size of the construction grows as the inverse square of the interval width. This phenomenon, that errors are higher closer to thresholds (and thresholds closer to the boundary are harder to represent), is a well-known cognitive finding.",
        "bibtex": "@InProceedings{pmlr-v49-papadimitriou16,\n  title = \t {Cortical Computation via Iterative Constructions},\n  author = \t {Papadimitriou, Christos and Petti, Samantha and Vempala, Santosh},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1357--1375},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/papadimitriou16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/papadimitriou16.html},\n  abstract = \t {We study Boolean functions of an arbitrary number of input variables that can be realized by simple iterative constructions based on constant-size primitives. This restricted type of construction needs little global coordination or control and thus is a candidate for neurally feasible computation. Valiant\u2019s construction of a majority function can be realized in this manner and, as we show, can be generalized to any uniform threshold function. We study the rate of convergence, finding that while linear convergence to the correct function can be achieved for any threshold using a fixed set of primitives, for quadratic convergence, the size of the primitives must grow as the threshold approaches 0 or 1. We also study finite realizations of this process and the learnability of the functions realized. We show that the constructions realized are accurate outside a small interval near the target threshold, where the size of the construction grows as the inverse square of the interval width. This phenomenon, that errors are higher closer to thresholds (and thresholds closer to the boundary are harder to represent), is a well-known cognitive finding.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/papadimitriou16.pdf",
        "supp": "",
        "pdf_size": 377180,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8225059315173778171&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "UC Berkeley; Georgia Tech; Georgia Tech",
        "aff_domain": "berkeley.edu;gatech.edu;gatech.edu",
        "email": "berkeley.edu;gatech.edu;gatech.edu",
        "github": "",
        "project": "arXiv:1602.08357",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Berkeley;Georgia Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.gatech.edu",
        "aff_unique_abbr": "UC Berkeley;Georgia Tech",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "cb62236d06",
        "title": "Delay and Cooperation in Nonstochastic Bandits",
        "site": "https://proceedings.mlr.press/v49/cesa-bianchi16.html",
        "author": "Nicol\u2018o Cesa-Bianchi; Claudio Gentile; Yishay Mansour; Alberto Minora",
        "abstract": "We study networks of communicating learning agents that cooperate to solve a common nonstochastic bandit problem. Agents use an underlying communication network to get messages about actions selected by other agents, and drop messages that took more than d hops to arrive, where d is a delay parameter. We introduce Exp3-Coop, a cooperative version of the Exp3 algorithm and prove that with K actions and N agents the average per-agent regret after T rounds is at most of order \\sqrt\\left(d+1 + \\fracKN\\alpha_\u2264d\\right)(T\\ln K), where \\alpha_\u2264d is the independence number of the d-th power of the communication graph G. We then show that for any connected graph, for d=\\sqrtK the regret bound is K^1/4\\sqrtT, strictly better than the minimax regret \\sqrtKT for noncooperating agents. More informed choices of d lead to bounds which are arbitrarily close to the full information minimax regret \\sqrtT\\ln K when G is dense. When G has sparse components, we show that a variant of Exp3-Coop, allowing agents to choose their parameters according to their centrality in G, strictly improves the regret. Finally, as a by-product of our analysis, we provide the first characterization of the minimax regret for bandit learning with delay.",
        "bibtex": "@InProceedings{pmlr-v49-cesa-bianchi16,\n  title = \t {Delay and Cooperation in Nonstochastic Bandits},\n  author = \t {Cesa-Bianchi, Nicol\u2018o and Gentile, Claudio and Mansour, Yishay and Minora, Alberto},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {605--622},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/cesa-bianchi16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/cesa-bianchi16.html},\n  abstract = \t {We study networks of communicating learning agents that cooperate to solve a common nonstochastic bandit problem. Agents use an underlying communication network to get messages about actions selected by other agents, and drop messages that took more than d hops to arrive, where d is a delay parameter. We introduce Exp3-Coop, a cooperative version of the Exp3 algorithm and prove that with K actions and N agents the average per-agent regret after T rounds is at most of order \\sqrt\\left(d+1 + \\fracKN\\alpha_\u2264d\\right)(T\\ln K), where \\alpha_\u2264d is the independence number of the d-th power of the communication graph G. We then show that for any connected graph, for d=\\sqrtK the regret bound is K^1/4\\sqrtT, strictly better than the minimax regret \\sqrtKT for noncooperating agents. More informed choices of d lead to bounds which are arbitrarily close to the full information minimax regret \\sqrtT\\ln K when G is dense. When G has sparse components, we show that a variant of Exp3-Coop, allowing agents to choose their parameters according to their centrality in G, strictly improves the regret. Finally, as a by-product of our analysis, we provide the first characterization of the minimax regret for bandit learning with delay. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/cesa-bianchi16.pdf",
        "supp": "",
        "pdf_size": 396172,
        "gs_citation": 127,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=742995030175166602&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "aff": "Universit\u00e0 degli Studi di Milano, Italy; University of Insubria, Italy; Microsoft Research and Tel-Aviv University, Israel; University of Insubria, Italy",
        "aff_domain": "UNIMI.IT;UNINSUBRIA.IT;TAU.AC.IL;UNINSUBRIA.IT",
        "email": "UNIMI.IT;UNINSUBRIA.IT;TAU.AC.IL;UNINSUBRIA.IT",
        "github": "",
        "project": "Arxiv:1602.04741,v2",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Milano;University of Insubria;Microsoft",
        "aff_unique_dep": ";;Microsoft Research",
        "aff_unique_url": "https://www.unimi.it;https://www.uninsubria.it;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "UniMi;;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "a95b62bcc4",
        "title": "Density Evolution in the Degree-correlated Stochastic Block Model",
        "site": "https://proceedings.mlr.press/v49/mossel16.html",
        "author": "Elchanan Mossel; Jiaming Xu",
        "abstract": "There is a recent surge of interest in identifying the sharp recovery thresholds for cluster recovery under the stochastic block model. In this paper, we address the more refined question of how many vertices that will be misclassified on average. We consider the binary form of the stochastic block model, where n vertices are partitioned into  two clusters with edge probability a/n within the first cluster, c/n within the second cluster, and b/n across clusters.  Suppose that as n \\to \u221e, a= b+ \u03bc\\sqrt b ,  c=b+  \u03bd\\sqrt b  for two fixed constants \u03bc, \u03bd, and b \\to \u221ewith b=n^o(1). When the cluster sizes are balanced and \u03bc\u2260\u03bd, we show that the minimum fraction of misclassified vertices on average is given by  Q(\\sqrtv^*), where Q(x) is the Q-function for standard normal, v^* is the unique fixed point of v= \\frac(\u03bc-\u03bd)^216 + \\frac (\u03bc+\u03bd)^2 16 \\mathbbE[ \\tanh(v+ \\sqrtv Z)], and Z is standard normal. Moreover, the minimum  misclassified  fraction on average is attained by a local algorithm, namely belief propagation, in time linear in the number of edges. Our proof techniques are based on connecting the cluster recovery problem to tree reconstruction problems, and analyzing the density evolution of belief propagation on trees with Gaussian approximations.",
        "bibtex": "@InProceedings{pmlr-v49-mossel16,\n  title = \t {Density Evolution in the Degree-correlated Stochastic Block Model},\n  author = \t {Mossel, Elchanan and Xu, Jiaming},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1319--1356},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/mossel16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/mossel16.html},\n  abstract = \t {There is a recent surge of interest in identifying the sharp recovery thresholds for cluster recovery under the stochastic block model. In this paper, we address the more refined question of how many vertices that will be misclassified on average. We consider the binary form of the stochastic block model, where n vertices are partitioned into  two clusters with edge probability a/n within the first cluster, c/n within the second cluster, and b/n across clusters.  Suppose that as n \\to \u221e, a= b+ \u03bc\\sqrt b ,  c=b+  \u03bd\\sqrt b  for two fixed constants \u03bc, \u03bd, and b \\to \u221ewith b=n^o(1). When the cluster sizes are balanced and \u03bc\u2260\u03bd, we show that the minimum fraction of misclassified vertices on average is given by  Q(\\sqrtv^*), where Q(x) is the Q-function for standard normal, v^* is the unique fixed point of v= \\frac(\u03bc-\u03bd)^216 + \\frac (\u03bc+\u03bd)^2 16 \\mathbbE[ \\tanh(v+ \\sqrtv Z)], and Z is standard normal. Moreover, the minimum  misclassified  fraction on average is attained by a local algorithm, namely belief propagation, in time linear in the number of edges. Our proof techniques are based on connecting the cluster recovery problem to tree reconstruction problems, and analyzing the density evolution of belief propagation on trees with Gaussian approximations. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/mossel16.pdf",
        "supp": "",
        "pdf_size": 511428,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7873494678231269706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics, The Wharton School, University of Pennsylvania, Philadelphia, PA; Simons Institute for the Theory of Computing, University of California, Berkeley, Berkeley, CA",
        "aff_domain": "wharton.upenn.edu;berkeley.edu",
        "email": "wharton.upenn.edu;berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Pennsylvania;University of California, Berkeley",
        "aff_unique_dep": "Department of Statistics;Simons Institute for the Theory of Computing",
        "aff_unique_url": "https://www.upenn.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UPenn;UC Berkeley",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Philadelphia;Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7537ab8f38",
        "title": "Dropping Convexity for Faster Semi-definite Optimization",
        "site": "https://proceedings.mlr.press/v49/bhojanapalli16.html",
        "author": "Srinadh Bhojanapalli; Anastasios Kyrillidis; Sujay Sanghavi",
        "abstract": "We study the minimization of a convex function f(X) over the set of n \\times n positive semi-definite matrices, but when the problem is recast as \\min_U g(U) :=  f(UU^\u22a4), with U \u2208\\mathbbR^n \\times r and r \u2264n. We study the performance of gradient descent on g\u2014which we refer to as Factored Gradient Descent (\\textscFgd)\u2014under standard assumptions on the \\em original function f. We provide a rule for selecting the step size and, with this choice, show that the \\emphlocal convergence rate of \\textscFgd mirrors that of standard gradient descent on the original f: \\emphi.e., after k steps, the error is O(1/k) for smooth f, and exponentially small in k when f is (restricted) strongly convex. In addition, we provide a procedure to initialize \\textscFgd for (restricted) strongly convex objectives and when one only has access to f via a first-order oracle; for several problem instances, such proper initialization leads to \\emphglobal convergence guarantees. \\textscFgd and similar procedures are widely used in practice for problems that can be posed as matrix factorization. To the best of our knowledge, this is the first paper to provide precise convergence rate guarantees for general convex functions under standard convex assumptions.",
        "bibtex": "@InProceedings{pmlr-v49-bhojanapalli16,\n  title = \t {Dropping Convexity for Faster Semi-definite Optimization},\n  author = \t {Bhojanapalli, Srinadh and Kyrillidis, Anastasios and Sanghavi, Sujay},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {530--582},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/bhojanapalli16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/bhojanapalli16.html},\n  abstract = \t {We study the minimization of a convex function f(X) over the set of n \\times n positive semi-definite matrices, but when the problem is recast as \\min_U g(U) :=  f(UU^\u22a4), with U \u2208\\mathbbR^n \\times r and r \u2264n. We study the performance of gradient descent on g\u2014which we refer to as Factored Gradient Descent (\\textscFgd)\u2014under standard assumptions on the \\em original function f. We provide a rule for selecting the step size and, with this choice, show that the \\emphlocal convergence rate of \\textscFgd mirrors that of standard gradient descent on the original f: \\emphi.e., after k steps, the error is O(1/k) for smooth f, and exponentially small in k when f is (restricted) strongly convex. In addition, we provide a procedure to initialize \\textscFgd for (restricted) strongly convex objectives and when one only has access to f via a first-order oracle; for several problem instances, such proper initialization leads to \\emphglobal convergence guarantees. \\textscFgd and similar procedures are widely used in practice for problems that can be posed as matrix factorization. To the best of our knowledge, this is the first paper to provide precise convergence rate guarantees for general convex functions under standard convex assumptions.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/bhojanapalli16.pdf",
        "supp": "",
        "pdf_size": 4310832,
        "gs_citation": 198,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12943445173335487668&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Toyota Technological Institute at Chicago; University of Texas at Austin; University of Texas at Austin",
        "aff_domain": "TTIC.EDU;UTEXAS.EDU;MAIL.UTEXAS.EDU",
        "email": "TTIC.EDU;UTEXAS.EDU;MAIL.UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Toyota Technological Institute at Chicago;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tti-chicago.org;https://www.utexas.edu",
        "aff_unique_abbr": "TTI Chicago;UT Austin",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Chicago;Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a00c59a4a8",
        "title": "Efficient approaches for escaping higher order saddle points  in non-convex optimization",
        "site": "https://proceedings.mlr.press/v49/anandkumar16.html",
        "author": "Animashree Anandkumar; Rong Ge",
        "abstract": "Local search heuristics for non-convex optimizations are popular   in applied machine learning. However, in general it is  hard to  guarantee that such algorithms even  converge to a \\em local minimum, due to the existence of complicated saddle point structures in high dimensions. Many functions have \\em degenerate saddle points such that the first and second order derivatives cannot distinguish them with local optima.  In this paper we use higher order derivatives to escape these saddle points: we design the first efficient algorithm  guaranteed to converge to a third order local optimum (while existing techniques are at most second order). We also show that it is NP-hard to extend this further to finding fourth order local optima.",
        "bibtex": "@InProceedings{pmlr-v49-anandkumar16,\n  title = \t {Efficient approaches for escaping higher order saddle points  in non-convex optimization},\n  author = \t {Anandkumar, Animashree and Ge, Rong},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {81--102},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/anandkumar16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/anandkumar16.html},\n  abstract = \t {Local search heuristics for non-convex optimizations are popular   in applied machine learning. However, in general it is  hard to  guarantee that such algorithms even  converge to a \\em local minimum, due to the existence of complicated saddle point structures in high dimensions. Many functions have \\em degenerate saddle points such that the first and second order derivatives cannot distinguish them with local optima.  In this paper we use higher order derivatives to escape these saddle points: we design the first efficient algorithm  guaranteed to converge to a third order local optimum (while existing techniques are at most second order). We also show that it is NP-hard to extend this further to finding fourth order local optima.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/anandkumar16.pdf",
        "supp": "",
        "pdf_size": 505436,
        "gs_citation": 182,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6187540130441354517&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "University of California, Irvine; Duke University",
        "aff_domain": "uci.edu;cs.duke.edu",
        "email": "uci.edu;cs.duke.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Irvine;Duke University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uci.edu;https://www.duke.edu",
        "aff_unique_abbr": "UCI;Duke",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Irvine;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7e913985ce",
        "title": "First-order Methods for Geodesically Convex Optimization",
        "site": "https://proceedings.mlr.press/v49/zhang16b.html",
        "author": "Hongyi Zhang; Suvrit Sra",
        "abstract": "Geodesic convexity generalizes the notion of (vector space) convexity to nonlinear metric spaces. But unlike convex optimization, geodesically convex (g-convex) optimization is much less developed. In this paper we contribute to the understanding of g-convex optimization by developing iteration complexity analysis for several first-order algorithms on Hadamard manifolds. Specifically, we prove upper bounds for the global complexity of deterministic and stochastic (sub)gradient methods for optimizing smooth and nonsmooth g-convex functions, both with and without strong g-convexity. Our analysis also reveals how the manifold geometry, especially \\emphsectional curvature, impacts convergence rates. To the best of our knowledge, our work is the first to provide global complexity analysis for first-order algorithms for general g-convex optimization.",
        "bibtex": "@InProceedings{pmlr-v49-zhang16b,\n  title = \t {First-order Methods for Geodesically Convex Optimization},\n  author = \t {Zhang, Hongyi and Sra, Suvrit},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1617--1638},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/zhang16b.pdf},\n  url = \t {https://proceedings.mlr.press/v49/zhang16b.html},\n  abstract = \t {Geodesic convexity generalizes the notion of (vector space) convexity to nonlinear metric spaces. But unlike convex optimization, geodesically convex (g-convex) optimization is much less developed. In this paper we contribute to the understanding of g-convex optimization by developing iteration complexity analysis for several first-order algorithms on Hadamard manifolds. Specifically, we prove upper bounds for the global complexity of deterministic and stochastic (sub)gradient methods for optimizing smooth and nonsmooth g-convex functions, both with and without strong g-convexity. Our analysis also reveals how the manifold geometry, especially \\emphsectional curvature, impacts convergence rates. To the best of our knowledge, our work is the first to provide global complexity analysis for first-order algorithms for general g-convex optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/zhang16b.pdf",
        "supp": "",
        "pdf_size": 325202,
        "gs_citation": 352,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16607993473771572128&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Laboratory for Information & Decision Systems, Massachusetts Institute of Technology; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1bac4ce8b1",
        "title": "Gradient Descent Only Converges to Minimizers",
        "site": "https://proceedings.mlr.press/v49/lee16.html",
        "author": "Jason D. Lee; Max Simchowitz; Michael I. Jordan; Benjamin Recht",
        "abstract": "We show that gradient descent converges to a local minimizer, almost surely with random initial- ization. This is proved by applying the Stable Manifold Theorem from dynamical systems theory.",
        "bibtex": "@InProceedings{pmlr-v49-lee16,\n  title = \t {Gradient Descent Only Converges to Minimizers},\n  author = \t {Lee, Jason D. and Simchowitz, Max and Jordan, Michael I. and Recht, Benjamin},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1246--1257},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/lee16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/lee16.html},\n  abstract = \t {We show that gradient descent converges to a local minimizer, almost surely with random initial- ization. This is proved by applying the Stable Manifold Theorem from dynamical systems theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/lee16.pdf",
        "supp": "",
        "pdf_size": 259229,
        "gs_citation": 766,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2644396900437843156&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Data Sciences and Operations Department, Marshall School of Business, University of Southern California; Department of Electrical Engineering and Computer Science, UC Berkeley; Department of Electrical Engineering and Computer Science, UC Berkeley; Department of Electrical Engineering and Computer Science, UC Berkeley",
        "aff_domain": "MARSHALL.USC.EDU;BERKELEY.EDU;CS.BERKELEY.EDU;BERKELEY.EDU",
        "email": "MARSHALL.USC.EDU;BERKELEY.EDU;CS.BERKELEY.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Southern California;University of California, Berkeley",
        "aff_unique_dep": "Data Sciences and Operations Department;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.usc.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "USC;UC Berkeley",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Los Angeles;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "428ea39140",
        "title": "Highly-Smooth Zero-th Order Online Optimization",
        "site": "https://proceedings.mlr.press/v49/bach16.html",
        "author": "Francis Bach; Vianney Perchet",
        "abstract": "The minimization of convex functions which are only available through partial and noisy information is a key methodological problem in many disciplines. In this paper we consider  convex optimization with noisy zero-th order information, that is noisy function evaluations at any desired point. We focus on problems with high degrees of smoothness, such as  logistic regression. We show that as opposed to gradient-based algorithms, high-order smoothness may be used to improve estimation rates, with a precise dependence  of our upper-bounds on the degree of smoothness. In particular, we show that for infinitely differentiable functions, we recover the same dependence on sample size as gradient-based algorithms, with an extra dimension-dependent factor. This is done for both convex and strongly-convex functions, with finite horizon and anytime algorithms. Finally, we also recover similar results in the online optimization setting.",
        "bibtex": "@InProceedings{pmlr-v49-bach16,\n  title = \t {Highly-Smooth Zero-th Order Online Optimization},\n  author = \t {Bach, Francis and Perchet, Vianney},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {257--283},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/bach16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/bach16.html},\n  abstract = \t {The minimization of convex functions which are only available through partial and noisy information is a key methodological problem in many disciplines. In this paper we consider  convex optimization with noisy zero-th order information, that is noisy function evaluations at any desired point. We focus on problems with high degrees of smoothness, such as  logistic regression. We show that as opposed to gradient-based algorithms, high-order smoothness may be used to improve estimation rates, with a precise dependence  of our upper-bounds on the degree of smoothness. In particular, we show that for infinitely differentiable functions, we recover the same dependence on sample size as gradient-based algorithms, with an extra dimension-dependent factor. This is done for both convex and strongly-convex functions, with finite horizon and anytime algorithms. Finally, we also recover similar results in the online optimization setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/bach16.pdf",
        "supp": "",
        "pdf_size": 269998,
        "gs_citation": 118,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15011045946737452636&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "INRIA & D\u00b4epartement d\u2019Informatique de l\u2019Ecole Normale Sup\u00b4erieure; CREST - ENSAE",
        "aff_domain": "ENS.FR;NORMALESUP.ORG",
        "email": "ENS.FR;NORMALESUP.ORG",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "INRIA;\u00c9cole Nationale de la Statistique et de l'Administration \u00c9conomique",
        "aff_unique_dep": "D 'epartement d\u2019Informatique de l\u2019Ecole Normale Sup 'erieure;CREST",
        "aff_unique_url": "https://www.inria.fr;https://www.ensae.fr",
        "aff_unique_abbr": "INRIA;ENSAE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "d4a02727a8",
        "title": "How to calculate partition functions using convex programming hierarchies: provable bounds for variational methods",
        "site": "https://proceedings.mlr.press/v49/risteski16.html",
        "author": "Andrej Risteski",
        "abstract": "We consider the problem of approximating partition functions for Ising models. We make use of recent tools in combinatorial optimization: the Sherali-Adams and Lasserre convex programming hierarchies, in combination with variational methods to get algorithms for calculating partition functions in these families. These techniques give new, non-trivial approximation guarantees for the partition function beyond the regime of correlation decay. They also generalize some classical results from statistical physics about the Curie-Weiss ferromagnetic Ising model, as well as provide a partition function counterpart of classical results about max-cut on dense graphs (Arora, 1995). With this, we connect techniques from two apparently disparate research areas \u2013 optimization and counting/partition function approximations. (i.e. #-P type of problems). Furthermore, we design to the best of our knowledge the first provable, convex variational methods. Though in the literature there are a host of convex versions of variational methods, they come with no guarantees (apart from some extremely special cases, like e.g. the graph has a single cycle). We consider dense and low rank graphs, and interestingly, the reason our approach works on these types of graphs is because local correlations propagate to global correlations \u2013 completely the opposite of algorithms based on correlation decay. In the process we design novel entropy approximations based on the low-order moments of a distribution. Our proof techniques are very simple and generic, and likely to be applicable to many other settings other than Ising models.",
        "bibtex": "@InProceedings{pmlr-v49-risteski16,\n  title = \t {How to calculate partition functions using convex programming hierarchies: provable bounds for variational methods},\n  author = \t {Risteski, Andrej},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1402--1416},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/risteski16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/risteski16.html},\n  abstract = \t {We consider the problem of approximating partition functions for Ising models. We make use of recent tools in combinatorial optimization: the Sherali-Adams and Lasserre convex programming hierarchies, in combination with variational methods to get algorithms for calculating partition functions in these families. These techniques give new, non-trivial approximation guarantees for the partition function beyond the regime of correlation decay. They also generalize some classical results from statistical physics about the Curie-Weiss ferromagnetic Ising model, as well as provide a partition function counterpart of classical results about max-cut on dense graphs (Arora, 1995). With this, we connect techniques from two apparently disparate research areas \u2013 optimization and counting/partition function approximations. (i.e. #-P type of problems). Furthermore, we design to the best of our knowledge the first provable, convex variational methods. Though in the literature there are a host of convex versions of variational methods, they come with no guarantees (apart from some extremely special cases, like e.g. the graph has a single cycle). We consider dense and low rank graphs, and interestingly, the reason our approach works on these types of graphs is because local correlations propagate to global correlations \u2013 completely the opposite of algorithms based on correlation decay. In the process we design novel entropy approximations based on the low-order moments of a distribution. Our proof techniques are very simple and generic, and likely to be applicable to many other settings other than Ising models. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/risteski16.pdf",
        "supp": "",
        "pdf_size": 120017,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2093886888107301186&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Princeton University",
        "aff_domain": "CS.PRINCETON.EDU",
        "email": "CS.PRINCETON.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f5809b1688",
        "title": "Information-theoretic thresholds for community detection in sparse networks",
        "site": "https://proceedings.mlr.press/v49/banks16.html",
        "author": "Jess Banks; Cristopher Moore; Joe Neeman; Praneeth Netrapalli",
        "abstract": "We give upper and lower bounds on the information-theoretic threshold for community detection in the stochastic block model.  Specifically, consider a symmetric stochastic block model with q groups, average degree d, and connection probabilities c_\\mathrmin/n and c_\\mathrmout/n for within-group and between-group edges respectively; let \u03bb= (c_\\mathrmin-c_\\mathrmout)/(qd).  We show that, when q is large, and \u03bb= O(1/q), the critical value of d at which community detection becomes possible\u2014in physical terms, the condensation threshold\u2014is $ d_\\mathrmc = \u0398\\left( \\frac\\log qq \u03bb^2 \\right) \u2009,  with tighter results in certain regimes.  Above this threshold, we show that any partition of the nodes into q groups which is as \u2018good\u2019 as the planted one, in terms of the number of within- and between-group edges, is correlated with it. This gives an exponential-time algorithm that performs better than chance; specifically, community detection becomes possible below the Kesten-Stigum bound for q \\ge 5 in the disassortative case \u03bb< 0, and for q \\ge 11 in the assortative case \u03bb> 0 (similar upper bounds were obtained independently by Abbe and Sandon). Conversely, below this threshold, we show that no algorithm can label the vertices better than chance, or even distinguish the block model from an Erd\u0151s-R\u00e9nyi random graph with high probability. Our lower bound on d_\\mathrmc uses Robinson and Wormald\u2019s small subgraph conditioning method, and we also give (less explicit) results for non-symmetric stochastic block models.  In the symmetric case, we obtain explicit results by using bounds on certain functions of doubly stochastic matrices due to Achlioptas and Naor; indeed, our lower bound on d_\\mathrmc is their second moment lower bound on the q$-colorability threshold for random graphs with a certain effective degree.",
        "bibtex": "@InProceedings{pmlr-v49-banks16,\n  title = \t {Information-theoretic thresholds for community detection in sparse networks},\n  author = \t {Banks, Jess and Moore, Cristopher and Neeman, Joe and Netrapalli, Praneeth},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {383--416},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/banks16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/banks16.html},\n  abstract = \t {We give upper and lower bounds on the information-theoretic threshold for community detection in the stochastic block model.  Specifically, consider a symmetric stochastic block model with q groups, average degree d, and connection probabilities c_\\mathrmin/n and c_\\mathrmout/n for within-group and between-group edges respectively; let \u03bb= (c_\\mathrmin-c_\\mathrmout)/(qd).  We show that, when q is large, and \u03bb= O(1/q), the critical value of d at which community detection becomes possible\u2014in physical terms, the condensation threshold\u2014is $ d_\\mathrmc = \u0398\\left( \\frac\\log qq \u03bb^2 \\right) \u2009,  with tighter results in certain regimes.  Above this threshold, we show that any partition of the nodes into q groups which is as \u2018good\u2019 as the planted one, in terms of the number of within- and between-group edges, is correlated with it. This gives an exponential-time algorithm that performs better than chance; specifically, community detection becomes possible below the Kesten-Stigum bound for q \\ge 5 in the disassortative case \u03bb< 0, and for q \\ge 11 in the assortative case \u03bb> 0 (similar upper bounds were obtained independently by Abbe and Sandon). Conversely, below this threshold, we show that no algorithm can label the vertices better than chance, or even distinguish the block model from an Erd\u0151s-R\u00e9nyi random graph with high probability. Our lower bound on d_\\mathrmc uses Robinson and Wormald\u2019s small subgraph conditioning method, and we also give (less explicit) results for non-symmetric stochastic block models.  In the symmetric case, we obtain explicit results by using bounds on certain functions of doubly stochastic matrices due to Achlioptas and Naor; indeed, our lower bound on d_\\mathrmc is their second moment lower bound on the q$-colorability threshold for random graphs with a certain effective degree.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/banks16.pdf",
        "supp": "",
        "pdf_size": 338080,
        "gs_citation": 146,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2932284051196347572&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Santa Fe Institute, Santa Fe, New Mexico; Santa Fe Institute, Santa Fe, New Mexico; Institute of Applied Mathematics, University of Bonn + Mathematics Department, University of Texas, Austin; Microsoft Research, Cambridge MA",
        "aff_domain": "gmail.com;santafe.edu;gmail.com;microsoft.com",
        "email": "gmail.com;santafe.edu;gmail.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;3",
        "aff_unique_norm": "Santa Fe Institute;University of Bonn;University of Texas at Austin;Microsoft",
        "aff_unique_dep": ";Institute of Applied Mathematics;Department of Mathematics;Microsoft Research",
        "aff_unique_url": "https://www.santafe.edu;https://www.uni-bonn.de;https://www.utexas.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "SFI;;UT Austin;MSR",
        "aff_campus_unique_index": "0;0;2;3",
        "aff_campus_unique": "Santa Fe;;Austin;Cambridge",
        "aff_country_unique_index": "0;0;1+0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "39d05c30ca",
        "title": "Instance-dependent Regret Bounds for Dueling Bandits",
        "site": "https://proceedings.mlr.press/v49/balsubramani16.html",
        "author": "Akshay Balsubramani; Zohar Karnin; Robert E. Schapire; Masrour Zoghi",
        "abstract": "We study the multi-armed dueling bandit problem in which feedback is provided in the form of relative comparisons between pairs of actions, with the goal of eventually learning to select actions that are close to the best. Following  Dudik et al. (2015), we aim for algorithms whose performance approaches that of the optimal randomized choice of actions, the von Neumann winner, expressly avoiding more restrictive assumptions, for instance, regarding the existence of a single best action (a Condorcet winner). In this general setting, the best known algorithms achieve regret O(\\sqrtKT) in T rounds with K actions. In this paper, we present the first instance-dependent regret bounds for the general problem, focusing particularly on when the von Neumann winner is sparse. Specifically, we propose a new algorithm whose regret, relative to a unique von Neumann winner with sparsity s, is at most O(\\sqrtsT), plus an instance-dependent constant. Thus, when the sparsity is much smaller than the total number of actions, our result indicates that learning can be substantially faster.",
        "bibtex": "@InProceedings{pmlr-v49-balsubramani16,\n  title = \t {Instance-dependent Regret Bounds for Dueling Bandits},\n  author = \t {Balsubramani, Akshay and Karnin, Zohar and Schapire, Robert E. and Zoghi, Masrour},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {336--360},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/balsubramani16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/balsubramani16.html},\n  abstract = \t {We study the multi-armed dueling bandit problem in which feedback is provided in the form of relative comparisons between pairs of actions, with the goal of eventually learning to select actions that are close to the best. Following  Dudik et al. (2015), we aim for algorithms whose performance approaches that of the optimal randomized choice of actions, the von Neumann winner, expressly avoiding more restrictive assumptions, for instance, regarding the existence of a single best action (a Condorcet winner). In this general setting, the best known algorithms achieve regret O(\\sqrtKT) in T rounds with K actions. In this paper, we present the first instance-dependent regret bounds for the general problem, focusing particularly on when the von Neumann winner is sparse. Specifically, we propose a new algorithm whose regret, relative to a unique von Neumann winner with sparsity s, is at most O(\\sqrtsT), plus an instance-dependent constant. Thus, when the sparsity is much smaller than the total number of actions, our result indicates that learning can be substantially faster.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/balsubramani16.pdf",
        "supp": "",
        "pdf_size": 340605,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8355646979422183860&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "UC San Diego, CA, USA; Yahoo! Research, New York, NY, USA; Microsoft Research, New York, NY, USA; University of Amsterdam, Netherlands",
        "aff_domain": "UCSD.EDU;YAHOO-INC.COM;MICROSOFT.COM;UVA.NL",
        "email": "UCSD.EDU;YAHOO-INC.COM;MICROSOFT.COM;UVA.NL",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "University of California, San Diego;Yahoo! Research;Microsoft;University of Amsterdam",
        "aff_unique_dep": ";;Microsoft Research;",
        "aff_unique_url": "https://ucsd.edu;https://research.yahoo.com;https://www.microsoft.com/en-us/research;https://www.uva.nl",
        "aff_unique_abbr": "UCSD;Yahoo! Res;MSR;UvA",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "San Diego;New York;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Netherlands"
    },
    {
        "id": "b4e9d006e7",
        "title": "Interactive Algorithms: from Pool to Stream",
        "site": "https://proceedings.mlr.press/v49/sabato16.html",
        "author": "Sivan Sabato; Tom Hess",
        "abstract": "We consider interactive algorithms in the pool-based setting, and in the stream-based setting. Interactive algorithms observe suggested elements (representing actions or queries), and interactively select some of them and receive responses. Pool-based algorithms can select elements at any order, while stream-based algorithms observe elements in sequence, and can only select elements immediately after observing them. We assume that the suggested elements are generated independently from some source distribution, and ask what is the stream size required for emulating a pool algorithm with a given pool size. We provide algorithms and matching lower bounds for general pool algorithms, and for utility-based pool algorithms. We further show that a maximal gap between the two settings exists also in the special case of active learning for binary classification.",
        "bibtex": "@InProceedings{pmlr-v49-sabato16,\n  title = \t {Interactive Algorithms: from Pool to Stream},\n  author = \t {Sabato, Sivan and Hess, Tom},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1419--1439},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/sabato16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/sabato16.html},\n  abstract = \t {We consider interactive algorithms in the pool-based setting, and in the stream-based setting. Interactive algorithms observe suggested elements (representing actions or queries), and interactively select some of them and receive responses. Pool-based algorithms can select elements at any order, while stream-based algorithms observe elements in sequence, and can only select elements immediately after observing them. We assume that the suggested elements are generated independently from some source distribution, and ask what is the stream size required for emulating a pool algorithm with a given pool size. We provide algorithms and matching lower bounds for general pool algorithms, and for utility-based pool algorithms. We further show that a maximal gap between the two settings exists also in the special case of active learning for binary classification.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/sabato16.pdf",
        "supp": "",
        "pdf_size": 287216,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2863187471323911678&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel; Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel",
        "aff_domain": "cs.bgu.ac.il;post.bgu.ac.il",
        "email": "cs.bgu.ac.il;post.bgu.ac.il",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beer Sheva",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "26402941ed",
        "title": "Learning Combinatorial Functions from Pairwise Comparisons",
        "site": "https://proceedings.mlr.press/v49/balcan16b.html",
        "author": "Maria-Florina Balcan; Ellen Vitercik; Colin White",
        "abstract": "A large body of work in machine learning has focused on the problem of learning a close approximation to an underlying combinatorial function, given a small set of labeled examples. However, for real-valued functions, cardinal labels might not be accessible, or it may be difficult for an expert to consistently assign real-valued labels over the entire set of examples. For instance, it is notoriously hard for consumers to reliably assign values to bundles of merchandise. Instead, it might be much easier for a consumer to report which of two bundles she likes better. With this motivation in mind, we consider an alternative learning model, wherein the algorithm must learn the underlying function up to pairwise comparisons, from pairwise comparisons. In this model, we present a series of novel algorithms that learn over a wide variety of combinatorial function classes. These range from graph functions to broad classes of valuation functions that are fundamentally important in microeconomic theory, the analysis of social networks, and machine learning, such as coverage, submodular, XOS, and subadditive functions, as well as functions with sparse Fourier support.",
        "bibtex": "@InProceedings{pmlr-v49-balcan16b,\n  title = \t {Learning Combinatorial Functions from Pairwise Comparisons},\n  author = \t {Balcan, Maria-Florina and Vitercik, Ellen and White, Colin},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {310--335},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/balcan16b.pdf},\n  url = \t {https://proceedings.mlr.press/v49/balcan16b.html},\n  abstract = \t {A large body of work in machine learning has focused on the problem of learning a close approximation to an underlying combinatorial function, given a small set of labeled examples. However, for real-valued functions, cardinal labels might not be accessible, or it may be difficult for an expert to consistently assign real-valued labels over the entire set of examples. For instance, it is notoriously hard for consumers to reliably assign values to bundles of merchandise. Instead, it might be much easier for a consumer to report which of two bundles she likes better. With this motivation in mind, we consider an alternative learning model, wherein the algorithm must learn the underlying function up to pairwise comparisons, from pairwise comparisons. In this model, we present a series of novel algorithms that learn over a wide variety of combinatorial function classes. These range from graph functions to broad classes of valuation functions that are fundamentally important in microeconomic theory, the analysis of social networks, and machine learning, such as coverage, submodular, XOS, and subadditive functions, as well as functions with sparse Fourier support.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/balcan16b.pdf",
        "supp": "",
        "pdf_size": 627213,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8922795296346490986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu;cs.cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu;cs.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "87378d5ab0",
        "title": "Learning Communities in the Presence of Errors",
        "site": "https://proceedings.mlr.press/v49/makarychev16.html",
        "author": "Konstantin Makarychev; Yury Makarychev; Aravindan Vijayaraghavan",
        "abstract": "We study the problem of learning communities in the presence of modeling errors and give  robust recovery algorithms for the Stochastic Block Model (SBM). This model, which is also known as the Planted Partition Model,  is widely used for community detection and graph partitioning in various fields, including machine learning,  statistics, and social sciences. Many algorithms exist for learning communities in the Stochastic Block Model, but they do not work well in the presence of errors. In this paper, we initiate the study of robust algorithms for partial recovery in SBM with modeling errors or noise. We consider graphs generated according to the Stochastic Block Model and then modified by an adversary. We allow two types of adversarial errors, Feige\u2014Kilian or monotone errors, and edge outlier errors. Mossel, Neeman and Sly (STOC 2015) posed an open question about whether an almost exact recovery is possible when the adversary is allowed to add o(n) edges. Our work answers this question affirmatively even in the case of k>2 communities. We then show that our algorithms work not only when the instances come from SBM, but also work when the instances come from any distribution of graphs that is \\varepsilon m close to SBM in the Kullback\u2014Leibler divergence. This result also works in the presence of adversarial errors. Finally, we present almost tight lower bounds for two communities.",
        "bibtex": "@InProceedings{pmlr-v49-makarychev16,\n  title = \t {Learning Communities in the Presence of Errors},\n  author = \t {Makarychev, Konstantin and Makarychev, Yury and Vijayaraghavan, Aravindan},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1258--1291},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/makarychev16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/makarychev16.html},\n  abstract = \t {We study the problem of learning communities in the presence of modeling errors and give  robust recovery algorithms for the Stochastic Block Model (SBM). This model, which is also known as the Planted Partition Model,  is widely used for community detection and graph partitioning in various fields, including machine learning,  statistics, and social sciences. Many algorithms exist for learning communities in the Stochastic Block Model, but they do not work well in the presence of errors. In this paper, we initiate the study of robust algorithms for partial recovery in SBM with modeling errors or noise. We consider graphs generated according to the Stochastic Block Model and then modified by an adversary. We allow two types of adversarial errors, Feige\u2014Kilian or monotone errors, and edge outlier errors. Mossel, Neeman and Sly (STOC 2015) posed an open question about whether an almost exact recovery is possible when the adversary is allowed to add o(n) edges. Our work answers this question affirmatively even in the case of k>2 communities. We then show that our algorithms work not only when the instances come from SBM, but also work when the instances come from any distribution of graphs that is \\varepsilon m close to SBM in the Kullback\u2014Leibler divergence. This result also works in the presence of adversarial errors. Finally, we present almost tight lower bounds for two communities. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/makarychev16.pdf",
        "supp": "",
        "pdf_size": 450660,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6221329353770835670&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3c4d149687",
        "title": "Learning Simple Auctions",
        "site": "https://proceedings.mlr.press/v49/morgenstern16.html",
        "author": "Jamie Morgenstern; Tim Roughgarden",
        "abstract": "We present a general framework for proving polynomial sample complexity bounds for the problem of learning from samples the best auction in a class of \u201csimple\u201d auctions.  Our framework captures the most prominent examples of \u201csimple\u201d auctions, including anonymous and non-anonymous item and bundle pricings, with either a single or multiple buyers.  The first step of the framework is to show that the set of auction allocation rules have a low-dimensional representation.  The second step shows that, across the subset of auctions that share the same allocations on a given set of samples, the auction revenue varies in a low-dimensional way. Our results effectively imply that whenever it is possible to compute a near-optimal simple auction with a known prior, it is also possible to compute such an auction with an unknown prior, given a polynomial number of samples.",
        "bibtex": "@InProceedings{pmlr-v49-morgenstern16,\n  title = \t {Learning Simple Auctions},\n  author = \t {Morgenstern, Jamie and Roughgarden, Tim},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1298--1318},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/morgenstern16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/morgenstern16.html},\n  abstract = \t {We present a general framework for proving polynomial sample complexity bounds for the problem of learning from samples the best auction in a class of \u201csimple\u201d auctions.  Our framework captures the most prominent examples of \u201csimple\u201d auctions, including anonymous and non-anonymous item and bundle pricings, with either a single or multiple buyers.  The first step of the framework is to show that the set of auction allocation rules have a low-dimensional representation.  The second step shows that, across the subset of auctions that share the same allocations on a given set of samples, the auction revenue varies in a low-dimensional way. Our results effectively imply that whenever it is possible to compute a near-optimal simple auction with a known prior, it is also possible to compute such an auction with an unknown prior, given a polynomial number of samples. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/morgenstern16.pdf",
        "supp": "",
        "pdf_size": 345803,
        "gs_citation": 154,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3445500982915945332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "df81b1ee91",
        "title": "Learning and 1-bit Compressed Sensing under Asymmetric Noise",
        "site": "https://proceedings.mlr.press/v49/awasthi16.html",
        "author": "Pranjal Awasthi; Maria-Florina Balcan; Nika Haghtalab; Hongyang Zhang",
        "abstract": "We study the \\emphapproximate recovery problem: Given corrupted 1-bit measurements of the form sign(w^* \u22c5x_i), recover a vector w that is a good approximation to w^* \u2208\\Re^d. This problem has been studied by both the learning theory and signal processing communities. In learning theory, this is known as the problem of \\emphlearning halfspaces with noise, and in signal processing, as \\emph1-bit compressed sensing, in which there is an additional assumption that w^* is t-sparse. The challenge in both cases is to design computationally efficient algorithms that are tolerant to large amounts of noise under realistic noise models. Furthermore, in the case of 1-bit compressed sensing, we require  the number of measurements x_i to scale polynomially in t and only polylogarithmically in d, the ambient dimension. In this work, we introduce algorithms with nearly optimal guarantees for both problems under two realistic noise models, \\emphbounded (Massart) noise and \\emphadversarial (agnostic) noise, when the measurements x_i\u2019s are drawn from any isotropic log-concave distribution. In bounded (Massart) noise, an adversary can flip the measurement of each point x with probability \u03b7(x)\u2264\u03b7< 1/2. For this problem, we present an efficient algorithm that returns w such that \\|w- w^*\\|_2 \u2264\u03b5in time poly(d, \\frac 1 \u03b5) for \\emphany constant \u03b7< 1/2.  This improves significantly over the best known result of Awasthi et al. 2015, in this space that required the noise to be as small as \u03b7\u224810^-6. We then introduce an attribute-efficient variant of this algorithm for 1-bit compressed sensing that achieves the same guarantee with poly(t, \\log(d), \\frac 1 \u03b5) measurements when \\|w^*\\|_0\u2264t. For adversarial (agnostic) noise, where any \u03bdfraction of measurements can be corrupted, we provide an algorithm that returns w such that \\|w-w^*\\|_2 \u2264O(\u03bd) + \u03b5, with  \\tilde\u03a9( \\frac t \u03b5^3  \\polylog(d))  measurements. Our results improve on the best known approximation results in this space and under some regimes improve on the sample complexity of the existing results. Furthermore, this  is the first result of its kind in 1-bit compressed sensing that goes beyond the Gaussian marginal distribution and works for any isotrpic log-concave distribution.",
        "bibtex": "@InProceedings{pmlr-v49-awasthi16,\n  title = \t {Learning and 1-bit Compressed Sensing under Asymmetric Noise},\n  author = \t {Awasthi, Pranjal and Balcan, Maria-Florina and Haghtalab, Nika and Zhang, Hongyang},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {152--192},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/awasthi16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/awasthi16.html},\n  abstract = \t {We study the \\emphapproximate recovery problem: Given corrupted 1-bit measurements of the form sign(w^* \u22c5x_i), recover a vector w that is a good approximation to w^* \u2208\\Re^d. This problem has been studied by both the learning theory and signal processing communities. In learning theory, this is known as the problem of \\emphlearning halfspaces with noise, and in signal processing, as \\emph1-bit compressed sensing, in which there is an additional assumption that w^* is t-sparse. The challenge in both cases is to design computationally efficient algorithms that are tolerant to large amounts of noise under realistic noise models. Furthermore, in the case of 1-bit compressed sensing, we require  the number of measurements x_i to scale polynomially in t and only polylogarithmically in d, the ambient dimension. In this work, we introduce algorithms with nearly optimal guarantees for both problems under two realistic noise models, \\emphbounded (Massart) noise and \\emphadversarial (agnostic) noise, when the measurements x_i\u2019s are drawn from any isotropic log-concave distribution. In bounded (Massart) noise, an adversary can flip the measurement of each point x with probability \u03b7(x)\u2264\u03b7< 1/2. For this problem, we present an efficient algorithm that returns w such that \\|w- w^*\\|_2 \u2264\u03b5in time poly(d, \\frac 1 \u03b5) for \\emphany constant \u03b7< 1/2.  This improves significantly over the best known result of Awasthi et al. 2015, in this space that required the noise to be as small as \u03b7\u224810^-6. We then introduce an attribute-efficient variant of this algorithm for 1-bit compressed sensing that achieves the same guarantee with poly(t, \\log(d), \\frac 1 \u03b5) measurements when \\|w^*\\|_0\u2264t. For adversarial (agnostic) noise, where any \u03bdfraction of measurements can be corrupted, we provide an algorithm that returns w such that \\|w-w^*\\|_2 \u2264O(\u03bd) + \u03b5, with  \\tilde\u03a9( \\frac t \u03b5^3  \\polylog(d))  measurements. Our results improve on the best known approximation results in this space and under some regimes improve on the sample complexity of the existing results. Furthermore, this  is the first result of its kind in 1-bit compressed sensing that goes beyond the Gaussian marginal distribution and works for any isotrpic log-concave distribution.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/awasthi16.pdf",
        "supp": "",
        "pdf_size": 2338901,
        "gs_citation": 111,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17265169809209319644&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 11,
        "aff": "Rutgers University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": "RUTGERS.EDU;CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU",
        "email": "RUTGERS.EDU;CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Rutgers University;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.rutgers.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Rutgers;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "35cadd9f1f",
        "title": "Learning and Testing Junta Distributions",
        "site": "https://proceedings.mlr.press/v49/aliakbarpour16.html",
        "author": "Maryam Aliakbarpour; Eric Blais; Ronitt Rubinfeld",
        "abstract": "We consider the problem of learning distributions in the presence of irrelevant features. This problem is formalized by introducing a new notion of \\emphk-junta distributions. Informally, a distribution \\mathcalD over the domain \\mathcalX^n is a \\emphk-junta distribution with respect to another distribution \\mathcalU over the same domain if there is a set J \u2286[n] of size |J| \\le k that captures the difference between \\mathcal D and \\mathcalU. We show that it is possible to learn k-junta distributions with respect to the uniform distribution over the Boolean hypercube {0,1}^n in time \\poly(n^k, 1/\u03b5). This result is obtained via a new Fourier-based learning algorithm inspired by the Low-Degree Algorithm of Linial, Mansour, and Nisan (1993). We also consider the problem of testing whether an unknown distribution is a k-junta distribution with respect to the uniform distribution. We give a nearly-optimal algorithm for this task. Both the analysis of the algorithm and the lower bound showing its optimality are obtained by establishing connections between the problem of testing junta distributions and testing uniformity of weighted collections of distributions.",
        "bibtex": "@InProceedings{pmlr-v49-aliakbarpour16,\n  title = \t {Learning and Testing Junta Distributions},\n  author = \t {Aliakbarpour, Maryam and Blais, Eric and Rubinfeld, Ronitt},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {19--46},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/aliakbarpour16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/aliakbarpour16.html},\n  abstract = \t {We consider the problem of learning distributions in the presence of irrelevant features. This problem is formalized by introducing a new notion of \\emphk-junta distributions. Informally, a distribution \\mathcalD over the domain \\mathcalX^n is a \\emphk-junta distribution with respect to another distribution \\mathcalU over the same domain if there is a set J \u2286[n] of size |J| \\le k that captures the difference between \\mathcal D and \\mathcalU. We show that it is possible to learn k-junta distributions with respect to the uniform distribution over the Boolean hypercube {0,1}^n in time \\poly(n^k, 1/\u03b5). This result is obtained via a new Fourier-based learning algorithm inspired by the Low-Degree Algorithm of Linial, Mansour, and Nisan (1993). We also consider the problem of testing whether an unknown distribution is a k-junta distribution with respect to the uniform distribution. We give a nearly-optimal algorithm for this task. Both the analysis of the algorithm and the lower bound showing its optimality are obtained by establishing connections between the problem of testing junta distributions and testing uniformity of weighted collections of distributions. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/aliakbarpour16.pdf",
        "supp": "",
        "pdf_size": 505754,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=774001758366829921&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "CSAIL, MIT, Cambridge MA 02139; David Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; CSAIL, MIT, Cambridge MA 02139 + Blavatnik School of Computer Science, Tel Aviv University",
        "aff_domain": "mit.edu;uwaterloo.ca;csail.mit.edu",
        "email": "mit.edu;uwaterloo.ca;csail.mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Waterloo;Tel Aviv University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;David Cheriton School of Computer Science;Blavatnik School of Computer Science",
        "aff_unique_url": "https://www.csail.mit.edu;https://uwaterloo.ca;https://www.tau.ac.il",
        "aff_unique_abbr": "MIT;UW;TAU",
        "aff_campus_unique_index": "0;1;0+2",
        "aff_campus_unique": "Cambridge;Waterloo;Tel Aviv",
        "aff_country_unique_index": "0;1;0+2",
        "aff_country_unique": "United States;Canada;Israel"
    },
    {
        "id": "180583c076",
        "title": "Maximin Action Identification: A New Bandit Framework for Games",
        "site": "https://proceedings.mlr.press/v49/garivier16b.html",
        "author": "Aur\u00e9lien Garivier; Emilie Kaufmann; Wouter M. Koolen",
        "abstract": "We study an original problem of pure exploration in a strategic bandit model motivated by Monte Carlo Tree Search. It consists in identifying the best action in a game, when the player may sample random outcomes of sequentially chosen pairs of actions. We propose two strategies for the fixed-confidence setting: Maximin-LUCB, based on lower- and upper- confidence bounds; and Maximin-Racing, which operates by successively eliminating the sub-optimal actions. We discuss the sample complexity of both methods and compare their performance empirically. We sketch a lower bound analysis, and possible connections to an optimal algorithm.",
        "bibtex": "@InProceedings{pmlr-v49-garivier16b,\n  title = \t {Maximin Action Identification: A New Bandit Framework for Games},\n  author = \t {Garivier, Aur\u00e9lien and Kaufmann, Emilie and Koolen, Wouter M.},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1028--1050},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/garivier16b.pdf},\n  url = \t {https://proceedings.mlr.press/v49/garivier16b.html},\n  abstract = \t {We study an original problem of pure exploration in a strategic bandit model motivated by Monte Carlo Tree Search. It consists in identifying the best action in a game, when the player may sample random outcomes of sequentially chosen pairs of actions. We propose two strategies for the fixed-confidence setting: Maximin-LUCB, based on lower- and upper- confidence bounds; and Maximin-Racing, which operates by successively eliminating the sub-optimal actions. We discuss the sample complexity of both methods and compare their performance empirically. We sketch a lower bound analysis, and possible connections to an optimal algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/garivier16b.pdf",
        "supp": "",
        "pdf_size": 329701,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16427134999359460487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 17,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2612e9f1a0",
        "title": "Memory, Communication, and Statistical Queries",
        "site": "https://proceedings.mlr.press/v49/steinhardt16.html",
        "author": "Jacob Steinhardt; Gregory Valiant; Stefan Wager",
        "abstract": "If a concept class can be represented with a certain amount of memory, can it be efficiently learned with the same amount of memory? What concepts can be efficiently learned by algorithms that extract only a few bits of information from each example? We introduce a formal framework for studying these questions, and investigate the relationship between the fundamental resources of memory or communication and the sample complexity of the learning task. We relate our memory-bounded and communication-bounded learning models to the well-studied statistical query model. This connection can be leveraged to obtain both upper and lower bounds: we show strong lower bounds on learning parity functions with bounded communication, as well as upper bounds on solving sparse linear regression problems with limited memory.",
        "bibtex": "@InProceedings{pmlr-v49-steinhardt16,\n  title = \t {Memory, Communication, and Statistical Queries},\n  author = \t {Steinhardt, Jacob and Valiant, Gregory and Wager, Stefan},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1490--1516},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/steinhardt16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/steinhardt16.html},\n  abstract = \t {If a concept class can be represented with a certain amount of memory, can it be efficiently learned with the same amount of memory? What concepts can be efficiently learned by algorithms that extract only a few bits of information from each example? We introduce a formal framework for studying these questions, and investigate the relationship between the fundamental resources of memory or communication and the sample complexity of the learning task. We relate our memory-bounded and communication-bounded learning models to the well-studied statistical query model. This connection can be leveraged to obtain both upper and lower bounds: we show strong lower bounds on learning parity functions with bounded communication, as well as upper bounds on solving sparse linear regression problems with limited memory.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/steinhardt16.pdf",
        "supp": "",
        "pdf_size": 433639,
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14056031730268977861&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Departments of Computer Science*; Departments of Computer Science\u2020; Departments of Statistics\u2021, Stanford University, Stanford, CA-94305, USA",
        "aff_domain": "CS.STANFORD.EDU;STANFORD.EDU;STANFORD.EDU",
        "email": "CS.STANFORD.EDU;STANFORD.EDU;STANFORD.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Computer Science Department;University Affiliation Not Specified;Stanford University",
        "aff_unique_dep": "Computer Science;Departments of Computer Science;Departments of Statistics",
        "aff_unique_url": ";;https://www.stanford.edu",
        "aff_unique_abbr": ";;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "6ea2dde729",
        "title": "Monte Carlo Markov Chain Algorithms for Sampling Strongly Rayleigh Distributions and Determinantal Point Processes",
        "site": "https://proceedings.mlr.press/v49/anari16.html",
        "author": "Nima Anari; Shayan Oveis Gharan; Alireza Rezaei",
        "abstract": "Strongly Rayleigh distributions are natural generalizations of product and determinantal probability distributions and satisfy the strongest form of negative dependence properties. We show that the \"natural\" Monte Carlo Markov Chain (MCMC) algorithm mixes rapidly in the support of a homogeneous strongly Rayleigh distribution. As a byproduct, our proof implies Markov chains can be used to efficiently generate approximate samples of a k-determinantal point process. This answers an open question raised by Deshpande and Rademacher which was studied recently by Kang, Li-Jegelka-Sra, and Rebeschini-Karbasi.",
        "bibtex": "@InProceedings{pmlr-v49-anari16,\n  title = \t {Monte Carlo Markov Chain Algorithms for Sampling Strongly Rayleigh Distributions and Determinantal Point Processes},\n  author = \t {Anari, Nima and Oveis Gharan, Shayan and Rezaei, Alireza},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {103--115},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/anari16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/anari16.html},\n  abstract = \t {Strongly Rayleigh distributions are natural generalizations of product and determinantal probability distributions and satisfy the strongest form of negative dependence properties. We show that the \"natural\" Monte Carlo Markov Chain (MCMC) algorithm mixes rapidly in the support of a homogeneous strongly Rayleigh distribution. As a byproduct, our proof implies Markov chains can be used to efficiently generate approximate samples of a k-determinantal point process. This answers an open question raised by Deshpande and Rademacher which was studied recently by Kang, Li-Jegelka-Sra, and Rebeschini-Karbasi. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/anari16.pdf",
        "supp": "",
        "pdf_size": 261921,
        "gs_citation": 137,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4233782206788183372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Management Science and Engineering, Stanford University; Department of Computer Science and Engineering, University of Washington; Department of Computer Science and Engineering, University of Washington",
        "aff_domain": "berkeley.edu;cs.washington.edu;cs.wshington.edu",
        "email": "berkeley.edu;cs.washington.edu;cs.wshington.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Stanford University;University of Washington",
        "aff_unique_dep": "Department of Management Science and Engineering;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.stanford.edu;https://www.washington.edu",
        "aff_unique_abbr": "Stanford;UW",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Stanford;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a9f6cf6a9e",
        "title": "Multi-scale exploration of convex functions and bandit convex optimization",
        "site": "https://proceedings.mlr.press/v49/bubeck16.html",
        "author": "S\u00e9bastien Bubeck; Ronen Eldan",
        "abstract": "We construct a new map from a convex function to a distribution on its domain, with the property that this distribution is a multi-scale exploration of the function. We use this map to solve a decade-old open problem in adversarial bandit convex optimization by showing that the minimax regret for this problem is \\tildeO(\\mathrmpoly(n) \\sqrtT), where n is the dimension and T the number of rounds. This bound is obtained by studying the dual Bayesian maximin regret via the information ratio analysis of Russo and Van Roy, and then using the multi-scale exploration to construct a new algorithm for the Bayesian convex bandit problem.",
        "bibtex": "@InProceedings{pmlr-v49-bubeck16,\n  title = \t {Multi-scale exploration of convex functions and bandit convex optimization},\n  author = \t {Bubeck, S\u00e9bastien and Eldan, Ronen},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {583--589},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/bubeck16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/bubeck16.html},\n  abstract = \t {We construct a new map from a convex function to a distribution on its domain, with the property that this distribution is a multi-scale exploration of the function. We use this map to solve a decade-old open problem in adversarial bandit convex optimization by showing that the minimax regret for this problem is \\tildeO(\\mathrmpoly(n) \\sqrtT), where n is the dimension and T the number of rounds. This bound is obtained by studying the dual Bayesian maximin regret via the information ratio analysis of Russo and Van Roy, and then using the multi-scale exploration to construct a new algorithm for the Bayesian convex bandit problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/bubeck16.pdf",
        "supp": "",
        "pdf_size": 214039,
        "gs_citation": 89,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5402243810638670600&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Microsoft Research; Weizmann Institute",
        "aff_domain": "MICROSOFT.COM;GMAIL.COM",
        "email": "MICROSOFT.COM;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Microsoft;Weizmann Institute of Science",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.weizmann.org.il",
        "aff_unique_abbr": "MSR;Weizmann",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "15a31323fb",
        "title": "Noisy Tensor Completion via the Sum-of-Squares Hierarchy",
        "site": "https://proceedings.mlr.press/v49/barak16.html",
        "author": "Boaz Barak; Ankur Moitra",
        "abstract": "In the noisy tensor completion problem we observe m entries (whose location is chosen uniformly at random) from an unknown n_1 \\times n_2 \\times n_3 tensor T. We assume that T is entry-wise close to being rank r. Our goal is to fill in its missing entries using as few observations as possible. Let n = \\max(n_1, n_2, n_3). We show that if m =  n^3/2 r then there is a polynomial time algorithm based on the sixth level of the sum-of-squares hierarchy for completing it. Our estimate agrees with almost all of T\u2019s entries almost exactly and works even when our observations are corrupted by noise. This is also the first algorithm for tensor completion that works in the overcomplete case when r > n, and in fact it works all the way up to r = n^3/2-\u03b5. Our proofs are short and simple and are based on establishing a new connection between noisy tensor completion (through the language of Rademacher complexity) and the task of refuting random constant satisfaction problems. This connection seems to have gone unnoticed even in the context of matrix completion. Furthermore, we use this connection to show matching lower bounds. Our main technical result is in characterizing the Rademacher complexity of the sequence of norms that arise in the sum-of-squares relaxations to the tensor nuclear norm.  These results point to an interesting new direction: Can we explore computational vs. sample complexity tradeoffs through the sum-of-squares hierarchy?",
        "bibtex": "@InProceedings{pmlr-v49-barak16,\n  title = \t {Noisy Tensor Completion via the Sum-of-Squares Hierarchy},\n  author = \t {Barak, Boaz and Moitra, Ankur},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {417--445},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/barak16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/barak16.html},\n  abstract = \t {In the noisy tensor completion problem we observe m entries (whose location is chosen uniformly at random) from an unknown n_1 \\times n_2 \\times n_3 tensor T. We assume that T is entry-wise close to being rank r. Our goal is to fill in its missing entries using as few observations as possible. Let n = \\max(n_1, n_2, n_3). We show that if m =  n^3/2 r then there is a polynomial time algorithm based on the sixth level of the sum-of-squares hierarchy for completing it. Our estimate agrees with almost all of T\u2019s entries almost exactly and works even when our observations are corrupted by noise. This is also the first algorithm for tensor completion that works in the overcomplete case when r > n, and in fact it works all the way up to r = n^3/2-\u03b5. Our proofs are short and simple and are based on establishing a new connection between noisy tensor completion (through the language of Rademacher complexity) and the task of refuting random constant satisfaction problems. This connection seems to have gone unnoticed even in the context of matrix completion. Furthermore, we use this connection to show matching lower bounds. Our main technical result is in characterizing the Rademacher complexity of the sequence of norms that arise in the sum-of-squares relaxations to the tensor nuclear norm.  These results point to an interesting new direction: Can we explore computational vs. sample complexity tradeoffs through the sum-of-squares hierarchy?}\n}",
        "pdf": "http://proceedings.mlr.press/v49/barak16.pdf",
        "supp": "",
        "pdf_size": 363968,
        "gs_citation": 200,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15162139359172355699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "aff": "Harvard John A. Paulson School of Engineering and Applied Sciences; Massachusetts Institute of Technology. Department of Mathematics and the Computer Science and Artificial Intelligence Lab",
        "aff_domain": "BOAZBARAK.ORG;MIT.EDU",
        "email": "BOAZBARAK.ORG;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Harvard University;Massachusetts Institute of Technology",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences;Department of Mathematics and the Computer Science and Artificial Intelligence Lab",
        "aff_unique_url": "https://www.seas.harvard.edu;https://www.mit.edu",
        "aff_unique_abbr": "Harvard SEAS;MIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bc229b48d6",
        "title": "On the Approximability of Sparse PCA",
        "site": "https://proceedings.mlr.press/v49/chan16.html",
        "author": "Siu On Chan; Dimitris Papailliopoulos; Aviad Rubinstein",
        "abstract": "It is well known that Sparse PCA (Sparse Principal Component Analysis) is NP-hard to solve exactly on worst-case instances. What is the complexity of solving Sparse PCA approximately? Our contributions include: \\beginenumerate \\item a simple and efficient algorithm that achieves an n^-1/3-approximation; \\item NP-hardness of approximation to within (1-\\varepsilon), for some small constant \\varepsilon > 0; \\item SSE-hardness of approximation to within \\em any constant factor; and \\item an \\exp\\exp\\left(\u03a9\\left(\\sqrt\\log \\log n\\right)\\right) (\u201cquasi-quasi-polynomial\u201d) gap for the standard semidefinite program. \\endenumerate",
        "bibtex": "@InProceedings{pmlr-v49-chan16,\n  title = \t {On the Approximability of Sparse PCA},\n  author = \t {Chan, Siu On and Papailliopoulos, Dimitris and Rubinstein, Aviad},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {623--646},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/chan16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/chan16.html},\n  abstract = \t {It is well known that Sparse PCA (Sparse Principal Component Analysis) is NP-hard to solve exactly on worst-case instances. What is the complexity of solving Sparse PCA approximately? Our contributions include: \\beginenumerate \\item a simple and efficient algorithm that achieves an n^-1/3-approximation; \\item NP-hardness of approximation to within (1-\\varepsilon), for some small constant \\varepsilon > 0; \\item SSE-hardness of approximation to within \\em any constant factor; and \\item an \\exp\\exp\\left(\u03a9\\left(\\sqrt\\log \\log n\\right)\\right) (\u201cquasi-quasi-polynomial\u201d) gap for the standard semidefinite program. \\endenumerate}\n}",
        "pdf": "http://proceedings.mlr.press/v49/chan16.pdf",
        "supp": "",
        "pdf_size": 504241,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5992143983764390061&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Chinese University of Hong Kong + Microsoft Research New England; UC Berkeley; UC Berkeley + Simons Institute for the Theory of Computing + Microsoft Research New England",
        "aff_domain": "gmail.com;berkeley.edu;eecs.berkeley.edu",
        "email": "gmail.com;berkeley.edu;eecs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;2+3+1",
        "aff_unique_norm": "Chinese University of Hong Kong;Microsoft;University of California, Berkeley;Simons Institute for the Theory of Computing",
        "aff_unique_dep": ";Microsoft Research;;",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.microsoft.com/en-us/research/group/microsoft-research-new-england;https://www.berkeley.edu;https://simons.berkeley.edu",
        "aff_unique_abbr": "CUHK;MSR NE;UC Berkeley;",
        "aff_campus_unique_index": "0+1;2;2+1",
        "aff_campus_unique": "Hong Kong SAR;New England;Berkeley;",
        "aff_country_unique_index": "0+1;1;1+1+1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "860ddad3f6",
        "title": "On the Expressive Power of Deep Learning: A Tensor Analysis",
        "site": "https://proceedings.mlr.press/v49/cohen16.html",
        "author": "Nadav Cohen; Or Sharir; Amnon Shashua",
        "abstract": "It has long been conjectured that hypotheses spaces suitable for data that is compositional in nature, such as text or images, may be more efficiently represented with deep hierarchical networks than with shallow ones. Despite the vast empirical evidence supporting this belief, theoretical justifications to date are limited. In particular, they do not account for the locality, sharing and pooling constructs of convolutional networks, the most successful deep learning architecture to date. In this work we derive a deep network architecture based on arithmetic circuits that inherently employs locality, sharing and pooling. An equivalence between the networks and hierarchical tensor factorizations is established. We show that a shallow network corresponds to CP (rank-1) decomposition, whereas a deep network corresponds to Hierarchical Tucker decomposition. Using tools from measure theory and matrix algebra, we prove that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be realized (or even approximated) by a shallow network. Since log-space computation transforms our networks into SimNets, the result applies directly to a deep learning architecture demonstrating promising empirical performance. The construction and theory developed in this paper shed new light on various practices and ideas employed by the deep learning community.",
        "bibtex": "@InProceedings{pmlr-v49-cohen16,\n  title = \t {On the Expressive Power of Deep Learning: A Tensor Analysis},\n  author = \t {Cohen, Nadav and Sharir, Or and Shashua, Amnon},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {698--728},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/cohen16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/cohen16.html},\n  abstract = \t {It has long been conjectured that hypotheses spaces suitable for data that is compositional in nature, such as text or images, may be more efficiently represented with deep hierarchical networks than with shallow ones. Despite the vast empirical evidence supporting this belief, theoretical justifications to date are limited. In particular, they do not account for the locality, sharing and pooling constructs of convolutional networks, the most successful deep learning architecture to date. In this work we derive a deep network architecture based on arithmetic circuits that inherently employs locality, sharing and pooling. An equivalence between the networks and hierarchical tensor factorizations is established. We show that a shallow network corresponds to CP (rank-1) decomposition, whereas a deep network corresponds to Hierarchical Tucker decomposition. Using tools from measure theory and matrix algebra, we prove that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be realized (or even approximated) by a shallow network. Since log-space computation transforms our networks into SimNets, the result applies directly to a deep learning architecture demonstrating promising empirical performance. The construction and theory developed in this paper shed new light on various practices and ideas employed by the deep learning community.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/cohen16.pdf",
        "supp": "",
        "pdf_size": 841431,
        "gs_citation": 594,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4357399923827931570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "The Hebrew University of Jerusalem; The Hebrew University of Jerusalem; The Hebrew University of Jerusalem",
        "aff_domain": "CS.HUJI.AC.IL;CS.HUJI.AC.IL;CS.HUJI.AC.IL",
        "email": "CS.HUJI.AC.IL;CS.HUJI.AC.IL;CS.HUJI.AC.IL",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hebrew University of Jerusalem",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.huji.ac.il",
        "aff_unique_abbr": "HUJI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "bd556aee6d",
        "title": "On the capacity of information processing systems",
        "site": "https://proceedings.mlr.press/v49/massoulie16.html",
        "author": "Laurent Massoulie; Kuang Xu",
        "abstract": "We propose and analyze a family of \\emphinformation processing systems, where a finite set of experts or servers are employed to extract information about a stream of incoming jobs. Each job is associated with a hidden label drawn from some prior distribution. An inspection by an expert produces a noisy outcome that depends both on the job\u2019s hidden label and the type of the expert, and occupies the expert for a finite time duration. A decision maker\u2019s task is to dynamically assign inspections so that the resulting outcomes can be used to accurately recover the labels of all jobs, while keeping the system stable. Among our chief motivations are applications in crowd-sourcing, diagnostics, and experiment designs, where one wishes to efficiently discover the nature of a large number of items, using a finite pool of computational resources or human agents. We focus on the \\emphcapacity of such an information processing system. Given a level of accuracy guarantee, we ask how many experts are needed in order to stabilize the system, and through what inspection architecture. Our main result provides an adaptive inspection policy that is asymptotically optimal in the following sense: the ratio between the required number of experts under our policy and the theoretical optimal converges to one, as the probability of error in label recovery tends to zero.",
        "bibtex": "@InProceedings{pmlr-v49-massoulie16,\n  title = \t {On the capacity of information processing systems},\n  author = \t {Massoulie, Laurent and Xu, Kuang},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1292--1297},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/massoulie16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/massoulie16.html},\n  abstract = \t {We propose and analyze a family of \\emphinformation processing systems, where a finite set of experts or servers are employed to extract information about a stream of incoming jobs. Each job is associated with a hidden label drawn from some prior distribution. An inspection by an expert produces a noisy outcome that depends both on the job\u2019s hidden label and the type of the expert, and occupies the expert for a finite time duration. A decision maker\u2019s task is to dynamically assign inspections so that the resulting outcomes can be used to accurately recover the labels of all jobs, while keeping the system stable. Among our chief motivations are applications in crowd-sourcing, diagnostics, and experiment designs, where one wishes to efficiently discover the nature of a large number of items, using a finite pool of computational resources or human agents. We focus on the \\emphcapacity of such an information processing system. Given a level of accuracy guarantee, we ask how many experts are needed in order to stabilize the system, and through what inspection architecture. Our main result provides an adaptive inspection policy that is asymptotically optimal in the following sense: the ratio between the required number of experts under our policy and the theoretical optimal converges to one, as the probability of error in label recovery tends to zero.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/massoulie16.pdf",
        "supp": "",
        "pdf_size": 218618,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6324851167993464522&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "aff": "Microsoft Research-Inria Joint Centre, 91120 Palaiseau, France; Stanford Graduate School of Business, Stanford, CA 94305, USA",
        "aff_domain": "inria.fr;stanford.edu",
        "email": "inria.fr;stanford.edu",
        "github": "",
        "project": "http://arxiv.org/abs/1603.00544",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Microsoft;Stanford University",
        "aff_unique_dep": "Microsoft Research-Inria Joint Centre;Graduate School of Business",
        "aff_unique_url": ";https://www.stanford.edu",
        "aff_unique_abbr": ";Stanford GSB",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Palaiseau;Stanford",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "a8f19e5bc8",
        "title": "On the low-rank approach for semidefinite programs arising in synchronization and community detection",
        "site": "https://proceedings.mlr.press/v49/bandeira16.html",
        "author": "Afonso S. Bandeira; Nicolas Boumal; Vladislav Voroninski",
        "abstract": "To address difficult optimization problems, convex relaxations based on semidefinite programming are now common place in many fields. Although solvable in polynomial time, large semidefinite programs tend to be computationally challenging. Over a decade ago, exploiting the fact that in many applications of interest the desired solutions are low rank, Burer and Monteiro proposed a heuristic to solve such semidefinite programs by restricting the search space to low-rank matrices. The accompanying theory does not explain the extent of the empirical success. We focus on Synchronization and Community Detection problems and provide theoretical guarantees shedding light on the remarkable efficiency of this heuristic.",
        "bibtex": "@InProceedings{pmlr-v49-bandeira16,\n  title = \t {On the low-rank approach for semidefinite programs arising in synchronization and community detection},\n  author = \t {Bandeira, Afonso S. and Boumal, Nicolas and Voroninski, Vladislav},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {361--382},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/bandeira16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/bandeira16.html},\n  abstract = \t {To address difficult optimization problems, convex relaxations based on semidefinite programming are now common place in many fields. Although solvable in polynomial time, large semidefinite programs tend to be computationally challenging. Over a decade ago, exploiting the fact that in many applications of interest the desired solutions are low rank, Burer and Monteiro proposed a heuristic to solve such semidefinite programs by restricting the search space to low-rank matrices. The accompanying theory does not explain the extent of the empirical success. We focus on Synchronization and Community Detection problems and provide theoretical guarantees shedding light on the remarkable efficiency of this heuristic.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/bandeira16.pdf",
        "supp": "",
        "pdf_size": 389533,
        "gs_citation": 181,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2971443224711329978&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Mathematics, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA; Mathematics Department, Princeton University, Princeton, New Jersey, USA; Department of Mathematics, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA",
        "aff_domain": "MIT.EDU;MATH.PRINCETON.EDU;MATH.MIT.EDU",
        "email": "MIT.EDU;MATH.PRINCETON.EDU;MATH.MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Princeton University",
        "aff_unique_dep": "Department of Mathematics;Mathematics Department",
        "aff_unique_url": "https://web.mit.edu;https://www.princeton.edu",
        "aff_unique_abbr": "MIT;Princeton",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cambridge;Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2192336c33",
        "title": "Online Isotonic Regression",
        "site": "https://proceedings.mlr.press/v49/kotlowski16.html",
        "author": "Wojciech Kot\u0142owski; Wouter M. Koolen; Alan Malek",
        "abstract": "We consider the online version of the isotonic regression problem. Given a set of linearly ordered points (e.g., on the real line), the learner must predict labels sequentially at adversarially chosen positions and is evaluated by her total squared loss compared against the best isotonic (non-decreasing) function in hindsight. We survey several standard online learning algorithms and show that none of them achieve the optimal regret exponent; in fact, most of them (including Online Gradient Descent, Follow the Leader and Exponential Weights) incur linear regret. We then prove that the Exponential Weights algorithm played over a covering net of isotonic functions has a regret bounded by O\\big(T^1/3 \\log^2/3(T)\\big) and present a matching \u03a9(T^1/3) lower bound on regret. We provide a computationally efficient version of this algorithm. We also analyze the noise-free case, in which the revealed labels are isotonic, and show that the bound can be improved to O(\\log T) or even to O(1) (when the labels are revealed in isotonic order). Finally, we extend the analysis beyond squared loss and give  bounds for entropic loss and absolute loss.",
        "bibtex": "@InProceedings{pmlr-v49-kotlowski16,\n  title = \t {Online Isotonic Regression},\n  author = \t {Kot\u0142owski, Wojciech and Koolen, Wouter M. and Malek, Alan},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1165--1189},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/kotlowski16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/kotlowski16.html},\n  abstract = \t {We consider the online version of the isotonic regression problem. Given a set of linearly ordered points (e.g., on the real line), the learner must predict labels sequentially at adversarially chosen positions and is evaluated by her total squared loss compared against the best isotonic (non-decreasing) function in hindsight. We survey several standard online learning algorithms and show that none of them achieve the optimal regret exponent; in fact, most of them (including Online Gradient Descent, Follow the Leader and Exponential Weights) incur linear regret. We then prove that the Exponential Weights algorithm played over a covering net of isotonic functions has a regret bounded by O\\big(T^1/3 \\log^2/3(T)\\big) and present a matching \u03a9(T^1/3) lower bound on regret. We provide a computationally efficient version of this algorithm. We also analyze the noise-free case, in which the revealed labels are isotonic, and show that the bound can be improved to O(\\log T) or even to O(1) (when the labels are revealed in isotonic order). Finally, we extend the analysis beyond squared loss and give  bounds for entropic loss and absolute loss.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/kotlowski16.pdf",
        "supp": "",
        "pdf_size": 382328,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16609099217981314008&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Pozna \u00b4n University of Technology; Centrum Wiskunde & Informatica; University of California at Berkeley",
        "aff_domain": "CS.PUT.POZNAN.PL;CWI.NL;BERKELEY.EDU",
        "email": "CS.PUT.POZNAN.PL;CWI.NL;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Pozna\u0144 University of Technology;Centrum Wiskunde & Informatica;University of California, Berkeley",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.put.poznan.pl/;https://www.cwi.nl/;https://www.berkeley.edu",
        "aff_unique_abbr": "PUT;CWI;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "Poland;Netherlands;United States"
    },
    {
        "id": "3354e8f8fd",
        "title": "Online Learning and Blackwell Approachability in Quitting Games",
        "site": "https://proceedings.mlr.press/v49/flesch16.html",
        "author": "Janos Flesch; Rida Laraki; Vianney Perchet",
        "abstract": "We consider  the sequential decision problem known as regret minimization, or more precisely its generalization to the  vectorial or multi-criteria  setup called Blackwell approachability. We  assume that   Nature, the decision maker, or both, might have some quitting (or terminating) actions so that the stream of payoffs is constant whenever they are chosen. We call those environments  \u201cquitting games\u201d. We characterize convex target sets \\cC that are Blackwell approachable, in the sense that the decision maker has a policy ensuring that the expected average vector payoff converges to \\cC at some given horizon known in advance. Moreover, we also compare these results to the cases where  the horizon is not known and show that, unlike in standard online learning literature, the necessary or sufficient conditions for the anytime version of this problem are drastically different than those for the fixed horizon.",
        "bibtex": "@InProceedings{pmlr-v49-flesch16,\n  title = \t {Online Learning and Blackwell Approachability in Quitting Games},\n  author = \t {Flesch, Janos and Laraki, Rida and Perchet, Vianney},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {941--942},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/flesch16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/flesch16.html},\n  abstract = \t {We consider  the sequential decision problem known as regret minimization, or more precisely its generalization to the  vectorial or multi-criteria  setup called Blackwell approachability. We  assume that   Nature, the decision maker, or both, might have some quitting (or terminating) actions so that the stream of payoffs is constant whenever they are chosen. We call those environments  \u201cquitting games\u201d. We characterize convex target sets \\cC that are Blackwell approachable, in the sense that the decision maker has a policy ensuring that the expected average vector payoff converges to \\cC at some given horizon known in advance. Moreover, we also compare these results to the cases where  the horizon is not known and show that, unlike in standard online learning literature, the necessary or sufficient conditions for the anytime version of this problem are drastically different than those for the fixed horizon. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/flesch16.pdf",
        "supp": "",
        "pdf_size": 152988,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=138094003949172440&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Quantitative Economics, Maastricht University, The Netherlands; C.N.R.S. at LAMSADE (University Paris Dauphine) and Economics Department (Ecole Polytechnique), Paris, France; Laboratoire de Statistique, ENSAE - CREST, Malakoff, France",
        "aff_domain": "MAASTRICHTUNIVERSITY.NL;LAMSADE.DAUPHINE.FR;NORMALESUP.ORG",
        "email": "MAASTRICHTUNIVERSITY.NL;LAMSADE.DAUPHINE.FR;NORMALESUP.ORG",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Maastricht University;University Paris Dauphine;ENSAE - CREST",
        "aff_unique_dep": "Department of Quantitative Economics;LAMSADE;Laboratoire de Statistique",
        "aff_unique_url": "https://www.maastrichtuniversity.nl;https://www.univ-paris-dauphine.fr;https://www.ensae.fr",
        "aff_unique_abbr": "MU;UPD;ENSAE",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Paris;Malakoff",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Netherlands;France"
    },
    {
        "id": "a9e4ea0667",
        "title": "Online Learning with Low Rank Experts",
        "site": "https://proceedings.mlr.press/v49/hazan16.html",
        "author": "Elad Hazan; Tomer Koren; Roi Livni; Yishay Mansour",
        "abstract": "We consider the problem of prediction with expert advice when the losses of the experts have low-dimensional structure: they are restricted to an unknown d-dimensional subspace. We devise algorithms with regret bounds that are independent of the number of experts and depend only on the rank d. For the stochastic model we show a tight bound of \u0398(\\sqrtdT), and extend it to a setting of an approximate d subspace. For the adversarial model we show an upper bound of O(d\\sqrtT) and a lower bound of \u03a9(\\sqrtdT).",
        "bibtex": "@InProceedings{pmlr-v49-hazan16,\n  title = \t {Online Learning with Low Rank Experts},\n  author = \t {Hazan, Elad and Koren, Tomer and Livni, Roi and Mansour, Yishay},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1096--1114},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/hazan16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/hazan16.html},\n  abstract = \t {We consider the problem of prediction with expert advice when the losses of the experts have low-dimensional structure: they are restricted to an unknown d-dimensional subspace. We devise algorithms with regret bounds that are independent of the number of experts and depend only on the rank d. For the stochastic model we show a tight bound of \u0398(\\sqrtdT), and extend it to a setting of an approximate d subspace. For the adversarial model we show an upper bound of O(d\\sqrtT) and a lower bound of \u03a9(\\sqrtdT). }\n}",
        "pdf": "http://proceedings.mlr.press/v49/hazan16.pdf",
        "supp": "",
        "pdf_size": 288295,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17496968184950956337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Princeton University; Technion\u2014Israel Institute of Technology + Microsoft Research, Herzliya; The Hebrew University of Jerusalem + Microsoft Research, Herzliya; Microsoft Research, Herzliya + Tel Aviv University",
        "aff_domain": "cs.princeton.edu;technion.ac.il;mail.huji.ac.il;tau.ac.il",
        "email": "cs.princeton.edu;technion.ac.il;mail.huji.ac.il;tau.ac.il",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;3+2;2+4",
        "aff_unique_norm": "Princeton University;Technion\u2014Israel Institute of Technology;Microsoft;Hebrew University of Jerusalem;Tel Aviv University",
        "aff_unique_dep": ";;Microsoft Research;;",
        "aff_unique_url": "https://www.princeton.edu;https://www.technion.ac.il/en/;https://www.microsoft.com/en-us/research;https://www.huji.ac.il;https://www.tau.ac.il",
        "aff_unique_abbr": "Princeton;Technion;MSR;HUJI;TAU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Herzliya",
        "aff_country_unique_index": "0;1+1;1+1;1+1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "7bbd48c4b1",
        "title": "Online Sparse Linear Regression",
        "site": "https://proceedings.mlr.press/v49/foster16.html",
        "author": "Dean Foster; Satyen Kale; Howard Karloff",
        "abstract": "We consider the online sparse linear regression problem, which is the problem of sequentially making predictions observing only a limited number of features in each round, to minimize regret with respect to the best sparse linear regressor, where prediction accuracy is measured by square loss. We give an \\em inefficient algorithm that obtains regret bounded by \\tildeO(\\sqrtT) after T prediction rounds. We complement this result by showing that no algorithm running in polynomial time per iteration can achieve regret bounded by O(T^1-\u03b4) for any constant \u03b4> 0 unless \\textsfNP \u2286\\textsfBPP. This computational hardness result resolves an open problem presented in COLT 2014 (Kale, 2014) and also posed by Zolghadr et al. (2013). This hardness result holds even if the algorithm is allowed to access more features than the best sparse linear regressor up to a logarithmic factor in the dimension.",
        "bibtex": "@InProceedings{pmlr-v49-foster16,\n  title = \t {Online Sparse Linear Regression},\n  author = \t {Foster, Dean and Kale, Satyen and Karloff, Howard},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {960--970},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/foster16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/foster16.html},\n  abstract = \t {We consider the online sparse linear regression problem, which is the problem of sequentially making predictions observing only a limited number of features in each round, to minimize regret with respect to the best sparse linear regressor, where prediction accuracy is measured by square loss. We give an \\em inefficient algorithm that obtains regret bounded by \\tildeO(\\sqrtT) after T prediction rounds. We complement this result by showing that no algorithm running in polynomial time per iteration can achieve regret bounded by O(T^1-\u03b4) for any constant \u03b4> 0 unless \\textsfNP \u2286\\textsfBPP. This computational hardness result resolves an open problem presented in COLT 2014 (Kale, 2014) and also posed by Zolghadr et al. (2013). This hardness result holds even if the algorithm is allowed to access more features than the best sparse linear regressor up to a logarithmic factor in the dimension.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/foster16.pdf",
        "supp": "",
        "pdf_size": 266065,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13771737999849862288&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Amazon; Yahoo Research; ",
        "aff_domain": "FOSTER.NET;YAHOO-INC.COM;CC.GATECH.EDU",
        "email": "FOSTER.NET;YAHOO-INC.COM;CC.GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Amazon;Yahoo",
        "aff_unique_dep": "Amazon.com, Inc.;Yahoo Research",
        "aff_unique_url": "https://www.amazon.com;https://research.yahoo.com",
        "aff_unique_abbr": "Amazon;Yahoo Research",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "237829e482",
        "title": "Online learning in repeated auctions",
        "site": "https://proceedings.mlr.press/v49/weed16.html",
        "author": "Jonathan Weed; Vianney Perchet; Philippe Rigollet",
        "abstract": "Motivated by online advertising auctions, we consider repeated Vickrey auctions where goods of unknown value are sold sequentially and bidders only learn (potentially noisy) information about a good\u2019s value once it is purchased. We adopt an online learning approach with bandit feedback to  model this problem and derive bidding strategies for two models: stochastic and adversarial. In the stochastic model, the observed values of the goods are  random variables centered around the true value of the good. In this case, logarithmic regret is achievable when competing against well behaved adversaries. In the adversarial model, the goods need not be identical. Comparing our performance against that of the best fixed bid in hindsight, we show that sublinear regret is also achievable in this case. For both the stochastic and adversarial models, we prove matching minimax lower bounds showing our strategies to be optimal up to lower-order terms. To our knowledge, this is the first complete set of strategies for bidders participating in auctions of this type.",
        "bibtex": "@InProceedings{pmlr-v49-weed16,\n  title = \t {Online learning in repeated auctions},\n  author = \t {Weed, Jonathan and Perchet, Vianney and Rigollet, Philippe},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1562--1583},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/weed16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/weed16.html},\n  abstract = \t {Motivated by online advertising auctions, we consider repeated Vickrey auctions where goods of unknown value are sold sequentially and bidders only learn (potentially noisy) information about a good\u2019s value once it is purchased. We adopt an online learning approach with bandit feedback to  model this problem and derive bidding strategies for two models: stochastic and adversarial. In the stochastic model, the observed values of the goods are  random variables centered around the true value of the good. In this case, logarithmic regret is achievable when competing against well behaved adversaries. In the adversarial model, the goods need not be identical. Comparing our performance against that of the best fixed bid in hindsight, we show that sublinear regret is also achievable in this case. For both the stochastic and adversarial models, we prove matching minimax lower bounds showing our strategies to be optimal up to lower-order terms. To our knowledge, this is the first complete set of strategies for bidders participating in auctions of this type.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/weed16.pdf",
        "supp": "",
        "pdf_size": 376981,
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17108890295842882781&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Department of Mathematics, Massachusetts Institute of Technology; Laboratoire de Statistique, ENSAE - CREST; Department of Mathematics, Massachusetts Institute of Technology",
        "aff_domain": "MIT.EDU;NORMALESUP.ORG;MATH.MIT.EDU",
        "email": "MIT.EDU;NORMALESUP.ORG;MATH.MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;ENSAE - CREST",
        "aff_unique_dep": "Department of Mathematics;Laboratoire de Statistique",
        "aff_unique_url": "https://web.mit.edu;https://www.ensae.fr",
        "aff_unique_abbr": "MIT;ENSAE",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "c75383ea60",
        "title": "Open Problem: Approximate Planning of POMDPs in the class of Memoryless Policies",
        "site": "https://proceedings.mlr.press/v49/azizzadenesheli16b.html",
        "author": "Kamyar Azizzadenesheli; Alessandro Lazaric; Animashree Anandkumar",
        "abstract": "Planning plays an important role in the broad class of decision theory. Planning has drawn much attention in recent work in the robotics and sequential decision making areas. Recently, Reinforcement Learning (RL), as an agent-environment interaction problem, has brought further attention to planning methods. Generally in RL, one can assume a generative model, e.g. graphical models, for the environment, and then the task for the RL agent is to learn the model parameters and find the optimal strategy based on these learnt parameters. Based on environment behavior, the agent can assume various types of generative models, e.g. Multi Armed Bandit for a static environment, or Markov Decision Process (MDP) for a dynamic environment. The advantage of these popular models is their simplicity, which results in tractable methods of learning the parameters and finding the optimal policy. The drawback of these models is again their simplicity: these models usually underfit and underestimate the actual environment behavior. For example, in robotics, the agent usually has noisy observations of the environment inner state and MDP is not a suitable model. More complex models like Partially Observable Markov Decision Process (POMDP) can compensate for this drawback. Fitting this model to the environment, where the partial observation is given to the agent, generally gives dramatic performance improvement, sometimes unbounded improvement, compared to MDP. In general, finding the optimal policy for the POMDP model is computationally intractable and fully non convex, even for the class of memoryless policies. The open problem is to come up with a method to find an exact or an approximate optimal stochastic memoryless policy for POMDP models.",
        "bibtex": "@InProceedings{pmlr-v49-azizzadenesheli16b,\n  title = \t {Open Problem: Approximate Planning of POMDPs in the class of Memoryless Policies},\n  author = \t {Azizzadenesheli, Kamyar and Lazaric, Alessandro and Anandkumar, Animashree},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1639--1642},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/azizzadenesheli16b.pdf},\n  url = \t {https://proceedings.mlr.press/v49/azizzadenesheli16b.html},\n  abstract = \t {Planning plays an important role in the broad class of decision theory. Planning has drawn much attention in recent work in the robotics and sequential decision making areas. Recently, Reinforcement Learning (RL), as an agent-environment interaction problem, has brought further attention to planning methods. Generally in RL, one can assume a generative model, e.g. graphical models, for the environment, and then the task for the RL agent is to learn the model parameters and find the optimal strategy based on these learnt parameters. Based on environment behavior, the agent can assume various types of generative models, e.g. Multi Armed Bandit for a static environment, or Markov Decision Process (MDP) for a dynamic environment. The advantage of these popular models is their simplicity, which results in tractable methods of learning the parameters and finding the optimal policy. The drawback of these models is again their simplicity: these models usually underfit and underestimate the actual environment behavior. For example, in robotics, the agent usually has noisy observations of the environment inner state and MDP is not a suitable model. More complex models like Partially Observable Markov Decision Process (POMDP) can compensate for this drawback. Fitting this model to the environment, where the partial observation is given to the agent, generally gives dramatic performance improvement, sometimes unbounded improvement, compared to MDP. In general, finding the optimal policy for the POMDP model is computationally intractable and fully non convex, even for the class of memoryless policies. The open problem is to come up with a method to find an exact or an approximate optimal stochastic memoryless policy for POMDP models.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/azizzadenesheli16b.pdf",
        "supp": "",
        "pdf_size": 92192,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16536487296773395112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "University of California, Irvine; French Institute for Research in Computer Science and Automation (Inria); University of California, Irvine",
        "aff_domain": "UCI.EDU;INRIA.FR;UCI.EDU",
        "email": "UCI.EDU;INRIA.FR;UCI.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Irvine;French Institute for Research in Computer Science and Automation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uci.edu;https://www.inria.fr",
        "aff_unique_abbr": "UCI;Inria",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Irvine;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "91cc3dcf2e",
        "title": "Open Problem: Best Arm Identification: Almost Instance-Wise Optimality and the Gap Entropy Conjecture",
        "site": "https://proceedings.mlr.press/v49/chen16b.html",
        "author": "Lijie Chen; Jian Li",
        "abstract": "The best arm identification problem (BEST-1-ARM) is the most basic pure exploration problem in stochastic multi-armed bandits. The problem has a long history and attracted significant attention for the last decade. However, we do not yet have a complete understanding of the optimal sample complexity of the problem: The state-of-the-art algorithms achieve a sample complexity of O(\\sum_i=2^n \\Delta_i^-2(\\ln\u03b4^-1 + \\ln\\ln\\Delta_i^-1)) (\\Delta_i is the difference between the largest mean and the i^th mean), while the best known lower bound is \u03a9(\\sum_i=2^n \\Delta_i^-2\\ln\u03b4^-1) for general instances and \u03a9(\u2206^-2 \\ln\\ln \u2206^-1) for the two-arm instances. We propose to study the instance-wise optimality for the BEST-1-ARM problem. Previous work has proved that it is impossible to have an instance optimal algorithm for the 2-arm problem. However, we conjecture that modulo the additive term \u03a9(\\Delta_2^-2 \\ln\\ln \\Delta_2^-1) (which is an upper bound and worst case lower bound for the 2-arm problem), there is an instance optimal algorithm for BEST-1-ARM. Moreover, we introduce a new quantity, called the gap entropy for a best-arm problem instance, and conjecture that it is the instance-wise lower bound. Hence, resolving this conjecture would provide a final answer to the old and basic problem.",
        "bibtex": "@InProceedings{pmlr-v49-chen16b,\n  title = \t {Open Problem: Best Arm Identification: Almost Instance-Wise Optimality and the Gap Entropy Conjecture},\n  author = \t {Chen, Lijie and Li, Jian},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1643--1646},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/chen16b.pdf},\n  url = \t {https://proceedings.mlr.press/v49/chen16b.html},\n  abstract = \t {The best arm identification problem (BEST-1-ARM) is the most basic pure exploration problem in stochastic multi-armed bandits. The problem has a long history and attracted significant attention for the last decade. However, we do not yet have a complete understanding of the optimal sample complexity of the problem: The state-of-the-art algorithms achieve a sample complexity of O(\\sum_i=2^n \\Delta_i^-2(\\ln\u03b4^-1 + \\ln\\ln\\Delta_i^-1)) (\\Delta_i is the difference between the largest mean and the i^th mean), while the best known lower bound is \u03a9(\\sum_i=2^n \\Delta_i^-2\\ln\u03b4^-1) for general instances and \u03a9(\u2206^-2 \\ln\\ln \u2206^-1) for the two-arm instances. We propose to study the instance-wise optimality for the BEST-1-ARM problem. Previous work has proved that it is impossible to have an instance optimal algorithm for the 2-arm problem. However, we conjecture that modulo the additive term \u03a9(\\Delta_2^-2 \\ln\\ln \\Delta_2^-1) (which is an upper bound and worst case lower bound for the 2-arm problem), there is an instance optimal algorithm for BEST-1-ARM. Moreover, we introduce a new quantity, called the gap entropy for a best-arm problem instance, and conjecture that it is the instance-wise lower bound. Hence, resolving this conjecture would provide a final answer to the old and basic problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/chen16b.pdf",
        "supp": "",
        "pdf_size": 230676,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4626594380598681980&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, China; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, China",
        "aff_domain": "MAILS.TSINGHUA.EDU.CN;MAIL.TSINGHUA.EDU.CN",
        "email": "MAILS.TSINGHUA.EDU.CN;MAIL.TSINGHUA.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences (IIIS)",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8fba7d7537",
        "title": "Open Problem: Kernel methods on manifolds and metric spaces. What is the probability of a positive definite geodesic exponential kernel?",
        "site": "https://proceedings.mlr.press/v49/feragen16.html",
        "author": "Aasa Feragen; S\u00f8ren Hauberg",
        "abstract": "Radial kernels are well-suited for machine learning over general geodesic metric spaces, where pairwise distances are often the only computable quantity available. We have recently shown that geodesic exponential kernels are only positive definite for all bandwidths when the input space has strong linear properties. This negative result hints that radial kernel are perhaps not suitable over geodesic metric spaces after all. Here, however, we present evidence that large intervals of bandwidths exist where geodesic exponential kernels have high probability of being positive definite over finite datasets, while still having significant predictive power. From this we formulate conjectures on the probability of a positive definite kernel matrix for a finite random sample, depending on the geometry of the data space and the spread of the sample.",
        "bibtex": "@InProceedings{pmlr-v49-feragen16,\n  title = \t {Open Problem: Kernel methods on manifolds and metric spaces. What is the probability of a positive definite geodesic exponential kernel?},\n  author = \t {Feragen, Aasa and Hauberg, S\u00f8ren},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1647--1650},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/feragen16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/feragen16.html},\n  abstract = \t {Radial kernels are well-suited for machine learning over general geodesic metric spaces, where pairwise distances are often the only computable quantity available. We have recently shown that geodesic exponential kernels are only positive definite for all bandwidths when the input space has strong linear properties. This negative result hints that radial kernel are perhaps not suitable over geodesic metric spaces after all. Here, however, we present evidence that large intervals of bandwidths exist where geodesic exponential kernels have high probability of being positive definite over finite datasets, while still having significant predictive power. From this we formulate conjectures on the probability of a positive definite kernel matrix for a finite random sample, depending on the geometry of the data space and the spread of the sample.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/feragen16.pdf",
        "supp": "",
        "pdf_size": 279407,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1956888607561449759&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "University of Copenhagen, Universitetsparken 5, 2100 Copenhagen, Denmark; Technical University of Denmark, Richard Petersens Plads, Bld. 321, 2800 Kgs. Lyngby, Denmark",
        "aff_domain": "DI.KU.DK;DTU.DK",
        "email": "DI.KU.DK;DTU.DK",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Copenhagen;Technical University of Denmark",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ku.dk;https://www.teknologisk.dk",
        "aff_unique_abbr": "UCPH;DTU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Copenhagen;Lyngby",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "047ad0aa3c",
        "title": "Open Problem: Parameter-Free and Scale-Free Online Algorithms",
        "site": "https://proceedings.mlr.press/v49/orabona16.html",
        "author": "Francesco Orabona; D\u00e1vid P\u00e1l",
        "abstract": "Existing vanilla algorithms for online linear optimization have O((\u03b7R(u) + 1/\u03b7) \\sqrtT) regret with respect to any competitor u, where R(u) is a 1-strongly convex regularizer and \u03b7> 0 is a tuning parameter of the algorithm. For certain decision sets and regularizers, the so-called \\emphparameter-free algorithms have \\widetilde O(\\sqrtR(u) T) regret with respect to any competitor u.  Vanilla algorithm can achieve the same bound only for a fixed competitor u known ahead of time by setting \u03b7= 1/\\sqrtR(u). A drawback of both vanilla and parameter-free algorithms is that they assume that the norm of the loss vectors is bounded by a constant known to the algorithm. There exist \\emphscale-free algorithms that have O((\u03b7R(u) + 1/\u03b7) \\sqrtT \\max_1 \\le t \\le T \\norm\\ell_t) regret with respect to any competitor u and for any sequence of loss vector \\ell_1, \u2026, \\ell_T. Parameter-free analogue of scale-free algorithms have never been designed. Is is possible to design algorithms that are simultaneously \\emphparameter-free and \\emphscale-free?",
        "bibtex": "@InProceedings{pmlr-v49-orabona16,\n  title = \t {Open Problem: Parameter-Free and Scale-Free Online Algorithms},\n  author = \t {Orabona, Francesco and P\u00e1l, D\u00e1vid},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1659--1664},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/orabona16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/orabona16.html},\n  abstract = \t {Existing vanilla algorithms for online linear optimization have O((\u03b7R(u) + 1/\u03b7) \\sqrtT) regret with respect to any competitor u, where R(u) is a 1-strongly convex regularizer and \u03b7> 0 is a tuning parameter of the algorithm. For certain decision sets and regularizers, the so-called \\emphparameter-free algorithms have \\widetilde O(\\sqrtR(u) T) regret with respect to any competitor u.  Vanilla algorithm can achieve the same bound only for a fixed competitor u known ahead of time by setting \u03b7= 1/\\sqrtR(u). A drawback of both vanilla and parameter-free algorithms is that they assume that the norm of the loss vectors is bounded by a constant known to the algorithm. There exist \\emphscale-free algorithms that have O((\u03b7R(u) + 1/\u03b7) \\sqrtT \\max_1 \\le t \\le T \\norm\\ell_t) regret with respect to any competitor u and for any sequence of loss vector \\ell_1, \u2026, \\ell_T. Parameter-free analogue of scale-free algorithms have never been designed. Is is possible to design algorithms that are simultaneously \\emphparameter-free and \\emphscale-free? }\n}",
        "pdf": "http://proceedings.mlr.press/v49/orabona16.pdf",
        "supp": "",
        "pdf_size": 246730,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4740265199850277617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Yahoo Research, New York; Yahoo Research, New York",
        "aff_domain": "ORABONA.COM;YAHOO-INC.COM",
        "email": "ORABONA.COM;YAHOO-INC.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Yahoo Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://research.yahoo.com",
        "aff_unique_abbr": "Yahoo Res.",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "71e4d6e19f",
        "title": "Open Problem: Property Elicitation and Elicitation Complexity",
        "site": "https://proceedings.mlr.press/v49/frongillo16.html",
        "author": "Rafael Frongillo; Ian Kash; Stephen Becker",
        "abstract": "The study of property elicitation is gaining ground in statistics and machine learning as a way to view and reason about the expressive power of emiprical risk minimization (ERM).  Yet beyond a widening frontier of special cases, the two most fundamental questions in this area remain open: which statistics are elicitable (computable via ERM), and which loss functions elicit them?  Moreover, recent work suggests a complementary line of questioning: given a statistic, how many ERM parameters are needed to compute it?  We give concrete instantiations of these important questions, which have numerous applications to machine learning and related fields.",
        "bibtex": "@InProceedings{pmlr-v49-frongillo16,\n  title = \t {Open Problem: Property Elicitation and Elicitation Complexity},\n  author = \t {Frongillo, Rafael and Kash, Ian and Becker, Stephen},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1655--1658},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/frongillo16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/frongillo16.html},\n  abstract = \t {The study of property elicitation is gaining ground in statistics and machine learning as a way to view and reason about the expressive power of emiprical risk minimization (ERM).  Yet beyond a widening frontier of special cases, the two most fundamental questions in this area remain open: which statistics are elicitable (computable via ERM), and which loss functions elicit them?  Moreover, recent work suggests a complementary line of questioning: given a statistic, how many ERM parameters are needed to compute it?  We give concrete instantiations of these important questions, which have numerous applications to machine learning and related fields.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/frongillo16.pdf",
        "supp": "",
        "pdf_size": 147588,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17404042957198728461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "CU Boulder; Microsoft Research; CU Boulder",
        "aff_domain": "COLORADO.EDU;MICROSOFT.COM;COLORADO.EDU",
        "email": "COLORADO.EDU;MICROSOFT.COM;COLORADO.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Colorado Boulder;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.colorado.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "CU Boulder;MSR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b76922cfa1",
        "title": "Open Problem: Second order regret bounds based on scaling time",
        "site": "https://proceedings.mlr.press/v49/freund16.html",
        "author": "Yoav Freund",
        "abstract": "We argue that the second order bounds given in Cesa-Bianchi2006, which accumulate the square of the loss of each action separately, are loose. We propose a different form of a second order bound and conjecture the it is satisfied by NormalHedge ChaudhuriFrHs2009.",
        "bibtex": "@InProceedings{pmlr-v49-freund16,\n  title = \t {Open Problem: Second order regret bounds based on scaling time},\n  author = \t {Freund, Yoav},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1651--1654},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/freund16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/freund16.html},\n  abstract = \t {We argue that the second order bounds given in Cesa-Bianchi2006, which accumulate the square of the loss of each action separately, are loose. We propose a different form of a second order bound and conjecture the it is satisfied by NormalHedge ChaudhuriFrHs2009.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/freund16.pdf",
        "supp": "",
        "pdf_size": 287649,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=710264858856845150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "UCSD, San Diego, CA",
        "aff_domain": "UCSD.EDU",
        "email": "UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8a7093280a",
        "title": "Optimal Best Arm Identification with Fixed Confidence",
        "site": "https://proceedings.mlr.press/v49/garivier16a.html",
        "author": "Aur\u00e9lien Garivier; Emilie Kaufmann",
        "abstract": "We give a complete characterization of the complexity of best-arm identification in one-parameter bandit problems. We prove a new, tight lower bound on the sample complexity. We propose the \u2018Track-and-Stop\u2019 strategy, which we prove to be asymptotically optimal. It consists in a new sampling rule (which tracks the optimal proportions of arm draws highlighted by the lower bound) and in a stopping rule named after Chernoff, for which we give a new analysis.",
        "bibtex": "@InProceedings{pmlr-v49-garivier16a,\n  title = \t {Optimal Best Arm Identification with Fixed Confidence},\n  author = \t {Garivier, Aur\u00e9lien and Kaufmann, Emilie},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {998--1027},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/garivier16a.pdf},\n  url = \t {https://proceedings.mlr.press/v49/garivier16a.html},\n  abstract = \t {We give a complete characterization of the complexity of best-arm identification in one-parameter bandit problems. We prove a new, tight lower bound on the sample complexity. We propose the \u2018Track-and-Stop\u2019 strategy, which we prove to be asymptotically optimal. It consists in a new sampling rule (which tracks the optimal proportions of arm draws highlighted by the lower bound) and in a stopping rule named after Chernoff, for which we give a new analysis.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/garivier16a.pdf",
        "supp": "",
        "pdf_size": 406884,
        "gs_citation": 466,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12844182967736378808&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "50d27e0370",
        "title": "Optimal Learning via the Fourier Transform for Sums of Independent Integer Random Variables",
        "site": "https://proceedings.mlr.press/v49/diakonikolas16a.html",
        "author": "I. Diakonikolas; D. M. Kane; A. Stewart",
        "abstract": "We study the structure and learnability of sums of independent integer random variables (SIIRVs). For k \u2208\\mathbbZ_+, a \\emk-SIIRV of order n \u2208\\mathbbZ_+ is the probability distribution of the sum of n mutually independent random variables each supported on {0, 1, \u2026, k-1}. We denote by \\cal S_n,k the set of all k-SIIRVs of order n. How many samples are required to learn an arbitrary distribution in \\cal S_n,k? In this paper, we tightly characterize the sample and computational complexity of this problem. More precisely, we design a computationally efficient algorithm that uses \\widetildeO(k/\u03b5^2) samples, and learns an arbitrary k-SIIRV within error \u03b5, in total variation distance. Moreover, we show that the \\em optimal sample complexity of this learning problem is \u0398((k/\u03b5^2)\\sqrt\\log(1/\u03b5)), i.e., we prove an upper bound and a matching information-theoretic lower bound. Our algorithm proceeds by learning the Fourier transform of the target k-SIIRV in its effective support. Its correctness relies on the \\em approximate sparsity of the Fourier transform of k-SIIRVs \u2013 a structural property that we establish, roughly stating that the Fourier transform of k-SIIRVs has small magnitude outside a small set. Along the way we prove several new structural results about k-SIIRVs. As one of our main structural contributions, we give an efficient algorithm to construct a sparse \\em proper \u03b5-cover for \\cal S_n,k, in total variation distance. We also obtain a novel geometric characterization of the space of k-SIIRVs. Our characterization allows us to prove a tight lower bound on the size of \u03b5-covers for \\cal S_n,k \u2013 establishing that our cover upper bound is optimal \u2013 and is the key ingredient in our tight sample complexity lower bound. Our approach of exploiting the sparsity of the Fourier transform in distribution learning is general, and has recently found additional applications. In a subsequent work, we use a generalization of this idea to obtain the first computationally efficient learning algorithm for Poisson multinomial distributions. In\u00a0a separate work, we build on our Fourier-based approach to obtain the fastest known proper learning algorithm for Poisson binomial distributions (2-SIIRVs).",
        "bibtex": "@InProceedings{pmlr-v49-diakonikolas16a,\n  title = \t {Optimal Learning via the Fourier Transform for Sums of Independent Integer Random Variables},\n  author = \t {Diakonikolas, I. and Kane, D. M. and Stewart, A.},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {831--849},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/diakonikolas16a.pdf},\n  url = \t {https://proceedings.mlr.press/v49/diakonikolas16a.html},\n  abstract = \t {We study the structure and learnability of sums of independent integer random variables (SIIRVs). For k \u2208\\mathbbZ_+, a \\emk-SIIRV of order n \u2208\\mathbbZ_+ is the probability distribution of the sum of n mutually independent random variables each supported on {0, 1, \u2026, k-1}. We denote by \\cal S_n,k the set of all k-SIIRVs of order n. How many samples are required to learn an arbitrary distribution in \\cal S_n,k? In this paper, we tightly characterize the sample and computational complexity of this problem. More precisely, we design a computationally efficient algorithm that uses \\widetildeO(k/\u03b5^2) samples, and learns an arbitrary k-SIIRV within error \u03b5, in total variation distance. Moreover, we show that the \\em optimal sample complexity of this learning problem is \u0398((k/\u03b5^2)\\sqrt\\log(1/\u03b5)), i.e., we prove an upper bound and a matching information-theoretic lower bound. Our algorithm proceeds by learning the Fourier transform of the target k-SIIRV in its effective support. Its correctness relies on the \\em approximate sparsity of the Fourier transform of k-SIIRVs \u2013 a structural property that we establish, roughly stating that the Fourier transform of k-SIIRVs has small magnitude outside a small set. Along the way we prove several new structural results about k-SIIRVs. As one of our main structural contributions, we give an efficient algorithm to construct a sparse \\em proper \u03b5-cover for \\cal S_n,k, in total variation distance. We also obtain a novel geometric characterization of the space of k-SIIRVs. Our characterization allows us to prove a tight lower bound on the size of \u03b5-covers for \\cal S_n,k \u2013 establishing that our cover upper bound is optimal \u2013 and is the key ingredient in our tight sample complexity lower bound. Our approach of exploiting the sparsity of the Fourier transform in distribution learning is general, and has recently found additional applications. In a subsequent work, we use a generalization of this idea to obtain the first computationally efficient learning algorithm for Poisson multinomial distributions. In\u00a0a separate work, we build on our Fourier-based approach to obtain the fastest known proper learning algorithm for Poisson binomial distributions (2-SIIRVs). }\n}",
        "pdf": "http://proceedings.mlr.press/v49/diakonikolas16a.pdf",
        "supp": "",
        "pdf_size": 340638,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3355503688106163753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Dept. of Computer Science, University of Southern California, Los Angeles, CA, USA; Dept. of Computer Science & Engineering, and Mathematics, University of California, San Diego, CA, USA; Dept. of Computer Science, University of Southern California, Los Angeles, CA, USA",
        "aff_domain": "USC.EDU;CS.UCSD.EDU;USC.EDU",
        "email": "USC.EDU;CS.UCSD.EDU;USC.EDU",
        "github": "",
        "project": "http://arxiv.org/abs/1505.00662",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;University of California, San Diego",
        "aff_unique_dep": "Dept. of Computer Science;Dept. of Computer Science & Engineering, and Mathematics",
        "aff_unique_url": "https://www.usc.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "USC;UCSD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Los Angeles;San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f9dbaa1e40",
        "title": "Optimal rates for total variation denoising",
        "site": "https://proceedings.mlr.press/v49/huetter16.html",
        "author": "Jan-Christian H\u00fctter; Philippe Rigollet",
        "abstract": "Motivated by its practical success, we show that the 2D total variation denoiser satisfies a sharp oracle inequality that leads to near optimal rates of estimation for a large class of image models such as bi-isotonic, H\u00f6lder smooth and cartoons. Our analysis hinges on properties of the unnormalized Laplacian of the  two-dimensional grid such as eigenvector delocalization and spectral decay. We also present extensions to more than two dimensions as well as several other graphs.",
        "bibtex": "@InProceedings{pmlr-v49-huetter16,\n  title = \t {Optimal rates for total variation denoising},\n  author = \t {H\u00fctter, Jan-Christian and Rigollet, Philippe},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1115--1146},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/huetter16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/huetter16.html},\n  abstract = \t {Motivated by its practical success, we show that the 2D total variation denoiser satisfies a sharp oracle inequality that leads to near optimal rates of estimation for a large class of image models such as bi-isotonic, H\u00f6lder smooth and cartoons. Our analysis hinges on properties of the unnormalized Laplacian of the  two-dimensional grid such as eigenvector delocalization and spectral decay. We also present extensions to more than two dimensions as well as several other graphs. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/huetter16.pdf",
        "supp": "",
        "pdf_size": 414634,
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7200725543894130356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "MIT, Department of Mathematics; MIT, Department of Mathematics",
        "aff_domain": "MATH.MIT.EDU;MATH.MIT.EDU",
        "email": "MATH.MIT.EDU;MATH.MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6ae064f4a3",
        "title": "Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models",
        "site": "https://proceedings.mlr.press/v49/avilapires16.html",
        "author": "Bernardo \u00c1vila Pires; Csaba Szepesv\u00e1ri",
        "abstract": "In this paper we study a model-based approach to calculating approximately optimal policies in Markovian Decision Processes. In particular, we derive novel bounds on the loss of using a policy derived from a factored linear model, a class of models which generalize numerous previous models out of those that come with strong computational guarantees. For the first time in the literature, we derive performance bounds for model-based techniques where the model inaccuracy is measured in weighted norms. Moreover, our bounds show a decreased sensitivity to the discount factor and, unlike similar bounds derived for other approaches, they are insensitive to measure mismatch. Similarly to previous works, our proofs are also based on contraction arguments, but with the main differences that we use carefully constructed norms building on Banach lattices, and the contraction property is only assumed for operators acting on \u201ccompressed\u201d spaces, thus weakening previous assumptions, while strengthening previous results.",
        "bibtex": "@InProceedings{pmlr-v49-avilapires16,\n  title = \t {Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models},\n  author = \t {\u00c1vila Pires, Bernardo and Szepesv\u00e1ri, Csaba},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {121--151},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/avilapires16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/avilapires16.html},\n  abstract = \t {In this paper we study a model-based approach to calculating approximately optimal policies in Markovian Decision Processes. In particular, we derive novel bounds on the loss of using a policy derived from a factored linear model, a class of models which generalize numerous previous models out of those that come with strong computational guarantees. For the first time in the literature, we derive performance bounds for model-based techniques where the model inaccuracy is measured in weighted norms. Moreover, our bounds show a decreased sensitivity to the discount factor and, unlike similar bounds derived for other approaches, they are insensitive to measure mismatch. Similarly to previous works, our proofs are also based on contraction arguments, but with the main differences that we use carefully constructed norms building on Banach lattices, and the contraction property is only assumed for operators acting on \u201ccompressed\u201d spaces, thus weakening previous assumptions, while strengthening previous results.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/avilapires16.pdf",
        "supp": "",
        "pdf_size": 378575,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15502667356780145559&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computing Science, University of Alberta; Department of Computing Science, University of Alberta",
        "aff_domain": "ualberta.ca;cs.ualberta.ca",
        "email": "ualberta.ca;cs.ualberta.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "c3d6bcde5c",
        "title": "Preference-based Teaching",
        "site": "https://proceedings.mlr.press/v49/gao16.html",
        "author": "Ziyuan Gao; Christoph Ries; Hans Simon; Sandra Zilles",
        "abstract": "We introduce a new model of teaching named \u201cpreference-based teaching\u201d and a corresponding complexity parameter\u2014the preference-based teaching dimension (PBTD)\u2014representing the worst-case number of examples needed to teach any concept in a given concept class. Although the PBTD coincides with the well-known recursive teaching dimension (RTD) on finite classes, it is radically different on infinite ones: the RTD becomes infinite already for trivial infinite classes (such as half-intervals) whereas the PBTD evaluates to reasonably small values for a wide collection of infinite classes including classes consisting of so-called closed sets w.r.t.\u00a0a given closure operator, including various classes related to linear sets over \\mathbbN_0 (whose RTD had been studied quite recently) and including the class of Euclidean half-spaces (and some other geometric classes). On top of presenting these concrete results, we provide the reader with a theoretical framework (of a combinatorial flavor) which helps to derive bounds on the PBTD.",
        "bibtex": "@InProceedings{pmlr-v49-gao16,\n  title = \t {Preference-based Teaching},\n  author = \t {Gao, Ziyuan and Ries, Christoph and Simon, Hans and Zilles, Sandra},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {971--997},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/gao16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/gao16.html},\n  abstract = \t {We introduce a new model of teaching named \u201cpreference-based teaching\u201d and a corresponding complexity parameter\u2014the preference-based teaching dimension (PBTD)\u2014representing the worst-case number of examples needed to teach any concept in a given concept class. Although the PBTD coincides with the well-known recursive teaching dimension (RTD) on finite classes, it is radically different on infinite ones: the RTD becomes infinite already for trivial infinite classes (such as half-intervals) whereas the PBTD evaluates to reasonably small values for a wide collection of infinite classes including classes consisting of so-called closed sets w.r.t.\u00a0a given closure operator, including various classes related to linear sets over \\mathbbN_0 (whose RTD had been studied quite recently) and including the class of Euclidean half-spaces (and some other geometric classes). On top of presenting these concrete results, we provide the reader with a theoretical framework (of a combinatorial flavor) which helps to derive bounds on the PBTD.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/gao16.pdf",
        "supp": "",
        "pdf_size": 396721,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10880441412155025845&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "Department of Computer Science, University of Regina; Department of Mathematics, Ruhr-University Bochum; Department of Mathematics, Ruhr-University Bochum; Department of Computer Science, University of Regina",
        "aff_domain": "CS.UREGINA.CA;RUB.DE;RUB.DE;CS.UREGINA.CA",
        "email": "CS.UREGINA.CA;RUB.DE;RUB.DE;CS.UREGINA.CA",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Regina;Ruhr-University Bochum",
        "aff_unique_dep": "Department of Computer Science;Department of Mathematics",
        "aff_unique_url": "https://www.uregina.ca;https://www.ruhr-uni-bochum.de",
        "aff_unique_abbr": "U of R;RUB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Canada;Germany"
    },
    {
        "id": "64bc9e310b",
        "title": "Properly Learning Poisson Binomial Distributions in Almost Polynomial Time",
        "site": "https://proceedings.mlr.press/v49/diakonikolas16b.html",
        "author": "I. Diakonikolas; D. M. Kane; A. Stewart",
        "abstract": "We give an algorithm for properly learning Poisson binomial distributions. A Poisson binomial distribution (PBD) of order n \u2208\\mathbbZ_+ is the discrete probability distribution of the sum of n mutually independent Bernoulli random variables. Given \\widetildeO(1/\u03b5^2) samples from an unknown PBD P, our algorithm runs in time (1/\\eps)^O(\\log \\log (1/\u03b5)), and outputs a hypothesis PBD that is \u03b5-close to P in total variation distance. The sample complexity of our algorithm is known to be nearly-optimal, up to logarithmic factors, as established in previous work. However, the previously best known running time for properly learning PBDs was (1/\u03b5)^O(\\log(1/\u03b5)), and was essentially obtained by enumeration over an appropriate  \u03b5-cover. We remark that the running time of this cover-based approach cannot be improved, as any \u03b5-cover for the space of PBDs has size  (1/\u03b5)^\u03a9(\\log(1/\u03b5)). As one of our main contributions, we provide a novel structural characterization of PBDs, showing that any PBD P is \u03b5-close to another PBD Q with O(\\log(1/\u03b5)) distinct parameters. More precisely, we prove that, for all \u03b5>0, there exists an explicit collection \\calM of (1/\u03b5)^O(\\log \\log (1/\u03b5)) vectors of multiplicities, such that for any PBD P there exists a PBD Q with O(\\log(1/\u03b5)) distinct parameters whose multiplicities are given by some element of \\cal M, such that Q is \u03b5-close to P.  Our proof combines tools from Fourier analysis and algebraic geometry. Our approach to the proper learning problem is as follows: Starting with an accurate non-proper hypothesis, we fit a PBD to this hypothesis. This fitting problem can be formulated as a natural polynomial optimization problem. Our aforementioned structural characterization allows us to reduce the corresponding fitting problem to a collection of (1/\u03b5)^O(\\log \\log(1/\u03b5)) systems of low-degree polynomial inequalities. We show that each such system can be solved in time (1/\u03b5)^O(\\log \\log(1/\u03b5)), which yields the overall running time of our algorithm.",
        "bibtex": "@InProceedings{pmlr-v49-diakonikolas16b,\n  title = \t {Properly Learning Poisson Binomial Distributions in Almost Polynomial Time},\n  author = \t {Diakonikolas, I. and Kane, D. M. and Stewart, A.},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {850--878},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/diakonikolas16b.pdf},\n  url = \t {https://proceedings.mlr.press/v49/diakonikolas16b.html},\n  abstract = \t {We give an algorithm for properly learning Poisson binomial distributions. A Poisson binomial distribution (PBD) of order n \u2208\\mathbbZ_+ is the discrete probability distribution of the sum of n mutually independent Bernoulli random variables. Given \\widetildeO(1/\u03b5^2) samples from an unknown PBD P, our algorithm runs in time (1/\\eps)^O(\\log \\log (1/\u03b5)), and outputs a hypothesis PBD that is \u03b5-close to P in total variation distance. The sample complexity of our algorithm is known to be nearly-optimal, up to logarithmic factors, as established in previous work. However, the previously best known running time for properly learning PBDs was (1/\u03b5)^O(\\log(1/\u03b5)), and was essentially obtained by enumeration over an appropriate  \u03b5-cover. We remark that the running time of this cover-based approach cannot be improved, as any \u03b5-cover for the space of PBDs has size  (1/\u03b5)^\u03a9(\\log(1/\u03b5)). As one of our main contributions, we provide a novel structural characterization of PBDs, showing that any PBD P is \u03b5-close to another PBD Q with O(\\log(1/\u03b5)) distinct parameters. More precisely, we prove that, for all \u03b5>0, there exists an explicit collection \\calM of (1/\u03b5)^O(\\log \\log (1/\u03b5)) vectors of multiplicities, such that for any PBD P there exists a PBD Q with O(\\log(1/\u03b5)) distinct parameters whose multiplicities are given by some element of \\cal M, such that Q is \u03b5-close to P.  Our proof combines tools from Fourier analysis and algebraic geometry. Our approach to the proper learning problem is as follows: Starting with an accurate non-proper hypothesis, we fit a PBD to this hypothesis. This fitting problem can be formulated as a natural polynomial optimization problem. Our aforementioned structural characterization allows us to reduce the corresponding fitting problem to a collection of (1/\u03b5)^O(\\log \\log(1/\u03b5)) systems of low-degree polynomial inequalities. We show that each such system can be solved in time (1/\u03b5)^O(\\log \\log(1/\u03b5)), which yields the overall running time of our algorithm. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/diakonikolas16b.pdf",
        "supp": "",
        "pdf_size": 364905,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=948709969534328849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 16,
        "aff": "Dept. of Computer Science, University of Southern California, Los Angeles, CA, USA; Dept. of Computer Science & Engineering, and Mathematics, University of California, San Diego, CA, USA; Dept. of Computer Science, University of Southern California, Los Angeles, CA, USA",
        "aff_domain": "USC.EDU;CS.UCSD.EDU;USC.EDU",
        "email": "USC.EDU;CS.UCSD.EDU;USC.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;University of California, San Diego",
        "aff_unique_dep": "Dept. of Computer Science;Dept. of Computer Science & Engineering, and Mathematics",
        "aff_unique_url": "https://www.usc.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "USC;UCSD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Los Angeles;San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7025da744e",
        "title": "Provably manipulation-resistant reputation systems",
        "site": "https://proceedings.mlr.press/v49/christiano16.html",
        "author": "Paul Christiano",
        "abstract": "Reputation and reliability play a central role in a wide range of applications, from online marketplaces to review aggregators to ridesharing services.  Many reputation systems are vulnerable to manipulation, and protected only by keeping algorithms secret, avoiding high-stakes applications, or using side information to identify malicious users.  The current situation is reminiscent of pre-modern cryptography, characterized by a patchwork of ad hoc techniques with minimal formal understanding of their security. We propose a reputation system which provably achieves a very strong correctness guarantee under extremely pessimistic assumptions\u2014it works even given a supermajority of malicious users, converges to optimal behavior after a constant number of interactions per user, does not require repeated interactions, and accommodates time-varying quality of resources. Our formal model is simple but general.  In each period, a user is given an opportunity to interact with a resource, and must accept or reject the proposed interaction.  If they accept, they receive a payoff in [-1, 1].  Ideally all users would behave honestly, pooling their data and quickly learning which resources are worth interacting with.  Our protocol essentially matches this performance when all users are honest, while guaranteeing that adding malicious users or users with varying tastes does very little damage. We also extend our results to a more challenging setting where users interact with each other rather than with static resources, and where the two parties to an interaction may receive different payoffs.",
        "bibtex": "@InProceedings{pmlr-v49-christiano16,\n  title = \t {Provably manipulation-resistant reputation systems},\n  author = \t {Christiano, Paul},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {670--697},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/christiano16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/christiano16.html},\n  abstract = \t {Reputation and reliability play a central role in a wide range of applications, from online marketplaces to review aggregators to ridesharing services.  Many reputation systems are vulnerable to manipulation, and protected only by keeping algorithms secret, avoiding high-stakes applications, or using side information to identify malicious users.  The current situation is reminiscent of pre-modern cryptography, characterized by a patchwork of ad hoc techniques with minimal formal understanding of their security. We propose a reputation system which provably achieves a very strong correctness guarantee under extremely pessimistic assumptions\u2014it works even given a supermajority of malicious users, converges to optimal behavior after a constant number of interactions per user, does not require repeated interactions, and accommodates time-varying quality of resources. Our formal model is simple but general.  In each period, a user is given an opportunity to interact with a resource, and must accept or reject the proposed interaction.  If they accept, they receive a payoff in [-1, 1].  Ideally all users would behave honestly, pooling their data and quickly learning which resources are worth interacting with.  Our protocol essentially matches this performance when all users are honest, while guaranteeing that adding malicious users or users with varying tastes does very little damage. We also extend our results to a more challenging setting where users interact with each other rather than with static resources, and where the two parties to an interaction may receive different payoffs. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/christiano16.pdf",
        "supp": "",
        "pdf_size": 340702,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11495435354169211370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "UC Berkeley",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "409eae9763",
        "title": "Pure Exploration of Multi-armed Bandit Under Matroid Constraints",
        "site": "https://proceedings.mlr.press/v49/chen16a.html",
        "author": "Lijie Chen; Anupam Gupta; Jian Li",
        "abstract": "We study the pure exploration problem subject to a matroid constraint\t(Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance, we are given n stochastic arms with unknown reward distributions, as well as a matroid \\mathcalM over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify a basis of \\mathcalM with the maximum total weight, using as few samples as possible. The problem is a significant generalization of the best arm identification problem and the top-k arm identification problem, which have attracted significant attentions in recent years. We study both the exact and PAC versions of Best-Basis, and provide algorithms with nearly-optimal sample complexities for these versions. Our results generalize and/or improve on several previous results for the top-k arm identification problem and the combinatorial pure exploration problem when the combinatorial constraint is a matroid.",
        "bibtex": "@InProceedings{pmlr-v49-chen16a,\n  title = \t {Pure Exploration of Multi-armed Bandit Under Matroid Constraints},\n  author = \t {Chen, Lijie and Gupta, Anupam and Li, Jian},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {647--669},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/chen16a.pdf},\n  url = \t {https://proceedings.mlr.press/v49/chen16a.html},\n  abstract = \t {We study the pure exploration problem subject to a matroid constraint\t(Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance, we are given n stochastic arms with unknown reward distributions, as well as a matroid \\mathcalM over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify a basis of \\mathcalM with the maximum total weight, using as few samples as possible. The problem is a significant generalization of the best arm identification problem and the top-k arm identification problem, which have attracted significant attentions in recent years. We study both the exact and PAC versions of Best-Basis, and provide algorithms with nearly-optimal sample complexities for these versions. Our results generalize and/or improve on several previous results for the top-k arm identification problem and the combinatorial pure exploration problem when the combinatorial constraint is a matroid.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/chen16a.pdf",
        "supp": "",
        "pdf_size": 398304,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5459042992299184249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China; Department of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "arXiv:1605.07162",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tsinghua University;Carnegie Mellon University",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences (IIIS);Department of Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.cmu.edu",
        "aff_unique_abbr": "Tsinghua;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Beijing;Pittsburgh",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "fe6ebc5f76",
        "title": "Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits",
        "site": "https://proceedings.mlr.press/v49/lattimore16.html",
        "author": "Tor Lattimore",
        "abstract": "I prove near-optimal frequentist regret guarantees for the finite-horizon Gittins index strategy for multi-armed bandits with Gaussian noise and prior. Along the way I derive finite-time bounds on the Gittins index that are asymptotically exact and may be of independent interest. I also discuss computational issues and present experimental results suggesting that a particular version of the Gittins index strategy is an improvement on existing algorithms with finite-time regret guarantees such as UCB and Thompson sampling.",
        "bibtex": "@InProceedings{pmlr-v49-lattimore16,\n  title = \t {Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits},\n  author = \t {Lattimore, Tor},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1214--1245},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/lattimore16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/lattimore16.html},\n  abstract = \t {I prove near-optimal frequentist regret guarantees for the finite-horizon Gittins index strategy for multi-armed bandits with Gaussian noise and prior. Along the way I derive finite-time bounds on the Gittins index that are asymptotically exact and may be of independent interest. I also discuss computational issues and present experimental results suggesting that a particular version of the Gittins index strategy is an improvement on existing algorithms with finite-time regret guarantees such as UCB and Thompson sampling. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/lattimore16.pdf",
        "supp": "",
        "pdf_size": 357489,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15266846632372525878&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6503b0581c",
        "title": "Reinforcement Learning of POMDPs using Spectral Methods",
        "site": "https://proceedings.mlr.press/v49/azizzadenesheli16a.html",
        "author": "Kamyar Azizzadenesheli; Alessandro Lazaric; Animashree Anandkumar",
        "abstract": "We propose a new reinforcement learning algorithm for partially observable Markov decision processes (POMDP) based on spectral decomposition methods. While spectral methods have been previously employed for consistent learning of (passive) latent variable models such as hidden Markov models, POMDPs are more challenging  since the learner interacts with the environment and possibly changes the future observations in the process. We devise a learning algorithm running through episodes, in each episode we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy. At the end of the episode, an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model. We prove an order-optimal regret bound w.r.t. the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces.",
        "bibtex": "@InProceedings{pmlr-v49-azizzadenesheli16a,\n  title = \t {Reinforcement Learning of POMDPs using Spectral Methods},\n  author = \t {Azizzadenesheli, Kamyar and Lazaric, Alessandro and Anandkumar, Animashree},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {193--256},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/azizzadenesheli16a.pdf},\n  url = \t {https://proceedings.mlr.press/v49/azizzadenesheli16a.html},\n  abstract = \t {We propose a new reinforcement learning algorithm for partially observable Markov decision processes (POMDP) based on spectral decomposition methods. While spectral methods have been previously employed for consistent learning of (passive) latent variable models such as hidden Markov models, POMDPs are more challenging  since the learner interacts with the environment and possibly changes the future observations in the process. We devise a learning algorithm running through episodes, in each episode we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy. At the end of the episode, an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model. We prove an order-optimal regret bound w.r.t. the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/azizzadenesheli16a.pdf",
        "supp": "",
        "pdf_size": 774345,
        "gs_citation": 158,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2230057980824371491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 23,
        "aff": "University of California, Irvine; Institut National de Recherche en Informatique et en Automatique, (Inria); University of California, Irvine",
        "aff_domain": "UCI.EDU;INRIA.FR;UCI.EDU",
        "email": "UCI.EDU;INRIA.FR;UCI.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Irvine;Institut National de Recherche en Informatique et en Automatique",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uci.edu;https://www.inria.fr",
        "aff_unique_abbr": "UCI;Inria",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Irvine;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "86cda6f73f",
        "title": "Semidefinite Programs for Exact Recovery of a Hidden Community",
        "site": "https://proceedings.mlr.press/v49/hajek16.html",
        "author": "Bruce Hajek; Yihong Wu; Jiaming Xu",
        "abstract": "We study a semidefinite programming (SDP) relaxation of the maximum likelihood estimation for exactly recovering a hidden community of cardinality K from an n \\times n symmetric data matrix A, where for distinct indices i,j, A_ij \u223cP if i, j are both in the community and A_ij \u223cQ otherwise, for two known probability distributions P and Q. We identify a  sufficient condition  and a  necessary condition for the success of SDP  for the general model. For both the Bernoulli case (P=\\rm Bern(p) and Q=\\rm Bern(q) with p>q) and the Gaussian case (P=\\mathcalN(\u03bc,1) and Q=\\mathcalN(0,1) with \u03bc>0), which correspond to the problem of planted dense subgraph recovery and submatrix localization respectively, the general results lead to the following findings: (1) If K=\u03c9( n /\\log n), SDP attains the information-theoretic recovery limits with sharp constants; (2) If K=\u0398(n/\\log n), SDP is order-wise optimal, but strictly suboptimal by a constant factor; (3) If K=o(n/\\log n) and K \\to \u221e, SDP is order-wise suboptimal. The same critical scaling for K is found to hold, up to constant factors, for the performance of SDP on the stochastic block model of n vertices partitioned into multiple communities of equal size K. A key ingredient in the proof of the necessary condition is a construction of a primal feasible solution based on random perturbation of the true cluster matrix.",
        "bibtex": "@InProceedings{pmlr-v49-hajek16,\n  title = \t {Semidefinite Programs for Exact Recovery of a Hidden Community},\n  author = \t {Hajek, Bruce and Wu, Yihong and Xu, Jiaming},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1051--1095},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/hajek16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/hajek16.html},\n  abstract = \t {We study a semidefinite programming (SDP) relaxation of the maximum likelihood estimation for exactly recovering a hidden community of cardinality K from an n \\times n symmetric data matrix A, where for distinct indices i,j, A_ij \u223cP if i, j are both in the community and A_ij \u223cQ otherwise, for two known probability distributions P and Q. We identify a  sufficient condition  and a  necessary condition for the success of SDP  for the general model. For both the Bernoulli case (P=\\rm Bern(p) and Q=\\rm Bern(q) with p>q) and the Gaussian case (P=\\mathcalN(\u03bc,1) and Q=\\mathcalN(0,1) with \u03bc>0), which correspond to the problem of planted dense subgraph recovery and submatrix localization respectively, the general results lead to the following findings: (1) If K=\u03c9( n /\\log n), SDP attains the information-theoretic recovery limits with sharp constants; (2) If K=\u0398(n/\\log n), SDP is order-wise optimal, but strictly suboptimal by a constant factor; (3) If K=o(n/\\log n) and K \\to \u221e, SDP is order-wise suboptimal. The same critical scaling for K is found to hold, up to constant factors, for the performance of SDP on the stochastic block model of n vertices partitioned into multiple communities of equal size K. A key ingredient in the proof of the necessary condition is a construction of a primal feasible solution based on random perturbation of the true cluster matrix. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/hajek16.pdf",
        "supp": "",
        "pdf_size": 526702,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3581699876437460260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of ECE, University of Illinois at Urbana-Champaign, Urbana, IL; Department of ECE, University of Illinois at Urbana-Champaign, Urbana, IL; Simons Institute for the Theory of Computing, University of California, Berkeley, Berkeley, CA",
        "aff_domain": "ILLINOIS.EDU;ILLINOIS.EDU;BERKELEY.EDU",
        "email": "ILLINOIS.EDU;ILLINOIS.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Simons Institute for the Theory of Computing",
        "aff_unique_url": "https://illinois.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UIUC;UC Berkeley",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Urbana;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "86e6824f29",
        "title": "Sign rank versus VC dimension",
        "site": "https://proceedings.mlr.press/v49/alon16.html",
        "author": "Noga Alon; Shay Moran; Amir Yehudayoff",
        "abstract": "This work studies the maximum possible sign rank of N \\times N sign matrices with a given VC dimension d. For d=1, this maximum is three. For d=2, this maximum is \\tilde\u0398(N^1/2). For d >2, similar but slightly less accurate statements hold. Our lower bounds improve over previous ones by Ben-David et al.\u00a0and can be interpreted as exhibiting a weakness of kernel-based classifiers. Our upper bounds, on the other hand, can be interpreted as exhibiting the universality of kernel-based classifiers. The lower bounds are obtained by probabilistic constructions, using a theorem of Warren in real algebraic topology. The upper bounds are obtained using a result of Welzl about spanning trees with low stabbing number, and using the moment curve. The upper bound technique is also used to: (i) provide estimates on the number of classes of a given VC dimension, and the number of maximum classes of a given VC dimension \u2013 answering a question of Frankl from \u201989, and (ii) design an efficient algorithm that provides an O(N/\\log(N)) multiplicative approximation for the sign rank (computing the sign rank is equivalent to the existential theory of the reals). We also observe a general connection between sign rank and spectral gaps which is based on Forster\u2019s argument. Consider the N \\times N adjacency matrix of a \u2206regular graph with a second eigenvalue of absolute value \u03bband \u2206\u2264N/2. We show that the sign rank of the signed version of this matrix is at least \u2206/\u03bb. We use this connection to prove the existence of a maximum class C\u2286{\\pm 1}^N with VC dimension 2 and sign rank \\tilde\u0398(N^1/2). This answers a question of Ben-David et al.\u00a0regarding the sign rank of large VC classes. We also describe limitations of this approach, in the spirit of the Alon-Boppana theorem. We further describe connections to communication complexity, geometry, learning theory, and combinatorics.",
        "bibtex": "@InProceedings{pmlr-v49-alon16,\n  title = \t {Sign rank versus {VC} dimension},\n  author = \t {Alon, Noga and Moran, Shay and Yehudayoff, Amir},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {47--80},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/alon16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/alon16.html},\n  abstract = \t {This work studies the maximum possible sign rank of N \\times N sign matrices with a given VC dimension d. For d=1, this maximum is three. For d=2, this maximum is \\tilde\u0398(N^1/2). For d >2, similar but slightly less accurate statements hold. Our lower bounds improve over previous ones by Ben-David et al.\u00a0and can be interpreted as exhibiting a weakness of kernel-based classifiers. Our upper bounds, on the other hand, can be interpreted as exhibiting the universality of kernel-based classifiers. The lower bounds are obtained by probabilistic constructions, using a theorem of Warren in real algebraic topology. The upper bounds are obtained using a result of Welzl about spanning trees with low stabbing number, and using the moment curve. The upper bound technique is also used to: (i) provide estimates on the number of classes of a given VC dimension, and the number of maximum classes of a given VC dimension \u2013 answering a question of Frankl from \u201989, and (ii) design an efficient algorithm that provides an O(N/\\log(N)) multiplicative approximation for the sign rank (computing the sign rank is equivalent to the existential theory of the reals). We also observe a general connection between sign rank and spectral gaps which is based on Forster\u2019s argument. Consider the N \\times N adjacency matrix of a \u2206regular graph with a second eigenvalue of absolute value \u03bband \u2206\u2264N/2. We show that the sign rank of the signed version of this matrix is at least \u2206/\u03bb. We use this connection to prove the existence of a maximum class C\u2286{\\pm 1}^N with VC dimension 2 and sign rank \\tilde\u0398(N^1/2). This answers a question of Ben-David et al.\u00a0regarding the sign rank of large VC classes. We also describe limitations of this approach, in the spirit of the Alon-Boppana theorem. We further describe connections to communication complexity, geometry, learning theory, and combinatorics.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/alon16.pdf",
        "supp": "",
        "pdf_size": 406586,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8430008775750952035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 21,
        "aff": "School of Computer Science, Tel Aviv University, Tel Aviv 69978, Israel + Microsoft Research, Hertzeliya + School of Mathematics, Institute for Advanced Study, Princeton, NJ 08540; Department of Computer Science, Technion-IIT, Microsoft Research, Hertzeliya + Max Planck Institute for Informatics, Saarbr\u00fccken, Germany; Department of Mathematics, Technion-IIT",
        "aff_domain": "TAU.AC.IL;CS.TECHNION.AC.IL;GMAIL.COM",
        "email": "TAU.AC.IL;CS.TECHNION.AC.IL;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;3+4;3",
        "aff_unique_norm": "Tel Aviv University;Microsoft;Institute for Advanced Study;Technion-IIT;Max Planck Institute for Informatics",
        "aff_unique_dep": "School of Computer Science;Microsoft Research;School of Mathematics;Department of Computer Science;",
        "aff_unique_url": "https://www.tau.ac.il;https://www.microsoft.com/en-us/research/group/microsoft-research-israel;https://www.ias.edu;https://www.technion.ac.il/en/;https://mpi-inf.mpg.de",
        "aff_unique_abbr": "TAU;MSR;IAS;Technion;MPII",
        "aff_campus_unique_index": "0+1+2;4",
        "aff_campus_unique": "Tel Aviv;Hertzeliya;Princeton;;Saarbr\u00fccken",
        "aff_country_unique_index": "0+0+1;0+2;0",
        "aff_country_unique": "Israel;United States;Germany"
    },
    {
        "id": "24cca9b47f",
        "title": "Simple Bayesian Algorithms for Best Arm Identification",
        "site": "https://proceedings.mlr.press/v49/russo16.html",
        "author": "Daniel Russo",
        "abstract": "This paper considers the optimal adaptive allocation of measurement effort for identifying the best among a finite set of options or designs.  An experimenter sequentially chooses designs to measure and observes noisy signals of their quality with the goal of confidently identifying the best design  after a small number of measurements. I propose three simple Bayesian algorithms for adaptively allocating measurement effort. One is Top-Two Probability sampling, which computes the two designs with the highest posterior probability of being optimal, and then randomizes to select among these two. One is a variant a top-two sampling which considers not only the probability a design is optimal, but the expected amount by which its quality exceeds that of other designs. The final algorithm is a modified version of Thompson sampling that is tailored for identifying the best design. I prove that these simple algorithms satisfy a strong optimality property. In a frequestist setting where the true quality of the designs is fixed, one hopes the posterior definitively identifies the optimal design, in the sense that that the posterior probability assigned to the event that some other design is optimal converges to zero as measurements are collected. I show that under the proposed algorithms this convergence occurs at an \\emphexponential rate, and the corresponding exponent is the best possible among all allocation rules.",
        "bibtex": "@InProceedings{pmlr-v49-russo16,\n  title = \t {Simple Bayesian Algorithms for Best Arm Identification},\n  author = \t {Russo, Daniel},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1417--1418},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/russo16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/russo16.html},\n  abstract = \t {This paper considers the optimal adaptive allocation of measurement effort for identifying the best among a finite set of options or designs.  An experimenter sequentially chooses designs to measure and observes noisy signals of their quality with the goal of confidently identifying the best design  after a small number of measurements. I propose three simple Bayesian algorithms for adaptively allocating measurement effort. One is Top-Two Probability sampling, which computes the two designs with the highest posterior probability of being optimal, and then randomizes to select among these two. One is a variant a top-two sampling which considers not only the probability a design is optimal, but the expected amount by which its quality exceeds that of other designs. The final algorithm is a modified version of Thompson sampling that is tailored for identifying the best design. I prove that these simple algorithms satisfy a strong optimality property. In a frequestist setting where the true quality of the designs is fixed, one hopes the posterior definitively identifies the optimal design, in the sense that that the posterior probability assigned to the event that some other design is optimal converges to zero as measurements are collected. I show that under the proposed algorithms this convergence occurs at an \\emphexponential rate, and the corresponding exponent is the best possible among all allocation rules.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/russo16.pdf",
        "supp": "",
        "pdf_size": 81993,
        "gs_citation": 365,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5472303939121651001&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Microsoft Research New England",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "http://arxiv.org/abs/1602.08448",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-new-england",
        "aff_unique_abbr": "MSR NE",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New England",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c8b7fb072c",
        "title": "Spectral thresholds in the bipartite stochastic block model",
        "site": "https://proceedings.mlr.press/v49/florescu16.html",
        "author": "Laura Florescu; Will Perkins",
        "abstract": "We consider a bipartite stochastic block model on vertex sets V_1 and V_2, with planted partitions in each, and ask at what densities efficient algorithms can recover the partition of the smaller vertex set. When |V_2| \u226b|V_1|, multiple thresholds emerge.  We first locate a sharp threshold for detection of the partition, in the sense of the results of Mossel, Neeman and Sly and  Massoulie for the stochastic block model.  We then show that at a higher edge density, the singular vectors of the rectangular biadjacency matrix exhibit a localization / delocalization phase transition, giving recovery above the threshold and no recovery below.  Nevertheless, we propose a simple spectral algorithm,  Diagonal Deletion SVD, which recovers the partition at a nearly optimal edge density. The bipartite stochastic block model studied here was used by Feldman, Perkins, Vempala to give a unified algorithm for recovering planted partitions and assignments in random hypergraphs and random k-SAT formulae respectively.  Our results give the best known bounds for the clause density at which solutions can be found efficiently in these models as well as showing a barrier to further improvement via this reduction to the bipartite block model.",
        "bibtex": "@InProceedings{pmlr-v49-florescu16,\n  title = \t {Spectral thresholds in the bipartite stochastic block model},\n  author = \t {Florescu, Laura and Perkins, Will},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {943--959},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/florescu16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/florescu16.html},\n  abstract = \t {We consider a bipartite stochastic block model on vertex sets V_1 and V_2, with planted partitions in each, and ask at what densities efficient algorithms can recover the partition of the smaller vertex set. When |V_2| \u226b|V_1|, multiple thresholds emerge.  We first locate a sharp threshold for detection of the partition, in the sense of the results of Mossel, Neeman and Sly and  Massoulie for the stochastic block model.  We then show that at a higher edge density, the singular vectors of the rectangular biadjacency matrix exhibit a localization / delocalization phase transition, giving recovery above the threshold and no recovery below.  Nevertheless, we propose a simple spectral algorithm,  Diagonal Deletion SVD, which recovers the partition at a nearly optimal edge density. The bipartite stochastic block model studied here was used by Feldman, Perkins, Vempala to give a unified algorithm for recovering planted partitions and assignments in random hypergraphs and random k-SAT formulae respectively.  Our results give the best known bounds for the clause density at which solutions can be found efficiently in these models as well as showing a barrier to further improvement via this reduction to the bipartite block model.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/florescu16.pdf",
        "supp": "",
        "pdf_size": 501097,
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15215340328811975052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "New York University; University of Birmingham",
        "aff_domain": "CIMS.NYU.EDU;GMAIL.COM",
        "email": "CIMS.NYU.EDU;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "New York University;University of Birmingham",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nyu.edu;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "NYU;Birmingham",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9e2216a198",
        "title": "Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja\u2019s Algorithm",
        "site": "https://proceedings.mlr.press/v49/jain16.html",
        "author": "Prateek Jain; Chi Jin; Sham M. Kakade; Praneeth Netrapalli; Aaron Sidford",
        "abstract": "In this paper we provide improved guarantees for streaming principal component analysis (PCA). Given A_1, \\ldots, A_n\u2208\\mathbbR^d\\times d sampled independently from distributions satisfying \\mathbbE[A_i] = \u03a3for \u03a3\\succeq 0, we present an O(d)-space linear-time single-pass streaming algorithm for estimating the top eigenvector of \u03a3. The algorithm nearly matches (and in certain cases improves upon) the accuracy obtained by the standard batch method that computes top eigenvector of the empirical covariance \\frac1n \\sum_i \u2208[n] A_i as analyzed by the matrix Bernstein inequality. Moreover, to achieve constant accuracy, our algorithm improves upon the best previous known sample complexities of streaming algorithms by either a multiplicative factor of O(d) or 1/\\mathrmgap where \\mathrmgap is the relative distance between the top two eigenvalues of \u03a3. We achieve these results through a novel analysis of the classic Oja\u2019s algorithm, one of the oldest and perhaps, most popular algorithms for streaming PCA. We show that simply picking a random initial point w_0 and applying the natural update rule w_i + 1 = w_i + \\eta_i A_i w_i suffices for suitable choice of \\eta_i. We believe our result sheds light on how to efficiently perform streaming PCA both in theory and in practice and we hope that our analysis may serve as the basis for analyzing many variants and extensions of streaming PCA.",
        "bibtex": "@InProceedings{pmlr-v49-jain16,\n  title = \t {Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja's Algorithm},\n  author = \t {Jain, Prateek and Jin, Chi and Kakade, Sham M. and Netrapalli, Praneeth and Sidford, Aaron},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1147--1164},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/jain16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/jain16.html},\n  abstract = \t {In this paper we provide improved guarantees for streaming principal component analysis (PCA). Given A_1, \\ldots, A_n\u2208\\mathbbR^d\\times d sampled independently from distributions satisfying \\mathbbE[A_i] = \u03a3for \u03a3\\succeq 0, we present an O(d)-space linear-time single-pass streaming algorithm for estimating the top eigenvector of \u03a3. The algorithm nearly matches (and in certain cases improves upon) the accuracy obtained by the standard batch method that computes top eigenvector of the empirical covariance \\frac1n \\sum_i \u2208[n] A_i as analyzed by the matrix Bernstein inequality. Moreover, to achieve constant accuracy, our algorithm improves upon the best previous known sample complexities of streaming algorithms by either a multiplicative factor of O(d) or 1/\\mathrmgap where \\mathrmgap is the relative distance between the top two eigenvalues of \u03a3. We achieve these results through a novel analysis of the classic Oja\u2019s algorithm, one of the oldest and perhaps, most popular algorithms for streaming PCA. We show that simply picking a random initial point w_0 and applying the natural update rule w_i + 1 = w_i + \\eta_i A_i w_i suffices for suitable choice of \\eta_i. We believe our result sheds light on how to efficiently perform streaming PCA both in theory and in practice and we hope that our analysis may serve as the basis for analyzing many variants and extensions of streaming PCA.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/jain16.pdf",
        "supp": "",
        "pdf_size": 373203,
        "gs_citation": 154,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14100386427123413647&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Microsoft Research, Bangalore India; UC Berkeley, Berkeley CA; University of Washington, Seattle WA; Microsoft Research, Cambridge MA; Microsoft Research, Cambridge MA",
        "aff_domain": "MICROSOFT.COM;CS.BERKELEY.EDU;CS.WASHINGTON.EDU;MICROSOFT.COM;MICROSOFT.COM",
        "email": "MICROSOFT.COM;CS.BERKELEY.EDU;CS.WASHINGTON.EDU;MICROSOFT.COM;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Microsoft;University of California, Berkeley;University of Washington",
        "aff_unique_dep": "Research;;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/bangalore;https://www.berkeley.edu;https://www.washington.edu",
        "aff_unique_abbr": "MSR;UC Berkeley;UW",
        "aff_campus_unique_index": "0;1;2;3;3",
        "aff_campus_unique": "Bangalore;Berkeley;Seattle;Cambridge",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "b32caecda6",
        "title": "The Extended Littlestone\u2019s Dimension for Learning with Mistakes and Abstentions",
        "site": "https://proceedings.mlr.press/v49/zhang16a.html",
        "author": "Chicheng Zhang; Kamalika Chaudhuri",
        "abstract": "This paper studies classification with an abstention option in the online setting. In this setting, examples arrive sequentially, the learner is given a hypothesis class \\mathcalH, and the goal of the learner is to either predict a label on each example or abstain, while ensuring that it does not make more than a pre-specified number of mistakes when it does predict a label. Previous work on this problem has left open two main challenges. First, not much is known about the optimality of algorithms, and in particular, about what an optimal algorithmic strategy is for any individual hypothesis class. Second, while the realizable case has been studied, the more realistic non-realizable scenario is not well-understood. In this paper, we address both challenges. First, we provide a novel measure, called the Extended Littlestone\u2019s Dimension, which captures the number of abstentions needed to ensure a certain number of mistakes. Second, we explore the non-realizable case, and provide upper and lower bounds on the number of abstentions required by an algorithm to guarantee a specified number of mistakes.",
        "bibtex": "@InProceedings{pmlr-v49-zhang16a,\n  title = \t {The Extended Littlestone's Dimension for Learning with Mistakes and Abstentions},\n  author = \t {Zhang, Chicheng and Chaudhuri, Kamalika},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1584--1616},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/zhang16a.pdf},\n  url = \t {https://proceedings.mlr.press/v49/zhang16a.html},\n  abstract = \t {This paper studies classification with an abstention option in the online setting. In this setting, examples arrive sequentially, the learner is given a hypothesis class \\mathcalH, and the goal of the learner is to either predict a label on each example or abstain, while ensuring that it does not make more than a pre-specified number of mistakes when it does predict a label. Previous work on this problem has left open two main challenges. First, not much is known about the optimality of algorithms, and in particular, about what an optimal algorithmic strategy is for any individual hypothesis class. Second, while the realizable case has been studied, the more realistic non-realizable scenario is not well-understood. In this paper, we address both challenges. First, we provide a novel measure, called the Extended Littlestone\u2019s Dimension, which captures the number of abstentions needed to ensure a certain number of mistakes. Second, we explore the non-realizable case, and provide upper and lower bounds on the number of abstentions required by an algorithm to guarantee a specified number of mistakes.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/zhang16a.pdf",
        "supp": "",
        "pdf_size": 349886,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6781420208788866285&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science and Engineering, University of California San Diego; Department of Computer Science and Engineering, University of California San Diego",
        "aff_domain": "UCSD.EDU;CS.UCSD.EDU",
        "email": "UCSD.EDU;CS.UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "15d7dc579f",
        "title": "The Power of Depth for Feedforward Neural Networks",
        "site": "https://proceedings.mlr.press/v49/eldan16.html",
        "author": "Ronen Eldan; Ohad Shamir",
        "abstract": "We show that there is a simple (approximately radial) function on \\mathbbR^d, expressible by a small 3-layer feedforward neural networks, which cannot be approximated by any 2-layer network, to more than a certain constant accuracy, unless its width is exponential in the dimension. The result holds for virtually all known activation functions, including rectified linear units, sigmoids and thresholds, and formally demonstrates that depth \u2013 even if increased by 1 \u2013 can be exponentially more valuable than width for standard feedforward neural networks. Moreover, compared to related results in the context of Boolean functions, our result requires fewer assumptions, and the proof techniques and construction are very different.",
        "bibtex": "@InProceedings{pmlr-v49-eldan16,\n  title = \t {The Power of Depth for Feedforward Neural Networks},\n  author = \t {Eldan, Ronen and Shamir, Ohad},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {907--940},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/eldan16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/eldan16.html},\n  abstract = \t {We show that there is a simple (approximately radial) function on \\mathbbR^d, expressible by a small 3-layer feedforward neural networks, which cannot be approximated by any 2-layer network, to more than a certain constant accuracy, unless its width is exponential in the dimension. The result holds for virtually all known activation functions, including rectified linear units, sigmoids and thresholds, and formally demonstrates that depth \u2013 even if increased by 1 \u2013 can be exponentially more valuable than width for standard feedforward neural networks. Moreover, compared to related results in the context of Boolean functions, our result requires fewer assumptions, and the proof techniques and construction are very different. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/eldan16.pdf",
        "supp": "",
        "pdf_size": 626371,
        "gs_citation": 1078,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12999536636571089381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Weizmann Institute of Science, Rehovot, Israel; Weizmann Institute of Science, Rehovot, Israel",
        "aff_domain": "WEIZMANN.AC.IL;WEIZMANN.AC.IL",
        "email": "WEIZMANN.AC.IL;WEIZMANN.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Weizmann Institute of Science",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.weizmann.org.il",
        "aff_unique_abbr": "Weizmann",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Rehovot",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "972a99b3e7",
        "title": "Tight (Lower) Bounds for the Fixed Budget Best Arm Identification Bandit Problem",
        "site": "https://proceedings.mlr.press/v49/carpentier16.html",
        "author": "Alexandra Carpentier; Andrea Locatelli",
        "abstract": "We consider the problem of \\textitbest arm identification with a \\textitfixed budget T, in the K-armed stochastic bandit setting, with arms distribution defined on [0,1]. We prove that any bandit strategy, for at least one bandit problem characterized by a complexity H, will misidentify the best arm with probability lower bounded by $\\exp\\Big(-\\frac{T}\\log(K)H\\Big)$, where $H$ is the sum for all sub-optimal arms of the inverse of the squared gaps. Our result disproves formally the general belief - coming from results in the fixed confidence setting - that there must exist an algorithm for this problem whose probability of error is upper bounded by $\\exp(-T/H)$. This also proves that some existing strategies based on the Successive Rejection of the arms are optimal - closing therefore the current gap between upper and lower bounds for the fixed budget best arm identification problem.",
        "bibtex": "@InProceedings{pmlr-v49-carpentier16,\n  title = \t {Tight (Lower) Bounds for the Fixed Budget Best Arm Identification Bandit Problem},\n  author = \t {Carpentier, Alexandra and Locatelli, Andrea},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {590--604},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/carpentier16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/carpentier16.html},\n  abstract = \t {We consider the problem of \\textitbest arm identification with a \\textitfixed budget T, in the K-armed stochastic bandit setting, with arms distribution defined on [0,1]. We prove that any bandit strategy, for at least one bandit problem characterized by a complexity H, will misidentify the best arm with probability lower bounded by $\\exp\\Big(-\\frac{T}\\log(K)H\\Big)$, where $H$ is the sum for all sub-optimal arms of the inverse of the squared gaps. Our result disproves formally the general belief - coming from results in the fixed confidence setting - that there must exist an algorithm for this problem whose probability of error is upper bounded by $\\exp(-T/H)$. This also proves that some existing strategies based on the Successive Rejection of the arms are optimal - closing therefore the current gap between upper and lower bounds for the fixed budget best arm identification problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/carpentier16.pdf",
        "supp": "",
        "pdf_size": 242081,
        "gs_citation": 172,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8604721548756933296&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Mathematics, University of Potsdam, Germany; Department of Mathematics, University of Potsdam, Germany",
        "aff_domain": "uni-potsdam.de;uni-potsdam.de",
        "email": "uni-potsdam.de;uni-potsdam.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Potsdam",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.uni-potsdam.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "ea27c0b5d9",
        "title": "Time series prediction and online learning",
        "site": "https://proceedings.mlr.press/v49/kuznetsov16.html",
        "author": "Vitaly Kuznetsov; Mehryar Mohri",
        "abstract": "We present a series of theoretical and algorithmic results combining the benefits of the statistical learning approach to time series prediction with that of on-line learning. We prove new generalization guarantees for hypotheses derived from regret minimization algorithms in the general scenario where the data is generated by a non-stationary non-mixing stochastic process. Our theory enables us to derive model selection techniques with favorable theoretical guarantees in the scenario of time series, thereby solving a problem that is notoriously difficult in that scenario. It also helps us devise new ensemble methods with favorable theoretical guarantees for the task of forecasting non-stationary time series.",
        "bibtex": "@InProceedings{pmlr-v49-kuznetsov16,\n  title = \t {Time series prediction and online learning},\n  author = \t {Kuznetsov, Vitaly and Mohri, Mehryar},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1190--1213},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/kuznetsov16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/kuznetsov16.html},\n  abstract = \t {We present a series of theoretical and algorithmic results combining the benefits of the statistical learning approach to time series prediction with that of on-line learning. We prove new generalization guarantees for hypotheses derived from regret minimization algorithms in the general scenario where the data is generated by a non-stationary non-mixing stochastic process. Our theory enables us to derive model selection techniques with favorable theoretical guarantees in the scenario of time series, thereby solving a problem that is notoriously difficult in that scenario. It also helps us devise new ensemble methods with favorable theoretical guarantees for the task of forecasting non-stationary time series. }\n}",
        "pdf": "http://proceedings.mlr.press/v49/kuznetsov16.pdf",
        "supp": "",
        "pdf_size": 381517,
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13987482240884813295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Courant Institute, New York; Courant Institute and Google Research, New York",
        "aff_domain": "CIMS.NYU.EDU;CS.NYU.EDU",
        "email": "CIMS.NYU.EDU;CS.NYU.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Courant Institute of Mathematical Sciences",
        "aff_unique_dep": "Mathematical Sciences",
        "aff_unique_url": "https://courant.nyu.edu",
        "aff_unique_abbr": "Courant",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "49ec14c268",
        "title": "When can we rank well from comparisons of O(n\\log(n)) non-actively chosen pairs?",
        "site": "https://proceedings.mlr.press/v49/rajkumar16.html",
        "author": "Arun Rajkumar; Shivani Agarwal",
        "abstract": "Ranking from pairwise comparisons is a ubiquitous problem and has been studied in disciplines ranging from statistics to operations research and from theoretical computer science to machine learning. Here we consider a general setting where outcomes of pairwise comparisons between items i and j are drawn probabilistically by flipping a coin with unknown bias P_ij , and ask under what conditions on these unknown probabilities one can learn a good ranking from comparisons of only O(n\\log(n)) non-actively chosen pairs. Recent work has established this is possible under the Bradley-Terry-Luce (BTL) and noisy permutation (NP) models. Here we introduce a broad family of \u2018low-rank\u2019 conditions on the probabilities P_ij under which the resulting preference matrix P has low rank under some link function, and show these conditions encompass the BTL and Thurstone classes as special cases, but are considerably more general. We then give a new algorithm called low-rank pairwise ranking (LRPR) which provably learns a good ranking from comparisons of only O(n\\log(n)) randomly chosen comparisons under such low-rank models. Our algorithm and analysis make use of tools from the theory of low-rank matrix completion, and provide a new perspective on the problem of ranking from pairwise comparisons in non-active settings.",
        "bibtex": "@InProceedings{pmlr-v49-rajkumar16,\n  title = \t {When can we rank well from comparisons of $O(n\\log(n))$ non-actively chosen pairs?},\n  author = \t {Rajkumar, Arun and Agarwal, Shivani},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1376--1401},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/rajkumar16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/rajkumar16.html},\n  abstract = \t {Ranking from pairwise comparisons is a ubiquitous problem and has been studied in disciplines ranging from statistics to operations research and from theoretical computer science to machine learning. Here we consider a general setting where outcomes of pairwise comparisons between items i and j are drawn probabilistically by flipping a coin with unknown bias P_ij , and ask under what conditions on these unknown probabilities one can learn a good ranking from comparisons of only O(n\\log(n)) non-actively chosen pairs. Recent work has established this is possible under the Bradley-Terry-Luce (BTL) and noisy permutation (NP) models. Here we introduce a broad family of \u2018low-rank\u2019 conditions on the probabilities P_ij under which the resulting preference matrix P has low rank under some link function, and show these conditions encompass the BTL and Thurstone classes as special cases, but are considerably more general. We then give a new algorithm called low-rank pairwise ranking (LRPR) which provably learns a good ranking from comparisons of only O(n\\log(n)) randomly chosen comparisons under such low-rank models. Our algorithm and analysis make use of tools from the theory of low-rank matrix completion, and provide a new perspective on the problem of ranking from pairwise comparisons in non-active settings.}\n}",
        "pdf": "http://proceedings.mlr.press/v49/rajkumar16.pdf",
        "supp": "",
        "pdf_size": 713460,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16902268119243600316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Xerox Research, Bangalore, India; Radcliffe Institute for Advanced Study, Harvard University, Cambridge, MA, USA + Indian Institute of Science, Bangalore, India",
        "aff_domain": "CSA.IISC.ERNET.IN;CSA.IISC.ERNET.IN",
        "email": "CSA.IISC.ERNET.IN;CSA.IISC.ERNET.IN",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Xerox Research Centre India;Harvard University;Indian Institute of Science",
        "aff_unique_dep": "Research;Radcliffe Institute for Advanced Study;",
        "aff_unique_url": "https://www.xrci.xerox.com;https://www.harvard.edu;https://www.iisc.ac.in",
        "aff_unique_abbr": "XRCI;Harvard;IISc",
        "aff_campus_unique_index": "0;1+0",
        "aff_campus_unique": "Bangalore;Cambridge",
        "aff_country_unique_index": "0;1+0",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "04e6e1d240",
        "title": "benefits of depth in neural networks",
        "site": "https://proceedings.mlr.press/v49/telgarsky16.html",
        "author": "Matus Telgarsky",
        "abstract": "For any positive integer k, there exist neural networks with \u0398(k^3) layers, \u0398(1) nodes per layer, and \u0398(1) distinct parameters which can not be approximated by networks with O(k) layers unless they are exponentially large \u2014 they must possess \u03a9(2^k) nodes. This result is proved here for a class of nodes termed \\emphsemi-algebraic gates which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, sum-product networks, and boosted decision trees (in this last case with a stronger separation: \u03a9(2^k^3) total tree nodes are required).",
        "bibtex": "@InProceedings{pmlr-v49-telgarsky16,\n  title = \t {benefits of depth in neural networks},\n  author = \t {Telgarsky, Matus},\n  booktitle = \t {29th Annual Conference on Learning Theory},\n  pages = \t {1517--1539},\n  year = \t {2016},\n  editor = \t {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},\n  volume = \t {49},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Columbia University, New York, New York, USA},\n  month = \t {23--26 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v49/telgarsky16.pdf},\n  url = \t {https://proceedings.mlr.press/v49/telgarsky16.html},\n  abstract = \t {For any positive integer k, there exist neural networks with \u0398(k^3) layers, \u0398(1) nodes per layer, and \u0398(1) distinct parameters which can not be approximated by networks with O(k) layers unless they are exponentially large \u2014 they must possess \u03a9(2^k) nodes. This result is proved here for a class of nodes termed \\emphsemi-algebraic gates which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, sum-product networks, and boosted decision trees (in this last case with a stronger separation: \u03a9(2^k^3) total tree nodes are required). }\n}",
        "pdf": "http://proceedings.mlr.press/v49/telgarsky16.pdf",
        "supp": "",
        "pdf_size": 328213,
        "gs_citation": 745,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15269530899389386213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Michigan, Ann Arbor",
        "aff_domain": "CS.UCSD.EDU",
        "email": "CS.UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    }
]