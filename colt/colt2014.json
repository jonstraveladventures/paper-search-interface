[
    {
        "id": "5698caa77d",
        "title": "A Convex Formulation for Mixed Regression with Two Components: Minimax Optimal Rates",
        "site": "https://proceedings.mlr.press/v35/chen14.html",
        "author": "Yudong Chen; Xinyang Yi; Constantine Caramanis",
        "abstract": "We consider the mixed regression problem with two components, under adversarial and stochastic noise. We give a convex optimization formulation that provably recovers the true solution, and provide upper bounds on the recovery errors for both arbitrary noise and stochastic noise settings. We also give matching minimax lower bounds (up to log factors), showing that under certain assumptions, our algorithm is information-theoretically optimal. Our results represent the first (and currently only known) tractable algorithm guaranteeing successful recovery with tight bounds on recovery errors and sample complexity.",
        "bibtex": "@InProceedings{pmlr-v35-chen14,\n  title = \t {A Convex Formulation for Mixed Regression with Two Components: Minimax Optimal Rates},\n  author = \t {Chen, Yudong and Yi, Xinyang and Caramanis, Constantine},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {560--604},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/chen14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/chen14.html},\n  abstract = \t {We consider the mixed regression problem with two components, under adversarial and stochastic noise. We give a convex optimization formulation that provably recovers the true solution, and provide upper bounds on the recovery errors for both arbitrary noise and stochastic noise settings. We also give matching minimax lower bounds (up to log factors), showing that under certain assumptions, our algorithm is information-theoretically optimal. Our results represent the first (and currently only known) tractable algorithm guaranteeing successful recovery with tight bounds on recovery errors and sample complexity.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/chen14.pdf",
        "supp": "",
        "pdf_size": 465947,
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2814917968801822746&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical and Computer Engineering, The University of Texas at Austin; Department of Electrical and Computer Engineering, The University of Texas at Austin",
        "aff_domain": "BERKELEY.EDU;UTEXAS.EDU;UTEXAS.EDU",
        "email": "BERKELEY.EDU;UTEXAS.EDU;UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Berkeley;University of Texas at Austin",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UC Berkeley;UT Austin",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Berkeley;Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "632b430580",
        "title": "A second-order bound with excess losses",
        "site": "https://proceedings.mlr.press/v35/gaillard14.html",
        "author": "Pierre Gaillard; Gilles Stoltz; Tim van Erven",
        "abstract": "We study online aggregation of the predictions of experts, and first show new second-order regret bounds in the standard setting, which are obtained via a version of the Prod algorithm (and also a version of the polynomially weighted average algorithm) with multiple learning rates. These bounds are in terms of excess losses, the differences between the instantaneous losses suffered by the algorithm and the ones of a given expert. We then demonstrate the interest of these bounds in the context of experts that report their confidences as a number in the interval [0,1] using a generic reduction to the standard setting. We conclude by two other applications in the standard setting, which improve the known bounds in case of small excess losses and show a bounded regret against i.i.d. sequences of losses.",
        "bibtex": "@InProceedings{pmlr-v35-gaillard14,\n  title = \t {A second-order bound with excess losses},\n  author = \t {Gaillard, Pierre and Stoltz, Gilles and van Erven, Tim},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {176--196},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/gaillard14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/gaillard14.html},\n  abstract = \t {We study online aggregation of the predictions of experts, and first show new second-order regret bounds in the standard setting, which are obtained via a version of the Prod algorithm (and also a version of the polynomially weighted average algorithm) with multiple learning rates. These bounds are in terms of excess losses, the differences between the instantaneous losses suffered by the algorithm and the ones of a given expert. We then demonstrate the interest of these bounds in the context of experts that report their confidences as a number in the interval [0,1] using a generic reduction to the standard setting. We conclude by two other applications in the standard setting, which improve the known bounds in case of small excess losses and show a bounded regret against i.i.d. sequences of losses.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/gaillard14.pdf",
        "supp": "",
        "pdf_size": 299553,
        "gs_citation": 192,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15699052936448445414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 20,
        "aff": "EDF R&D, Clamart, France + GREGHEC: HEC Paris \u2013 CNRS, Jouy-en-Josas, France; GREGHEC: HEC Paris \u2013 CNRS, Jouy-en-Josas, France; Universit \u00b4e Paris-Sud, Orsay, France",
        "aff_domain": "EDF.FR;HEC.FR;TIMVANERVEN.NL",
        "email": "EDF.FR;HEC.FR;TIMVANERVEN.NL",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;2",
        "aff_unique_norm": "EDF R&D;HEC Paris;Universit\u00e9 Paris-Sud",
        "aff_unique_dep": ";GREGHEC;",
        "aff_unique_url": "https://www.edf.com;https://www.hec.edu;https://www.universite-paris-sud.fr",
        "aff_unique_abbr": "EDF;HEC;UPS",
        "aff_campus_unique_index": "0+1;1;2",
        "aff_campus_unique": "Clamart;Jouy-en-Josas;Orsay",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "e9a3e61e46",
        "title": "An Inequality with Applications to Structured Sparsity and Multitask Dictionary Learning",
        "site": "https://proceedings.mlr.press/v35/maurer14.html",
        "author": "Andreas Maurer; Massimiliano Pontil; Bernardino Romera-Paredes",
        "abstract": "From concentration inequalities for the suprema of Gaussian or Rademacher processes an inequality is derived. It is applied to sharpen existing and to derive novel bounds on the empirical Rademacher complexities of unit balls in various norms appearing in the context of structured sparsity and multitask dictionary learning or matrix factorization. A key role is played by the largest eigenvalue of the data covariance matrix.",
        "bibtex": "@InProceedings{pmlr-v35-maurer14,\n  title = \t {An Inequality with Applications to Structured Sparsity and Multitask Dictionary Learning},\n  author = \t {Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {440--460},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/maurer14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/maurer14.html},\n  abstract = \t {From concentration inequalities for the suprema of Gaussian or Rademacher processes an inequality is derived. It is applied to sharpen existing and to derive novel bounds on the empirical Rademacher complexities of unit balls in various norms appearing in the context of structured sparsity and multitask dictionary learning or matrix factorization. A key role is played by the largest eigenvalue of the data covariance matrix.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/maurer14.pdf",
        "supp": "",
        "pdf_size": 355191,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12245082749885290423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Adalbertstrasse 55, D-80799 Munchen, Germany; Department of Computer Science, Centre for Computational Statistics and Machine Learning, University College London, UK; Department of Computer Science and UCL Interactive Centre, University College London, UK",
        "aff_domain": "andreas-maurer.eu;cs.ucl.ac.uk;ucl.ac.uk",
        "email": "andreas-maurer.eu;cs.ucl.ac.uk;ucl.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Technical University of Munich;University College London",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.tum.de;https://www.ucl.ac.uk",
        "aff_unique_abbr": "TUM;UCL",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Munich;;London",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "73357229a0",
        "title": "Approachability in unknown games: Online learning meets multi-objective optimization",
        "site": "https://proceedings.mlr.press/v35/mannor14.html",
        "author": "Shie Mannor; Vianney Perchet; Gilles Stoltz",
        "abstract": "In the standard setting of approachability there are two players and a target set. The players play a repeated vector-valued game where one of them wants to have the average vector-valued payoff converge to the target set which the other player tries to exclude. We revisit the classical setting and consider the setting where the player has a preference relation between target sets: she wishes to approach the smallest (\u201cbest\u201d) set possible given the observed average payoffs in hindsight. Moreover, as opposed to previous works on approachability, and in the spirit of online learning, we do not assume that there is a known game structure with actions for two players. Rather, the player receives an arbitrary vector-valued reward vector at every round. We show that it is impossible, in general, to approach the best target set in hindsight. We further propose a concrete strategy that approaches a non-trivial relaxation of the best-in-hindsight given the actual rewards. Our approach does not require projection onto a target set and amounts to switching between scalar regret minimization algorithms that are performed in episodes.",
        "bibtex": "@InProceedings{pmlr-v35-mannor14,\n  title = \t {Approachability in unknown games: {O}nline learning meets multi-objective optimization},\n  author = \t {Mannor, Shie and Perchet, Vianney and Stoltz, Gilles},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {339--355},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/mannor14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/mannor14.html},\n  abstract = \t {In the standard setting of approachability there are two players and a target set. The players play a repeated vector-valued game where one of them wants to have the average vector-valued payoff converge to the target set which the other player tries to exclude. We revisit the classical setting and consider the setting where the player has a preference relation between target sets: she wishes to approach the smallest (\u201cbest\u201d) set possible given the observed average payoffs in hindsight. Moreover, as opposed to previous works on approachability, and in the spirit of online learning, we do not assume that there is a known game structure with actions for two players. Rather, the player receives an arbitrary vector-valued reward vector at every round. We show that it is impossible, in general, to approach the best target set in hindsight. We further propose a concrete strategy that approaches a non-trivial relaxation of the best-in-hindsight given the actual rewards. Our approach does not require projection onto a target set and amounts to switching between scalar regret minimization algorithms that are performed in episodes.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/mannor14.pdf",
        "supp": "",
        "pdf_size": 328686,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16131611596767110241&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "The Technion, Israel; Universit\u00e9 Paris Diderot, France; GREGHEC: HEC Paris \u2013 CNRS, France",
        "aff_domain": "EE.TECHNION.AC.IL;NORMALESUP.ORG;HEC.FR",
        "email": "EE.TECHNION.AC.IL;NORMALESUP.ORG;HEC.FR",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Technion - Israel Institute of Technology;Universit\u00e9 Paris Diderot;HEC Paris",
        "aff_unique_dep": ";;GREGHEC",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.univ-paris-diderot.fr;https://www.hec.edu",
        "aff_unique_abbr": "Technion;UPD;HEC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Israel;France"
    },
    {
        "id": "a419888861",
        "title": "Bayes-Optimal Scorers for Bipartite Ranking",
        "site": "https://proceedings.mlr.press/v35/menon14.html",
        "author": "Aditya Krishna Menon; Robert C. Williamson",
        "abstract": "We address the following seemingly simple question: what is the Bayes-optimal scorer for a bipartite ranking risk? The answer to this question helps establish the consistency of the minimisation of surrogate bipartite risks, and elucidates the relationship between bipartite ranking and other established learning problems. We show that the answer is non-trivial in general, but may be easily determined for certain special cases using the theory of proper losses. Our analysis immediately establishes equivalences between several seemingly disparate risks for bipartite ranking, such as minimising a suitable class-probability estimation risk, and minimising the p-norm push risk proposed by Rudin (2009).",
        "bibtex": "@InProceedings{pmlr-v35-menon14,\n  title = \t {Bayes-Optimal Scorers for Bipartite Ranking},\n  author = \t {Menon, Aditya Krishna and Williamson, Robert C.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {68--106},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/menon14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/menon14.html},\n  abstract = \t {We address the following seemingly simple question: what is the Bayes-optimal scorer for a bipartite ranking risk? The answer to this question helps establish the consistency of the minimisation of surrogate bipartite risks, and elucidates the relationship between bipartite ranking and other established learning problems. We show that the answer is non-trivial in general, but may be easily determined for certain special cases using the theory of proper losses. Our analysis immediately establishes equivalences between several seemingly disparate risks for bipartite ranking, such as minimising a suitable class-probability estimation risk, and minimising the p-norm push risk proposed by Rudin (2009).}\n}",
        "pdf": "http://proceedings.mlr.press/v35/menon14.pdf",
        "supp": "",
        "pdf_size": 490392,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11720556796272492511&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "NICTA and the Australian National University, Canberra, ACT, Australia; NICTA and the Australian National University, Canberra, ACT, Australia",
        "aff_domain": "nicta.com.au;nicta.com.au",
        "email": "nicta.com.au;nicta.com.au",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Canberra",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "1f55b6027c",
        "title": "Belief propagation, robust reconstruction and optimal recovery of block models",
        "site": "https://proceedings.mlr.press/v35/mossel14.html",
        "author": "Elchanan Mossel; Joe Neeman; Allan Sly",
        "abstract": "We consider the problem of reconstructing sparse symmetric block models with two blocks and connection probabilities a/n and b/n for inter- and intra-block edge probabilities respectively. It was recently shown that one can do better than a random guess if and only if (a-b)^2 > 2(a+b). Using a variant of Belief Propagation, we give a reconstruction algorithm that is \\emphoptimal in the sense that if (a-b)^2 > C (a+b) for some constant C then our algorithm maximizes the fraction of the nodes labelled correctly. Along the way we prove some results of independent interest regarding \\em robust reconstruction for the Ising model on regular and Poisson trees.",
        "bibtex": "@InProceedings{pmlr-v35-mossel14,\n  title = \t {Belief propagation, robust reconstruction and optimal recovery of block models},\n  author = \t {Mossel, Elchanan and Neeman, Joe and Sly, Allan},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {356--370},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/mossel14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/mossel14.html},\n  abstract = \t {We consider the problem of reconstructing sparse symmetric block models with two blocks and connection probabilities a/n and b/n for inter- and intra-block edge probabilities respectively. It was recently shown that one can do better than a random guess if and only if (a-b)^2 > 2(a+b). Using a variant of Belief Propagation, we give a reconstruction algorithm that is \\emphoptimal in the sense that if (a-b)^2 > C (a+b) for some constant C then our algorithm maximizes the fraction of the nodes labelled correctly. Along the way we prove some results of independent interest regarding \\em robust reconstruction for the Ising model on regular and Poisson trees. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/mossel14.pdf",
        "supp": "",
        "pdf_size": 279754,
        "gs_citation": 126,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15778375635072325089&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics and Department of Computer Science, U.C. Berkeley; Department of Electrical and Computer Engineering and Department of Math, U.T. Austin; Department of Statistics, U.C. Berkeley",
        "aff_domain": "stat.berkeley.edu;gmail.com;stat.berkeley.edu",
        "email": "stat.berkeley.edu;gmail.com;stat.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Berkeley;University of Texas at Austin",
        "aff_unique_dep": "Department of Statistics;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UC Berkeley;UT Austin",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Berkeley;Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "34121fed98",
        "title": "Community Detection via Random and Adaptive Sampling",
        "site": "https://proceedings.mlr.press/v35/yun14.html",
        "author": "Se-Young Yun; Alexandre Proutiere",
        "abstract": "In this paper, we consider networks consisting of a finite number of non-overlapping communities. To extract these communities, the interaction between pairs of nodes may be sampled from a large available data set, which allows a given node pair to be sampled several times. When a node pair is sampled, the observed outcome is a binary random variable, equal to 1 if nodes interact and to 0 otherwise. The outcome is more likely to be positive if nodes belong to the same communities. For a given budget of node pair samples or observations, we wish to jointly design a sampling strategy (the sequence of sampled node pairs) and a clustering algorithm that recover the hidden communities with the highest possible accuracy. We consider both non-adaptive and adaptive sampling strategies, and for both classes of strategies, we derive fundamental performance limits satisfied by any sampling and clustering algorithm. In particular, we provide necessary conditions for the existence of algorithms recovering the communities accurately as the network size grows large. We also devise simple algorithms that accurately reconstruct the communities when this is at all possible, hence proving that the proposed necessary conditions for accurate community detection are also sufficient. The classical problem of community detection in the stochastic block model can be seen as a particular instance of the problems consider here. But our framework covers more general scenarios where the sequence of sampled node pairs can be designed in an adaptive manner. The paper provides new results for the stochastic block model, and extends the analysis to the case of adaptive sampling.",
        "bibtex": "@InProceedings{pmlr-v35-yun14,\n  title = \t {Community Detection via Random and Adaptive Sampling},\n  author = \t {Yun, Se-Young and Proutiere, Alexandre},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {138--175},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/yun14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/yun14.html},\n  abstract = \t {In this paper, we consider networks consisting of a finite number of non-overlapping communities. To extract these communities, the interaction between pairs of nodes may be sampled from a large available data set, which allows a given node pair to be sampled several times. When a node pair is sampled, the observed outcome is a binary random variable, equal to 1 if nodes interact and to 0 otherwise. The outcome is more likely to be positive if nodes belong to the same communities. For a given budget of node pair samples or observations, we wish to jointly design a sampling strategy (the sequence of sampled node pairs) and a clustering algorithm that recover the hidden communities with the highest possible accuracy. We consider both non-adaptive and adaptive sampling strategies, and for both classes of strategies, we derive fundamental performance limits satisfied by any sampling and clustering algorithm. In particular, we provide necessary conditions for the existence of algorithms recovering the communities accurately as the network size grows large. We also devise simple algorithms that accurately reconstruct the communities when this is at all possible, hence proving that the proposed necessary conditions for accurate community detection are also sufficient. The classical problem of community detection in the stochastic block model can be seen as a particular instance of the problems consider here. But our framework covers more general scenarios where the sequence of sampled node pairs can be designed in an adaptive manner. The paper provides new results for the stochastic block model, and extends the analysis to the case of adaptive sampling.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/yun14.pdf",
        "supp": "",
        "pdf_size": 421981,
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2572003552130073357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "MSR-Inria, 23 Avenue d\u2019Italie, 75013 Paris, France; KTH, Osquldasv. 10, 100-44 Stockholm, Sweden + INRIA, 23 Avenue d\u2019Italie, 75013 Paris, France",
        "aff_domain": "inria.fr;kth.se",
        "email": "inria.fr;kth.se",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Microsoft;KTH Royal Institute of Technology;INRIA",
        "aff_unique_dep": "Microsoft Research - Inria Joint Research Centre;;",
        "aff_unique_url": "https://www.msr-inria.fr;https://www.kth.se;https://www.inria.fr",
        "aff_unique_abbr": "MSR-Inria;KTH;INRIA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stockholm",
        "aff_country_unique_index": "0;1+0",
        "aff_country_unique": "France;Sweden"
    },
    {
        "id": "0adddc2f22",
        "title": "Compressed Counting Meets Compressed Sensing",
        "site": "https://proceedings.mlr.press/v35/li14.html",
        "author": "Ping Li; Cun-Hui Zhang; Tong Zhang",
        "abstract": "Compressed sensing (sparse signal recovery) has been a popular and important research topic in recent years. By observing that natural signals  (e.g., images or network data) are often nonnegative, we propose a framework for nonnegative signal recovery using \\em Compressed Counting (CC). CC is a technique built on  \\em maximally-skewed \u03b1-stable random projections originally developed for data stream computations (e.g., entropy estimations).  Our recovery procedure is computationally efficient in that it requires only one linear scan of the coordinates. In our settings, the signal \\mathbfx\u2208\\mathbbR^N is assumed to be nonnegative, i.e., x_i\u22650, \u2200i. We prove that, when \u03b1\u2208(0, 0.5], it suffices to use  M=(C_\u03b1+o(1)) \u03b5^-\u03b1 \\left(\\sum_i=1^N x_i^\u03b1\\right)\\log N/\u03b4measurements so that, with probability 1-\u03b4, all coordinates will be recovered within \u03b5additive precision, in one scan of the coordinates. The constant C_\u03b1=1 when \u03b1\\rightarrow0 and C_\u03b1=\\pi/2 when \u03b1=0.5. In particular, when \u03b1\\rightarrow0, the required number of measurements is essentially M=K\\log N/\u03b4, where K = \\sum_i=1^N 1{x_i\u22600} is the number of nonzero coordinates of the signal.",
        "bibtex": "@InProceedings{pmlr-v35-li14,\n  title = \t {Compressed Counting Meets Compressed Sensing},\n  author = \t {Li, Ping and Zhang, Cun-Hui and Zhang, Tong},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1058--1077},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/li14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/li14.html},\n  abstract = \t {Compressed sensing (sparse signal recovery) has been a popular and important research topic in recent years. By observing that natural signals  (e.g., images or network data) are often nonnegative, we propose a framework for nonnegative signal recovery using \\em Compressed Counting (CC). CC is a technique built on  \\em maximally-skewed \u03b1-stable random projections originally developed for data stream computations (e.g., entropy estimations).  Our recovery procedure is computationally efficient in that it requires only one linear scan of the coordinates. In our settings, the signal \\mathbfx\u2208\\mathbbR^N is assumed to be nonnegative, i.e., x_i\u22650, \u2200i. We prove that, when \u03b1\u2208(0, 0.5], it suffices to use  M=(C_\u03b1+o(1)) \u03b5^-\u03b1 \\left(\\sum_i=1^N x_i^\u03b1\\right)\\log N/\u03b4measurements so that, with probability 1-\u03b4, all coordinates will be recovered within \u03b5additive precision, in one scan of the coordinates. The constant C_\u03b1=1 when \u03b1\\rightarrow0 and C_\u03b1=\\pi/2 when \u03b1=0.5. In particular, when \u03b1\\rightarrow0, the required number of measurements is essentially M=K\\log N/\u03b4, where K = \\sum_i=1^N 1{x_i\u22600} is the number of nonzero coordinates of the signal.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/li14.pdf",
        "supp": "",
        "pdf_size": 208356,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10680166790267819707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Departmentof StatisticsandBiostatistics,Departmentof ComputerScience, RutgersUniversity; Departmentof StatisticsandBiostatistics, RutgersUniversity; Departmentof StatisticsandBiostatistics, RutgersUniversity",
        "aff_domain": "STAT.RUTGERS.EDU;STAT.RUTGERS.EDU;STAT.RUTGERS.EDU",
        "email": "STAT.RUTGERS.EDU;STAT.RUTGERS.EDU;STAT.RUTGERS.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Statistics and Biostatistics",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7a3d267f4f",
        "title": "Computational Limits for Matrix Completion",
        "site": "https://proceedings.mlr.press/v35/hardt14b.html",
        "author": "Moritz Hardt; Raghu Meka; Prasad Raghavendra; Benjamin Weitz",
        "abstract": "Matrix Completion is the problem of recovering an unknown real-valued low-rank matrix from a subsample of its entries. Important recent results show that the problem can be solved efficiently under the assumption that the unknown matrix is incoherent and the subsample is drawn uniformly at random. Are these assumptions necessary? It is well known that Matrix Completion in its full generality is NP-hard. However, little is known if we make additional assumptions such as incoherence and permit the algorithm to output a matrix of slightly higher rank. In this paper we prove that Matrix Completion remains computationally intractable even if the unknown matrix has rank\u00a04 but we are allowed to output any constant rank matrix, and even if additionally we assume that the unknown  matrix is incoherent and are shown 90% of the entries. This result relies on the conjectured hardness of the 4-Coloring problem. We also consider the positive semidefinite Matrix Completion problem. Here we show a similar hardness result under the standard assumption that \\mathrmP\\ne \\mathrmNP. Our results greatly narrow the gap between existing feasibility results and computational lower bounds. In particular, we believe that our results give the first complexity-theoretic justification for why distributional assumptions are needed beyond the incoherence assumption in order to obtain positive results. On the technical side, we contribute several new ideas on how to encode hard combinatorial problems in low-rank optimization problems. We hope that these techniques will be helpful in further understanding the computational limits of Matrix Completion and related problems.",
        "bibtex": "@InProceedings{pmlr-v35-hardt14b,\n  title = \t {Computational Limits for Matrix Completion},\n  author = \t {Hardt, Moritz and Meka, Raghu and Raghavendra, Prasad and Weitz, Benjamin},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {703--725},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/hardt14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/hardt14b.html},\n  abstract = \t {Matrix Completion is the problem of recovering an unknown real-valued low-rank matrix from a subsample of its entries. Important recent results show that the problem can be solved efficiently under the assumption that the unknown matrix is incoherent and the subsample is drawn uniformly at random. Are these assumptions necessary? It is well known that Matrix Completion in its full generality is NP-hard. However, little is known if we make additional assumptions such as incoherence and permit the algorithm to output a matrix of slightly higher rank. In this paper we prove that Matrix Completion remains computationally intractable even if the unknown matrix has rank\u00a04 but we are allowed to output any constant rank matrix, and even if additionally we assume that the unknown  matrix is incoherent and are shown 90% of the entries. This result relies on the conjectured hardness of the 4-Coloring problem. We also consider the positive semidefinite Matrix Completion problem. Here we show a similar hardness result under the standard assumption that \\mathrmP\\ne \\mathrmNP. Our results greatly narrow the gap between existing feasibility results and computational lower bounds. In particular, we believe that our results give the first complexity-theoretic justification for why distributional assumptions are needed beyond the incoherence assumption in order to obtain positive results. On the technical side, we contribute several new ideas on how to encode hard combinatorial problems in low-rank optimization problems. We hope that these techniques will be helpful in further understanding the computational limits of Matrix Completion and related problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/hardt14b.pdf",
        "supp": "",
        "pdf_size": 269971,
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8181783707986544373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "IBM Research Almaden; Microsoft Research; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "US.IBM.COM;MICROSOFT.COM;CS.BERKELEY.EDU;EECS.BERKELEY.EDU",
        "email": "US.IBM.COM;MICROSOFT.COM;CS.BERKELEY.EDU;EECS.BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "IBM;Microsoft;University of California, Berkeley",
        "aff_unique_dep": "IBM Research;Microsoft Research;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.microsoft.com/en-us/research;https://www.berkeley.edu",
        "aff_unique_abbr": "IBM;MSR;UC Berkeley",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "Almaden;;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "551433dcda",
        "title": "Density-preserving quantization with application to graph downsampling",
        "site": "https://proceedings.mlr.press/v35/alamgir14.html",
        "author": "Morteza Alamgir; G\u00e1bor Lugosi; Ulrike Luxburg",
        "abstract": "We consider the problem of vector quantization of i.i.d. samples drawn from a density p on \\mathbbR^d. It is  desirable that the representatives selected by the quantization algorithm have the same distribution p as the original sample points. However, quantization algorithms based on Euclidean distance, such as k-means, do not have this property. We provide a solution to this problem that takes the unweighted k-nearest neighbor graph on the sample as input. In particular, it does not need to have access to the data points themselves. Our solution generates quantization centers that are \u201cevenly spaced\". We exploit this property to downsample geometric graphs and show that our method produces  sparse downsampled graphs.  Our algorithm is easy to implement, and we provide theoretical guarantees on the performance of the proposed algorithm.",
        "bibtex": "@InProceedings{pmlr-v35-alamgir14,\n  title = \t {Density-preserving quantization with application to graph downsampling},\n  author = \t {Alamgir, Morteza and Lugosi, G\u00e1bor and Luxburg, Ulrike},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {543--559},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/alamgir14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/alamgir14.html},\n  abstract = \t {We consider the problem of vector quantization of i.i.d. samples drawn from a density p on \\mathbbR^d. It is  desirable that the representatives selected by the quantization algorithm have the same distribution p as the original sample points. However, quantization algorithms based on Euclidean distance, such as k-means, do not have this property. We provide a solution to this problem that takes the unweighted k-nearest neighbor graph on the sample as input. In particular, it does not need to have access to the data points themselves. Our solution generates quantization centers that are \u201cevenly spaced\". We exploit this property to downsample geometric graphs and show that our method produces  sparse downsampled graphs.  Our algorithm is easy to implement, and we provide theoretical guarantees on the performance of the proposed algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/alamgir14.pdf",
        "supp": "",
        "pdf_size": 562998,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12087416019891886149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, University of Hamburg; ICREA and Department of Economics, Universitat Pompeu Fabra + Department of Computer Science, University of Hamburg; Department of Computer Science, University of Hamburg",
        "aff_domain": "INFORMATIK.UNI-HAMBURG.DE;UPF.EDU;INFORMATIK.UNI-HAMBURG.DE",
        "email": "INFORMATIK.UNI-HAMBURG.DE;UPF.EDU;INFORMATIK.UNI-HAMBURG.DE",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "University of Hamburg;Universitat Pompeu Fabra",
        "aff_unique_dep": "Department of Computer Science;Department of Economics",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.upf.edu",
        "aff_unique_abbr": "UHH;UPF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;0",
        "aff_country_unique": "Germany;Spain"
    },
    {
        "id": "15fcb9c754",
        "title": "Distribution-independent Reliable Learning",
        "site": "https://proceedings.mlr.press/v35/kanade14.html",
        "author": "Varun Kanade; Justin Thaler",
        "abstract": "We study several questions in the \\emphreliable agnostic learning framework of Kalai et al. (2009), which captures learning tasks in which one type of error is costlier than other types. A positive reliable classifier is one that makes no false positive errors.  The goal in the \\emphpositive reliable agnostic framework is to output a hypothesis with the following properties: (i) its false positive error rate is at most \u03b5, (ii) its false negative error rate is at most \u03b5more than that of the best positive reliable classifier from the class.  A closely related notion is \\emphfully reliable agnostic learning, which considers \\emphpartial classifiers that are allowed to predict \u201cunknown\u201d on some inputs. The best fully reliable partial classifier is one that makes no errors and minimizes the probability of predicting \u201cunknown\u201d, and the goal in fully reliable learning is to output a hypothesis that is almost as good as the best fully reliable partial classifier from a class. For distribution-independent learning,  the best known algorithms for PAC learning typically utilize polynomial threshold representations, while the state of the art agnostic learning algorithms use point-wise polynomial approximations.  We show that \\emphone-sided polynomial approximations, an intermediate notion between polynomial threshold representations and point-wise polynomial approximations, suffice for learning in the reliable agnostic settings. We then show that majorities can be fully reliably learned and disjunctions of majorities can be positive reliably learned, through constructions of appropriate one-sided polynomial approximations.  Our fully reliable algorithm for majorities provides the first evidence that fully reliable learning may be strictly easier than agnostic learning.  Our algorithms also satisfy strong attribute-efficiency properties, and in many cases they provide smooth tradeoffs between sample complexity and running time.",
        "bibtex": "@InProceedings{pmlr-v35-kanade14,\n  title = \t {Distribution-independent Reliable Learning},\n  author = \t {Kanade, Varun and Thaler, Justin},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {3--24},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kanade14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kanade14.html},\n  abstract = \t {We study several questions in the \\emphreliable agnostic learning framework of Kalai et al. (2009), which captures learning tasks in which one type of error is costlier than other types. A positive reliable classifier is one that makes no false positive errors.  The goal in the \\emphpositive reliable agnostic framework is to output a hypothesis with the following properties: (i) its false positive error rate is at most \u03b5, (ii) its false negative error rate is at most \u03b5more than that of the best positive reliable classifier from the class.  A closely related notion is \\emphfully reliable agnostic learning, which considers \\emphpartial classifiers that are allowed to predict \u201cunknown\u201d on some inputs. The best fully reliable partial classifier is one that makes no errors and minimizes the probability of predicting \u201cunknown\u201d, and the goal in fully reliable learning is to output a hypothesis that is almost as good as the best fully reliable partial classifier from a class. For distribution-independent learning,  the best known algorithms for PAC learning typically utilize polynomial threshold representations, while the state of the art agnostic learning algorithms use point-wise polynomial approximations.  We show that \\emphone-sided polynomial approximations, an intermediate notion between polynomial threshold representations and point-wise polynomial approximations, suffice for learning in the reliable agnostic settings. We then show that majorities can be fully reliably learned and disjunctions of majorities can be positive reliably learned, through constructions of appropriate one-sided polynomial approximations.  Our fully reliable algorithm for majorities provides the first evidence that fully reliable learning may be strictly easier than agnostic learning.  Our algorithms also satisfy strong attribute-efficiency properties, and in many cases they provide smooth tradeoffs between sample complexity and running time. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/kanade14.pdf",
        "supp": "",
        "pdf_size": 307384,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15294137774905479667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of California, Berkeley + Simons Institute for the Theory of Computing at UC Berkeley; Simons Institute for the Theory of Computing at UC Berkeley",
        "aff_domain": "eecs.berkeley.edu;seas.harvard.edu",
        "email": "eecs.berkeley.edu;seas.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0+0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6b4c8fc621",
        "title": "Edge Label Inference in Generalized Stochastic Block Models: from Spectral Theory to Impossibility Results",
        "site": "https://proceedings.mlr.press/v35/xu14.html",
        "author": "Jiaming Xu; Laurent Massouli\u00e9; Marc Lelarge",
        "abstract": "The classical setting of community detection consists of networks exhibiting a clustered structure. To more accurately model real systems we consider a class of networks (i) whose edges may carry labels and (ii) which may lack a clustered structure. Specifically we assume that nodes possess latent attributes drawn from a general compact space and edges between two nodes are randomly generated and labeled according to some unknown distribution as a function of their latent attributes. Our goal is then to infer the edge label distributions from a partially observed network. We propose a computationally efficient spectral algorithm and show it allows for asymptotically correct inference when the average node degree could be as low as logarithmic in the total number of nodes. Conversely, if the average node degree is below a specific constant threshold, we show that no algorithm can achieve better inference than guessing without using the observations. As a byproduct of our analysis, we show that our model provides a general procedure to construct random graph models with a spectrum asymptotic to a pre-specified eigenvalue distribution such as a power-law distribution.",
        "bibtex": "@InProceedings{pmlr-v35-xu14,\n  title = \t {Edge Label Inference in Generalized Stochastic Block Models: from Spectral Theory to Impossibility Results},\n  author = \t {Xu, Jiaming and Massouli\u00e9, Laurent and Lelarge, Marc},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {903--920},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/xu14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/xu14.html},\n  abstract = \t {The classical setting of community detection consists of networks exhibiting a clustered structure. To more accurately model real systems we consider a class of networks (i) whose edges may carry labels and (ii) which may lack a clustered structure. Specifically we assume that nodes possess latent attributes drawn from a general compact space and edges between two nodes are randomly generated and labeled according to some unknown distribution as a function of their latent attributes. Our goal is then to infer the edge label distributions from a partially observed network. We propose a computationally efficient spectral algorithm and show it allows for asymptotically correct inference when the average node degree could be as low as logarithmic in the total number of nodes. Conversely, if the average node degree is below a specific constant threshold, we show that no algorithm can achieve better inference than guessing without using the observations. As a byproduct of our analysis, we show that our model provides a general procedure to construct random graph models with a spectrum asymptotic to a pre-specified eigenvalue distribution such as a power-law distribution. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/xu14.pdf",
        "supp": "",
        "pdf_size": 371536,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11588839362580453088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of Illinois at Urbana-Champaign; Microsoft Research-Inria Joint Centre; INRIA-ENS",
        "aff_domain": "ILLINOIS.EDU;INRIA.FR;ENS.FR",
        "email": "ILLINOIS.EDU;INRIA.FR;ENS.FR",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Microsoft;INRIA",
        "aff_unique_dep": ";Microsoft Research-Inria Joint Centre;ENS",
        "aff_unique_url": "https://illinois.edu;https://www.microsoft.com/en-us/research/group/microsoft-research-inria;https://www.inria.fr",
        "aff_unique_abbr": "UIUC;;INRIA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "efe85dec98",
        "title": "Efficiency of conformalized ridge regression",
        "site": "https://proceedings.mlr.press/v35/burnaev14.html",
        "author": "Evgeny Burnaev; Vladimir Vovk",
        "abstract": "Conformal prediction is a method of producing prediction sets that can be applied on top of a wide range of prediction algorithms. The method has a guaranteed coverage probability under the standard IID assumption regardless of whether the assumptions (often considerably more restrictive) of the underlying algorithm are satisfied. However, for the method to be really useful it is desirable that in the case where the assumptions of the underlying algorithm are satisfied, the conformal predictor loses little in efficiency as compared with the underlying algorithm (whereas being a conformal predictor, it has the stronger guarantee of validity). In this paper we explore the degree to which this additional requirement of efficiency is satisfied in the case of Bayesian ridge regression; we find that asymptotically conformal prediction sets differ little from ridge regression prediction intervals when the standard Bayesian assumptions are satisfied.",
        "bibtex": "@InProceedings{pmlr-v35-burnaev14,\n  title = \t {Efficiency of conformalized ridge regression},\n  author = \t {Burnaev, Evgeny and Vovk, Vladimir},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {605--622},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/burnaev14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/burnaev14.html},\n  abstract = \t {Conformal prediction is a method of producing prediction sets that can be applied on top of a wide range of prediction algorithms. The method has a guaranteed coverage probability under the standard IID assumption regardless of whether the assumptions (often considerably more restrictive) of the underlying algorithm are satisfied. However, for the method to be really useful it is desirable that in the case where the assumptions of the underlying algorithm are satisfied, the conformal predictor loses little in efficiency as compared with the underlying algorithm (whereas being a conformal predictor, it has the stronger guarantee of validity). In this paper we explore the degree to which this additional requirement of efficiency is satisfied in the case of Bayesian ridge regression; we find that asymptotically conformal prediction sets differ little from ridge regression prediction intervals when the standard Bayesian assumptions are satisfied.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/burnaev14.pdf",
        "supp": "",
        "pdf_size": 314472,
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15161363406722621541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Datadvance LLC + Institute for Information Transmission Problems + Moscow Institute of Physics and Technology, Russia; Computer Learning Research Centre, Department of Computer Science, Royal Holloway, University of London, United Kingdom",
        "aff_domain": "DATADVANCE.NET;RHUL.AC.UK",
        "email": "DATADVANCE.NET;RHUL.AC.UK",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "1+2;3",
        "aff_unique_norm": ";Institute for Information Transmission Problems;Moscow Institute of Physics and Technology;Royal Holloway, University of London",
        "aff_unique_dep": ";;;Department of Computer Science",
        "aff_unique_url": ";http://www.iitp.ru;https://www.mipt.ru/en;https://www.royalholloway.ac.uk",
        "aff_unique_abbr": ";;MIPT;RHUL",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Royal Holloway",
        "aff_country_unique_index": "1+1;2",
        "aff_country_unique": ";Russian Federation;United Kingdom"
    },
    {
        "id": "9b12ae99c4",
        "title": "Elicitation and Identification of Properties",
        "site": "https://proceedings.mlr.press/v35/steinwart14.html",
        "author": "Ingo Steinwart; Chlo\u00e9 Pasin; Robert Williamson; Siyu Zhang",
        "abstract": "Properties of distributions are real-valued functionals such as the mean, quantile or conditional value at risk. A property is elicitable if there exists a  scoring function such that minimization of the associated risks recovers the property. We extend existing results to characterize the elicitability of properties in a general setting. We further relate elicitability to identifiability (a notion introduced by Osband) and provide a general formula describing all scoring functions for an elicitable property. Finally, we draw some connections to the theory of coherent risk measures.",
        "bibtex": "@InProceedings{pmlr-v35-steinwart14,\n  title = \t {Elicitation and Identification of Properties},\n  author = \t {Steinwart, Ingo and Pasin, Chlo\u00e9 and Williamson, Robert and Zhang, Siyu},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {482--526},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/steinwart14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/steinwart14.html},\n  abstract = \t {Properties of distributions are real-valued functionals such as the mean, quantile or conditional value at risk. A property is elicitable if there exists a  scoring function such that minimization of the associated risks recovers the property. We extend existing results to characterize the elicitability of properties in a general setting. We further relate elicitability to identifiability (a notion introduced by Osband) and provide a general formula describing all scoring functions for an elicitable property. Finally, we draw some connections to the theory of coherent risk measures.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/steinwart14.pdf",
        "supp": "",
        "pdf_size": 592476,
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6329502340581050487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "University of Stuttgart; \u00c9cole normale sup\u00e9rieure de Cachan; Australian National University and NICTA + \u00c9cole normale sup\u00e9rieure de Cachan; \u00c9cole normale sup\u00e9rieure de Cachan",
        "aff_domain": "mathematik.uni-stuttgart.de;ens-cachan.fr;anu.edu.au; ",
        "email": "mathematik.uni-stuttgart.de;ens-cachan.fr;anu.edu.au; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+1;1",
        "aff_unique_norm": "University of Stuttgart;\u00c9cole Normale Sup\u00e9rieure de Cachan;Australian National University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.ens-cachan.fr;https://www.anu.edu.au",
        "aff_unique_abbr": "USTuttgart;ENS Cachan;ANU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2+1;1",
        "aff_country_unique": "Germany;France;Australia"
    },
    {
        "id": "38a95f60eb",
        "title": "Fast matrix completion without the condition number",
        "site": "https://proceedings.mlr.press/v35/hardt14a.html",
        "author": "Moritz Hardt; Mary Wootters",
        "abstract": "We give the first algorithm for Matrix Completion that achieves running time and sample complexity that is polynomial in the rank of the unknown target matrix, \\emphlinear in the dimension of the matrix, and \\emphlogarithmic in the condition number of the matrix.  To the best of our knowledge, all previous algorithms either incurred a quadratic dependence on the condition number of the unknown matrix or a quadratic dependence on the dimension of the matrix. Our algorithm is based on a novel extension of Alternating Minimization which we show has theoretical guarantees under standard assumptions even in the presence of noise.",
        "bibtex": "@InProceedings{pmlr-v35-hardt14a,\n  title = \t {Fast matrix completion without the condition number},\n  author = \t {Hardt, Moritz and Wootters, Mary},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {638--678},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/hardt14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/hardt14a.html},\n  abstract = \t {We give the first algorithm for Matrix Completion that achieves running time and sample complexity that is polynomial in the rank of the unknown target matrix, \\emphlinear in the dimension of the matrix, and \\emphlogarithmic in the condition number of the matrix.  To the best of our knowledge, all previous algorithms either incurred a quadratic dependence on the condition number of the unknown matrix or a quadratic dependence on the dimension of the matrix. Our algorithm is based on a novel extension of Alternating Minimization which we show has theoretical guarantees under standard assumptions even in the presence of noise. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/hardt14a.pdf",
        "supp": "",
        "pdf_size": 469987,
        "gs_citation": 141,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12437700743688342740&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "IBM Research Almaden; University of Michigan",
        "aff_domain": "US.IBM.COM;UMICH.EDU",
        "email": "US.IBM.COM;UMICH.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "IBM;University of Michigan",
        "aff_unique_dep": "IBM Research;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.umich.edu",
        "aff_unique_abbr": "IBM;UM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Almaden;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "34a993b2b3",
        "title": "Faster and Sample Near-Optimal Algorithms for Proper Learning Mixtures of Gaussians",
        "site": "https://proceedings.mlr.press/v35/daskalakis14.html",
        "author": "Constantinos Daskalakis; Gautam Kamath",
        "abstract": "We provide an algorithm for properly learning mixtures of two single-dimensional Gaussians without any separability assumptions. Given \\tildeO(1/\\varepsilon^2) samples from an unknown mixture, our algorithm outputs a mixture that is \\varepsilon-close in total variation distance, in time \\tildeO(1/\\varepsilon^5). Our sample complexity is optimal up to logarithmic factors, and significantly improves upon both Kalai et al., whose algorithm has a prohibitive dependence on 1/\\varepsilon, and Feldman et al., whose algorithm requires bounds on the mixture parameters and depends pseudo-polynomially in these parameters. One of our main contributions is an improved and generalized algorithm for selecting a good candidate distribution from among competing hypotheses. Namely, given a collection of N hypotheses containing at least one candidate that is \\varepsilon-close to an unknown distribution, our algorithm outputs a candidate which is O(\\varepsilon)-close to the  distribution. The algorithm requires O(\\logN/\\varepsilon^2) samples from the unknown distribution and O(N \\log N/\\varepsilon^2) time, which improves previous such results (such as the Scheff\u00e9 estimator) from a quadratic dependence of the running time on N to quasilinear. Given the wide use of such results for the purpose of hypothesis selection, our improved algorithm implies immediate improvements to any such use.",
        "bibtex": "@InProceedings{pmlr-v35-daskalakis14,\n  title = \t {Faster and Sample Near-Optimal Algorithms for Proper Learning Mixtures of Gaussians},\n  author = \t {Daskalakis, Constantinos and Kamath, Gautam},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1183--1213},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/daskalakis14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/daskalakis14.html},\n  abstract = \t {We provide an algorithm for properly learning mixtures of two single-dimensional Gaussians without any separability assumptions. Given \\tildeO(1/\\varepsilon^2) samples from an unknown mixture, our algorithm outputs a mixture that is \\varepsilon-close in total variation distance, in time \\tildeO(1/\\varepsilon^5). Our sample complexity is optimal up to logarithmic factors, and significantly improves upon both Kalai et al., whose algorithm has a prohibitive dependence on 1/\\varepsilon, and Feldman et al., whose algorithm requires bounds on the mixture parameters and depends pseudo-polynomially in these parameters. One of our main contributions is an improved and generalized algorithm for selecting a good candidate distribution from among competing hypotheses. Namely, given a collection of N hypotheses containing at least one candidate that is \\varepsilon-close to an unknown distribution, our algorithm outputs a candidate which is O(\\varepsilon)-close to the  distribution. The algorithm requires O(\\logN/\\varepsilon^2) samples from the unknown distribution and O(N \\log N/\\varepsilon^2) time, which improves previous such results (such as the Scheff\u00e9 estimator) from a quadratic dependence of the running time on N to quasilinear. Given the wide use of such results for the purpose of hypothesis selection, our improved algorithm implies immediate improvements to any such use. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/daskalakis14.pdf",
        "supp": "",
        "pdf_size": 495344,
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18437637635154470189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "MIT; MIT",
        "aff_domain": "mit.edu;csail.mit.edu",
        "email": "mit.edu;csail.mit.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f0bf2a97e4",
        "title": "Finding a most biased coin with fewest flips",
        "site": "https://proceedings.mlr.press/v35/chandrasekaran14.html",
        "author": "Karthekeyan Chandrasekaran; Richard Karp",
        "abstract": "We study the problem of learning a most biased coin among a set of coins by tossing the coins adaptively. The goal is to minimize the number of tosses until we identify a coin whose posterior probability of being most biased is at least 1-\u03b4for a given \u03b4. Under a particular probabilistic model, we give an optimal algorithm, i.e., an algorithm that minimizes the expected number of future tosses. The problem is closely related to finding the best arm in the multi-armed bandit problem using adaptive strategies. Our algorithm employs an optimal adaptive strategy\u2014a strategy that performs the best possible action at each step after observing the outcomes of all previous coin tosses. Consequently, our algorithm is also optimal for any given starting history of outcomes. To our knowledge, this is the first algorithm that employs an optimal adaptive strategy under a Bayesian setting for this problem. Our proof of optimality employs mathematical tools from the area of Markov games.",
        "bibtex": "@InProceedings{pmlr-v35-chandrasekaran14,\n  title = \t {Finding a most biased coin with fewest flips},\n  author = \t {Chandrasekaran, Karthekeyan and Karp, Richard},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {394--407},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/chandrasekaran14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/chandrasekaran14.html},\n  abstract = \t {We study the problem of learning a most biased coin among a set of coins by tossing the coins adaptively. The goal is to minimize the number of tosses until we identify a coin whose posterior probability of being most biased is at least 1-\u03b4for a given \u03b4. Under a particular probabilistic model, we give an optimal algorithm, i.e., an algorithm that minimizes the expected number of future tosses. The problem is closely related to finding the best arm in the multi-armed bandit problem using adaptive strategies. Our algorithm employs an optimal adaptive strategy\u2014a strategy that performs the best possible action at each step after observing the outcomes of all previous coin tosses. Consequently, our algorithm is also optimal for any given starting history of outcomes. To our knowledge, this is the first algorithm that employs an optimal adaptive strategy under a Bayesian setting for this problem. Our proof of optimality employs mathematical tools from the area of Markov games.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/chandrasekaran14.pdf",
        "supp": "",
        "pdf_size": 316524,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11636298041949351826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Harvard University; University of California, Berkeley",
        "aff_domain": "SEAS.HARVARD.EDU;CS.BERKELEY.EDU",
        "email": "SEAS.HARVARD.EDU;CS.BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Harvard University;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.harvard.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Harvard;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a11eabb020",
        "title": "Follow the Leader with Dropout Perturbations",
        "site": "https://proceedings.mlr.press/v35/vanerven14.html",
        "author": "Tim Van Erven; Wojciech Kot\u0142owski; Manfred K. Warmuth",
        "abstract": "We consider online prediction with expert advice. Over the course of many trials, the goal of the learning algorithm is to achieve small additional loss (i.e. regret) compared to the loss of the best from a set of K experts. The two most popular algorithms are Hedge/Weighted Majority and Follow the Perturbed Leader (FPL). The latter algorithm first perturbs the loss of each expert by independent additive noise drawn from a fixed distribution, and then predicts with the expert of minimum perturbed loss (\u201cthe leader\u201d) where ties are broken uniformly at random. To achieve the optimal worst-case regret as a function of the loss L^* of the best expert in hindsight, the two types of algorithms need to tune their learning rate or noise magnitude, respectively, as a function of L^*. Instead of perturbing the losses of the experts with additive noise, we randomly set them to 0 or 1 before selecting the leader. We show that our perturbations are an instance of dropout \u2014 because experts may be interpreted as features \u2014 although for non-binary losses the dropout probability needs to be made dependent on the losses to get good regret bounds. We show that this simple, tuning-free version of the FPL algorithm achieves two feats: optimal worst-case O(\\sqrtL^* \\ln K + \\ln K) regret as a function of L^*, and optimal O(\\ln K) regret when the loss vectors are drawn i.i.d. from a fixed distribution and there is a gap between the expected loss of the best expert and all others. A number of recent algorithms from the Hedge family (AdaHedge and FlipFlop) also achieve this, but they employ sophisticated tuning regimes. The dropout perturbation of the losses of the experts result in different noise distributions for each expert (because they depend on the expert\u2019s total loss) and curiously enough no additional tuning is needed: the choice of dropout probability only affects the constants.",
        "bibtex": "@InProceedings{pmlr-v35-vanerven14,\n  title = \t {Follow the Leader with Dropout Perturbations},\n  author = \t {Van Erven, Tim and Kot\u0142owski, Wojciech and Warmuth, Manfred K.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {949--974},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/vanerven14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/vanerven14.html},\n  abstract = \t {We consider online prediction with expert advice. Over the course of many trials, the goal of the learning algorithm is to achieve small additional loss (i.e. regret) compared to the loss of the best from a set of K experts. The two most popular algorithms are Hedge/Weighted Majority and Follow the Perturbed Leader (FPL). The latter algorithm first perturbs the loss of each expert by independent additive noise drawn from a fixed distribution, and then predicts with the expert of minimum perturbed loss (\u201cthe leader\u201d) where ties are broken uniformly at random. To achieve the optimal worst-case regret as a function of the loss L^* of the best expert in hindsight, the two types of algorithms need to tune their learning rate or noise magnitude, respectively, as a function of L^*. Instead of perturbing the losses of the experts with additive noise, we randomly set them to 0 or 1 before selecting the leader. We show that our perturbations are an instance of dropout \u2014 because experts may be interpreted as features \u2014 although for non-binary losses the dropout probability needs to be made dependent on the losses to get good regret bounds. We show that this simple, tuning-free version of the FPL algorithm achieves two feats: optimal worst-case O(\\sqrtL^* \\ln K + \\ln K) regret as a function of L^*, and optimal O(\\ln K) regret when the loss vectors are drawn i.i.d. from a fixed distribution and there is a gap between the expected loss of the best expert and all others. A number of recent algorithms from the Hedge family (AdaHedge and FlipFlop) also achieve this, but they employ sophisticated tuning regimes. The dropout perturbation of the losses of the experts result in different noise distributions for each expert (because they depend on the expert\u2019s total loss) and curiously enough no additional tuning is needed: the choice of dropout probability only affects the constants.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/vanerven14.pdf",
        "supp": "",
        "pdf_size": 323203,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7007334539697683712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "D\u00b4epartement de Math \u00b4ematiques, Universit \u00b4e Paris-Sud, France; Institute of Computing Science, Pozna \u00b4n University of Technology, Poland; Department of Computer Science, University of California, Santa Cruz",
        "aff_domain": "TIMVANERVEN.NL;CS.PUT.POZNAN.PL;CSE.UCSC.EDU",
        "email": "TIMVANERVEN.NL;CS.PUT.POZNAN.PL;CSE.UCSC.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Universit u00e9 Paris-Sud;Pozna\u0144 University of Technology;University of California, Santa Cruz",
        "aff_unique_dep": "D u00e9partement de Math u00e9matiques;Institute of Computing Science;Department of Computer Science",
        "aff_unique_url": "https://www.universite-paris-sud.fr;https://www.put.poznan.pl/;https://www.ucsc.edu",
        "aff_unique_abbr": "UPS;PUT;UCSC",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Pozna\u0144;Santa Cruz",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "France;Poland;United States"
    },
    {
        "id": "a8151a4293",
        "title": "Higher-Order Regret Bounds with Switching Costs",
        "site": "https://proceedings.mlr.press/v35/gofer14.html",
        "author": "Eyal Gofer",
        "abstract": "This work examines online linear optimization with full information and switching costs (SCs) and focuses on regret bounds that depend on properties of the loss sequences. The SCs considered are bounded functions of a pair of decisions, and regret is augmented with the total SC. We show under general conditions that for any normed SC, \u03c3(\\mathbfx,\\mathbfx\u2019)=\\|\\mathbfx-\\mathbfx\u2019\\|, regret \\textitcannot be bounded given only a bound Q on the quadratic variation of losses. With an additional bound \u039bon the total length of losses, we prove O(\\sqrtQ+\u039b) regret for Regularized Follow the Leader (RFTL). Furthermore, an O(\\sqrtQ) bound holds for RFTL given a cost \\|\\mathbfx-\\mathbfx\u2019\\|^2. By generalizing the Shrinking Dartboard algorithm, we also show an expected regret bound for the best expert setting with any SC, given bounds on the total loss of the best expert and the quadratic variation of any expert. As SCs vanish, all our bounds depend purely on quadratic variation. We apply our results to pricing options in an arbitrage-free market with proportional transaction costs. In particular, we upper bound the price of \u201cat the money\u201d call options, assuming bounds on the quadratic variation of a stock price and the minimum of summed gains and summed losses.",
        "bibtex": "@InProceedings{pmlr-v35-gofer14,\n  title = \t {Higher-Order Regret Bounds with Switching Costs},\n  author = \t {Gofer, Eyal},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {210--243},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/gofer14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/gofer14.html},\n  abstract = \t {This work examines online linear optimization with full information and switching costs (SCs) and focuses on regret bounds that depend on properties of the loss sequences. The SCs considered are bounded functions of a pair of decisions, and regret is augmented with the total SC. We show under general conditions that for any normed SC, \u03c3(\\mathbfx,\\mathbfx\u2019)=\\|\\mathbfx-\\mathbfx\u2019\\|, regret \\textitcannot be bounded given only a bound Q on the quadratic variation of losses. With an additional bound \u039bon the total length of losses, we prove O(\\sqrtQ+\u039b) regret for Regularized Follow the Leader (RFTL). Furthermore, an O(\\sqrtQ) bound holds for RFTL given a cost \\|\\mathbfx-\\mathbfx\u2019\\|^2. By generalizing the Shrinking Dartboard algorithm, we also show an expected regret bound for the best expert setting with any SC, given bounds on the total loss of the best expert and the quadratic variation of any expert. As SCs vanish, all our bounds depend purely on quadratic variation. We apply our results to pricing options in an arbitrage-free market with proportional transaction costs. In particular, we upper bound the price of \u201cat the money\u201d call options, assuming bounds on the quadratic variation of a stock price and the minimum of summed gains and summed losses.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/gofer14.pdf",
        "supp": "",
        "pdf_size": 370872,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9867826531575589715&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c83bc6dce",
        "title": "Learning Coverage Functions and Private Release of Marginals",
        "site": "https://proceedings.mlr.press/v35/feldman14a.html",
        "author": "Vitaly Feldman; Pravesh Kothari",
        "abstract": "We study the problem of approximating and learning coverage functions. A function c: 2^[n] \u2192\\mathbfR^+ is a coverage function, if there exists a universe U with non-negative weights w(u) for each u \u2208U and subsets A_1, A_2, \\ldots, A_n of U such that c(S) = \\sum_u \u2208\\cup_i \u2208S A_i w(u). Alternatively, coverage functions can be described as non-negative linear combinations of monotone disjunctions. They are a natural subclass of submodular functions and arise in a number of applications. We give an algorithm that for any \u03b3,\u03b4>0, given random and uniform examples of an unknown coverage function c, finds a function h that approximates c within factor 1+\u03b3on all but \u03b4-fraction of the points in time poly(n,1/\u03b3,1/\u03b4). This is the first fully-polynomial algorithm for learning an interesting class of functions in the demanding PMAC model of Balcan and Harvey (2011). Our algorithms are based on several new structural properties of coverage functions. Using the results in (Feldman and Kothari, 2014), we also show that coverage functions are learnable agnostically with excess \\ell_1-error \u03b5over all product and symmetric distributions in time n^\\log(1/\u03b5). In contrast, we show that, without assumptions on the distribution, learning coverage functions is at least as hard as learning polynomial-size disjoint DNF formulas, a class of functions for which the best known algorithm runs in time 2^\\tildeO(n^1/3) (Klivans and Servedio, 2004). As an application of our learning results, we give simple differentially-private algorithms for releasing monotone conjunction counting queries with low \\em average error. In particular, for any k \u2264n, we obtain private release of k-way marginals with average error \\bar\u03b1 in time n^O(\\log(1/\\bar\u03b1)).",
        "bibtex": "@InProceedings{pmlr-v35-feldman14a,\n  title = \t {Learning Coverage Functions and Private Release of Marginals},\n  author = \t {Feldman, Vitaly and Kothari, Pravesh},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {679--702},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/feldman14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/feldman14a.html},\n  abstract = \t {We study the problem of approximating and learning coverage functions. A function c: 2^[n] \u2192\\mathbfR^+ is a coverage function, if there exists a universe U with non-negative weights w(u) for each u \u2208U and subsets A_1, A_2, \\ldots, A_n of U such that c(S) = \\sum_u \u2208\\cup_i \u2208S A_i w(u). Alternatively, coverage functions can be described as non-negative linear combinations of monotone disjunctions. They are a natural subclass of submodular functions and arise in a number of applications. We give an algorithm that for any \u03b3,\u03b4>0, given random and uniform examples of an unknown coverage function c, finds a function h that approximates c within factor 1+\u03b3on all but \u03b4-fraction of the points in time poly(n,1/\u03b3,1/\u03b4). This is the first fully-polynomial algorithm for learning an interesting class of functions in the demanding PMAC model of Balcan and Harvey (2011). Our algorithms are based on several new structural properties of coverage functions. Using the results in (Feldman and Kothari, 2014), we also show that coverage functions are learnable agnostically with excess \\ell_1-error \u03b5over all product and symmetric distributions in time n^\\log(1/\u03b5). In contrast, we show that, without assumptions on the distribution, learning coverage functions is at least as hard as learning polynomial-size disjoint DNF formulas, a class of functions for which the best known algorithm runs in time 2^\\tildeO(n^1/3) (Klivans and Servedio, 2004). As an application of our learning results, we give simple differentially-private algorithms for releasing monotone conjunction counting queries with low \\em average error. In particular, for any k \u2264n, we obtain private release of k-way marginals with average error \\bar\u03b1 in time n^O(\\log(1/\\bar\u03b1)). }\n}",
        "pdf": "http://proceedings.mlr.press/v35/feldman14a.pdf",
        "supp": "",
        "pdf_size": 485691,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14535375165183262997&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "IBM Research - Almaden; University of Texas at Austin*",
        "aff_domain": "POST.HARVARD.EDU;CS.UTEXAS.EDU",
        "email": "POST.HARVARD.EDU;CS.UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "IBM;University of Texas at Austin",
        "aff_unique_dep": "IBM Research;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.utexas.edu",
        "aff_unique_abbr": "IBM;UT Austin",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Almaden;Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "31a918419b",
        "title": "Learning Mixtures of Discrete Product Distributions using Spectral Decompositions",
        "site": "https://proceedings.mlr.press/v35/jain14.html",
        "author": "Prateek Jain; Sewoong Oh",
        "abstract": "We study the problem of learning a distribution from samples, when the underlying distribution is a mixture of product distributions over discrete domains. This problem is motivated by several practical applications such as  crowdsourcing, recommendation systems, and learning Boolean functions. The existing solutions either heavily rely on the fact that the number of mixtures is finite or have  sample/time complexity that is exponential in the number of mixtures. In this paper, we introduce a polynomial time/sample complexity  method for learning a mixture of r discrete product distributions over {1, 2, \u2026, \\ell}^n, for  general \\ell and r. We show that our approach is consistent and further provide finite sample guarantees. We use recently developed techniques from tensor decompositions for moment matching. A crucial step  in these approaches is to construct certain  tensors  with low-rank spectral decompositions. These tensors are typically estimated from the sample moments. The main challenge in learning mixtures of discrete product distributions is that  the corresponding low-rank tensors cannot be obtained directly from the sample moments. Instead, we need to estimate a low-rank matrix using only off-diagonal entries, and estimate a tensor using a few linear measurements. We give an alternating minimization based method to estimate the low-rank matrix, and  formulate the tensor estimation problem as a least-squares problem.",
        "bibtex": "@InProceedings{pmlr-v35-jain14,\n  title = \t {Learning Mixtures of Discrete Product Distributions using Spectral Decompositions},\n  author = \t {Jain, Prateek and Oh, Sewoong},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {824--856},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/jain14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/jain14.html},\n  abstract = \t {We study the problem of learning a distribution from samples, when the underlying distribution is a mixture of product distributions over discrete domains. This problem is motivated by several practical applications such as  crowdsourcing, recommendation systems, and learning Boolean functions. The existing solutions either heavily rely on the fact that the number of mixtures is finite or have  sample/time complexity that is exponential in the number of mixtures. In this paper, we introduce a polynomial time/sample complexity  method for learning a mixture of r discrete product distributions over {1, 2, \u2026, \\ell}^n, for  general \\ell and r. We show that our approach is consistent and further provide finite sample guarantees. We use recently developed techniques from tensor decompositions for moment matching. A crucial step  in these approaches is to construct certain  tensors  with low-rank spectral decompositions. These tensors are typically estimated from the sample moments. The main challenge in learning mixtures of discrete product distributions is that  the corresponding low-rank tensors cannot be obtained directly from the sample moments. Instead, we need to estimate a low-rank matrix using only off-diagonal entries, and estimate a tensor using a few linear measurements. We give an alternating minimization based method to estimate the low-rank matrix, and  formulate the tensor estimation problem as a least-squares problem. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/jain14.pdf",
        "supp": "",
        "pdf_size": 447510,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12526047212273964398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "aff": "Microsoft Research India, Bangalore; Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign",
        "aff_domain": "MICROSOFT.COM;ILLINOIS.EDU",
        "email": "MICROSOFT.COM;ILLINOIS.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Microsoft;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Microsoft Research India;Department of Industrial and Enterprise Systems Engineering",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-india;https://illinois.edu",
        "aff_unique_abbr": "MSRI;UIUC",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Bangalore;Urbana-Champaign",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "c1bd5bfa49",
        "title": "Learning Sparsely Used Overcomplete Dictionaries",
        "site": "https://proceedings.mlr.press/v35/agarwal14a.html",
        "author": "Alekh Agarwal; Animashree Anandkumar; Prateek Jain; Praneeth Netrapalli; Rashish Tandon",
        "abstract": "We consider the problem of learning sparsely used overcomplete dictionaries, where each observation is  a sparse combination of elements from an unknown overcomplete dictionary. We establish exact recovery when the dictionary elements are mutually incoherent. Our method consists of a clustering-based initialization step, which provides an approximate estimate   of the true dictionary with guaranteed accuracy. This estimate is then refined via an iterative algorithm with the following alternating steps: 1) estimation of the dictionary coefficients for each observation through \\ell_1 minimization, given the dictionary estimate, and 2) estimation of the dictionary elements through least squares, given the coefficient estimates. We establish that, under a set of sufficient conditions, our method converges at a linear rate to the true dictionary as well as the true coefficients for each observation.",
        "bibtex": "@InProceedings{pmlr-v35-agarwal14a,\n  title = \t {Learning Sparsely Used Overcomplete Dictionaries},\n  author = \t {Agarwal, Alekh and Anandkumar, Animashree and Jain, Prateek and Netrapalli, Praneeth and Tandon, Rashish},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {123--137},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/agarwal14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/agarwal14a.html},\n  abstract = \t {We consider the problem of learning sparsely used overcomplete dictionaries, where each observation is  a sparse combination of elements from an unknown overcomplete dictionary. We establish exact recovery when the dictionary elements are mutually incoherent. Our method consists of a clustering-based initialization step, which provides an approximate estimate   of the true dictionary with guaranteed accuracy. This estimate is then refined via an iterative algorithm with the following alternating steps: 1) estimation of the dictionary coefficients for each observation through \\ell_1 minimization, given the dictionary estimate, and 2) estimation of the dictionary elements through least squares, given the coefficient estimates. We establish that, under a set of sufficient conditions, our method converges at a linear rate to the true dictionary as well as the true coefficients for each observation.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/agarwal14a.pdf",
        "supp": "",
        "pdf_size": 211414,
        "gs_citation": 125,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8347525336525722974&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Microsoft Research, New York NY USA; Dept of EECS, UCIrvine, Irvine, CA USA; Microsoft Research, Bangalore, India; Dept of ECE, UT Austin, Austin, TX USA; Dept of CS, UTAustin, Austin, TX USA",
        "aff_domain": "MICROSOFT.COM;UCI.EDU;MICROSOFT.COM;UTEXAS.EDU;CS.UTEXAS.EDU",
        "email": "MICROSOFT.COM;UCI.EDU;MICROSOFT.COM;UTEXAS.EDU;CS.UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Microsoft;University of California, Irvine;University of Texas at Austin",
        "aff_unique_dep": "Microsoft Research;Department of Electrical Engineering and Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.uci.edu;https://www.utexas.edu",
        "aff_unique_abbr": "MSR;UCI;UT Austin",
        "aff_campus_unique_index": "0;1;2;3;3",
        "aff_campus_unique": "New York;Irvine;Bangalore;Austin",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "18f8e75c72",
        "title": "Learning without concentration",
        "site": "https://proceedings.mlr.press/v35/mendelson14.html",
        "author": "Shahar Mendelson",
        "abstract": "We obtain sharp bounds on the convergence rate of Empirical Risk Minimization performed in a convex class and with respect to the squared loss, without any boundedness assumptions on class members or on the target. Rather than resorting to a concentration-based argument, the method relies on a \u2018small-ball\u2019 assumption and thus holds for heavy-tailed sampling and heavy-tailed targets. Moreover, the resulting estimates scale correctly with the \u2018noise level\u2019 of the problem. When applied to the classical, bounded scenario, the method always improves the known estimates.",
        "bibtex": "@InProceedings{pmlr-v35-mendelson14,\n  title = \t {Learning without concentration},\n  author = \t {Mendelson, Shahar},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {25--39},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/mendelson14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/mendelson14.html},\n  abstract = \t {We obtain sharp bounds on the convergence rate of Empirical Risk Minimization performed in a convex class and with respect to the squared loss, without any boundedness assumptions on class members or on the target. Rather than resorting to a concentration-based argument, the method relies on a \u2018small-ball\u2019 assumption and thus holds for heavy-tailed sampling and heavy-tailed targets. Moreover, the resulting estimates scale correctly with the \u2018noise level\u2019 of the problem. When applied to the classical, bounded scenario, the method always improves the known estimates. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/mendelson14.pdf",
        "supp": "",
        "pdf_size": 125077,
        "gs_citation": 384,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2909341792559719555&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Department of Mathematics, Technion, I.I.T., Israel",
        "aff_domain": "TX.TECHNION.AC.IL",
        "email": "TX.TECHNION.AC.IL",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "fcd9e8f9c6",
        "title": "Lipschitz Bandits: Regret Lower Bound and Optimal Algorithms",
        "site": "https://proceedings.mlr.press/v35/magureanu14.html",
        "author": "Stefan Magureanu; Richard Combes; Alexandre Proutiere",
        "abstract": "We consider stochastic multi-armed bandit problems where the expected reward is a Lipschitz function of the arm, and where the set of arms is either discrete or continuous. For discrete Lipschitz bandits, we derive asymptotic problem specific lower bounds for the regret satisfied by any algorithm, and propose OSLB and CKL-UCB, two algorithms that efficiently exploit the Lipschitz structure of the problem. In fact, we prove  that OSLB is asymptotically optimal, as its asymptotic regret matches the lower bound. The regret analysis of our algorithms relies on a new concentration inequality for weighted sums of KL divergences between the empirical distributions of rewards and their true distributions. For continuous Lipschitz bandits, we propose to first discretize the action space, and then apply OSLB or CKL-UCB, algorithms that provably exploit the structure efficiently. This approach is shown, through numerical experiments, to significantly outperform existing algorithms that directly deal with the continuous set of arms. Finally the results and algorithms are extended to contextual bandits with similarities.",
        "bibtex": "@InProceedings{pmlr-v35-magureanu14,\n  title = \t {Lipschitz Bandits: Regret Lower Bound and Optimal Algorithms},\n  author = \t {Magureanu, Stefan and Combes, Richard and Proutiere, Alexandre},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {975--999},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/magureanu14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/magureanu14.html},\n  abstract = \t {We consider stochastic multi-armed bandit problems where the expected reward is a Lipschitz function of the arm, and where the set of arms is either discrete or continuous. For discrete Lipschitz bandits, we derive asymptotic problem specific lower bounds for the regret satisfied by any algorithm, and propose OSLB and CKL-UCB, two algorithms that efficiently exploit the Lipschitz structure of the problem. In fact, we prove  that OSLB is asymptotically optimal, as its asymptotic regret matches the lower bound. The regret analysis of our algorithms relies on a new concentration inequality for weighted sums of KL divergences between the empirical distributions of rewards and their true distributions. For continuous Lipschitz bandits, we propose to first discretize the action space, and then apply OSLB or CKL-UCB, algorithms that provably exploit the structure efficiently. This approach is shown, through numerical experiments, to significantly outperform existing algorithms that directly deal with the continuous set of arms. Finally the results and algorithms are extended to contextual bandits with similarities.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/magureanu14.pdf",
        "supp": "",
        "pdf_size": 570383,
        "gs_citation": 199,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17744772705778311761&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "KTH, The Royal Institute of Technology, EE School / ACL, Osquldasv. 10, Stockholm 100-44, Sweden; Supelec, Plateau de Moulon, 3 rue Joliot-Curie 91192 Gif-sur-Yvette Cedex, France; KTH, The Royal Institute of Technology, Stockholm, Sweden + INRIA, Paris, France",
        "aff_domain": "KTH.SE;SUPELEC.FR;KTH.SE",
        "email": "KTH.SE;SUPELEC.FR;KTH.SE",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3",
        "aff_unique_norm": "KTH - The Royal Institute of Technology;SUPELEC;Royal Institute of Technology;INRIA",
        "aff_unique_dep": "EE School / ACL;;;",
        "aff_unique_url": "https://www.kth.se;https://www.supelec.fr;https://www.kth.se;https://www.inria.fr",
        "aff_unique_abbr": "KTH;;KTH;INRIA",
        "aff_campus_unique_index": "0;1;0+2",
        "aff_campus_unique": "Stockholm;Gif-sur-Yvette;Paris",
        "aff_country_unique_index": "0;1;0+1",
        "aff_country_unique": "Sweden;France"
    },
    {
        "id": "657b63ac9c",
        "title": "Localized Complexities for Transductive Learning",
        "site": "https://proceedings.mlr.press/v35/tolstikhin14.html",
        "author": "Ilya Tolstikhin; Gilles Blanchard; Marius Kloft",
        "abstract": "We show two novel concentration inequalities for suprema of empirical processes when sampling without replacement, which both take the variance of the functions into account. While these inequalities may potentially have broad applications in learning theory in general, we exemplify their significance by studying the transductive setting of learning theory. For which we provide the first excess risk bounds based on the localized complexity of the hypothesis class, which can yield fast rates of convergence also in the transductive learning setting. We give a preliminary analysis of the localized complexities for the prominent case of kernel classes.",
        "bibtex": "@InProceedings{pmlr-v35-tolstikhin14,\n  title = \t {Localized Complexities for Transductive Learning},\n  author = \t {Tolstikhin, Ilya and Blanchard, Gilles and Kloft, Marius},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {857--884},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/tolstikhin14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/tolstikhin14.html},\n  abstract = \t {We show two novel concentration inequalities for suprema of empirical processes when sampling without replacement, which both take the variance of the functions into account. While these inequalities may potentially have broad applications in learning theory in general, we exemplify their significance by studying the transductive setting of learning theory. For which we provide the first excess risk bounds based on the localized complexity of the hypothesis class, which can yield fast rates of convergence also in the transductive learning setting. We give a preliminary analysis of the localized complexities for the prominent case of kernel classes.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/tolstikhin14.pdf",
        "supp": "",
        "pdf_size": 377863,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3876748308329494472&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Computing Centre of Russian Academy of Sciences, Russia; Department of Mathematics, University of Potsdam, Germany; Department of Computer Science, Humboldt University of Berlin, Germany + Courant Institute of Mathematical Sciences and Memorial Sloan-Kettering Cancer Center, New York, NY, USA",
        "aff_domain": "GMAIL.COM;MATH.UNI-POTSDAM.DE;CS.NYU.EDU",
        "email": "GMAIL.COM;MATH.UNI-POTSDAM.DE;CS.NYU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3",
        "aff_unique_norm": "Russian Academy of Sciences;University of Potsdam;Humboldt University of Berlin;Courant Institute of Mathematical Sciences",
        "aff_unique_dep": "Computing Centre;Department of Mathematics;Department of Computer Science;Mathematical Sciences",
        "aff_unique_url": "http://www.ras.ru;https://www.uni-potsdam.de;https://www.hu-berlin.de;https://courant.nyu.edu",
        "aff_unique_abbr": ";;HU Berlin;Courant",
        "aff_campus_unique_index": "1+2",
        "aff_campus_unique": ";Berlin;New York",
        "aff_country_unique_index": "0;1;1+2",
        "aff_country_unique": "Russian Federation;Germany;United States"
    },
    {
        "id": "ca90f28a74",
        "title": "Logistic Regression: Tight Bounds for Stochastic and Online Optimization",
        "site": "https://proceedings.mlr.press/v35/hazan14a.html",
        "author": "Elad Hazan; Tomer Koren; Kfir Y. Levy",
        "abstract": "The logistic loss function is often advocated in machine learning and statistics as a smooth and strictly convex surrogate for the 0-1 loss. In this paper we investigate the question of whether these smoothness and convexity properties make the logistic loss preferable to other widely considered options such as the hinge loss. We show that in contrast to known asymptotic bounds, as long as the number of prediction/optimization iterations is sub exponential, the logistic loss provides no improvement over a generic non-smooth loss function such as the hinge loss. In particular we show that the convergence rate of stochastic logistic optimization is bounded from below by a polynomial in the diameter of the decision set and the number of prediction iterations, and provide a matching tight upper bound. This resolves the COLT open problem of McMahan and Streeter (2012).",
        "bibtex": "@InProceedings{pmlr-v35-hazan14a,\n  title = \t {Logistic Regression: Tight Bounds for Stochastic and Online Optimization},\n  author = \t {Hazan, Elad and Koren, Tomer and Levy, Kfir Y.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {197--209},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/hazan14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/hazan14a.html},\n  abstract = \t {The logistic loss function is often advocated in machine learning and statistics as a smooth and strictly convex surrogate for the 0-1 loss. In this paper we investigate the question of whether these smoothness and convexity properties make the logistic loss preferable to other widely considered options such as the hinge loss. We show that in contrast to known asymptotic bounds, as long as the number of prediction/optimization iterations is sub exponential, the logistic loss provides no improvement over a generic non-smooth loss function such as the hinge loss. In particular we show that the convergence rate of stochastic logistic optimization is bounded from below by a polynomial in the diameter of the decision set and the number of prediction iterations, and provide a matching tight upper bound. This resolves the COLT open problem of McMahan and Streeter (2012).}\n}",
        "pdf": "http://proceedings.mlr.press/v35/hazan14a.pdf",
        "supp": "",
        "pdf_size": 299515,
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15427856168768614830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Technion\u2014Israel Institute of Technology; Technion\u2014Israel Institute of Technology; Technion\u2014Israel Institute of Technology",
        "aff_domain": "ie.technion.ac.il;technion.ac.il;tx.technion.ac.il",
        "email": "ie.technion.ac.il;technion.ac.il;tx.technion.ac.il",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technion\u2014Israel Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "19ef5d5e07",
        "title": "Lower Bounds on the Performance of Polynomial-time Algorithms for Sparse Linear Regression",
        "site": "https://proceedings.mlr.press/v35/zhang14.html",
        "author": "Yuchen Zhang; Martin J. Wainwright; Michael I. Jordan",
        "abstract": "Under a standard assumption in complexity theory (NP not in P/poly), we demonstrate a gap between the minimax prediction risk for sparse linear regression that can be achieved by polynomial-time algorithms, and that achieved by optimal algorithms.  In particular, when the design matrix is ill-conditioned, the minimax prediction loss achievable by polynomial-time algorithms can be substantially greater than that of an optimal algorithm.  This result is the first known gap between polynomial and optimal algorithms for sparse linear regression, and does not depend on conjectures in average-case complexity.",
        "bibtex": "@InProceedings{pmlr-v35-zhang14,\n  title = \t {Lower Bounds on the Performance of Polynomial-time Algorithms for Sparse Linear Regression},\n  author = \t {Zhang, Yuchen and Wainwright, Martin J. and Jordan, Michael I.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {921--948},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/zhang14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/zhang14.html},\n  abstract = \t {Under a standard assumption in complexity theory (NP not in P/poly), we demonstrate a gap between the minimax prediction risk for sparse linear regression that can be achieved by polynomial-time algorithms, and that achieved by optimal algorithms.  In particular, when the design matrix is ill-conditioned, the minimax prediction loss achievable by polynomial-time algorithms can be substantially greater than that of an optimal algorithm.  This result is the first known gap between polynomial and optimal algorithms for sparse linear regression, and does not depend on conjectures in average-case complexity.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/zhang14.pdf",
        "supp": "",
        "pdf_size": 439368,
        "gs_citation": 153,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2193731599901976308&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of EECS; Department of EECS + Department of Statistics; Department of EECS + Department of Statistics",
        "aff_domain": "BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU",
        "email": "BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0+1",
        "aff_unique_norm": "University of California, Berkeley;University Affiliation Not Specified",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;Department of Statistics",
        "aff_unique_url": "https://www.berkeley.edu;",
        "aff_unique_abbr": "UC Berkeley;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "f5d8676960",
        "title": "Most Correlated Arms Identification",
        "site": "https://proceedings.mlr.press/v35/liu14.html",
        "author": "Che-Yu Liu; S\u00e9bastien Bubeck",
        "abstract": "We study the problem of finding the most mutually correlated arms among many arms. We show that adaptive arms sampling strategies can have significant advantages over the non-adaptive uniform sampling strategy. Our proposed algorithms rely on a novel correlation estimator. The use of this accurate estimator allows us to get improved results for a wide range of problem instances.",
        "bibtex": "@InProceedings{pmlr-v35-liu14,\n  title = \t {Most Correlated Arms Identification},\n  author = \t {Liu, Che-Yu and Bubeck, S\u00e9bastien},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {623--637},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/liu14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/liu14.html},\n  abstract = \t {We study the problem of finding the most mutually correlated arms among many arms. We show that adaptive arms sampling strategies can have significant advantages over the non-adaptive uniform sampling strategy. Our proposed algorithms rely on a novel correlation estimator. The use of this accurate estimator allows us to get improved results for a wide range of problem instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/liu14.pdf",
        "supp": "",
        "pdf_size": 294366,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9156840795804339070&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Operations Research and Financial Engineering, Princeton University; Department of Operations Research and Financial Engineering, Princeton University",
        "aff_domain": "PRINCETON;PRINCETON",
        "email": "PRINCETON;PRINCETON",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Operations Research and Financial Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3238959c6e",
        "title": "Multiarmed Bandits With Limited Expert Advice",
        "site": "https://proceedings.mlr.press/v35/kale14a.html",
        "author": "Satyen Kale",
        "abstract": "We consider the problem of minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts\u2019 advice in each round, which has a regret bound of \\tildeO\\left(\\sqrt\\frac\\min{K, M} NM T\\right) after T rounds. We also prove that any algorithm for this problem must have expected regret at least \\tilde\u03a9\\left(\\sqrt\\frac\\min{K, M} NMT\\right), thus showing that our upper bound is nearly tight. This solves the COLT 2013 open problem of Seldin et al. (2013).",
        "bibtex": "@InProceedings{pmlr-v35-kale14a,\n  title = \t {Multiarmed Bandits With Limited Expert Advice},\n  author = \t {Kale, Satyen},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {107--122},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kale14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kale14a.html},\n  abstract = \t {We consider the problem of minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts\u2019 advice in each round, which has a regret bound of \\tildeO\\left(\\sqrt\\frac\\min{K, M} NM T\\right) after T rounds. We also prove that any algorithm for this problem must have expected regret at least \\tilde\u03a9\\left(\\sqrt\\frac\\min{K, M} NMT\\right), thus showing that our upper bound is nearly tight. This solves the COLT 2013 open problem of Seldin et al. (2013).}\n}",
        "pdf": "http://proceedings.mlr.press/v35/kale14a.pdf",
        "supp": "",
        "pdf_size": 307944,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1038452966128841866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Yahoo! Labs New York + IBM T. J. Watson Research Center",
        "aff_domain": "YAHOO-INC.COM",
        "email": "YAHOO-INC.COM",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "Yahoo!;IBM",
        "aff_unique_dep": "Yahoo! Labs;IBM",
        "aff_unique_url": "https://yahoo.com;https://www.ibm.com/research/watson",
        "aff_unique_abbr": "Yahoo!;IBM",
        "aff_campus_unique_index": "0+1",
        "aff_campus_unique": "New York;T. J. Watson",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ad34e87ddb",
        "title": "Near-Optimal Herding",
        "site": "https://proceedings.mlr.press/v35/harvey14.html",
        "author": "Nick Harvey; Samira Samadi",
        "abstract": "Herding is an algorithm of recent interest in the machine learning community, motivated by inference in Markov random fields. It solves the following sampling problem: given a set \\mathcalX \u2282\\mathbbR^d with mean \u03bc, construct an infinite sequence of points from \\mathcalX such that, for every t \u22651, the mean of the first t points in that sequence lies within Euclidean distance O(1/t) of \u03bc. The classic Perceptron boundedness theorem implies that such a result actually holds for a wide class of algorithms, although the factors suppressed by the O(1/t) notation are exponential in d. Thus, to establish a non-trivial result for the sampling problem, one must carefully analyze the factors suppressed by the O(1/t) error bound. This paper studies the best error that can be achieved for the sampling problem. Known analysis of the Herding algorithm give an error bound that depends on geometric properties of \\mathcalX but, even under favorable conditions, this bound depends linearly on d. We present a new polynomial-time algorithm that solves the sampling problem with error O\\left(\\sqrtd \\log^2.5|\\mathcalX| / t \\right) assuming that \\mathcalX is finite. Our algorithm is based on recent algorithmic results in \\textitdiscrepancy theory. We also show that any algorithm for the sampling problem must have error \u03a9( \\sqrtd / t ). This implies that our algorithm is optimal to within logarithmic factors.",
        "bibtex": "@InProceedings{pmlr-v35-harvey14,\n  title = \t {Near-Optimal Herding},\n  author = \t {Harvey, Nick and Samadi, Samira},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1165--1182},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/harvey14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/harvey14.html},\n  abstract = \t {Herding is an algorithm of recent interest in the machine learning community, motivated by inference in Markov random fields. It solves the following sampling problem: given a set \\mathcalX \u2282\\mathbbR^d with mean \u03bc, construct an infinite sequence of points from \\mathcalX such that, for every t \u22651, the mean of the first t points in that sequence lies within Euclidean distance O(1/t) of \u03bc. The classic Perceptron boundedness theorem implies that such a result actually holds for a wide class of algorithms, although the factors suppressed by the O(1/t) notation are exponential in d. Thus, to establish a non-trivial result for the sampling problem, one must carefully analyze the factors suppressed by the O(1/t) error bound. This paper studies the best error that can be achieved for the sampling problem. Known analysis of the Herding algorithm give an error bound that depends on geometric properties of \\mathcalX but, even under favorable conditions, this bound depends linearly on d. We present a new polynomial-time algorithm that solves the sampling problem with error O\\left(\\sqrtd \\log^2.5|\\mathcalX| / t \\right) assuming that \\mathcalX is finite. Our algorithm is based on recent algorithmic results in \\textitdiscrepancy theory. We also show that any algorithm for the sampling problem must have error \u03a9( \\sqrtd / t ). This implies that our algorithm is optimal to within logarithmic factors. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/harvey14.pdf",
        "supp": "",
        "pdf_size": 289703,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15815705054432990606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of British Columbia, Department of Computer Science; University of British Columbia, Department of Computer Science",
        "aff_domain": "CS.UBC.CA;CS.UBC.CA",
        "email": "CS.UBC.CA;CS.UBC.CA",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Vancouver",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "29d9454be4",
        "title": "New Algorithms for Learning Incoherent and Overcomplete Dictionaries",
        "site": "https://proceedings.mlr.press/v35/arora14.html",
        "author": "Sanjeev Arora; Rong Ge; Ankur Moitra",
        "abstract": "In \\em sparse recovery we are given a matrix A \u2208\\mathbbR^n\\times m (\u201cthe dictionary\u201d) and a vector of the form A X where X is \\em sparse, and the goal is to recover X. This is a central notion in signal processing, statistics and machine learning. But in applications such as \\em sparse coding, edge detection, compression and super resolution, the dictionary A is unknown and has to be learned from random examples of the form Y = AX where X is drawn from an appropriate distribution \u2014 this is the \\em dictionary learning problem. In most settings, A is \\em overcomplete: it has more columns than rows. This paper presents a polynomial-time algorithm for learning overcomplete dictionaries; the only previously known algorithm with provable guarantees is the recent work of Spielman et al. (2012) who who gave an algorithm for the undercomplete case, which is rarely the case in applications. Our algorithm applies to \\em incoherent dictionaries which have been a central object of study since they were introduced in seminal work of Donoho and Huo (1999). In particular, a dictionary is \u03bc-incoherent if each pair of columns has inner product at most \u03bc/ \\sqrtn. The algorithm makes natural stochastic assumptions about the unknown sparse vector X, which can contain k \u2264c \\min(\\sqrtn/\u03bc\\log n, m^1/2 - \u03b7) non-zero entries (for any \u03b7> 0). This is close to the best k allowable by the best sparse recovery algorithms  \\em even if one knows the dictionary A exactly. Moreover, both the running time and sample complexity depend on \\log 1/\u03b5, where \u03b5is the target accuracy, and so our algorithms converge very quickly to the true dictionary. Our algorithm can also tolerate substantial amounts of noise provided it is incoherent with respect to the dictionary (e.g., Gaussian). In the noisy setting, our running time and sample complexity depend polynomially on 1/\u03b5, and this is necessary.",
        "bibtex": "@InProceedings{pmlr-v35-arora14,\n  title = \t {New Algorithms for Learning Incoherent and Overcomplete Dictionaries },\n  author = \t {Arora, Sanjeev and Ge, Rong and Moitra, Ankur},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {779--806},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/arora14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/arora14.html},\n  abstract = \t {In \\em sparse recovery we are given a matrix A \u2208\\mathbbR^n\\times m (\u201cthe dictionary\u201d) and a vector of the form A X where X is \\em sparse, and the goal is to recover X. This is a central notion in signal processing, statistics and machine learning. But in applications such as \\em sparse coding, edge detection, compression and super resolution, the dictionary A is unknown and has to be learned from random examples of the form Y = AX where X is drawn from an appropriate distribution \u2014 this is the \\em dictionary learning problem. In most settings, A is \\em overcomplete: it has more columns than rows. This paper presents a polynomial-time algorithm for learning overcomplete dictionaries; the only previously known algorithm with provable guarantees is the recent work of Spielman et al. (2012) who who gave an algorithm for the undercomplete case, which is rarely the case in applications. Our algorithm applies to \\em incoherent dictionaries which have been a central object of study since they were introduced in seminal work of Donoho and Huo (1999). In particular, a dictionary is \u03bc-incoherent if each pair of columns has inner product at most \u03bc/ \\sqrtn. The algorithm makes natural stochastic assumptions about the unknown sparse vector X, which can contain k \u2264c \\min(\\sqrtn/\u03bc\\log n, m^1/2 - \u03b7) non-zero entries (for any \u03b7> 0). This is close to the best k allowable by the best sparse recovery algorithms  \\em even if one knows the dictionary A exactly. Moreover, both the running time and sample complexity depend on \\log 1/\u03b5, where \u03b5is the target accuracy, and so our algorithms converge very quickly to the true dictionary. Our algorithm can also tolerate substantial amounts of noise provided it is incoherent with respect to the dictionary (e.g., Gaussian). In the noisy setting, our running time and sample complexity depend polynomially on 1/\u03b5, and this is necessary. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/arora14.pdf",
        "supp": "",
        "pdf_size": 468188,
        "gs_citation": 237,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2407699418094448960&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Princeton University, Computer Science Department and Center for Computational Intractability; Microsoft Research, New England; Massachusetts Institute of Technology, Department of Mathematics and CSAIL",
        "aff_domain": "CS.PRINCETON.EDU;MICROSOFT.COM;MIT.EDU",
        "email": "CS.PRINCETON.EDU;MICROSOFT.COM;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Microsoft;Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science Department;Microsoft Research;Department of Mathematics and CSAIL",
        "aff_unique_url": "https://www.princeton.edu;https://www.microsoft.com/en-us/research/group/newengland;https://web.mit.edu",
        "aff_unique_abbr": "Princeton;MSR;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New England",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7458bf7165",
        "title": "On the Complexity of A/B Testing",
        "site": "https://proceedings.mlr.press/v35/kaufmann14.html",
        "author": "Emilie Kaufmann; Olivier Capp\u00e9; Aur\u00e9lien Garivier",
        "abstract": "A/B testing refers to the task of determining the best option among two alternatives that yield random outcomes. We provide distribution-dependent lower bounds for the performance of A/B testing that improve over the results currently available both in the fixed-confidence (or \u03b4-PAC) and fixed-budget settings. When the distribution of the outcomes are Gaussian, we prove that the complexity of the fixed-confidence and fixed-budget settings are equivalent, and that uniform sampling of both alternatives is optimal only in the case of equal variances. In the common variance case, we also provide a stopping rule that terminates faster than existing fixed-confidence algorithms. In the case of Bernoulli distributions, we show that the complexity of fixed-budget setting is smaller than that of fixed-confidence setting and that uniform sampling of both alternatives\u2014though not optimal\u2014is advisable in practice when combined with an appropriate stopping criterion.",
        "bibtex": "@InProceedings{pmlr-v35-kaufmann14,\n  title = \t {On the Complexity of A/B Testing},\n  author = \t {Kaufmann, Emilie and Capp\u00e9, Olivier and Garivier, Aur\u00e9lien},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {461--481},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kaufmann14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kaufmann14.html},\n  abstract = \t {A/B testing refers to the task of determining the best option among two alternatives that yield random outcomes. We provide distribution-dependent lower bounds for the performance of A/B testing that improve over the results currently available both in the fixed-confidence (or \u03b4-PAC) and fixed-budget settings. When the distribution of the outcomes are Gaussian, we prove that the complexity of the fixed-confidence and fixed-budget settings are equivalent, and that uniform sampling of both alternatives is optimal only in the case of equal variances. In the common variance case, we also provide a stopping rule that terminates faster than existing fixed-confidence algorithms. In the case of Bernoulli distributions, we show that the complexity of fixed-budget setting is smaller than that of fixed-confidence setting and that uniform sampling of both alternatives\u2014though not optimal\u2014is advisable in practice when combined with an appropriate stopping criterion.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/kaufmann14.pdf",
        "supp": "",
        "pdf_size": 411882,
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1825638252972549185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "LTCI, T\u00e9l\u00e9com ParisTech & CNRS; LTCI, T\u00e9l\u00e9com ParisTech & CNRS; Institut de Math\u00e9matiques de Toulouse, Universit\u00e9 Paul Sabatier",
        "aff_domain": "TELECOM-PARISTECH.FR;TELECOM-PARISTECH.FR;MATH.UNIV-TOULOUSE.FR",
        "email": "TELECOM-PARISTECH.FR;TELECOM-PARISTECH.FR;MATH.UNIV-TOULOUSE.FR",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "T\u00e9l\u00e9com ParisTech;Universit\u00e9 Paul Sabatier",
        "aff_unique_dep": "LTCI;Institut de Math\u00e9matiques de Toulouse",
        "aff_unique_url": "https://www.telecom-paris.fr;https://www.univ-toulouse.fr",
        "aff_unique_abbr": "T\u00e9l\u00e9com ParisTech;UPS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "185ebf69a6",
        "title": "On the Consistency of Output Code Based Learning Algorithms for Multiclass Learning Problems",
        "site": "https://proceedings.mlr.press/v35/ramaswamy14.html",
        "author": "Harish G. Ramaswamy; Balaji Srinivasan Babu; Shivani Agarwal; Robert C. Williamson",
        "abstract": "A popular approach to solving multiclass learning problems is to reduce them to a set of binary classification problems through some output code matrix: the widely used one-vs-all and all-pairs methods, and the error-correcting output code methods of Dietterich and Bakiri (1995), can all be viewed as special cases of this approach. In this paper, we consider the question of statistical consistency of such methods. We focus on settings where the binary problems are solved by minimizing a binary surrogate loss, and derive general conditions on the binary surrogate loss under which the one-vs-all and all-pairs code matrices yield consistent algorithms with respect to the multiclass 0-1 loss. We then consider general multiclass learning problems defined by a general multiclass loss, and derive conditions on the output code matrix and binary surrogates under which the resulting algorithm is consistent with respect to the target multiclass loss. We also consider \\emphprobabilistic code matrices, where one reduces a multiclass problem to a set of \\emphclass probability labeled binary problems, and show that these can yield benefits in the sense of requiring a smaller number of binary problems to achieve overall consistency. Our analysis makes interesting connections with the theory of proper composite losses (Buja et al., 2005; Reid and Williamson, 2010); these play a role in constructing the right \u2018decoding\u2019 for converting the predictions on the binary problems to the final multiclass prediction. To our knowledge, this is the first work that comprehensively studies consistency properties of output code based methods for multiclass learning.",
        "bibtex": "@InProceedings{pmlr-v35-ramaswamy14,\n  title = \t {On the Consistency of Output Code Based Learning Algorithms for Multiclass Learning Problems},\n  author = \t {Ramaswamy, Harish G. and Srinivasan Babu, Balaji and Agarwal, Shivani and Williamson, Robert C.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {885--902},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/ramaswamy14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/ramaswamy14.html},\n  abstract = \t {A popular approach to solving multiclass learning problems is to reduce them to a set of binary classification problems through some output code matrix: the widely used one-vs-all and all-pairs methods, and the error-correcting output code methods of Dietterich and Bakiri (1995), can all be viewed as special cases of this approach. In this paper, we consider the question of statistical consistency of such methods. We focus on settings where the binary problems are solved by minimizing a binary surrogate loss, and derive general conditions on the binary surrogate loss under which the one-vs-all and all-pairs code matrices yield consistent algorithms with respect to the multiclass 0-1 loss. We then consider general multiclass learning problems defined by a general multiclass loss, and derive conditions on the output code matrix and binary surrogates under which the resulting algorithm is consistent with respect to the target multiclass loss. We also consider \\emphprobabilistic code matrices, where one reduces a multiclass problem to a set of \\emphclass probability labeled binary problems, and show that these can yield benefits in the sense of requiring a smaller number of binary problems to achieve overall consistency. Our analysis makes interesting connections with the theory of proper composite losses (Buja et al., 2005; Reid and Williamson, 2010); these play a role in constructing the right \u2018decoding\u2019 for converting the predictions on the binary problems to the final multiclass prediction. To our knowledge, this is the first work that comprehensively studies consistency properties of output code based methods for multiclass learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/ramaswamy14.pdf",
        "supp": "",
        "pdf_size": 360922,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7325095320280940135&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Indian Institute of Science, Bangalore 560012, India; Indian Institute of Science, Bangalore 560012, India; Indian Institute of Science, Bangalore 560012, India; Australian National University and National ICT Australia, Canberra, ACT 2601, Australia",
        "aff_domain": "CSA.IISC.ERNET.IN;ECE.IISC.ERNET.IN;CSA.IISC.ERNET.IN;ANU.EDU.AU",
        "email": "CSA.IISC.ERNET.IN;ECE.IISC.ERNET.IN;CSA.IISC.ERNET.IN;ANU.EDU.AU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Indian Institute of Science;Australian National University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iisc.ac.in;https://www.anu.edu.au",
        "aff_unique_abbr": "IISc;ANU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Bangalore;Canberra",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "India;Australia"
    },
    {
        "id": "2d9a4c7044",
        "title": "Online Learning with Composite Loss Functions",
        "site": "https://proceedings.mlr.press/v35/dekel14.html",
        "author": "Ofer Dekel; Jian Ding; Tomer Koren; Yuval Peres",
        "abstract": "We study a new class of online learning problems where each of the online algorithm\u2019s actions is assigned an adversarial value, and the loss of the algorithm at each step is a known and deterministic function of the values assigned to its recent actions. This class includes problems where the algorithm\u2019s loss is the \\emphminimum over the recent adversarial values, the \\emphmaximum over the recent values, or a \\emphlinear combination of the recent values. We analyze the minimax regret of this class of problems when the algorithm receives bandit feedback, and prove that when the    \\emphminimum or \\emphmaximum functions are used, the minimax regret is \\widetilde \u03a9(T^2/3) (so called \\emphhard online learning problems), and when a linear function is used, the minimax regret is \\widetilde O(\\sqrtT) (so called \\empheasy learning problems). Previously, the only online learning problem that was known to be provably hard was the multi-armed bandit with switching costs.",
        "bibtex": "@InProceedings{pmlr-v35-dekel14,\n  title = \t {Online Learning with Composite Loss Functions},\n  author = \t {Dekel, Ofer and Ding, Jian and Koren, Tomer and Peres, Yuval},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1214--1231},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/dekel14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/dekel14.html},\n  abstract = \t {We study a new class of online learning problems where each of the online algorithm\u2019s actions is assigned an adversarial value, and the loss of the algorithm at each step is a known and deterministic function of the values assigned to its recent actions. This class includes problems where the algorithm\u2019s loss is the \\emphminimum over the recent adversarial values, the \\emphmaximum over the recent values, or a \\emphlinear combination of the recent values. We analyze the minimax regret of this class of problems when the algorithm receives bandit feedback, and prove that when the    \\emphminimum or \\emphmaximum functions are used, the minimax regret is \\widetilde \u03a9(T^2/3) (so called \\emphhard online learning problems), and when a linear function is used, the minimax regret is \\widetilde O(\\sqrtT) (so called \\empheasy learning problems). Previously, the only online learning problem that was known to be provably hard was the multi-armed bandit with switching costs.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/dekel14.pdf",
        "supp": "",
        "pdf_size": 278358,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=108205579735410580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Microsoft Research; University of Chicago; Technion; Microsoft Research",
        "aff_domain": "Microsoft.COM;GALTON.UCHICAGO.EDU;TECHNION.AC.IL;MICROSOFT.COM",
        "email": "Microsoft.COM;GALTON.UCHICAGO.EDU;TECHNION.AC.IL;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Microsoft;University of Chicago;Technion - Israel Institute of Technology",
        "aff_unique_dep": "Microsoft Research;;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.uchicago.edu;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "MSR;UChicago;Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "999d38b8ed",
        "title": "Online Linear Optimization via Smoothing",
        "site": "https://proceedings.mlr.press/v35/abernethy14.html",
        "author": "Jacob Abernethy; Chansoo Lee; Abhinav Sinha; Ambuj Tewari",
        "abstract": "We present a new optimization-theoretic approach to analyzing Follow-the-Leader style algorithms, particularly in the setting where perturbations are used as a tool for regularization. We show that adding a strongly convex penalty function to the decision rule and adding stochastic perturbations to data correspond to deterministic and stochastic smoothing operations, respectively. We establish an equivalence between \u201cFollow the Regularized Leader\u201d and \u201cFollow the Perturbed Leader\u201d up to the smoothness properties. This intuition leads to a new generic analysis framework that recovers and improves the previous known regret bounds of the class of algorithms commonly known as Follow the Perturbed Leader.",
        "bibtex": "@InProceedings{pmlr-v35-abernethy14,\n  title = \t {Online Linear Optimization via Smoothing},\n  author = \t {Abernethy, Jacob and Lee, Chansoo and Sinha, Abhinav and Tewari, Ambuj},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {807--823},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/abernethy14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/abernethy14.html},\n  abstract = \t {We present a new optimization-theoretic approach to analyzing Follow-the-Leader style algorithms, particularly in the setting where perturbations are used as a tool for regularization. We show that adding a strongly convex penalty function to the decision rule and adding stochastic perturbations to data correspond to deterministic and stochastic smoothing operations, respectively. We establish an equivalence between \u201cFollow the Regularized Leader\u201d and \u201cFollow the Perturbed Leader\u201d up to the smoothness properties. This intuition leads to a new generic analysis framework that recovers and improves the previous known regret bounds of the class of algorithms commonly known as Follow the Perturbed Leader.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/abernethy14.pdf",
        "supp": "",
        "pdf_size": 348552,
        "gs_citation": 93,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17299171319289791647&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Computer Science and Engineering Division, University of Michigan, Ann Arbor; Computer Science and Engineering Division, University of Michigan, Ann Arbor; Electrical and Computer Engineering Division, University of Michigan, Ann Arbor; Department of Statistics, University of Michigan, Ann Arbor",
        "aff_domain": "UMICH.EDU;UMICH.EDU;UMICH.EDU;UMICH.EDU",
        "email": "UMICH.EDU;UMICH.EDU;UMICH.EDU;UMICH.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Computer Science and Engineering Division",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "43a86e896c",
        "title": "Online Non-Parametric Regression",
        "site": "https://proceedings.mlr.press/v35/rakhlin14.html",
        "author": "Alexander Rakhlin; Karthik Sridharan",
        "abstract": "We establish optimal rates for online regression for arbitrary classes of regression functions in terms of the sequential entropy introduced in (Rakhlin et al., 2010). The optimal rates are shown to exhibit a phase transition analogous to the i.i.d./statistical learning case, studied in  (Rakhlin et al., 2014b). In the frequently encountered situation when sequential entropy and i.i.d. empirical entropy match, our results point to the interesting phenomenon that the rates for statistical learning with squared loss and online nonparametric regression are the same. In addition to a non-algorithmic study of minimax regret, we exhibit a generic forecaster that enjoys the established optimal rates. We also provide a recipe for designing online regression algorithms that can be computationally efficient. We illustrate the techniques by deriving existing and new forecasters for the case of finite experts and for online linear regression.",
        "bibtex": "@InProceedings{pmlr-v35-rakhlin14,\n  title = \t {Online Non-Parametric Regression},\n  author = \t {Rakhlin, Alexander and Sridharan, Karthik},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1232--1264},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/rakhlin14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/rakhlin14.html},\n  abstract = \t {We establish optimal rates for online regression for arbitrary classes of regression functions in terms of the sequential entropy introduced in (Rakhlin et al., 2010). The optimal rates are shown to exhibit a phase transition analogous to the i.i.d./statistical learning case, studied in  (Rakhlin et al., 2014b). In the frequently encountered situation when sequential entropy and i.i.d. empirical entropy match, our results point to the interesting phenomenon that the rates for statistical learning with squared loss and online nonparametric regression are the same. In addition to a non-algorithmic study of minimax regret, we exhibit a generic forecaster that enjoys the established optimal rates. We also provide a recipe for designing online regression algorithms that can be computationally efficient. We illustrate the techniques by deriving existing and new forecasters for the case of finite experts and for online linear regression.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/rakhlin14.pdf",
        "supp": "",
        "pdf_size": 490096,
        "gs_citation": 109,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11054349176534750063&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 16,
        "aff": "University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "WHARTON.UPENN.EDU;WHARTON.UPENN.EDU",
        "email": "WHARTON.UPENN.EDU;WHARTON.UPENN.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a9dd481eee",
        "title": "Open Problem: A (Missing) Boosting-type Convergence Result for AdaBoost.MH with Factorized Multi-class Classifiers",
        "site": "https://proceedings.mlr.press/v35/kegl14.html",
        "author": "Bal\u00e1zs K\u00e9gl",
        "abstract": "In (K\u00e9gl, 2014), we recently showed empirically that AdaBoost.MH is one of the best multi-class boosting algorithms when the classical one-against-all base classifiers, proposed in the seminal paper of Schapire and Singer\u00a0(1999), are replaced by factorized base classifiers containing a binary classifier and a vote (or code) vector. In a slightly different setup, a similar factorization coupled with an iterative optimization of the two factors also proved to be an excellent approach (Gao and Koller, 2011). The main algorithmic advantage of our approach over the original setup of Schapire and Singer\u00a0(1999) is that trees can be built in a straightforward way by using the binary classifier at inner nodes. In this open problem paper we take a step back to the basic setup of boosting generic multi-class factorized (Hamming) classifiers (so no trees), and state the classical problem of boosting-like convergence of the training error. Given a vote vector, training the classifier leads to a standard weighted binary classification problem. The main difficulty of proving the convergence is that, unlike in binary AdaBoost, the sum of the weights in this weighted binary classification problem is less than one, which means that the lower bound on the edge, coming from the weak learning condition, shrinks. To show the convergence, we need a (uniform) lower bound on the sum of the weights in this derived binary classification problem.",
        "bibtex": "@InProceedings{pmlr-v35-kegl14,\n  title = \t {Open Problem: A (missing) Boosting-Type Convergence Result for \\textsc{AdaBoost.MH} with Factorized Multi-class Classifiers},\n  author = \t {K\u00e9gl, Bal\u00e1zs},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1268--1275},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kegl14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kegl14.html},\n  abstract = \t {In (K\u00e9gl, 2014), we recently showed empirically that AdaBoost.MH is one of the best multi-class boosting algorithms when the classical one-against-all base classifiers, proposed in the seminal paper of Schapire and Singer\u00a0(1999), are replaced by factorized base classifiers containing a binary classifier and a vote (or code) vector. In a slightly different setup, a similar factorization coupled with an iterative optimization of the two factors also proved to be an excellent approach (Gao and Koller, 2011). The main algorithmic advantage of our approach over the original setup of Schapire and Singer\u00a0(1999) is that trees can be built in a straightforward way by using the binary classifier at inner nodes. In this open problem paper we take a step back to the basic setup of boosting generic multi-class factorized (Hamming) classifiers (so no trees), and state the classical problem of boosting-like convergence of the training error. Given a vote vector, training the classifier leads to a standard weighted binary classification problem. The main difficulty of proving the convergence is that, unlike in binary AdaBoost, the sum of the weights in this weighted binary classification problem is less than one, which means that the lower bound on the edge, coming from the weak learning condition, shrinks. To show the convergence, we need a (uniform) lower bound on the sum of the weights in this derived binary classification problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/kegl14.pdf",
        "supp": "",
        "pdf_size": 354354,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:EImQmzfjA18J:scholar.google.com/&scioq=Open+Problem:+A+(Missing)+Boosting-type+Convergence+Result+for+AdaBoost.MH+with+Factorized+Multi-class+Classifiers&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": "LAL/LRI, University of Paris-Sud, CNRS, 91898 Orsay, France",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Paris-Sud",
        "aff_unique_dep": "LAL/LRI",
        "aff_unique_url": "https://www.universite-paris-sud.fr",
        "aff_unique_abbr": "Paris-Sud",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "524d7f7984",
        "title": "Open Problem: Efficient Online Sparse Regression",
        "site": "https://proceedings.mlr.press/v35/kale14b.html",
        "author": "Satyen Kale",
        "abstract": "In practical scenarios, it is often necessary to be able to make predictions with very limited access to the features of any example. We provide one natural formulation as an online sparse regression problem with squared loss, and ask whether it is possible to achieve sublinear regret with efficient algorithms (i.e. polynomial running time in the natural parameters of the problem).",
        "bibtex": "@InProceedings{pmlr-v35-kale14b,\n  title = \t {Open Problem: Efficient Online Sparse Regression},\n  author = \t {Kale, Satyen},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1299--1301},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kale14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kale14b.html},\n  abstract = \t {In practical scenarios, it is often necessary to be able to make predictions with very limited access to the features of any example. We provide one natural formulation as an online sparse regression problem with squared loss, and ask whether it is possible to achieve sublinear regret with efficient algorithms (i.e. polynomial running time in the natural parameters of the problem).}\n}",
        "pdf": "http://proceedings.mlr.press/v35/kale14b.pdf",
        "supp": "",
        "pdf_size": 183690,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2718548478135903447&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Yahoo! Labs New York",
        "aff_domain": "yahoo-inc.com",
        "email": "yahoo-inc.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Yahoo!",
        "aff_unique_dep": "Yahoo! Labs",
        "aff_unique_url": "https://yahoo.com",
        "aff_unique_abbr": "Yahoo!",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fb04109d4a",
        "title": "Open Problem: Finding Good Cascade Sampling Processes for the Network Inference Problem",
        "site": "https://proceedings.mlr.press/v35/gomezrodriguez14.html",
        "author": "Manuel Gomez-Rodriguez; Le Song; Bernhard Schoelkopf",
        "abstract": "Information spreads across social and technological networks, but often the network structures are hidden and we only observe the traces left by the diffusion processes, called cascades. It is known that, under a popular continuous-time diffusion model, as long as the model parameters satisfy a natural incoherence condition, it is possible to recover the correct network structure with high probability if we observe O(d^3 \\log N) cascades, where d is the maximum number of parents of a node and N is the total number of nodes. However, the incoherence condition depends, in a non-trivial way, on the source (node) distribution of the cascades, which is typically unknown. Our open problem is whether it is possible to design an active algorithm which samples the source locations in a sequential manner and achieves the same or even better sample complexity, e.g., o(d_i^3 \\log N), than previous work.",
        "bibtex": "@InProceedings{pmlr-v35-gomezrodriguez14,\n  title = \t {Open Problem: Finding Good Cascade Sampling Processes for the Network Inference Problem},\n  author = \t {Gomez-Rodriguez, Manuel and Song, Le and Schoelkopf, Bernhard},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1276--1279},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/gomezrodriguez14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/gomezrodriguez14.html},\n  abstract = \t {Information spreads across social and technological networks, but often the network structures are hidden and we only observe the traces left by the diffusion processes, called cascades. It is known that, under a popular continuous-time diffusion model, as long as the model parameters satisfy a natural incoherence condition, it is possible to recover the correct network structure with high probability if we observe O(d^3 \\log N) cascades, where d is the maximum number of parents of a node and N is the total number of nodes. However, the incoherence condition depends, in a non-trivial way, on the source (node) distribution of the cascades, which is typically unknown. Our open problem is whether it is possible to design an active algorithm which samples the source locations in a sequential manner and achieves the same or even better sample complexity, e.g., o(d_i^3 \\log N), than previous work.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/gomezrodriguez14.pdf",
        "supp": "",
        "pdf_size": 188315,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13481461849184261075&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "MPI for Intelligent Systems; Georgia Institute of Technology; MPI for Intelligent Systems",
        "aff_domain": "TUE.MPG.DE;CC.GATECH.EDU;TUE.MPG.DE",
        "email": "TUE.MPG.DE;CC.GATECH.EDU;TUE.MPG.DE",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Georgia Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.gatech.edu",
        "aff_unique_abbr": "MPI-IS;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "fe28631d0d",
        "title": "Open Problem: Online Local Learning",
        "site": "https://proceedings.mlr.press/v35/christiano14.html",
        "author": "Paul Christiano",
        "abstract": "In many learning problems, we attempt to infer \\emphglobal structure in the interest of making \\emphlocal predictions.  For example, we might try to infer the skills of the competitors in a tournament in order to predict who will win a match, or we might try to predict characteristics of users and films in order to predict which users will like which films.  In even relatively simple settings of this type, it is typically NP-hard to find the latent data which best explain some observations.  But do these complexity-theoretic obstructions actually prevent us from making good predictions?  Because each prediction depends on only a small number of variables, it might be possible to make good predictions without actually finding a good global assignment.  This may seem to be a purely technical distinction, but recent work has shown that several local prediction problems actually \\emphare easy even though the corresponding global inference problem is hard.  The question we pose is: how general is this phenomenon?",
        "bibtex": "@InProceedings{pmlr-v35-christiano14,\n  title = \t {Open Problem: Online Local Learning},\n  author = \t {Christiano, Paul},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1290--1294},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/christiano14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/christiano14.html},\n  abstract = \t {In many learning problems, we attempt to infer \\emphglobal structure in the interest of making \\emphlocal predictions.  For example, we might try to infer the skills of the competitors in a tournament in order to predict who will win a match, or we might try to predict characteristics of users and films in order to predict which users will like which films.  In even relatively simple settings of this type, it is typically NP-hard to find the latent data which best explain some observations.  But do these complexity-theoretic obstructions actually prevent us from making good predictions?  Because each prediction depends on only a small number of variables, it might be possible to make good predictions without actually finding a good global assignment.  This may seem to be a purely technical distinction, but recent work has shown that several local prediction problems actually \\emphare easy even though the corresponding global inference problem is hard.  The question we pose is: how general is this phenomenon?}\n}",
        "pdf": "http://proceedings.mlr.press/v35/christiano14.pdf",
        "supp": "",
        "pdf_size": 167543,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5325740423334590499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "UC Berkeley",
        "aff_domain": "EECS.BERKELEY.EDU",
        "email": "EECS.BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ff6933540f",
        "title": "Open Problem: Shifting Experts on Easy Data",
        "site": "https://proceedings.mlr.press/v35/warmuth14.html",
        "author": "Manfred K. Warmuth; Wouter M. Koolen",
        "abstract": "A number of online algorithms have been developed that have small additional loss (regret) compared to the best \u201cshifting expert\u201d. In this model, there is a set of experts and the comparator is the best partition of the trial sequence into a small number of segments, where the expert of smallest loss is chosen in each segment. The regret is typically defined for worst-case data / loss sequences. There has been a recent surge of interest in online algorithms that combine good worst-case guarantees with much improved performance on easy data. A practically relevant class of easy data is the case when the loss of each expert is iid and the best and second best experts have a gap between their mean loss. In the full information setting, the FlipFlop algorithm by De Rooij et al. (2014) combines the best of the iid optimal Follow-The-Leader (FL) and the worst-case-safe Hedge algorithms, whereas in the bandit information case SAO by Bubeck and Slivkins (2012) competes with the iid optimal UCB and the worst-case-safe EXP3. We ask the same question for the shifting expert problem. First, we ask what are the simple and efficient algorithms for the shifting experts problem when the loss sequence in each segment is iid with respect to a fixed but unknown distribution. Second, we ask how to efficiently unite the performance of such algorithms on easy data with worst-case robustness. A particular intriguing open problem is the case when the comparator shifts within a small subset of experts from a large set under the assumption that the losses in each segment are iid.",
        "bibtex": "@InProceedings{pmlr-v35-warmuth14,\n  title = \t {Open Problem: Shifting Experts on Easy Data},\n  author = \t {Warmuth, Manfred K. and Koolen, Wouter M.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1295--1298},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/warmuth14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/warmuth14.html},\n  abstract = \t {A number of online algorithms have been developed that have small additional loss (regret) compared to the best \u201cshifting expert\u201d. In this model, there is a set of experts and the comparator is the best partition of the trial sequence into a small number of segments, where the expert of smallest loss is chosen in each segment. The regret is typically defined for worst-case data / loss sequences. There has been a recent surge of interest in online algorithms that combine good worst-case guarantees with much improved performance on easy data. A practically relevant class of easy data is the case when the loss of each expert is iid and the best and second best experts have a gap between their mean loss. In the full information setting, the FlipFlop algorithm by De Rooij et al. (2014) combines the best of the iid optimal Follow-The-Leader (FL) and the worst-case-safe Hedge algorithms, whereas in the bandit information case SAO by Bubeck and Slivkins (2012) competes with the iid optimal UCB and the worst-case-safe EXP3. We ask the same question for the shifting expert problem. First, we ask what are the simple and efficient algorithms for the shifting experts problem when the loss sequence in each segment is iid with respect to a fixed but unknown distribution. Second, we ask how to efficiently unite the performance of such algorithms on easy data with worst-case robustness. A particular intriguing open problem is the case when the comparator shifts within a small subset of experts from a large set under the assumption that the losses in each segment are iid.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/warmuth14.pdf",
        "supp": "",
        "pdf_size": 167141,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8888607937418691090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "UC Santa Cruz, USA; Queensland University of Technology, Brisbane, Australia",
        "aff_domain": "cse.ucsc.edu;qut.edu.au",
        "email": "cse.ucsc.edu;qut.edu.au",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Santa Cruz;Queensland University of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsc.edu;https://www.qut.edu.au",
        "aff_unique_abbr": "UCSC;QUT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Santa Cruz;Brisbane",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "d2fbd6cb89",
        "title": "Open Problem: Tensor Decompositions: Algorithms up to the Uniqueness Threshold?",
        "site": "https://proceedings.mlr.press/v35/bhaskara14b.html",
        "author": "Aditya Bhaskara; Moses Charikar; Ankur Moitra; Aravindan Vijayaraghavan",
        "abstract": "",
        "bibtex": "@InProceedings{pmlr-v35-bhaskara14b,\n  title = \t {Open Problem: Tensor Decompositions: Algorithms up to the Uniqueness Threshold?},\n  author = \t {Bhaskara, Aditya and Charikar, Moses and Moitra, Ankur and Vijayaraghavan, Aravindan},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1280--1282},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/bhaskara14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/bhaskara14b.html}\n}",
        "pdf": "http://proceedings.mlr.press/v35/bhaskara14b.pdf",
        "supp": "",
        "pdf_size": 128684,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16588004866211679823&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Google Research NYC; Princeton University; MIT; CMU",
        "aff_domain": "CS.PRINCETON.EDU;CS.PRINCETON.EDU;MIT.EDU;CS.CMU.EDU",
        "email": "CS.PRINCETON.EDU;CS.PRINCETON.EDU;MIT.EDU;CS.CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Google;Princeton University;Massachusetts Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "Google Research;;;",
        "aff_unique_url": "https://research.google;https://www.princeton.edu;https://web.mit.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Google Research;Princeton;MIT;CMU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New York City;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "cf67223569",
        "title": "Open Problem: The Statistical Query Complexity of Learning Sparse Halfspaces",
        "site": "https://proceedings.mlr.press/v35/feldman14c.html",
        "author": "Vitaly Feldman",
        "abstract": "We consider the long-open problem of attribute-efficient learning of halfspaces. In this problem the learner is given random examples labeled by an unknown halfspace function f on \\mathbbR^n. Further f is r-sparse, that is it depends on at most r out of n variables. An attribute-efficient learning algorithm is an algorithm that can output a hypothesis close to f using a polynomial in r and \\log n number of examples (Blum, 1992). Despite a number of attempts and some partial progress, there are no efficient algorithms or hardness results for the problem. We propose a potentially easier question: what is the query complexity of this learning problem in the statistical query (SQ) model of Kearns (1998). We show that, as in the case of general PAC learning, the query complexity of attribute-efficient SQ learning of any concept class can be characterized by a combinatorial parameter of the concept class. The proposed question is then equivalent to estimating the value of this parameter for the concept class of halfspaces. A potentially simpler problem is to estimate this parameter for the concept class of decision lists, a subclass of halfspaces.",
        "bibtex": "@InProceedings{pmlr-v35-feldman14c,\n  title = \t {Open Problem: The Statistical Query Complexity of Learning Sparse Halfspaces},\n  author = \t {Feldman, Vitaly},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1283--1289},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/feldman14c.pdf},\n  url = \t {https://proceedings.mlr.press/v35/feldman14c.html},\n  abstract = \t {We consider the long-open problem of attribute-efficient learning of halfspaces. In this problem the learner is given random examples labeled by an unknown halfspace function f on \\mathbbR^n. Further f is r-sparse, that is it depends on at most r out of n variables. An attribute-efficient learning algorithm is an algorithm that can output a hypothesis close to f using a polynomial in r and \\log n number of examples (Blum, 1992). Despite a number of attempts and some partial progress, there are no efficient algorithms or hardness results for the problem. We propose a potentially easier question: what is the query complexity of this learning problem in the statistical query (SQ) model of Kearns (1998). We show that, as in the case of general PAC learning, the query complexity of attribute-efficient SQ learning of any concept class can be characterized by a combinatorial parameter of the concept class. The proposed question is then equivalent to estimating the value of this parameter for the concept class of halfspaces. A potentially simpler problem is to estimate this parameter for the concept class of decision lists, a subclass of halfspaces.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/feldman14c.pdf",
        "supp": "",
        "pdf_size": 224221,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2495026771001163331&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0be8d01573",
        "title": "Open Problem: Tightness of maximum likelihood semidefinite relaxations",
        "site": "https://proceedings.mlr.press/v35/bandeira14.html",
        "author": "Afonso S. Bandeira; Yuehaw Khoo; Amit Singer",
        "abstract": "We have observed an interesting, yet unexplained, phenomenon: Semidefinite programming (SDP) based relaxations of maximum likelihood estimators (MLE) tend to be tight in recovery problems with noisy data, even when MLE cannot exactly recover the ground truth. Several results establish tightness of SDP based relaxations in the regime where exact recovery from MLE is possible. However, to the best of our knowledge, their tightness is not understood beyond this regime. As an illustrative example, we focus on the generalized Procrustes problem.",
        "bibtex": "@InProceedings{pmlr-v35-bandeira14,\n  title = \t {Open Problem: Tightness of maximum likelihood semidefinite relaxations},\n  author = \t {Bandeira, Afonso S. and Khoo, Yuehaw and Singer, Amit},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1265--1267},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/bandeira14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/bandeira14.html},\n  abstract = \t {We have observed an interesting, yet unexplained, phenomenon: Semidefinite programming (SDP) based relaxations of maximum likelihood estimators (MLE) tend to be tight in recovery problems with noisy data, even when MLE cannot exactly recover the ground truth. Several results establish tightness of SDP based relaxations in the regime where exact recovery from MLE is possible. However, to the best of our knowledge, their tightness is not understood beyond this regime. As an illustrative example, we focus on the generalized Procrustes problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/bandeira14.pdf",
        "supp": "",
        "pdf_size": 188932,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10366707781735940880&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Program in Applied and Computational Mathematics (PACM), Princeton University, Princeton NJ, USA; Department of Physics, Princeton University, Princeton NJ, USA; Department of Mathematics and PACM, Princeton University, Princeton NJ, USA",
        "aff_domain": "MATH.PRINCEON.EDU;PRINCETON.EDU;MATH.PRINCEON.EDU",
        "email": "MATH.PRINCEON.EDU;PRINCETON.EDU;MATH.PRINCEON.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Program in Applied and Computational Mathematics (PACM)",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3cc385288e",
        "title": "Optimal learners for multiclass problems",
        "site": "https://proceedings.mlr.press/v35/daniely14b.html",
        "author": "Amit Daniely; Shai Shalev-Shwartz",
        "abstract": "The fundamental theorem of statistical learning states that for \\emphbinary classification problems, any Empirical Risk Minimization (ERM) learning rule has close to optimal sample complexity. In this paper we seek for a generic optimal learner for \\emphmulticlass prediction.  We start by proving a surprising result: a generic optimal multiclass learner must be \\emphimproper, namely, it must have the ability to output hypotheses which do not belong to the hypothesis class, even though it knows that all the labels are generated by some hypothesis from the class. In particular, no ERM learner is optimal. This brings back the fundamental question of \u201chow to learn\u201d? We give a complete answer to this question by giving a new analysis of the one-inclusion multiclass learner of Rubinstein et el (2006) showing that its sample complexity is essentially optimal. Then, we turn to study the popular hypothesis class of generalized linear classifiers. We derive optimal learners that, unlike the one-inclusion algorithm, are computationally efficient. Furthermore, we show that the sample complexity of these learners is better than the sample complexity of the ERM rule, thus settling in negative an open question due to Collins (2005)",
        "bibtex": "@InProceedings{pmlr-v35-daniely14b,\n  title = \t {Optimal learners for multiclass problems},\n  author = \t {Daniely, Amit and Shalev-Shwartz, Shai},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {287--316},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/daniely14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/daniely14b.html},\n  abstract = \t {The fundamental theorem of statistical learning states that for \\emphbinary classification problems, any Empirical Risk Minimization (ERM) learning rule has close to optimal sample complexity. In this paper we seek for a generic optimal learner for \\emphmulticlass prediction.  We start by proving a surprising result: a generic optimal multiclass learner must be \\emphimproper, namely, it must have the ability to output hypotheses which do not belong to the hypothesis class, even though it knows that all the labels are generated by some hypothesis from the class. In particular, no ERM learner is optimal. This brings back the fundamental question of \u201chow to learn\u201d? We give a complete answer to this question by giving a new analysis of the one-inclusion multiclass learner of Rubinstein et el (2006) showing that its sample complexity is essentially optimal. Then, we turn to study the popular hypothesis class of generalized linear classifiers. We derive optimal learners that, unlike the one-inclusion algorithm, are computationally efficient. Furthermore, we show that the sample complexity of these learners is better than the sample complexity of the ERM rule, thus settling in negative an open question due to Collins (2005)}\n}",
        "pdf": "http://proceedings.mlr.press/v35/daniely14b.pdf",
        "supp": "",
        "pdf_size": 482373,
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8522422180757059443&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Dept. of Mathematics, The Hebrew University, Jerusalem, Israel; School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hebrew University",
        "aff_unique_dep": "Dept. of Mathematics",
        "aff_unique_url": "http://www.huji.ac.il",
        "aff_unique_abbr": "HUJI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Jerusalem",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "5cf0682208",
        "title": "Preface",
        "site": "https://proceedings.mlr.press/v35/balcan14.html",
        "author": "Maria Florina Balcan; Csaba Szepesv\u00e1ri",
        "abstract": "",
        "bibtex": "@InProceedings{pmlr-v35-balcan14,\n  title = \t {Preface},\n  author = \t {Balcan, Maria Florina and Szepesv\u00e1ri, Csaba},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1--2},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/balcan14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/balcan14.html}\n}",
        "pdf": "http://proceedings.mlr.press/v35/balcan14.pdf",
        "supp": "",
        "pdf_size": 76365,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14141043608347785016&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "School of Computer Science, Carnegie Mellon University; Department of Computing Science, University of Alberta",
        "aff_domain": "CS.CMU.EDU;CS.UALBERTA.CA",
        "email": "CS.CMU.EDU;CS.UALBERTA.CA",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Carnegie Mellon University;University of Alberta",
        "aff_unique_dep": "School of Computer Science;Department of Computing Science",
        "aff_unique_url": "https://www.cmu.edu;https://www.ualberta.ca",
        "aff_unique_abbr": "CMU;UAlberta",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "b4a230170d",
        "title": "Principal Component Analysis and Higher Correlations for Distributed Data",
        "site": "https://proceedings.mlr.press/v35/kannan14.html",
        "author": "Ravi Kannan; Santosh Vempala; David Woodruff",
        "abstract": "We consider algorithmic problems in the setting in which the input data has been partitioned arbitrarily on many servers. The goal is to compute a function of all the data, and the bottleneck is the communication used by the algorithm. We present algorithms for two illustrative problems on massive data sets: (1) computing a low-rank approximation of a matrix A=A^1 + A^2 + \\ldots + A^s, with matrix A^t stored on server t and (2) computing a function of a vector a_1 + a_2 + \\ldots + a_s, where server t has the vector a_t; this includes the well-studied special case of computing frequency moments and separable functions, as well as higher-order correlations such as the number of subgraphs of a specified type occurring in a graph. For both problems we give algorithms with nearly optimal communication, and in particular the only dependence on n, the size of the data, is in the number of bits needed to represent indices and words (O(\\log n)).",
        "bibtex": "@InProceedings{pmlr-v35-kannan14,\n  title = \t {Principal Component Analysis and Higher Correlations for Distributed Data},\n  author = \t {Kannan, Ravi and Vempala, Santosh and Woodruff, David},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1040--1057},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kannan14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kannan14.html},\n  abstract = \t {We consider algorithmic problems in the setting in which the input data has been partitioned arbitrarily on many servers. The goal is to compute a function of all the data, and the bottleneck is the communication used by the algorithm. We present algorithms for two illustrative problems on massive data sets: (1) computing a low-rank approximation of a matrix A=A^1 + A^2 + \\ldots + A^s, with matrix A^t stored on server t and (2) computing a function of a vector a_1 + a_2 + \\ldots + a_s, where server t has the vector a_t; this includes the well-studied special case of computing frequency moments and separable functions, as well as higher-order correlations such as the number of subgraphs of a specified type occurring in a graph. For both problems we give algorithms with nearly optimal communication, and in particular the only dependence on n, the size of the data, is in the number of bits needed to represent indices and words (O(\\log n)). }\n}",
        "pdf": "http://proceedings.mlr.press/v35/kannan14.pdf",
        "supp": "",
        "pdf_size": 363235,
        "gs_citation": 115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16395042660979409649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Microsoft Research India; Georgia Tech; IBM Research Almaden",
        "aff_domain": "MICROSOFT.COM;GATECH.EDU;US.UBM.COM",
        "email": "MICROSOFT.COM;GATECH.EDU;US.UBM.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Microsoft;Georgia Institute of Technology;IBM",
        "aff_unique_dep": "Microsoft Research India;;IBM Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-india;https://www.gatech.edu;https://www.ibm.com/research",
        "aff_unique_abbr": "MSR India;Georgia Tech;IBM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Almaden",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "6b32185491",
        "title": "Resourceful Contextual Bandits",
        "site": "https://proceedings.mlr.press/v35/badanidiyuru14.html",
        "author": "Ashwinkumar Badanidiyuru; John Langford; Aleksandrs Slivkins",
        "abstract": "We study contextual bandits with ancillary constraints on resources, which are common in real-world applications such as choosing ads or dynamic pricing of items.  We design the first algorithm for solving these problems that improves over a trivial reduction to the non-contextual case. We consider very general settings for both contextual bandits (arbitrary policy sets, Dudik et al. (2011)) and bandits with resource constraints (bandits with knapsacks,  Badanidiyuru et al. (2013a)), and prove a regret guarantee with near-optimal statistical properties.",
        "bibtex": "@InProceedings{pmlr-v35-badanidiyuru14,\n  title = \t {Resourceful Contextual Bandits},\n  author = \t {Badanidiyuru, Ashwinkumar and Langford, John and Slivkins, Aleksandrs},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1109--1134},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/badanidiyuru14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/badanidiyuru14.html},\n  abstract = \t {We study contextual bandits with ancillary constraints on resources, which are common in real-world applications such as choosing ads or dynamic pricing of items.  We design the first algorithm for solving these problems that improves over a trivial reduction to the non-contextual case. We consider very general settings for both contextual bandits (arbitrary policy sets, Dudik et al. (2011)) and bandits with resource constraints (bandits with knapsacks,  Badanidiyuru et al. (2013a)), and prove a regret guarantee with near-optimal statistical properties.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/badanidiyuru14.pdf",
        "supp": "",
        "pdf_size": 484851,
        "gs_citation": 161,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13295553671396126158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, Cornell University, Ithaca NY, USA; Microsoft Research, New York, NY, USA; Microsoft Research, New York, NY, USA",
        "aff_domain": "GMAIL.COM;MICROSOFT.COM;MICROSOFT.COM",
        "email": "GMAIL.COM;MICROSOFT.COM;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Cornell University;Microsoft",
        "aff_unique_dep": "Department of Computer Science;Microsoft Research",
        "aff_unique_url": "https://www.cornell.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Cornell;MSR",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Ithaca;New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4bacfd7d35",
        "title": "Robust Multi-objective Learning with Mentor Feedback",
        "site": "https://proceedings.mlr.press/v35/agarwal14b.html",
        "author": "Alekh Agarwal; Ashwinkumar Badanidiyuru; Miroslav Dud\u00edk; Robert E. Schapire; Aleksandrs Slivkins",
        "abstract": "We study decision making when each action is described by a set of objectives, all of which are to be maximized. During the training phase, we have access to the actions of an outside agent (\u201cmentor\u201d). In the test phase, our goal is to maximally improve upon the mentor\u2019s (unobserved) actions across all objectives. We present an algorithm with a vanishing regret compared with the optimal possible improvement, and show that our regret bound is the best possible. The bound is independent of the number of actions, and scales only as the logarithm of the number of objectives.",
        "bibtex": "@InProceedings{pmlr-v35-agarwal14b,\n  title = \t {Robust Multi-objective Learning with Mentor Feedback},\n  author = \t {Agarwal, Alekh and Badanidiyuru, Ashwinkumar and Dud\u00edk, Miroslav and Schapire, Robert E. and Slivkins, Aleksandrs},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {726--741},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/agarwal14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/agarwal14b.html},\n  abstract = \t {We study decision making when each action is described by a set of objectives, all of which are to be maximized. During the training phase, we have access to the actions of an outside agent (\u201cmentor\u201d). In the test phase, our goal is to maximally improve upon the mentor\u2019s (unobserved) actions across all objectives. We present an algorithm with a vanishing regret compared with the optimal possible improvement, and show that our regret bound is the best possible. The bound is independent of the number of actions, and scales only as the logarithm of the number of objectives.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/agarwal14b.pdf",
        "supp": "",
        "pdf_size": 358270,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6307826173237515077&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Microsoft Research, New York, NY USA; Cornell University, Dept of Computer Science, Ithaca, NY USA; Microsoft Research, New York, NY USA; Princeton University, Dept of Computer Science, Princeton, NJ USA; Microsoft Research, New York, NY USA",
        "aff_domain": "microsoft.com;gmail.com;microsoft.com;cs.princeton.edu;microsoft.com",
        "email": "microsoft.com;gmail.com;microsoft.com;cs.princeton.edu;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Microsoft;Cornell University;Princeton University",
        "aff_unique_dep": "Microsoft Research;Dept of Computer Science;Dept of Computer Science",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.cornell.edu;https://www.princeton.edu",
        "aff_unique_abbr": "MSR;Cornell;Princeton",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "New York;Ithaca;Princeton",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "cfe33c0a9c",
        "title": "Sample Complexity Bounds on Differentially Private Learning via Communication Complexity",
        "site": "https://proceedings.mlr.press/v35/feldman14b.html",
        "author": "Vitaly Feldman; David Xiao",
        "abstract": "In this work we analyze the sample complexity of classification by differentially private algorithms. Differential privacy is a strong and well-studied notion of privacy introduced by Dwork et al. (2006) that ensures that the output of an algorithm leaks little information about the data point provided by any of the participating individuals. Sample complexity of private PAC and agnostic learning was studied in a number of prior works starting with (Kasiviswanathan et al., 2008) but a number of basic questions still remain open (Beimel et al. 2010; Chaudhuri and Hsu, 2011; Beimel et al., 2013a,b). Our main contribution is an equivalence between the sample complexity of differentially-private learning of a concept class C (or \\mathrmSCDP(C)) and the randomized one-way communication complexity of the evaluation problem for concepts from C. Using this equivalence we prove the following bounds: \\beginitemize \\item \\mathrmSCDP(C) = \u03a9(\\mathrmLDim(C)), where \\mathrmLDim(C) is the Littlestone\u2019s (1987) dimension characterizing the number of mistakes in the online-mistake-bound learning model. This result implies that \\mathrmSCDP(C) is different from the VC-dimension of C, resolving one of the main open questions from prior work. \\item For any t, there exists a class C such that \\mathrmLDim(C)=2 but \\mathrmSCDP(C) \u2265t. \\item For any t, there exists a class C such that the sample complexity of (pure) \u03b1-differentially private PAC learning is \u03a9(t/\u03b1) but the sample complexity of the relaxed (\u03b1,\u03b2)-differentially private PAC learning is O(\\log(1/\u03b2)/\u03b1). This resolves an open problem from (Beimel et al., 2013b). \\enditemize We also obtain simpler proofs for a number of known related results. Our equivalence builds on a characterization of sample complexity by Beimel et al., (2013a) and our bounds rely on a number of known results from communication complexity.",
        "bibtex": "@InProceedings{pmlr-v35-feldman14b,\n  title = \t {Sample Complexity Bounds on Differentially Private Learning via Communication Complexity},\n  author = \t {Feldman, Vitaly and Xiao, David},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1000--1019},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/feldman14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/feldman14b.html},\n  abstract = \t {In this work we analyze the sample complexity of classification by differentially private algorithms. Differential privacy is a strong and well-studied notion of privacy introduced by Dwork et al. (2006) that ensures that the output of an algorithm leaks little information about the data point provided by any of the participating individuals. Sample complexity of private PAC and agnostic learning was studied in a number of prior works starting with (Kasiviswanathan et al., 2008) but a number of basic questions still remain open (Beimel et al. 2010; Chaudhuri and Hsu, 2011; Beimel et al., 2013a,b). Our main contribution is an equivalence between the sample complexity of differentially-private learning of a concept class C (or \\mathrmSCDP(C)) and the randomized one-way communication complexity of the evaluation problem for concepts from C. Using this equivalence we prove the following bounds: \\beginitemize \\item \\mathrmSCDP(C) = \u03a9(\\mathrmLDim(C)), where \\mathrmLDim(C) is the Littlestone\u2019s (1987) dimension characterizing the number of mistakes in the online-mistake-bound learning model. This result implies that \\mathrmSCDP(C) is different from the VC-dimension of C, resolving one of the main open questions from prior work. \\item For any t, there exists a class C such that \\mathrmLDim(C)=2 but \\mathrmSCDP(C) \u2265t. \\item For any t, there exists a class C such that the sample complexity of (pure) \u03b1-differentially private PAC learning is \u03a9(t/\u03b1) but the sample complexity of the relaxed (\u03b1,\u03b2)-differentially private PAC learning is O(\\log(1/\u03b2)/\u03b1). This resolves an open problem from (Beimel et al., 2013b). \\enditemize We also obtain simpler proofs for a number of known related results. Our equivalence builds on a characterization of sample complexity by Beimel et al., (2013a) and our bounds rely on a number of known results from communication complexity.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/feldman14b.pdf",
        "supp": "",
        "pdf_size": 423805,
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4072438802465227213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 19,
        "aff": "IBM Research - Almaden; CNRS, Universit\u00e9 Paris 7",
        "aff_domain": "POST.HARVARD.EDU;LIAFA.UNIV-PARIS-DIDEROT.FR",
        "email": "POST.HARVARD.EDU;LIAFA.UNIV-PARIS-DIDEROT.FR",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "IBM;CNRS",
        "aff_unique_dep": "IBM Research;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.cnrs.fr",
        "aff_unique_abbr": "IBM;CNRS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Almaden;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "03392c028c",
        "title": "Sample Compression for Multi-label Concept Classes",
        "site": "https://proceedings.mlr.press/v35/samei14.html",
        "author": "Rahim Samei; Pavel Semukhin; Boting Yang; Sandra Zilles",
        "abstract": "This paper studies labeled sample compression for multi-label concept classes. For a specific extension of the notion of VC-dimension to multi-label classes, we prove that every maximum multi-label class of dimension d has a sample compression scheme in which every sample is compressed to a subset of size at most d. We further show that every multi-label class of dimension 1 has a sample compression scheme using only sets of size at most 1. As opposed to the binary case, the latter result is not immediately implied by the former, since there are multi-label concept classes of dimension 1 that are not contained in maximum classes of dimension 1.",
        "bibtex": "@InProceedings{pmlr-v35-samei14,\n  title = \t {Sample Compression for Multi-label Concept Classes},\n  author = \t {Samei, Rahim and Semukhin, Pavel and Yang, Boting and Zilles, Sandra},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {371--393},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/samei14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/samei14.html},\n  abstract = \t {This paper studies labeled sample compression for multi-label concept classes. For a specific extension of the notion of VC-dimension to multi-label classes, we prove that every maximum multi-label class of dimension d has a sample compression scheme in which every sample is compressed to a subset of size at most d. We further show that every multi-label class of dimension 1 has a sample compression scheme using only sets of size at most 1. As opposed to the binary case, the latter result is not immediately implied by the former, since there are multi-label concept classes of dimension 1 that are not contained in maximum classes of dimension 1.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/samei14.pdf",
        "supp": "",
        "pdf_size": 375026,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15397566304181184289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Regina, Canada; Kurt G \u00a8odel Research Centre, Vienna, Austria + Department of Computer Science, University of Regina, Canada; Department of Computer Science, University of Regina, Canada; Department of Computer Science, University of Regina, Canada",
        "aff_domain": "CS.UREGINA.CA;UNIVIE.AC.AT;CS.UREGINA.CA;CS.UREGINA.CA",
        "email": "CS.UREGINA.CA;UNIVIE.AC.AT;CS.UREGINA.CA;CS.UREGINA.CA",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;0",
        "aff_unique_norm": "University of Regina;Kurt G\u00f6del Research Centre",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uregina.ca;",
        "aff_unique_abbr": "U of R;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Vienna",
        "aff_country_unique_index": "0;1+0;0;0",
        "aff_country_unique": "Canada;Austria"
    },
    {
        "id": "f7a5766ee1",
        "title": "Stochastic Regret Minimization via Thompson Sampling",
        "site": "https://proceedings.mlr.press/v35/guha14.html",
        "author": "Sudipto Guha; Kamesh Munagala",
        "abstract": "The Thompson Sampling (TS) policy  is a widely implemented algorithm for the stochastic multi-armed bandit (MAB) problem. Given a prior distribution over possible parameter settings of the underlying reward distributions of the arms, at each time instant, the policy plays an arm with probability equal to the probability that this arm has largest mean reward conditioned on the current posterior distributions of the arms.  This policy generalizes the celebrated \u201cprobability matching\u201d heuristic which has been experimentally and widely observed in human decision making. However, despite its ubiquity, the Thompson Sampling policy is poorly understood. Our goal in this paper is to make progress towards understanding the empirical success of this policy. We proceed using the lens of approximation algorithms and problem definitions from stochastic optimization. We focus on an objective function termed \\em stochastic regret that captures the expected number of times the policy plays an arm that is not the eventual best arm, where the expectation is over the prior distribution. Given such a definition, we show that TS is a 2\u2013approximation to the optimal decision policy in two extreme but canonical scenarios. One such scenario is the two-armed bandit problem which is used as a calibration point in all bandit literature. The second scenario is stochastic optimization where the outcome of a random variable is revealed in a single play to a high or low deterministic value. We show that the 2 approximation is tight in both these scenarios. We provide an uniform analysis framework that in theory is capable of proving our  conjecture that the TS policy is a 2\u2013approximation to the optimal decision policy for minimizing stochastic regret, for any prior distribution and any time horizon.",
        "bibtex": "@InProceedings{pmlr-v35-guha14,\n  title = \t {Stochastic Regret Minimization via Thompson Sampling},\n  author = \t {Guha, Sudipto and Munagala, Kamesh},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {317--338},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/guha14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/guha14.html},\n  abstract = \t {The Thompson Sampling (TS) policy  is a widely implemented algorithm for the stochastic multi-armed bandit (MAB) problem. Given a prior distribution over possible parameter settings of the underlying reward distributions of the arms, at each time instant, the policy plays an arm with probability equal to the probability that this arm has largest mean reward conditioned on the current posterior distributions of the arms.  This policy generalizes the celebrated \u201cprobability matching\u201d heuristic which has been experimentally and widely observed in human decision making. However, despite its ubiquity, the Thompson Sampling policy is poorly understood. Our goal in this paper is to make progress towards understanding the empirical success of this policy. We proceed using the lens of approximation algorithms and problem definitions from stochastic optimization. We focus on an objective function termed \\em stochastic regret that captures the expected number of times the policy plays an arm that is not the eventual best arm, where the expectation is over the prior distribution. Given such a definition, we show that TS is a 2\u2013approximation to the optimal decision policy in two extreme but canonical scenarios. One such scenario is the two-armed bandit problem which is used as a calibration point in all bandit literature. The second scenario is stochastic optimization where the outcome of a random variable is revealed in a single play to a high or low deterministic value. We show that the 2 approximation is tight in both these scenarios. We provide an uniform analysis framework that in theory is capable of proving our  conjecture that the TS policy is a 2\u2013approximation to the optimal decision policy for minimizing stochastic regret, for any prior distribution and any time horizon.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/guha14.pdf",
        "supp": "",
        "pdf_size": 365324,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16510624125484030289&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer and Information Sciences, University of Pennsylvania, Philadelphia, PA; Department of Computer Science, Duke University, Durham, NC 27708-0129",
        "aff_domain": "CIS.UPENN.EDU;CS.DUKE.EDU",
        "email": "CIS.UPENN.EDU;CS.DUKE.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Pennsylvania;Duke University",
        "aff_unique_dep": "Department of Computer and Information Sciences;Department of Computer Science",
        "aff_unique_url": "https://www.upenn.edu;https://www.duke.edu",
        "aff_unique_abbr": "UPenn;Duke",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Philadelphia;Durham",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9c3a93c753",
        "title": "The Complexity of Learning Halfspaces using Generalized Linear Methods",
        "site": "https://proceedings.mlr.press/v35/daniely14a.html",
        "author": "Amit Daniely; Nati Linial; Shai Shalev-Shwartz",
        "abstract": "Many popular learning algorithms (E.g. Regression, Fourier-Transform based algorithms, Kernel SVM and Kernel ridge regression) operate by reducing the problem to a convex optimization problem over a set of functions. These methods offer the currently best approach to several central problems such as learning half spaces and learning DNF\u2019s. In addition they are widely used in numerous application domains. Despite their importance, there are still very few proof techniques to show limits on the power of these algorithms. We study the performance of this approach in the problem of (agnostically and improperly) learning halfspaces with margin \u03b3. Let D be a distribution over labeled examples. The \u03b3-margin error of a hyperplane h is the probability of an example to fall on the wrong side of h or at a distance \\le\u03b3from it. The \u03b3-margin error of the best h is denoted \\mathrmErr_\u03b3(D).  An \u03b1(\u03b3)-approximation algorithm receives \u03b3,\u03b5as input and, using i.i.d. samples of D, outputs a classifier with error rate \\le \u03b1(\u03b3)\\mathrmErr_\u03b3(D) + \u03b5.  Such an algorithm is efficient if it uses \\mathrmpoly(\\frac1\u03b3,\\frac1\u03b5) samples and runs in time polynomial in the sample size. The best approximation ratio achievable by an efficient algorithm is O\\left(\\frac1/\u03b3\\sqrt\\log(1/\u03b3)\\right) and is achieved using an algorithm from the above class. Our main result shows that the approximation ratio of every efficient algorithm from this family must be \\ge \u03a9\\left(\\frac1/\u03b3\\mathrmpoly\\left(\\log\\left(1/\u03b3\\right)\\right)\\right), essentially matching the best known upper bound.",
        "bibtex": "@InProceedings{pmlr-v35-daniely14a,\n  title = \t {The Complexity of Learning Halfspaces using Generalized Linear Methods},\n  author = \t {Daniely, Amit and Linial, Nati and Shalev-Shwartz, Shai},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {244--286},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/daniely14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/daniely14a.html},\n  abstract = \t {Many popular learning algorithms (E.g. Regression, Fourier-Transform based algorithms, Kernel SVM and Kernel ridge regression) operate by reducing the problem to a convex optimization problem over a set of functions. These methods offer the currently best approach to several central problems such as learning half spaces and learning DNF\u2019s. In addition they are widely used in numerous application domains. Despite their importance, there are still very few proof techniques to show limits on the power of these algorithms. We study the performance of this approach in the problem of (agnostically and improperly) learning halfspaces with margin \u03b3. Let D be a distribution over labeled examples. The \u03b3-margin error of a hyperplane h is the probability of an example to fall on the wrong side of h or at a distance \\le\u03b3from it. The \u03b3-margin error of the best h is denoted \\mathrmErr_\u03b3(D).  An \u03b1(\u03b3)-approximation algorithm receives \u03b3,\u03b5as input and, using i.i.d. samples of D, outputs a classifier with error rate \\le \u03b1(\u03b3)\\mathrmErr_\u03b3(D) + \u03b5.  Such an algorithm is efficient if it uses \\mathrmpoly(\\frac1\u03b3,\\frac1\u03b5) samples and runs in time polynomial in the sample size. The best approximation ratio achievable by an efficient algorithm is O\\left(\\frac1/\u03b3\\sqrt\\log(1/\u03b3)\\right) and is achieved using an algorithm from the above class. Our main result shows that the approximation ratio of every efficient algorithm from this family must be \\ge \u03a9\\left(\\frac1/\u03b3\\mathrmpoly\\left(\\log\\left(1/\u03b3\\right)\\right)\\right), essentially matching the best known upper bound.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/daniely14a.pdf",
        "supp": "",
        "pdf_size": 596428,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8281558919895356943&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8779a7cb54",
        "title": "The Geometry of Losses",
        "site": "https://proceedings.mlr.press/v35/williamson14.html",
        "author": "Robert C. Williamson",
        "abstract": "Loss functions are central to machine learning because they are the means by which the quality of a prediction is evaluated. Any loss that is not proper, or can not be transformed to be proper via a link function is inadmissible. All admissible losses for n-class problems can be obtained in terms of a convex body in \\mathbbR^n.  We show this explicitly and show how some existing results simplify when viewed from this perspective.  This  allows the development of a rich algebra of losses induced by binary operations on convex bodies (that return a convex body).  Furthermore it allows us to define an \u201cinverse loss\u201d which provides a universal \u201csubstitution function\u201d for the Aggregating Algorithm.  In doing so we show a formal connection between proper losses and norms.",
        "bibtex": "@InProceedings{pmlr-v35-williamson14,\n  title = \t {The Geometry of Losses},\n  author = \t {Williamson, Robert C.},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1078--1108},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/williamson14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/williamson14.html},\n  abstract = \t {Loss functions are central to machine learning because they are the means by which the quality of a prediction is evaluated. Any loss that is not proper, or can not be transformed to be proper via a link function is inadmissible. All admissible losses for n-class problems can be obtained in terms of a convex body in \\mathbbR^n.  We show this explicitly and show how some existing results simplify when viewed from this perspective.  This  allows the development of a rich algebra of losses induced by binary operations on convex bodies (that return a convex body).  Furthermore it allows us to define an \u201cinverse loss\u201d which provides a universal \u201csubstitution function\u201d for the Aggregating Algorithm.  In doing so we show a formal connection between proper losses and norms. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/williamson14.pdf",
        "supp": "",
        "pdf_size": 2071274,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3137976438428535060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c348c98299",
        "title": "The More, the Merrier: the Blessing of Dimensionality for Learning Large Gaussian Mixtures",
        "site": "https://proceedings.mlr.press/v35/anderson14.html",
        "author": "Joseph Anderson; Mikhail Belkin; Navin Goyal; Luis Rademacher; James Voss",
        "abstract": "In this paper we show that very large mixtures of Gaussians are efficiently learnable in high dimension. More precisely, we prove that a mixture with known identical covariance matrices whose number of components is a polynomial of any fixed degree in the dimension n is polynomially learnable as long as a certain non-degeneracy condition on the means is satisfied. It turns out that this condition is generic in the sense of smoothed complexity, as soon as the dimensionality of the space is high enough. Moreover, we prove that no such condition can possibly exist in low dimension and the problem of learning the parameters is generically hard.  In contrast, much of the existing work on Gaussian Mixtures relies on low-dimensional projections and thus hits an artificial barrier. Our main result on mixture recovery relies on a new \u201cPoissonization\"-based technique, which transforms a mixture of Gaussians to a linear map of a product distribution. The problem of learning this map can be efficiently solved using some recent results on tensor decompositions and Independent Component Analysis (ICA), thus giving an  algorithm for recovering the mixture. In addition, we combine our low-dimensional hardness results for Gaussian mixtures with  Poissonization to show how to embed difficult instances of low-dimensional Gaussian mixtures into the ICA setting, thus establishing exponential information-theoretic lower bounds for underdetermined ICA in low dimension. To the best of our knowledge, this is the first such result  in the literature. In addition to contributing to  the problem of Gaussian mixture learning, we believe that this work is among the first steps toward better understanding the rare phenomenon of the \u201cblessing of dimensionality\" in the computational aspects of statistical inference.",
        "bibtex": "@InProceedings{pmlr-v35-anderson14,\n  title = \t {The More, the Merrier: the Blessing of Dimensionality for Learning Large Gaussian Mixtures},\n  author = \t {Anderson, Joseph and Belkin, Mikhail and Goyal, Navin and Rademacher, Luis and Voss, James},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1135--1164},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/anderson14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/anderson14.html},\n  abstract = \t {In this paper we show that very large mixtures of Gaussians are efficiently learnable in high dimension. More precisely, we prove that a mixture with known identical covariance matrices whose number of components is a polynomial of any fixed degree in the dimension n is polynomially learnable as long as a certain non-degeneracy condition on the means is satisfied. It turns out that this condition is generic in the sense of smoothed complexity, as soon as the dimensionality of the space is high enough. Moreover, we prove that no such condition can possibly exist in low dimension and the problem of learning the parameters is generically hard.  In contrast, much of the existing work on Gaussian Mixtures relies on low-dimensional projections and thus hits an artificial barrier. Our main result on mixture recovery relies on a new \u201cPoissonization\"-based technique, which transforms a mixture of Gaussians to a linear map of a product distribution. The problem of learning this map can be efficiently solved using some recent results on tensor decompositions and Independent Component Analysis (ICA), thus giving an  algorithm for recovering the mixture. In addition, we combine our low-dimensional hardness results for Gaussian mixtures with  Poissonization to show how to embed difficult instances of low-dimensional Gaussian mixtures into the ICA setting, thus establishing exponential information-theoretic lower bounds for underdetermined ICA in low dimension. To the best of our knowledge, this is the first such result  in the literature. In addition to contributing to  the problem of Gaussian mixture learning, we believe that this work is among the first steps toward better understanding the rare phenomenon of the \u201cblessing of dimensionality\" in the computational aspects of statistical inference. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/anderson14.pdf",
        "supp": "",
        "pdf_size": 405121,
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2354134984114851691&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Computer Science and Engineering, the Ohio State University; Department of Computer Science and Engineering, the Ohio State University; Microsoft Research India; Department of Computer Science and Engineering, the Ohio State University; Department of Computer Science and Engineering, the Ohio State University",
        "aff_domain": "CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU;MICROSOFT.COM;CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU",
        "email": "CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU;MICROSOFT.COM;CSE.OHIO-STATE.EDU;CSE.OHIO-STATE.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Ohio State University;Microsoft",
        "aff_unique_dep": "Department of Computer Science and Engineering;Microsoft Research India",
        "aff_unique_url": "https://www.osu.edu;https://www.microsoft.com/en-us/research/group/microsoft-research-india",
        "aff_unique_abbr": "OSU;MSR India",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "7c62e4d149",
        "title": "The sample complexity of agnostic learning under deterministic labels",
        "site": "https://proceedings.mlr.press/v35/ben-david14.html",
        "author": "Shai Ben-David; Ruth Urner",
        "abstract": "With the emergence of Machine Learning tools that allow handling data with a huge number of features, it becomes reasonable to assume that, over the full set of features, the true labeling is (almost) fully determined. That is, the labeling function is deterministic, but not necessarily a member of some known  hypothesis class. However, agnostic learning of deterministic labels has so far received little research attention. We investigate this setting and show that it displays a behavior that is quite different from that of the fundamental results of the common (PAC) learning setups. First, we show that the sample complexity of learning a binary hypothesis class (with respect to deterministic labeling functions) is not fully determined by the VC-dimension of the class. For any d, we present classes of VC-dimension d that are learnable from \\tilde O(d/\u03b5)-many samples and classes that require samples of size \u03a9(d/\u03b5^2). Furthermore, we show that in this setup, there are classes for which any proper learner has suboptimal sample complexity.  While the class can be learned with sample complexity \\tilde O(d/\u03b5), any \\emphproper (and therefore, any ERM) algorithm requires \u03a9(d/\u03b5^2) samples. We provide combinatorial characterizations of both phenomena, and further analyze the utility of unlabeled samples in this setting. Lastly, we discuss the error rates of nearest neighbor algorithms under deterministic labels and additional niceness-of-data assumptions.",
        "bibtex": "@InProceedings{pmlr-v35-ben-david14,\n  title = \t {The sample complexity of agnostic learning under deterministic labels},\n  author = \t {Ben-David, Shai and Urner, Ruth},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {527--542},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/ben-david14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/ben-david14.html},\n  abstract = \t {With the emergence of Machine Learning tools that allow handling data with a huge number of features, it becomes reasonable to assume that, over the full set of features, the true labeling is (almost) fully determined. That is, the labeling function is deterministic, but not necessarily a member of some known  hypothesis class. However, agnostic learning of deterministic labels has so far received little research attention. We investigate this setting and show that it displays a behavior that is quite different from that of the fundamental results of the common (PAC) learning setups. First, we show that the sample complexity of learning a binary hypothesis class (with respect to deterministic labeling functions) is not fully determined by the VC-dimension of the class. For any d, we present classes of VC-dimension d that are learnable from \\tilde O(d/\u03b5)-many samples and classes that require samples of size \u03a9(d/\u03b5^2). Furthermore, we show that in this setup, there are classes for which any proper learner has suboptimal sample complexity.  While the class can be learned with sample complexity \\tilde O(d/\u03b5), any \\emphproper (and therefore, any ERM) algorithm requires \u03a9(d/\u03b5^2) samples. We provide combinatorial characterizations of both phenomena, and further analyze the utility of unlabeled samples in this setting. Lastly, we discuss the error rates of nearest neighbor algorithms under deterministic labels and additional niceness-of-data assumptions.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/ben-david14.pdf",
        "supp": "",
        "pdf_size": 304289,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2411220377373996515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario N2L 3G1, CANADA; School of Computer Science, Georgia Institute of Technology, Atlanta, Georgia 30332, USA",
        "aff_domain": "UWATERLOO.CA;CC.GATECH.EDU",
        "email": "UWATERLOO.CA;CC.GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Waterloo;Georgia Institute of Technology",
        "aff_unique_dep": "Cheriton School of Computer Science;School of Computer Science",
        "aff_unique_url": "https://uwaterloo.ca;https://www.gatech.edu",
        "aff_unique_abbr": "UWaterloo;Georgia Tech",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Waterloo;Atlanta",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "81d2f6297a",
        "title": "Unconstrained Online Linear Learning in Hilbert Spaces: Minimax Algorithms and Normal Approximations",
        "site": "https://proceedings.mlr.press/v35/mcmahan14.html",
        "author": "H. Brendan McMahan; Francesco Orabona",
        "abstract": "We study algorithms for online linear optimization in Hilbert spaces, focusing on the case where the player is unconstrained.  We develop a novel characterization of a large class of minimax algorithms, recovering, and even improving, several previous results as immediate corollaries.  Moreover, using our tools, we develop an algorithm that provides a regret bound of O(U \\sqrtT \\log( U \\sqrtT \\log^2 T +1)), where U is the L_2 norm of an arbitrary comparator and both T and U are unknown to the player. This bound is optimal up to \\sqrt\\log \\log T terms.  When T is known, we derive an algorithm with an optimal regret bound (up to constant factors).  For both the known and unknown T case, a Normal approximation to the conditional value of the game proves to be the key analysis tool.",
        "bibtex": "@InProceedings{pmlr-v35-mcmahan14,\n  title = \t {Unconstrained Online Linear Learning in Hilbert Spaces: Minimax Algorithms and Normal Approximations},\n  author = \t {McMahan, H. Brendan and Orabona, Francesco},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {1020--1039},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/mcmahan14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/mcmahan14.html},\n  abstract = \t {We study algorithms for online linear optimization in Hilbert spaces, focusing on the case where the player is unconstrained.  We develop a novel characterization of a large class of minimax algorithms, recovering, and even improving, several previous results as immediate corollaries.  Moreover, using our tools, we develop an algorithm that provides a regret bound of O(U \\sqrtT \\log( U \\sqrtT \\log^2 T +1)), where U is the L_2 norm of an arbitrary comparator and both T and U are unknown to the player. This bound is optimal up to \\sqrt\\log \\log T terms.  When T is known, we derive an algorithm with an optimal regret bound (up to constant factors).  For both the known and unknown T case, a Normal approximation to the conditional value of the game proves to be the key analysis tool.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/mcmahan14.pdf",
        "supp": "",
        "pdf_size": 330883,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=868872675275356403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Google, Seattle, WA; Toyota Technological Institute at Chicago, Chicago, IL",
        "aff_domain": "GOOGLE.COM;ORABONA.COM",
        "email": "GOOGLE.COM;ORABONA.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Google;Toyota Technological Institute at Chicago",
        "aff_unique_dep": "Google;",
        "aff_unique_url": "https://www.google.com;https://www.tti-chicago.org",
        "aff_unique_abbr": "Google;TTI Chicago",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seattle;Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5d4b2287b9",
        "title": "Uniqueness of Ordinal Embedding",
        "site": "https://proceedings.mlr.press/v35/kleindessner14.html",
        "author": "Matth\u00e4us Kleindessner; Ulrike Luxburg",
        "abstract": "Ordinal embedding refers to the following problem: all we know about an unknown set of \t \t\tpoints x_1,\\ldots, x_n \u2208\\mathbbR^d are ordinal constraints of the form \\|x_i - x_j\\| < \\|x_k - x_l\\|; the task is to construct a realization y_1,\\ldots, y_n \u2208\\mathbbR^d that preserves these ordinal constraints. It has been conjectured since the 1960ies that upon knowledge of all ordinal constraints a large but finite set of points can be approximately reconstructed up to a similarity transformation. The main result of our paper is a formal proof of this conjecture.",
        "bibtex": "@InProceedings{pmlr-v35-kleindessner14,\n  title = \t {Uniqueness of Ordinal Embedding},\n  author = \t {Kleindessner, Matth\u00e4us and Luxburg, Ulrike},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {40--67},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/kleindessner14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/kleindessner14.html},\n  abstract = \t {Ordinal embedding refers to the following problem: all we know about an unknown set of \t \t\tpoints x_1,\\ldots, x_n \u2208\\mathbbR^d are ordinal constraints of the form \\|x_i - x_j\\| < \\|x_k - x_l\\|; the task is to construct a realization y_1,\\ldots, y_n \u2208\\mathbbR^d that preserves these ordinal constraints. It has been conjectured since the 1960ies that upon knowledge of all ordinal constraints a large but finite set of points can be approximately reconstructed up to a similarity transformation. The main result of our paper is a formal proof of this conjecture.}\n}",
        "pdf": "http://proceedings.mlr.press/v35/kleindessner14.pdf",
        "supp": "",
        "pdf_size": 689294,
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4784779138908518692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, University of Hamburg, Germany; Department of Computer Science, University of Hamburg, Germany",
        "aff_domain": "INFORMATIK.UNI-HAMBURG.DE;INFORMATIK.UNI-HAMBURG.DE",
        "email": "INFORMATIK.UNI-HAMBURG.DE;INFORMATIK.UNI-HAMBURG.DE",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Hamburg",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "232292b733",
        "title": "Uniqueness of Tensor Decompositions with Applications to Polynomial Identifiability",
        "site": "https://proceedings.mlr.press/v35/bhaskara14a.html",
        "author": "Aditya Bhaskara; Moses Charikar; Aravindan Vijayaraghavan",
        "abstract": "We give a robust version of the celebrated result of Kruskal on the uniqueness of tensor decompositions: given a tensor whose decomposition satisfies a robust form of Kruskal\u2019s rank condition, we prove that it is possible to approximately recover the decomposition if the tensor is known up to a sufficiently small (inverse polynomial) error. Kruskal\u2019s theorem has found many applications in proving the identifiability of parameters for various latent variable models and mixture models such as Hidden Markov models, topic models etc. Our robust version immediately implies identifiability using only polynomially many samples in many of these settings \u2013 an essential first step towards efficient learning algorithms. Our methods also apply to the \u201covercomplete\u201d case, which has proved challenging in many applications. Given the importance of Kruskal\u2019s theorem in the tensor literature, we expect that our robust version will have several applications beyond the settings we explore in this work.",
        "bibtex": "@InProceedings{pmlr-v35-bhaskara14a,\n  title = \t {Uniqueness of Tensor Decompositions with Applications to Polynomial Identifiability},\n  author = \t {Bhaskara, Aditya and Charikar, Moses and Vijayaraghavan, Aravindan},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {742--778},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/bhaskara14a.pdf},\n  url = \t {https://proceedings.mlr.press/v35/bhaskara14a.html},\n  abstract = \t {We give a robust version of the celebrated result of Kruskal on the uniqueness of tensor decompositions: given a tensor whose decomposition satisfies a robust form of Kruskal\u2019s rank condition, we prove that it is possible to approximately recover the decomposition if the tensor is known up to a sufficiently small (inverse polynomial) error. Kruskal\u2019s theorem has found many applications in proving the identifiability of parameters for various latent variable models and mixture models such as Hidden Markov models, topic models etc. Our robust version immediately implies identifiability using only polynomially many samples in many of these settings \u2013 an essential first step towards efficient learning algorithms. Our methods also apply to the \u201covercomplete\u201d case, which has proved challenging in many applications. Given the importance of Kruskal\u2019s theorem in the tensor literature, we expect that our robust version will have several applications beyond the settings we explore in this work. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/bhaskara14a.pdf",
        "supp": "",
        "pdf_size": 529894,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8715607782571304215&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Google Research NYC; Princeton University; Carnegie Mellon University",
        "aff_domain": "CS.PRINCETON.EDU;CS.PRINCETON.EDU;CS.PRINCETON.EDU",
        "email": "CS.PRINCETON.EDU;CS.PRINCETON.EDU;CS.PRINCETON.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Google;Princeton University;Carnegie Mellon University",
        "aff_unique_dep": "Google Research;;",
        "aff_unique_url": "https://research.google;https://www.princeton.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Google Research;Princeton;CMU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New York City;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9e43d1d350",
        "title": "Volumetric Spanners: an Efficient Exploration Basis for Learning",
        "site": "https://proceedings.mlr.press/v35/hazan14b.html",
        "author": "Elad Hazan; Zohar Karnin; Raghu Meka",
        "abstract": "Numerous machine learning problems require an \\it exploration basis - a mechanism to explore the action space. We define a novel geometric notion of exploration basis with low variance called volumetric spanners, and give efficient algorithms to construct such bases. We show how efficient volumetric spanners give rise to an efficient and near-optimal regret algorithm for bandit linear optimization over general convex sets. Previously such results were known only for specific convex sets, or under special conditions such as the existence of an efficient self-concordant barrier for the underlying set.",
        "bibtex": "@InProceedings{pmlr-v35-hazan14b,\n  title = \t {Volumetric Spanners: an Efficient Exploration Basis for Learning },\n  author = \t {Hazan, Elad and Karnin, Zohar and Meka, Raghu},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {408--422},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/hazan14b.pdf},\n  url = \t {https://proceedings.mlr.press/v35/hazan14b.html},\n  abstract = \t {Numerous machine learning problems require an \\it exploration basis - a mechanism to explore the action space. We define a novel geometric notion of exploration basis with low variance called volumetric spanners, and give efficient algorithms to construct such bases. We show how efficient volumetric spanners give rise to an efficient and near-optimal regret algorithm for bandit linear optimization over general convex sets. Previously such results were known only for specific convex sets, or under special conditions such as the existence of an efficient self-concordant barrier for the underlying set. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/hazan14b.pdf",
        "supp": "",
        "pdf_size": 308652,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9360251540133340106&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Technion - Israel Inst. of Tech.; Yahoo Labs; Microsoft Research",
        "aff_domain": "ie.technion.ac.il;ymail.com;microsoft.com",
        "email": "ie.technion.ac.il;ymail.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Technion - Israel Institute of Technology;Yahoo;Microsoft",
        "aff_unique_dep": ";Yahoo Labs;Microsoft Research",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://yahoo.com;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Technion;Yahoo;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "880fb5825c",
        "title": "lil\u2019 UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits",
        "site": "https://proceedings.mlr.press/v35/jamieson14.html",
        "author": "Kevin Jamieson; Matthew Malloy; Robert Nowak; S\u00e9bastien Bubeck",
        "abstract": "The paper proposes a novel upper confidence bound (UCB) procedure for identifying the arm with the largest mean in a multi-armed bandit game in the fixed confidence setting using a small number of total samples.  The procedure cannot be improved in the sense that the number of samples required to identify the best arm is within a constant factor of a lower bound based on the law of the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence bounds to explicitly account for the infinite time horizon of the algorithm. In addition, by using a novel stopping time for the algorithm we avoid a union bound over the arms that has been observed in other UCB-type algorithms. We prove that the algorithm is optimal up to constants and also show through simulations that it provides superior performance with respect to the state-of-the-art.",
        "bibtex": "@InProceedings{pmlr-v35-jamieson14,\n  title = \t {lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits},\n  author = \t {Jamieson, Kevin and Malloy, Matthew and Nowak, Robert and Bubeck, S\u00e9bastien},\n  booktitle = \t {Proceedings of The 27th Conference on Learning Theory},\n  pages = \t {423--439},\n  year = \t {2014},\n  editor = \t {Balcan, Maria Florina and Feldman, Vitaly and Szepesv\u00e1ri, Csaba},\n  volume = \t {35},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Barcelona, Spain},\n  month = \t {13--15 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v35/jamieson14.pdf},\n  url = \t {https://proceedings.mlr.press/v35/jamieson14.html},\n  abstract = \t {The paper proposes a novel upper confidence bound (UCB) procedure for identifying the arm with the largest mean in a multi-armed bandit game in the fixed confidence setting using a small number of total samples.  The procedure cannot be improved in the sense that the number of samples required to identify the best arm is within a constant factor of a lower bound based on the law of the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence bounds to explicitly account for the infinite time horizon of the algorithm. In addition, by using a novel stopping time for the algorithm we avoid a union bound over the arms that has been observed in other UCB-type algorithms. We prove that the algorithm is optimal up to constants and also show through simulations that it provides superior performance with respect to the state-of-the-art. }\n}",
        "pdf": "http://proceedings.mlr.press/v35/jamieson14.pdf",
        "supp": "",
        "pdf_size": 1409191,
        "gs_citation": 510,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17910731907045958521&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "University of Wisconsin; University of Wisconsin; University of Wisconsin; Princeton University",
        "aff_domain": "WISC.EDU;WISC.EDU;ECE.WISC.EDU;PRINCETON.EDU",
        "email": "WISC.EDU;WISC.EDU;ECE.WISC.EDU;PRINCETON.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Wisconsin;Princeton University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.princeton.edu",
        "aff_unique_abbr": "UW;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    }
]