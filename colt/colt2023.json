[
    {
        "id": "acb274065b",
        "title": "$\\ell_p$-Regression in the Arbitrary Partition Model of Communication",
        "site": "https://proceedings.mlr.press/v195/li23b.html",
        "author": "Yi Li; Honghao Lin; David Woodruff",
        "abstract": "We consider the randomized communication complexity of the distributed $\\ell_p$-regression problem in the coordinator model, for $p\\in (0,2]$. In this problem, there is a coordinator and $s$ servers. The $i$-th server receives $A^i\\in\\{-M, -M+1, \\ldots, M\\}^{n\\times d}$ and $b^i\\in\\{-M, -M+1, \\ldots, M\\}^n$ and the coordinator would like to find a $(1+\\eps)$-approximate solution to $\\min_{x\\in\\R^n} \\norm{(\\sum_i A^i)x - (\\sum_i b^i)}_p$. Here $M \\leq \\poly(nd)$ for convenience. This model, where the data is additively shared across servers, is commonly referred to as the arbitrary partition model.     We obtain significantly improved bounds for this problem. For $p = 2$, i.e., least squares regression, we give the first optimal bound of $\\tilde{\\Theta}(sd^2 + sd/\\epsilon)$ bits.     For $p \\in (1,2)$, we obtain an $\\tilde{O}(sd^2/\\eps + sd/\\poly(\\eps))$ upper bound. Notably, for $d$ sufficiently large, our leading order term only depends linearly on $1/\\epsilon$ rather than quadratically. We also show communication lower bounds of $\\Omega(sd^2 + sd/\\eps^2)$ for $p\\in (0,1]$ and $\\Omega(sd^2 + sd/\\eps)$ for $p\\in (1,2]$. Our bounds considerably improve previous bounds due to (Woodruff et al. COLT, 2013) and (Vempala et al., SODA, 2020).",
        "bibtex": "@InProceedings{pmlr-v195-li23b,\n  title = \t {$\\ell_p$-Regression in the Arbitrary Partition Model of Communication},\n  author =       {Li, Yi and Lin, Honghao and Woodruff, David},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4902--4928},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/li23b/li23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/li23b.html},\n  abstract = \t {We consider the randomized communication complexity of the distributed $\\ell_p$-regression problem in the coordinator model, for $p\\in (0,2]$. In this problem, there is a coordinator and $s$ servers. The $i$-th server receives $A^i\\in\\{-M, -M+1, \\ldots, M\\}^{n\\times d}$ and $b^i\\in\\{-M, -M+1, \\ldots, M\\}^n$ and the coordinator would like to find a $(1+\\eps)$-approximate solution to $\\min_{x\\in\\R^n} \\norm{(\\sum_i A^i)x - (\\sum_i b^i)}_p$. Here $M \\leq \\poly(nd)$ for convenience. This model, where the data is additively shared across servers, is commonly referred to as the arbitrary partition model.     We obtain significantly improved bounds for this problem. For $p = 2$, i.e., least squares regression, we give the first optimal bound of $\\tilde{\\Theta}(sd^2 + sd/\\epsilon)$ bits.     For $p \\in (1,2)$, we obtain an $\\tilde{O}(sd^2/\\eps + sd/\\poly(\\eps))$ upper bound. Notably, for $d$ sufficiently large, our leading order term only depends linearly on $1/\\epsilon$ rather than quadratically. We also show communication lower bounds of $\\Omega(sd^2 + sd/\\eps^2)$ for $p\\in (0,1]$ and $\\Omega(sd^2 + sd/\\eps)$ for $p\\in (1,2]$. Our bounds considerably improve previous bounds due to (Woodruff et al. COLT, 2013) and (Vempala et al., SODA, 2020). }\n}",
        "pdf": "https://proceedings.mlr.press/v195/li23b/li23b.pdf",
        "supp": "",
        "pdf_size": 464624,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13396810465770585859&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Nanyang Technological University; Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": "NTU.EDU.SG;ANDREW.CMU.EDU;ANDREW.CMU.EDU",
        "email": "NTU.EDU.SG;ANDREW.CMU.EDU;ANDREW.CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Nanyang Technological University;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.cmu.edu",
        "aff_unique_abbr": "NTU;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "8dc5e301c1",
        "title": "A Blackbox Approach to Best of Both Worlds in Bandits and Beyond",
        "site": "https://proceedings.mlr.press/v195/dann23a.html",
        "author": "Chris Dann; Chen-Yu Wei; Julian Zimmert",
        "abstract": "Best-of-both-worlds algorithms for online learning which achieve near-optimal regret in both the adversarial and the stochastic regimes have received growing attention recently. Existing techniques often require careful adaptation to every new problem setup, including specialized potentials and careful tuning of algorithm parameters. Yet, in domains such as linear bandits, it is still unknown if there exists an algorithm that can obtain $O(\\log(T))$ regret in the stochastic regime and $\\tilde{O}(\\sqrt{T})$ regret in the adversarial regime. In this work, we resolve this question positively and present a generally applicable reduction from best of both worlds to a wide family of follow-the-regularized-leader (FTRL) algorithms. We showcase the capability of this reduction by transforming existing algorithms that only achieve worst-case guarantees into new best-of-both-worlds algorithms in the setting of contextual bandits, graph bandits and tabular Markov decision processes.",
        "bibtex": "@InProceedings{pmlr-v195-dann23a,\n  title = \t {A Blackbox Approach to Best of Both Worlds in Bandits and Beyond},\n  author =       {Dann, Chris and Wei, Chen-Yu and Zimmert, Julian},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5503--5570},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/dann23a/dann23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/dann23a.html},\n  abstract = \t {Best-of-both-worlds algorithms for online learning which achieve near-optimal regret in both the adversarial and the stochastic regimes have received growing attention recently. Existing techniques often require careful adaptation to every new problem setup, including specialized potentials and careful tuning of algorithm parameters. Yet, in domains such as linear bandits, it is still unknown if there exists an algorithm that can obtain $O(\\log(T))$ regret in the stochastic regime and $\\tilde{O}(\\sqrt{T})$ regret in the adversarial regime. In this work, we resolve this question positively and present a generally applicable reduction from best of both worlds to a wide family of follow-the-regularized-leader (FTRL) algorithms. We showcase the capability of this reduction by transforming existing algorithms that only achieve worst-case guarantees into new best-of-both-worlds algorithms in the setting of contextual bandits, graph bandits and tabular Markov decision processes.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/dann23a/dann23a.pdf",
        "supp": "",
        "pdf_size": 688003,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10012082396331376240&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Google Research; MIT Institute for Data, Systems, and Society; Google Research",
        "aff_domain": "cdann.net;mit.edu;google.com",
        "email": "cdann.net;mit.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Google;Massachusetts Institute of Technology",
        "aff_unique_dep": "Google Research;Institute for Data, Systems, and Society",
        "aff_unique_url": "https://research.google;https://web.mit.edu",
        "aff_unique_abbr": "Google Research;MIT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Mountain View;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "57ee6ba80a",
        "title": "A High-dimensional Convergence Theorem for U-statistics with Applications to Kernel-based Testing",
        "site": "https://proceedings.mlr.press/v195/huang23a.html",
        "author": "Kevin H. Huang; Xing Liu; Andrew Duncan; Axel Gandy",
        "abstract": "We prove a convergence theorem for U-statistics of degree two, where the data dimension $d$ is allowed to scale with sample size $n$. We find that the limiting distribution of a U-statistic undergoes a phase transition from the non-degenerate Gaussian limit to the degenerate limit, regardless of its degeneracy and depending only on a moment ratio. A surprising consequence is that a non-degenerate U-statistic in high dimensions can have a non-Gaussian limit with a larger variance and asymmetric distribution. Our bounds are valid for any finite $n$ and $d$, independent of individual eigenvalues of the underlying function, and dimension-independent under a mild assumption. As an application, we apply our theory to two popular kernel-based distribution tests, MMD and KSD, whose high-dimensional performance has been challenging to study. In a simple empirical setting, our results correctly predict how the test power at a fixed threshold scales with $d$ and the bandwidth.",
        "bibtex": "@InProceedings{pmlr-v195-huang23a,\n  title = \t {A High-dimensional Convergence Theorem for U-statistics with Applications to Kernel-based Testing},\n  author =       {Huang, Kevin H. and Liu, Xing and Duncan, Andrew and Gandy, Axel},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3827--3918},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/huang23a/huang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/huang23a.html},\n  abstract = \t {We prove a convergence theorem for U-statistics of degree two, where the data dimension $d$ is allowed to scale with sample size $n$. We find that the limiting distribution of a U-statistic undergoes a phase transition from the non-degenerate Gaussian limit to the degenerate limit, regardless of its degeneracy and depending only on a moment ratio. A surprising consequence is that a non-degenerate U-statistic in high dimensions can have a non-Gaussian limit with a larger variance and asymmetric distribution. Our bounds are valid for any finite $n$ and $d$, independent of individual eigenvalues of the underlying function, and dimension-independent under a mild assumption. As an application, we apply our theory to two popular kernel-based distribution tests, MMD and KSD, whose high-dimensional performance has been challenging to study. In a simple empirical setting, our results correctly predict how the test power at a fixed threshold scales with $d$ and the bandwidth.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/huang23a/huang23a.pdf",
        "supp": "",
        "pdf_size": 3717340,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9961768699285516287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Gatsby Unit, University College London; Department of Mathematics, Imperial College London; Department of Mathematics, Imperial College London and Alan Turing Institute; Department of Mathematics, Imperial College London",
        "aff_domain": "UCL.AC.UK;IMPERIAL.AC.UK;IMPERIAL.AC.UK;IMPERIAL.AC.UK",
        "email": "UCL.AC.UK;IMPERIAL.AC.UK;IMPERIAL.AC.UK;IMPERIAL.AC.UK",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University College London;Imperial College London",
        "aff_unique_dep": "Gatsby Unit;Department of Mathematics",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "UCL;Imperial",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "78c7fd42e1",
        "title": "A Lower Bound for Linear and Kernel Regression with Adaptive Covariates",
        "site": "https://proceedings.mlr.press/v195/lattimore23b.html",
        "author": "Tor Lattimore",
        "abstract": "We prove that the continuous time version of the concentration bounds by Abbasi-Yadkori et al. (2011) for adaptive linear regression cannot be improved in general, showing that there can be a significant price for sequential design. This resolves the continuous time version of the COLT open problem by Vakili et al. (2021b) on confidence intervals for kernel regression with sequential designs. Experimental evidence suggests that improved confidence bounds are also not possible in discrete time.",
        "bibtex": "@InProceedings{pmlr-v195-lattimore23b,\n  title = \t {A Lower Bound for Linear and Kernel Regression with Adaptive Covariates},\n  author =       {Lattimore, Tor},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2095--2113},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/lattimore23b/lattimore23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/lattimore23b.html},\n  abstract = \t {We prove that the continuous time version of the concentration bounds by Abbasi-Yadkori et al. (2011) for adaptive linear regression cannot be improved in general, showing that there can be a significant price for sequential design. This resolves the continuous time version of the COLT open problem by Vakili et al. (2021b) on confidence intervals for kernel regression with sequential designs. Experimental evidence suggests that improved confidence bounds are also not possible in discrete time.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/lattimore23b/lattimore23b.pdf",
        "supp": "",
        "pdf_size": 329271,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17771256667804422711&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Google DeepMind, London",
        "aff_domain": "DEEPMIND.COM",
        "email": "DEEPMIND.COM",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google DeepMind",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9cfefc3d76",
        "title": "A Nearly Tight Bound for Fitting an Ellipsoid to Gaussian Random Points",
        "site": "https://proceedings.mlr.press/v195/kane23a.html",
        "author": "Daniel Kane; Ilias Diakonikolas",
        "abstract": "We prove that for $c>0$ a sufficiently small universal constant that a random set of $c d^2/\\log^4(d)$ independent Gaussian random points in $\\R^d$ lie on a common ellipsoid with high probability. This nearly establishes a conjecture of\u00a0\\citet{SaundersonCPW12}, within logarithmic factors.The latter conjecture has attracted significant attention over the past decade, dueto its connections to machine learning and sum-of-squares lower bounds for certain statistical problems.",
        "bibtex": "@InProceedings{pmlr-v195-kane23a,\n  title = \t {A Nearly Tight Bound for Fitting an Ellipsoid to Gaussian Random Points},\n  author =       {Kane, Daniel and Diakonikolas, Ilias},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3014--3028},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kane23a/kane23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kane23a.html},\n  abstract = \t {We prove that for $c>0$ a sufficiently small universal constant that a random set of $c d^2/\\log^4(d)$ independent Gaussian random points in $\\R^d$ lie on a common ellipsoid with high probability. This nearly establishes a conjecture of\u00a0\\citet{SaundersonCPW12}, within logarithmic factors.The latter conjecture has attracted significant attention over the past decade, dueto its connections to machine learning and sum-of-squares lower bounds for certain statistical problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/kane23a/kane23a.pdf",
        "supp": "",
        "pdf_size": 274736,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7992642149678334939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, San Diego; University of Wisconsin, Madison",
        "aff_domain": "CS.UCSD.EDU;CS.WISC.EDU",
        "email": "CS.UCSD.EDU;CS.WISC.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, San Diego;University of Wisconsin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsd.edu;https://www.wisc.edu",
        "aff_unique_abbr": "UCSD;UW",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "San Diego;Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4c9e689ae5",
        "title": "A Pretty Fast Algorithm for Adaptive Private Mean Estimation",
        "site": "https://proceedings.mlr.press/v195/kuditipudi23a.html",
        "author": "Rohith Kuditipudi; John Duchi; Saminul Haque",
        "abstract": "We design an $(\\varepsilon, \\delta)$-differentially private algorithm to estimate the mean of a $d$-variate distribution, with unknown covariance $\\Sigma$, that is adaptive to $\\Sigma$. To within polylogarithmic factors, the estimator achieves optimal rates of convergence with respect to the induced Mahalanobis norm $||\\cdot||_\\Sigma$, takes time $\\tilde{O}(n d^2)$ to compute, has near linear sample complexity for sub-Gaussian distributions, allows $\\Sigma$ to be degenerate or low rank, and adaptively extends beyond sub-Gaussianity. Prior to this work, other methods required exponential computation time or the superlinear scaling $n = \\Omega(d^{3/2})$ to achieve non-trivial error with respect to the norm $||\\cdot||_\\Sigma$.",
        "bibtex": "@InProceedings{pmlr-v195-kuditipudi23a,\n  title = \t {A Pretty Fast Algorithm for Adaptive Private Mean Estimation},\n  author =       {Kuditipudi, Rohith and Duchi, John and Haque, Saminul},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2511--2551},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kuditipudi23a/kuditipudi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kuditipudi23a.html},\n  abstract = \t {We design an $(\\varepsilon, \\delta)$-differentially private algorithm to estimate the mean of a $d$-variate distribution, with unknown covariance $\\Sigma$, that is adaptive to $\\Sigma$. To within polylogarithmic factors, the estimator achieves optimal rates of convergence with respect to the induced Mahalanobis norm $||\\cdot||_\\Sigma$, takes time $\\tilde{O}(n d^2)$ to compute, has near linear sample complexity for sub-Gaussian distributions, allows $\\Sigma$ to be degenerate or low rank, and adaptively extends beyond sub-Gaussianity. Prior to this work, other methods required exponential computation time or the superlinear scaling $n = \\Omega(d^{3/2})$ to achieve non-trivial error with respect to the norm $||\\cdot||_\\Sigma$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/kuditipudi23a/kuditipudi23a.pdf",
        "supp": "",
        "pdf_size": 685237,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9681741705459954772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Departments of Statistics and Electrical Engineering, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University",
        "aff_domain": "stanford.edu;stanford.edu;stanford.edu",
        "email": "stanford.edu;stanford.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d579c432c1",
        "title": "A Second-Order Method for Stochastic Bandit Convex Optimisation",
        "site": "https://proceedings.mlr.press/v195/lattimore23a.html",
        "author": "Tor Lattimore; Andr\u00e1s Gy\u00f6rgy",
        "abstract": "We introduce a simple and efficient algorithm for unconstrained zeroth-order stochastic convex bandits and prove its regret is at most (1 + r/d)[d^1.5 sqrt(n) + d^3] polylog(n, d, r) where n is the horizon, d the dimension and r is the radius of a known ball containing the minimiser of the loss.",
        "bibtex": "@InProceedings{pmlr-v195-lattimore23a,\n  title = \t {A Second-Order Method for Stochastic Bandit Convex Optimisation},\n  author =       {Lattimore, Tor and Gy{\\\"o}rgy, Andr{\\'a}s},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2067--2094},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/lattimore23a/lattimore23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/lattimore23a.html},\n  abstract = \t {We introduce a simple and efficient algorithm for unconstrained zeroth-order stochastic convex bandits and prove its regret is at most (1 + r/d)[d^1.5 sqrt(n) + d^3] polylog(n, d, r) where n is the horizon, d the dimension and r is the radius of a known ball containing the minimiser of the loss.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/lattimore23a/lattimore23a.pdf",
        "supp": "",
        "pdf_size": 404670,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15826566485688169103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Google DeepMind, London; Google DeepMind, London",
        "aff_domain": "GOOGLE.COM;GOOGLE.COM",
        "email": "GOOGLE.COM;GOOGLE.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google DeepMind",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "f41e6a923c",
        "title": "A Unified Analysis of Nonstochastic Delayed Feedback for Combinatorial Semi-Bandits, Linear Bandits, and MDPs",
        "site": "https://proceedings.mlr.press/v195/hoeven23a.html",
        "author": "Dirk van der Hoeven; Lukas Zierahn; Tal Lancewicki; Aviv Rosenberg; Nicol\u00f2 Cesa-Bianchi",
        "abstract": "We derive a new analysis of Follow The Regularized Leader (FTRL) for online learning with delayed bandit feedback. By separating the cost of delayed feedback from that of bandit feedback, our analysis allows us to obtain new results in three important settings. On the one hand, we derive the first optimal (up to logarithmic factors) regret bounds for combinatorial semi-bandits with delay and adversarial Markov decision processes with delay (and known transition functions).   On the other hand, we use our analysis to derive an efficient algorithm for linear bandits with delay achieving near-optimal regret bounds. Our novel regret decomposition shows that FTRL remains stable across multiple rounds under mild assumptions on the Hessian of the regularizer.",
        "bibtex": "@InProceedings{pmlr-v195-hoeven23a,\n  title = \t {A Unified Analysis of Nonstochastic Delayed Feedback for Combinatorial Semi-Bandits, Linear Bandits, and MDPs},\n  author =       {van der Hoeven, Dirk and Zierahn, Lukas and Lancewicki, Tal and Rosenberg, Aviv and Cesa-Bianchi, Nicol{\\`o}},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1285--1321},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hoeven23a/hoeven23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hoeven23a.html},\n  abstract = \t {We derive a new analysis of Follow The Regularized Leader (FTRL) for online learning with delayed bandit feedback. By separating the cost of delayed feedback from that of bandit feedback, our analysis allows us to obtain new results in three important settings. On the one hand, we derive the first optimal (up to logarithmic factors) regret bounds for combinatorial semi-bandits with delay and adversarial Markov decision processes with delay (and known transition functions).   On the other hand, we use our analysis to derive an efficient algorithm for linear bandits with delay achieving near-optimal regret bounds. Our novel regret decomposition shows that FTRL remains stable across multiple rounds under mild assumptions on the Hessian of the regularizer.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hoeven23a/hoeven23a.pdf",
        "supp": "",
        "pdf_size": 484906,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2152097594243481449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Korteweg-de Vries Institute for Mathematics, University of Amsterdam, The Netherlands; Universit\u00e0 degli Studi di Milano, Italy; Blavatnik School of Computer Science, Tel Aviv University, Israel; Amazon Science; Universit\u00e0 degli Studi di Milano and Politecnico di Milano, Italy",
        "aff_domain": "dirkvanderhoeven.com;gmail.com;mail.tau.ac.il;gmail.com;unimi.it",
        "email": "dirkvanderhoeven.com;gmail.com;mail.tau.ac.il;gmail.com;unimi.it",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;1",
        "aff_unique_norm": "University of Amsterdam;Universit\u00e0 degli Studi di Milano;Tel Aviv University;Amazon",
        "aff_unique_dep": "Korteweg-de Vries Institute for Mathematics;;Blavatnik School of Computer Science;Amazon Science",
        "aff_unique_url": "https://www.uva.nl;https://www.unimi.it;https://www.tau.ac.il;https://www.amazon.science",
        "aff_unique_abbr": ";UniMi;TAU;Amazon Science",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tel Aviv",
        "aff_country_unique_index": "0;1;2;3;1",
        "aff_country_unique": "Netherlands;Italy;Israel;United States"
    },
    {
        "id": "62cc92fd42",
        "title": "A new ranking scheme for modern data and its application to two-sample hypothesis testing",
        "site": "https://proceedings.mlr.press/v195/zhou23a.html",
        "author": "Doudou Zhou; Hao Chen",
        "abstract": "Rank-based approaches are among the most popular nonparametric methods for univariate data in tackling statistical problems such as hypothesis testing due to their robustness and effectiveness. However, they are unsatisfactory for more complex data. In the era of big data, high-dimensional and non-Euclidean data, such as networks and images, are ubiquitous and pose challenges for statistical analysis. Existing multivariate ranks such as component-wise, spatial, and depth-based ranks do not apply to non-Euclidean data and have limited performance for high-dimensional data. Instead of dealing with the ranks of observations, we propose two types of ranks applicable to complex data based on a similarity graph constructed on observations: a graph-induced rank defined by the inductive nature of the graph and an overall rank defined by the weight of edges in the graph. To illustrate their utilization, both the new ranks are used to construct test statistics for the two-sample hypothesis testing, which converge to the $\\chi_2^2$ distribution under the permutation null distribution and some mild conditions of the ranks, enabling an easy type-I error control. Simulation studies show that the new method exhibits good power under a wide range of alternatives compared to existing methods. The new test is illustrated on the New York City taxi data for comparing travel patterns in consecutive months and a brain network dataset comparing male and female subjects.",
        "bibtex": "@InProceedings{pmlr-v195-zhou23a,\n  title = \t {A new ranking scheme for modern data and its application to two-sample hypothesis testing},\n  author =       {Zhou, Doudou and Chen, Hao},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3615--3668},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/zhou23a/zhou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/zhou23a.html},\n  abstract = \t {Rank-based approaches are among the most popular nonparametric methods for univariate data in tackling statistical problems such as hypothesis testing due to their robustness and effectiveness. However, they are unsatisfactory for more complex data. In the era of big data, high-dimensional and non-Euclidean data, such as networks and images, are ubiquitous and pose challenges for statistical analysis. Existing multivariate ranks such as component-wise, spatial, and depth-based ranks do not apply to non-Euclidean data and have limited performance for high-dimensional data. Instead of dealing with the ranks of observations, we propose two types of ranks applicable to complex data based on a similarity graph constructed on observations: a graph-induced rank defined by the inductive nature of the graph and an overall rank defined by the weight of edges in the graph. To illustrate their utilization, both the new ranks are used to construct test statistics for the two-sample hypothesis testing, which converge to the $\\chi_2^2$ distribution under the permutation null distribution and some mild conditions of the ranks, enabling an easy type-I error control. Simulation studies show that the new method exhibits good power under a wide range of alternatives compared to existing methods. The new test is illustrated on the New York City taxi data for comparing travel patterns in consecutive months and a brain network dataset comparing male and female subjects.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/zhou23a/zhou23a.pdf",
        "supp": "",
        "pdf_size": 1273558,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2966799964790177312&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, Davis; University of California, Davis",
        "aff_domain": "ucdavis.edu;ucdavis.edu",
        "email": "ucdavis.edu;ucdavis.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Davis",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Davis",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Davis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8d8474f75a",
        "title": "Accelerated Riemannian Optimization: Handling Constraints with a Prox to Bound Geometric Penalties",
        "site": "https://proceedings.mlr.press/v195/martinez-rubio23a.html",
        "author": "David Mart\u00ednez-Rubio; Sebastian Pokutta",
        "abstract": "We propose a globally-accelerated, first-order method for the optimization of smooth and (strongly or not) geodesically-convex functions in a wide class of Hadamard manifolds. We achieve the same convergence rates as Nesterov\u2019s accelerated gradient descent, up to a multiplicative geometric penalty and log factors.  Crucially, we can enforce our method to stay within a compact set we define. Prior fully accelerated works \\emph{resort to assuming} that the iterates of their algorithms stay in some pre-specified compact set, except for two previous methods of limited applicability. For our manifolds, this solves the open question in (Kim and Yang, 2022) about obtaining global general acceleration without iterates assumptively staying in the feasible set.In our solution, we design an accelerated Riemannian inexact proximal point algorithm, which is a result that was unknown even with exact access to the proximal operator, and is of independent interest. For smooth functions, we show we can implement the prox step inexactly with first-order methods in Riemannian balls of certain diameter that is enough for global accelerated optimization.",
        "bibtex": "@InProceedings{pmlr-v195-martinez-rubio23a,\n  title = \t {Accelerated Riemannian Optimization: Handling Constraints with a Prox to Bound Geometric Penalties},\n  author =       {Mart{\\'i}nez-Rubio, David and Pokutta, Sebastian},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {359--393},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/martinez-rubio23a/martinez-rubio23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/martinez-rubio23a.html},\n  abstract = \t {We propose a globally-accelerated, first-order method for the optimization of smooth and (strongly or not) geodesically-convex functions in a wide class of Hadamard manifolds. We achieve the same convergence rates as Nesterov\u2019s accelerated gradient descent, up to a multiplicative geometric penalty and log factors.  Crucially, we can enforce our method to stay within a compact set we define. Prior fully accelerated works \\emph{resort to assuming} that the iterates of their algorithms stay in some pre-specified compact set, except for two previous methods of limited applicability. For our manifolds, this solves the open question in (Kim and Yang, 2022) about obtaining global general acceleration without iterates assumptively staying in the feasible set.In our solution, we design an accelerated Riemannian inexact proximal point algorithm, which is a result that was unknown even with exact access to the proximal operator, and is of independent interest. For smooth functions, we show we can implement the prox step inexactly with first-order methods in Riemannian balls of certain diameter that is enough for global accelerated optimization.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/martinez-rubio23a/martinez-rubio23a.pdf",
        "supp": "",
        "pdf_size": 489455,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7684116023378407718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Zuse Institute Berlin and Technische Universit\u00e4t Berlin, Germany; Zuse Institute Berlin and Technische Universit\u00e4t Berlin, Germany",
        "aff_domain": "ZIB.DE;ZIB.DE",
        "email": "ZIB.DE;ZIB.DE",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Zuse Institute Berlin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.zib.de",
        "aff_unique_abbr": "ZIB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "ff29118756",
        "title": "Accelerated and Sparse Algorithms for Approximate Personalized PageRank and Beyond",
        "site": "https://proceedings.mlr.press/v195/martinez-rubio23b.html",
        "author": "David Mart\u00ednez-Rubio; Elias Wirth; Sebastian Pokutta",
        "abstract": "It has recently been shown that ISTA, an unaccelerated optimization method, presents sparse updates for the $\\ell_1$-regularized undirected personalized PageRank problem (Fountoulakis et al., 2019), leading to cheap iteration complexity and providing the same guarantees as the approximate personalized PageRank algorithm (\\appr{}), (Andersen et al., 2016).      In this work, we design an accelerated optimization algorithm for this problem that also performs sparse updates, providing an affirmative answer to the COLT 2022 open question of (Fountoulakis et al., 2022).  Acceleration provides a reduced dependence on the condition number, while the dependence on the sparsity in our updates differs from the ISTA approach.      Further, we design another algorithm by using conjugate directions to achieve an exact solution while exploiting sparsity. Both algorithms lead to faster convergence for certain parameter regimes. Our findings apply beyond PageRank and work for any quadratic objective whose Hessian is a positive-definite $M$-matrix.",
        "bibtex": "@InProceedings{pmlr-v195-martinez-rubio23b,\n  title = \t {Accelerated and Sparse Algorithms for Approximate Personalized PageRank and Beyond},\n  author =       {Mart{\\'i}nez-Rubio, David and Wirth, Elias and Pokutta, Sebastian},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2852--2876},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/martinez-rubio23b/martinez-rubio23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/martinez-rubio23b.html},\n  abstract = \t {     It has recently been shown that ISTA, an unaccelerated optimization method, presents sparse updates for the $\\ell_1$-regularized undirected personalized PageRank problem (Fountoulakis et al., 2019), leading to cheap iteration complexity and providing the same guarantees as the approximate personalized PageRank algorithm (\\appr{}), (Andersen et al., 2016).      In this work, we design an accelerated optimization algorithm for this problem that also performs sparse updates, providing an affirmative answer to the COLT 2022 open question of (Fountoulakis et al., 2022).  Acceleration provides a reduced dependence on the condition number, while the dependence on the sparsity in our updates differs from the ISTA approach.      Further, we design another algorithm by using conjugate directions to achieve an exact solution while exploiting sparsity. Both algorithms lead to faster convergence for certain parameter regimes. Our findings apply beyond PageRank and work for any quadratic objective whose Hessian is a positive-definite $M$-matrix.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/martinez-rubio23b/martinez-rubio23b.pdf",
        "supp": "",
        "pdf_size": 380447,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14132853577287791772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Institute of Mathematics, Berlin Institute of Technology, Berlin, Germany; Institute of Mathematics, Berlin Institute of Technology, Berlin, Germany; Institute of Mathematics, Berlin Institute of Technology, Berlin, Germany",
        "aff_domain": "ZIB.DE;MATH.TU-BERLIN.DE;ZIB.DE",
        "email": "ZIB.DE;MATH.TU-BERLIN.DE;ZIB.DE",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Berlin Institute of Technology",
        "aff_unique_dep": "Institute of Mathematics",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "006b869b00",
        "title": "Active Coverage for PAC Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v195/al-marjani23a.html",
        "author": "Aymen Al-Marjani; Andrea Tirinzoni; Emilie Kaufmann",
        "abstract": "Collecting and leveraging data with good coverage properties plays a crucial role in different aspects of reinforcement learning (RL), including reward-free exploration and offline learning.   However, the notion of \u201cgood coverage\u201d really depends on the application at hand, as data suitable for one context may not be so for another.   In this paper, we formalize the problem of \\emph{active coverage} in episodic Markov decision processes (MDPs), where the goal is to interact with the environment so as to fulfill given sampling requirements.   This framework is sufficiently flexible to specify any desired coverage property, making it applicable to any problem that involves online exploration.   Our main contribution is an \\emph{instance-dependent} lower bound on the sample complexity of active coverage and a simple game-theoretic algorithm, CovGame, that nearly matches it. We then show that CovGame can be used as a building block to solve different PAC RL tasks. In particular, we obtain a simple algorithm for PAC reward-free exploration with an instance-dependent sample complexity that, in certain MDPs which are \u201ceasy to explore\u201d, is lower than the minimax one.   By further coupling this exploration algorithm with a new technique to do implicit eliminations in policy space, we obtain a computationally-efficient algorithm for best-policy identification whose instance-dependent sample complexity scales with gaps between policy values.",
        "bibtex": "@InProceedings{pmlr-v195-al-marjani23a,\n  title = \t {Active Coverage for PAC Reinforcement Learning},\n  author =       {Al-Marjani, Aymen and Tirinzoni, Andrea and Kaufmann, Emilie},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5044--5109},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/al-marjani23a/al-marjani23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/al-marjani23a.html},\n  abstract = \t { Collecting and leveraging data with good coverage properties plays a crucial role in different aspects of reinforcement learning (RL), including reward-free exploration and offline learning.   However, the notion of \u201cgood coverage\u201d really depends on the application at hand, as data suitable for one context may not be so for another.   In this paper, we formalize the problem of \\emph{active coverage} in episodic Markov decision processes (MDPs), where the goal is to interact with the environment so as to fulfill given sampling requirements.   This framework is sufficiently flexible to specify any desired coverage property, making it applicable to any problem that involves online exploration.   Our main contribution is an \\emph{instance-dependent} lower bound on the sample complexity of active coverage and a simple game-theoretic algorithm, CovGame, that nearly matches it. We then show that CovGame can be used as a building block to solve different PAC RL tasks. In particular, we obtain a simple algorithm for PAC reward-free exploration with an instance-dependent sample complexity that, in certain MDPs which are \u201ceasy to explore\u201d, is lower than the minimax one.   By further coupling this exploration algorithm with a new technique to do implicit eliminations in policy space, we obtain a computationally-efficient algorithm for best-policy identification whose instance-dependent sample complexity scales with gaps between policy values. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/al-marjani23a/al-marjani23a.pdf",
        "supp": "",
        "pdf_size": 612892,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7006256420909414493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "UMPA, ENS Lyon, Lyon, France; Meta AI, Paris, France; Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 - CRIStAL, Lille, France",
        "aff_domain": "ens-lyon.fr;meta.com;univ-lille.fr",
        "email": "ens-lyon.fr;meta.com;univ-lille.fr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "\u00c9cole Normale Sup\u00e9rieure de Lyon;Meta;University of Lille",
        "aff_unique_dep": "UMPA (Unit\u00e9 de Math\u00e9matiques Pures et Appliqu\u00e9es);Meta AI;UMR 9189 - CRIStAL",
        "aff_unique_url": "https://www.ens-lyon.fr;https://meta.ai;https://www.univ-lille.fr",
        "aff_unique_abbr": "ENS Lyon;Meta AI;Univ. Lille",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Lyon;Paris;Lille",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "399781dc6c",
        "title": "Algorithmic Aspects of the Log-Laplace Transform and a Non-Euclidean Proximal Sampler",
        "site": "https://proceedings.mlr.press/v195/gopi23a.html",
        "author": "Sivakanth Gopi; Yin Tat Lee; Daogao Liu; Ruoqi Shen; Kevin Tian",
        "abstract": "The development of efficient sampling algorithms catering to non-Euclidean geometries has been a challenging endeavor, as discretization techniques which succeed in the Euclidean setting do not readily carry over to more general settings. We develop a non-Euclidean analog of the recent proximal sampler of [LST21], which naturally induces regularization by an object known as the log-Laplace transform (LLT) of a density. We prove new mathematical properties (with an algorithmic flavor) of the LLT, such as strong convexity-smoothness duality and an isoperimetric inequality, which are used to prove a mixing time on our proximal sampler matching [LST21] under a warm start. As our main application, we show our warm-started sampler improves the value oracle complexity of differentially private convex optimization in $\\ell_p$ and Schatten-$p$ norms for $p \\in [1, 2]$ to match the Euclidean setting [GLL22], while retaining state-of-the-art excess risk bounds [GLLST23]. We find our investigation of the LLT to be a promising proof-of-concept of its utility as a tool for designing samplers, and outline directions for future exploration.",
        "bibtex": "@InProceedings{pmlr-v195-gopi23a,\n  title = \t {Algorithmic Aspects of the Log-Laplace Transform and a Non-Euclidean Proximal Sampler},\n  author =       {Gopi, Sivakanth and Lee, Yin Tat and Liu, Daogao and Shen, Ruoqi and Tian, Kevin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2399--2439},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gopi23a/gopi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gopi23a.html},\n  abstract = \t {The development of efficient sampling algorithms catering to non-Euclidean geometries has been a challenging endeavor, as discretization techniques which succeed in the Euclidean setting do not readily carry over to more general settings. We develop a non-Euclidean analog of the recent proximal sampler of [LST21], which naturally induces regularization by an object known as the log-Laplace transform (LLT) of a density. We prove new mathematical properties (with an algorithmic flavor) of the LLT, such as strong convexity-smoothness duality and an isoperimetric inequality, which are used to prove a mixing time on our proximal sampler matching [LST21] under a warm start. As our main application, we show our warm-started sampler improves the value oracle complexity of differentially private convex optimization in $\\ell_p$ and Schatten-$p$ norms for $p \\in [1, 2]$ to match the Euclidean setting [GLL22], while retaining state-of-the-art excess risk bounds [GLLST23]. We find our investigation of the LLT to be a promising proof-of-concept of its utility as a tool for designing samplers, and outline directions for future exploration.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/gopi23a/gopi23a.pdf",
        "supp": "",
        "pdf_size": 501981,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15603713540502675673&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft Research; Microsoft Research; University of Washington; University of Washington; Microsoft Research",
        "aff_domain": "microsoft.com;microsoft.com;uw.edu;cs.washington.edu;microsoft.com",
        "email": "microsoft.com;microsoft.com;uw.edu;cs.washington.edu;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Microsoft;University of Washington",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.washington.edu",
        "aff_unique_abbr": "MSR;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fb021d480b",
        "title": "Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs",
        "site": "https://proceedings.mlr.press/v195/derezinski23a.html",
        "author": "Micha\u0142 Derezi\u0144ski",
        "abstract": "Algorithmic Gaussianization is a phenomenon that can arise when using randomized sketching or sampling methods to produce smaller representations of large datasets: For certain tasks, these sketched representations have been observed to exhibit many robust performance characteristics that are known to occur when a data sample comes from a sub-gaussian random design, which is a powerful statistical model of data distributions. However, this phenomenon has only been studied for specific tasks and metrics, or by relying on computationally expensive methods. We address this by providing an algorithmic framework for gaussianizing data using sparse sketching operators, proving that it is possible to efficiently construct data sketches that are nearly indistinguishable (in terms of total variation distance) from sub-gaussian random designs. In particular, relying on a recently introduced sketching technique called Leverage Score Sparsified (LESS) embeddings, we show that one can construct an $n\\times d$ sketch of an$N\\times d$ matrix $A$, where $n\\ll N$, that is nearly indistinguishable from a sub-gaussian design, in time $O(\\mathrm{nnz}(A)\\log N + nd^2)$, where $\\mathrm{nnz}(A)$ is the number of non-zero entries in $A$. As a consequence, strong statistical guarantees and precise asymptotics available for the estimators produced from sub-gaussian designs (e.g., for least squares and Lasso regression, covariance estimation, low-rank approximation, etc.) can be straightforwardly adapted to our sketching framework. We illustrate this with a new approximation guarantee for sketched least squares, among other examples. The key technique that enables our analysis is a novel variant of the Hanson-Wright inequality on the concentration of random quadratic forms, which we establish for random vectors that arise from sparse sketches.",
        "bibtex": "@InProceedings{pmlr-v195-derezinski23a,\n  title = \t {Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs},\n  author =       {Derezi{\\'n}ski, Micha{\\l}},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3137--3172},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/derezinski23a/derezinski23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/derezinski23a.html},\n  abstract = \t {Algorithmic Gaussianization is a phenomenon that can arise when using randomized sketching or sampling methods to produce smaller representations of large datasets: For certain tasks, these sketched representations have been observed to exhibit many robust performance characteristics that are known to occur when a data sample comes from a sub-gaussian random design, which is a powerful statistical model of data distributions. However, this phenomenon has only been studied for specific tasks and metrics, or by relying on computationally expensive methods. We address this by providing an algorithmic framework for gaussianizing data using sparse sketching operators, proving that it is possible to efficiently construct data sketches that are nearly indistinguishable (in terms of total variation distance) from sub-gaussian random designs. In particular, relying on a recently introduced sketching technique called Leverage Score Sparsified (LESS) embeddings, we show that one can construct an $n\\times d$ sketch of an$N\\times d$ matrix $A$, where $n\\ll N$, that is nearly indistinguishable from a sub-gaussian design, in time $O(\\mathrm{nnz}(A)\\log N + nd^2)$, where $\\mathrm{nnz}(A)$ is the number of non-zero entries in $A$. As a consequence, strong statistical guarantees and precise asymptotics available for the estimators produced from sub-gaussian designs (e.g., for least squares and Lasso regression, covariance estimation, low-rank approximation, etc.) can be straightforwardly adapted to our sketching framework. We illustrate this with a new approximation guarantee for sketched least squares, among other examples. The key technique that enables our analysis is a novel variant of the Hanson-Wright inequality on the concentration of random quadratic forms, which we establish for random vectors that arise from sparse sketches.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/derezinski23a/derezinski23a.pdf",
        "supp": "",
        "pdf_size": 907188,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5185010980696574294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Michigan",
        "aff_domain": "UMICH.EDU",
        "email": "UMICH.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "697ca02bc4",
        "title": "Algorithmically Effective Differentially Private Synthetic Data",
        "site": "https://proceedings.mlr.press/v195/he23a.html",
        "author": "Yiyun He; Roman Vershynin; Yizhe Zhu",
        "abstract": "We present a highly effective algorithmic approach for generating $\\varepsilon$-differentially private synthetic data in a bounded metric space with near-optimal utility guarantees under the  1-Wasserstein distance. In particular, for a dataset $\\mathcal X$ in the hypercube $[0,1]^d$, our algorithm generates synthetic dataset $\\mathcal Y$ such that the expected 1-Wasserstein distance between the empirical measure of $\\mathcal X$ and $\\mathcal Y$ is $O((\\varepsilon n)^{-1/d})$ for $d\\geq 2$, and is $O(\\log^2(\\varepsilon n)(\\varepsilon n)^{-1})$ for $d=1$. The accuracy guarantee is optimal up to a constant factor for $d\\geq 2$, and up to a logarithmic factor for $d=1$. Our algorithm has a fast running time of $O(\\varepsilon d n)$ for all $d\\geq 1$ and demonstrates improved accuracy compared to the method in Boedihardjo et al. (2022) for $d\\geq 2$.",
        "bibtex": "@InProceedings{pmlr-v195-he23a,\n  title = \t {Algorithmically Effective Differentially Private Synthetic Data},\n  author =       {He, Yiyun and Vershynin, Roman and Zhu, Yizhe},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3941--3968},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/he23a/he23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/he23a.html},\n  abstract = \t {We present a highly effective algorithmic approach for generating $\\varepsilon$-differentially private synthetic data in a bounded metric space with near-optimal utility guarantees under the  1-Wasserstein distance. In particular, for a dataset $\\mathcal X$ in the hypercube $[0,1]^d$, our algorithm generates synthetic dataset $\\mathcal Y$ such that the expected 1-Wasserstein distance between the empirical measure of $\\mathcal X$ and $\\mathcal Y$ is $O((\\varepsilon n)^{-1/d})$ for $d\\geq 2$, and is $O(\\log^2(\\varepsilon n)(\\varepsilon n)^{-1})$ for $d=1$. The accuracy guarantee is optimal up to a constant factor for $d\\geq 2$, and up to a logarithmic factor for $d=1$. Our algorithm has a fast running time of $O(\\varepsilon d n)$ for all $d\\geq 1$ and demonstrates improved accuracy compared to the method in Boedihardjo et al. (2022) for $d\\geq 2$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/he23a/he23a.pdf",
        "supp": "",
        "pdf_size": 358880,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1483855863085686816&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Irvine; University of California, Irvine; University of California, Irvine",
        "aff_domain": "uci.edu;uci.edu;uci.edu",
        "email": "uci.edu;uci.edu;uci.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Irvine",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uci.edu",
        "aff_unique_abbr": "UCI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Irvine",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "829092bcca",
        "title": "Allocating Divisible Resources on Arms with Unknown and Random Rewards",
        "site": "https://proceedings.mlr.press/v195/li23a.html",
        "author": "Wenhao Li; Ningyuan Chen",
        "abstract": "We consider a decision maker allocating one unit of renewable and divisible resource in each period on a number of arms. The arms have unknown and random rewards whose means are proportional to the allocated resource and whose variances are proportional to an order $b$ of the allocated resource. When the order ranges from 0 to 1, the framework smoothly bridges the standard stochastic multi-armed bandit and online learning with full feedback. We design two algorithms that attain the optimal gap-dependent and gap-independent regret bounds for $b\\in [0,1]$, and demonstrate a phase transition at $b=1/2$. The theoretical results hinge on a novel concentration inequality we have developed that bounds a linear combination of sub-Gaussian random variables whose weights are fractional, adapted to the filtration, and monotonic.",
        "bibtex": "@InProceedings{pmlr-v195-li23a,\n  title = \t {Allocating Divisible Resources on Arms with Unknown and Random Rewards},\n  author =       {Li, Wenhao and Chen, Ningyuan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2350--2351},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/li23a/li23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/li23a.html},\n  abstract = \t {We consider a decision maker allocating one unit of renewable and divisible resource in each period on a number of arms. The arms have unknown and random rewards whose means are proportional to the allocated resource and whose variances are proportional to an order $b$ of the allocated resource. When the order ranges from 0 to 1, the framework smoothly bridges the standard stochastic multi-armed bandit and online learning with full feedback. We design two algorithms that attain the optimal gap-dependent and gap-independent regret bounds for $b\\in [0,1]$, and demonstrate a phase transition at $b=1/2$. The theoretical results hinge on a novel concentration inequality we have developed that bounds a linear combination of sub-Gaussian random variables whose weights are fractional, adapted to the filtration, and monotonic.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/li23a/li23a.pdf",
        "supp": "",
        "pdf_size": 136870,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:TM61i87wG4MJ:scholar.google.com/&scioq=Allocating+Divisible+Resources+on+Arms+with+Unknown+and+Random+Rewards&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "College of Business, Shanghai University of Finance and Economics; Department of Management, University of Toronto+Rotman School of Management, University of Toronto",
        "aff_domain": "GMAIL.COM;UTORONTO.CA",
        "email": "GMAIL.COM;UTORONTO.CA",
        "github": "",
        "project": "arXiv:2306.16578",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+1",
        "aff_unique_norm": "Shanghai University of Finance and Economics;University of Toronto",
        "aff_unique_dep": "College of Business;Department of Management",
        "aff_unique_url": "http://www.sufe.edu.cn;https://www.utoronto.ca",
        "aff_unique_abbr": "SUFE;U of T",
        "aff_campus_unique_index": "1+1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1+1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "e8eb229fad",
        "title": "Approximately Stationary Bandits with Knapsacks",
        "site": "https://proceedings.mlr.press/v195/fikioris23a.html",
        "author": "Giannis Fikioris; \u00c9va Tardos",
        "abstract": "Bandits with Knapsacks (BwK), the generalization of the Multi-Armed Bandits problem under global budget constraints, has received a lot of attention in recent years. It has numerous applications, including dynamic pricing, repeated auctions, ad allocation, network scheduling, etc. Previous work has focused on one of the two extremes: Stochastic BwK where the rewards and consumptions of the resources of each round are sampled from an i.i.d. distribution, and Adversarial BwK where these parameters are picked by an adversary. Achievable guarantees in the two cases exhibit a massive gap: No-regret learning is achievable in the stochastic case, but in the adversarial case only competitive ratio style guarantees are achievable, where the competitive ratio depends either on the budget or on both the time and the number of resources. What makes this gap so vast is that in Adversarial BwK the guarantees get worse in the typical case when the budget is more binding. While \u201cbest-of-both-worlds\u201d type algorithms are known (single algorithms that provide the best achievable guarantee in each extreme case), their bounds degrade to the adversarial case as soon as the environment is not fully stochastic.Our work aims to bridge this gap, offering guarantees for a workload that is not exactly stochastic but is also not worst-case. We define a condition, Approximately Stationary BwK, that parameterizes how close to stochastic or adversarial an instance is. Based on these parameters, we explore what is the best competitive ratio attainable in BwL. We explore two algorithms that are oblivious to the values of the parameters but guarantee competitive ratios that smoothly transition between the best possible guarantees in the two extreme cases, depending on the values of the parameters. Our guarantees offer great improvement over the adversarial guarantee, especially when the available budget is small. We also prove bounds on the achievable guarantee, showing that our results are approximately tight when the budget is small.",
        "bibtex": "@InProceedings{pmlr-v195-fikioris23a,\n  title = \t {Approximately Stationary Bandits with Knapsacks},\n  author =       {Fikioris, Giannis and Tardos, {\\'E}va},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3758--3782},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/fikioris23a/fikioris23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/fikioris23a.html},\n  abstract = \t {Bandits with Knapsacks (BwK), the generalization of the Multi-Armed Bandits problem under global budget constraints, has received a lot of attention in recent years. It has numerous applications, including dynamic pricing, repeated auctions, ad allocation, network scheduling, etc. Previous work has focused on one of the two extremes: Stochastic BwK where the rewards and consumptions of the resources of each round are sampled from an i.i.d. distribution, and Adversarial BwK where these parameters are picked by an adversary. Achievable guarantees in the two cases exhibit a massive gap: No-regret learning is achievable in the stochastic case, but in the adversarial case only competitive ratio style guarantees are achievable, where the competitive ratio depends either on the budget or on both the time and the number of resources. What makes this gap so vast is that in Adversarial BwK the guarantees get worse in the typical case when the budget is more binding. While \u201cbest-of-both-worlds\u201d type algorithms are known (single algorithms that provide the best achievable guarantee in each extreme case), their bounds degrade to the adversarial case as soon as the environment is not fully stochastic.Our work aims to bridge this gap, offering guarantees for a workload that is not exactly stochastic but is also not worst-case. We define a condition, Approximately Stationary BwK, that parameterizes how close to stochastic or adversarial an instance is. Based on these parameters, we explore what is the best competitive ratio attainable in BwL. We explore two algorithms that are oblivious to the values of the parameters but guarantee competitive ratios that smoothly transition between the best possible guarantees in the two extreme cases, depending on the values of the parameters. Our guarantees offer great improvement over the adversarial guarantee, especially when the available budget is small. We also prove bounds on the achievable guarantee, showing that our results are approximately tight when the budget is small.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/fikioris23a/fikioris23a.pdf",
        "supp": "",
        "pdf_size": 437141,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14084370286109849679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Cornell University; Cornell University",
        "aff_domain": "CS.CORNELL.EDU;CORNELL.EDU",
        "email": "CS.CORNELL.EDU;CORNELL.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4b639870e0",
        "title": "Asymptotic confidence sets for random linear programs",
        "site": "https://proceedings.mlr.press/v195/liu23d.html",
        "author": "Shuyu Liu; Florentina Bunea; Jonathan Niles-Weed",
        "abstract": "Motivated by the statistical analysis of the discrete optimal transport problem, we prove distributional limits for the solutions of linear programs with random constraints.Such limits were first obtained by Klatt, Munk, & Zemel (2022), but their expressions for the limits involve a computationally intractable decomposition of $\\mathbb{R}^m$ into a possibly exponential number of convex cones.We give a new expression for the limit in terms of auxiliary linear programs, which can be solved in polynomial time.We also leverage tools from random convex geometry to give distributional limits for the entire set of random optimal solutions, when the optimum is not unique.Finally, we describe a simple, data-driven method to construct asymptotically valid confidence sets in polynomial time.",
        "bibtex": "@InProceedings{pmlr-v195-liu23d,\n  title = \t {Asymptotic confidence sets for random linear programs},\n  author =       {Liu, Shuyu and Bunea, Florentina and Niles-Weed, Jonathan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3919--3940},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/liu23d/liu23d.pdf},\n  url = \t {https://proceedings.mlr.press/v195/liu23d.html},\n  abstract = \t {Motivated by the statistical analysis of the discrete optimal transport problem, we prove distributional limits for the solutions of linear programs with random constraints.Such limits were first obtained by Klatt, Munk, & Zemel (2022), but their expressions for the limits involve a computationally intractable decomposition of $\\mathbb{R}^m$ into a possibly exponential number of convex cones.We give a new expression for the limit in terms of auxiliary linear programs, which can be solved in polynomial time.We also leverage tools from random convex geometry to give distributional limits for the entire set of random optimal solutions, when the optimum is not unique.Finally, we describe a simple, data-driven method to construct asymptotically valid confidence sets in polynomial time.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/liu23d/liu23d.pdf",
        "supp": "",
        "pdf_size": 912540,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6841028734707228684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Courant Institute of Mathematical Sciences, New York University, New York, NY, 10012; Department of Statistics and Data Science, Cornell University, Ithaca, NY, 14853; Courant Institute of Mathematical Sciences and Center for Data Science, New York University, New York, NY, 10012",
        "aff_domain": "NYU.EDU;CORNELL.EDU;CIMS.NYU.EDU",
        "email": "NYU.EDU;CORNELL.EDU;CIMS.NYU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "New York University;Cornell University",
        "aff_unique_dep": "Courant Institute of Mathematical Sciences;Department of Statistics and Data Science",
        "aff_unique_url": "https://www.nyu.edu;https://www.cornell.edu",
        "aff_unique_abbr": "NYU;Cornell",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "New York;Ithaca",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3b9d01c372",
        "title": "Backward Feature Correction: How Deep Learning Performs Deep (Hierarchical) Learning",
        "site": "https://proceedings.mlr.press/v195/allen-zhu23a.html",
        "author": "Zeyuan Allen-Zhu; Yuanzhi Li",
        "abstract": "Deep learning is also known as hierarchical learning, where the learner $\\textit{learns}$ to represent a complicated target function by decomposing it into a sequence of simpler functions  to reduce sample and time complexity. This paper formally analyzes how multi-layer neural networks can perform such hierarchical learning $\\textit{efficiently}$ and $\\textit{automatically}$ by applying stochastic gradient descent (SGD) or its variants on the training objective.On the conceptual side, we present a theoretical characterizations of how certain types of deep (i.e. super-constantly many layers) neural networks can still be sample and time efficiently trained on some hierarchical learning tasks, when no known existing algorithm (including layerwise training, kernel method, etc) is efficient. We establish a new principle called \u201cbackward feature correction\u201d, where \\emph{the errors in the lower-level features can be automatically corrected when training together with the higher-level layers}. We believe this is a key behind how deep learning is performing deep (hierarchical) learning, as opposed to layerwise learning or simulating some known non-hierarchical method.",
        "bibtex": "@InProceedings{pmlr-v195-allen-zhu23a,\n  title = \t {Backward Feature Correction: How Deep Learning Performs Deep (Hierarchical) Learning},\n  author =       {Allen-Zhu, Zeyuan and Li, Yuanzhi},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4598--4598},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/allen-zhu23a/allen-zhu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/allen-zhu23a.html},\n  abstract = \t {Deep learning is also known as hierarchical learning, where the learner $\\textit{learns}$ to represent a complicated target function by decomposing it into a sequence of simpler functions  to reduce sample and time complexity. This paper formally analyzes how multi-layer neural networks can perform such hierarchical learning $\\textit{efficiently}$ and $\\textit{automatically}$ by applying stochastic gradient descent (SGD) or its variants on the training objective.On the conceptual side, we present a theoretical characterizations of how certain types of deep (i.e. super-constantly many layers) neural networks can still be sample and time efficiently trained on some hierarchical learning tasks, when no known existing algorithm (including layerwise training, kernel method, etc) is efficient. We establish a new principle called \u201cbackward feature correction\u201d, where \\emph{the errors in the lower-level features can be automatically corrected when training together with the higher-level layers}. We believe this is a key behind how deep learning is performing deep (hierarchical) learning, as opposed to layerwise learning or simulating some known non-hierarchical method.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/allen-zhu23a/allen-zhu23a.pdf",
        "supp": "",
        "pdf_size": 135777,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16894869767480091627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Meta FAIR Labs; Mohamed bin Zayed University of AI",
        "aff_domain": "meta.com;mbzuai.ac.ae",
        "email": "meta.com;mbzuai.ac.ae",
        "github": "",
        "project": "http://arxiv.org/abs/2001.04413",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Meta;Mohamed bin Zayed University of Artificial Intelligence",
        "aff_unique_dep": "Meta FAIR Labs;",
        "aff_unique_url": "https://research.facebook.com;https://mbzuai.ac.ae",
        "aff_unique_abbr": "Meta FAIR Labs;MBZUAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "3d1d059b3d",
        "title": "Bagging is an Optimal PAC Learner",
        "site": "https://proceedings.mlr.press/v195/larsen23a.html",
        "author": "Kasper Green Larsen",
        "abstract": "Determining the optimal sample complexity of PAC learning in the realizable setting was a central open problem in learning theory for decades. Finally, the seminal work by Hanneke (2016) gave an algorithm with a provably optimal sample complexity. His algorithm is based on a careful and structured sub-sampling of the training data and then returning a majority vote among hypotheses trained on each of the sub-samples. While being a very exciting theoretical result, it has not had much impact in practice, in part due to inefficiency, since it constructs a polynomial number of sub-samples of the training data, each of linear size.In this work, we prove the surprising result that the practical and classic heuristic \\emph{bagging} (a.k.a. bootstrap aggregation), due to Breiman (1996), is in fact also an optimal PAC learner. Bagging pre-dates Hanneke\u2019s algorithm by twenty years and is taught in most undergraduate machine learning courses. Moreover, we show that it only requires a logarithmic number of sub-samples to reach optimality.",
        "bibtex": "@InProceedings{pmlr-v195-larsen23a,\n  title = \t {Bagging is an Optimal PAC Learner},\n  author =       {Larsen, Kasper Green},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {450--468},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/larsen23a/larsen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/larsen23a.html},\n  abstract = \t {Determining the optimal sample complexity of PAC learning in the realizable setting was a central open problem in learning theory for decades. Finally, the seminal work by Hanneke (2016) gave an algorithm with a provably optimal sample complexity. His algorithm is based on a careful and structured sub-sampling of the training data and then returning a majority vote among hypotheses trained on each of the sub-samples. While being a very exciting theoretical result, it has not had much impact in practice, in part due to inefficiency, since it constructs a polynomial number of sub-samples of the training data, each of linear size.In this work, we prove the surprising result that the practical and classic heuristic \\emph{bagging} (a.k.a. bootstrap aggregation), due to Breiman (1996), is in fact also an optimal PAC learner. Bagging pre-dates Hanneke\u2019s algorithm by twenty years and is taught in most undergraduate machine learning courses. Moreover, we show that it only requires a logarithmic number of sub-samples to reach optimality. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/larsen23a/larsen23a.pdf",
        "supp": "",
        "pdf_size": 282801,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12626884535058072600&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Aarhus University, Denmark",
        "aff_domain": "CS.AU.DK",
        "email": "CS.AU.DK",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Aarhus University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://au.dk",
        "aff_unique_abbr": "AU",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "756dcdc038",
        "title": "Bandit Learnability can be Undecidable",
        "site": "https://proceedings.mlr.press/v195/hanneke23d.html",
        "author": "Steve Hanneke; Liu Yang",
        "abstract": "We initiate a general investigation into structured bandits. Specifically, for an abstract space $X$, we suppose a true reward function $f$ resides in a known, but arbitrary, function class $F$. The algorithm may then pull a number of arms $x$ (i.e., query for the value $f(x)$), and thereby attempts to identify an arm $\\hat{x}$ of near-maximum reward: $f(\\hat{x}) \\geq \\sup_x f(x) - \\epsilon$. While special cases of this problem are well understood in the literature, our interest is in the possibility of a fully-general theory of bandit learnability, analogous to the PAC model for classification: that is, a theory which precisely characterizes which function classes $F$ admit a learning algorithm guaranteed to identify a near-optimal arm within a bounded number of pulls.Our main result in this regard is an illuminating impossibility result. Namely, there exist well-defined function classes $F$ such that bandit learnability is \\emph{undecidable} within ZFC set theory. While such undecidability results have previously been shown for a certain abstractly-defined learning problem known as EMX, this is the first example of a natural or commonly-encountered learning problem (i.e., bandits) for which learnability can be provably undecidable. Our proof is based on establishing a (rather-sophisticated) equivalence between certain subfamilies of EMX learning problems and corresponding constructed bandit problems.Despite this general undecidability result, we also establish new general results in special cases. Specifically, we characterize the optimal query complexity in the special case of binary-valued reward functions in terms of a combinatorial complexity measure related to the teaching dimension.  We also present an extension to general bounded real-valued rewards, though in this case the upper bound is not always optimal.  We instantiate the new complexity measures for several important families of function classes $F$.",
        "bibtex": "@InProceedings{pmlr-v195-hanneke23d,\n  title = \t {Bandit Learnability can be Undecidable},\n  author =       {Hanneke, Steve and Yang, Liu},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5813--5849},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hanneke23d/hanneke23d.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hanneke23d.html},\n  abstract = \t {We initiate a general investigation into structured bandits. Specifically, for an abstract space $X$, we suppose a true reward function $f$ resides in a known, but arbitrary, function class $F$. The algorithm may then pull a number of arms $x$ (i.e., query for the value $f(x)$), and thereby attempts to identify an arm $\\hat{x}$ of near-maximum reward: $f(\\hat{x}) \\geq \\sup_x f(x) - \\epsilon$. While special cases of this problem are well understood in the literature, our interest is in the possibility of a fully-general theory of bandit learnability, analogous to the PAC model for classification: that is, a theory which precisely characterizes which function classes $F$ admit a learning algorithm guaranteed to identify a near-optimal arm within a bounded number of pulls.Our main result in this regard is an illuminating impossibility result. Namely, there exist well-defined function classes $F$ such that bandit learnability is \\emph{undecidable} within ZFC set theory. While such undecidability results have previously been shown for a certain abstractly-defined learning problem known as EMX, this is the first example of a natural or commonly-encountered learning problem (i.e., bandits) for which learnability can be provably undecidable. Our proof is based on establishing a (rather-sophisticated) equivalence between certain subfamilies of EMX learning problems and corresponding constructed bandit problems.Despite this general undecidability result, we also establish new general results in special cases. Specifically, we characterize the optimal query complexity in the special case of binary-valued reward functions in terms of a combinatorial complexity measure related to the teaching dimension.  We also present an extension to general bounded real-valued rewards, though in this case the upper bound is not always optimal.  We instantiate the new complexity measures for several important families of function classes $F$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hanneke23d/hanneke23d.pdf",
        "supp": "",
        "pdf_size": 438387,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6580170913088563770&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Purdue University; Santai Technology Co., Ltd",
        "aff_domain": "GMAIL.COM;OUTLOOK.COM",
        "email": "GMAIL.COM;OUTLOOK.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Purdue University;Santai Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.purdue.edu;",
        "aff_unique_abbr": "Purdue;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "5ec2f50c09",
        "title": "Benign Overfitting in Linear Classifiers and Leaky ReLU Networks from KKT Conditions for Margin Maximization",
        "site": "https://proceedings.mlr.press/v195/frei23a.html",
        "author": "Spencer Frei; Gal Vardi; Peter Bartlett; Nathan Srebro",
        "abstract": "Linear classifiers and leaky ReLU networks trained by gradient flow on the logistic loss have an implicit bias towards solutions which satisfy the Karush\u2013Kuhn\u2013Tucker (KKT) conditions for margin maximization. In this work we establish a number of settings where the satisfaction of these KKT conditions implies benign overfitting in linear classifiers and in two-layer leaky ReLU networks: the estimators interpolate noisy training data and simultaneously generalize well to test data. The settings include variants of the noisy class-conditional Gaussians considered in previous work as well as new distributional settings where benign overfitting has not been previously observed. The key ingredient to our proof is the observation that when the training data is nearly-orthogonal, both linear classifiers and leaky ReLU networks satisfying the KKT conditions for their respective margin maximization problems behave like a weighted average of the training examples.",
        "bibtex": "@InProceedings{pmlr-v195-frei23a,\n  title = \t {Benign Overfitting in Linear Classifiers and Leaky ReLU Networks from KKT Conditions for Margin Maximization},\n  author =       {Frei, Spencer and Vardi, Gal and Bartlett, Peter and Srebro, Nathan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3173--3228},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/frei23a/frei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/frei23a.html},\n  abstract = \t {Linear classifiers and leaky ReLU networks trained by gradient flow on the logistic loss have an implicit bias towards solutions which satisfy the Karush\u2013Kuhn\u2013Tucker (KKT) conditions for margin maximization. In this work we establish a number of settings where the satisfaction of these KKT conditions implies benign overfitting in linear classifiers and in two-layer leaky ReLU networks: the estimators interpolate noisy training data and simultaneously generalize well to test data. The settings include variants of the noisy class-conditional Gaussians considered in previous work as well as new distributional settings where benign overfitting has not been previously observed. The key ingredient to our proof is the observation that when the training data is nearly-orthogonal, both linear classifiers and leaky ReLU networks satisfying the KKT conditions for their respective margin maximization problems behave like a weighted average of the training examples.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/frei23a/frei23a.pdf",
        "supp": "",
        "pdf_size": 541795,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5306593145008066107&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "UC Berkeley; TTI-Chicago + Hebrew University; UC Berkeley + Google DeepMind; TTI-Chicago",
        "aff_domain": "berkeley.edu;ttic.edu;berkeley.edu;ttic.edu",
        "email": "berkeley.edu;ttic.edu;berkeley.edu;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;0+3;1",
        "aff_unique_norm": "University of California, Berkeley;Toyota Technological Institute at Chicago;Hebrew University of Jerusalem;Google",
        "aff_unique_dep": ";;;Google DeepMind",
        "aff_unique_url": "https://www.berkeley.edu;https://www.tti-chicago.org;https://www.huji.ac.il;https://deepmind.com",
        "aff_unique_abbr": "UC Berkeley;TTI;HUJI;DeepMind",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Berkeley;Chicago;",
        "aff_country_unique_index": "0;0+1;0+2;0",
        "aff_country_unique": "United States;Israel;United Kingdom"
    },
    {
        "id": "a3d793292e",
        "title": "Best-of-Three-Worlds Linear Bandit Algorithm with Variance-Adaptive Regret Bounds",
        "site": "https://proceedings.mlr.press/v195/ito23a.html",
        "author": "Shinji Ito; Kei Takemura",
        "abstract": "This paper proposes a linear bandit algorithm that is adaptive to environments at two different levels of hierarchy.  At the higher level, the proposed algorithm adapts to a variety of types of environments.  More precisely, it achieves best-of-three-worlds regret bounds, i.e., of ${O}(\\sqrt{T \\log T})$ for adversarial environments and of $O(\\frac{\\log T}{\\Delta_{\\min}} + \\sqrt{\\frac{C \\log T}{\\Delta_{\\min}}})$ for stochastic environments with adversarial corruptions, where $T$, $\\Delta_{\\min}$, and $C$ denote, respectively, the time horizon, the minimum sub-optimality gap, and the total amount of the corruption.  Note that polynomial factors in the dimensionality are omitted here.  At the lower level, in each of the adversarial and stochastic regimes, the proposed algorithm adapts to certain environmental characteristics, thereby performing better.  The proposed algorithm has data-dependent regret bounds that depend on all of the cumulative loss for the optimal action, the total quadratic variation, and the path-length of the loss vector sequence.  In addition, for stochastic environments, the proposed algorithm has a variance-adaptive regret bound of $O(\\frac{\\sigma^2 \\log T}{\\Delta_{\\min}})$ as well, where $\\sigma^2$ denotes the maximum variance of the feedback loss.  The proposed algorithm is based on the \\texttt{SCRiBLe} algorithm (Abernethy et al., 2012).  By incorporating into this a new technique we call \\textit{scaled-up sampling}, we obtain high-level adaptability, and by incorporating the technique of optimistic online learning, we obtain low-level adaptability.",
        "bibtex": "@InProceedings{pmlr-v195-ito23a,\n  title = \t {Best-of-Three-Worlds Linear Bandit Algorithm with Variance-Adaptive Regret Bounds},\n  author =       {Ito, Shinji and Takemura, Kei},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2653--2677},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/ito23a/ito23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/ito23a.html},\n  abstract = \t {This paper proposes a linear bandit algorithm that is adaptive to environments at two different levels of hierarchy.  At the higher level, the proposed algorithm adapts to a variety of types of environments.  More precisely, it achieves best-of-three-worlds regret bounds, i.e., of ${O}(\\sqrt{T \\log T})$ for adversarial environments and of $O(\\frac{\\log T}{\\Delta_{\\min}} + \\sqrt{\\frac{C \\log T}{\\Delta_{\\min}}})$ for stochastic environments with adversarial corruptions, where $T$, $\\Delta_{\\min}$, and $C$ denote, respectively, the time horizon, the minimum sub-optimality gap, and the total amount of the corruption.  Note that polynomial factors in the dimensionality are omitted here.  At the lower level, in each of the adversarial and stochastic regimes, the proposed algorithm adapts to certain environmental characteristics, thereby performing better.  The proposed algorithm has data-dependent regret bounds that depend on all of the cumulative loss for the optimal action, the total quadratic variation, and the path-length of the loss vector sequence.  In addition, for stochastic environments, the proposed algorithm has a variance-adaptive regret bound of $O(\\frac{\\sigma^2 \\log T}{\\Delta_{\\min}})$ as well, where $\\sigma^2$ denotes the maximum variance of the feedback loss.  The proposed algorithm is based on the \\texttt{SCRiBLe} algorithm (Abernethy et al., 2012).  By incorporating into this a new technique we call \\textit{scaled-up sampling}, we obtain high-level adaptability, and by incorporating the technique of optimistic online learning, we obtain low-level adaptability.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/ito23a/ito23a.pdf",
        "supp": "",
        "pdf_size": 366991,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15055751040442102168&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "NEC Corporation; NEC Corporation",
        "aff_domain": "NEC.COM;NEC.COM",
        "email": "NEC.COM;NEC.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "NEC Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nec.com",
        "aff_unique_abbr": "NEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "4dc33efb6f",
        "title": "Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm",
        "site": "https://proceedings.mlr.press/v195/kong23a.html",
        "author": "Fang Kong; Canzhe Zhao; Shuai Li",
        "abstract": "The linear bandit problem has been studied for many years in both stochastic and adversarial settings. Designing an algorithm that can optimize the environment without knowing the loss type attracts lots of interest. \\citet{LeeLWZ021} propose an algorithm that actively detects the loss type and then switches between different algorithms specially designed for specific settings. However, such an approach requires meticulous designs to perform well in all environments. Follow-the-regularized-leader (FTRL) is another type of popular algorithm that can adapt to different environments. This algorithm is of simple design and the regret bounds are shown to be optimal in traditional multi-armed bandit problems compared with the detect-switch type. Designing an FTRL-type algorithm for linear bandits is an important question that has been open for a long time. In this paper, we prove that the FTRL algorithm with a negative entropy regularizer can achieve the best-of-three-world results for the linear bandit problem. Our regret bounds achieve the same or nearly the same order as the previous detect-switch type algorithm but with a much simpler algorithmic design.",
        "bibtex": "@InProceedings{pmlr-v195-kong23a,\n  title = \t {Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm},\n  author =       {Kong, Fang and Zhao, Canzhe and Li, Shuai},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {657--673},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kong23a/kong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kong23a.html},\n  abstract = \t {The linear bandit problem has been studied for many years in both stochastic and adversarial settings. Designing an algorithm that can optimize the environment without knowing the loss type attracts lots of interest. \\citet{LeeLWZ021} propose an algorithm that actively detects the loss type and then switches between different algorithms specially designed for specific settings. However, such an approach requires meticulous designs to perform well in all environments. Follow-the-regularized-leader (FTRL) is another type of popular algorithm that can adapt to different environments. This algorithm is of simple design and the regret bounds are shown to be optimal in traditional multi-armed bandit problems compared with the detect-switch type. Designing an FTRL-type algorithm for linear bandits is an important question that has been open for a long time. In this paper, we prove that the FTRL algorithm with a negative entropy regularizer can achieve the best-of-three-world results for the linear bandit problem. Our regret bounds achieve the same or nearly the same order as the previous detect-switch type algorithm but with a much simpler algorithmic design. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/kong23a/kong23a.pdf",
        "supp": "",
        "pdf_size": 257925,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9667948181940264250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "John Hopcroft Center for Computer Science, Shanghai Jiao Tong University, Shanghai, China; John Hopcroft Center for Computer Science, Shanghai Jiao Tong University, Shanghai, China; John Hopcroft Center for Computer Science, Shanghai Jiao Tong University, Shanghai, China",
        "aff_domain": "sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn",
        "email": "sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "John Hopcroft Center for Computer Science",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "f943c9457f",
        "title": "Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for Non-Spherical Gaussian Mixtures",
        "site": "https://proceedings.mlr.press/v195/buhai23a.html",
        "author": "Rares-Darius Buhai; David Steurer",
        "abstract": "We consider mixtures of k >= 2 Gaussian components with unknown means and unknown covariance (identical for all components) that are well-separated, i.e., distinct components have statistical overlap at most k^{-C} for a large enough constant C >= 1.Previous statistical-query [DKS17] and cryptographic [BRST21, GVV22] lower bounds give formal evidence that, even for the special case of colinear means, distinguishing such mixtures from (pure) Gaussians may be exponentially hard (in k).We show that, surprisingly, this kind of hardness can only appear if mixing weights are allowed to be exponentially small. For polynomially lower bounded mixing weights, we show how to achieve non-trivial statistical guarantees in quasi-polynomial time.Concretely, we develop an algorithm based on the sum-of-squares method with running time quasi-polynomial in the minimum mixing weight. The algorithm can reliably distinguish between a mixture of k >= 2 well-separated Gaussian components and a (pure) Gaussian distribution. As a certificate, the algorithm computes a bipartition of the input sample that separates some pairs of mixture components, i.e., both sides of the bipartition contain most of the sample points of at least one component.For the special case of colinear means, our algorithm outputs a k-clustering of the input sample that is approximately consistent with all components of the underlying mixture. We obtain similar clustering guarantees also for the case that the overlap between any two mixture components is lower bounded quasi-polynomially ink (in addition to being upper bounded polynomially in k).A significant challenge for our results is that they appear to be inherently sensitive to small fractions of adversarial outliers unlike most previous algorithmic results for Gaussian mixtures. The reason is that such outliers can simulate exponentially small mixing weights even for mixtures with polynomially lower bounded mixing weights.A key technical ingredient of our algorithms is a characterization of separating directions for well-separated Gaussian components in terms of ratios of polynomials that correspond to moments of two carefully chosen orders logarithmic in the minimum mixing weight.",
        "bibtex": "@InProceedings{pmlr-v195-buhai23a,\n  title = \t {Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for Non-Spherical Gaussian Mixtures},\n  author =       {Buhai, Rares-Darius and Steurer, David},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {548--611},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/buhai23a/buhai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/buhai23a.html},\n  abstract = \t {We consider mixtures of k >= 2 Gaussian components with unknown means and unknown covariance (identical for all components) that are well-separated, i.e., distinct components have statistical overlap at most k^{-C} for a large enough constant C >= 1.Previous statistical-query [DKS17] and cryptographic [BRST21, GVV22] lower bounds give formal evidence that, even for the special case of colinear means, distinguishing such mixtures from (pure) Gaussians may be exponentially hard (in k).We show that, surprisingly, this kind of hardness can only appear if mixing weights are allowed to be exponentially small. For polynomially lower bounded mixing weights, we show how to achieve non-trivial statistical guarantees in quasi-polynomial time.Concretely, we develop an algorithm based on the sum-of-squares method with running time quasi-polynomial in the minimum mixing weight. The algorithm can reliably distinguish between a mixture of k >= 2 well-separated Gaussian components and a (pure) Gaussian distribution. As a certificate, the algorithm computes a bipartition of the input sample that separates some pairs of mixture components, i.e., both sides of the bipartition contain most of the sample points of at least one component.For the special case of colinear means, our algorithm outputs a k-clustering of the input sample that is approximately consistent with all components of the underlying mixture. We obtain similar clustering guarantees also for the case that the overlap between any two mixture components is lower bounded quasi-polynomially ink (in addition to being upper bounded polynomially in k).A significant challenge for our results is that they appear to be inherently sensitive to small fractions of adversarial outliers unlike most previous algorithmic results for Gaussian mixtures. The reason is that such outliers can simulate exponentially small mixing weights even for mixtures with polynomially lower bounded mixing weights.A key technical ingredient of our algorithms is a characterization of separating directions for well-separated Gaussian components in terms of ratios of polynomials that correspond to moments of two carefully chosen orders logarithmic in the minimum mixing weight.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/buhai23a/buhai23a.pdf",
        "supp": "",
        "pdf_size": 563387,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4673166200195651799&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "ETH Zurich; ETH Zurich",
        "aff_domain": "INF.ETHZ.CH;INF.ETHZ.CH",
        "email": "INF.ETHZ.CH;INF.ETHZ.CH",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "e493388be8",
        "title": "Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD",
        "site": "https://proceedings.mlr.press/v195/faw23a.html",
        "author": "Matthew Faw; Litu Rout; Constantine Caramanis; Sanjay Shakkottai",
        "abstract": "This work considers the problem of finding a first-order stationary point of a non-convex function with potentially unbounded smoothness constant using a stochastic gradient oracle. We focus on the class of $(L_0,L_1)$-smooth functions proposed by Zhang et al. (ICLR\u201920). Empirical evidence suggests that these functions more closely capture practical machine learning problems as compared to the pervasive $L_0$-smoothness. This class is rich enough to include highly non-smooth functions, such as $\\exp(L_1 x)$ which is $(0,\\mathcal{O}(L_1))$-smooth. Despite the richness,  an emerging line of works achieves the $\\widetilde{\\mathcal{O}}(\\frac{1}{\\sqrt{T}})$ rate of convergence when the noise of the stochastic gradients is deterministically and uniformly bounded. This noise restriction is not required in the $\\L_0$-smooth setting, and in many practical settings is either not satisfied, or results in weaker convergence rates with respect to the noise scaling of the convergence rate.We develop a technique that allows us to prove $\\mathcal{O}(\\frac{\\mathrm{poly}\\log(T)}{\\sqrt{T}})$ convergence rates for $(L_0,L_1)$-smooth functions without assuming uniform bounds on the noise support. The key innovation behind our results is a carefully constructed stopping time $\\tau$ which is simultaneously \u201clarge\u201d on average, yet also allows us to treat the adaptive step sizes before $\\tau$ as (roughly) independent of the gradients. For general $(L_0,L_1)$-smooth functions, our analysis requires the mild restriction that the multiplicative noise parameter $\\sigma_1 < 1$. For a broad subclass of $(L_0,L_1)$-smooth functions, our convergence rate continues to hold when $\\sigma_1 \\geq 1$. By contrast, we prove that many algorithms analyzed by prior works on $(L_0,L_1)$-smooth optimization diverge with constant probability even for smooth and strongly-convex functions when $\\sigma_1 > 1$.",
        "bibtex": "@InProceedings{pmlr-v195-faw23a,\n  title = \t {Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD},\n  author =       {Faw, Matthew and Rout, Litu and Caramanis, Constantine and Shakkottai, Sanjay},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {89--160},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/faw23a/faw23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/faw23a.html},\n  abstract = \t {This work considers the problem of finding a first-order stationary point of a non-convex function with potentially unbounded smoothness constant using a stochastic gradient oracle. We focus on the class of $(L_0,L_1)$-smooth functions proposed by Zhang et al. (ICLR\u201920). Empirical evidence suggests that these functions more closely capture practical machine learning problems as compared to the pervasive $L_0$-smoothness. This class is rich enough to include highly non-smooth functions, such as $\\exp(L_1 x)$ which is $(0,\\mathcal{O}(L_1))$-smooth. Despite the richness,  an emerging line of works achieves the $\\widetilde{\\mathcal{O}}(\\frac{1}{\\sqrt{T}})$ rate of convergence when the noise of the stochastic gradients is deterministically and uniformly bounded. This noise restriction is not required in the $\\L_0$-smooth setting, and in many practical settings is either not satisfied, or results in weaker convergence rates with respect to the noise scaling of the convergence rate.We develop a technique that allows us to prove $\\mathcal{O}(\\frac{\\mathrm{poly}\\log(T)}{\\sqrt{T}})$ convergence rates for $(L_0,L_1)$-smooth functions without assuming uniform bounds on the noise support. The key innovation behind our results is a carefully constructed stopping time $\\tau$ which is simultaneously \u201clarge\u201d on average, yet also allows us to treat the adaptive step sizes before $\\tau$ as (roughly) independent of the gradients. For general $(L_0,L_1)$-smooth functions, our analysis requires the mild restriction that the multiplicative noise parameter $\\sigma_1 < 1$. For a broad subclass of $(L_0,L_1)$-smooth functions, our convergence rate continues to hold when $\\sigma_1 \\geq 1$. By contrast, we prove that many algorithms analyzed by prior works on $(L_0,L_1)$-smooth optimization diverge with constant probability even for smooth and strongly-convex functions when $\\sigma_1 > 1$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/faw23a/faw23a.pdf",
        "supp": "",
        "pdf_size": 691278,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2816553516716979695&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin",
        "aff_domain": "UTEXAS.EDU;UTEXAS.EDU;UTEXAS.EDU;UTEXAS.EDU",
        "email": "UTEXAS.EDU;UTEXAS.EDU;UTEXAS.EDU;UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "63fd64b7d4",
        "title": "Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation",
        "site": "https://proceedings.mlr.press/v195/wang23b.html",
        "author": "Yuanhao Wang; Qinghua Liu; Yu Bai; Chi Jin",
        "abstract": "A unique challenge in Multi-Agent Reinforcement Learning (MARL) is the \\emph{curse of multiagency}, where the description length of the game as well as the complexity of many existing learning algorithms scale \\emph{exponentially} in the number of agents. While recent work successfully addresses this challenge under the model of tabular Markov Games, their mechanisms critically rely on the number of states being finite and small, and do not extend to practical scenarios with enormous state spaces where \\emph{function approximation} must be used to approximate value functions or policies. This paper presents the first line of MARL algorithms that provably resolve the curse of multiagency under function approximation. We design a new algorithm\u2014\\emph{V-Learning with Policy Replay}, which gives the first \\emph{polynomial} sample complexity results for learning approximate Coarse Correlated Equilibria (CCEs) of Markov Games under decentralized linear function approximation. Our algorithm always outputs Markov CCEs, and its sample complexity also significantly improves over the current best result for finding Markov CCEs in the tabular setting. This paper further presents an alternative algorithm\u2014\\emph{Decentralized Optimistic Policy Mirror Descent}, which finds policy-class-restricted CCEs using a polynomial number of samples. In exchange for learning a weaker version of CCEs, this algorithm applies to a wider range of problems under generic function approximation, such as linear quadratic games and MARL problems with low \u201cmarginal\u201d Eluder dimension.",
        "bibtex": "@InProceedings{pmlr-v195-wang23b,\n  title = \t {Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation},\n  author =       {Wang, Yuanhao and Liu, Qinghua and Bai, Yu and Jin, Chi},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2793--2848},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wang23b/wang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wang23b.html},\n  abstract = \t {A unique challenge in Multi-Agent Reinforcement Learning (MARL) is the \\emph{curse of multiagency}, where the description length of the game as well as the complexity of many existing learning algorithms scale \\emph{exponentially} in the number of agents. While recent work successfully addresses this challenge under the model of tabular Markov Games, their mechanisms critically rely on the number of states being finite and small, and do not extend to practical scenarios with enormous state spaces where \\emph{function approximation} must be used to approximate value functions or policies. This paper presents the first line of MARL algorithms that provably resolve the curse of multiagency under function approximation. We design a new algorithm\u2014\\emph{V-Learning with Policy Replay}, which gives the first \\emph{polynomial} sample complexity results for learning approximate Coarse Correlated Equilibria (CCEs) of Markov Games under decentralized linear function approximation. Our algorithm always outputs Markov CCEs, and its sample complexity also significantly improves over the current best result for finding Markov CCEs in the tabular setting. This paper further presents an alternative algorithm\u2014\\emph{Decentralized Optimistic Policy Mirror Descent}, which finds policy-class-restricted CCEs using a polynomial number of samples. In exchange for learning a weaker version of CCEs, this algorithm applies to a wider range of problems under generic function approximation, such as linear quadratic games and MARL problems with low \u201cmarginal\u201d Eluder dimension.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wang23b/wang23b.pdf",
        "supp": "",
        "pdf_size": 669405,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13459553272113910478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Princeton University; Princeton University; Salesforce Research; Princeton University",
        "aff_domain": "princeton.edu;princeton.edu;salesforce.com;princeton.edu",
        "email": "princeton.edu;princeton.edu;salesforce.com;princeton.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Princeton University;Salesforce",
        "aff_unique_dep": ";Salesforce Research",
        "aff_unique_url": "https://www.princeton.edu;https://research.salesforce.com",
        "aff_unique_abbr": "Princeton;Salesforce",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f82f754c41",
        "title": "Breaking the Curse of Multiagents in a Large State Space: RL  in Markov Games with Independent  Linear Function Approximation",
        "site": "https://proceedings.mlr.press/v195/cui23a.html",
        "author": "Qiwen Cui; Kaiqing Zhang; Simon Du",
        "abstract": "We propose a new model, \\emph{independent linear Markov game}, for multi-agent reinforcement learning with a large state space and a large number of agents.This is a class of Markov games with \\emph{independent} linear function approximation, where each agent has its own function approximation for the state-action value functions that are {\\it marginalized} by other players\u2019 policies. We design new algorithms for learning the Markov coarse correlated equilibria (CCE) and Markov correlated equilibria (CE) with sample complexity bounds that only scale polynomially with \\emph{each agent\u2019s own function class complexity}, thus breaking the curse of multiagents. In contrast, existing works for Markov games with function approximation have sample complexity bounds scale with the size of the \\emph{joint action space} when specialized to the canonical tabular Markov game setting, which is exponentially large in the number of agents. Our algorithms rely on two key technical innovations:  (1) utilizing policy replay to tackle {\\it non-stationarity} incurred by multiple agents and the use of function approximation; (2) separating learning Markov equilibria and exploration in the Markov games, which allows us to use the full-information no-regret learning oracle instead of the stronger bandit-feedback no-regret learning oracle used in the tabular setting.  Furthermore, we propose an iterative-best-response type algorithm that can learn pure Markov Nash  equilibria in independent linear Markov potential games, with applications in learning in congestion games.In the tabular case, by adapting the  policy replay mechanism for independent linear Markov games, we propose an algorithm with $\\widetilde{O}(\\epsilon^{-2})$ sample complexity to learn Markov CCE, which  improves the state-of-the-art result $\\widetilde{O}(\\epsilon^{-3})$ in \\citep{daskalakis2022complexity}, where $\\epsilon$ is the desired accuracy, and also significantly improves other problem parameters. Furthermore, we design  the first provably efficient  algorithm for learning Markov CE that breaks the curse of multiagents.",
        "bibtex": "@InProceedings{pmlr-v195-cui23a,\n  title = \t {Breaking the Curse of Multiagents in a Large State Space: RL  in Markov Games with Independent  Linear Function Approximation},\n  author =       {Cui, Qiwen and Zhang, Kaiqing and Du, Simon},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2651--2652},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/cui23a/cui23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/cui23a.html},\n  abstract = \t {We propose a new model, \\emph{independent linear Markov game}, for multi-agent reinforcement learning with a large state space and a large number of agents.This is a class of Markov games with \\emph{independent} linear function approximation, where each agent has its own function approximation for the state-action value functions that are {\\it marginalized} by other players\u2019 policies. We design new algorithms for learning the Markov coarse correlated equilibria (CCE) and Markov correlated equilibria (CE) with sample complexity bounds that only scale polynomially with \\emph{each agent\u2019s own function class complexity}, thus breaking the curse of multiagents. In contrast, existing works for Markov games with function approximation have sample complexity bounds scale with the size of the \\emph{joint action space} when specialized to the canonical tabular Markov game setting, which is exponentially large in the number of agents. Our algorithms rely on two key technical innovations:  (1) utilizing policy replay to tackle {\\it non-stationarity} incurred by multiple agents and the use of function approximation; (2) separating learning Markov equilibria and exploration in the Markov games, which allows us to use the full-information no-regret learning oracle instead of the stronger bandit-feedback no-regret learning oracle used in the tabular setting.  Furthermore, we propose an iterative-best-response type algorithm that can learn pure Markov Nash  equilibria in independent linear Markov potential games, with applications in learning in congestion games.In the tabular case, by adapting the  policy replay mechanism for independent linear Markov games, we propose an algorithm with $\\widetilde{O}(\\epsilon^{-2})$ sample complexity to learn Markov CCE, which  improves the state-of-the-art result $\\widetilde{O}(\\epsilon^{-3})$ in \\citep{daskalakis2022complexity}, where $\\epsilon$ is the desired accuracy, and also significantly improves other problem parameters. Furthermore, we design  the first provably efficient  algorithm for learning Markov CE that breaks the curse of multiagents. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/cui23a/cui23a.pdf",
        "supp": "",
        "pdf_size": 100050,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6619279389961188420&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Washington; University of Maryland, College Park; University of Washington",
        "aff_domain": "CS.WASHINGTON.EDU;UMD.EDU;CS.WASHINGTON.EDU",
        "email": "CS.WASHINGTON.EDU;UMD.EDU;CS.WASHINGTON.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Washington;University of Maryland",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.washington.edu;https://www/umd.edu",
        "aff_unique_abbr": "UW;UMD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fde3bbf9a6",
        "title": "Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise",
        "site": "https://proceedings.mlr.press/v195/liu23c.html",
        "author": "Zijian Liu; Jiawei Zhang; Zhengyuan Zhou",
        "abstract": "In this paper, we consider the stochastic optimization problem with smooth but not necessarily convex objectives in the heavy-tailed noise regime, where the stochastic gradient\u2019s noise is assumed to have bounded $p$th moment ($p\\in(1,2]$). This is motivated by a recent plethora of studies in the machine learning literature, which point out that, in comparison to the standard finite-variance assumption, the heavy-tailed noise regime is more appropriate for modern machine learning tasks such as training neural networks. In the heavy-tailed noise regime, Zhang et al. (2020) is the first to prove the $\\Omega(T^{\\frac{1-p}{3p-2}})$ lower bound for convergence (in expectation) and provides a simple clipping algorithm that matches this optimal rate. Later, Cutkosky and Mehta (2021) proposes another algorithm, which is shown to achieve the nearly optimal high-probability convergence guarantee $O(\\log(T/\\delta)T^{\\frac{1-p}{3p-2}})$, where $\\delta$ is the probability of failure. However, this desirable guarantee is only established under the additional assumption that the stochastic gradient itself is bounded in $p$th moment, which fails to hold even for quadratic objectives and centered Gaussian noise. In this work, we first improve the analysis of the algorithm in Later, Cutkosky and Mehta (2021) to obtain the same nearly optimal high-probability convergence rate $O(\\log(T/\\delta)T^{\\frac{1-p}{3p-2}})$, without the above-mentioned restrictive assumption. Next, and curiously, we show that one can achieve a faster rate than that dictated by the lower bound $\\Omega(T^{\\frac{1-p}{3p-2}})$ with only a tiny bit of structure, i.e., when the objective function $F(x)$ is assumed to be in the form of $\\E_{\\Xi\\sim\\domxi}[f(x,\\Xi)]$, arguably the most widely applicable class of stochastic optimization problems. For this class of problems, we propose the first variance-reduced accelerated algorithm and establish that it guarantees a high-probability convergence rate of $O(\\log(T/\\delta)T^{\\frac{1-p}{2p-1}})$ under a mild condition, which is faster than $\\Omega(T^{\\frac{1-p}{3p-2}})$. Notably, even when specialized to the standard finite-variance case ($p =2$), our result yields the (near-)optimal high-probability rate $O(\\log(T/\\delta)T^{-1/3})$, which is unknown before.",
        "bibtex": "@InProceedings{pmlr-v195-liu23c,\n  title = \t {Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise},\n  author =       {Liu, Zijian and Zhang, Jiawei and Zhou, Zhengyuan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2266--2290},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/liu23c/liu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v195/liu23c.html},\n  abstract = \t {In this paper, we consider the stochastic optimization problem with smooth but not necessarily convex objectives in the heavy-tailed noise regime, where the stochastic gradient\u2019s noise is assumed to have bounded $p$th moment ($p\\in(1,2]$). This is motivated by a recent plethora of studies in the machine learning literature, which point out that, in comparison to the standard finite-variance assumption, the heavy-tailed noise regime is more appropriate for modern machine learning tasks such as training neural networks. In the heavy-tailed noise regime, Zhang et al. (2020) is the first to prove the $\\Omega(T^{\\frac{1-p}{3p-2}})$ lower bound for convergence (in expectation) and provides a simple clipping algorithm that matches this optimal rate. Later, Cutkosky and Mehta (2021) proposes another algorithm, which is shown to achieve the nearly optimal high-probability convergence guarantee $O(\\log(T/\\delta)T^{\\frac{1-p}{3p-2}})$, where $\\delta$ is the probability of failure. However, this desirable guarantee is only established under the additional assumption that the stochastic gradient itself is bounded in $p$th moment, which fails to hold even for quadratic objectives and centered Gaussian noise. In this work, we first improve the analysis of the algorithm in Later, Cutkosky and Mehta (2021) to obtain the same nearly optimal high-probability convergence rate $O(\\log(T/\\delta)T^{\\frac{1-p}{3p-2}})$, without the above-mentioned restrictive assumption. Next, and curiously, we show that one can achieve a faster rate than that dictated by the lower bound $\\Omega(T^{\\frac{1-p}{3p-2}})$ with only a tiny bit of structure, i.e., when the objective function $F(x)$ is assumed to be in the form of $\\E_{\\Xi\\sim\\domxi}[f(x,\\Xi)]$, arguably the most widely applicable class of stochastic optimization problems. For this class of problems, we propose the first variance-reduced accelerated algorithm and establish that it guarantees a high-probability convergence rate of $O(\\log(T/\\delta)T^{\\frac{1-p}{2p-1}})$ under a mild condition, which is faster than $\\Omega(T^{\\frac{1-p}{3p-2}})$. Notably, even when specialized to the standard finite-variance case ($p =2$), our result yields the (near-)optimal high-probability rate $O(\\log(T/\\delta)T^{-1/3})$, which is unknown before.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/liu23c/liu23c.pdf",
        "supp": "",
        "pdf_size": 381648,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2348494396078364218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Stern School of Business, New York University; Stern School of Business, New York University; Stern School of Business, New York University",
        "aff_domain": "STERN.NYU.EDU;STERN.NYU.EDU;STERN.NYU.EDU",
        "email": "STERN.NYU.EDU;STERN.NYU.EDU;STERN.NYU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Stern School of Business",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b1b13fbb61",
        "title": "Bregman Deviations of Generic Exponential Families",
        "site": "https://proceedings.mlr.press/v195/chowdhury23a.html",
        "author": "Sayak Ray Chowdhury; Patrick Saux; Odalric Maillard; Aditya Gopalan",
        "abstract": "We revisit the method of mixtures, or Laplace method, to study the concentration phenomenon in generic (possibly multidimensional) exponential families. Using the duality properties of the Bregman divergence associated with the log-partition function of the family to construct nonnegative martingales, we establish a generic bound controlling the deviation between the parameter of the family and a finite sample estimate, expressed in the local geometry induced by the Bregman pseudo-metric. Our bound is time-uniform and involves a quantity extending the classical information gain to exponential families, which we call the Bregman information gain.For the practitioner, we instantiate this novel bound to several classical families, e.g., Gaussian (including with unknown variance or multivariate), Bernoulli, Exponential, Weibull, Pareto, Poisson and Chi-square, yielding explicit forms of the confidence sets and the Bregman information gain. We further compare the resulting confidence bounds to state-of-the-art time-uniform alternatives and show this novel method yields competitive results. Finally, we apply our result to the design of generalized likelihood ratio tests for change detection, capturing new settings such as variance change in Gaussian families.",
        "bibtex": "@InProceedings{pmlr-v195-chowdhury23a,\n  title = \t {Bregman Deviations of Generic Exponential Families},\n  author =       {Chowdhury, Sayak Ray and Saux, Patrick and Maillard, Odalric and Gopalan, Aditya},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {394--449},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/chowdhury23a/chowdhury23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/chowdhury23a.html},\n  abstract = \t {We revisit the method of mixtures, or Laplace method, to study the concentration phenomenon in generic (possibly multidimensional) exponential families. Using the duality properties of the Bregman divergence associated with the log-partition function of the family to construct nonnegative martingales, we establish a generic bound controlling the deviation between the parameter of the family and a finite sample estimate, expressed in the local geometry induced by the Bregman pseudo-metric. Our bound is time-uniform and involves a quantity extending the classical information gain to exponential families, which we call the Bregman information gain.For the practitioner, we instantiate this novel bound to several classical families, e.g., Gaussian (including with unknown variance or multivariate), Bernoulli, Exponential, Weibull, Pareto, Poisson and Chi-square, yielding explicit forms of the confidence sets and the Bregman information gain. We further compare the resulting confidence bounds to state-of-the-art time-uniform alternatives and show this novel method yields competitive results. Finally, we apply our result to the design of generalized likelihood ratio tests for change detection, capturing new settings such as variance change in Gaussian families.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/chowdhury23a/chowdhury23a.pdf",
        "supp": "",
        "pdf_size": 4761419,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9552367729927191324&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Microsoft Research, India; Univ. Lille, Inria, CNRS, UMR 9189 - CRIStAL, F-59000, Lille, France; Univ. Lille, Inria, CNRS, UMR 9189 - CRIStAL, F-59000, Lille, France; Indian Institute of Science, Bangalore, India",
        "aff_domain": "microsoft.com;inria.fr;inria.fr;iisc.ac.in",
        "email": "microsoft.com;inria.fr;inria.fr;iisc.ac.in",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Microsoft;University of Lille;Indian Institute of Science",
        "aff_unique_dep": "Microsoft Research;Inria, CNRS, UMR 9189 - CRIStAL;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/india.aspx;https://www.univ-lille.fr;https://www.iisc.ac.in",
        "aff_unique_abbr": "MSR India;Univ. Lille;IISc",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";Lille;Bangalore",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "India;France"
    },
    {
        "id": "eb71a33414",
        "title": "Causal Matrix Completion",
        "site": "https://proceedings.mlr.press/v195/agarwal23c.html",
        "author": "Anish Agarwal; Munther Dahleh; Devavrat Shah; Dennis Shen",
        "abstract": "Matrix completion is the study of recovering an underlying matrix from a sparse subset of noisy observations. Traditionally, it is assumed that the entries of the matrix are \u201cmissing completely at random\u201d (MCAR), i.e., each entry is revealed at random, independent of everything else, with uniform probability. This is likely unrealistic due to the presence of \u201clatent confounders\u201d, i.e., unobserved factors that determine both the entries of the underlying matrix and the missingness pattern in the observed matrix. For example, in the context of movie recommender systems\u2014a canonical application for matrix completion\u2014a user who vehemently dislikes horror films is unlikely to ever watch horror films. In general, these confounders yield \u201cmissing not at random\u201d (MNAR) data, which can severely impact any inference procedure that does not correct for this bias. We develop a formal causal model for matrix completion through the language of potential outcomes, and provide novel identification arguments for a variety of causal estimands of interest. We design a procedure, which we call \u201csynthetic nearest neighbors\u201d (SNN), to estimate these causal estimands. We prove finite-sample consistency and asymptotic normality of our estimator. Our analysis also leads to new theoretical results for the matrix completion literature. In particular, we establish entry-wise, i.e., max-norm, finite-sample consistency and asymptotic normality results for matrix completion with MNAR data. As a special case, this also provides entry-wise bounds for matrix completion with MCAR data. Across simulated and real data, we demonstrate the efficacy of our proposed estimator.",
        "bibtex": "@InProceedings{pmlr-v195-agarwal23c,\n  title = \t {Causal Matrix Completion},\n  author =       {Agarwal, Anish and Dahleh, Munther and Shah, Devavrat and Shen, Dennis},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3821--3826},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/agarwal23c/agarwal23c.pdf},\n  url = \t {https://proceedings.mlr.press/v195/agarwal23c.html},\n  abstract = \t {Matrix completion is the study of recovering an underlying matrix from a sparse subset of noisy observations. Traditionally, it is assumed that the entries of the matrix are \u201cmissing completely at random\u201d (MCAR), i.e., each entry is revealed at random, independent of everything else, with uniform probability. This is likely unrealistic due to the presence of \u201clatent confounders\u201d, i.e., unobserved factors that determine both the entries of the underlying matrix and the missingness pattern in the observed matrix. For example, in the context of movie recommender systems\u2014a canonical application for matrix completion\u2014a user who vehemently dislikes horror films is unlikely to ever watch horror films. In general, these confounders yield \u201cmissing not at random\u201d (MNAR) data, which can severely impact any inference procedure that does not correct for this bias. We develop a formal causal model for matrix completion through the language of potential outcomes, and provide novel identification arguments for a variety of causal estimands of interest. We design a procedure, which we call \u201csynthetic nearest neighbors\u201d (SNN), to estimate these causal estimands. We prove finite-sample consistency and asymptotic normality of our estimator. Our analysis also leads to new theoretical results for the matrix completion literature. In particular, we establish entry-wise, i.e., max-norm, finite-sample consistency and asymptotic normality results for matrix completion with MNAR data. As a special case, this also provides entry-wise bounds for matrix completion with MCAR data. Across simulated and real data, we demonstrate the efficacy of our proposed estimator.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/agarwal23c/agarwal23c.pdf",
        "supp": "",
        "pdf_size": 367876,
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6225936837511593899&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Columbia University; MIT; MIT; USC",
        "aff_domain": "COLUMBIA.EDU;MIT.EDU;MIT.EDU;MARSHALL.USC.EDU",
        "email": "COLUMBIA.EDU;MIT.EDU;MIT.EDU;MARSHALL.USC.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Columbia University;Massachusetts Institute of Technology;University of Southern California",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.columbia.edu;https://web.mit.edu;https://www.usc.edu",
        "aff_unique_abbr": "Columbia;MIT;USC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b16bfc2efe",
        "title": "Community Detection in the Hypergraph SBM: Exact Recovery Given the Similarity Matrix",
        "site": "https://proceedings.mlr.press/v195/gaudio23a.html",
        "author": "Julia Gaudio; Nirmit Joshi",
        "abstract": "Community detection is a fundamental problem in network science. In this paper, we consider community detection in hypergraphs drawn from the \\emph{hypergraph stochastic block model} (HSBM), with a focus on exact community recovery. We study the performance of polynomial-time algorithms which operate on the \\emph{similarity matrix} $W$, where $W_{ij}$ reports the number of hyperedges containing both $i$ and $j$. Under this information model, while the precise information-theoretic limit is unknown, Kim, Bandeira, and Goemans derived a sharp threshold up to which the natural min-bisection estimator on $W$ succeeds. As min-bisection is NP-hard in the worst case, they additionally proposed a semidefinite programming (SDP) relaxation and conjectured that it achieves the same recovery threshold as the min-bisection algorithm. In this paper, we confirm this conjecture. We also design a simple and highly efficient spectral algorithm with nearly linear runtime and show that it achieves the min-bisection threshold. Moreover, the spectral algorithm also succeeds in denser regimes and is considerably more efficient than previous approaches, establishing it as the method of choice. Our analysis of the spectral algorithm crucially relies on strong \\emph{entrywise} bounds on the eigenvectors of $W$. Our bounds are inspired by the work of Abbe, Fan, Wang, and Zhong, who developed entrywise bounds for eigenvectors of symmetric matrices with independent entries. Despite the complex dependency structure in similarity matrices, we prove similar entrywise guarantees.",
        "bibtex": "@InProceedings{pmlr-v195-gaudio23a,\n  title = \t {Community Detection in the Hypergraph SBM: Exact Recovery Given the Similarity Matrix},\n  author =       {Gaudio, Julia and Joshi, Nirmit},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {469--510},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gaudio23a/gaudio23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gaudio23a.html},\n  abstract = \t { Community detection is a fundamental problem in network science. In this paper, we consider community detection in hypergraphs drawn from the \\emph{hypergraph stochastic block model} (HSBM), with a focus on exact community recovery. We study the performance of polynomial-time algorithms which operate on the \\emph{similarity matrix} $W$, where $W_{ij}$ reports the number of hyperedges containing both $i$ and $j$. Under this information model, while the precise information-theoretic limit is unknown, Kim, Bandeira, and Goemans derived a sharp threshold up to which the natural min-bisection estimator on $W$ succeeds. As min-bisection is NP-hard in the worst case, they additionally proposed a semidefinite programming (SDP) relaxation and conjectured that it achieves the same recovery threshold as the min-bisection algorithm. In this paper, we confirm this conjecture. We also design a simple and highly efficient spectral algorithm with nearly linear runtime and show that it achieves the min-bisection threshold. Moreover, the spectral algorithm also succeeds in denser regimes and is considerably more efficient than previous approaches, establishing it as the method of choice. Our analysis of the spectral algorithm crucially relies on strong \\emph{entrywise} bounds on the eigenvectors of $W$. Our bounds are inspired by the work of Abbe, Fan, Wang, and Zhong, who developed entrywise bounds for eigenvectors of symmetric matrices with independent entries. Despite the complex dependency structure in similarity matrices, we prove similar entrywise guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/gaudio23a/gaudio23a.pdf",
        "supp": "",
        "pdf_size": 525674,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1973767934645595869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Northwestern University; Toyota Technological Institute at Chicago",
        "aff_domain": "northwestern.edu;ttic.edu",
        "email": "northwestern.edu;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Northwestern University;Toyota Technological Institute at Chicago",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.northwestern.edu;https://www.tti-chicago.org",
        "aff_unique_abbr": "NU;TTI Chicago",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "30df50cf48",
        "title": "Complexity of High-Dimensional Identity Testing with Coordinate Conditional Sampling",
        "site": "https://proceedings.mlr.press/v195/blanca23a.html",
        "author": "Antonio Blanca; Zongchen Chen; Daniel \u0160tefankovi\u010d; Eric Vigoda",
        "abstract": "We study the identity testing problem for high-dimensional distributions. Given as input an explicit distribution $\\mu$, an $\\varepsilon>0$, and access to sampling oracle(s) for a hidden distribution $\\pi$, the goal in identity testing is to distinguish whether the two distributions $\\mu$ and $\\pi$ are identical or are at least $\\varepsilon$-far apart. When there is only access to full samples from the hidden distribution $\\pi$, it is known that exponentially many samples (in the dimension) may be needed for identity testing, and hence previous works have studied identity testing with additional access to various \u201cconditional\u201d sampling oracles. We consider a significantly weaker conditional sampling oracle, which we call the Coordinate Oracle, and provide a computational and statistical characterization of the identity testing problem in this new model.We prove that if an analytic property known as approximate tensorization of entropy holds for an $n$-dimensional visible distribution $\\mu$, then there is an efficient identity testing algorithm for any hidden distribution $\\pi$ using $\\widetilde{O}(n/\\varepsilon)$ queries to the Coordinate Oracle. Approximate tensorization of entropy is a pertinent condition as recent works have established it for a large class of high-dimensional distributions. We also prove a computational phase transition: for a well-studied class of $n$-dimensional distributions, specifically sparse antiferromagnetic Ising models over $\\{+1,-1\\}^n$, we show that in the regime where approximate tensorization of entropy fails, there is no efficient identity testing algorithm unless RP=NP. We complement our results with a matching $\\Omega(n/\\varepsilon)$ statistical lower bound for the sample complexity of identity testing in the $\\coorora$ model.",
        "bibtex": "@InProceedings{pmlr-v195-blanca23a,\n  title = \t {Complexity of High-Dimensional Identity Testing with Coordinate Conditional Sampling},\n  author =       {Blanca, Antonio and Chen, Zongchen and {\\v{S}}tefankovi{\\v{c}}, Daniel and Vigoda, Eric},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1774--1790},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/blanca23a/blanca23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/blanca23a.html},\n  abstract = \t {We study the identity testing problem for high-dimensional distributions. Given as input an explicit distribution $\\mu$, an $\\varepsilon>0$, and access to sampling oracle(s) for a hidden distribution $\\pi$, the goal in identity testing is to distinguish whether the two distributions $\\mu$ and $\\pi$ are identical or are at least $\\varepsilon$-far apart. When there is only access to full samples from the hidden distribution $\\pi$, it is known that exponentially many samples (in the dimension) may be needed for identity testing, and hence previous works have studied identity testing with additional access to various \u201cconditional\u201d sampling oracles. We consider a significantly weaker conditional sampling oracle, which we call the Coordinate Oracle, and provide a computational and statistical characterization of the identity testing problem in this new model.We prove that if an analytic property known as approximate tensorization of entropy holds for an $n$-dimensional visible distribution $\\mu$, then there is an efficient identity testing algorithm for any hidden distribution $\\pi$ using $\\widetilde{O}(n/\\varepsilon)$ queries to the Coordinate Oracle. Approximate tensorization of entropy is a pertinent condition as recent works have established it for a large class of high-dimensional distributions. We also prove a computational phase transition: for a well-studied class of $n$-dimensional distributions, specifically sparse antiferromagnetic Ising models over $\\{+1,-1\\}^n$, we show that in the regime where approximate tensorization of entropy fails, there is no efficient identity testing algorithm unless RP=NP. We complement our results with a matching $\\Omega(n/\\varepsilon)$ statistical lower bound for the sample complexity of identity testing in the $\\coorora$ model.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/blanca23a/blanca23a.pdf",
        "supp": "",
        "pdf_size": 285418,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2197334480717383107&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science and Engineering, Pennsylvania State University; Department of Mathematics, Massachusetts Institute of Technology; Department of Computer Science, University of Rochester; Department of Computer Science, University of California, Santa Barbara",
        "aff_domain": "CSE.PSU.EDU;MIT.EDU;CS.ROCHESTER.EDU;UCSB.EDU",
        "email": "CSE.PSU.EDU;MIT.EDU;CS.ROCHESTER.EDU;UCSB.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Pennsylvania State University;Massachusetts Institute of Technology;University of Rochester;University of California, Santa Barbara",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Mathematics;Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.psu.edu;https://web.mit.edu;https://www.rochester.edu;https://www.ucsb.edu",
        "aff_unique_abbr": "PSU;MIT;U of R;UCSB",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Cambridge;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "518985fb4b",
        "title": "Condition-number-independent Convergence Rate of Riemannian Hamiltonian Monte Carlo with Numerical Integrators",
        "site": "https://proceedings.mlr.press/v195/kook23a.html",
        "author": "Yunbum Kook; Yin Tat Lee; Ruoqi Shen; Santosh Vempala",
        "abstract": "We study the convergence rate of discretized Riemannian Hamiltonian Monte Carlo on sampling from distributions in the form of $e^{-f(x)}$ on a convex body $\\mathcal{M}\\subset\\R^{n}$. We show that for distributions in the form of $e^{-\\alpha^{\\top}x}$ on a polytope with $m$ constraints, the convergence rate of a family of commonly-used integrators is independent of $\\left\\Vert \\alpha\\right\\Vert _{2}$ and the geometry of the polytope. In particular, the implicit midpoint method (IMM) and the generalized Leapfrog method (LM) have a mixing time of $\\widetilde{O}\\left(mn^{3}\\right)$ to achieve $\\epsilon$ total variation distance to the target distribution. These guarantees are based on a general bound on the convergence rate for densities of the form $e^{-f(x)}$ in terms of parameters of the manifold and the integrator. Our theoretical guarantee complements the empirical results of \\cite{kook2022sampling}, which shows that RHMC with IMM can sample ill-conditioned, non-smooth and constrained distributions in very high dimension efficiently in practice.",
        "bibtex": "@InProceedings{pmlr-v195-kook23a,\n  title = \t {Condition-number-independent Convergence Rate of Riemannian Hamiltonian Monte Carlo with Numerical Integrators},\n  author =       {Kook, Yunbum and Lee, Yin Tat and Shen, Ruoqi and Vempala, Santosh},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4504--4569},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kook23a/kook23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kook23a.html},\n  abstract = \t {We study the convergence rate of discretized Riemannian Hamiltonian Monte Carlo on sampling from distributions in the form of $e^{-f(x)}$ on a convex body $\\mathcal{M}\\subset\\R^{n}$. We show that for distributions in the form of $e^{-\\alpha^{\\top}x}$ on a polytope with $m$ constraints, the convergence rate of a family of commonly-used integrators is independent of $\\left\\Vert \\alpha\\right\\Vert _{2}$ and the geometry of the polytope. In particular, the implicit midpoint method (IMM) and the generalized Leapfrog method (LM) have a mixing time of $\\widetilde{O}\\left(mn^{3}\\right)$ to achieve $\\epsilon$ total variation distance to the target distribution. These guarantees are based on a general bound on the convergence rate for densities of the form $e^{-f(x)}$ in terms of parameters of the manifold and the integrator. Our theoretical guarantee complements the empirical results of \\cite{kook2022sampling}, which shows that RHMC with IMM can sample ill-conditioned, non-smooth and constrained distributions in very high dimension efficiently in practice. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/kook23a/kook23a.pdf",
        "supp": "",
        "pdf_size": 630743,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15186780973303680444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Georgia Institute of Technology; University of Washington + Microsoft Research; University of Washington; Georgia Institute of Technology",
        "aff_domain": "GATECH.EDU;UW.EDU;CS.WASHINGTON.EDU;GATECH.EDU",
        "email": "GATECH.EDU;UW.EDU;CS.WASHINGTON.EDU;GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of Washington;Microsoft",
        "aff_unique_dep": ";;Microsoft Research",
        "aff_unique_url": "https://www.gatech.edu;https://www.washington.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Georgia Tech;UW;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3ff6e63248",
        "title": "Conference on Learning Theory 2023: Preface",
        "site": "https://proceedings.mlr.press/v195/neu23a.html",
        "author": "Gergely Neu; Lorenzo Rosasco",
        "abstract": "",
        "bibtex": "@InProceedings{pmlr-v195-neu23a,\n  title = \t {Conference on Learning Theory 2023: Preface},\n  author =       {Neu, Gergely and Rosasco, Lorenzo},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {i--i},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/neu23a/neu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/neu23a.html}\n}",
        "pdf": "https://proceedings.mlr.press/v195/neu23a/neu23a.pdf",
        "supp": "",
        "pdf_size": 48648,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Cgn3BUnkDwYJ:scholar.google.com/&scioq=Conference+on+Learning+Theory+2023:+Preface&hl=en&as_sdt=0,14",
        "gs_version_total": 0,
        "aff": "Universitat Pompeu Fabra, Barcelona, Spain; Universit\uf1e0 degli studi di Genova, Genova, Italy + CBMM, Massachusetts Institute of Technology, Boston, USA + Istituto Italiano di Tecnologia, Genova, Italy",
        "aff_domain": "GMAIL.COM;UNIGE.IT",
        "email": "GMAIL.COM;UNIGE.IT",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2+3",
        "aff_unique_norm": "Universitat Pompeu Fabra;University of Genoa;Massachusetts Institute of Technology;Istituto Italiano di Tecnologia",
        "aff_unique_dep": ";;CBMM;",
        "aff_unique_url": "https://www.upf.edu/;https://www.unige.it;https://web.mit.edu;https://www.iit.it",
        "aff_unique_abbr": "UPF;UniGe;MIT;IIT",
        "aff_campus_unique_index": "0;1+2+1",
        "aff_campus_unique": "Barcelona;Genova;Boston",
        "aff_country_unique_index": "0;1+2+1",
        "aff_country_unique": "Spain;Italy;United States"
    },
    {
        "id": "7e65b17b58",
        "title": "Contexts can be Cheap: Solving Stochastic Contextual Bandits with Linear Bandit Algorithms",
        "site": "https://proceedings.mlr.press/v195/hanna23a.html",
        "author": "Osama A Hanna; Lin Yang; Christina Fragouli",
        "abstract": "In this paper, we address the stochastic contextual linear bandit problem, where a decision maker is provided a context (a random set of actions drawn from a distribution). The expected reward of each action is specified by the inner product of the action  and an unknown parameter. The goal is to design an algorithm that learns to play as close as possible  to the unknown optimal policy after a number of action plays. This problem is considered more challenging than the linear bandit problem, which can be viewed as a contextual bandit problem with a \\emph{fixed} context. Surprisingly, in this paper, we show that the stochastic contextual problem can be solved as if it is a linear bandit problem. In particular, we establish a novel reduction framework that converts every stochastic contextual linear bandit instance to a linear bandit instance, when the context distribution is known. When the context distribution is unknown, we establish an algorithm that reduces the stochastic contextual instance to a sequence of linear bandit instances with small misspecifications and achieves nearly the same worst-case regret bound as the algorithm that solves the misspecified linear bandit instances.       As a consequence, our results imply a $O(d\\sqrt{T\\log T})$ high-probability regret bound for contextual linear bandits, making progress in resolving an open problem in Li et al., 2019b, 2021.      Our reduction framework opens up a new way to approach stochastic contextual linear bandit problems, and enables  improved regret bounds in a number of instances including the batch setting, contextual bandits with misspecifications, contextual bandits with sparse unknown parameters, and contextual bandits with adversarial corruption.",
        "bibtex": "@InProceedings{pmlr-v195-hanna23a,\n  title = \t {Contexts can be Cheap: Solving Stochastic Contextual Bandits with Linear Bandit Algorithms},\n  author =       {Hanna, Osama A and Yang, Lin and Fragouli, Christina},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1791--1821},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hanna23a/hanna23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hanna23a.html},\n  abstract = \t {   In this paper, we address the stochastic contextual linear bandit problem, where a decision maker is provided a context (a random set of actions drawn from a distribution). The expected reward of each action is specified by the inner product of the action  and an unknown parameter. The goal is to design an algorithm that learns to play as close as possible  to the unknown optimal policy after a number of action plays. This problem is considered more challenging than the linear bandit problem, which can be viewed as a contextual bandit problem with a \\emph{fixed} context. Surprisingly, in this paper, we show that the stochastic contextual problem can be solved as if it is a linear bandit problem. In particular, we establish a novel reduction framework that converts every stochastic contextual linear bandit instance to a linear bandit instance, when the context distribution is known. When the context distribution is unknown, we establish an algorithm that reduces the stochastic contextual instance to a sequence of linear bandit instances with small misspecifications and achieves nearly the same worst-case regret bound as the algorithm that solves the misspecified linear bandit instances.       As a consequence, our results imply a $O(d\\sqrt{T\\log T})$ high-probability regret bound for contextual linear bandits, making progress in resolving an open problem in Li et al., 2019b, 2021.      Our reduction framework opens up a new way to approach stochastic contextual linear bandit problems, and enables  improved regret bounds in a number of instances including the batch setting, contextual bandits with misspecifications, contextual bandits with sparse unknown parameters, and contextual bandits with adversarial corruption.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hanna23a/hanna23a.pdf",
        "supp": "",
        "pdf_size": 376606,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17818672001311627707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "aff_domain": "UCLA.EDU;UCLA.EDU;UCLA.EDU",
        "email": "UCLA.EDU;UCLA.EDU;UCLA.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0647108a0c",
        "title": "Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression",
        "site": "https://proceedings.mlr.press/v195/foster23c.html",
        "author": "Aleksandrs Slivkins; Karthik Abinav Sankararaman; Dylan J Foster",
        "abstract": "We consider contextual bandits with linear constraints (CBwLC), a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We provide the first algorithm for CBwLC (or CBwK) that is based on regression oracles. The algorithm is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for the variant of CBwK in which the algorithm must stop once some constraint is violated. Further, we provide the first vanishing-regret guarantees for CBwLC (or CBwK) that extend beyond the stochastic environment. We side-step strong impossibility results from prior work by identifying a weaker (and, arguably, fairer) benchmark to compare against. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019), a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.",
        "bibtex": "@InProceedings{pmlr-v195-foster23c,\n  title = \t {Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression},\n  author =       {Slivkins, Aleksandrs and Sankararaman, Karthik Abinav and Foster, Dylan J},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4633--4656},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/foster23c/foster23c.pdf},\n  url = \t {https://proceedings.mlr.press/v195/foster23c.html},\n  abstract = \t {We consider contextual bandits with linear constraints (CBwLC), a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We provide the first algorithm for CBwLC (or CBwK) that is based on regression oracles. The algorithm is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for the variant of CBwK in which the algorithm must stop once some constraint is violated. Further, we provide the first vanishing-regret guarantees for CBwLC (or CBwK) that extend beyond the stochastic environment. We side-step strong impossibility results from prior work by identifying a weaker (and, arguably, fairer) benchmark to compare against. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019), a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/foster23c/foster23c.pdf",
        "supp": "",
        "pdf_size": 572193,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16715314821110334976&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft Research NYC, New York, NY, USA; Meta; Microsoft Research NYC, New York, NY, USA",
        "aff_domain": "microsoft.com;gmail.com;microsoft.com",
        "email": "microsoft.com;gmail.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Microsoft;Meta",
        "aff_unique_dep": "Microsoft Research;Meta Platforms, Inc.",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-new-york-city;https://meta.com",
        "aff_unique_abbr": "MSR NYC;Meta",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York City;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "00b2207ac4",
        "title": "Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and Relaxed Assumptions",
        "site": "https://proceedings.mlr.press/v195/wang23a.html",
        "author": "Bohan Wang; Huishuai Zhang; Zhiming Ma; Wei Chen",
        "abstract": "We provide a simple convergence proof for AdaGrad optimizing non-convex objectives under only affine noise variance and bounded smoothness assumptions. The proof is essentially based on a novel auxiliary function $\\xi$ that helps eliminate the complexity of handling the correlation between the numerator and denominator of AdaGrad\u2019s update. Leveraging simple proofs, we are able to obtain tighter results than existing results [Faw et al 2002] and extend the analysis to several new and important cases. Specifically, for the over-parameterized regime, we show that AdaGrad needs only $\\mathcal{O}(\\frac{1}{\\varepsilon^2})$ iterations to ensure the gradient norm smaller than $\\varepsilon$, which matches the rate of SGD and significantly tighter than existing rates $\\mathcal{O}(\\frac{1}{\\varepsilon^4})$ for AdaGrad. We then discard the bounded smoothness assumption, and consider a realistic assumption on smoothness called $(L_0,L_1)$-smooth condition, which allows local smoothness to grow with the gradient norm. Again based on the auxiliary function $\\xi$, we prove that AdaGrad succeeds in converging under $(L_0,L_1)$-smooth condition as long as the learning rate is lower than a threshold. Interestingly, we further show that the requirement on learning rate under the $(L_0,L_1)$-smooth condition is necessary via proof by contradiction, in contrast with the case of uniform smoothness conditions where convergence is guaranteed regardless of learning rate choices. Together, our analyses broaden the understanding of AdaGrad and demonstrate the power of the new auxiliary function in the investigations of AdaGrad.",
        "bibtex": "@InProceedings{pmlr-v195-wang23a,\n  title = \t {Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and Relaxed Assumptions},\n  author =       {Wang, Bohan and Zhang, Huishuai and Ma, Zhiming and Chen, Wei},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {161--190},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wang23a/wang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wang23a.html},\n  abstract = \t {We provide a simple convergence proof for AdaGrad optimizing non-convex objectives under only affine noise variance and bounded smoothness assumptions. The proof is essentially based on a novel auxiliary function $\\xi$ that helps eliminate the complexity of handling the correlation between the numerator and denominator of AdaGrad\u2019s update. Leveraging simple proofs, we are able to obtain tighter results than existing results [Faw et al 2002] and extend the analysis to several new and important cases. Specifically, for the over-parameterized regime, we show that AdaGrad needs only $\\mathcal{O}(\\frac{1}{\\varepsilon^2})$ iterations to ensure the gradient norm smaller than $\\varepsilon$, which matches the rate of SGD and significantly tighter than existing rates $\\mathcal{O}(\\frac{1}{\\varepsilon^4})$ for AdaGrad. We then discard the bounded smoothness assumption, and consider a realistic assumption on smoothness called $(L_0,L_1)$-smooth condition, which allows local smoothness to grow with the gradient norm. Again based on the auxiliary function $\\xi$, we prove that AdaGrad succeeds in converging under $(L_0,L_1)$-smooth condition as long as the learning rate is lower than a threshold. Interestingly, we further show that the requirement on learning rate under the $(L_0,L_1)$-smooth condition is necessary via proof by contradiction, in contrast with the case of uniform smoothness conditions where convergence is guaranteed regardless of learning rate choices. Together, our analyses broaden the understanding of AdaGrad and demonstrate the power of the new auxiliary function in the investigations of AdaGrad.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wang23a/wang23a.pdf",
        "supp": "",
        "pdf_size": 469583,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12091947499410899140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Science and Technology of China; Microsoft Research Asia; Academy of Mathematics and Systems Science, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences",
        "aff_domain": "GMAIL.COM;MICROSOFT.COM;AMT.AC.CN;ICT.AC.CN",
        "email": "GMAIL.COM;MICROSOFT.COM;AMT.AC.CN;ICT.AC.CN",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Science and Technology of China;Microsoft;Chinese Academy of Sciences",
        "aff_unique_dep": ";Research;Academy of Mathematics and Systems Science",
        "aff_unique_url": "http://www.ustc.edu.cn;https://www.microsoft.com/en-us/research/group/asia;http://www.amss.cas.cn",
        "aff_unique_abbr": "USTC;MSR Asia;AMSS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Asia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "2ff500763e",
        "title": "Curvature and complexity: Better lower bounds for geodesically convex optimization",
        "site": "https://proceedings.mlr.press/v195/criscitiello23a.html",
        "author": "Christopher Criscitiello; Nicolas Boumal",
        "abstract": "We study the query complexity of geodesically convex (g-convex) optimization on a manifold.  To isolate the effect of that manifold\u2019s curvature, we primarily focus on hyperbolic spaces.  In a variety of settings (smooth or not; strongly g-convex or not; high- or low-dimensional), known upper bounds worsen with curvature.  It is natural to ask whether this is warranted, or an artifact.For many such settings, we propose a first set of lower bounds which indeed confirm that (negative) curvature is detrimental to complexity.  To do so, we build on recent lower bounds (Hamilton and Moitra, 2021; Criscitiello and Boumal, 2022) for the particular case of smooth, strongly g-convex optimization.  Using a number of techniques, we also secure lower bounds which capture dependence on condition number and optimality gap, which was not previously the case.We suspect these bounds are not optimal.  We conjecture optimal ones, and support them with a matching lower bound for a class of algorithms which includes subgradient descent, and a lower bound for a related game.  Lastly, to pinpoint the difficulty of proving lower bounds, we study how negative curvature influences (and sometimes obstructs) interpolation with g-convex functions.",
        "bibtex": "@InProceedings{pmlr-v195-criscitiello23a,\n  title = \t {Curvature and complexity: Better lower bounds for geodesically convex optimization},\n  author =       {Criscitiello, Christopher and Boumal, Nicolas},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2969--3013},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/criscitiello23a/criscitiello23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/criscitiello23a.html},\n  abstract = \t {We study the query complexity of geodesically convex (g-convex) optimization on a manifold.  To isolate the effect of that manifold\u2019s curvature, we primarily focus on hyperbolic spaces.  In a variety of settings (smooth or not; strongly g-convex or not; high- or low-dimensional), known upper bounds worsen with curvature.  It is natural to ask whether this is warranted, or an artifact.For many such settings, we propose a first set of lower bounds which indeed confirm that (negative) curvature is detrimental to complexity.  To do so, we build on recent lower bounds (Hamilton and Moitra, 2021; Criscitiello and Boumal, 2022) for the particular case of smooth, strongly g-convex optimization.  Using a number of techniques, we also secure lower bounds which capture dependence on condition number and optimality gap, which was not previously the case.We suspect these bounds are not optimal.  We conjecture optimal ones, and support them with a matching lower bound for a class of algorithms which includes subgradient descent, and a lower bound for a related game.  Lastly, to pinpoint the difficulty of proving lower bounds, we study how negative curvature influences (and sometimes obstructs) interpolation with g-convex functions.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/criscitiello23a/criscitiello23a.pdf",
        "supp": "",
        "pdf_size": 568743,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17686105428901625628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Ecole Polytechnique F\u00e9d\u00e9r\u00e1le de Lausanne (EPFL), Institute of Mathematics; Ecole Polytechnique F\u00e9d\u00e9r\u00e1le de Lausanne (EPFL), Institute of Mathematics",
        "aff_domain": "epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Institute of Mathematics",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "879368d44f",
        "title": "Detection-Recovery Gap for Planted Dense Cycles",
        "site": "https://proceedings.mlr.press/v195/mao23a.html",
        "author": "Cheng Mao; Alexander S. Wein; Shenduo Zhang",
        "abstract": "Planted dense cycles are a type of latent structure that appears in many applications, such as small-world networks in social sciences and sequence assembly in computational biology. We consider a model where a dense cycle with expected bandwidth $n \\tau$ and edge density $p$ is planted in an Erd\u0151s\u2013R\u00e9nyi graph $G(n,q)$. We characterize the computational thresholds for the associated detection and recovery problems for the class of low-degree polynomial algorithms. In particular, a gap exists between the two thresholds in a certain regime of parameters. For example, if $n^{-3/4} \\ll \\tau \\ll n^{-1/2}$ and $p = C q = \\Theta(1)$ for a constant $C>1$, the detection problem is computationally easy while the recovery problem is hard for low-degree algorithms.",
        "bibtex": "@InProceedings{pmlr-v195-mao23a,\n  title = \t {Detection-Recovery Gap for Planted Dense Cycles},\n  author =       {Mao, Cheng and Wein, Alexander S. and Zhang, Shenduo},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2440--2481},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mao23a/mao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mao23a.html},\n  abstract = \t {Planted dense cycles are a type of latent structure that appears in many applications, such as small-world networks in social sciences and sequence assembly in computational biology. We consider a model where a dense cycle with expected bandwidth $n \\tau$ and edge density $p$ is planted in an Erd\u0151s\u2013R\u00e9nyi graph $G(n,q)$. We characterize the computational thresholds for the associated detection and recovery problems for the class of low-degree polynomial algorithms. In particular, a gap exists between the two thresholds in a certain regime of parameters. For example, if $n^{-3/4} \\ll \\tau \\ll n^{-1/2}$ and $p = C q = \\Theta(1)$ for a constant $C>1$, the detection problem is computationally easy while the recovery problem is hard for low-degree algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mao23a/mao23a.pdf",
        "supp": "",
        "pdf_size": 463543,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6133644049918964690&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "School of Mathematics, Georgia Institute of Technology; Department of Mathematics, University of California, Davis; School of Mathematics, Georgia Institute of Technology",
        "aff_domain": "MATH.GATECH.EDU;UCDAVIS.EDU;GATECH.EDU",
        "email": "MATH.GATECH.EDU;UCDAVIS.EDU;GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of California, Davis",
        "aff_unique_dep": "School of Mathematics;Department of Mathematics",
        "aff_unique_url": "https://www.gatech.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "Georgia Tech;UC Davis",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Davis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "720ce76b02",
        "title": "Detection-Recovery and Detection-Refutation Gaps via Reductions from Planted Clique",
        "site": "https://proceedings.mlr.press/v195/bresler23a.html",
        "author": "Guy Bresler; Tianze Jiang",
        "abstract": "Planted Dense Subgraph (PDS) problem is a prototypical problem with a computational-statistical gap. It also exhibits an intriguing additional phenomenon: different tasks, such as detection or recovery, appear to have different computational limits. A detection-recovery gap for PDS was substantiated in the form of a precise conjecture given by Chen and Xu (2014) (based on the parameter values for which a convexified MLE succeeds), and then shown to hold for low-degree polynomial algorithms by Schramm and Wein (2022) and for MCMC algorithms for Ben Arous et al. (2020). In this paper we demonstrate that a slight variation of the Planted Clique Hypothesis with secret leakage (introduced in Brennan and Bresler (2020)), implies a detection-recovery gap for PDS. In the same vein, we also obtain a sharp lower bound for refutation, yielding a detection-refutation gap. Our methods build on the framework of Brennan and Bresler (2020) to construct average-case reductions mapping secret leakage Planted Clique to appropriate target problems.",
        "bibtex": "@InProceedings{pmlr-v195-bresler23a,\n  title = \t {Detection-Recovery and Detection-Refutation Gaps via Reductions from Planted Clique},\n  author =       {Bresler, Guy and Jiang, Tianze},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5850--5889},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bresler23a/bresler23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bresler23a.html},\n  abstract = \t {Planted Dense Subgraph (PDS) problem is a prototypical problem with a computational-statistical gap. It also exhibits an intriguing additional phenomenon: different tasks, such as detection or recovery, appear to have different computational limits. A detection-recovery gap for PDS was substantiated in the form of a precise conjecture given by Chen and Xu (2014) (based on the parameter values for which a convexified MLE succeeds), and then shown to hold for low-degree polynomial algorithms by Schramm and Wein (2022) and for MCMC algorithms for Ben Arous et al. (2020). In this paper we demonstrate that a slight variation of the Planted Clique Hypothesis with secret leakage (introduced in Brennan and Bresler (2020)), implies a detection-recovery gap for PDS. In the same vein, we also obtain a sharp lower bound for refutation, yielding a detection-refutation gap. Our methods build on the framework of Brennan and Bresler (2020) to construct average-case reductions mapping secret leakage Planted Clique to appropriate target problems. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/bresler23a/bresler23a.pdf",
        "supp": "",
        "pdf_size": 503921,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=859243912884396495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "77 Massachusetts Ave., Cambridge, MA, USA; 77 Massachusetts Ave., Cambridge, MA, USA",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu/",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "49fd5176c5",
        "title": "Deterministic Nonsmooth Nonconvex Optimization",
        "site": "https://proceedings.mlr.press/v195/jordan23a.html",
        "author": "Michael Jordan; Guy Kornowski; Tianyi Lin; Ohad Shamir; Manolis Zampetakis",
        "abstract": "We study the complexity of optimizing nonsmooth nonconvex Lipschitz functions by producing $(\\delta,\\epsilon)$-Goldstein stationary points. Several recent works have presented randomized algorithms that produce such points using $\\widetilde{O}(\\delta^{-1}\\epsilon^{-3})$ first-order oracle calls, independent of the dimension $d$.  It has been an open problem as to whether a similar result can be obtained via a deterministic algorithm. We resolve this open problem, showing that randomization is necessary to obtain a dimension-free rate. In particular, we prove a lower bound of $\\Omega(d)$ for any deterministic algorithm. Moreover, we show that unlike smooth or convex optimization, access to function values is required for any deterministic algorithm to halt within any finite time horizon.On the other hand, we prove that if the function is even slightly smooth, then the dimension-free rate of $\\widetilde{O}(\\delta^{-1}\\epsilon^{-3})$ can be obtained by a deterministic algorithm with merely a logarithmic dependence on the smoothness parameter. Motivated by these findings, we turn to study the complexity of deterministically smoothing Lipschitz functions. Though there are well-known efficient black-box randomized smoothings, we start by showing that no such deterministic procedure can smooth functions in a meaningful manner (suitably defined), resolving an open question in the literature. We then bypass this impossibility result for the structured case of ReLU neural networks. To that end, in a practical \u201cwhite-box\u201d setting in which the optimizer is granted access to the network\u2019s architecture, we propose a simple, dimension-free, deterministic smoothing of ReLU networks that provably preserves $(\\delta,\\epsilon)$-Goldstein stationary points. Our method applies to a variety of architectures of arbitrary depth, including ResNets and ConvNets.Combined with our algorithm for slightly-smooth functions, this yields the first deterministic, dimension-free algorithm for optimizing ReLU networks, circumventing our lower bound.",
        "bibtex": "@InProceedings{pmlr-v195-jordan23a,\n  title = \t {Deterministic Nonsmooth Nonconvex Optimization},\n  author =       {Jordan, Michael and Kornowski, Guy and Lin, Tianyi and Shamir, Ohad and Zampetakis, Manolis},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4570--4597},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/jordan23a/jordan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/jordan23a.html},\n  abstract = \t {We study the complexity of optimizing nonsmooth nonconvex Lipschitz functions by producing $(\\delta,\\epsilon)$-Goldstein stationary points. Several recent works have presented randomized algorithms that produce such points using $\\widetilde{O}(\\delta^{-1}\\epsilon^{-3})$ first-order oracle calls, independent of the dimension $d$.  It has been an open problem as to whether a similar result can be obtained via a deterministic algorithm. We resolve this open problem, showing that randomization is necessary to obtain a dimension-free rate. In particular, we prove a lower bound of $\\Omega(d)$ for any deterministic algorithm. Moreover, we show that unlike smooth or convex optimization, access to function values is required for any deterministic algorithm to halt within any finite time horizon.On the other hand, we prove that if the function is even slightly smooth, then the dimension-free rate of $\\widetilde{O}(\\delta^{-1}\\epsilon^{-3})$ can be obtained by a deterministic algorithm with merely a logarithmic dependence on the smoothness parameter. Motivated by these findings, we turn to study the complexity of deterministically smoothing Lipschitz functions. Though there are well-known efficient black-box randomized smoothings, we start by showing that no such deterministic procedure can smooth functions in a meaningful manner (suitably defined), resolving an open question in the literature. We then bypass this impossibility result for the structured case of ReLU neural networks. To that end, in a practical \u201cwhite-box\u201d setting in which the optimizer is granted access to the network\u2019s architecture, we propose a simple, dimension-free, deterministic smoothing of ReLU networks that provably preserves $(\\delta,\\epsilon)$-Goldstein stationary points. Our method applies to a variety of architectures of arbitrary depth, including ResNets and ConvNets.Combined with our algorithm for slightly-smooth functions, this yields the first deterministic, dimension-free algorithm for optimizing ReLU networks, circumventing our lower bound.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/jordan23a/jordan23a.pdf",
        "supp": "",
        "pdf_size": 458721,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9233180830765686476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, Berkeley; Weizmann Institute of Science; University of California, Berkeley; Weizmann Institute of Science; University of California, Berkeley",
        "aff_domain": "CS.BERKELEY.EDU;WEIZMANN.AC.IL;BERKELEY.EDU;WEIZMANN.AC.IL;BERKELEY.EDU",
        "email": "CS.BERKELEY.EDU;WEIZMANN.AC.IL;BERKELEY.EDU;WEIZMANN.AC.IL;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Weizmann Institute of Science",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.weizmann.org.il",
        "aff_unique_abbr": "UC Berkeley;Weizmann",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "2144c06620",
        "title": "Differentially Private Algorithms for the Stochastic Saddle Point Problem with Optimal Rates for the Strong Gap",
        "site": "https://proceedings.mlr.press/v195/bassily23a.html",
        "author": "Raef Bassily; Crist\u00f3bal Guzm\u00e1n; Michael Menart",
        "abstract": "We show that convex-concave Lipschitz stochastic saddle point problems (also known as stochastic minimax optimization) can be solved under the constraint of $(\\epsilon,\\delta)$-differential privacy with \\emph{strong (primal-dual) gap} rate of $\\tilde O\\big(\\frac{1}{\\sqrt{n}} + \\frac{\\sqrt{d}}{n\\epsilon}\\big)$, where $n$ is the dataset size and $d$ is the dimension of the problem. This rate is nearly optimal, based on existing lower bounds in differentially private stochastic optimization. Specifically, we prove a tight upper bound on the strong gap via novel implementation and analysis of the recursive regularization technique repurposed for saddle point problems. We show that this rate can be attained with  $O\\big(\\min\\big\\{\\frac{n^2\\epsilon^{1.5}}{\\sqrt{d}}, n^{3/2}\\big\\}\\big)$ gradient complexity, and $\\tilde{O}(n)$ gradient complexity if the loss function is smooth. As a byproduct of our method, we develop a general algorithm that, given a black-box access to a subroutine satisfying a certain $\\alpha$ primal-dual accuracy guarantee with respect to the empirical objective, gives a solution to the stochastic saddle point problem with a strong gap of $\\tilde{O}(\\alpha+\\frac{1}{\\sqrt{n}})$. We show that this $\\alpha$-accuracy condition is satisfied by standard algorithms for the empirical saddle point problem such as the proximal point method and the stochastic gradient descent ascent algorithm. Finally, to emphasize the importance of the strong gap as a convergence criterion compared to the weaker notion of primal-dual gap, commonly known as the \\emph{weak gap}, we show that even for simple problems it is possible for an algorithm to have zero weak gap and suffer from $\\Omega(1)$ strong gap. We also show that there exists a fundamental tradeoff between stability and accuracy. Specifically, we show that any $\\Delta$-stable algorithm has empirical gap $\\Omega\\big(\\frac{1}{\\Delta n}\\big)$, and that this bound is tight. This result also holds also more specifically for empirical risk minimization problems and may be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v195-bassily23a,\n  title = \t {Differentially Private Algorithms for the Stochastic Saddle Point Problem with Optimal Rates for the Strong Gap},\n  author =       {Bassily, Raef and Guzm{\\'a}n, Crist{\\'o}bal and Menart, Michael},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2482--2508},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bassily23a/bassily23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bassily23a.html},\n  abstract = \t {We show that convex-concave Lipschitz stochastic saddle point problems (also known as stochastic minimax optimization) can be solved under the constraint of $(\\epsilon,\\delta)$-differential privacy with \\emph{strong (primal-dual) gap} rate of $\\tilde O\\big(\\frac{1}{\\sqrt{n}} + \\frac{\\sqrt{d}}{n\\epsilon}\\big)$, where $n$ is the dataset size and $d$ is the dimension of the problem. This rate is nearly optimal, based on existing lower bounds in differentially private stochastic optimization. Specifically, we prove a tight upper bound on the strong gap via novel implementation and analysis of the recursive regularization technique repurposed for saddle point problems. We show that this rate can be attained with  $O\\big(\\min\\big\\{\\frac{n^2\\epsilon^{1.5}}{\\sqrt{d}}, n^{3/2}\\big\\}\\big)$ gradient complexity, and $\\tilde{O}(n)$ gradient complexity if the loss function is smooth. As a byproduct of our method, we develop a general algorithm that, given a black-box access to a subroutine satisfying a certain $\\alpha$ primal-dual accuracy guarantee with respect to the empirical objective, gives a solution to the stochastic saddle point problem with a strong gap of $\\tilde{O}(\\alpha+\\frac{1}{\\sqrt{n}})$. We show that this $\\alpha$-accuracy condition is satisfied by standard algorithms for the empirical saddle point problem such as the proximal point method and the stochastic gradient descent ascent algorithm. Finally, to emphasize the importance of the strong gap as a convergence criterion compared to the weaker notion of primal-dual gap, commonly known as the \\emph{weak gap}, we show that even for simple problems it is possible for an algorithm to have zero weak gap and suffer from $\\Omega(1)$ strong gap. We also show that there exists a fundamental tradeoff between stability and accuracy. Specifically, we show that any $\\Delta$-stable algorithm has empirical gap $\\Omega\\big(\\frac{1}{\\Delta n}\\big)$, and that this bound is tight. This result also holds also more specifically for empirical risk minimization problems and may be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/bassily23a/bassily23a.pdf",
        "supp": "",
        "pdf_size": 465554,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10267185565493843088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science & Engineering and the Translational Data Analytics Institute (TDAI), The Ohio State University; Institute for Mathematical and Computational Eng., Facultad de Matem \u00b4aticas & Escuela de Ingenier \u00b4\u0131a, Pontificia Universidad Cat \u00b4olica de Chile; Department of Computer Science & Engineering, The Ohio State University",
        "aff_domain": "OSU.EDU;MAT.UC.CL;OSU.EDU",
        "email": "OSU.EDU;MAT.UC.CL;OSU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ohio State University;Pontificia Universidad Cat\u00f3lica de Chile",
        "aff_unique_dep": "Department of Computer Science & Engineering;Institute for Mathematical and Computational Eng.",
        "aff_unique_url": "https://www.osu.edu;https://www.puc.cl",
        "aff_unique_abbr": "OSU;PUC Chile",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Chile"
    },
    {
        "id": "8087f25e91",
        "title": "Differentially Private and Lazy Online Convex Optimization",
        "site": "https://proceedings.mlr.press/v195/agarwal23d.html",
        "author": "Naman Agarwal; Satyen Kale; Karan Singh; Abhradeep Thakurta",
        "abstract": "We study the task of differentially private online convex optimization (OCO). In the online setting, the release of each distinct decision or iterate carries with it the potential for privacy loss. To limit such privacy leakage, we design an optimization-based OCO algorithm that explicitly limits the number of switches via objective perturbation and rejection sampling. This improves over known results in multiple aspects: an optimal leading-order regret term, in being efficiently implementable without requiring log-concave sampling subroutines, and in matching the non-private regret bound for sub-constant regimes of privacy parameters. Leveraging the fact that the algorithm is designed to explicitly minimize the number of switches of decisions, we show that the algorithm also obtains optimal regret bounds in the lazy OCO setting, where the learner is constrained to perform a limited number of switches. In addition, for one- and two-dimensional decision sets, we present a novel approach for differentially private online Lipschitz learning, where the loss functions are Lipschitz but not necessarily convex, that achieves the optimal regret bound matching known lower bounds.",
        "bibtex": "@InProceedings{pmlr-v195-agarwal23d,\n  title = \t {Differentially Private and Lazy Online Convex Optimization},\n  author =       {Agarwal, Naman and Kale, Satyen and Singh, Karan and Thakurta, Abhradeep},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4599--4632},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/agarwal23d/agarwal23d.pdf},\n  url = \t {https://proceedings.mlr.press/v195/agarwal23d.html},\n  abstract = \t {We study the task of differentially private online convex optimization (OCO). In the online setting, the release of each distinct decision or iterate carries with it the potential for privacy loss. To limit such privacy leakage, we design an optimization-based OCO algorithm that explicitly limits the number of switches via objective perturbation and rejection sampling. This improves over known results in multiple aspects: an optimal leading-order regret term, in being efficiently implementable without requiring log-concave sampling subroutines, and in matching the non-private regret bound for sub-constant regimes of privacy parameters. Leveraging the fact that the algorithm is designed to explicitly minimize the number of switches of decisions, we show that the algorithm also obtains optimal regret bounds in the lazy OCO setting, where the learner is constrained to perform a limited number of switches. In addition, for one- and two-dimensional decision sets, we present a novel approach for differentially private online Lipschitz learning, where the loss functions are Lipschitz but not necessarily convex, that achieves the optimal regret bound matching known lower bounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/agarwal23d/agarwal23d.pdf",
        "supp": "",
        "pdf_size": 478454,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13086202563478936519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Google DeepMind; Google Research; Tepper School of Business, Carnegie Mellon University; Google DeepMind",
        "aff_domain": "google.com;google.com;cmu.edu;google.com",
        "email": "google.com;google.com;cmu.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Google;Carnegie Mellon University",
        "aff_unique_dep": "Google DeepMind;Tepper School of Business",
        "aff_unique_url": "https://deepmind.com;https://www.cmu.edu",
        "aff_unique_abbr": "DeepMind;CMU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "b2ef70d8e6",
        "title": "Distribution-Independent Regression for Generalized Linear Models with Oblivious Corruptions",
        "site": "https://proceedings.mlr.press/v195/diakonikolas23e.html",
        "author": "Ilias Diakonikolas; Sushrut Karmalkar; Jong Ho Park; Christos Tzamos",
        "abstract": "We demonstrate the first algorithms for the problem of regression for generalized linear models (GLMs) in the presence of additive oblivious noise. We assume we have sample access to examples $(x, y)$ where $y$ is a noisy measurement of $g(w^* \\cdot x)$. In particular, $y = g(w^* \\cdot x) + \\xi + \\eps$ where $\\xi$ is the oblivious noise drawn independently of $x$, satisfying  $\\Pr[\\xi = 0] \\geq o(1)$, and $\\eps \\sim \\cN(0, \\sigma^2)$. Our goal is to accurately recover a function $g(w \\cdot x)$ with arbitrarily small error when compared to the true values $g(w^* \\cdot x)$, rather than the noisy measurements $y$. We present an algorithm that tackles the problem in its most general distribution-independent setting, where the solution may not be identifiable. The algorithm is designed to return the solution if it is identifiable, and otherwise return a small list of candidates, one of which is close to the true solution. Furthermore, we characterize a necessary and sufficient condition for identifiability, which holds in broad settings. The problem is identifiable when the quantile at which $\\xi + \\eps = 0$ is known, or when the family of hypotheses does not contain candidates that are nearly equal to a translated $g(w^* \\cdot x) + A$ for some real number $A$, while also having large error when compared to $g(w^* \\cdot x)$. This is the first result for GLM regression which can handle more than half the samples being arbitrarily corrupted. Prior work focused largely on the setting of linear regression with oblivious noise, and giving algorithms under more restrictive assumptions.",
        "bibtex": "@InProceedings{pmlr-v195-diakonikolas23e,\n  title = \t {Distribution-Independent Regression for Generalized Linear Models with Oblivious Corruptions},\n  author =       {Diakonikolas, Ilias and Karmalkar, Sushrut and Park, Jong Ho and Tzamos, Christos},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5453--5475},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/diakonikolas23e/diakonikolas23e.pdf},\n  url = \t {https://proceedings.mlr.press/v195/diakonikolas23e.html},\n  abstract = \t {We demonstrate the first algorithms for the problem of regression for generalized linear models (GLMs) in the presence of additive oblivious noise. We assume we have sample access to examples $(x, y)$ where $y$ is a noisy measurement of $g(w^* \\cdot x)$. In particular, $y = g(w^* \\cdot x) + \\xi + \\eps$ where $\\xi$ is the oblivious noise drawn independently of $x$, satisfying  $\\Pr[\\xi = 0] \\geq o(1)$, and $\\eps \\sim \\cN(0, \\sigma^2)$. Our goal is to accurately recover a function $g(w \\cdot x)$ with arbitrarily small error when compared to the true values $g(w^* \\cdot x)$, rather than the noisy measurements $y$. We present an algorithm that tackles the problem in its most general distribution-independent setting, where the solution may not be identifiable. The algorithm is designed to return the solution if it is identifiable, and otherwise return a small list of candidates, one of which is close to the true solution. Furthermore, we characterize a necessary and sufficient condition for identifiability, which holds in broad settings. The problem is identifiable when the quantile at which $\\xi + \\eps = 0$ is known, or when the family of hypotheses does not contain candidates that are nearly equal to a translated $g(w^* \\cdot x) + A$ for some real number $A$, while also having large error when compared to $g(w^* \\cdot x)$. This is the first result for GLM regression which can handle more than half the samples being arbitrarily corrupted. Prior work focused largely on the setting of linear regression with oblivious noise, and giving algorithms under more restrictive assumptions.  }\n}",
        "pdf": "https://proceedings.mlr.press/v195/diakonikolas23e/diakonikolas23e.pdf",
        "supp": "",
        "pdf_size": 458266,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18437840690892508876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison; KRAFTON Inc. + University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": "CS.WISC.EDU;WISC.EDU;WISC.EDU;GMAIL.COM",
        "email": "CS.WISC.EDU;WISC.EDU;WISC.EDU;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+0;0",
        "aff_unique_norm": "University of Wisconsin-Madison;KRAFTON Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.krafton.com",
        "aff_unique_abbr": "UW-Madison;KRAFTON",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Madison;",
        "aff_country_unique_index": "0;0;1+0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "963d4e5a01",
        "title": "Efficient Algorithms for Sparse Moment Problems without Separation",
        "site": "https://proceedings.mlr.press/v195/fan23b.html",
        "author": "Zhiyuan Fan; Jian Li",
        "abstract": "We consider the sparse moment problem of learning a $k$-spike mixture in high-dimensional space from its noisy moment information in any dimension. We measure the accuracy of the learned mixtures using transportation distance. Previous algorithms either assume certain separation assumptions, use more recovery moments, or run in (super) exponential time. Our algorithm for the 1-dimensional problem (also called the sparse Hausdorff moment problem) is a robust version of the classic Prony\u2019s method, and our contribution mainly lies in the analysis. We adopt a global and much tighter analysis than previous work (which analyzes the perturbation of the intermediate results of Prony\u2019s method). A useful technical ingredient is a connection between the linear system defined by the Vandermonde matrix and the Schur polynomial, which allows us to provide tight perturbation bound independent of the separation and may be useful in other contexts. To tackle the high-dimensional problem, we first solve the 2-dimensional problem by extending the 1-dimensional algorithm and analysis to complex numbers. Our algorithm for the high-dimensional case determines the coordinates of each spike by aligning a 1d projection of the mixture to a random vector and a set of 2d projections of the mixture. Our results have applications to learning topic models and Gaussian mixtures, implying improved sample complexity results or running time over prior work.",
        "bibtex": "@InProceedings{pmlr-v195-fan23b,\n  title = \t {Efficient Algorithms for Sparse Moment Problems without Separation},\n  author =       {Fan, Zhiyuan and Li, Jian},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3510--3565},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/fan23b/fan23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/fan23b.html},\n  abstract = \t {We consider the sparse moment problem of learning a $k$-spike mixture in high-dimensional space from its noisy moment information in any dimension. We measure the accuracy of the learned mixtures using transportation distance. Previous algorithms either assume certain separation assumptions, use more recovery moments, or run in (super) exponential time. Our algorithm for the 1-dimensional problem (also called the sparse Hausdorff moment problem) is a robust version of the classic Prony\u2019s method, and our contribution mainly lies in the analysis. We adopt a global and much tighter analysis than previous work (which analyzes the perturbation of the intermediate results of Prony\u2019s method). A useful technical ingredient is a connection between the linear system defined by the Vandermonde matrix and the Schur polynomial, which allows us to provide tight perturbation bound independent of the separation and may be useful in other contexts. To tackle the high-dimensional problem, we first solve the 2-dimensional problem by extending the 1-dimensional algorithm and analysis to complex numbers. Our algorithm for the high-dimensional case determines the coordinates of each spike by aligning a 1d projection of the mixture to a random vector and a set of 2d projections of the mixture. Our results have applications to learning topic models and Gaussian mixtures, implying improved sample complexity results or running time over prior work.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/fan23b/fan23b.pdf",
        "supp": "",
        "pdf_size": 623276,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16475651873661588451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Tsinghua University; Tsinghua University",
        "aff_domain": "MAILS.TSINGHUA.EDU.CN;MAIL.TSINGHUA.EDU.CN",
        "email": "MAILS.TSINGHUA.EDU.CN;MAIL.TSINGHUA.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "5773331d3b",
        "title": "Efficient median of means estimator",
        "site": "https://proceedings.mlr.press/v195/minsker23a.html",
        "author": "Stanislav Minsker",
        "abstract": "The goal of this note is to present a modification of the popular median of means estimator that achieves sub-Gaussian deviation bounds with nearly optimal constants under minimal assumptions on the underlying distribution. We build on a recent work on the topic and prove that desired guarantees can be attained under weaker requirements.",
        "bibtex": "@InProceedings{pmlr-v195-minsker23a,\n  title = \t {Efficient median of means estimator},\n  author =       {Minsker, Stanislav},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5925--5933},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/minsker23a/minsker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/minsker23a.html},\n  abstract = \t {The goal of this note is to present a modification of the popular median of means estimator that achieves sub-Gaussian deviation bounds with nearly optimal constants under minimal assumptions on the underlying distribution. We build on a recent work on the topic and prove that desired guarantees can be attained under weaker requirements.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/minsker23a/minsker23a.pdf",
        "supp": "",
        "pdf_size": 222446,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17688647558556543920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics, University of Southern California",
        "aff_domain": "usc.edu",
        "email": "usc.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "850b4b1bda",
        "title": "Empirical Bayes via ERM and Rademacher complexities: the Poisson model",
        "site": "https://proceedings.mlr.press/v195/jana23a.html",
        "author": "Soham Jana; Yury Polyanskiy; Anzo Z. Teh; Yihong Wu",
        "abstract": "We consider the problem of empirical Bayes estimation for (multivariate) Poisson means. Existing solutions that have been shown theoretically optimal for minimizing the regret (excess risk over the Bayesian oracle that knows the prior) have several shortcomings. For example, the classical Robbins estimator does not retain the monotonicity property of the Bayes estimator and performs poorly under moderate sample size. Estimators based on the minimum distance and non-parametric maximum likelihood (NPMLE) methods correct these issues, but are computationally expensive with complexity growing exponentially with dimension. Extending the approach of Barbehenn andZhao (2022), in this work we construct monotone estimators based on empirical risk minimization (ERM) that retain similar theoretical guarantees and can be computed much more efficiently. Adapting the idea of offset Rademacher complexity Liang et al. (2015) to the non-standard loss and function class in empirical Bayes, we show that the shape-constrained ERM estimator attains the minimax regret within constant factors in one dimension and within logarithmic factors in multiple dimensions.",
        "bibtex": "@InProceedings{pmlr-v195-jana23a,\n  title = \t {Empirical Bayes via ERM and Rademacher complexities: the Poisson model},\n  author =       {Jana, Soham and Polyanskiy, Yury and Teh, Anzo Z. and Wu, Yihong},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5199--5235},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/jana23a/jana23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/jana23a.html},\n  abstract = \t {We consider the problem of empirical Bayes estimation for (multivariate) Poisson means. Existing solutions that have been shown theoretically optimal for minimizing the regret (excess risk over the Bayesian oracle that knows the prior) have several shortcomings. For example, the classical Robbins estimator does not retain the monotonicity property of the Bayes estimator and performs poorly under moderate sample size. Estimators based on the minimum distance and non-parametric maximum likelihood (NPMLE) methods correct these issues, but are computationally expensive with complexity growing exponentially with dimension. Extending the approach of Barbehenn andZhao (2022), in this work we construct monotone estimators based on empirical risk minimization (ERM) that retain similar theoretical guarantees and can be computed much more efficiently. Adapting the idea of offset Rademacher complexity Liang et al. (2015) to the non-standard loss and function class in empirical Bayes, we show that the shape-constrained ERM estimator attains the minimax regret within constant factors in one dimension and within logarithmic factors in multiple dimensions. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/jana23a/jana23a.pdf",
        "supp": "",
        "pdf_size": 640959,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=746132421258879144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of ORFE, Princeton University, Princeton, NJ; Department of EECS, MIT, Cambridge, MA; Department of EECS, MIT, Cambridge, MA; Department of Statistics and Data Science, Yale University, New Haven, CT",
        "aff_domain": "princeton.edu;mit.edu;mit.edu;yale.edu",
        "email": "princeton.edu;mit.edu;mit.edu;yale.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Princeton University;Massachusetts Institute of Technology;Yale University",
        "aff_unique_dep": "Department of ORFE;Department of Electrical Engineering and Computer Science;Department of Statistics and Data Science",
        "aff_unique_url": "https://www.princeton.edu;https://web.mit.edu;https://www.yale.edu",
        "aff_unique_abbr": "Princeton;MIT;Yale",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Princeton;Cambridge;New Haven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3e97de0a67",
        "title": "Entropic characterization of optimal rates for learning Gaussian mixtures",
        "site": "https://proceedings.mlr.press/v195/jia23a.html",
        "author": "Zeyu Jia; Yury Polyanskiy; Yihong Wu",
        "abstract": "We consider the question of estimating multi-dimensional Gaussian mixtures (GM) with com- pactly supported or subgaussian mixing distributions. Minimax estimation rate for this class (under Hellinger, TV and KL divergences) is a long-standing open question, even for dimension one. In this paper we characterize this rate (in all dimensions) in terms of the metric entropy of the class. Such characterizations originate from seminal works of Le Cam (1973); Birge \u0301 (1983); Haussler and Opper (1997); Yang and Barron (1999). However, for GMs a key ingredient missing from earlier work (and widely sought-after) is a comparison result showing that the KL and the squared Hellinger distance are within a constant multiple of each other uniformly over the class. Our main technical contribution is in showing this fact, from which we derive entropy characterization for estimation rate under Hellinger and KL. Interestingly, the sequential (online learning) estimation rate is characterized by the global entropy, while the single-step (batch) rate corresponds to local entropy, paralleling a similar recent discovery for the case of Gaussian sequence model in a pair of works Neykov (2022); Mourtada (2023). Additionally, since Hellinger is a proper metric, our comparison shows that GMs under KL satisfy a version of triangle inequality (with a multiplicative constant), implying that proper and improper estimation rates coincide.",
        "bibtex": "@InProceedings{pmlr-v195-jia23a,\n  title = \t {Entropic characterization of optimal rates for learning Gaussian mixtures},\n  author =       {Jia, Zeyu and Polyanskiy, Yury and Wu, Yihong},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4296--4335},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/jia23a/jia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/jia23a.html},\n  abstract = \t {We consider the question of estimating multi-dimensional Gaussian mixtures (GM) with com- pactly supported or subgaussian mixing distributions. Minimax estimation rate for this class (under Hellinger, TV and KL divergences) is a long-standing open question, even for dimension one. In this paper we characterize this rate (in all dimensions) in terms of the metric entropy of the class. Such characterizations originate from seminal works of Le Cam (1973); Birge \u0301 (1983); Haussler and Opper (1997); Yang and Barron (1999). However, for GMs a key ingredient missing from earlier work (and widely sought-after) is a comparison result showing that the KL and the squared Hellinger distance are within a constant multiple of each other uniformly over the class. Our main technical contribution is in showing this fact, from which we derive entropy characterization for estimation rate under Hellinger and KL. Interestingly, the sequential (online learning) estimation rate is characterized by the global entropy, while the single-step (batch) rate corresponds to local entropy, paralleling a similar recent discovery for the case of Gaussian sequence model in a pair of works Neykov (2022); Mourtada (2023). Additionally, since Hellinger is a proper metric, our comparison shows that GMs under KL satisfy a version of triangle inequality (with a multiplicative constant), implying that proper and improper estimation rates coincide.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/jia23a/jia23a.pdf",
        "supp": "",
        "pdf_size": 477192,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11203238677157817682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Yale University",
        "aff_domain": "MIT.EDU;MIT.EDU;YALE.EDU",
        "email": "MIT.EDU;MIT.EDU;YALE.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Yale University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.yale.edu",
        "aff_unique_abbr": "MIT;Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "40ce76fd34",
        "title": "Exploring Local Norms in Exp-concave Statistical Learning",
        "site": "https://proceedings.mlr.press/v195/puchkin23a.html",
        "author": "Nikita Puchkin; Nikita Zhivotovskiy",
        "abstract": "We consider the standard problem of stochastic convex optimization with exp-concave losses using Empirical Risk Minimization in a convex class. Answering a question raised in several prior works, we provide a $O ( d/n + 1/n \\log( 1 / \\delta ) )$ excess risk bound valid for a wide class of bounded exp-concave losses, where $d$ is the dimension of the convex reference set, $n$ is the sample size, and $\\delta$ is the confidence level. Our result is based on a unified geometric assumption on the gradient of losses and the notion of local norms.",
        "bibtex": "@InProceedings{pmlr-v195-puchkin23a,\n  title = \t {Exploring Local Norms in Exp-concave Statistical Learning},\n  author =       {Puchkin, Nikita and Zhivotovskiy, Nikita},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1993--2013},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/puchkin23a/puchkin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/puchkin23a.html},\n  abstract = \t {We consider the standard problem of stochastic convex optimization with exp-concave losses using Empirical Risk Minimization in a convex class. Answering a question raised in several prior works, we provide a $O ( d/n + 1/n \\log( 1 / \\delta ) )$ excess risk bound valid for a wide class of bounded exp-concave losses, where $d$ is the dimension of the convex reference set, $n$ is the sample size, and $\\delta$ is the confidence level. Our result is based on a unified geometric assumption on the gradient of losses and the notion of local norms.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/puchkin23a/puchkin23a.pdf",
        "supp": "",
        "pdf_size": 307871,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7578442925433615268&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "HSE University and IITP RAS, Russian Federation; UC Berkeley, Department of Statistics, USA",
        "aff_domain": "HSE.RU;BERKELEY.EDU",
        "email": "HSE.RU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "HSE University;University of California, Berkeley",
        "aff_unique_dep": ";Department of Statistics",
        "aff_unique_url": "https://hse.ru;https://www.berkeley.edu",
        "aff_unique_abbr": "HSE;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Russian Federation;United States"
    },
    {
        "id": "fea7e57d42",
        "title": "Exponential Hardness of Reinforcement Learning with Linear Function Approximation",
        "site": "https://proceedings.mlr.press/v195/liu23b.html",
        "author": "Sihan Liu; Gaurav Mahajan; Daniel Kane; Shachar Lovett; Gell\u00e9rt Weisz; Csaba Szepesv\u00e1ri",
        "abstract": "A fundamental question in reinforcement learning theory is: suppose the optimal value functions are linear in given features, can we learn them efficiently? This problem\u2019s counterpart in supervised learning, linear regression, can be solved both statistically and computationally efficiently. Therefore, it was quite surprising when a recent work \\cite{kane2022computational} showed a computational-statistical gap for linear reinforcement learning: even though there are polynomial sample-complexity algorithms, unless NP = RP, there are no polynomial time algorithms for this setting.In this work, we build on their result to show a computational lower bound, which is exponential in feature dimension and horizon, for linear reinforcement learning under the Randomized Exponential Time Hypothesis. To prove this we build a round-based game where in each round the learner is searching for an unknown vector in a unit hypercube. The rewards in this game are chosen such that if the learner achieves large reward, then the learner\u2019s actions can be used to simulate solving a variant of 3-SAT, where (a) each variable shows up in a bounded number of clauses (b) if an instance has no solutions then it also has no solutions that satisfy more than (1-$\\epsilon$)-fraction of clauses. We use standard reductions to show this 3-SAT variant is approximately as hard as 3-SAT. Finally, we also show a lower bound optimized for horizon dependence that almost matches the best known upper bound of $\\exp(\\sqrt{H})$.",
        "bibtex": "@InProceedings{pmlr-v195-liu23b,\n  title = \t {Exponential Hardness of Reinforcement Learning with Linear Function Approximation},\n  author =       {Liu, Sihan and Mahajan, Gaurav and Kane, Daniel and Lovett, Shachar and Weisz, Gell{\\'e}rt and Szepesv{\\'a}ri, Csaba},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1588--1617},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/liu23b/liu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/liu23b.html},\n  abstract = \t {A fundamental question in reinforcement learning theory is: suppose the optimal value functions are linear in given features, can we learn them efficiently? This problem\u2019s counterpart in supervised learning, linear regression, can be solved both statistically and computationally efficiently. Therefore, it was quite surprising when a recent work \\cite{kane2022computational} showed a computational-statistical gap for linear reinforcement learning: even though there are polynomial sample-complexity algorithms, unless NP = RP, there are no polynomial time algorithms for this setting.In this work, we build on their result to show a computational lower bound, which is exponential in feature dimension and horizon, for linear reinforcement learning under the Randomized Exponential Time Hypothesis. To prove this we build a round-based game where in each round the learner is searching for an unknown vector in a unit hypercube. The rewards in this game are chosen such that if the learner achieves large reward, then the learner\u2019s actions can be used to simulate solving a variant of 3-SAT, where (a) each variable shows up in a bounded number of clauses (b) if an instance has no solutions then it also has no solutions that satisfy more than (1-$\\epsilon$)-fraction of clauses. We use standard reductions to show this 3-SAT variant is approximately as hard as 3-SAT. Finally, we also show a lower bound optimized for horizon dependence that almost matches the best known upper bound of $\\exp(\\sqrt{H})$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/liu23b/liu23b.pdf",
        "supp": "",
        "pdf_size": 354959,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9713656471475595792&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of California, San Diego; University of California, San Diego; University of California, San Diego; Yale University; DeepMind, London, UK+University of Alberta, Edmonton, Canada; DeepMind, London, UK+University College London, London, UK",
        "aff_domain": "ENG.UCSD.EDU;UCSD.EDU;CS.UCSD.EDU;YALE.EDU;UALBERTA.CA;DEEPMIND.COM",
        "email": "ENG.UCSD.EDU;UCSD.EDU;CS.UCSD.EDU;YALE.EDU;UALBERTA.CA;DEEPMIND.COM",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2+3;2+4",
        "aff_unique_norm": "University of California, San Diego;Yale University;DeepMind;University of Alberta;University College London",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.ucsd.edu;https://www.yale.edu;https://deepmind.com;https://www.ualberta.ca;https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCSD;Yale;DeepMind;UAlberta;UCL",
        "aff_campus_unique_index": "0;0;0;2+3;2+2",
        "aff_campus_unique": "San Diego;;London;Edmonton",
        "aff_country_unique_index": "0;0;0;0;1+2;1+1",
        "aff_country_unique": "United States;United Kingdom;Canada"
    },
    {
        "id": "0ef07fe939",
        "title": "Fast Algorithms for a New Relaxation of Optimal Transport",
        "site": "https://proceedings.mlr.press/v195/charikar23a.html",
        "author": "Moses Charikar; Beidi Chen; Christopher R\u00e9; Erik Waingarten",
        "abstract": "We introduce a new class of objectives for optimal transport computations of datasets in high-dimensional Euclidean spaces. The new objectives are parametrized by $\\rho \\geq 1$, and provide a metric space $\\mathcal{R}_{\\rho}(\\cdot, \\cdot)$ for discrete probability distributions in $\\mathbb{R}^d$. As $\\rho$ approaches $1$, the metric approaches the Earth Mover\u2019s distance, but for $\\rho$ larger than (but close to) $1$, admits significantly faster algorithms. Namely, for distributions $\\mu$ and $\\nu$ supported on $n$ and $m$ vectors in $\\mathbb{R}^d$ of norm at most $r$ and any $\\epsilon > 0$, we give an algorithm which outputs an additive $\\epsilon r$ approximation to $\\mathcal{R}_{\\rho}(\\mu, \\nu)$ in time $(n+m) \\cdot \\mathrm{poly}((nm)^{(\\rho-1)/\\rho} \\cdot 2^{\\rho / (\\rho-1)} / \\epsilon)$.",
        "bibtex": "@InProceedings{pmlr-v195-charikar23a,\n  title = \t {Fast Algorithms for a New Relaxation of Optimal Transport},\n  author =       {Charikar, Moses and Chen, Beidi and R{\\'e}, Christopher and Waingarten, Erik},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4831--4862},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/charikar23a/charikar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/charikar23a.html},\n  abstract = \t {We introduce a new class of objectives for optimal transport computations of datasets in high-dimensional Euclidean spaces. The new objectives are parametrized by $\\rho \\geq 1$, and provide a metric space $\\mathcal{R}_{\\rho}(\\cdot, \\cdot)$ for discrete probability distributions in $\\mathbb{R}^d$. As $\\rho$ approaches $1$, the metric approaches the Earth Mover\u2019s distance, but for $\\rho$ larger than (but close to) $1$, admits significantly faster algorithms. Namely, for distributions $\\mu$ and $\\nu$ supported on $n$ and $m$ vectors in $\\mathbb{R}^d$ of norm at most $r$ and any $\\epsilon > 0$, we give an algorithm which outputs an additive $\\epsilon r$ approximation to $\\mathcal{R}_{\\rho}(\\mu, \\nu)$ in time $(n+m) \\cdot \\mathrm{poly}((nm)^{(\\rho-1)/\\rho} \\cdot 2^{\\rho / (\\rho-1)} / \\epsilon)$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/charikar23a/charikar23a.pdf",
        "supp": "",
        "pdf_size": 477683,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7917106595979316079&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; Carnegie Mellow University; Stanford University; University of Pennsylvania",
        "aff_domain": "CS.STANFORD.EDU;ANDREW.CMU.EDU;CS.STANFORD.EDU;CIS.UPENN.EDU",
        "email": "CS.STANFORD.EDU;ANDREW.CMU.EDU;CS.STANFORD.EDU;CIS.UPENN.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Stanford University;Carnegie Mellon University;University of Pennsylvania",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.cmu.edu;https://www.upenn.edu",
        "aff_unique_abbr": "Stanford;CMU;UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9b0d70530e",
        "title": "Fast, Sample-Efficient, Affine-Invariant Private Mean and Covariance Estimation for Subgaussian Distributions",
        "site": "https://proceedings.mlr.press/v195/brown23a.html",
        "author": "Gavin Brown; Samuel Hopkins; Adam Smith",
        "abstract": "We present a fast, differentially private algorithm for high-dimensional covariance-aware mean estimation with nearly optimal sample complexity. Only exponential-time estimators were previously known to achieve this guarantee. Given $n$ samples from a (sub-)Gaussian distribution with unknown mean $\\mu$ and covariance $\\Sigma$, our $(\\epsilon,\\delta)$-differentially private estimator produces $\\tilde{\\mu}$ such that $\\|\\mu - \\tilde{\\mu}\\|_{\\Sigma} \\leq \\alpha$ as long as $n \\gtrsim \\tfrac d {\\alpha^2} + \\tfrac{d \\sqrt{\\log 1/\\delta}}{\\alpha \\epsilon}+\\frac{d\\log 1/\\delta}{\\epsilon}$. The Mahalanobis error metric $\\|\\mu - \\hat{\\mu}\\|_{\\Sigma}$ measures the distance between $\\hat \\mu$ and $\\mu$ relative to $\\Sigma$; it characterizes the error of the sample mean. Our algorithm runs in time $\\tilde{O}(nd^{\\omega - 1} + nd/\\eps)$, where $\\omega < 2.38$ is the matrix multiplication exponent.We adapt an exponential-time approach of Brown, Gaboardi, Smith, Ullman, and Zakynthinou (2021), giving efficient variants of stable mean and covariance estimation subroutines that also improve the sample complexity to the nearly optimal bound above.Our stable covariance estimator can be turned to private covariance estimation for unrestricted subgaussian distributions. With $n\\gtrsim d^{3/2}$ samples, our estimate is accurate in spectral norm. This is the first such algorithm using $n= o(d^2)$ samples, answering an open question posed by Alabi et al. (2022). With $n\\gtrsim d^2$ samples, our estimate is accurate in Frobenius norm. This leads to a fast, nearly optimal algorithm for private learning of unrestricted Gaussian distributions in TV distance.Duchi, Haque, and Kuditipudi (2023) obtained similar results independently and concurrently.",
        "bibtex": "@InProceedings{pmlr-v195-brown23a,\n  title = \t {Fast, Sample-Efficient, Affine-Invariant Private Mean and Covariance Estimation for Subgaussian Distributions},\n  author =       {Brown, Gavin and Hopkins, Samuel and Smith, Adam},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5578--5579},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/brown23a/brown23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/brown23a.html},\n  abstract = \t {We present a fast, differentially private algorithm for high-dimensional covariance-aware mean estimation with nearly optimal sample complexity. Only exponential-time estimators were previously known to achieve this guarantee. Given $n$ samples from a (sub-)Gaussian distribution with unknown mean $\\mu$ and covariance $\\Sigma$, our $(\\epsilon,\\delta)$-differentially private estimator produces $\\tilde{\\mu}$ such that $\\|\\mu - \\tilde{\\mu}\\|_{\\Sigma} \\leq \\alpha$ as long as $n \\gtrsim \\tfrac d {\\alpha^2} + \\tfrac{d \\sqrt{\\log 1/\\delta}}{\\alpha \\epsilon}+\\frac{d\\log 1/\\delta}{\\epsilon}$. The Mahalanobis error metric $\\|\\mu - \\hat{\\mu}\\|_{\\Sigma}$ measures the distance between $\\hat \\mu$ and $\\mu$ relative to $\\Sigma$; it characterizes the error of the sample mean. Our algorithm runs in time $\\tilde{O}(nd^{\\omega - 1} + nd/\\eps)$, where $\\omega < 2.38$ is the matrix multiplication exponent.We adapt an exponential-time approach of Brown, Gaboardi, Smith, Ullman, and Zakynthinou (2021), giving efficient variants of stable mean and covariance estimation subroutines that also improve the sample complexity to the nearly optimal bound above.Our stable covariance estimator can be turned to private covariance estimation for unrestricted subgaussian distributions. With $n\\gtrsim d^{3/2}$ samples, our estimate is accurate in spectral norm. This is the first such algorithm using $n= o(d^2)$ samples, answering an open question posed by Alabi et al. (2022). With $n\\gtrsim d^2$ samples, our estimate is accurate in Frobenius norm. This leads to a fast, nearly optimal algorithm for private learning of unrestricted Gaussian distributions in TV distance.Duchi, Haque, and Kuditipudi (2023) obtained similar results independently and concurrently.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/brown23a/brown23a.pdf",
        "supp": "",
        "pdf_size": 128302,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1242324065113565269&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Boston University; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology; Department of Computer Science, Boston University",
        "aff_domain": "BU.EDU;MIT.EDU;BU.EDU",
        "email": "BU.EDU;MIT.EDU;BU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Boston University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.bu.edu;https://web.mit.edu",
        "aff_unique_abbr": "BU;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d81d3ddf66",
        "title": "Find a witness or shatter: the landscape of computable PAC learning.",
        "site": "https://proceedings.mlr.press/v195/delle-rose23a.html",
        "author": "Valentino Delle Rose; Alexander Kozachinskiy; Crist\u00f3bal Rojas; Tomasz Steifer",
        "abstract": "This paper contributes to the study of CPAC learnability \u2014a computable version of PAC learning\u2013 by solving three open questions from recent papers. Firstly, we prove that every improperly CPAC learnable class is contained in a class which is properly CPAC learnable with polynomial sample complexity. This confirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that there exists a decidable class of hypotheses which is properly CPAC learnable, but only with uncomputably fast-growing sample complexity. This solves a question from Sterkenburg (COLT 2022). Finally, we construct a decidable class of finite Littlestone dimension which is not improperly CPAC learnable, strengthening a recent result of Sterkenburg (2022) and answering a question posed by Hasrati and Ben-David (ALT 2023). Together with previous work, our results provide a complete landscape for the learnability problem in the CPAC setting.",
        "bibtex": "@InProceedings{pmlr-v195-delle-rose23a,\n  title = \t {Find a witness or shatter: the landscape of computable PAC learning.},\n  author =       {Delle Rose, Valentino and Kozachinskiy, Alexander and Rojas, Crist{\\'o}bal and Steifer, Tomasz},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {511--524},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/delle-rose23a/delle-rose23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/delle-rose23a.html},\n  abstract = \t {   This paper contributes to the study of CPAC learnability \u2014a computable version of PAC learning\u2013 by solving three open questions from recent papers. Firstly, we prove that every improperly CPAC learnable class is contained in a class which is properly CPAC learnable with polynomial sample complexity. This confirms a conjecture by Agarwal et al (COLT 2021). Secondly, we show that there exists a decidable class of hypotheses which is properly CPAC learnable, but only with uncomputably fast-growing sample complexity. This solves a question from Sterkenburg (COLT 2022). Finally, we construct a decidable class of finite Littlestone dimension which is not improperly CPAC learnable, strengthening a recent result of Sterkenburg (2022) and answering a question posed by Hasrati and Ben-David (ALT 2023). Together with previous work, our results provide a complete landscape for the learnability problem in the CPAC setting. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/delle-rose23a/delle-rose23a.pdf",
        "supp": "",
        "pdf_size": 274844,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2027856569384695470&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Institute for Mathematical and Computational Engineering, PUC, Chile + CENIA, Chile; CENIA, Chile + IMFD, Chile; Institute for Mathematical and Computational Engineering, PUC, Chile + CENIA, Chile; Institute of Fundamental Technological Research, Polish Academy of Sciences + Institute for Mathematical and Computational Engineering, PUC, Chile + IMFD, Chile",
        "aff_domain": "cenia.cl;cenia.cl;mat.uc.cl;ippt.pan.pl",
        "email": "cenia.cl;cenia.cl;mat.uc.cl;ippt.pan.pl",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1+2;0+1;3+0+2",
        "aff_unique_norm": "Pontificia Universidad Cat\u00f3lica de Chile;CENIA;IMFD;Institute of Fundamental Technological Research",
        "aff_unique_dep": "Institute for Mathematical and Computational Engineering;;;Polish Academy of Sciences",
        "aff_unique_url": "https://www.puc.cl;;;https://www.ippt.pan.pl",
        "aff_unique_abbr": "PUC;;;IPPT PAS",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0;1+0+0",
        "aff_country_unique": "Chile;Poland"
    },
    {
        "id": "e4898abaa0",
        "title": "Fine-Grained Distribution-Dependent Learning Curves",
        "site": "https://proceedings.mlr.press/v195/bousquet23a.html",
        "author": "Olivier Bousquet; Steve Hanneke; Shay Moran; Jonathan Shafer; Ilya Tolstikhin",
        "abstract": "Learning curves plot the expected error of a learning algorithm as a function of the number of labeled samples it receives from a target distribution. They are widely used as a measure of an algorithm\u2019s performance, but classic PAC learning theory cannot explain their behavior. As observed by Antos and Lugosi (1996, 1998), the classic \u2018No Free Lunch\u2019 lower bounds only trace the upper envelope above all learning curves of specific target distributions. For a concept class with VC dimension $d$ the classic bound decays like $d/n$, yet it is possible that the learning curve for \\emph{every} specific distribution decays exponentially. In this case, for each $n$ there exists a different \u2018hard\u2019 distribution requiring $d/n$ samples. Antos and Lugosi asked which concept classes admit a \u2018strong minimax lower bound\u2019 \u2013 a lower bound of $d\u2019/n$ that holds for a fixed distribution for infinitely many $n$.We solve this problem in a principled manner, by introducing a combinatorial dimension called VCL that characterizes the best $d\u2019$ for which $d\u2019/n$ is a strong minimax lower bound. Conceptually, the VCL dimension determines the asymptotic rate of decay of the minimax learning curve, which we call the \u2018distribution-free trail\u2019 of the class. Our characterization strengthens the lower bounds of Bousquet, Hanneke, Moran, van Handel, and Yehudayoff (2021), and it refines their analysis of learning curves, by showing that for classes with finite VCL the learning rate can be decomposed into a linear component that depends only on the hypothesis class and a faster (e.g., exponential) component that depends also on the target distribution. As a corollary, we recover the lower bound of Antos and Lugosi (1996, 1998) for half-spaces in $\\mathbb{R}^d$.Finally, to provide another viewpoint on our work and how it compares to traditional PAC learning bounds, we also present an alternative formulation of our results in a language that is closer to the PAC setting.",
        "bibtex": "@InProceedings{pmlr-v195-bousquet23a,\n  title = \t {Fine-Grained Distribution-Dependent Learning Curves},\n  author =       {Bousquet, Olivier and Hanneke, Steve and Moran, Shay and Shafer, Jonathan and Tolstikhin, Ilya},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5890--5924},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bousquet23a/bousquet23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bousquet23a.html},\n  abstract = \t {Learning curves plot the expected error of a learning algorithm as a function of the number of labeled samples it receives from a target distribution. They are widely used as a measure of an algorithm\u2019s performance, but classic PAC learning theory cannot explain their behavior. As observed by Antos and Lugosi (1996, 1998), the classic \u2018No Free Lunch\u2019 lower bounds only trace the upper envelope above all learning curves of specific target distributions. For a concept class with VC dimension $d$ the classic bound decays like $d/n$, yet it is possible that the learning curve for \\emph{every} specific distribution decays exponentially. In this case, for each $n$ there exists a different \u2018hard\u2019 distribution requiring $d/n$ samples. Antos and Lugosi asked which concept classes admit a \u2018strong minimax lower bound\u2019 \u2013 a lower bound of $d\u2019/n$ that holds for a fixed distribution for infinitely many $n$.We solve this problem in a principled manner, by introducing a combinatorial dimension called VCL that characterizes the best $d\u2019$ for which $d\u2019/n$ is a strong minimax lower bound. Conceptually, the VCL dimension determines the asymptotic rate of decay of the minimax learning curve, which we call the \u2018distribution-free trail\u2019 of the class. Our characterization strengthens the lower bounds of Bousquet, Hanneke, Moran, van Handel, and Yehudayoff (2021), and it refines their analysis of learning curves, by showing that for classes with finite VCL the learning rate can be decomposed into a linear component that depends only on the hypothesis class and a faster (e.g., exponential) component that depends also on the target distribution. As a corollary, we recover the lower bound of Antos and Lugosi (1996, 1998) for half-spaces in $\\mathbb{R}^d$.Finally, to provide another viewpoint on our work and how it compares to traditional PAC learning bounds, we also present an alternative formulation of our results in a language that is closer to the PAC setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/bousquet23a/bousquet23a.pdf",
        "supp": "",
        "pdf_size": 581890,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12738104970753181927&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Google, Brain Team; Purdue University; Technion \u2013 Israel Institute of Technology + Google Research; University of California, Berkeley; Google, Brain Team",
        "aff_domain": "google.com;gmail.com;technion.ac.il;berkeley.edu;google.com",
        "email": "google.com;gmail.com;technion.ac.il;berkeley.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+0;3;0",
        "aff_unique_norm": "Google;Purdue University;Technion \u2013 Israel Institute of Technology;University of California, Berkeley",
        "aff_unique_dep": "Brain Team;;;",
        "aff_unique_url": "https://www.google.com;https://www.purdue.edu;https://www.technion.ac.il/en/;https://www.berkeley.edu",
        "aff_unique_abbr": "Google;Purdue;Technion;UC Berkeley",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Mountain View;;Berkeley",
        "aff_country_unique_index": "0;0;1+0;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "f196812f41",
        "title": "Finite-Sample Symmetric Mean Estimation with Fisher Information Rate",
        "site": "https://proceedings.mlr.press/v195/gupta23a.html",
        "author": "Shivam Gupta; Jasper C. H. Lee; Eric Price",
        "abstract": "The mean of an unknown variance-$\\sigma^2$ distribution $f$ can be estimated from $n$ samples with variance $\\frac{\\sigma^2}{n}$ and nearly corresponding subgaussian rate.  When $f$ is known up to translation, this can be improved asymptotically to $\\frac{1}{nI}$, where $I$ is the Fisher information of the distribution.  Such an improvement is not possible for general unknown $f$, but [Stone 1975] showed that this asymptotic convergence \\emph{is} possible if $f$ is _symmetric_ about its mean.  Stone\u2019s bound is asymptotic, however: the $n$ required for convergence depends in an unspecified way on the distribution $f$ and failure probability $\\delta$.   In this paper we give finite-sample guarantees for symmetric mean estimation in terms of Fisher information.  For every $f, n, \\delta$ with $n > \\log \\frac{1}{\\delta}$, we get convergence close to a subgaussian with variance $\\frac{1}{n I_r}$, where $I_r$ is the $r$-smoothed Fisher information with smoothing radius $r$ that decays polynomially in $n$.  Such a bound essentially matches the finite-sample guarantees in the known-$f$ setting.",
        "bibtex": "@InProceedings{pmlr-v195-gupta23a,\n  title = \t {Finite-Sample Symmetric Mean Estimation with Fisher Information Rate},\n  author =       {Gupta, Shivam and Lee, Jasper C. H. and Price, Eric},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4777--4830},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gupta23a/gupta23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gupta23a.html},\n  abstract = \t {The mean of an unknown variance-$\\sigma^2$ distribution $f$ can be estimated from $n$ samples with variance $\\frac{\\sigma^2}{n}$ and nearly corresponding subgaussian rate.  When $f$ is known up to translation, this can be improved asymptotically to $\\frac{1}{nI}$, where $I$ is the Fisher information of the distribution.  Such an improvement is not possible for general unknown $f$, but [Stone 1975] showed that this asymptotic convergence \\emph{is} possible if $f$ is _symmetric_ about its mean.  Stone\u2019s bound is asymptotic, however: the $n$ required for convergence depends in an unspecified way on the distribution $f$ and failure probability $\\delta$.   In this paper we give finite-sample guarantees for symmetric mean estimation in terms of Fisher information.  For every $f, n, \\delta$ with $n > \\log \\frac{1}{\\delta}$, we get convergence close to a subgaussian with variance $\\frac{1}{n I_r}$, where $I_r$ is the $r$-smoothed Fisher information with smoothing radius $r$ that decays polynomially in $n$.  Such a bound essentially matches the finite-sample guarantees in the known-$f$ setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/gupta23a/gupta23a.pdf",
        "supp": "",
        "pdf_size": 624267,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5831292655031745367&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "The University of Texas at Austin; University of Wisconsin-Madison; The University of Texas at Austin",
        "aff_domain": "utexas.edu;wisc.edu;cs.utexas.edu",
        "email": "utexas.edu;wisc.edu;cs.utexas.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Austin;University of Wisconsin-Madison",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.wisc.edu",
        "aff_unique_abbr": "UT Austin;UW-Madison",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Austin;Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "273187371f",
        "title": "From Pseudorandomness to Multi-Group Fairness and Back",
        "site": "https://proceedings.mlr.press/v195/dwork23a.html",
        "author": "Cynthia Dwork; Daniel Lee; Huijia Lin; Pranay Tankala",
        "abstract": "We identify and explore connections between the recent literature on multi-group fairness for prediction algorithms and the pseudorandomness notions of leakage-resilience and graph regularity. We frame our investigation using new, statistical distance-based variants of multicalibration that are closely related to the concept of outcome indistinguishability. Adopting this perspective leads us naturally not only to our graph theoretic results, but also to new, more efficient algorithms for multicalibration in certain parameter regimes and a novel proof of a hardcore lemma for real-valued functions.",
        "bibtex": "@InProceedings{pmlr-v195-dwork23a,\n  title = \t {From Pseudorandomness to Multi-Group Fairness and Back},\n  author =       {Dwork, Cynthia and Lee, Daniel and Lin, Huijia and Tankala, Pranay},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3566--3614},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/dwork23a/dwork23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/dwork23a.html},\n  abstract = \t {We identify and explore connections between the recent literature on multi-group fairness for prediction algorithms and the pseudorandomness notions of leakage-resilience and graph regularity. We frame our investigation using new, statistical distance-based variants of multicalibration that are closely related to the concept of outcome indistinguishability. Adopting this perspective leads us naturally not only to our graph theoretic results, but also to new, more efficient algorithms for multicalibration in certain parameter regimes and a novel proof of a hardcore lemma for real-valued functions.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/dwork23a/dwork23a.pdf",
        "supp": "",
        "pdf_size": 545657,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15908020713831854612&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Harvard University; Massachusetts Institute of Technology; University of Washington; Harvard University",
        "aff_domain": "SEAS.HARVARD.EDU;MIT.EDU;CS.WASHINGTON.EDU;G.HARVARD.EDU",
        "email": "SEAS.HARVARD.EDU;MIT.EDU;CS.WASHINGTON.EDU;G.HARVARD.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Harvard University;Massachusetts Institute of Technology;University of Washington",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.harvard.edu;https://web.mit.edu;https://www.washington.edu",
        "aff_unique_abbr": "Harvard;MIT;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "414fc5bd6d",
        "title": "From high-dimensional & mean-field dynamics to dimensionless ODEs: A unifying approach to SGD in two-layers networks",
        "site": "https://proceedings.mlr.press/v195/arnaboldi23a.html",
        "author": "Luca Arnaboldi; Ludovic Stephan; Florent Krzakala; Bruno Loureiro",
        "abstract": "This manuscript investigates the one-pass stochastic gradient descent (SGD) dynamics of a two-layer neural network trained on Gaussian data and labels generated by a similar, though not necessarily identical, target function. We rigorously analyse the limiting dynamics via a deterministic and low-dimensional description in terms of the sufficient statistics for the population risk. Our unifying analysis bridges different regimes of interest, such as the classical gradient-flow regime of vanishing learning rate, the high-dimensional regime of large input dimension, and the overparameterised \u201cmean-field\u201d regime of large network width, covering as well the intermediate regimes where the limiting dynamics is determined by the interplay between these behaviours. In particular, in the high-dimensional limit, the infinite-width dynamics is found to remain close to a low-dimensional subspace spanned by the target principal directions. Our results therefore provide a unifying picture of the limiting SGD dynamics with synthetic data.",
        "bibtex": "@InProceedings{pmlr-v195-arnaboldi23a,\n  title = \t {From high-dimensional & mean-field dynamics to dimensionless ODEs: A unifying approach to SGD in two-layers networks},\n  author =       {Arnaboldi, Luca and Stephan, Ludovic and Krzakala, Florent and Loureiro, Bruno},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1199--1227},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/arnaboldi23a/arnaboldi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/arnaboldi23a.html},\n  abstract = \t {This manuscript investigates the one-pass stochastic gradient descent (SGD) dynamics of a two-layer neural network trained on Gaussian data and labels generated by a similar, though not necessarily identical, target function. We rigorously analyse the limiting dynamics via a deterministic and low-dimensional description in terms of the sufficient statistics for the population risk. Our unifying analysis bridges different regimes of interest, such as the classical gradient-flow regime of vanishing learning rate, the high-dimensional regime of large input dimension, and the overparameterised \u201cmean-field\u201d regime of large network width, covering as well the intermediate regimes where the limiting dynamics is determined by the interplay between these behaviours. In particular, in the high-dimensional limit, the infinite-width dynamics is found to remain close to a low-dimensional subspace spanned by the target principal directions. Our results therefore provide a unifying picture of the limiting SGD dynamics with synthetic data. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/arnaboldi23a/arnaboldi23a.pdf",
        "supp": "",
        "pdf_size": 1041622,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4586214403420133276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "\u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL), IdePHICS Lab, CH-1015 Lausanne, Switzerland; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL), IdePHICS Lab, CH-1015 Lausanne, Switzerland; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL), IdePHICS Lab, CH-1015 Lausanne, Switzerland; D\u00b4epartement d\u2019Informatique, \u00b4Ecole Normale Sup\u00b4erieure, PSL & CNRS, 45 rue d\u2019Ulm, F-75230 Paris France",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch;di.ens.fr",
        "email": "epfl.ch;epfl.ch;epfl.ch;di.ens.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "EPFL;Ecole Normale Sup\u00e9rieure",
        "aff_unique_dep": "IdePHICS Lab;D\u00e9partement d\u2019Informatique",
        "aff_unique_url": "https://www.epfl.ch;https://www.ens.fr",
        "aff_unique_abbr": "EPFL;ENS",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Lausanne;Paris",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Switzerland;France"
    },
    {
        "id": "1ceb01b321",
        "title": "Generalization Error Bounds for Noisy, Iterative Algorithms via Maximal Leakage",
        "site": "https://proceedings.mlr.press/v195/issa23a.html",
        "author": "Ibrahim Issa; Amedeo Roberto Esposito; Michael Gastpar",
        "abstract": "We adopt an information-theoretic framework to analyze the generalization behavior of the class of iterative, noisy learning algorithms. This class is particularly suitable for study under information-theoretic metrics as the algorithms are inherently randomized, and it includes commonly used algorithms such as Stochastic Gradient Langevin Dynamics (SGLD). Herein, we use the maximal leakage (equivalently, the Sibson mutual information of order infinity) metric, as it is simple to analyze, and it implies both bounds on the probability of having a large generalization error and on its expected value. We show that, if the update function (e.g., gradient) is bounded in $L_2$-norm and the additive noise is isotropic Gaussian noise, then one can obtain an upper-bound on maximal leakage in semi-closed form. Furthermore, we demonstrate how the assumptions on the update function affect the optimal (in the sense of minimizing the induced maximal leakage) choice of the noise. Finally, we compute explicit tight upper bounds on the induced maximal leakage for other scenarios of interest.",
        "bibtex": "@InProceedings{pmlr-v195-issa23a,\n  title = \t {Generalization Error Bounds for Noisy, Iterative Algorithms via Maximal Leakage},\n  author =       {Issa, Ibrahim and Esposito, Amedeo Roberto and Gastpar, Michael},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4952--4976},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/issa23a/issa23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/issa23a.html},\n  abstract = \t {We adopt an information-theoretic framework to analyze the generalization behavior of the class of iterative, noisy learning algorithms. This class is particularly suitable for study under information-theoretic metrics as the algorithms are inherently randomized, and it includes commonly used algorithms such as Stochastic Gradient Langevin Dynamics (SGLD). Herein, we use the maximal leakage (equivalently, the Sibson mutual information of order infinity) metric, as it is simple to analyze, and it implies both bounds on the probability of having a large generalization error and on its expected value. We show that, if the update function (e.g., gradient) is bounded in $L_2$-norm and the additive noise is isotropic Gaussian noise, then one can obtain an upper-bound on maximal leakage in semi-closed form. Furthermore, we demonstrate how the assumptions on the update function affect the optimal (in the sense of minimizing the induced maximal leakage) choice of the noise. Finally, we compute explicit tight upper bounds on the induced maximal leakage for other scenarios of interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/issa23a/issa23a.pdf",
        "supp": "",
        "pdf_size": 394086,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8029286152597999054&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "American University of Beirut, Lebanon + \u00b4Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne, Switzerland; Institute of Science and Technology Austria; \u00b4Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne, Switzerland",
        "aff_domain": "AUB.EDU.LB;IST.AC.AT;EPFL.CH",
        "email": "AUB.EDU.LB;IST.AC.AT;EPFL.CH",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;1",
        "aff_unique_norm": "American University of Beirut;EPFL;Institute of Science and Technology Austria",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.aub.edu.lb;https://www.epfl.ch;https://www.ist.ac.at",
        "aff_unique_abbr": "AUB;EPFL;IST Austria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;2;1",
        "aff_country_unique": "Lebanon;Switzerland;Austria"
    },
    {
        "id": "6a49b2399d",
        "title": "Generalization Guarantees via Algorithm-dependent Rademacher Complexity",
        "site": "https://proceedings.mlr.press/v195/sachs23a.html",
        "author": "Sarah Sachs; Tim van Erven; Liam Hodgkinson; Rajiv Khanna; Umut \u015eim\u015fekli",
        "abstract": "Algorithm- and data-dependent generalization bounds are required to explain the generalization behavior of modern machine learning algorithms. In this context, there exists information theoretic generalization bounds that involve (various forms of) mutual information, as well as bounds based on hypothesis set stability. We propose a conceptually related, but technically distinct complexity measure to control generalization error, which is the empirical Rademacher complexity of an algorithm- and data-dependent hypothesis class. Combining standard properties of Rademacher complexity with the convenient structure of this class, we are able to (i) obtain novel bounds based on the finite fractal dimension, which (a) extend previous fractal dimension-type bounds from continuous to finite hypothesis classes, and (b) avoid a mutual information term that was required in prior work; (ii) we greatly simplify the proof of a recent dimension-independent generalization bound for stochastic gradient descent; and (iii) we easily recover results for VC classes and compression schemes, similar to approaches based on conditional mutual information.",
        "bibtex": "@InProceedings{pmlr-v195-sachs23a,\n  title = \t {Generalization Guarantees via Algorithm-dependent Rademacher Complexity},\n  author =       {Sachs, Sarah and van Erven, Tim and Hodgkinson, Liam and Khanna, Rajiv and {\\c{S}}im{\\c{s}}ekli, Umut},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4863--4880},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/sachs23a/sachs23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/sachs23a.html},\n  abstract = \t {Algorithm- and data-dependent generalization bounds are required to explain the generalization behavior of modern machine learning algorithms. In this context, there exists information theoretic generalization bounds that involve (various forms of) mutual information, as well as bounds based on hypothesis set stability. We propose a conceptually related, but technically distinct complexity measure to control generalization error, which is the empirical Rademacher complexity of an algorithm- and data-dependent hypothesis class. Combining standard properties of Rademacher complexity with the convenient structure of this class, we are able to (i) obtain novel bounds based on the finite fractal dimension, which (a) extend previous fractal dimension-type bounds from continuous to finite hypothesis classes, and (b) avoid a mutual information term that was required in prior work; (ii) we greatly simplify the proof of a recent dimension-independent generalization bound for stochastic gradient descent; and (iii) we easily recover results for VC classes and compression schemes, similar to approaches based on conditional mutual information.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/sachs23a/sachs23a.pdf",
        "supp": "",
        "pdf_size": 339960,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9004009635097032695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Korteweg-de Vries Institute for Mathematics, University of Amsterdam; Korteweg-de Vries Institute for Mathematics, University of Amsterdam; School of Mathematics and Statistics, University of Melbourne; Department of Computer Science, Purdue University; Inria, CNRS, Ecole Normale Sup\u00e9rieure, PSL Research University",
        "aff_domain": "UVA.NL;TIMVANERVEN.NL;UNIMELB.EDU.AU;PURDUE.EDU;INRIA.FR",
        "email": "UVA.NL;TIMVANERVEN.NL;UNIMELB.EDU.AU;PURDUE.EDU;INRIA.FR",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "University of Amsterdam;University of Melbourne;Purdue University;INRIA",
        "aff_unique_dep": "Korteweg-de Vries Institute for Mathematics;School of Mathematics and Statistics;Department of Computer Science;",
        "aff_unique_url": "https://www.uva.nl;https://www.unimelb.edu.au;https://www.purdue.edu;https://www.inria.fr",
        "aff_unique_abbr": "UvA;UniMelb;Purdue;Inria",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Melbourne",
        "aff_country_unique_index": "0;0;1;2;3",
        "aff_country_unique": "Netherlands;Australia;United States;France"
    },
    {
        "id": "141405ed86",
        "title": "Geodesically convex $M$-estimation in metric spaces",
        "site": "https://proceedings.mlr.press/v195/brunel23a.html",
        "author": "Victor-Emmanuel Brunel",
        "abstract": "We study the asymptotic properties of geodesically convex $M$-estimation on non-linear spaces. Namely, we prove that under very minimal assumptions besides geodesic convexity of the cost function, one can obtain consistency and asymptotic normality, which are fundamental properties in statistical inference. Our results extend the Euclidean theory of convex $M$-estimation; They also generalize limit theorems on non-linear spaces which, essentially, were only known for barycenters, allowing to consider robust alternatives that are defined through non-smooth $M$-estimation procedures.",
        "bibtex": "@InProceedings{pmlr-v195-brunel23a,\n  title = \t {Geodesically convex $M$-estimation in metric spaces},\n  author =       {Brunel, Victor-Emmanuel},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2188--2210},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/brunel23a/brunel23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/brunel23a.html},\n  abstract = \t {We study the asymptotic properties of geodesically convex $M$-estimation on non-linear spaces. Namely, we prove that under very minimal assumptions besides geodesic convexity of the cost function, one can obtain consistency and asymptotic normality, which are fundamental properties in statistical inference. Our results extend the Euclidean theory of convex $M$-estimation; They also generalize limit theorems on non-linear spaces which, essentially, were only known for barycenters, allowing to consider robust alternatives that are defined through non-smooth $M$-estimation procedures.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/brunel23a/brunel23a.pdf",
        "supp": "",
        "pdf_size": 308006,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6976666029572485546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "ENSAE",
        "aff_domain": "ENSAE.FR",
        "email": "ENSAE.FR",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "\u00c9cole Nationale de la Statistique et de l'Administration \u00c9conomique",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ensae.fr",
        "aff_unique_abbr": "ENSAE",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "2ca8408f6a",
        "title": "Geometric Barriers for Stable and Online Algorithms for Discrepancy Minimization",
        "site": "https://proceedings.mlr.press/v195/gamarnik23a.html",
        "author": "David Gamarnik; Eren C. Kizilda\u011f; Will Perkins; Changji Xu",
        "abstract": "For many computational problems involving randomness, intricate geometric features of the solution space have been used to rigorously rule out powerful classes of algorithms. This is often accomplished through the lens of the multi Overlap Gap Property ($m$-OGP), a rigorous barrier against algorithms exhibiting input stability. In this paper, we focus on the algorithmic tractability of two models: (i) discrepancy minimization, and (ii) the symmetric binary perceptron (\\texttt{SBP}), a random constraint satisfaction problem as well as a toy model of a single-layer neural network.Our first focus is on the limits of online algorithms. By establishing and leveraging a novel geometrical barrier, we obtain sharp hardness guarantees against online algorithms for both the \\texttt{SBP} and discrepancy minimization. Our results match the best known  algorithmic guarantees, up to constant factors. Our second focus is on efficiently finding a constant discrepancy solution, given a random matrix $\\mathcal{M}\\in\\R^{M\\times n}$. In a smooth setting, where the entries of $\\mathcal{M}$ are i.i.d.\\,standard normal, we establish the presence of $m$-OGP for $n=\\Theta(M\\log M)$. Consequently, we rule out the class of stable algorithms at this value. These results give the first rigorous evidence towards\u00a0\\citet[Conjecture\u00a01]{altschuler2021discrepancy}.  Our methods use the intricate geometry of the solution space to prove tight hardness results for online algorithms. The barrier we establish is a novel variant of the $m$-OGP.  Furthermore, it regards $m$-tuples of solutions with respect to correlated instances, with growing values of $m$, $m=\\omega(1)$.  Importantly, our results rule out online algorithms succeeding even with an exponentially small probability.",
        "bibtex": "@InProceedings{pmlr-v195-gamarnik23a,\n  title = \t {Geometric Barriers for Stable and Online Algorithms for Discrepancy Minimization},\n  author =       {Gamarnik, David and Kizilda{\\u{g}}, Eren C. and Perkins, Will and Xu, Changji},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3231--3263},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gamarnik23a/gamarnik23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gamarnik23a.html},\n  abstract = \t {For many computational problems involving randomness, intricate geometric features of the solution space have been used to rigorously rule out powerful classes of algorithms. This is often accomplished through the lens of the multi Overlap Gap Property ($m$-OGP), a rigorous barrier against algorithms exhibiting input stability. In this paper, we focus on the algorithmic tractability of two models: (i) discrepancy minimization, and (ii) the symmetric binary perceptron (\\texttt{SBP}), a random constraint satisfaction problem as well as a toy model of a single-layer neural network.Our first focus is on the limits of online algorithms. By establishing and leveraging a novel geometrical barrier, we obtain sharp hardness guarantees against online algorithms for both the \\texttt{SBP} and discrepancy minimization. Our results match the best known  algorithmic guarantees, up to constant factors. Our second focus is on efficiently finding a constant discrepancy solution, given a random matrix $\\mathcal{M}\\in\\R^{M\\times n}$. In a smooth setting, where the entries of $\\mathcal{M}$ are i.i.d.\\,standard normal, we establish the presence of $m$-OGP for $n=\\Theta(M\\log M)$. Consequently, we rule out the class of stable algorithms at this value. These results give the first rigorous evidence towards\u00a0\\citet[Conjecture\u00a01]{altschuler2021discrepancy}.  Our methods use the intricate geometry of the solution space to prove tight hardness results for online algorithms. The barrier we establish is a novel variant of the $m$-OGP.  Furthermore, it regards $m$-tuples of solutions with respect to correlated instances, with growing values of $m$, $m=\\omega(1)$.  Importantly, our results rule out online algorithms succeeding even with an exponentially small probability.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/gamarnik23a/gamarnik23a.pdf",
        "supp": "",
        "pdf_size": 476890,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13764164547131988745&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Sloan School of Management, Massachusetts Institute of Technology; Department of Statistics, Columbia University; School of Computer Science, Georgia Institute of Technology; Center of Mathematical Sciences and Applications, Harvard University",
        "aff_domain": "MIT.EDU;COLUMBIA.EDU;WILLPERKINS.ORG;CMSA.FAS.HARVARD.EDU",
        "email": "MIT.EDU;COLUMBIA.EDU;WILLPERKINS.ORG;CMSA.FAS.HARVARD.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Massachusetts Institute of Technology;Columbia University;Georgia Institute of Technology;Harvard University",
        "aff_unique_dep": "Sloan School of Management;Department of Statistics;School of Computer Science;Center of Mathematical Sciences and Applications",
        "aff_unique_url": "https://mitsloan.mit.edu/;https://www.columbia.edu;https://www.gatech.edu;https://www.harvard.edu",
        "aff_unique_abbr": "MIT;Columbia;Georgia Tech;Harvard",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Cambridge;;Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e47137491a",
        "title": "Hardness of Agnostically Learning Halfspaces from Worst-Case Lattice Problems",
        "site": "https://proceedings.mlr.press/v195/tiegel23a.html",
        "author": "Stefan Tiegel",
        "abstract": "We show hardness of improperly learning halfspaces in the agnostic model, both in the distribution-independent as well as the distribution-specific setting, based on the assumption that worst-case lattice problems, e.g., approximating shortest vectors within polynomial factors, are hard.In particular, we show that under this assumption there is no efficient algorithm that outputs any binary hypothesis, not necessarily a halfspace, achieving misclassfication error better than $\\frac 1 2 - \\gamma$ even if the optimal misclassification error is as small is as small as $\\delta$.Here, $\\gamma$ can be smaller than the inverse of any polynomial in the dimension and $\\delta$ as small as $\\exp(-\\Omega(\\log^{1-c}(d)))$, where $0 < c < 1$ is an arbitrary constant and $d$ is the dimension.For the distribution-specific setting, we show that if the marginal distribution is standard Gaussian, for any $\\beta > 0$ learning halfspaces up to error $\\OPT_\\LTF + \\varepsilon$ takes time at least $d^{\\tilde{\\Omega}(1/\\varepsilon^{2-\\beta})}$ under the same hardness assumptions.Similarly, we show that learning degree-$\\ell$ polynomial threshold functions up to error $\\OPT_{\\PTF_\\ell} + \\e$ takes time at least $d^{\\tilde{\\Omega}(\\ell^{2-\\beta}/\\varepsilon^{4-2\\beta})}$.$\\OPT_\\LTF$ and $\\OPT_{\\PTF_\\ell}$ denote the best error achievable by any halfspace or polynomial threshold function, respectively.Our lower bounds qualitively match algorithmic guarantees and (nearly) recover known lower bounds based on non-worst-case assumptions.Previously, such hardness results [D16, DKPZ21] were based on average-case complexity assumptions, specifically, variants of Feige\u2019s random 3SAT hypothesis, or restricted to the statistical query model.Our work gives the first hardness results basing these fundamental learning problems on well-understood worst-case complexity assumption.It is inspired by a sequence of recent works showing hardness of learning well-separated Gaussian mixtures based on worst-case lattice problems.",
        "bibtex": "@InProceedings{pmlr-v195-tiegel23a,\n  title = \t {Hardness of Agnostically Learning Halfspaces from Worst-Case Lattice Problems},\n  author =       {Tiegel, Stefan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3029--3064},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/tiegel23a/tiegel23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/tiegel23a.html},\n  abstract = \t {We show hardness of improperly learning halfspaces in the agnostic model, both in the distribution-independent as well as the distribution-specific setting, based on the assumption that worst-case lattice problems, e.g., approximating shortest vectors within polynomial factors, are hard.In particular, we show that under this assumption there is no efficient algorithm that outputs any binary hypothesis, not necessarily a halfspace, achieving misclassfication error better than $\\frac 1 2 - \\gamma$ even if the optimal misclassification error is as small is as small as $\\delta$.Here, $\\gamma$ can be smaller than the inverse of any polynomial in the dimension and $\\delta$ as small as $\\exp(-\\Omega(\\log^{1-c}(d)))$, where $0 < c < 1$ is an arbitrary constant and $d$ is the dimension.For the distribution-specific setting, we show that if the marginal distribution is standard Gaussian, for any $\\beta > 0$ learning halfspaces up to error $\\OPT_\\LTF + \\varepsilon$ takes time at least $d^{\\tilde{\\Omega}(1/\\varepsilon^{2-\\beta})}$ under the same hardness assumptions.Similarly, we show that learning degree-$\\ell$ polynomial threshold functions up to error $\\OPT_{\\PTF_\\ell} + \\e$ takes time at least $d^{\\tilde{\\Omega}(\\ell^{2-\\beta}/\\varepsilon^{4-2\\beta})}$.$\\OPT_\\LTF$ and $\\OPT_{\\PTF_\\ell}$ denote the best error achievable by any halfspace or polynomial threshold function, respectively.Our lower bounds qualitively match algorithmic guarantees and (nearly) recover known lower bounds based on non-worst-case assumptions.Previously, such hardness results [D16, DKPZ21] were based on average-case complexity assumptions, specifically, variants of Feige\u2019s random 3SAT hypothesis, or restricted to the statistical query model.Our work gives the first hardness results basing these fundamental learning problems on well-understood worst-case complexity assumption.It is inspired by a sequence of recent works showing hardness of learning well-separated Gaussian mixtures based on worst-case lattice problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/tiegel23a/tiegel23a.pdf",
        "supp": "",
        "pdf_size": 490332,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5818740504963735680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Andreasstrasse 5, 8050 Z\u00fcrich",
        "aff_domain": "inf.ethz.ch",
        "email": "inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "26184ee381",
        "title": "Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing",
        "site": "https://proceedings.mlr.press/v195/soltanolkotabi23a.html",
        "author": "Mahdi Soltanolkotabi; Dominik St\u00f6ger; Changzhi Xie",
        "abstract": "Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization, remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factorized gradient descent converges to the low-rank matrix generating the measurements. We show that in this setting, factorized gradient descent enjoys two implicit properties: (1) coupling of the trajectory of gradient descent where the factors are coupled in various ways throughout the gradient update trajectory and (2) an algorithmic regularization property where the iterates show a propensity towards low-rank models despite the overparameterized nature of the factorized model. These two implicit properties in turn allow us to show that the gradient descent trajectory from small random initialization moves towards solutions that are both globally optimal and generalize well.",
        "bibtex": "@InProceedings{pmlr-v195-soltanolkotabi23a,\n  title = \t {Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing},\n  author =       {Soltanolkotabi, Mahdi and St{\\\"o}ger, Dominik and Xie, Changzhi},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5140--5142},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/soltanolkotabi23a/soltanolkotabi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/soltanolkotabi23a.html},\n  abstract = \t {Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization, remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factorized gradient descent converges to the low-rank matrix generating the measurements. We show that in this setting, factorized gradient descent enjoys two implicit properties: (1) coupling of the trajectory of gradient descent where the factors are coupled in various ways throughout the gradient update trajectory and (2) an algorithmic regularization property where the iterates show a propensity towards low-rank models despite the overparameterized nature of the factorized model. These two implicit properties in turn allow us to show that the gradient descent trajectory from small random initialization moves towards solutions that are both globally optimal and generalize well.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/soltanolkotabi23a/soltanolkotabi23a.pdf",
        "supp": "",
        "pdf_size": 87374,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "University of Southern California; KU Eichst\\\"att-Ingolstadt; University of Southern California",
        "aff_domain": "USC.EDU;KU.DE;USC.EDU",
        "email": "USC.EDU;KU.DE;USC.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;Katholische Universit\u00e4t Eichst\u00e4tt-Ingolstadt",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.usc.edu;https://www.ku-eichstaett.de",
        "aff_unique_abbr": "USC;KU Eichst\u00e4tt-Ingolstadt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "212aea63e5",
        "title": "Improper Multiclass Boosting",
        "site": "https://proceedings.mlr.press/v195/brukhim23a.html",
        "author": "Nataly Brukhim; Steve Hanneke; Shay Moran",
        "abstract": "We study the setting of multiclass boosting with a possibly large number of classes. A recent work by Brukhim, Hazan, Moran, and Schapire, 2021, proved a hardness result for a large class of natural boosting algorithms we call proper. These algorithms output predictors that correspond to a plurality-vote aggregation of weak hypotheses. In particular, they showed that proper boosting algorithms must incur a large cost that scales with the number of classes.In this work we propose an efficient improper multiclass boosting algorithm that circumvents this hardness result. A key component of our algorithm is based on the technique of list learning. In list learning, instead of predicting a single outcome for a given unseen input, the goal is to provide a short menu of predictions. The resulting boosting algorithm has sample and oracle complexity bounds that are entirely independent of the number of classes.A corollary of the above is that plurality-vote over a learnable class is also learnable. We complement this result by showing that other simple aggregations over hypotheses from a learnable class do not preserve learnability, unlike in the binary setting.",
        "bibtex": "@InProceedings{pmlr-v195-brukhim23a,\n  title = \t {Improper Multiclass Boosting},\n  author =       {Brukhim, Nataly and Hanneke, Steve and Moran, Shay},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5433--5452},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/brukhim23a/brukhim23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/brukhim23a.html},\n  abstract = \t {We study the setting of multiclass boosting with a possibly large number of classes. A recent work by Brukhim, Hazan, Moran, and Schapire, 2021, proved a hardness result for a large class of natural boosting algorithms we call proper. These algorithms output predictors that correspond to a plurality-vote aggregation of weak hypotheses. In particular, they showed that proper boosting algorithms must incur a large cost that scales with the number of classes.In this work we propose an efficient improper multiclass boosting algorithm that circumvents this hardness result. A key component of our algorithm is based on the technique of list learning. In list learning, instead of predicting a single outcome for a given unseen input, the goal is to provide a short menu of predictions. The resulting boosting algorithm has sample and oracle complexity bounds that are entirely independent of the number of classes.A corollary of the above is that plurality-vote over a learnable class is also learnable. We complement this result by showing that other simple aggregations over hypotheses from a learnable class do not preserve learnability, unlike in the binary setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/brukhim23a/brukhim23a.pdf",
        "supp": "",
        "pdf_size": 340403,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11942058903098908788&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Computer Science, Princeton University; Department of Computer Science, Purdue University; Departments of Mathematics and Computer Science, Technion and Google Research",
        "aff_domain": "princeton.edu;gmail.com;technion.ac.il",
        "email": "princeton.edu;gmail.com;technion.ac.il",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Purdue University;Technion",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Departments of Mathematics and Computer Science",
        "aff_unique_url": "https://www.princeton.edu;https://www.purdue.edu;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Princeton;Purdue;Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "3f9d7cd9bd",
        "title": "Improved Bounds for Multi-task Learning with Trace Norm Regularization",
        "site": "https://proceedings.mlr.press/v195/liu23a.html",
        "author": "Weiwei Liu",
        "abstract": "Compared with learning each task independently, multi-task learning (MTL) is able to learn with few training samples and achieves better prediction performance. Recently, Boursier et al. (2022) study the estimation error bound for MTL with trace norm regularizer and a few observations per task. However, their results rely on three assumptions: 1) The features are isotropic; 2) The task diversity assumption is enforced to the parameters matrix; 3) The number of tasks is larger than the features dimension. Whether it is possible to drop these three assumptions and improve the bounds in Boursier et al. (2022) has remained unknown. This paper provides an affirmative answer to this question. Specifically, we reduce their upper bounds from $\\tilde{\\mathcal{O}}(\\sigma \\sqrt{\\frac{rd^2/m+rT}{m}} + \\sqrt{\\frac{rd^2/m+rdT/m}{m}})$ to $\\mathcal{O}( \\sigma\\sqrt{\\frac{r+rd/T}{m}} )$ without three assumptions, where $T$ is the number of tasks, $d$ is the dimension of the feature space, $m$ is the number of observations per task, $r$ is the rank of ground truth matrix, $\\sigma$ is the standard deviation of the noise random variable. Moreover, we provide minimax lower bounds showing our upper bounds are rateoptimal if $T =\\mathcal{O}(d)$.",
        "bibtex": "@InProceedings{pmlr-v195-liu23a,\n  title = \t {Improved Bounds for Multi-task Learning with Trace Norm Regularization},\n  author =       {Liu, Weiwei},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {700--714},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/liu23a/liu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/liu23a.html},\n  abstract = \t {Compared with learning each task independently, multi-task learning (MTL) is able to learn with few training samples and achieves better prediction performance. Recently, Boursier et al. (2022) study the estimation error bound for MTL with trace norm regularizer and a few observations per task. However, their results rely on three assumptions: 1) The features are isotropic; 2) The task diversity assumption is enforced to the parameters matrix; 3) The number of tasks is larger than the features dimension. Whether it is possible to drop these three assumptions and improve the bounds in Boursier et al. (2022) has remained unknown. This paper provides an affirmative answer to this question. Specifically, we reduce their upper bounds from $\\tilde{\\mathcal{O}}(\\sigma \\sqrt{\\frac{rd^2/m+rT}{m}} + \\sqrt{\\frac{rd^2/m+rdT/m}{m}})$ to $\\mathcal{O}( \\sigma\\sqrt{\\frac{r+rd/T}{m}} )$ without three assumptions, where $T$ is the number of tasks, $d$ is the dimension of the feature space, $m$ is the number of observations per task, $r$ is the rank of ground truth matrix, $\\sigma$ is the standard deviation of the noise random variable. Moreover, we provide minimax lower bounds showing our upper bounds are rateoptimal if $T =\\mathcal{O}(d)$.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/liu23a/liu23a.pdf",
        "supp": "",
        "pdf_size": 355793,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4569857013283980116&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "School of Computer Science, National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence and Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University, Wuhan, China",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Wuhan University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "http://www.whu.edu.cn",
        "aff_unique_abbr": "WHU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "id": "ae50ffbd86",
        "title": "Improved Discretization Analysis for Underdamped Langevin Monte Carlo",
        "site": "https://proceedings.mlr.press/v195/zhang23a.html",
        "author": "Shunshi Zhang; Sinho Chewi; Mufan Li; Krishna Balasubramanian; Murat A. Erdogdu",
        "abstract": "Underdamped Langevin Monte Carlo (ULMC) is an algorithm used to sample from unnormalized densities by leveraging the momentum of a particle moving in a potential well. We provide a novel analysis of ULMC, motivated by two central questions: (1) Can we obtain improved sampling guarantees beyond strong log-concavity? (2) Can we achieve acceleration for sampling?For (1), prior results for ULMC only hold under a log-Sobolev inequality together with a restrictive Hessian smoothness condition. Here, we relax these assumptions by removing the Hessian smoothness condition and by considering distributions satisfying a Poincare inequality. Our analysis achieves the state of art dimension dependence, and is also flexible enough to handle weakly smooth potentials. As a byproduct, we also obtain the first KL divergence guarantees for ULMC without Hessian smoothness under strong log-concavity, which is based on a new result on the log-Sobolev constant along the underdamped Langevin diffusion.For (2), the recent breakthrough of Cao, Lu, and Wang (2020) established the first accelerated result for sampling in continuous time via PDE methods. Our discretization analysis translates their result into an algorithmic guarantee, which indeed enjoys better condition number dependence than prior works on ULMC, although we leave open the question of full acceleration in discrete time.Both (1) and (2) necessitate Renyi discretization bounds, which are more challenging than the typically used Wasserstein coupling arguments. We address this using a flexible discretization analysis based on Girsanov\u2019s theorem that easily extends to more general settings.",
        "bibtex": "@InProceedings{pmlr-v195-zhang23a,\n  title = \t {Improved Discretization Analysis for Underdamped Langevin Monte Carlo},\n  author =       {Zhang, Shunshi and Chewi, Sinho and Li, Mufan and Balasubramanian, Krishna and Erdogdu, Murat A.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {36--71},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/zhang23a/zhang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/zhang23a.html},\n  abstract = \t {Underdamped Langevin Monte Carlo (ULMC) is an algorithm used to sample from unnormalized densities by leveraging the momentum of a particle moving in a potential well. We provide a novel analysis of ULMC, motivated by two central questions: (1) Can we obtain improved sampling guarantees beyond strong log-concavity? (2) Can we achieve acceleration for sampling?For (1), prior results for ULMC only hold under a log-Sobolev inequality together with a restrictive Hessian smoothness condition. Here, we relax these assumptions by removing the Hessian smoothness condition and by considering distributions satisfying a Poincare inequality. Our analysis achieves the state of art dimension dependence, and is also flexible enough to handle weakly smooth potentials. As a byproduct, we also obtain the first KL divergence guarantees for ULMC without Hessian smoothness under strong log-concavity, which is based on a new result on the log-Sobolev constant along the underdamped Langevin diffusion.For (2), the recent breakthrough of Cao, Lu, and Wang (2020) established the first accelerated result for sampling in continuous time via PDE methods. Our discretization analysis translates their result into an algorithmic guarantee, which indeed enjoys better condition number dependence than prior works on ULMC, although we leave open the question of full acceleration in discrete time.Both (1) and (2) necessitate Renyi discretization bounds, which are more challenging than the typically used Wasserstein coupling arguments. We address this using a flexible discretization analysis based on Girsanov\u2019s theorem that easily extends to more general settings. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/zhang23a/zhang23a.pdf",
        "supp": "",
        "pdf_size": 480287,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16472727208089787120&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "University of Toronto and Vector Institute; Massachusetts Institute of Technology; University of Toronto and Vector Institute; University of California, Davis; University of Toronto and Vector Institute",
        "aff_domain": "MAIL.UTORONTO.CA;MIT.EDU;MAIL.UTORONTO.CA;UCDAVIS.EDU;CS.TORONTO.EDU",
        "email": "MAIL.UTORONTO.CA;MIT.EDU;MAIL.UTORONTO.CA;UCDAVIS.EDU;CS.TORONTO.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "University of Toronto;Massachusetts Institute of Technology;University of California, Davis",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.utoronto.ca;https://web.mit.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "U of T;MIT;UC Davis",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Toronto;;Davis",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "7adcb59637",
        "title": "Improved Dynamic Regret for Online Frank-Wolfe",
        "site": "https://proceedings.mlr.press/v195/wan23a.html",
        "author": "Yuanyu Wan; Lijun Zhang; Mingli Song",
        "abstract": "To deal with non-stationary online problems with complex constraints, we investigate the dynamic regret of online Frank-Wolfe (OFW), which is an efficient projection-free algorithm for online convex optimization. It is well-known that in the setting of offline optimization, the smoothness of functions and the strong convexity of functions accompanying specific properties of constraint sets can be utilized to achieve fast convergence rates for the Frank-Wolfe (FW) algorithm. However, for OFW, previous studies only establish a dynamic regret bound of $O(\\sqrt{T}(V_T+\\sqrt{D_T}+1))$ by utilizing the convexity of problems, where $T$ is the number of rounds, $V_T$ is the function variation, and $D_T$ is the gradient variation. In this paper, we derive improved dynamic regret bounds for OFW by extending the fast convergence rates of FW from offline optimization to online optimization. The key technique for this extension is to set the step size of OFW with a line search rule. In this way, we first show that the dynamic regret bound of OFW can be improved to $O(\\sqrt{T(V_T+1)})$ for smooth functions. Second, we achieve a better dynamic regret bound of $O(T^{1/3}(V_T+1)^{2/3})$ when functions are smooth and strongly convex, and the constraint set is strongly convex. Finally, for smooth and strongly convex functions with minimizers in the interior of the constraint set, we demonstrate that the dynamic regret of OFW reduces to $O(V_T+1)$, and can be further strengthened to $O(\\min\\{P_T^\\ast,S_T^\\ast,V_T\\}+1)$ by performing a constant number of FW iterations per round, where $P_T^\\ast$ and $S_T^\\ast$ denote the path length and squared path length of minimizers, respectively.",
        "bibtex": "@InProceedings{pmlr-v195-wan23a,\n  title = \t {Improved Dynamic Regret for Online Frank-Wolfe},\n  author =       {Wan, Yuanyu and Zhang, Lijun and Song, Mingli},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3304--3327},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wan23a/wan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wan23a.html},\n  abstract = \t {To deal with non-stationary online problems with complex constraints, we investigate the dynamic regret of online Frank-Wolfe (OFW), which is an efficient projection-free algorithm for online convex optimization. It is well-known that in the setting of offline optimization, the smoothness of functions and the strong convexity of functions accompanying specific properties of constraint sets can be utilized to achieve fast convergence rates for the Frank-Wolfe (FW) algorithm. However, for OFW, previous studies only establish a dynamic regret bound of $O(\\sqrt{T}(V_T+\\sqrt{D_T}+1))$ by utilizing the convexity of problems, where $T$ is the number of rounds, $V_T$ is the function variation, and $D_T$ is the gradient variation. In this paper, we derive improved dynamic regret bounds for OFW by extending the fast convergence rates of FW from offline optimization to online optimization. The key technique for this extension is to set the step size of OFW with a line search rule. In this way, we first show that the dynamic regret bound of OFW can be improved to $O(\\sqrt{T(V_T+1)})$ for smooth functions. Second, we achieve a better dynamic regret bound of $O(T^{1/3}(V_T+1)^{2/3})$ when functions are smooth and strongly convex, and the constraint set is strongly convex. Finally, for smooth and strongly convex functions with minimizers in the interior of the constraint set, we demonstrate that the dynamic regret of OFW reduces to $O(V_T+1)$, and can be further strengthened to $O(\\min\\{P_T^\\ast,S_T^\\ast,V_T\\}+1)$ by performing a constant number of FW iterations per round, where $P_T^\\ast$ and $S_T^\\ast$ denote the path length and squared path length of minimizers, respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wan23a/wan23a.pdf",
        "supp": "",
        "pdf_size": 342464,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12178240985361373976&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "School of Software Technology, Zhejiang University; National Key Laboratory for Novel Software Technology, Nanjing University; Shanghai Institute for Advanced Study, Zhejiang University",
        "aff_domain": "zju.edu.cn;lamda.nju.edu.cn;zju.edu.cn",
        "email": "zju.edu.cn;lamda.nju.edu.cn;zju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Zhejiang University;Nanjing University",
        "aff_unique_dep": "School of Software Technology;National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.zju.edu.cn;http://www.nju.edu.cn",
        "aff_unique_abbr": "ZJU;Nanjing University",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "67a8cceb15",
        "title": "Improved dimension dependence of a proximal algorithm for sampling",
        "site": "https://proceedings.mlr.press/v195/fan23a.html",
        "author": "Jiaojiao Fan; Bo Yuan; Yongxin Chen",
        "abstract": "We propose a sampling algorithm that achieves superior complexity bounds in all the classical settings (strongly log-concave, log-concave, Logarithmic-Sobolev inequality (LSI), Poincar\u00e9 inequality) as well as more general settings with semi-smooth or composite potentials. Our algorithm is based on the proximal sampler introduced in Lee et al. 2021. The performance of this proximal sampler is determined by that of the restricted Gaussian oracle (RGO), a key step in the proximal sampler. The main contribution of this work is an inexact realization of RGO based on approximate rejection sampling. To bound the inexactness of RGO, we establish a new concentration inequality for semi-smooth functions over Gaussian distributions, extending the well-known concentration inequality for Lipschitz functions. Applying our RGO implementation to the proximal sampler, we achieve state-of-the-art complexity bounds in almost all settings. For instance, for strongly log-concave distributions, our method has complexity bound $\\tilde\\cO(\\kappa d^{1/2})$ without warm start, better than the minimax bound for MALA. For distributions satisfying the LSI, our bound is $\\tilde \\cO(\\hat \\kappa d^{1/2})$ where $\\hat \\kappa$ is the ratio between smoothness and the LSI constant, better than all existing bounds.",
        "bibtex": "@InProceedings{pmlr-v195-fan23a,\n  title = \t {Improved dimension dependence of a proximal algorithm for sampling},\n  author =       {Fan, Jiaojiao and Yuan, Bo and Chen, Yongxin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1473--1521},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/fan23a/fan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/fan23a.html},\n  abstract = \t {We propose a sampling algorithm that achieves superior complexity bounds in all the classical settings (strongly log-concave, log-concave, Logarithmic-Sobolev inequality (LSI), Poincar\u00e9 inequality) as well as more general settings with semi-smooth or composite potentials. Our algorithm is based on the proximal sampler introduced in Lee et al. 2021. The performance of this proximal sampler is determined by that of the restricted Gaussian oracle (RGO), a key step in the proximal sampler. The main contribution of this work is an inexact realization of RGO based on approximate rejection sampling. To bound the inexactness of RGO, we establish a new concentration inequality for semi-smooth functions over Gaussian distributions, extending the well-known concentration inequality for Lipschitz functions. Applying our RGO implementation to the proximal sampler, we achieve state-of-the-art complexity bounds in almost all settings. For instance, for strongly log-concave distributions, our method has complexity bound $\\tilde\\cO(\\kappa d^{1/2})$ without warm start, better than the minimax bound for MALA. For distributions satisfying the LSI, our bound is $\\tilde \\cO(\\hat \\kappa d^{1/2})$ where $\\hat \\kappa$ is the ratio between smoothness and the LSI constant, better than all existing bounds. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/fan23a/fan23a.pdf",
        "supp": "",
        "pdf_size": 525713,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8459208298697008281&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "aff_domain": "GATECH.EDU;GATECH.EDU;GATECH.EDU",
        "email": "GATECH.EDU;GATECH.EDU;GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3ca221fe78",
        "title": "Inference on Strongly Identified Functionals of Weakly Identified Functions",
        "site": "https://proceedings.mlr.press/v195/bennett23a.html",
        "author": "Andrew Bennett; Nathan Kallus; Xiaojie Mao; Whitney Newey; Vasilis Syrgkanis; Masatoshi Uehara",
        "abstract": "In a variety of applications, including nonparametric instrumental variable (NPIV) analysis, proximal causal inference under unmeasured confounding, and missing-not-at-random data with shadow variables, we are interested in inference on a continuous linear functional (e.g., average causal effects) of nuisance function (e.g., NPIV regression) defined by conditional moment restrictions. These nuisance functions are generally weakly identified, in that the conditional moment restrictions can be severely ill-posed as well as admit multiple solutions. This is sometimes resolved by imposing strong conditions that imply the function can be estimated at rates that make inference on the functional possible. In this paper, we study a novel condition for the functional to be strongly identified even when the nuisance function is not; that is, the functional is amenable to asymptotically-normal estimation at root-n-rates. The condition implies the existence of debiasing nuisance functions, and we propose penalized minimax estimators for both the primary and debiasing nuisance functions. The proposed nuisance estimators can accommodate flexible function classes, and importantly they can converge to fixed limits determined by the penalization regardless of the identifiability of the nuisances. We use the penalized nuisance estimators to form a debiased estimator for the functional of interest and prove its asymptotic normality under generic high-level conditions, which provide for asymptotically valid confidence intervals. We also illustrate our method in a novel partially linear proximal causal inference problem and a partially linear instrumental variable regression problem.",
        "bibtex": "@InProceedings{pmlr-v195-bennett23a,\n  title = \t {Inference on Strongly Identified Functionals of Weakly Identified Functions},\n  author =       {Bennett, Andrew and Kallus, Nathan and Mao, Xiaojie and Newey, Whitney and Syrgkanis, Vasilis and Uehara, Masatoshi},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2265--2265},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bennett23a/bennett23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bennett23a.html},\n  abstract = \t {In a variety of applications, including nonparametric instrumental variable (NPIV) analysis, proximal causal inference under unmeasured confounding, and missing-not-at-random data with shadow variables, we are interested in inference on a continuous linear functional (e.g., average causal effects) of nuisance function (e.g., NPIV regression) defined by conditional moment restrictions. These nuisance functions are generally weakly identified, in that the conditional moment restrictions can be severely ill-posed as well as admit multiple solutions. This is sometimes resolved by imposing strong conditions that imply the function can be estimated at rates that make inference on the functional possible. In this paper, we study a novel condition for the functional to be strongly identified even when the nuisance function is not; that is, the functional is amenable to asymptotically-normal estimation at root-n-rates. The condition implies the existence of debiasing nuisance functions, and we propose penalized minimax estimators for both the primary and debiasing nuisance functions. The proposed nuisance estimators can accommodate flexible function classes, and importantly they can converge to fixed limits determined by the penalization regardless of the identifiability of the nuisances. We use the penalized nuisance estimators to form a debiased estimator for the functional of interest and prove its asymptotic normality under generic high-level conditions, which provide for asymptotically valid confidence intervals. We also illustrate our method in a novel partially linear proximal causal inference problem and a partially linear instrumental variable regression problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/bennett23a/bennett23a.pdf",
        "supp": "",
        "pdf_size": 64654,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5499830376964577901&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Cornell University; Cornell University; Tsinghua University; Massachusetts Institute of Technology; Stanford University; Cornell University",
        "aff_domain": "CORNELL.EDU;CORNELL.EDU;SEM.TSINGHUA.EDU.CN;MIT.EDU;STANFORD.EDU;CORNELL.EDU",
        "email": "CORNELL.EDU;CORNELL.EDU;SEM.TSINGHUA.EDU.CN;MIT.EDU;STANFORD.EDU;CORNELL.EDU",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "Cornell University;Tsinghua University;Massachusetts Institute of Technology;Stanford University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.cornell.edu;https://www.tsinghua.edu.cn;https://web.mit.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Cornell;THU;MIT;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "a1757dd1e2",
        "title": "InfoNCE Loss Provably Learns Cluster-Preserving Representations",
        "site": "https://proceedings.mlr.press/v195/parulekar23a.html",
        "author": "Advait Parulekar; Liam Collins; Karthikeyan Shanmugam; Aryan Mokhtari; Sanjay Shakkottai",
        "abstract": "The goal of contrasting learning is to learn a representation that preserves underlying clusters by keeping samples with similar content, e.g. the \u201cdogness\u201d of a dog, close to each other in the space generated by the representation. A common and successful approach for tackling this unsupervised learning problem is minimizing the InfoNCE loss associated with the training samples, where each sample is associated with their augmentations (positive samples such as rotation, crop) and a batch of negative samples (unrelated samples). To the best of our knowledge, it was unanswered if the representation learned by minimizing the InfoNCE loss preserves the underlying data clusters, as it only promotes learning a representation that is faithful to augmentations, i.e., an image and its augmentations have the same representation. Our main result is to show that the representation learned by InfoNCE with a finite number of negative samples is also consistent with respect to {\\em clusters} in the data, under the condition that the augmentation sets within clusters may be non-overlapping but are close and intertwined, relative to the complexity of the learning function class.",
        "bibtex": "@InProceedings{pmlr-v195-parulekar23a,\n  title = \t {InfoNCE Loss Provably Learns Cluster-Preserving Representations},\n  author =       {Parulekar, Advait and Collins, Liam and Shanmugam, Karthikeyan and Mokhtari, Aryan and Shakkottai, Sanjay},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1914--1961},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/parulekar23a/parulekar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/parulekar23a.html},\n  abstract = \t {The goal of contrasting learning is to learn a representation that preserves underlying clusters by keeping samples with similar content, e.g. the \u201cdogness\u201d of a dog, close to each other in the space generated by the representation. A common and successful approach for tackling this unsupervised learning problem is minimizing the InfoNCE loss associated with the training samples, where each sample is associated with their augmentations (positive samples such as rotation, crop) and a batch of negative samples (unrelated samples). To the best of our knowledge, it was unanswered if the representation learned by minimizing the InfoNCE loss preserves the underlying data clusters, as it only promotes learning a representation that is faithful to augmentations, i.e., an image and its augmentations have the same representation. Our main result is to show that the representation learned by InfoNCE with a finite number of negative samples is also consistent with respect to {\\em clusters} in the data, under the condition that the augmentation sets within clusters may be non-overlapping but are close and intertwined, relative to the complexity of the learning function class.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/parulekar23a/parulekar23a.pdf",
        "supp": "",
        "pdf_size": 1922076,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2334111974089941902&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Texas at Austin; University of Texas at Austin; Google Research India; University of Texas at Austin; University of Texas at Austin",
        "aff_domain": "UTEXAS.EDU;UTEXAS.EDU;GOOGLE.COM;AUSTIN.UTEXAS.EDU;UTEXAS.EDU",
        "email": "UTEXAS.EDU;UTEXAS.EDU;GOOGLE.COM;AUSTIN.UTEXAS.EDU;UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Texas at Austin;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.utexas.edu;https://research.google",
        "aff_unique_abbr": "UT Austin;Google Research India",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Austin;Bangalore",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "bb51966b34",
        "title": "Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise",
        "site": "https://proceedings.mlr.press/v195/diakonikolas23a.html",
        "author": "Ilias Diakonikolas; Jelena Diakonikolas; Daniel M. Kane; Puqian Wang; Nikos Zarifis",
        "abstract": "We study the problem of PAC learning $\\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoffsuggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\\widetilde{O}(1/(\\gamma^2 \\epsilon^2))$. Our main resultis a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\\epsilon$ in the sample complexity is inherent for computationally efficient algorithms.Specifically, our results imply a lower bound of $\\widetilde{\\Omega}(1/(\\gamma^{1/2} \\epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.",
        "bibtex": "@InProceedings{pmlr-v195-diakonikolas23a,\n  title = \t {Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise},\n  author =       {Diakonikolas, Ilias and Diakonikolas, Jelena and Kane, Daniel M. and Wang, Puqian and Zarifis, Nikos},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2211--2239},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/diakonikolas23a/diakonikolas23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/diakonikolas23a.html},\n  abstract = \t {We study the problem of PAC learning $\\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoffsuggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\\widetilde{O}(1/(\\gamma^2 \\epsilon^2))$. Our main resultis a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\\epsilon$ in the sample complexity is inherent for computationally efficient algorithms.Specifically, our results imply a lower bound of $\\widetilde{\\Omega}(1/(\\gamma^{1/2} \\epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/diakonikolas23a/diakonikolas23a.pdf",
        "supp": "",
        "pdf_size": 567809,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17829906349967188040&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison; University California, San Diego; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": "cs.wisc.edu;cs.wisc.edu;ucsd.edu;wisc.edu;wisc.edu",
        "email": "cs.wisc.edu;cs.wisc.edu;ucsd.edu;wisc.edu;wisc.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Wisconsin-Madison;University of California, San Diego",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "UW-Madison;UCSD",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Madison;San Diego",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0933bde1cf",
        "title": "Information-Directed Selection for Top-Two Algorithms",
        "site": "https://proceedings.mlr.press/v195/you23a.html",
        "author": "Wei You; Chao Qin; Zihao Wang; Shuoguang Yang",
        "abstract": "We consider the best-k-arm identification problem for multi-armed bandits, where the objective is to select the exact set of k arms with the highest mean rewards by sequentially allocating measurement effort. We characterize the necessary and sufficient conditions for the optimal allocation using dual variables. Remarkably these optimality conditions lead to the extension of top-two algorithm design principle (Russo, 2020), initially proposed for best-arm identification. Furthermore, our optimality conditions induce a simple and effective selection rule dubbed information-directed selection (IDS) that selects one of the top-two candidates based on a measure of information gain. As a theoretical guarantee, we prove that integrated with IDS, top-two Thompson sampling is (asymptotically) optimal for Gaussian best-arm identification, solving a glaring open problem in the pure exploration literature (Russo, 2020). As a by-product, we show that for $k > 1$, top-two algorithms cannot achieve optimality even with an oracle tuning parameter. Numerical experiments show the superior performance of the proposed top-two algorithms with IDS and considerable improvement compared with algorithms without adaptive selection.",
        "bibtex": "@InProceedings{pmlr-v195-you23a,\n  title = \t {Information-Directed Selection for Top-Two Algorithms},\n  author =       {You, Wei and Qin, Chao and Wang, Zihao and Yang, Shuoguang},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2850--2851},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/you23a/you23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/you23a.html},\n  abstract = \t {We consider the best-k-arm identification problem for multi-armed bandits, where the objective is to select the exact set of k arms with the highest mean rewards by sequentially allocating measurement effort. We characterize the necessary and sufficient conditions for the optimal allocation using dual variables. Remarkably these optimality conditions lead to the extension of top-two algorithm design principle (Russo, 2020), initially proposed for best-arm identification. Furthermore, our optimality conditions induce a simple and effective selection rule dubbed information-directed selection (IDS) that selects one of the top-two candidates based on a measure of information gain. As a theoretical guarantee, we prove that integrated with IDS, top-two Thompson sampling is (asymptotically) optimal for Gaussian best-arm identification, solving a glaring open problem in the pure exploration literature (Russo, 2020). As a by-product, we show that for $k > 1$, top-two algorithms cannot achieve optimality even with an oracle tuning parameter. Numerical experiments show the superior performance of the proposed top-two algorithms with IDS and considerable improvement compared with algorithms without adaptive selection.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/you23a/you23a.pdf",
        "supp": "",
        "pdf_size": 81106,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6723450852928280044&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "The Hong Kong University of Science and Technology; Columbia University; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology",
        "aff_domain": "ust.hk;columbia.edu;connect.ust.hk;ust.hk",
        "email": "ust.hk;columbia.edu;connect.ust.hk;ust.hk",
        "github": "",
        "project": "https://arxiv.org/abs/2205.12086",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Columbia University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ust.hk;https://www.columbia.edu",
        "aff_unique_abbr": "HKUST;Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "f577a2d469",
        "title": "Instance-Optimality in Interactive Decision Making: Toward a Non-Asymptotic Theory",
        "site": "https://proceedings.mlr.press/v195/wagenmaker23a.html",
        "author": "Andrew J. Wagenmaker; Dylan J. Foster",
        "abstract": "We consider the development of adaptive, instance-dependent algorithms for interactive decision making (bandits, reinforcement learning, and beyond) that, rather than only performing well in the worst case, adapt to favorable properties of real-world instances for improved performance. We aim for instance-optimality, a strong notion of adaptivity which asserts that, on any particular problem instance, the algorithm under consideration outperforms all consistent algorithms. Instance-optimality enjoys a rich asymptotic theory originating from the work of \\citet{lai1985asymptotically} and \\citet{graves1997asymptotically}, but non-asymptotic guarantees have remained elusive outside of certain special cases. Even for problems as simple as tabular reinforcement learning, existing algorithms do not attain instance-optimal performance until the number of rounds of interaction is doubly exponential in the number of states.In this paper, we take the first step toward developing a non-asymptotic theory of instance-optimal decision making with general function approximation. We introduce a new complexity measure, the Allocation-Estimation Coefficient (AEC), and provide a new algorithm, AE2, which attains non-asymptotic instance-optimal performance at a rate controlled by the AEC. Our results recover the best known guarantees for well-studied problems such as finite-armed and linear bandits and, when specialized to tabular reinforcement learning, attain the first instance-optimal regret bounds with polynomial dependence on all problem parameters, improving over prior work exponentially. We complement these results with lower bounds that show that i) existing notions of statistical complexity are insufficient to derive non-asymptotic guarantees, and ii) under certain technical conditions, boundedness of the Allocation-Estimation Coefficient is necessary to learn an instance-optimal allocation of decisions in finite time.",
        "bibtex": "@InProceedings{pmlr-v195-wagenmaker23a,\n  title = \t {Instance-Optimality in Interactive Decision Making: Toward a Non-Asymptotic Theory},\n  author =       {Wagenmaker, Andrew J. and Foster, Dylan J.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1322--1472},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wagenmaker23a/wagenmaker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wagenmaker23a.html},\n  abstract = \t {We consider the development of adaptive, instance-dependent algorithms for interactive decision making (bandits, reinforcement learning, and beyond) that, rather than only performing well in the worst case, adapt to favorable properties of real-world instances for improved performance. We aim for instance-optimality, a strong notion of adaptivity which asserts that, on any particular problem instance, the algorithm under consideration outperforms all consistent algorithms. Instance-optimality enjoys a rich asymptotic theory originating from the work of \\citet{lai1985asymptotically} and \\citet{graves1997asymptotically}, but non-asymptotic guarantees have remained elusive outside of certain special cases. Even for problems as simple as tabular reinforcement learning, existing algorithms do not attain instance-optimal performance until the number of rounds of interaction is doubly exponential in the number of states.In this paper, we take the first step toward developing a non-asymptotic theory of instance-optimal decision making with general function approximation. We introduce a new complexity measure, the Allocation-Estimation Coefficient (AEC), and provide a new algorithm, AE2, which attains non-asymptotic instance-optimal performance at a rate controlled by the AEC. Our results recover the best known guarantees for well-studied problems such as finite-armed and linear bandits and, when specialized to tabular reinforcement learning, attain the first instance-optimal regret bounds with polynomial dependence on all problem parameters, improving over prior work exponentially. We complement these results with lower bounds that show that i) existing notions of statistical complexity are insufficient to derive non-asymptotic guarantees, and ii) under certain technical conditions, boundedness of the Allocation-Estimation Coefficient is necessary to learn an instance-optimal allocation of decisions in finite time.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wagenmaker23a/wagenmaker23a.pdf",
        "supp": "",
        "pdf_size": 1172592,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14301892247013600412&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Washington, Seattle, WA; Microsoft Research, New England",
        "aff_domain": "CS.WASHINGTON.EDU;MICROSOFT.COM",
        "email": "CS.WASHINGTON.EDU;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Washington;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.washington.edu;https://www.microsoft.com/en-us/research/group/newengland",
        "aff_unique_abbr": "UW;MSR",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seattle;New England",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "05433a36f0",
        "title": "Intrinsic dimensionality and generalization properties of the R-norm inductive bias",
        "site": "https://proceedings.mlr.press/v195/ardeshir23a.html",
        "author": "Navid Ardeshir; Daniel J. Hsu; Clayton H. Sanford",
        "abstract": "We study the structural and statistical properties of R-norm minimizing interpolants of datasets labeled by specific target functions. The R-norm is the basis of an inductive bias for two-layer neural networks, recently introduced to capture the functional effect of controlling the size of network weights, independently of the network width. We find that these interpolants are intrinsically multivariate functions, even when there are ridge functions that fit the data, and also that the R-norm inductive bias is not sufficient for achieving statistically optimal generalization for certain learning problems. Altogether, these results shed new light on an inductive bias that is connected to practical neural network training.",
        "bibtex": "@InProceedings{pmlr-v195-ardeshir23a,\n  title = \t {Intrinsic dimensionality and generalization properties of the R-norm inductive bias},\n  author =       {Ardeshir, Navid and Hsu, Daniel J. and Sanford, Clayton H.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3264--3303},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/ardeshir23a/ardeshir23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/ardeshir23a.html},\n  abstract = \t {We study the structural and statistical properties of R-norm minimizing interpolants of datasets labeled by specific target functions. The R-norm is the basis of an inductive bias for two-layer neural networks, recently introduced to capture the functional effect of controlling the size of network weights, independently of the network width. We find that these interpolants are intrinsically multivariate functions, even when there are ridge functions that fit the data, and also that the R-norm inductive bias is not sufficient for achieving statistically optimal generalization for certain learning problems. Altogether, these results shed new light on an inductive bias that is connected to practical neural network training.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/ardeshir23a/ardeshir23a.pdf",
        "supp": "",
        "pdf_size": 558762,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7172852563334484152&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Dept. of Statistics, Columbia University; Dept. of Computer Science, Columbia University; Dept. of Computer Science, Columbia University",
        "aff_domain": "COLUMBIA.EDU;CS.COLUMBIA.EDU;CS.COLUMBIA.EDU",
        "email": "COLUMBIA.EDU;CS.COLUMBIA.EDU;CS.COLUMBIA.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Dept. of Statistics",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "30fe26b455",
        "title": "Is Planted Coloring Easier than Planted Clique?",
        "site": "https://proceedings.mlr.press/v195/kothari23a.html",
        "author": "Pravesh Kothari; Santosh S Vempala; Alexander S Wein; Jeff Xu",
        "abstract": "We study the computational complexity of two related problems: recovering a planted q-coloring in G(n,1/2), and finding efficiently verifiable witnesses of non-q-colorability (a.k.a. refutations) in G(n,1/2). Our main results show hardness for both these problems in a restricted-but-powerful class of algorithms based on computing low-degree polynomials in the inputs.The problem of recovering a planted q-coloring is equivalent to recovering q disjoint planted cliques that cover all the vertices \u2014 a potentially easier variant of the well-studied planted clique problem. Our first result shows that this variant is as hard as the original planted clique problem in the low-degree polynomial model of computation: each clique needs to have size k >> sqrt(n) for efficient recovery to be possible. For the related variant where the cliques cover a (1-epsilon)-fraction of the vertices, we also show hardness by reduction from planted clique.Our second result shows that refuting q-colorability of G(n,1/2) is hard in the low-degree polynomial model when q >> n^{2/3} but easy when q << n^{1/2}, and we leave closing this gap for future work. Our proof is more subtle than similar results for planted clique and involves constructing a non-standard distribution over q-colorable graphs. We note that while related to several prior works, this is the first work that explicitly formulates refutation problems in the low-degree polynomial model.The proofs of our main results involve showing low-degree hardness of hypothesis testing between an appropriately constructed pair of distributions. For refutation, we show completeness of this approach: in the low-degree model, the refutation task is precisely as hard as the hardest associated testing problem, i.e., proving hardness of refutation amounts to finding a \"hard\" distribution.",
        "bibtex": "@InProceedings{pmlr-v195-kothari23a,\n  title = \t {Is Planted Coloring Easier than Planted Clique?},\n  author =       {Kothari, Pravesh and Vempala, Santosh S and Wein, Alexander S and Xu, Jeff},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5343--5372},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kothari23a/kothari23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kothari23a.html},\n  abstract = \t {We study the computational complexity of two related problems: recovering a planted q-coloring in G(n,1/2), and finding efficiently verifiable witnesses of non-q-colorability (a.k.a. refutations) in G(n,1/2). Our main results show hardness for both these problems in a restricted-but-powerful class of algorithms based on computing low-degree polynomials in the inputs.The problem of recovering a planted q-coloring is equivalent to recovering q disjoint planted cliques that cover all the vertices \u2014 a potentially easier variant of the well-studied planted clique problem. Our first result shows that this variant is as hard as the original planted clique problem in the low-degree polynomial model of computation: each clique needs to have size k >> sqrt(n) for efficient recovery to be possible. For the related variant where the cliques cover a (1-epsilon)-fraction of the vertices, we also show hardness by reduction from planted clique.Our second result shows that refuting q-colorability of G(n,1/2) is hard in the low-degree polynomial model when q >> n^{2/3} but easy when q << n^{1/2}, and we leave closing this gap for future work. Our proof is more subtle than similar results for planted clique and involves constructing a non-standard distribution over q-colorable graphs. We note that while related to several prior works, this is the first work that explicitly formulates refutation problems in the low-degree polynomial model.The proofs of our main results involve showing low-degree hardness of hypothesis testing between an appropriately constructed pair of distributions. For refutation, we show completeness of this approach: in the low-degree model, the refutation task is precisely as hard as the hardest associated testing problem, i.e., proving hardness of refutation amounts to finding a \"hard\" distribution.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/kothari23a/kothari23a.pdf",
        "supp": "",
        "pdf_size": 405642,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9567834754086237582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Computer Science Department, Carnegie Mellon University; School of Computer Science, Georgia Tech; Department of Mathematics, University of California, Davis; Computer Science Department, Carnegie Mellon University",
        "aff_domain": "CS.CMU.EDU;GATECH.EDU;UCDAVIS.EDU;CMU.EDU",
        "email": "CS.CMU.EDU;GATECH.EDU;UCDAVIS.EDU;CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Carnegie Mellon University;Georgia Institute of Technology;University of California, Davis",
        "aff_unique_dep": "Computer Science Department;School of Computer Science;Department of Mathematics",
        "aff_unique_url": "https://www.cmu.edu;https://www.gatech.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "CMU;Georgia Tech;UC Davis",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Atlanta;Davis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "41f83f3a9b",
        "title": "Kernelized Diffusion Maps",
        "site": "https://proceedings.mlr.press/v195/pillaud-vivien23a.html",
        "author": "Loucas Pillaud-Vivien; Francis Bach",
        "abstract": "Spectral clustering and diffusion maps are celebrated dimensionality reduction algorithms built on eigen-elements related to the diffusive structure of the data. The core of these procedures is the approximation of a Laplacian through a graph kernel approach, however this local average construction is known to be cursed by the high-dimension $d$. In this article, we build a different estimator of the Laplacian, via a reproducing kernel Hilbert spaces method, which adapts naturally to the regularity of the problem. We provide non-asymptotic statistical rates proving that the kernel estimator we build can circumvent the curse of dimensionality. Finally we discuss techniques (Nystr\u00f6m subsampling, Fourier features) that enable to reduce the computational cost of the estimator while not degrading its overall performance.",
        "bibtex": "@InProceedings{pmlr-v195-pillaud-vivien23a,\n  title = \t {Kernelized Diffusion Maps},\n  author =       {Pillaud-Vivien, Loucas and Bach, Francis},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5236--5259},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/pillaud-vivien23a/pillaud-vivien23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/pillaud-vivien23a.html},\n  abstract = \t {Spectral clustering and diffusion maps are celebrated dimensionality reduction algorithms built on eigen-elements related to the diffusive structure of the data. The core of these procedures is the approximation of a Laplacian through a graph kernel approach, however this local average construction is known to be cursed by the high-dimension $d$. In this article, we build a different estimator of the Laplacian, via a reproducing kernel Hilbert spaces method, which adapts naturally to the regularity of the problem. We provide non-asymptotic statistical rates proving that the kernel estimator we build can circumvent the curse of dimensionality. Finally we discuss techniques (Nystr\u00f6m subsampling, Fourier features) that enable to reduce the computational cost of the estimator while not degrading its overall performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/pillaud-vivien23a/pillaud-vivien23a.pdf",
        "supp": "",
        "pdf_size": 551304,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7246373953380712659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "NYU Courant - Flatiron Institute; INRIA Paris - DI ENS - PSL",
        "aff_domain": "FLATIRONINSTITUTE.ORG;INRIA.FR",
        "email": "FLATIRONINSTITUTE.ORG;INRIA.FR",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "New York University Courant Institute of Mathematical Sciences;INRIA Paris",
        "aff_unique_dep": "Courant Institute of Mathematical Sciences;DI ENS",
        "aff_unique_url": "https://courant.nyu.edu;https://www.inria.fr",
        "aff_unique_abbr": "NYU Courant;INRIA",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "New York;Paris",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "ab59981787",
        "title": "Law of Large Numbers for Bayesian two-layer Neural Network trained with Variational Inference",
        "site": "https://proceedings.mlr.press/v195/descours23a.html",
        "author": "Arnaud Descours; Tom Huix; Arnaud Guillin; Manon Michel; \u00c9ric Moulines; Boris Nectoux",
        "abstract": "We provide a rigorous analysis of training by variational inference (VI) of Bayesian neural networks in the two-layer and infinite-width case. We consider a regression problem with a regularized evidence lower bound (ELBO) which is decomposed into the expected log-likelihood of the data and the Kullback-Leibler (KL) divergence between the a priori distribution and the variational posterior. With an appropriate weighting of the KL, we prove a law of large numbers for three different training schemes: (i) the idealized case with exact estimation of a multiple Gaussian integral from the reparametrization trick, (ii) a minibatch scheme using Monte Carlo sampling, commonly known as Bayes by Backprop, and (iii) a new and computationally cheaper algorithm which we introduce as Minimal VI. An important result is that all methods converge to the same mean-field limit. Finally, we illustrate our results numerically and discuss the need for the derivation of a central limit theorem.",
        "bibtex": "@InProceedings{pmlr-v195-descours23a,\n  title = \t {Law of Large Numbers for Bayesian two-layer Neural Network trained with Variational Inference},\n  author =       {Descours, Arnaud and Huix, Tom and Guillin, Arnaud and Michel, Manon and Moulines, {\\'E}ric and Nectoux, Boris},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4657--4695},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/descours23a/descours23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/descours23a.html},\n  abstract = \t {We provide a rigorous analysis of training by variational inference (VI) of Bayesian neural networks in the two-layer and infinite-width case. We consider a regression problem with a regularized evidence lower bound (ELBO) which is decomposed into the expected log-likelihood of the data and the Kullback-Leibler (KL) divergence between the a priori distribution and the variational posterior. With an appropriate weighting of the KL, we prove a law of large numbers for three different training schemes: (i) the idealized case with exact estimation of a multiple Gaussian integral from the reparametrization trick, (ii) a minibatch scheme using Monte Carlo sampling, commonly known as Bayes by Backprop, and (iii) a new and computationally cheaper algorithm which we introduce as Minimal VI. An important result is that all methods converge to the same mean-field limit. Finally, we illustrate our results numerically and discuss the need for the derivation of a central limit theorem.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/descours23a/descours23a.pdf",
        "supp": "",
        "pdf_size": 552526,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9353449575201686044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Laboratoire de Mathematiques Blaise Pascal UMR 6620, CNRS, Universite Clermont-Auvergne, Aubiere, France; Centre de Mathematiques Appliquees, UMR 7641, Ecole polytechnique, France; Laboratoire de Mathematiques Blaise Pascal UMR 6620, CNRS, Universite Clermont-Auvergne, Aubiere, France; Laboratoire de Mathematiques Blaise Pascal UMR 6620, CNRS, Universite Clermont-Auvergne, Aubiere, France; Centre de Mathematiques Appliquees, UMR 7641, Ecole polytechnique, France; Laboratoire de Mathematiques Blaise Pascal UMR 6620, CNRS, Universite Clermont-Auvergne, Aubiere, France",
        "aff_domain": "uca.fr;polytechnique.edu;uca.fr;uca.fr;polytechnique.edu;uca.fr",
        "email": "uca.fr;polytechnique.edu;uca.fr;uca.fr;polytechnique.edu;uca.fr",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Universite Clermont-Auvergne;Ecole Polytechnique",
        "aff_unique_dep": "Laboratoire de Mathematiques Blaise Pascal UMR 6620;Centre de Mathematiques Appliquees",
        "aff_unique_url": "https://www.uca.fr;https://www.polytechnique.edu",
        "aff_unique_abbr": ";Ecole polytechnique",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Aubiere;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "e06a70d968",
        "title": "Learning Hidden Markov Models Using Conditional Samples",
        "site": "https://proceedings.mlr.press/v195/mahajan23a.html",
        "author": "Gaurav Mahajan; Sham Kakade; Akshay Krishnamurthy; Cyril Zhang",
        "abstract": "This paper is concerned with the computational and statistical  complexity of learning the Hidden Markov model (HMM).  Although HMMs  are some of the most widely used tools in sequential and time series  modeling, they are cryptographically hard to learn in the standard  setting where one has access to i.i.d. samples of observation  sequences. In this paper, we depart from this setup and consider an  \\emph{interactive access model}, in which the algorithm can query  for samples from the \\emph{conditional distributions} of the  HMMs. We show that interactive access to the HMM enables  computationally efficient learning algorithms, thereby bypassing  cryptographic hardness.Specifically, we obtain efficient algorithms for learning HMMs in two settings: \\begin{enumerate} \\item An easier setting where we have query access to the exact conditional probabilities. Here our algorithm runs in polynomial time and makes polynomially many queries to approximate any HMM in total variation distance. \\item A harder setting where we can only obtain samples from the  conditional distributions. Here the performance of the algorithm depends on a new parameter, called the fidelity of the HMM. We show that this captures cryptographically hard instances and all previously known positive results. \\end{enumerate}  We also show that these results extend to a broader class of  distributions with latent low rank structure. Our algorithms can be viewed as generalizations and robustifications of Angluin\u2019s $L^*$ algorithm for learning deterministic finite automata from membership queries.",
        "bibtex": "@InProceedings{pmlr-v195-mahajan23a,\n  title = \t {Learning Hidden Markov Models Using Conditional Samples},\n  author =       {Mahajan, Gaurav and Kakade, Sham and Krishnamurthy, Akshay and Zhang, Cyril},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2014--2066},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mahajan23a/mahajan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mahajan23a.html},\n  abstract = \t {This paper is concerned with the computational and statistical  complexity of learning the Hidden Markov model (HMM).  Although HMMs  are some of the most widely used tools in sequential and time series  modeling, they are cryptographically hard to learn in the standard  setting where one has access to i.i.d. samples of observation  sequences. In this paper, we depart from this setup and consider an  \\emph{interactive access model}, in which the algorithm can query  for samples from the \\emph{conditional distributions} of the  HMMs. We show that interactive access to the HMM enables  computationally efficient learning algorithms, thereby bypassing  cryptographic hardness.Specifically, we obtain efficient algorithms for learning HMMs in two settings: \\begin{enumerate} \\item An easier setting where we have query access to the exact conditional probabilities. Here our algorithm runs in polynomial time and makes polynomially many queries to approximate any HMM in total variation distance. \\item A harder setting where we can only obtain samples from the  conditional distributions. Here the performance of the algorithm depends on a new parameter, called the fidelity of the HMM. We show that this captures cryptographically hard instances and all previously known positive results. \\end{enumerate}  We also show that these results extend to a broader class of  distributions with latent low rank structure. Our algorithms can be viewed as generalizations and robustifications of Angluin\u2019s $L^*$ algorithm for learning deterministic finite automata from membership queries.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mahajan23a/mahajan23a.pdf",
        "supp": "",
        "pdf_size": 577898,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9760246046198033259&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "aff": "Harvard University; Microsoft Research NYC; Yale University; Microsoft Research NYC",
        "aff_domain": "SEAS.HARVARD.EDU;CS.UMASS.EDU;YALE.EDU;MICROSOFT.COM",
        "email": "SEAS.HARVARD.EDU;CS.UMASS.EDU;YALE.EDU;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Harvard University;Microsoft;Yale University",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://www.harvard.edu;https://www.microsoft.com/en-us/research/group/microsoft-research-new-york-city;https://www.yale.edu",
        "aff_unique_abbr": "Harvard;MSR NYC;Yale",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";New York City",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "55797f6966",
        "title": "Learning Narrow One-Hidden-Layer ReLU Networks",
        "site": "https://proceedings.mlr.press/v195/chen23a.html",
        "author": "Sitan Chen; Zehao Dou; Surbhi Goel; Adam Klivans; Raghu Meka",
        "abstract": "We consider the well-studied problem of learning a linear combination of $k$ ReLU activations with respect to a Gaussian distribution on inputs in $d$ dimensions.  We give the first polynomial-time algorithm that succeeds whenever $k$ is a constant.  All prior polynomial-time learners require additional assumptions on the network, such as positive combining coefficients or the matrix of hidden weight vectors being well-conditioned.Our approach is based on analyzing random contractions of higher-order moment tensors.  We use a multi-scale clustering procedure to argue that sufficiently close neurons can be collapsed together, sidestepping the conditioning issues present in prior work. This allows us to design an iterative procedure to discover individual neurons.",
        "bibtex": "@InProceedings{pmlr-v195-chen23a,\n  title = \t {Learning Narrow One-Hidden-Layer ReLU Networks},\n  author =       {Chen, Sitan and Dou, Zehao and Goel, Surbhi and Klivans, Adam and Meka, Raghu},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5580--5614},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/chen23a/chen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/chen23a.html},\n  abstract = \t {We consider the well-studied problem of learning a linear combination of $k$ ReLU activations with respect to a Gaussian distribution on inputs in $d$ dimensions.  We give the first polynomial-time algorithm that succeeds whenever $k$ is a constant.  All prior polynomial-time learners require additional assumptions on the network, such as positive combining coefficients or the matrix of hidden weight vectors being well-conditioned.Our approach is based on analyzing random contractions of higher-order moment tensors.  We use a multi-scale clustering procedure to argue that sufficiently close neurons can be collapsed together, sidestepping the conditioning issues present in prior work. This allows us to design an iterative procedure to discover individual neurons.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/chen23a/chen23a.pdf",
        "supp": "",
        "pdf_size": 537657,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3953735259929210974&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Berkeley; Yale; University of Pennsylvania; University of Texas at Austin; University of California, Los Angeles",
        "aff_domain": "BERKELEY.EDU;YALE.EDU;CIS.UPENN.EDU;CS.UTEXAS.EDU;CS.UCLA.EDU",
        "email": "BERKELEY.EDU;YALE.EDU;CIS.UPENN.EDU;CS.UTEXAS.EDU;CS.UCLA.EDU",
        "github": "",
        "project": "arXiv:2304.10524",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of California, Berkeley;Yale University;University of Pennsylvania;University of Texas at Austin;University of California, Los Angeles",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.yale.edu;https://www.upenn.edu;https://www.utexas.edu;https://www.ucla.edu",
        "aff_unique_abbr": "UC Berkeley;Yale;UPenn;UT Austin;UCLA",
        "aff_campus_unique_index": "0;2;3",
        "aff_campus_unique": "Berkeley;;Austin;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7ac67dbaf8",
        "title": "Learning and Testing Latent-Tree Ising Models Efficiently",
        "site": "https://proceedings.mlr.press/v195/kandiros23a.html",
        "author": "Vardis Kandiros; Constantinos Daskalakis; Yuval Dagan; Davin Choo",
        "abstract": "We provide time- and sample-efficient algorithms for learning and testing latent-tree Ising models, i.e.\u00a0Ising models that may only be observed at their leaf nodes. On the learning side, we obtain efficient algorithms for learning a tree-structured Ising model whose leaf node distribution is close in Total Variation Distance, improving on the results of \\cite{cryan2001evolutionary}. On the testing side, we provide an efficient algorithm with fewer samples for testing whether two latent-tree Ising models have leaf-node distributions that are close or far in Total Variation distance. We obtain our algorithms by showing novel localization results for the total variation distance between the leaf-node distributions of tree-structured Ising models, in terms of their marginals on pairs of leaves.",
        "bibtex": "@InProceedings{pmlr-v195-kandiros23a,\n  title = \t {Learning and Testing Latent-Tree Ising Models Efficiently},\n  author =       {Kandiros, Vardis and Daskalakis, Constantinos and Dagan, Yuval and Choo, Davin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1666--1729},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kandiros23a/kandiros23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kandiros23a.html},\n  abstract = \t {We provide time- and sample-efficient algorithms for learning and testing latent-tree Ising models, i.e.\u00a0Ising models that may only be observed at their leaf nodes. On the learning side, we obtain efficient algorithms for learning a tree-structured Ising model whose leaf node distribution is close in Total Variation Distance, improving on the results of \\cite{cryan2001evolutionary}. On the testing side, we provide an efficient algorithm with fewer samples for testing whether two latent-tree Ising models have leaf-node distributions that are close or far in Total Variation distance. We obtain our algorithms by showing novel localization results for the total variation distance between the leaf-node distributions of tree-structured Ising models, in terms of their marginals on pairs of leaves.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/kandiros23a/kandiros23a.pdf",
        "supp": "",
        "pdf_size": 680347,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4302926121268032869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Department of Electrical Engineering and Computer Science, MIT; Department of Electrical Engineering and Computer Science, MIT; Department of Electrical Engineering and Computer Science, MIT; School of Computing, National University of Singapore",
        "aff_domain": "csail.mit.edu;csail.mit.edu;mit.edu;u.nus.edu",
        "email": "csail.mit.edu;csail.mit.edu;mit.edu;u.nus.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;National University of Singapore",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;School of Computing",
        "aff_unique_url": "https://web.mit.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "MIT;NUS",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Cambridge;Singapore",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "224e25cd82",
        "title": "Limits of Model Selection under Transfer Learning",
        "site": "https://proceedings.mlr.press/v195/hanneke23c.html",
        "author": "Steve Hanneke; Samory Kpotufe; Yasaman Mahdaviyeh",
        "abstract": "Theoretical studies on \\emph{transfer learning} (or \\emph{domain adaptation}) have so far focused on situations with a known hypothesis class or \\emph{model}; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term or \\emph{hyperparameter-tuning}: for example, one may think of the problem of \\emph{tuning} for the right neural network architecture towards a target task, while leveraging data from a related \\emph{source} task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the \\emph{transfer distance} between source and target distributions, which is known to vary with the choice of hypothesis class. We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: \\emph{adaptive rates}, i.e., those achievable with no distributional information, can be arbitrarily slower than \\emph{oracle rates}, i.e., when given knowledge on \\emph{distances}",
        "bibtex": "@InProceedings{pmlr-v195-hanneke23c,\n  title = \t {Limits of Model Selection under Transfer Learning},\n  author =       {Hanneke, Steve and Kpotufe, Samory and Mahdaviyeh, Yasaman},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5781--5812},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hanneke23c/hanneke23c.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hanneke23c.html},\n  abstract = \t {Theoretical studies on \\emph{transfer learning} (or \\emph{domain adaptation}) have so far focused on situations with a known hypothesis class or \\emph{model}; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term or \\emph{hyperparameter-tuning}: for example, one may think of the problem of \\emph{tuning} for the right neural network architecture towards a target task, while leveraging data from a related \\emph{source} task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the \\emph{transfer distance} between source and target distributions, which is known to vary with the choice of hypothesis class. We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: \\emph{adaptive rates}, i.e., those achievable with no distributional information, can be arbitrarily slower than \\emph{oracle rates}, i.e., when given knowledge on \\emph{distances}}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hanneke23c/hanneke23c.pdf",
        "supp": "",
        "pdf_size": 444469,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4534615882027958818&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Purdue University; Columbia University; Columbia University",
        "aff_domain": "GMAIL.COM;COLUMBIA.EDU;COLUMBIA.EDU",
        "email": "GMAIL.COM;COLUMBIA.EDU;COLUMBIA.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Purdue University;Columbia University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.purdue.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Purdue;Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c228b40258",
        "title": "Linearization Algorithms for Fully Composite Optimization",
        "site": "https://proceedings.mlr.press/v195/vladarean23a.html",
        "author": "Maria-Luiza Vladarean; Nikita Doikov; Martin Jaggi; Nicolas Flammarion",
        "abstract": "This paper studies first-order algorithms for solving fully composite optimization problems over convex and compact sets. We leverage the structure of the objective by handling its differentiable and non-differentiable components separately, linearizing only the smooth parts. This provides us with new generalizations of the classical Frank-Wolfe method and the Conditional Gradient Sliding algorithm, that cater to a subclass of non-differentiable problems. Our algorithms rely on a stronger version of the linear minimization oracle, which can be efficiently implemented in several practical applications. We provide the basic version of our method with an affine-invariant analysis and prove global convergence rates for both convex and non-convex objectives. Furthermore, in the convex case, we propose an accelerated method with correspondingly improved complexity. Finally, we provide illustrative experiments to support our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v195-vladarean23a,\n  title = \t {Linearization Algorithms for Fully Composite Optimization},\n  author =       {Vladarean, Maria-Luiza and Doikov, Nikita and Jaggi, Martin and Flammarion, Nicolas},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3669--3695},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/vladarean23a/vladarean23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/vladarean23a.html},\n  abstract = \t {This paper studies first-order algorithms for solving fully composite optimization problems over convex and compact sets. We leverage the structure of the objective by handling its differentiable and non-differentiable components separately, linearizing only the smooth parts. This provides us with new generalizations of the classical Frank-Wolfe method and the Conditional Gradient Sliding algorithm, that cater to a subclass of non-differentiable problems. Our algorithms rely on a stronger version of the linear minimization oracle, which can be efficiently implemented in several practical applications. We provide the basic version of our method with an affine-invariant analysis and prove global convergence rates for both convex and non-convex objectives. Furthermore, in the convex case, we propose an accelerated method with correspondingly improved complexity. Finally, we provide illustrative experiments to support our theoretical results.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/vladarean23a/vladarean23a.pdf",
        "supp": "",
        "pdf_size": 616634,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3443479384063204050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "\u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne",
        "aff_domain": "EPFL.CH;EPFL.CH;EPFL.CH;EPFL.CH",
        "email": "EPFL.CH;EPFL.CH;EPFL.CH;EPFL.CH",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "e4131aaf2f",
        "title": "List Online Classification",
        "site": "https://proceedings.mlr.press/v195/moran23a.html",
        "author": "Shay Moran; Ohad Sharon; Iska Tsubari; Sivan Yosebashvili",
        "abstract": "We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible.As part of our work, we adapt classical algorithms such as Littlestone\u2019s SOA and Rosenblatt\u2019s Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable classes, including an online version of the Sauer-Shelah-Perles Lemma. We state our results within the framework of pattern classes \u2014 a generalization of hypothesis classes which can represent adaptive hypotheses (i.e. functions with memory), and model data-dependent assumptions such as linear classification with margin.",
        "bibtex": "@InProceedings{pmlr-v195-moran23a,\n  title = \t {List Online Classification},\n  author =       {Moran, Shay and Sharon, Ohad and Tsubari, Iska and Yosebashvili, Sivan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1885--1913},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/moran23a/moran23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/moran23a.html},\n  abstract = \t {We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible.As part of our work, we adapt classical algorithms such as Littlestone\u2019s SOA and Rosenblatt\u2019s Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable classes, including an online version of the Sauer-Shelah-Perles Lemma. We state our results within the framework of pattern classes \u2014 a generalization of hypothesis classes which can represent adaptive hypotheses (i.e. functions with memory), and model data-dependent assumptions such as linear classification with margin.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/moran23a/moran23a.pdf",
        "supp": "",
        "pdf_size": 3778972,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15583127165276367931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Departments of Mathematics and Computer Science, Technion\u2013IIT and Google Research; Department of Mathematics, Technion\u2013IIT; Department of Mathematics, Technion\u2013IIT; Mobileye",
        "aff_domain": "TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL",
        "email": "TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Technion\u2013IIT;Mobileye",
        "aff_unique_dep": "Departments of Mathematics and Computer Science;",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.mobileye.com",
        "aff_unique_abbr": "Technion;Mobileye",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "62b438574a",
        "title": "Local Glivenko-Cantelli",
        "site": "https://proceedings.mlr.press/v195/cohen23a.html",
        "author": "Doron Cohen; Aryeh Kontorovich",
        "abstract": "If $\\mu$ is a distribution over the $d$-dimensional Boolean cube $\\set{0,1}^d$, our goal is to estimate its mean $p\\in[0,1]^d$ based on $n$ iid draws from $\\mu$. Specifically, we consider the empirical mean estimator $\\pn$ and study the expected maximal deviation $\\Delta_n=\\E\\max_{j\\in[d]}|\\pn(j)-p(j)|$. In the classical Universal Glivenko-Cantelli setting, one seeks distribution-free (i.e., independent of $\\mu$) bounds on $\\Delta_n$. This regime is well-understood: for all $\\mu$, we have $\\Delta_n\\lesssim\\sqrt{\\log(d)/n}$ up to universal constants, and the bound is tight.Our present work seeks to establish dimension-free (i.e., without an explicit dependence on $d$) estimates on $\\Delta_n$, including those that hold for $d=\\infty$. As such bounds must necessarily depend on $\\mu$, we refer to this regime as {\\em local} Glivenko-Cantelli (also known as $\\mu$-GC), and are aware of very few previous bounds of this type \u2014 which are either \u201cabstract\u201d or quite sub-optimal. Already the special case of product measures $\\mu$ is rather non-trivial. We give necessary and sufficient conditions on $\\mu$ for $\\Delta_n\\to0$, and calculate sharp rates for this decay. Along the way, we discover a novel sub-gamma-type maximal inequality for shifted Bernoullis, of independent interest.",
        "bibtex": "@InProceedings{pmlr-v195-cohen23a,\n  title = \t {Local Glivenko-Cantelli},\n  author =       {Cohen, Doron and Kontorovich, Aryeh},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {715--715},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/cohen23a/cohen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/cohen23a.html},\n  abstract = \t {If $\\mu$ is a distribution over the $d$-dimensional Boolean cube $\\set{0,1}^d$, our goal is to estimate its mean $p\\in[0,1]^d$ based on $n$ iid draws from $\\mu$. Specifically, we consider the empirical mean estimator $\\pn$ and study the expected maximal deviation $\\Delta_n=\\E\\max_{j\\in[d]}|\\pn(j)-p(j)|$. In the classical Universal Glivenko-Cantelli setting, one seeks distribution-free (i.e., independent of $\\mu$) bounds on $\\Delta_n$. This regime is well-understood: for all $\\mu$, we have $\\Delta_n\\lesssim\\sqrt{\\log(d)/n}$ up to universal constants, and the bound is tight.Our present work seeks to establish dimension-free (i.e., without an explicit dependence on $d$) estimates on $\\Delta_n$, including those that hold for $d=\\infty$. As such bounds must necessarily depend on $\\mu$, we refer to this regime as {\\em local} Glivenko-Cantelli (also known as $\\mu$-GC), and are aware of very few previous bounds of this type \u2014 which are either \u201cabstract\u201d or quite sub-optimal. Already the special case of product measures $\\mu$ is rather non-trivial. We give necessary and sufficient conditions on $\\mu$ for $\\Delta_n\\to0$, and calculate sharp rates for this decay. Along the way, we discover a novel sub-gamma-type maximal inequality for shifted Bernoullis, of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/cohen23a/cohen23a.pdf",
        "supp": "",
        "pdf_size": 131341,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12430271140191125810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev; Department of Computer Science, Ben-Gurion University of the Negev",
        "aff_domain": "post.bgu.ac.il;cs.bgu.ac.il",
        "email": "post.bgu.ac.il;cs.bgu.ac.il",
        "github": "",
        "project": "arxiv.org/abs/2209.04054v4",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "0790cdd87b",
        "title": "Local Risk Bounds for Statistical Aggregation",
        "site": "https://proceedings.mlr.press/v195/mourtada23a.html",
        "author": "Jaouad Mourtada; Tomas Va\u0161kevi\u010dius; Nikita Zhivotovskiy",
        "abstract": "In the problem of aggregation, the aim is to combine a given class of base predictors to achieve predictions nearly as accurate as the best one. In this flexible framework, no assumption is made on the structure of the class or the nature of the target. Aggregation has been studied in both sequential and statistical contexts. Despite some important differences between the two problems, the classical results in both cases feature the same global complexity measure. In this paper, we revisit and tighten classical results in the theory of aggregation in the statistical setting by replacing the global complexity with a smaller, local one. Some of our proofs build on the PAC-Bayes localization technique introduced by Catoni. Among other results, we prove localized versions of the classical bound for the exponential weights estimator due to Leung and Barron and deviation-optimal bounds for the Q-aggregation estimator. These bounds improve over the results of Dai, Rigollet and Zhang for fixed design regression and the results of Lecu\u00e9 and Rigollet for random design regression.",
        "bibtex": "@InProceedings{pmlr-v195-mourtada23a,\n  title = \t {Local Risk Bounds for Statistical Aggregation},\n  author =       {Mourtada, Jaouad and Va{\\v{s}}kevi{\\v{c}}ius, Tomas and Zhivotovskiy, Nikita},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5697--5698},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mourtada23a/mourtada23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mourtada23a.html},\n  abstract = \t {In the problem of aggregation, the aim is to combine a given class of base predictors to achieve predictions nearly as accurate as the best one. In this flexible framework, no assumption is made on the structure of the class or the nature of the target. Aggregation has been studied in both sequential and statistical contexts. Despite some important differences between the two problems, the classical results in both cases feature the same global complexity measure. In this paper, we revisit and tighten classical results in the theory of aggregation in the statistical setting by replacing the global complexity with a smaller, local one. Some of our proofs build on the PAC-Bayes localization technique introduced by Catoni. Among other results, we prove localized versions of the classical bound for the exponential weights estimator due to Leung and Barron and deviation-optimal bounds for the Q-aggregation estimator. These bounds improve over the results of Dai, Rigollet and Zhang for fixed design regression and the results of Lecu\u00e9 and Rigollet for random design regression.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mourtada23a/mourtada23a.pdf",
        "supp": "",
        "pdf_size": 169613,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5232326659653340206&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "CREST, ENSAE, Institut Polytechnique de Paris, France; Institute of Mathematics, EPFL, Switzerland; Department of Statistics, UC Berkeley, USA",
        "aff_domain": "ensae.fr;epfl.ch;berkeley.edu",
        "email": "ensae.fr;epfl.ch;berkeley.edu",
        "github": "",
        "project": "arXiv:2306.17151",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Institut Polytechnique de Paris;EPFL;University of California, Berkeley",
        "aff_unique_dep": "CREST;Institute of Mathematics;Department of Statistics",
        "aff_unique_url": "https://www.ipparis.fr;https://www.epfl.ch;https://www.berkeley.edu",
        "aff_unique_abbr": "IP Paris;EPFL;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "France;Switzerland;United States"
    },
    {
        "id": "bc85668e22",
        "title": "Lower Bounds for the Convergence of Tensor Power Iteration on Random Overcomplete Models",
        "site": "https://proceedings.mlr.press/v195/wu23b.html",
        "author": "Yuchen Wu; Kangjie Zhou",
        "abstract": "Tensor decomposition serves as a powerful primitive in statistics and machine learning, and has numerous applications in problems such as learning latent variable models or mixture of Gaussians. In this paper, we focus on using power iteration to decompose an overcomplete random tensor. Past work studying the properties of tensor power iteration either requires a non-trivial data-independent initialization, or is restricted to the undercomplete regime. Moreover, several papers implicitly suggest that logarithmically many iterations (in terms of the input dimension) are suf\ufb01cient for the power method to recover one of the tensor components.Here we present a novel analysis of the dynamics of tensor power iteration from random initialization in the overcomplete regime, where the tensor rank is much greater than its dimension. Surprisingly, we show that polynomially many steps are necessary for convergence of tensor power iteration to any of the true component, which refutes the previous conjecture. On the other hand, our numerical experiments suggest that tensor power iteration successfully recovers tensor components for a broad range of parameters in polynomial time. To further complement our empirical evidence, we prove that a popular objective function for tensor decomposition is strictly increasing along the power iteration path.Our proof is based on the Gaussian conditioning technique, which has been applied to analyze the approximate message passing (AMP) algorithm. The major ingredient of our argument is a conditioning lemma that allows us to generalize AMP-type analysis to non-proportional limit and polynomially many iterations of the power method.",
        "bibtex": "@InProceedings{pmlr-v195-wu23b,\n  title = \t {Lower Bounds for the Convergence of Tensor Power Iteration on Random Overcomplete Models},\n  author =       {Wu, Yuchen and Zhou, Kangjie},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3783--3820},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wu23b/wu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wu23b.html},\n  abstract = \t {Tensor decomposition serves as a powerful primitive in statistics and machine learning, and has numerous applications in problems such as learning latent variable models or mixture of Gaussians. In this paper, we focus on using power iteration to decompose an overcomplete random tensor. Past work studying the properties of tensor power iteration either requires a non-trivial data-independent initialization, or is restricted to the undercomplete regime. Moreover, several papers implicitly suggest that logarithmically many iterations (in terms of the input dimension) are suf\ufb01cient for the power method to recover one of the tensor components.Here we present a novel analysis of the dynamics of tensor power iteration from random initialization in the overcomplete regime, where the tensor rank is much greater than its dimension. Surprisingly, we show that polynomially many steps are necessary for convergence of tensor power iteration to any of the true component, which refutes the previous conjecture. On the other hand, our numerical experiments suggest that tensor power iteration successfully recovers tensor components for a broad range of parameters in polynomial time. To further complement our empirical evidence, we prove that a popular objective function for tensor decomposition is strictly increasing along the power iteration path.Our proof is based on the Gaussian conditioning technique, which has been applied to analyze the approximate message passing (AMP) algorithm. The major ingredient of our argument is a conditioning lemma that allows us to generalize AMP-type analysis to non-proportional limit and polynomially many iterations of the power method.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wu23b/wu23b.pdf",
        "supp": "",
        "pdf_size": 470537,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7276511519817414951&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "STANFORD.EDU;STANFORD.EDU",
        "email": "STANFORD.EDU;STANFORD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6e5e1a846f",
        "title": "Minimax Instrumental Variable Regression and $L_2$ Convergence Guarantees without Identification or Closedness",
        "site": "https://proceedings.mlr.press/v195/bennett23b.html",
        "author": "Andrew Bennett; Nathan Kallus; Xiaojie Mao; Whitney Newey; Vasilis Syrgkanis; Masatoshi Uehara",
        "abstract": "In this paper, we study nonparametric estimation of instrumental variable (IV) regressions. Recently, many flexible machine learning methods have been developed for instrumental variable estimation. However, these methods have at least one of the following limitations: (1) restricting the IV regression  to be uniquely identified; (2) only obtaining estimation error rates in terms weak metrics (e.g., projected norm) rather than strong metrics (e.g., L_2 norm); or (3) imposing the so-called closedness condition that requires a certain conditional expectation operator to be sufficiently smooth. In this paper, we present the first method and analysis that can avoid all three limitations, while still permitting general function approximation. Specifically, we propose a new penalized minimax estimator that can converge to a fixed IV  solution even when there are multiple solutions, and we derive a strong L_2 error rate for our estimator under lax conditions. Notably, this guarantee only needs a widely-used source condition and realizability assumptions, but not the so-called closedness condition. We argue that the source condition and the closedness condition are inherently conflicting, so relaxing the latter significantly improves upon the existing literature that requires both conditions. Our estimator can achieve this improvement because it builds on a novel formulation of the IV estimation problem as a constrained optimization problem.",
        "bibtex": "@InProceedings{pmlr-v195-bennett23b,\n  title = \t {Minimax Instrumental Variable Regression and $L_2$ Convergence Guarantees without Identification or Closedness},\n  author =       {Bennett, Andrew and Kallus, Nathan and Mao, Xiaojie and Newey, Whitney and Syrgkanis, Vasilis and Uehara, Masatoshi},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2291--2318},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bennett23b/bennett23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bennett23b.html},\n  abstract = \t {In this paper, we study nonparametric estimation of instrumental variable (IV) regressions. Recently, many flexible machine learning methods have been developed for instrumental variable estimation. However, these methods have at least one of the following limitations: (1) restricting the IV regression  to be uniquely identified; (2) only obtaining estimation error rates in terms weak metrics (e.g., projected norm) rather than strong metrics (e.g., L_2 norm); or (3) imposing the so-called closedness condition that requires a certain conditional expectation operator to be sufficiently smooth. In this paper, we present the first method and analysis that can avoid all three limitations, while still permitting general function approximation. Specifically, we propose a new penalized minimax estimator that can converge to a fixed IV  solution even when there are multiple solutions, and we derive a strong L_2 error rate for our estimator under lax conditions. Notably, this guarantee only needs a widely-used source condition and realizability assumptions, but not the so-called closedness condition. We argue that the source condition and the closedness condition are inherently conflicting, so relaxing the latter significantly improves upon the existing literature that requires both conditions. Our estimator can achieve this improvement because it builds on a novel formulation of the IV estimation problem as a constrained optimization problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/bennett23b/bennett23b.pdf",
        "supp": "",
        "pdf_size": 391032,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9371154557759505532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Cornell University; Cornell University; Tsinghua University; Massachusetts Institute of Technology; Stanford University; Cornell University",
        "aff_domain": "CORNELL.EDU;CORNELL.EDU;SEM.TSINGHUA.EDU.CN;MIT.EDU;STANFORD.EDU;CORNELL.EDU",
        "email": "CORNELL.EDU;CORNELL.EDU;SEM.TSINGHUA.EDU.CN;MIT.EDU;STANFORD.EDU;CORNELL.EDU",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "Cornell University;Tsinghua University;Massachusetts Institute of Technology;Stanford University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.cornell.edu;https://www.tsinghua.edu.cn;https://web.mit.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Cornell;THU;MIT;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "856edea9fb",
        "title": "Minimax optimal testing by classification",
        "site": "https://proceedings.mlr.press/v195/gerber23a.html",
        "author": "Patrik R. Gerber; Yanjun Han; Yury Polyanskiy",
        "abstract": "This paper considers an ML inspired approach to hypothesis testing known as classifier/classification-accuracy testing (CAT). In CAT, one first trains a classifier by feeding it labeled synthetic samples generated by the null and alternative distributions, which is then used to predict labels of the actual data samples. This method is widely used in practice when the null and alternative are only specified via simulators (as in many scientific experiments). We study goodness-of-fit, two-sample (TS) and likelihood-free hypothesis testing (LFHT), and show that CAT achieves (near-)minimax optimal sample complexity in both the dependence on the total-variation (TV) separation \u03b5 and the probability of error \u03b4 in a variety of non-parametric settings, including discrete distributions, d-dimensional distributions with a smooth density, and the Gaussian sequence model. In particular, we close the high probability sample complexity of LFHT for each class. As another highlight, we recover the minimax optimal complexity of TS over discrete distributions, which was recently established by Diakonikolas et al. (2021). The corresponding CAT simply compares empirical frequencies in the first half of the data, and rejects the null when the classification accuracy on the second half is better than random.",
        "bibtex": "@InProceedings{pmlr-v195-gerber23a,\n  title = \t {Minimax optimal testing by classification},\n  author =       {Gerber, Patrik R. and Han, Yanjun and Polyanskiy, Yury},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5395--5432},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gerber23a/gerber23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gerber23a.html},\n  abstract = \t {This paper considers an ML inspired approach to hypothesis testing known as classifier/classification-accuracy testing (CAT). In CAT, one first trains a classifier by feeding it labeled synthetic samples generated by the null and alternative distributions, which is then used to predict labels of the actual data samples. This method is widely used in practice when the null and alternative are only specified via simulators (as in many scientific experiments). We study goodness-of-fit, two-sample (TS) and likelihood-free hypothesis testing (LFHT), and show that CAT achieves (near-)minimax optimal sample complexity in both the dependence on the total-variation (TV) separation \u03b5 and the probability of error \u03b4 in a variety of non-parametric settings, including discrete distributions, d-dimensional distributions with a smooth density, and the Gaussian sequence model. In particular, we close the high probability sample complexity of LFHT for each class. As another highlight, we recover the minimax optimal complexity of TS over discrete distributions, which was recently established by Diakonikolas et al. (2021). The corresponding CAT simply compares empirical frequencies in the first half of the data, and rejects the null when the classification accuracy on the second half is better than random. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/gerber23a/gerber23a.pdf",
        "supp": "",
        "pdf_size": 518113,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=934424818692316455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "MIT.EDU;MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "90ec0c7dc6",
        "title": "Minimizing Dynamic Regret on Geodesic Metric Spaces",
        "site": "https://proceedings.mlr.press/v195/hu23a.html",
        "author": "Zihao Hu; Guanghui Wang; Jacob D. Abernethy",
        "abstract": "In this paper, we consider the sequential decision problem where the goal is to minimize the general dynamic regret on a complete Riemannian manifold. The task of offline optimization on such a domain, also known as a geodesic metric space, has recently received significant attention. The online setting has received significantly less attention, and it has remained an open question whether the body of results that hold in the Euclidean setting can be transplanted into the land of Riemannian manifolds where new challenges (e.g., curvature) come into play. In this paper, we show how to get optimistic regret bound on manifolds with non-positive curvature whenever improper learning is allowed and propose an array of adaptive no-regret algorithms. To the best of our knowledge, this is the first work that considers general dynamic regret and develops \u201coptimistic\u201d online learning algorithms which can be employed on geodesic metric spaces.",
        "bibtex": "@InProceedings{pmlr-v195-hu23a,\n  title = \t {Minimizing Dynamic Regret on Geodesic Metric Spaces},\n  author =       {Hu, Zihao and Wang, Guanghui and Abernethy, Jacob D.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4336--4383},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hu23a/hu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hu23a.html},\n  abstract = \t {In this paper, we consider the sequential decision problem where the goal is to minimize the general dynamic regret on a complete Riemannian manifold. The task of offline optimization on such a domain, also known as a geodesic metric space, has recently received significant attention. The online setting has received significantly less attention, and it has remained an open question whether the body of results that hold in the Euclidean setting can be transplanted into the land of Riemannian manifolds where new challenges (e.g., curvature) come into play. In this paper, we show how to get optimistic regret bound on manifolds with non-positive curvature whenever improper learning is allowed and propose an array of adaptive no-regret algorithms. To the best of our knowledge, this is the first work that considers general dynamic regret and develops \u201coptimistic\u201d online learning algorithms which can be employed on geodesic metric spaces.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hu23a/hu23a.pdf",
        "supp": "",
        "pdf_size": 516425,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13590297084617283709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology+Google Research",
        "aff_domain": "GATECH.EDU;GATECH.EDU;GOOGLE.COM",
        "email": "GATECH.EDU;GATECH.EDU;GOOGLE.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Georgia Institute of Technology;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.gatech.edu;https://research.google",
        "aff_unique_abbr": "Georgia Tech;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "eb04b810a4",
        "title": "Moments, Random Walks, and Limits for Spectrum Approximation",
        "site": "https://proceedings.mlr.press/v195/jin23a.html",
        "author": "Yujia Jin; Christopher Musco; Aaron Sidford; Apoorv Vikram Singh",
        "abstract": "We study lower bounds for the problem of approximating a one dimensional distribution given (noisy) measurements of its moments. We show that there are distributions on $[-1,1]$ that cannot be approximated to accuracy $\\epsilon$ in Wasserstein-1 distance even if we know \\emph{all} of their moments to multiplicative accuracy $(1\\pm2^{-\\Omega(1/\\epsilon)})$; this result matches an upper bound of Kong and Valiant [Annals of Statistics, 2017].  To obtain our result, we provide a hard instance involving distributions induced by the eigenvalue spectra of carefully constructed graph adjacency matrices. Efficiently approximating such spectra in Wasserstein-1 distance is a well-studied algorithmic problem, and a recent result of Cohen-Steiner et al. [KDD 2018] gives a method based on accurately approximating spectral moments using $2^{O(1/\\epsilon)}$ random walks initiated at uniformly random nodes in the graph.As a strengthening of our main result, we show that improving the dependence on $1/\\epsilon$ in this result would require a new algorithmic approach. Specifically, no algorithm can compute an $\\epsilon$-accurate approximation to the spectrum of a normalized graph adjacency matrix with constant probability, even when given the transcript of $2^{\\Omega(1/\\epsilon)}$ random walks of length $2^{\\Omega(1/\\epsilon)}$ started at random nodes.",
        "bibtex": "@InProceedings{pmlr-v195-jin23a,\n  title = \t {Moments, Random Walks, and Limits for Spectrum Approximation},\n  author =       {Jin, Yujia and Musco, Christopher and Sidford, Aaron and Singh, Apoorv Vikram},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5373--5394},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/jin23a/jin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/jin23a.html},\n  abstract = \t {We study lower bounds for the problem of approximating a one dimensional distribution given (noisy) measurements of its moments. We show that there are distributions on $[-1,1]$ that cannot be approximated to accuracy $\\epsilon$ in Wasserstein-1 distance even if we know \\emph{all} of their moments to multiplicative accuracy $(1\\pm2^{-\\Omega(1/\\epsilon)})$; this result matches an upper bound of Kong and Valiant [Annals of Statistics, 2017].  To obtain our result, we provide a hard instance involving distributions induced by the eigenvalue spectra of carefully constructed graph adjacency matrices. Efficiently approximating such spectra in Wasserstein-1 distance is a well-studied algorithmic problem, and a recent result of Cohen-Steiner et al. [KDD 2018] gives a method based on accurately approximating spectral moments using $2^{O(1/\\epsilon)}$ random walks initiated at uniformly random nodes in the graph.As a strengthening of our main result, we show that improving the dependence on $1/\\epsilon$ in this result would require a new algorithmic approach. Specifically, no algorithm can compute an $\\epsilon$-accurate approximation to the spectrum of a normalized graph adjacency matrix with constant probability, even when given the transcript of $2^{\\Omega(1/\\epsilon)}$ random walks of length $2^{\\Omega(1/\\epsilon)}$ started at random nodes.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/jin23a/jin23a.pdf",
        "supp": "",
        "pdf_size": 492732,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12222270694459821024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Stanford University; New York University; Stanford University; New York University",
        "aff_domain": "STANFORD.EDU;NYU.EDU;STANFORD.EDU;NYU.EDU",
        "email": "STANFORD.EDU;NYU.EDU;STANFORD.EDU;NYU.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Stanford University;New York University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.nyu.edu",
        "aff_unique_abbr": "Stanford;NYU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8827a5073e",
        "title": "Multiclass Online Learning and Uniform Convergence",
        "site": "https://proceedings.mlr.press/v195/hanneke23b.html",
        "author": "Steve Hanneke; Shay Moran; Vinod Raman; Unique Subedi; Ambuj Tewari",
        "abstract": "We study multiclass classification in the agnostic adversarial online learning setting. As our main result, we prove that any multiclass concept class is agnostically learnable if and only if its Littlestone dimension is finite. This solves an open problem studied by Daniely, Sabato, Ben-David, and Shalev-Shwartz (2011,2015) who handled the case when the number of classes (or labels) is bounded. We also prove a separation between online learnability and online uniform convergence by exhibiting an easy-to-learn class whose sequential Rademacher complexity is unbounded.Our learning algorithm uses the multiplicative weights algorithm, with a set of experts defined by executions of the Standard Optimal Algorithm on subsequences of size Littlestone dimension. We argue that the best expert has regret at most Littlestone dimension relative to the best concept in the class.  This differs from the well-known covering technique of Ben-David, Pal, and Shalev-Shwartz (2009) for binary classification, where the best expert has regret zero.",
        "bibtex": "@InProceedings{pmlr-v195-hanneke23b,\n  title = \t {Multiclass Online Learning and Uniform Convergence},\n  author =       {Hanneke, Steve and Moran, Shay and Raman, Vinod and Subedi, Unique and Tewari, Ambuj},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5682--5696},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hanneke23b/hanneke23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hanneke23b.html},\n  abstract = \t {We study multiclass classification in the agnostic adversarial online learning setting. As our main result, we prove that any multiclass concept class is agnostically learnable if and only if its Littlestone dimension is finite. This solves an open problem studied by Daniely, Sabato, Ben-David, and Shalev-Shwartz (2011,2015) who handled the case when the number of classes (or labels) is bounded. We also prove a separation between online learnability and online uniform convergence by exhibiting an easy-to-learn class whose sequential Rademacher complexity is unbounded.Our learning algorithm uses the multiplicative weights algorithm, with a set of experts defined by executions of the Standard Optimal Algorithm on subsequences of size Littlestone dimension. We argue that the best expert has regret at most Littlestone dimension relative to the best concept in the class.  This differs from the well-known covering technique of Ben-David, Pal, and Shalev-Shwartz (2009) for binary classification, where the best expert has regret zero.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hanneke23b/hanneke23b.pdf",
        "supp": "",
        "pdf_size": 344024,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14386357611448385888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Purdue University; Technion+Google Research; University of Michigan; University of Michigan; University of Michigan",
        "aff_domain": "GMAIL.COM;TECHNION.AC.IL;UMICH.EDU;UMICH.EDU;UMICH.EDU",
        "email": "GMAIL.COM;TECHNION.AC.IL;UMICH.EDU;UMICH.EDU;UMICH.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;3;3;3",
        "aff_unique_norm": "Purdue University;Technion - Israel Institute of Technology;Google;University of Michigan",
        "aff_unique_dep": ";;Google Research;",
        "aff_unique_url": "https://www.purdue.edu;https://www.technion.ac.il/en/;https://research.google;https://www.umich.edu",
        "aff_unique_abbr": "Purdue;Technion;Google Research;UM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1+0;0;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "2e82ee622b",
        "title": "Multitask Learning via Shared Features: Algorithms and Hardness",
        "site": "https://proceedings.mlr.press/v195/bairaktari23a.html",
        "author": "Konstantina Bairaktari; Guy Blanc; Li-Yang Tan; Jonathan Ullman; Lydia Zakynthinou",
        "abstract": "We investigate the computational efficiency of multitask learning of Boolean functions over the $d$-dimensional hypercube, that are related by means of a feature representation of size $k\\ll d$ shared across all tasks. We present a polynomial time multitask learning algorithm for the concept class of halfspaces with margin $\\gamma$, which is based on a simultaneous boosting technique and requires only $\\mathrm{poly}(k/\\gamma)$ samples-per-task and $\\mathrm{poly}(k\\log(d)/\\gamma)$ samples in total. In addition, we prove a computational separation, showing that assuming there exists a concept class that cannot be learned in the attribute-efficient model, we can construct another concept class such that can be learned in the attribute-efficient model, but cannot be multitask learned efficiently\u2014multitask learning this concept class either requires super-polynomial time complexity or a much larger total number of samples.",
        "bibtex": "@InProceedings{pmlr-v195-bairaktari23a,\n  title = \t {Multitask Learning via Shared Features: Algorithms and Hardness},\n  author =       {Bairaktari, Konstantina and Blanc, Guy and Tan, Li-Yang and Ullman, Jonathan and Zakynthinou, Lydia},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {747--772},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bairaktari23a/bairaktari23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bairaktari23a.html},\n  abstract = \t {We investigate the computational efficiency of multitask learning of Boolean functions over the $d$-dimensional hypercube, that are related by means of a feature representation of size $k\\ll d$ shared across all tasks. We present a polynomial time multitask learning algorithm for the concept class of halfspaces with margin $\\gamma$, which is based on a simultaneous boosting technique and requires only $\\mathrm{poly}(k/\\gamma)$ samples-per-task and $\\mathrm{poly}(k\\log(d)/\\gamma)$ samples in total. In addition, we prove a computational separation, showing that assuming there exists a concept class that cannot be learned in the attribute-efficient model, we can construct another concept class such that can be learned in the attribute-efficient model, but cannot be multitask learned efficiently\u2014multitask learning this concept class either requires super-polynomial time complexity or a much larger total number of samples.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/bairaktari23a/bairaktari23a.pdf",
        "supp": "",
        "pdf_size": 410594,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17152273875714524621&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Khoury College of Computer Sciences, Northeastern University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Khoury College of Computer Sciences, Northeastern University; Khoury College of Computer Sciences, Northeastern University",
        "aff_domain": "NORTHEASTERN.EDU;STANFORD.EDU;STANFORD.EDU;CCS.NEU.EDU;NORTHEASTERN.EDU",
        "email": "NORTHEASTERN.EDU;STANFORD.EDU;STANFORD.EDU;CCS.NEU.EDU;NORTHEASTERN.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Northeastern University;Stanford University",
        "aff_unique_dep": "Khoury College of Computer Sciences;Department of Computer Science",
        "aff_unique_url": "https://www.northeastern.edu;https://www.stanford.edu",
        "aff_unique_abbr": "NU;Stanford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "050790e003",
        "title": "Near Optimal Heteroscedastic Regression with Symbiotic Learning",
        "site": "https://proceedings.mlr.press/v195/das23a.html",
        "author": "Aniket Das; Dheeraj M. Nagaraj; Praneeth Netrapalli; Dheeraj Baby",
        "abstract": "We consider the classical problem of heteroscedastic linear regression where, given $n$ i.i.d. samples $(\\vx_i, y_i)$ drawn from the model $y_i = \\dotp{\\wstar}{\\vx_i} + \\epsilon_i \\cdot \\dotp{\\fstar}{\\vx_i},  \\vx_i \\sim \\cN(0, \\vI),  \\epsilon_i \\sim \\cN(0, 1)$, our aim is to \\emph{estimate the regressor} $\\wstar$ \\emph{without prior knowledge of the noise parameter} $\\fstar$. In addition to classical applications of such models in statistics\u00a0\\citep{jobson1980least}, econometrics\u00a0\\citep{harvey1976estimating}, time series analysis\u00a0\\citep{engle1982autoregressive} etc., it is also particularly relevant in machine learning problems where data is collected from multiple sources of varying (but apriori unknown) quality, e.g., in the training of large models\u00a0\\citep{devlin2019bert} on web-scale data. In this work, we develop an algorithm called \\emph{\\ouralg} (short for \\emph{Symb}iotic \\emph{Learn}ing) which estimates $\\wstar$ in squared norm upto an error of $\\Otilde(\\| \\fstar \\|^2 \\cdot (\\nicefrac{1}{n} + (\\nicefrac{d}{n})^2))$, and prove that this rate is minimax optimal modulo logarithmic factors. This represents a substantial improvement upon the previous best known upper bound of $\\Otilde(\\| \\fstar \\|^2 \\cdot \\nicefrac{d}{n})$. Our algorithm is essentially an alternating minimization procedure which comprises of two key subroutines 1. An adaptation of the classical weighted least squares heuristic to estimate $\\wstar$ (dating back to at least\u00a0\\citet{davidian1987variance}), for which our work presents the first non-asymptotic guarantee; 2. A novel non-convex pseudogradient descent procedure for estimating $\\fstar$, which draws inspiration from the phase retrieval literature. As corollaries of our analysis, we obtain fast non-asymptotic rates for two important problems, linear regression with multiplicative noise, and phase retrieval with multiplicative noise, both of which could be of independent interest. Beyond this, the proof of our lower bound, which involves a novel adaptation of LeCam\u2019s two point method for handling infinite mutual information quantities (thereby preventing a direct application of standard techniques such as Fano\u2019s method), could also be of broader interest for establishing lower bounds for other heteroscedastic or heavy tailed statistical problems.",
        "bibtex": "@InProceedings{pmlr-v195-das23a,\n  title = \t {Near Optimal Heteroscedastic Regression with Symbiotic Learning},\n  author =       {Das, Aniket and Nagaraj, Dheeraj M. and Netrapalli, Praneeth and Baby, Dheeraj},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3696--3757},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/das23a/das23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/das23a.html},\n  abstract = \t {We consider the classical problem of heteroscedastic linear regression where, given $n$ i.i.d. samples $(\\vx_i, y_i)$ drawn from the model $y_i = \\dotp{\\wstar}{\\vx_i} + \\epsilon_i \\cdot \\dotp{\\fstar}{\\vx_i},  \\vx_i \\sim \\cN(0, \\vI),  \\epsilon_i \\sim \\cN(0, 1)$, our aim is to \\emph{estimate the regressor} $\\wstar$ \\emph{without prior knowledge of the noise parameter} $\\fstar$. In addition to classical applications of such models in statistics\u00a0\\citep{jobson1980least}, econometrics\u00a0\\citep{harvey1976estimating}, time series analysis\u00a0\\citep{engle1982autoregressive} etc., it is also particularly relevant in machine learning problems where data is collected from multiple sources of varying (but apriori unknown) quality, e.g., in the training of large models\u00a0\\citep{devlin2019bert} on web-scale data. In this work, we develop an algorithm called \\emph{\\ouralg} (short for \\emph{Symb}iotic \\emph{Learn}ing) which estimates $\\wstar$ in squared norm upto an error of $\\Otilde(\\| \\fstar \\|^2 \\cdot (\\nicefrac{1}{n} + (\\nicefrac{d}{n})^2))$, and prove that this rate is minimax optimal modulo logarithmic factors. This represents a substantial improvement upon the previous best known upper bound of $\\Otilde(\\| \\fstar \\|^2 \\cdot \\nicefrac{d}{n})$. Our algorithm is essentially an alternating minimization procedure which comprises of two key subroutines 1. An adaptation of the classical weighted least squares heuristic to estimate $\\wstar$ (dating back to at least\u00a0\\citet{davidian1987variance}), for which our work presents the first non-asymptotic guarantee; 2. A novel non-convex pseudogradient descent procedure for estimating $\\fstar$, which draws inspiration from the phase retrieval literature. As corollaries of our analysis, we obtain fast non-asymptotic rates for two important problems, linear regression with multiplicative noise, and phase retrieval with multiplicative noise, both of which could be of independent interest. Beyond this, the proof of our lower bound, which involves a novel adaptation of LeCam\u2019s two point method for handling infinite mutual information quantities (thereby preventing a direct application of standard techniques such as Fano\u2019s method), could also be of broader interest for establishing lower bounds for other heteroscedastic or heavy tailed statistical problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/das23a/das23a.pdf",
        "supp": "",
        "pdf_size": 989253,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11646762528393276708&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of California, Santa Barbara; Google Research, Bangalore; Google Research, Bangalore; Google Research, Bangalore",
        "aff_domain": "ucsb.edu;google.com;google.com;google.com",
        "email": "ucsb.edu;google.com;google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of California, Santa Barbara;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.ucsb.edu;https://research.google",
        "aff_unique_abbr": "UCSB;Google Research",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Santa Barbara;Bangalore",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "3fbf3b0243",
        "title": "Near-optimal fitting of ellipsoids to random points",
        "site": "https://proceedings.mlr.press/v195/potechin23a.html",
        "author": "Aaron Potechin; Paxton M. Turner; Prayaag Venkat; Alexander S. Wein",
        "abstract": "Given independent standard Gaussian points $v_1, \\ldots, v_n$ in dimension $d$, for what values of $(n, d)$ does there exist with high probability an origin-symmetric ellipsoid that simultaneously passes through all of the points? This basic problem of fitting an ellipsoid to random points has connections to low-rank matrix decompositions, independent component analysis, and principal component analysis. Based on strong numerical evidence, Saunderson, Parrilo, and Willsky [Proc. of Conference on Decision and Control, pp. 6031-6036, 2013] conjectured that the ellipsoid fitting problem transitions from feasible to infeasible as the number of points $n$ increases, with a sharp threshold at $n \\sim d^2/4$. We resolve this conjecture up to logarithmic factors by constructing a fitting ellipsoid for some $n = d^2/\\mathrm{polylog}(d)$. Our proof demonstrates feasibility of the least squares construction of Saunderson et al. using a convenient decomposition of a certain non-standard random matrix and a careful analysis of its Neumann expansion via the theory of graph matrices.",
        "bibtex": "@InProceedings{pmlr-v195-potechin23a,\n  title = \t {Near-optimal fitting of ellipsoids to random points},\n  author =       {Potechin, Aaron and Turner, Paxton M. and Venkat, Prayaag and Wein, Alexander S.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4235--4295},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/potechin23a/potechin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/potechin23a.html},\n  abstract = \t {Given independent standard Gaussian points $v_1, \\ldots, v_n$ in dimension $d$, for what values of $(n, d)$ does there exist with high probability an origin-symmetric ellipsoid that simultaneously passes through all of the points? This basic problem of fitting an ellipsoid to random points has connections to low-rank matrix decompositions, independent component analysis, and principal component analysis. Based on strong numerical evidence, Saunderson, Parrilo, and Willsky [Proc. of Conference on Decision and Control, pp. 6031-6036, 2013] conjectured that the ellipsoid fitting problem transitions from feasible to infeasible as the number of points $n$ increases, with a sharp threshold at $n \\sim d^2/4$. We resolve this conjecture up to logarithmic factors by constructing a fitting ellipsoid for some $n = d^2/\\mathrm{polylog}(d)$. Our proof demonstrates feasibility of the least squares construction of Saunderson et al. using a convenient decomposition of a certain non-standard random matrix and a careful analysis of its Neumann expansion via the theory of graph matrices. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/potechin23a/potechin23a.pdf",
        "supp": "",
        "pdf_size": 1124103,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1801621110495048563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Chicago; Harvard University; Harvard University; UC Davis",
        "aff_domain": "UCHICAGO.EDU;G.HARVARD.EDU;G.HARVARD.EDU;UCDAVIS.EDU",
        "email": "UCHICAGO.EDU;G.HARVARD.EDU;G.HARVARD.EDU;UCDAVIS.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "University of Chicago;Harvard University;University of California, Davis",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uchicago.edu;https://www.harvard.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "UChicago;Harvard;UC Davis",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Davis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "33667e6f97",
        "title": "Non-asymptotic convergence bounds for Sinkhorn iterates and their gradients: a coupling approach.",
        "site": "https://proceedings.mlr.press/v195/greco23a.html",
        "author": "Giacomo Greco; Maxence Noble; Giovanni Conforti; Alain Durmus",
        "abstract": "Computational optimal transport (OT) has recently emerged as a powerful framework with applications in various fields. In this paper we focus on a relaxation of the original OT problem, the entropic OT problem, which allows to implement efficient and practical algorithmic solutions, even in high dimensional settings. This formulation, also known as the Schr\u00f6dinger Bridge problem, notably connects with Stochastic Optimal Control (SOC) and can be solved with the popular Sinkhorn algorithm. In the case of discrete-state spaces, this algorithm is known to have exponential convergence; however, achieving a similar rate of convergence in a more general setting is still an active area of research. In this work, we analyze the convergence of the Sinkhorn algorithm for probability measures defined on the d-dimensional torus T, that admit densities with respect to the Haar measure of T. In particular, we prove pointwise exponential convergence of Sinkhorn iterates and their gradient. Our proof relies on the connection between these iterates and the evolution along the Hamilton-Jacobi-Bellman equations of value functions obtained from SOC-problems. Our approach is novel in that it is purely probabilistic and relies on coupling by reflection techniques for controlled diffusions on the torus.",
        "bibtex": "@InProceedings{pmlr-v195-greco23a,\n  title = \t {Non-asymptotic convergence bounds for Sinkhorn iterates and their gradients: a coupling approach.},\n  author =       {Greco, Giacomo and Noble, Maxence and Conforti, Giovanni and Durmus, Alain},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {716--746},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/greco23a/greco23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/greco23a.html},\n  abstract = \t {Computational optimal transport (OT) has recently emerged as a powerful framework with applications in various fields. In this paper we focus on a relaxation of the original OT problem, the entropic OT problem, which allows to implement efficient and practical algorithmic solutions, even in high dimensional settings. This formulation, also known as the Schr\u00f6dinger Bridge problem, notably connects with Stochastic Optimal Control (SOC) and can be solved with the popular Sinkhorn algorithm. In the case of discrete-state spaces, this algorithm is known to have exponential convergence; however, achieving a similar rate of convergence in a more general setting is still an active area of research. In this work, we analyze the convergence of the Sinkhorn algorithm for probability measures defined on the d-dimensional torus T, that admit densities with respect to the Haar measure of T. In particular, we prove pointwise exponential convergence of Sinkhorn iterates and their gradient. Our proof relies on the connection between these iterates and the evolution along the Hamilton-Jacobi-Bellman equations of value functions obtained from SOC-problems. Our approach is novel in that it is purely probabilistic and relies on coupling by reflection techniques for controlled diffusions on the torus.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/greco23a/greco23a.pdf",
        "supp": "",
        "pdf_size": 430474,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12969128371516662457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Eindhoven University of Technology; \u00c9cole Polytechnique; \u00c9cole Polytechnique; \u00c9cole Polytechnique",
        "aff_domain": "TUE.NL;POLYTECHNIQUE.EDU;POLYTECHNIQUE.EDU;POLYTECHNIQUE.EDU",
        "email": "TUE.NL;POLYTECHNIQUE.EDU;POLYTECHNIQUE.EDU;POLYTECHNIQUE.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Eindhoven University of Technology;Ecole Polytechnique",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tue.nl;https://www.polytechnique.edu",
        "aff_unique_abbr": "TU/e;X",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Netherlands;France"
    },
    {
        "id": "f4e04a1de1",
        "title": "On Classification-Calibration of Gamma-Phi Losses",
        "site": "https://proceedings.mlr.press/v195/wang23c.html",
        "author": "Yutong Wang; Clayton Scott",
        "abstract": "Gamma-Phi losses constitute a family of multiclass classification loss functions that generalize the logistic and other common losses, and have found application in the boosting literature. We establish the first general sufficient condition for the classification-calibration (CC) of such losses. To our knowledge, this sufficient condition gives the first family of nonconvex multiclass surrogate losses for which CC has been fully justified. In addition, we show that a previously proposed sufficient condition is in fact not sufficient. This contribution highlights a technical issue that is important in the study of multiclass CC but has been neglected in priorwork.",
        "bibtex": "@InProceedings{pmlr-v195-wang23c,\n  title = \t {On Classification-Calibration of Gamma-Phi Losses},\n  author =       {Wang, Yutong and Scott, Clayton},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4929--4951},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wang23c/wang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wang23c.html},\n  abstract = \t {Gamma-Phi losses constitute a family of multiclass classification loss functions that generalize the logistic and other common losses, and have found application in the boosting literature. We establish the first general sufficient condition for the classification-calibration (CC) of such losses. To our knowledge, this sufficient condition gives the first family of nonconvex multiclass surrogate losses for which CC has been fully justified. In addition, we show that a previously proposed sufficient condition is in fact not sufficient. This contribution highlights a technical issue that is important in the study of multiclass CC but has been neglected in priorwork.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wang23c/wang23c.pdf",
        "supp": "",
        "pdf_size": 428749,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15631376173477437244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Michigan; University of Michigan",
        "aff_domain": "UMICH.EDU;UMICH.EDU",
        "email": "UMICH.EDU;UMICH.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3bee4fb601",
        "title": "On Testing and Learning Quantum Junta Channels",
        "site": "https://proceedings.mlr.press/v195/bao23b.html",
        "author": "Zongbo Bao; Penghui Yao",
        "abstract": "We consider the problems of testing and learning quantum k-junta channels, which are n-qubit to n-qubit quantum channels acting non-trivially on at most k out of n qubits and leaving the rest of qubits unchanged. We show the following.1. An \\tilde{O}(k)-query algorithm to distinguish whether the given channel is k-junta channel or is far from any k-junta channels, and a lower bound \\Omega(\\sqrt{k}) on the number of queries;2. An \\tilde{O}(4^k)-query algorithm to learn a k-junta channel, and a lower bound \\Omega(4^k/k) on the number of queries.This gives the first junta channel testing and learning results, and partially answers an open problem raised by Chen et al. (2023). In order to settle these problems, we develop a Fourier analysis framework over the space of superoperators and prove several fundamental properties, which extends the Fourier analysis over the space of operators introduced in Montanaro and Osborne (2010).",
        "bibtex": "@InProceedings{pmlr-v195-bao23b,\n  title = \t {On Testing and Learning Quantum Junta Channels},\n  author =       {Bao, Zongbo and Yao, Penghui},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1064--1094},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bao23b/bao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bao23b.html},\n  abstract = \t {We consider the problems of testing and learning quantum k-junta channels, which are n-qubit to n-qubit quantum channels acting non-trivially on at most k out of n qubits and leaving the rest of qubits unchanged. We show the following.1. An \\tilde{O}(k)-query algorithm to distinguish whether the given channel is k-junta channel or is far from any k-junta channels, and a lower bound \\Omega(\\sqrt{k}) on the number of queries;2. An \\tilde{O}(4^k)-query algorithm to learn a k-junta channel, and a lower bound \\Omega(4^k/k) on the number of queries.This gives the first junta channel testing and learning results, and partially answers an open problem raised by Chen et al. (2023). In order to settle these problems, we develop a Fourier analysis framework over the space of superoperators and prove several fundamental properties, which extends the Fourier analysis over the space of operators introduced in Montanaro and Osborne (2010).}\n}",
        "pdf": "https://proceedings.mlr.press/v195/bao23b/bao23b.pdf",
        "supp": "",
        "pdf_size": 355982,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=348430361966077029&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China + Hefei National Laboratory, Hefei 230088, China",
        "aff_domain": "GMAIL.COM;GMAIL.COM",
        "email": "GMAIL.COM;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Nanjing University;Hefei National Laboratory",
        "aff_unique_dep": "State Key Laboratory for Novel Software Technology;",
        "aff_unique_url": "http://www.nju.edu.cn;",
        "aff_unique_abbr": "Nanjing U;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hefei",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "96e2eee178",
        "title": "On a Class of Gibbs Sampling over Networks",
        "site": "https://proceedings.mlr.press/v195/yuan23a.html",
        "author": "Bo Yuan; Jiaojiao Fan; Jiaming Liang; Andre Wibisono; Yongxin Chen",
        "abstract": "We consider the sampling problem from a composite distribution whose potential (negative log density) is $\\sum_{i=1}^n f_i(x_i)+\\sum_{j=1}^m g_j(y_j)+\\sum_{i=1}^n\\sum_{j=1}^m\\nicefrac{\\sigma_{ij}}{2\\eta} \\Vert x_i-y_j \\Vert^2_2$ where each of $x_i$ and $y_j$ is in $\\Rd$, $f_1, f_2, \\ldots, f_n, g_1, g_2, \\ldots, g_m$ are strongly convex functions, and $\\{\\sigma_{ij}\\}$ encodes a network structure. Building on the Gibbs sampling method, we develop an efficient sampling framework for this problem when the network is a bipartite graph. More importantly, we establish a non-asymptotic linear convergence rate for it. This work extends earlier works that involve only a graph with two nodes \\cite{lee2021structured}. To the best of our knowledge, our result represents the first non-asymptotic analysis of a Gibbs sampler for structured log-concave distributions over networks.Our framework can be potentially used to sample from the distribution $ \\propto \\exp[-\\sum_{i=1}^n f_i(x)-\\sum_{j=1}^m g_j(x)]$ in a distributed manner.",
        "bibtex": "@InProceedings{pmlr-v195-yuan23a,\n  title = \t {On a Class of Gibbs Sampling over Networks},\n  author =       {Yuan, Bo and Fan, Jiaojiao and Liang, Jiaming and Wibisono, Andre and Chen, Yongxin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5754--5780},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/yuan23a/yuan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/yuan23a.html},\n  abstract = \t {We consider the sampling problem from a composite distribution whose potential (negative log density) is $\\sum_{i=1}^n f_i(x_i)+\\sum_{j=1}^m g_j(y_j)+\\sum_{i=1}^n\\sum_{j=1}^m\\nicefrac{\\sigma_{ij}}{2\\eta} \\Vert x_i-y_j \\Vert^2_2$ where each of $x_i$ and $y_j$ is in $\\Rd$, $f_1, f_2, \\ldots, f_n, g_1, g_2, \\ldots, g_m$ are strongly convex functions, and $\\{\\sigma_{ij}\\}$ encodes a network structure. Building on the Gibbs sampling method, we develop an efficient sampling framework for this problem when the network is a bipartite graph. More importantly, we establish a non-asymptotic linear convergence rate for it. This work extends earlier works that involve only a graph with two nodes \\cite{lee2021structured}. To the best of our knowledge, our result represents the first non-asymptotic analysis of a Gibbs sampler for structured log-concave distributions over networks.Our framework can be potentially used to sample from the distribution $ \\propto \\exp[-\\sum_{i=1}^n f_i(x)-\\sum_{j=1}^m g_j(x)]$ in a distributed manner. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/yuan23a/yuan23a.pdf",
        "supp": "",
        "pdf_size": 579865,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3345929121063650136&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Yale University; Yale University; Georgia Institute of Technology",
        "aff_domain": "gatech.edu;gatech.edu;yale.edu;yale.edu;gatech.edu",
        "email": "gatech.edu;gatech.edu;yale.edu;yale.edu;gatech.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Yale University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.yale.edu",
        "aff_unique_abbr": "Georgia Tech;Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9b54190418",
        "title": "On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring",
        "site": "https://proceedings.mlr.press/v195/foster23a.html",
        "author": "Dean Foster; Dylan J. Foster; Noah Golowich; Alexander Rakhlin",
        "abstract": "A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an (unknown) environment. Our main contributions are:\u2022 We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the single-agent setting, our upper and lower bounds have additional gaps. We show that no \u201creasonable\u201d complexity measure can close these gaps, highlighting a striking separation between single and multiple agents.\u2022 We show that characterizing the statistical complexity for multi-agent decision making is equivalent to characterizing the statistical complexity of single-agent decision making, but with hidden (unobserved) rewards, a framework that subsumes variants of the partial monitoring problem. As a consequence of this connection, we characterize the statistical complexity for hidden-reward interactive decision making to the best extent possible.Building on this development, we provide several new structural results, including 1) conditions under which the statistical complexity of multi-agent decision making can be reduced to that of single-agent, and 2) conditions under which the so-called curse of multiple agents can be avoided.",
        "bibtex": "@InProceedings{pmlr-v195-foster23a,\n  title = \t {On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring},\n  author =       {Foster, Dean and Foster, Dylan J. and Golowich, Noah and Rakhlin, Alexander},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2678--2792},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/foster23a/foster23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/foster23a.html},\n  abstract = \t {A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an (unknown) environment. Our main contributions are:\u2022 We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the single-agent setting, our upper and lower bounds have additional gaps. We show that no \u201creasonable\u201d complexity measure can close these gaps, highlighting a striking separation between single and multiple agents.\u2022 We show that characterizing the statistical complexity for multi-agent decision making is equivalent to characterizing the statistical complexity of single-agent decision making, but with hidden (unobserved) rewards, a framework that subsumes variants of the partial monitoring problem. As a consequence of this connection, we characterize the statistical complexity for hidden-reward interactive decision making to the best extent possible.Building on this development, we provide several new structural results, including 1) conditions under which the statistical complexity of multi-agent decision making can be reduced to that of single-agent, and 2) conditions under which the so-called curse of multiple agents can be avoided.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/foster23a/foster23a.pdf",
        "supp": "",
        "pdf_size": 1021085,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12281127486648614666&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft Research; Amazon; MIT; MIT",
        "aff_domain": "microsoft.com;foster.net;mit.edu;mit.edu",
        "email": "microsoft.com;foster.net;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Microsoft;Amazon;Massachusetts Institute of Technology",
        "aff_unique_dep": "Microsoft Research;Amazon.com, Inc.;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.amazon.com;https://web.mit.edu",
        "aff_unique_abbr": "MSR;Amazon;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "62f621ef30",
        "title": "On the Existence of a Complexity in Fixed Budget Bandit Identification",
        "site": "https://proceedings.mlr.press/v195/degenne23a.html",
        "author": "R\u00e9my Degenne",
        "abstract": "In fixed budget bandit identification, an algorithm sequentially observes samples from several distributions up to a given final time.It then answers a query about the set of distributions. A good algorithm will have a small probability of error.While that probability decreases exponentially with the final time, the best attainable rate is not known precisely for most identification tasks.We show that if a fixed budget task admits a complexity, defined as a lower bound on the probability of error which is attained by the same algorithm on all bandit problems, then that complexity is determined by the best non-adaptive sampling procedure for that problem.We show that there is no such complexity for several fixed budget identification tasks including Bernoulli best arm identification with two arms: there is no single algorithm that attains everywhere the best possible rate.",
        "bibtex": "@InProceedings{pmlr-v195-degenne23a,\n  title = \t {On the Existence of a Complexity in Fixed Budget Bandit Identification},\n  author =       {Degenne, R{\\'e}my},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1131--1154},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/degenne23a/degenne23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/degenne23a.html},\n  abstract = \t {In fixed budget bandit identification, an algorithm sequentially observes samples from several distributions up to a given final time.It then answers a query about the set of distributions. A good algorithm will have a small probability of error.While that probability decreases exponentially with the final time, the best attainable rate is not known precisely for most identification tasks.We show that if a fixed budget task admits a complexity, defined as a lower bound on the probability of error which is attained by the same algorithm on all bandit problems, then that complexity is determined by the best non-adaptive sampling procedure for that problem.We show that there is no such complexity for several fixed budget identification tasks including Bernoulli best arm identification with two arms: there is no single algorithm that attains everywhere the best possible rate.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/degenne23a/degenne23a.pdf",
        "supp": "",
        "pdf_size": 302125,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9175907542685983036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189-CRIStAL, F-59000 Lille, France",
        "aff_domain": "INRIA.FR",
        "email": "INRIA.FR",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Lille",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.univ-lille.fr",
        "aff_unique_abbr": "Univ. Lille",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Lille",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "121d992a6c",
        "title": "On the Lower Bound of Minimizing Polyak-\u0141ojasiewicz functions",
        "site": "https://proceedings.mlr.press/v195/yue23a.html",
        "author": "Pengyun Yue; Cong Fang; Zhouchen Lin",
        "abstract": "Polyak-\u0141ojasiewicz (PL) (Polyak, 1963) condition is a weaker condition than the strong convexity but suffices to ensure a global convergence for the Gradient Descent algorithm. In this paper, we study the lower bound of algorithms using first-order oracles to find an approximate optimal solution. We show that any first-order algorithm requires at least ${\\Omega}\\left(\\frac{L}{\\mu}\\log\\frac{1}{\\epsilon}\\right)$ gradient costs to \u03bc\u03b5 find an $\\epsilon$-approximate optimal solution for a general $L$-smooth function that has an $\\mu$-PL constant. This result demonstrates the optimality of the Gradient Descent algorithm to minimize smooth PL functions in the sense that there exists a \u201chard\u201d PL function such that no first-order algorithm can be faster than Gradient Descent when ignoring a numerical constant. In contrast, it is well-known that the momentum technique, e.g. Nesterov (2003, chap. 2), can provably accelerate Gradient Descent to ${O}\\left(\\sqrt{\\frac{L}{\\hat{\\mu}}}\\log\\frac{1}{\\epsilon}\\right)$ gradient costs for functions that are $L$-smooth and $\\hat{\\mu}$-strongly convex. Therefore, our result distinguishes the hardness of minimizing a smooth PL function and a smooth strongly convex function as the complexity of the former cannot be improved by any polynomial order in general.",
        "bibtex": "@InProceedings{pmlr-v195-yue23a,\n  title = \t {On the Lower Bound of Minimizing Polyak-\u0141ojasiewicz functions},\n  author =       {Yue, Pengyun and Fang, Cong and Lin, Zhouchen},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2948--2968},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/yue23a/yue23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/yue23a.html},\n  abstract = \t {Polyak-\u0141ojasiewicz (PL) (Polyak, 1963) condition is a weaker condition than the strong convexity but suffices to ensure a global convergence for the Gradient Descent algorithm. In this paper, we study the lower bound of algorithms using first-order oracles to find an approximate optimal solution. We show that any first-order algorithm requires at least ${\\Omega}\\left(\\frac{L}{\\mu}\\log\\frac{1}{\\epsilon}\\right)$ gradient costs to \u03bc\u03b5 find an $\\epsilon$-approximate optimal solution for a general $L$-smooth function that has an $\\mu$-PL constant. This result demonstrates the optimality of the Gradient Descent algorithm to minimize smooth PL functions in the sense that there exists a \u201chard\u201d PL function such that no first-order algorithm can be faster than Gradient Descent when ignoring a numerical constant. In contrast, it is well-known that the momentum technique, e.g. Nesterov (2003, chap. 2), can provably accelerate Gradient Descent to ${O}\\left(\\sqrt{\\frac{L}{\\hat{\\mu}}}\\log\\frac{1}{\\epsilon}\\right)$ gradient costs for functions that are $L$-smooth and $\\hat{\\mu}$-strongly convex. Therefore, our result distinguishes the hardness of minimizing a smooth PL function and a smooth strongly convex function as the complexity of the former cannot be improved by any polynomial order in general.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/yue23a/yue23a.pdf",
        "supp": "",
        "pdf_size": 420362,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14279576987513792768&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "National Key Lab of General AI, School of Intelligence Science and Technology, Peking University; National Key Lab of General AI, School of Intelligence Science and Technology, Peking University+Institute for Artificial Intelligence, Peking University; National Key Lab of General AI, School of Intelligence Science and Technology, Peking University+Institute for Artificial Intelligence, Peking University+Peng Cheng Laboratory",
        "aff_domain": "pku.edu.cn;pku.edu.cn;pku.edu.cn",
        "email": "pku.edu.cn;pku.edu.cn;pku.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+0;0+0+1",
        "aff_unique_norm": "Peking University;Pengcheng Laboratory",
        "aff_unique_dep": "School of Intelligence Science and Technology;Peng Cheng Laboratory",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.pcl.ac.cn",
        "aff_unique_abbr": "Peking University;PCL",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0+0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "1ac6a039a1",
        "title": "Online Learning Guided Curvature Approximation: A Quasi-Newton Method with Global Non-Asymptotic Superlinear Convergence",
        "site": "https://proceedings.mlr.press/v195/jiang23a.html",
        "author": "Ruichen Jiang; Qiujiang Jin; Aryan Mokhtari",
        "abstract": "Quasi-Newton algorithms are among the most popular iterative methods for solving unconstrained minimization problems, largely due to their favorable superlinear convergence property. However, existing results for these algorithms are limited as they provide either (i) a global convergence guarantee with an asymptotic superlinear convergence rate, or (ii) a local non-asymptotic superlinear rate for the case that the initial point and the initial Hessian approximation are chosen properly. In particular, no current analysis for quasi-Newton methods guarantees global convergence with an explicit superlinear convergence rate. In this paper, we close this gap and present  the first globally convergent quasi-Newton method with an explicit non-asymptotic superlinear convergence rate. Unlike classical quasi-Newton methods, we build our algorithm upon the hybrid proximal extragradient method and propose a novel online learning framework for updating the Hessian approximation matrices. Specifically, guided by the convergence analysis, we formulate the Hessian approximation update as an online convex optimization problem in the space of matrices, and we relate the bounded regret of the online problem to the superlinear convergence of our method.",
        "bibtex": "@InProceedings{pmlr-v195-jiang23a,\n  title = \t {Online Learning Guided Curvature Approximation: A Quasi-Newton Method with Global Non-Asymptotic Superlinear Convergence},\n  author =       {Jiang, Ruichen and Jin, Qiujiang and Mokhtari, Aryan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1962--1992},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/jiang23a/jiang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/jiang23a.html},\n  abstract = \t {Quasi-Newton algorithms are among the most popular iterative methods for solving unconstrained minimization problems, largely due to their favorable superlinear convergence property. However, existing results for these algorithms are limited as they provide either (i) a global convergence guarantee with an asymptotic superlinear convergence rate, or (ii) a local non-asymptotic superlinear rate for the case that the initial point and the initial Hessian approximation are chosen properly. In particular, no current analysis for quasi-Newton methods guarantees global convergence with an explicit superlinear convergence rate. In this paper, we close this gap and present  the first globally convergent quasi-Newton method with an explicit non-asymptotic superlinear convergence rate. Unlike classical quasi-Newton methods, we build our algorithm upon the hybrid proximal extragradient method and propose a novel online learning framework for updating the Hessian approximation matrices. Specifically, guided by the convergence analysis, we formulate the Hessian approximation update as an online convex optimization problem in the space of matrices, and we relate the bounded regret of the online problem to the superlinear convergence of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/jiang23a/jiang23a.pdf",
        "supp": "",
        "pdf_size": 660962,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11842196074080971249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin",
        "aff_domain": "UTEXAS.EDU;AUSTIN.UTEXAS.EDU;AUSTIN.UTEXAS.EDU",
        "email": "UTEXAS.EDU;AUSTIN.UTEXAS.EDU;AUSTIN.UTEXAS.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f4fb70c6c1",
        "title": "Online Learning and Solving Infinite Games with an ERM Oracle",
        "site": "https://proceedings.mlr.press/v195/assos23a.html",
        "author": "Angelos Assos; Idan Attias; Yuval Dagan; Constantinos Daskalakis; Maxwell K. Fishelson",
        "abstract": "While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for  online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class.We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in  two-player zero-sum games and  approximate coarse correlated equilibria in multi-player general-sum games, as long as the game has bounded fat-threshold dimension. Our algorithms apply to both binary-valued and real-valued games and can be viewed as providing justification for the wide use of double oracle and multiple oracle algorithms in the practice of solving large games.",
        "bibtex": "@InProceedings{pmlr-v195-assos23a,\n  title = \t {Online Learning and Solving Infinite Games with an ERM Oracle},\n  author =       {Assos, Angelos and Attias, Idan and Dagan, Yuval and Daskalakis, Constantinos and Fishelson, Maxwell K.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {274--324},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/assos23a/assos23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/assos23a.html},\n  abstract = \t {While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for  online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class.We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in  two-player zero-sum games and  approximate coarse correlated equilibria in multi-player general-sum games, as long as the game has bounded fat-threshold dimension. Our algorithms apply to both binary-valued and real-valued games and can be viewed as providing justification for the wide use of double oracle and multiple oracle algorithms in the practice of solving large games.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/assos23a/assos23a.pdf",
        "supp": "",
        "pdf_size": 551712,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15872580537830314937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Massachusetts Institute of Technology; Ben-Gurion University; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "MIT.EDU;POST.BGU.AC.IL;GMAIL.COM;CSAIL.MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;POST.BGU.AC.IL;GMAIL.COM;CSAIL.MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Ben-Gurion University of the Negev",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.bgu.ac.il",
        "aff_unique_abbr": "MIT;BGU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "45f2e8e02c",
        "title": "Online Learning in Dynamically Changing Environments",
        "site": "https://proceedings.mlr.press/v195/wu23a.html",
        "author": "Changlong Wu; Ananth Grama; Wojciech Szpankowski",
        "abstract": "We study the problem of online learning and online regret minimization when samples are drawn from a general unknown \\emph{non-stationary} process. We introduce the concept of a \\emph{dynamic changing process} with cost $K$, where the \\emph{conditional} marginals of the process can vary arbitrarily, but that the number of different conditional marginals is bounded by $K$ over $T$ rounds. For such processes we prove a tight (upto $\\sqrt{\\log T}$ factor) bound $O(\\sqrt{KT\\cdot\\vch\\log T})$ for the \\emph{expected worst case} regret of any finite VC-dimensional class $\\mathcal{H}$ under absolute loss (i.e., the expected miss-classification loss). We then improve this bound for general mixable losses, by establishing a tight (up to $\\log^3 T$ factor) regret bound $O(K\\cdot\\vch\\log^3 T)$. We extend these results to general \\emph{smooth adversary} processes with \\emph{unknown} reference measure by showing a sub-linear regret bound for $1$-dimensional threshold functions under a general bounded convex loss. Our results can be viewed as a first step towards regret analysis with non-stationary samples in the \\emph{distribution blind} (universal) regime. This also brings a new viewpoint that shifts the study of complexity of the hypothesis classes to the study of the complexity of processes generating data.",
        "bibtex": "@InProceedings{pmlr-v195-wu23a,\n  title = \t {Online Learning in Dynamically Changing Environments},\n  author =       {Wu, Changlong and Grama, Ananth and Szpankowski, Wojciech},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {325--358},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/wu23a/wu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/wu23a.html},\n  abstract = \t {We study the problem of online learning and online regret minimization when samples are drawn from a general unknown \\emph{non-stationary} process. We introduce the concept of a \\emph{dynamic changing process} with cost $K$, where the \\emph{conditional} marginals of the process can vary arbitrarily, but that the number of different conditional marginals is bounded by $K$ over $T$ rounds. For such processes we prove a tight (upto $\\sqrt{\\log T}$ factor) bound $O(\\sqrt{KT\\cdot\\vch\\log T})$ for the \\emph{expected worst case} regret of any finite VC-dimensional class $\\mathcal{H}$ under absolute loss (i.e., the expected miss-classification loss). We then improve this bound for general mixable losses, by establishing a tight (up to $\\log^3 T$ factor) regret bound $O(K\\cdot\\vch\\log^3 T)$. We extend these results to general \\emph{smooth adversary} processes with \\emph{unknown} reference measure by showing a sub-linear regret bound for $1$-dimensional threshold functions under a general bounded convex loss. Our results can be viewed as a first step towards regret analysis with non-stationary samples in the \\emph{distribution blind} (universal) regime. This also brings a new viewpoint that shifts the study of complexity of the hypothesis classes to the study of the complexity of processes generating data.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/wu23a/wu23a.pdf",
        "supp": "",
        "pdf_size": 475700,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7520306297987016225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "CSoI, Purdue University; CSoI, Purdue University; CSoI, Purdue University",
        "aff_domain": "HAWAII.EDU;CS.PURDUE.EDU;PURDUE.EDU",
        "email": "HAWAII.EDU;CS.PURDUE.EDU;PURDUE.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Center for Science of Information (CSoI)",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6eb68c27a1",
        "title": "Online Nonconvex Optimization with Limited Instantaneous Oracle Feedback",
        "site": "https://proceedings.mlr.press/v195/guan23a.html",
        "author": "Ziwei Guan; Yi Zhou; Yingbin Liang",
        "abstract": "We investigate online nonconvex optimization from a local regret minimization perspective. Previous studies along this line implicitly required the access to sufficient gradient oracles at each time instance in order to design double-loop algorithms. In this work, we focus on more challenging but practical settings where only limited number of oracles are available in online nonconvex optimization, including window-smoothed single gradient oracle (Window-SGO), single function value oracle (Window-SVO) and multiple function value oracles (Window-MVO). Specifically, in the Window-SGO setting which allows only single-loop algorithm design, we derive a local regret lower bound, which indicates that single-loop algorithms are provably worse than double-loop algorithms. Further, the simple classical OGD algorithm achieves the window-unconditioned lower bound. Moreover, in the Window-SVO setting, we propose a novel single-loop online algorithm named SkipOGD, and show that it achieves a near-optimal local regret that matches the Window-SGO regret lower bound up to a factor of the dimension $d$ due to the function value feedback. Lastly, in the Window-MVO setting, we propose a new double-loop online algorithm named LoopOGD and show that it achieves a smooth trade-off between regret minimization and sample complexity over the number of oracle calls $K$ per time instance. In particular, with $K=1$ and $wd$, LoopOGD respectively achieves our regret lower bound with Window-SGO (up to the factor $d$ due to function value feedback) and the existing regret lower bound with multiple gradient oracle feedback.",
        "bibtex": "@InProceedings{pmlr-v195-guan23a,\n  title = \t {Online Nonconvex Optimization with Limited Instantaneous Oracle Feedback},\n  author =       {Guan, Ziwei and Zhou, Yi and Liang, Yingbin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3328--3355},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/guan23a/guan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/guan23a.html},\n  abstract = \t {We investigate online nonconvex optimization from a local regret minimization perspective. Previous studies along this line implicitly required the access to sufficient gradient oracles at each time instance in order to design double-loop algorithms. In this work, we focus on more challenging but practical settings where only limited number of oracles are available in online nonconvex optimization, including window-smoothed single gradient oracle (Window-SGO), single function value oracle (Window-SVO) and multiple function value oracles (Window-MVO). Specifically, in the Window-SGO setting which allows only single-loop algorithm design, we derive a local regret lower bound, which indicates that single-loop algorithms are provably worse than double-loop algorithms. Further, the simple classical OGD algorithm achieves the window-unconditioned lower bound. Moreover, in the Window-SVO setting, we propose a novel single-loop online algorithm named SkipOGD, and show that it achieves a near-optimal local regret that matches the Window-SGO regret lower bound up to a factor of the dimension $d$ due to the function value feedback. Lastly, in the Window-MVO setting, we propose a new double-loop online algorithm named LoopOGD and show that it achieves a smooth trade-off between regret minimization and sample complexity over the number of oracle calls $K$ per time instance. In particular, with $K=1$ and $wd$, LoopOGD respectively achieves our regret lower bound with Window-SGO (up to the factor $d$ due to function value feedback) and the existing regret lower bound with multiple gradient oracle feedback. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/guan23a/guan23a.pdf",
        "supp": "",
        "pdf_size": 334218,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8801260408751928399&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "2015 Neil Ave, Columbus, Ohio, USA; 50 Central Campus Dr #2110, Salt Lake City, Utah, USA + 2015 Neil Ave, Columbus, Ohio, USA; 2015 Neil Ave, Columbus, Ohio, USA",
        "aff_domain": "buckeyemail.osu.edu;utah.edu;osu.edu",
        "email": "buckeyemail.osu.edu;utah.edu;osu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "Ohio State University;University of Utah",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.osu.edu;https://www.utah.edu",
        "aff_unique_abbr": "OSU;U of U",
        "aff_campus_unique_index": "0;1+0;0",
        "aff_campus_unique": "Columbus;Salt Lake City",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "abd9e23146",
        "title": "Online Reinforcement Learning in Stochastic Continuous-Time Systems",
        "site": "https://proceedings.mlr.press/v195/shirani-faradonbeh23a.html",
        "author": "Mohamad Kazem Shirani Faradonbeh; Mohamad Sadegh Shirani Faradonbeh",
        "abstract": "Linear dynamical systems that obey stochastic differential equations are canonical models. While optimal control of known systems has a rich literature, the problem is technically hard under model uncertainty and there are hardly any such result. We initiate study of this problem and aim to learn (and simultaneously deploy) optimal actions for minimizing a quadratic cost function. Indeed, this work is the first that comprehensively addresses the crucial challenge of balancing exploration versus exploitation in continuous-time systems. We present online policies that learn optimal actions fast by carefully randomizing the parameter estimates, and establish their performance guarantees: a regret bound that grows with square-root of time multiplied by the number of parameters. Implementation of the policy for a flight-control task demonstrates its efficacy. Further, we prove sharp stability results for inexact system dynamics and tightly specify the infinitesimal regret caused by sub-optimal actions. To obtain the results, we conduct a novel eigenvalue-sensitivity analysis for matrix perturbation, establish upper-bounds for comparative ratios of stochastic integrals, and introduce the new method of policy differentiation. Our analysis sheds light on fundamental challenges in continuous-time reinforcement learning and suggests a useful cornerstone for similar problems.",
        "bibtex": "@InProceedings{pmlr-v195-shirani-faradonbeh23a,\n  title = \t {Online Reinforcement Learning in Stochastic Continuous-Time Systems},\n  author =       {Shirani Faradonbeh, Mohamad Kazem and Shirani Faradonbeh, Mohamad Sadegh},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {612--656},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/shirani-faradonbeh23a/shirani-faradonbeh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/shirani-faradonbeh23a.html},\n  abstract = \t {Linear dynamical systems that obey stochastic differential equations are canonical models. While optimal control of known systems has a rich literature, the problem is technically hard under model uncertainty and there are hardly any such result. We initiate study of this problem and aim to learn (and simultaneously deploy) optimal actions for minimizing a quadratic cost function. Indeed, this work is the first that comprehensively addresses the crucial challenge of balancing exploration versus exploitation in continuous-time systems. We present online policies that learn optimal actions fast by carefully randomizing the parameter estimates, and establish their performance guarantees: a regret bound that grows with square-root of time multiplied by the number of parameters. Implementation of the policy for a flight-control task demonstrates its efficacy. Further, we prove sharp stability results for inexact system dynamics and tightly specify the infinitesimal regret caused by sub-optimal actions. To obtain the results, we conduct a novel eigenvalue-sensitivity analysis for matrix perturbation, establish upper-bounds for comparative ratios of stochastic integrals, and introduce the new method of policy differentiation. Our analysis sheds light on fundamental challenges in continuous-time reinforcement learning and suggests a useful cornerstone for similar problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/shirani-faradonbeh23a/shirani-faradonbeh23a.pdf",
        "supp": "",
        "pdf_size": 542618,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9723779473689829284&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Mathematics, Southern Methodist University, Dallas, TX; Graduate School of Business, Stanford University, Stanford, CA",
        "aff_domain": "SMU.EDU;STANFORD.EDU",
        "email": "SMU.EDU;STANFORD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Southern Methodist University;Stanford University",
        "aff_unique_dep": "Department of Mathematics;Graduate School of Business",
        "aff_unique_url": "https://www.smu.edu;https://www.stanford.edu",
        "aff_unique_abbr": "SMU;Stanford",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Dallas;Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "70f60227ef",
        "title": "Open Problem: Is There a First-Order Method that Only Converges to Local Minimax Optima?",
        "site": "https://proceedings.mlr.press/v195/chae23a.html",
        "author": "Jiseok Chae; Kyuwon Kim; Donghwan Kim",
        "abstract": "Can we effectively train a generative adversarial network (GAN), i.e., optimize a minimax problem, similar to classification neural networks, i.e., minimize a function, by gradient methods? Currently, the answer to this question is \u201cNo\u201d. Despite the extensive studies, training GANs still remains challenging, and diffusion-based generative models are largely replacing GANs. When training GANs, we not only struggle with finding stationary points, but also suffer from the so-called mode-collapse phenomenon, generating samples that lack diversity compared to the training data. Due to the nature of GANs, mode-collapse is likely to occur when we find an optimal point for the maximin problem, rather than the original minimax problem.This suggests that answering to an open question of whether there exists a first-order method that only converges to (local) optimum of minimax problems can resolve these issues. None of the existing methods possess such a property, neither theoretically nor practically. This is in contrast to standard gradient descent successfully finding local minima. In nonconvex-nonconcave minimax problems, Jin et al. are the first to suggest an appropriate notion of local optimality, taking account of the order of minimization and maximization. They also presented a partial answer to the question above, showing that two-timescale gradient descent ascent converges to strict local minimax optima. However, the convergence to general local minimax optimum was left mostly unexplored, even though non-strict local minimax optima are prevalent. Our recent findings illustrate that it is possible to find some non-strict local minimax optima by a two-timescale extragradient method.This positive result brings new attention to the open question. Furthermore, we wish to revive discussion on the appropriate notion of local minimax optimum. This was initially discussed by Jin et al., but not much thereafter, which we believe is crucial in answering the open question.",
        "bibtex": "@InProceedings{pmlr-v195-chae23a,\n  title = \t {Open Problem: Is There a First-Order Method that Only Converges to Local Minimax Optima?},\n  author =       {Chae, Jiseok and Kim, Kyuwon and Kim, Donghwan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5957--5964},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/chae23a/chae23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/chae23a.html},\n  abstract = \t {Can we effectively train a generative adversarial network (GAN), i.e., optimize a minimax problem, similar to classification neural networks, i.e., minimize a function, by gradient methods? Currently, the answer to this question is \u201cNo\u201d. Despite the extensive studies, training GANs still remains challenging, and diffusion-based generative models are largely replacing GANs. When training GANs, we not only struggle with finding stationary points, but also suffer from the so-called mode-collapse phenomenon, generating samples that lack diversity compared to the training data. Due to the nature of GANs, mode-collapse is likely to occur when we find an optimal point for the maximin problem, rather than the original minimax problem.This suggests that answering to an open question of whether there exists a first-order method that only converges to (local) optimum of minimax problems can resolve these issues. None of the existing methods possess such a property, neither theoretically nor practically. This is in contrast to standard gradient descent successfully finding local minima. In nonconvex-nonconcave minimax problems, Jin et al. are the first to suggest an appropriate notion of local optimality, taking account of the order of minimization and maximization. They also presented a partial answer to the question above, showing that two-timescale gradient descent ascent converges to strict local minimax optima. However, the convergence to general local minimax optimum was left mostly unexplored, even though non-strict local minimax optima are prevalent. Our recent findings illustrate that it is possible to find some non-strict local minimax optima by a two-timescale extragradient method.This positive result brings new attention to the open question. Furthermore, we wish to revive discussion on the appropriate notion of local minimax optimum. This was initially discussed by Jin et al., but not much thereafter, which we believe is crucial in answering the open question.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/chae23a/chae23a.pdf",
        "supp": "",
        "pdf_size": 275406,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3795278837045980350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology",
        "aff_domain": "KAIST.AC.KR;KAIST.AC.KR;KAIST.AC.KR",
        "email": "KAIST.AC.KR;KAIST.AC.KR;KAIST.AC.KR",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "b1b8248c7a",
        "title": "Open Problem: Learning sparse linear concepts by priming the features",
        "site": "https://proceedings.mlr.press/v195/warmuth23a.html",
        "author": "Manfred K. Warmuth; Ehsan Amid",
        "abstract": "Sparse linear problems can be learned well with online multiplicative updates. The question is weather there are closed form updates based on the past examples that can sample efficiently learn such sparse linear problems as well?We show experimentally that this can be achieved by applying linear least squares, then \u201cpriming\u201d the ith features of the past instances by multiplying them by the ith linear least squares weight, and finally applying linear least squares a second time. However it is an open problem whether such priming methods have provably good regret bounds when applied online?",
        "bibtex": "@InProceedings{pmlr-v195-warmuth23a,\n  title = \t {Open Problem: Learning sparse linear concepts by priming the features},\n  author =       {Warmuth, Manfred K. and Amid, Ehsan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5937--5942},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/warmuth23a/warmuth23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/warmuth23a.html},\n  abstract = \t {Sparse linear problems can be learned well with online multiplicative updates. The question is weather there are closed form updates based on the past examples that can sample efficiently learn such sparse linear problems as well?We show experimentally that this can be achieved by applying linear least squares, then \u201cpriming\u201d the ith features of the past instances by multiplying them by the ith linear least squares weight, and finally applying linear least squares a second time. However it is an open problem whether such priming methods have provably good regret bounds when applied online?}\n}",
        "pdf": "https://proceedings.mlr.press/v195/warmuth23a/warmuth23a.pdf",
        "supp": "",
        "pdf_size": 1509346,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13009717979773571881&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Google Inc.; Google Inc.",
        "aff_domain": "google.com;google.com",
        "email": "google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "54d60352d6",
        "title": "Open Problem: Polynomial linearly-convergent method for g-convex optimization?",
        "site": "https://proceedings.mlr.press/v195/criscitiello23b.html",
        "author": "Christopher Criscitiello; David Mart\u00ednez-Rubio; Nicolas Boumal",
        "abstract": "Let $f \\colon \\mathcal{M} \\to \\mathbb{R}$ be a Lipschitz and geodesically convex function defined on a $d$-dimensional Riemannian manifold $\\mathcal{M}$. Does there exist a first-order deterministic algorithm which (a) uses at most $O(\\mathrm{poly}(d) \\log(\\epsilon^{-1}))$ subgradient queries to find a point with target accuracy $\\epsilon$, and (b) requires only $O(\\mathrm{poly}(d))$ arithmetic operations per query? In convex optimization, the classical ellipsoid method achieves this. After detailing related work, we provide an ellipsoid-like algorithm with query complexity $O(d^2 \\log^2(\\epsilon^{-1}))$ and per-query complexity $O(d^2)$ for the limited case where $\\mathcal{M}$ has constant curvature (hemisphere or hyperbolic space). We then detail possible approaches and corresponding obstacles for designing an ellipsoid-like method for general Riemannian manifolds.",
        "bibtex": "@InProceedings{pmlr-v195-criscitiello23b,\n  title = \t {Open Problem: Polynomial linearly-convergent method for g-convex optimization?},\n  author =       {Criscitiello, Christopher and Mart{\\'i}nez-Rubio, David and Boumal, Nicolas},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5950--5956},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/criscitiello23b/criscitiello23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/criscitiello23b.html},\n  abstract = \t {Let $f \\colon \\mathcal{M} \\to \\mathbb{R}$ be a Lipschitz and geodesically convex function defined on a $d$-dimensional Riemannian manifold $\\mathcal{M}$. Does there exist a first-order deterministic algorithm which (a) uses at most $O(\\mathrm{poly}(d) \\log(\\epsilon^{-1}))$ subgradient queries to find a point with target accuracy $\\epsilon$, and (b) requires only $O(\\mathrm{poly}(d))$ arithmetic operations per query? In convex optimization, the classical ellipsoid method achieves this. After detailing related work, we provide an ellipsoid-like algorithm with query complexity $O(d^2 \\log^2(\\epsilon^{-1}))$ and per-query complexity $O(d^2)$ for the limited case where $\\mathcal{M}$ has constant curvature (hemisphere or hyperbolic space). We then detail possible approaches and corresponding obstacles for designing an ellipsoid-like method for general Riemannian manifolds.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/criscitiello23b/criscitiello23b.pdf",
        "supp": "",
        "pdf_size": 207621,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15725960955794990089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Institute of Mathematics; Zuse Institute Berlin and Technische Universit\u00e4t; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Institute of Mathematics",
        "aff_domain": "epfl.ch;zib.de;epfl.ch",
        "email": "epfl.ch;zib.de;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "EPFL;Zuse Institute Berlin",
        "aff_unique_dep": "Institute of Mathematics;",
        "aff_unique_url": "https://www.epfl.ch;https://www.zib.de",
        "aff_unique_abbr": "EPFL;ZIB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "08ce394c02",
        "title": "Open Problem: The Sample Complexity of Multi-Distribution Learning for VC Classes",
        "site": "https://proceedings.mlr.press/v195/awasthi23a.html",
        "author": "Pranjal Awasthi; Nika Haghtalab; Eric Zhao",
        "abstract": "Multi-distribution learning is a natural generalization of PAC learning to settings with multiple data distributions. There remains a significant gap between the known upper and lower bounds for PAC-learnable classes. In particular, though we understand the sample complexity of learning a VC dimension $d$ class on $k$ distributions to be $O(\\epsilon^{-2} \\ln(k) (d + k) + \\min \\{\\epsilon^{-1} d k,  \\epsilon^{-4} \\ln(k) d\\})$, the best lower bound is $\\Omega(\\epsilon^{-2}(d + k \\ln(k)))$. We discuss recent progress on this problem and some hurdles that are fundamental to the use of game dynamics in statistical learning.",
        "bibtex": "@InProceedings{pmlr-v195-awasthi23a,\n  title = \t {Open Problem: The Sample Complexity of Multi-Distribution Learning for VC Classes},\n  author =       {Awasthi, Pranjal and Haghtalab, Nika and Zhao, Eric},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5943--5949},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/awasthi23a/awasthi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/awasthi23a.html},\n  abstract = \t {Multi-distribution learning is a natural generalization of PAC learning to settings with multiple data distributions. There remains a significant gap between the known upper and lower bounds for PAC-learnable classes. In particular, though we understand the sample complexity of learning a VC dimension $d$ class on $k$ distributions to be $O(\\epsilon^{-2} \\ln(k) (d + k) + \\min \\{\\epsilon^{-1} d k,  \\epsilon^{-4} \\ln(k) d\\})$, the best lower bound is $\\Omega(\\epsilon^{-2}(d + k \\ln(k)))$. We discuss recent progress on this problem and some hurdles that are fundamental to the use of game dynamics in statistical learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/awasthi23a/awasthi23a.pdf",
        "supp": "",
        "pdf_size": 236332,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15325099508609825817&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Google Research, Mountain View, CA, USA; University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA",
        "aff_domain": "GOOGLE.COM;BERKELEY.EDU;BERKELEY.EDU",
        "email": "GOOGLE.COM;BERKELEY.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Google;University of California, Berkeley",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://www.berkeley.edu",
        "aff_unique_abbr": "Google;UC Berkeley",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Mountain View;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c35cc1c5f9",
        "title": "Open problem: log(n) factor in \"Local Glivenko-Cantelli\"",
        "site": "https://proceedings.mlr.press/v195/cohen23b.html",
        "author": "Doron Cohen; Aryeh Kontorovich",
        "abstract": "Can the log(n) factor in the upper bound of Cohen and Kontorovich (COLT, 2023)be removed?",
        "bibtex": "@InProceedings{pmlr-v195-cohen23b,\n  title = \t {Open problem: log(n) factor in \"Local Glivenko-Cantelli},\n  author =       {Cohen, Doron and Kontorovich, Aryeh},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5934--5936},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/cohen23b/cohen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/cohen23b.html},\n  abstract = \t {Can the log(n) factor in the upper bound of Cohen and Kontorovich (COLT, 2023)be removed?}\n}",
        "pdf": "https://proceedings.mlr.press/v195/cohen23b/cohen23b.pdf",
        "supp": "",
        "pdf_size": 168431,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev; Department of Computer Science, Ben-Gurion University of the Negev",
        "aff_domain": "post.bgu.ac.il;cs.bgu.ac.il",
        "email": "post.bgu.ac.il;cs.bgu.ac.il",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "f82a2fe2b1",
        "title": "Optimal Prediction Using Expert Advice and Randomized Littlestone Dimension",
        "site": "https://proceedings.mlr.press/v195/filmus23a.html",
        "author": "Yuval Filmus; Steve Hanneke; Idan Mehalel; Shay Moran",
        "abstract": "A classical result in online learning characterizes the optimal mistake bound achievable by deterministic learners using the Littlestone dimension (Littlestone \u201988).We prove an analogous result for randomized learners: we show that the optimal expected mistake bound in learning a class $\\mathcal{H}$ equals its randomized Littlestone dimension, which we define as follows: it is the largest $d$ for which there exists a tree shattered by $\\mathcal{H}$ whose average depth is $2d$.We further study optimal mistake bounds in the agnostic case, as a function of the number of mistakes made by the best function in $\\mathcal{H}$, denoted by $k$. Towards this end we introduce the $k$-Littlestone dimension and its randomized variant, and use them to characterize the optimal deterministic and randomized mistake bounds.Quantitatively, we show that the optimal randomized mistake bound for learning a class with Littlestone dimension $d$ is $k + \\Theta (\\sqrt{k d} + d )$ (equivalently, the optimal regret is $\\Theta(\\sqrt{kd} + d$). This also implies an optimal deterministic mistake bound of $2k + O (\\sqrt{k d} + d )$, thus resolving an open question which was studied by Auer and Long [\u201999]. As an application of our theory, we revisit the classical problem of prediction using expert advice: about 30 years ago Cesa-Bianchi, Freund, Haussler, Helmbold, Schapire and Warmuth studied prediction using expert advice, provided that the best among the $n$ experts makes at most $k$ mistakes, and asked what are the optimal mistake bounds (as a function of $n$ and $k$). Cesa-Bianchi, Freund, Helmbold, and Warmuth [\u201993, \u201996] provided a nearly optimal bound for deterministic learners, and left the randomized case as an open problem. We resolve this question by providing an optimal learning rule in the randomized case, and showing that its expected mistake bound equals half of the deterministic bound, up to negligible additive terms. This improves upon previous works by Cesa-Bianchi, Freund, Haussler, Helmbold, Schapire and Warmuth [\u201993, \u201997], by Abernethy, Langford, and Warmuth [\u201906], and by Br\u00e2nzei and Peres [\u201919], which handled the regimes $k \\ll \\log n$ or $k\\gg \\log n$. In contrast, our result applies to all pairs $n,k$, and does so via a unified analysis using the randomized Littlestone dimension.In our proofs we develop and use optimal learning rules, which can be seen as natural variants of the Standard Optimal Algorithm ($\\mathsf{SOA}$) of Littlestone: a weighted variant in the agnostic case, and a probabilistic variant in the randomized case. We conclude the paper with suggested directions for future research and open questions.",
        "bibtex": "@InProceedings{pmlr-v195-filmus23a,\n  title = \t {Optimal Prediction Using Expert Advice and Randomized Littlestone Dimension},\n  author =       {Filmus, Yuval and Hanneke, Steve and Mehalel, Idan and Moran, Shay},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {773--836},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/filmus23a/filmus23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/filmus23a.html},\n  abstract = \t {A classical result in online learning characterizes the optimal mistake bound achievable by deterministic learners using the Littlestone dimension (Littlestone \u201988).We prove an analogous result for randomized learners: we show that the optimal expected mistake bound in learning a class $\\mathcal{H}$ equals its randomized Littlestone dimension, which we define as follows: it is the largest $d$ for which there exists a tree shattered by $\\mathcal{H}$ whose average depth is $2d$.We further study optimal mistake bounds in the agnostic case, as a function of the number of mistakes made by the best function in $\\mathcal{H}$, denoted by $k$. Towards this end we introduce the $k$-Littlestone dimension and its randomized variant, and use them to characterize the optimal deterministic and randomized mistake bounds.Quantitatively, we show that the optimal randomized mistake bound for learning a class with Littlestone dimension $d$ is $k + \\Theta (\\sqrt{k d} + d )$ (equivalently, the optimal regret is $\\Theta(\\sqrt{kd} + d$). This also implies an optimal deterministic mistake bound of $2k + O (\\sqrt{k d} + d )$, thus resolving an open question which was studied by Auer and Long [\u201999]. As an application of our theory, we revisit the classical problem of prediction using expert advice: about 30 years ago Cesa-Bianchi, Freund, Haussler, Helmbold, Schapire and Warmuth studied prediction using expert advice, provided that the best among the $n$ experts makes at most $k$ mistakes, and asked what are the optimal mistake bounds (as a function of $n$ and $k$). Cesa-Bianchi, Freund, Helmbold, and Warmuth [\u201993, \u201996] provided a nearly optimal bound for deterministic learners, and left the randomized case as an open problem. We resolve this question by providing an optimal learning rule in the randomized case, and showing that its expected mistake bound equals half of the deterministic bound, up to negligible additive terms. This improves upon previous works by Cesa-Bianchi, Freund, Haussler, Helmbold, Schapire and Warmuth [\u201993, \u201997], by Abernethy, Langford, and Warmuth [\u201906], and by Br\u00e2nzei and Peres [\u201919], which handled the regimes $k \\ll \\log n$ or $k\\gg \\log n$. In contrast, our result applies to all pairs $n,k$, and does so via a unified analysis using the randomized Littlestone dimension.In our proofs we develop and use optimal learning rules, which can be seen as natural variants of the Standard Optimal Algorithm ($\\mathsf{SOA}$) of Littlestone: a weighted variant in the agnostic case, and a probabilistic variant in the randomized case. We conclude the paper with suggested directions for future research and open questions.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/filmus23a/filmus23a.pdf",
        "supp": "",
        "pdf_size": 693454,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7062739671214127486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "The Henry and Marilyn Taub Faculty of Computer Science, Technion, Israel; Department of Computer Science, Purdue University, USA; The Henry and Marilyn Taub Faculty of Computer Science, Technion, Israel; The Henry and Marilyn Taub Faculty of Computer Science and Faculty of Mathematics, Technion, Israel+Google research, Israel",
        "aff_domain": "gmail.com;gmail.com;gmail.com;gmail.com",
        "email": "gmail.com;gmail.com;gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0+2",
        "aff_unique_norm": "Technion;Purdue University;Google",
        "aff_unique_dep": "Faculty of Computer Science;Department of Computer Science;Google Research",
        "aff_unique_url": "https://www.cs.technion.ac.il;https://www.purdue.edu;https://research.google",
        "aff_unique_abbr": "Technion;Purdue;Google",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0+0",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "c88f1c20ce",
        "title": "Optimal Scoring Rules for Multi-dimensional Effort",
        "site": "https://proceedings.mlr.press/v195/hartline23a.html",
        "author": "Jason D. Hartline; Liren Shan; Yingkai Li; Yifan Wu",
        "abstract": "This paper develops a framework for the design of scoring rules to optimally incentivize an agent to exert a multi-dimensional effort. This framework is a generalization to strategic agents of the classical knapsack problem (cf. Briest, Krysta, and Vocking, 2005; Singer, 2010) and it is foundational to applying algorithmic mechanism design to the classroom. The paper identifies two simple families of scoring rules that guarantee constant approximations to the optimal scoring rule. The truncated separate scoring rule is the sum of single dimensional scoring rules that is truncated to the bounded range of feasible scores. The threshold scoring rule gives the maximum score if reports exceed a threshold and zero otherwise. Approximate optimality of one or the other of these rules is similar to the bundling or selling separately result of Babaioff, Immorlica, Lucier, and Weinberg (2014). Finally, we show that the approximate optimality of the best of those two simple scoring rules is robust when the agent\u2019s choice of effort is made sequentially.",
        "bibtex": "@InProceedings{pmlr-v195-hartline23a,\n  title = \t {Optimal Scoring Rules for Multi-dimensional Effort},\n  author =       {Hartline, Jason D. and Shan, Liren and Li, Yingkai and Wu, Yifan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2624--2650},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hartline23a/hartline23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hartline23a.html},\n  abstract = \t {This paper develops a framework for the design of scoring rules to optimally incentivize an agent to exert a multi-dimensional effort. This framework is a generalization to strategic agents of the classical knapsack problem (cf. Briest, Krysta, and Vocking, 2005; Singer, 2010) and it is foundational to applying algorithmic mechanism design to the classroom. The paper identifies two simple families of scoring rules that guarantee constant approximations to the optimal scoring rule. The truncated separate scoring rule is the sum of single dimensional scoring rules that is truncated to the bounded range of feasible scores. The threshold scoring rule gives the maximum score if reports exceed a threshold and zero otherwise. Approximate optimality of one or the other of these rules is similar to the bundling or selling separately result of Babaioff, Immorlica, Lucier, and Weinberg (2014). Finally, we show that the approximate optimality of the best of those two simple scoring rules is robust when the agent\u2019s choice of effort is made sequentially.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hartline23a/hartline23a.pdf",
        "supp": "",
        "pdf_size": 361767,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4698273011086823639&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, Northwestern University; Department of Computer Science, Northwestern University; Cowles Foundation for Research in Economics, Yale University; Department of Computer Science, Northwestern University",
        "aff_domain": "northwestern.edu;u.northwestern.edu;yale.edu;u.northwestern.edu",
        "email": "northwestern.edu;u.northwestern.edu;yale.edu;u.northwestern.edu",
        "github": "",
        "project": "https://www.aeaweb.org/journals/policies/random-author-order/search?RandomAuthorsSearch%5Bsearch%5D=ZyHlOb3fJMgs",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Northwestern University;Yale University",
        "aff_unique_dep": "Department of Computer Science;Cowles Foundation for Research in Economics",
        "aff_unique_url": "https://www.northwestern.edu;https://www.yale.edu",
        "aff_unique_abbr": "NU;Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3cace26ac8",
        "title": "Oracle-Efficient Smoothed Online Learning for Piecewise Continuous Decision Making",
        "site": "https://proceedings.mlr.press/v195/block23b.html",
        "author": "Adam Block; Max Simchowitz; Alexander Rakhlin",
        "abstract": "Smoothed online learning has emerged as a popular framework to  mitigate the substantial loss in statistical and computational complexity that arises when one moves from classical to adversarial learning.  Unfortunately, for some spaces, it has been shown that efficient algorithms suffer an exponentially worse regret than that which is minimax optimal, even when the learner has access to an optimization oracle over the space.  To mitigate that exponential dependence, this work introduces a new notion of complexity, the generalized bracketing numbers, which marries constraints on the adversary to the size of the space, and shows that an instantiation of Follow-the-Perturbed-Leader can attain low regret with the number of calls to the optimization oracle scaling optimally with respect to average regret.  We then instantiate our bounds in several problems of interest, including online prediction and planning of piecewise continuous functions, which has many applications in fields as diverse as econometrics and robotics.",
        "bibtex": "@InProceedings{pmlr-v195-block23b,\n  title = \t {Oracle-Efficient Smoothed Online Learning for Piecewise Continuous Decision Making},\n  author =       {Block, Adam and Simchowitz, Max and Rakhlin, Alexander},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1618--1665},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/block23b/block23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/block23b.html},\n  abstract = \t {Smoothed online learning has emerged as a popular framework to  mitigate the substantial loss in statistical and computational complexity that arises when one moves from classical to adversarial learning.  Unfortunately, for some spaces, it has been shown that efficient algorithms suffer an exponentially worse regret than that which is minimax optimal, even when the learner has access to an optimization oracle over the space.  To mitigate that exponential dependence, this work introduces a new notion of complexity, the generalized bracketing numbers, which marries constraints on the adversary to the size of the space, and shows that an instantiation of Follow-the-Perturbed-Leader can attain low regret with the number of calls to the optimization oracle scaling optimally with respect to average regret.  We then instantiate our bounds in several problems of interest, including online prediction and planning of piecewise continuous functions, which has many applications in fields as diverse as econometrics and robotics.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/block23b/block23b.pdf",
        "supp": "",
        "pdf_size": 498112,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9875099825271110420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "MIT; MIT; MIT",
        "aff_domain": "MIT.EDU;MIT.EDU;CSAIL.MIT.EDU",
        "email": "MIT.EDU;MIT.EDU;CSAIL.MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "782910d2e1",
        "title": "Orthogonal Directions Constrained Gradient Method: from non-linear equality constraints to Stiefel manifold",
        "site": "https://proceedings.mlr.press/v195/schechtman23a.html",
        "author": "Sholom Schechtman; Daniil Tiapkin; Michael Muehlebach; \u00c9ric Moulines",
        "abstract": "We consider the problem of minimizing a non-convex function over a smooth manifold M. We propose a novel algorithm, the Orthogonal Directions Constrained Gradient Method (ODCGM), which only requires computing a projection onto a vector space. ODCGM is infeasible but the iterates are constantly pulled towards the manifold, ensuring the convergence of ODCGM towards M. ODCGM is much simpler to implement than the classical methods which require the computation of a retraction. Moreover, we show that ODCGM exhibits the near-optimal oracle complexities O(1/\u03b5^{-2}) and O(1/\u03b5^{-4}) in the deterministic and stochastic cases, respectively. Furthermore, we establish that, under an appropriate choice of the projection metric, our method recovers the landing algorithm of Ablin and Peyr\u00e9 (2022), a recently introduced algorithm for optimization over the Stiefel manifold. As a result, we significantly extend the analysis of Ablin and Peyr\u00e9 (2022), establishingnear-optimal rates both in deterministic and stochastic frameworks. Finally, we perform numerical experiments, which shows the efficiency of ODCGM in a high-dimensional setting.",
        "bibtex": "@InProceedings{pmlr-v195-schechtman23a,\n  title = \t {Orthogonal Directions Constrained Gradient Method: from non-linear equality constraints to Stiefel manifold},\n  author =       {Schechtman, Sholom and Tiapkin, Daniil and Muehlebach, Michael and Moulines, {\\'E}ric},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1228--1258},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/schechtman23a/schechtman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/schechtman23a.html},\n  abstract = \t {We consider the problem of minimizing a non-convex function over a smooth manifold M. We propose a novel algorithm, the Orthogonal Directions Constrained Gradient Method (ODCGM), which only requires computing a projection onto a vector space. ODCGM is infeasible but the iterates are constantly pulled towards the manifold, ensuring the convergence of ODCGM towards M. ODCGM is much simpler to implement than the classical methods which require the computation of a retraction. Moreover, we show that ODCGM exhibits the near-optimal oracle complexities O(1/\u03b5^{-2}) and O(1/\u03b5^{-4}) in the deterministic and stochastic cases, respectively. Furthermore, we establish that, under an appropriate choice of the projection metric, our method recovers the landing algorithm of Ablin and Peyr\u00e9 (2022), a recently introduced algorithm for optimization over the Stiefel manifold. As a result, we significantly extend the analysis of Ablin and Peyr\u00e9 (2022), establishingnear-optimal rates both in deterministic and stochastic frameworks. Finally, we perform numerical experiments, which shows the efficiency of ODCGM in a high-dimensional setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/schechtman23a/schechtman23a.pdf",
        "supp": "",
        "pdf_size": 642967,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16484593048325261580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "SAMOVAR, T\u00b4el\u00b4ecom Sudparis, Institut Polytechnique de Paris, 91120 Palaiseau, France; HSE University, Pokrovsky Blvd, 11, Moscow, Russia, 109028; Max Planck Ring 4, 72076 Tuebingen, Germany; CMAP, \u00b4Ecole Polytechnique, Route de Saclay, 91128, Palaiseau",
        "aff_domain": "TELECOM-SUDPARIS.EU;HSE.RU;TUEBINGEN.MPG.DE;POLYTECHNIQUE.EDU",
        "email": "TELECOM-SUDPARIS.EU;HSE.RU;TUEBINGEN.MPG.DE;POLYTECHNIQUE.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Institut Polytechnique de Paris;HSE University;Max Planck Institute;Ecole Polytechnique",
        "aff_unique_dep": "SAMOVAR;;;CMAP",
        "aff_unique_url": "https://www.institutpolytechnique.de;https://www.hse.ru;https://www.mpg.de;https://www.ecolepolytechnique.fr",
        "aff_unique_abbr": "IP Paris;HSE;MPG;Polytechnique",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Palaiseau;Moscow;Tuebingen",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "France;Russian Federation;Germany"
    },
    {
        "id": "bb538348f2",
        "title": "Over-Parameterization Exponentially Slows Down Gradient Descent for Learning a Single Neuron",
        "site": "https://proceedings.mlr.press/v195/xu23a.html",
        "author": "Weihang Xu; Simon Du",
        "abstract": "We revisit the canonical problem of learning a single neuron with ReLU activation under Gaussian input with square loss. We particularly focus on the over-parameterization setting where the student network has $n\\ge 2$ neurons. We prove the global convergence of randomly initialized gradient descent with a $O\\left(T^{-3}\\right)$ rate. This is the first global convergence result for this problem beyond the exact-parameterization setting ($n=1$) in which the gradient descent enjoys an $\\exp(-\\Omega(T))$ rate. Perhaps surprisingly, we further present an $\\Omega\\left(T^{-3}\\right)$ lower bound for randomly initialized gradient flow in the over-parameterization setting. These two bounds jointly give an exact characterization of the convergence rate and imply, for the first time, that \\emph{over-parameterization can exponentially slow down the convergence rate}. To prove the global convergence, we need to tackle the interactions among student neurons in the gradient descent dynamics, which are not present in the exact-parameterization case. We use a  three-phase structure to analyze GD\u2019s dynamics. Along the way, we prove gradient descent automatically balances student neurons and uses this property to deal with the non-smoothness of the objective function. To prove the convergence rate lower bound, we construct a novel potential function that characterizes the pairwise distances between the student neurons (which cannot be done in the exact-parameterization case). We show this potential function converges slowly, which implies the slow convergence rate of the loss function.",
        "bibtex": "@InProceedings{pmlr-v195-xu23a,\n  title = \t {Over-Parameterization Exponentially Slows Down Gradient Descent for Learning a Single Neuron},\n  author =       {Xu, Weihang and Du, Simon},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1155--1198},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/xu23a/xu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/xu23a.html},\n  abstract = \t {We revisit the canonical problem of learning a single neuron with ReLU activation under Gaussian input with square loss. We particularly focus on the over-parameterization setting where the student network has $n\\ge 2$ neurons. We prove the global convergence of randomly initialized gradient descent with a $O\\left(T^{-3}\\right)$ rate. This is the first global convergence result for this problem beyond the exact-parameterization setting ($n=1$) in which the gradient descent enjoys an $\\exp(-\\Omega(T))$ rate. Perhaps surprisingly, we further present an $\\Omega\\left(T^{-3}\\right)$ lower bound for randomly initialized gradient flow in the over-parameterization setting. These two bounds jointly give an exact characterization of the convergence rate and imply, for the first time, that \\emph{over-parameterization can exponentially slow down the convergence rate}. To prove the global convergence, we need to tackle the interactions among student neurons in the gradient descent dynamics, which are not present in the exact-parameterization case. We use a  three-phase structure to analyze GD\u2019s dynamics. Along the way, we prove gradient descent automatically balances student neurons and uses this property to deal with the non-smoothness of the objective function. To prove the convergence rate lower bound, we construct a novel potential function that characterizes the pairwise distances between the student neurons (which cannot be done in the exact-parameterization case). We show this potential function converges slowly, which implies the slow convergence rate of the loss function.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/xu23a/xu23a.pdf",
        "supp": "",
        "pdf_size": 616762,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18446102592109762563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Tsinghua University; University of Washington",
        "aff_domain": "outlook.com;cs.washington.edu",
        "email": "outlook.com;cs.washington.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Tsinghua University;University of Washington",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.washington.edu",
        "aff_unique_abbr": "THU;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "1c93d5fdc9",
        "title": "PAC Verification of Statistical Algorithms",
        "site": "https://proceedings.mlr.press/v195/mutreja23a.html",
        "author": "Saachi Mutreja; Jonathan Shafer",
        "abstract": "Goldwasser et al. (2021) recently proposed the setting of PAC verification, where a hypothesis (machine learning model) that purportedly satisfies the agnostic PAC learning objective is verified using an interactive proof. In this paper we develop this notion further in a number of ways. First, we prove a lower bound of $\\Omega(\\sqrt{d}/\\varepsilon^2)$ i.i.d. samples for PAC verification of hypothesis classes of VC dimension $d$. Second, we present a protocol for PAC verification of unions of intervals over $\\mathbb{R}$ that improves upon their proposed protocol for that task, and matches our lower bound\u2019s dependence on $d$. Third, we introduce a natural generalization of their definition to verification of general statistical algorithms, which is applicable to a wider variety of settings beyond agnostic PAC learning. Showcasing our proposed definition, our final result is a protocol for the verification of statistical query algorithms that satisfy a combinatorial constraint on their queries.",
        "bibtex": "@InProceedings{pmlr-v195-mutreja23a,\n  title = \t {PAC Verification of Statistical Algorithms},\n  author =       {Mutreja, Saachi and Shafer, Jonathan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5021--5043},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mutreja23a/mutreja23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mutreja23a.html},\n  abstract = \t {Goldwasser et al. (2021) recently proposed the setting of PAC verification, where a hypothesis (machine learning model) that purportedly satisfies the agnostic PAC learning objective is verified using an interactive proof. In this paper we develop this notion further in a number of ways. First, we prove a lower bound of $\\Omega(\\sqrt{d}/\\varepsilon^2)$ i.i.d. samples for PAC verification of hypothesis classes of VC dimension $d$. Second, we present a protocol for PAC verification of unions of intervals over $\\mathbb{R}$ that improves upon their proposed protocol for that task, and matches our lower bound\u2019s dependence on $d$. Third, we introduce a natural generalization of their definition to verification of general statistical algorithms, which is applicable to a wider variety of settings beyond agnostic PAC learning. Showcasing our proposed definition, our final result is a protocol for the verification of statistical query algorithms that satisfy a combinatorial constraint on their queries.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mutreja23a/mutreja23a.pdf",
        "supp": "",
        "pdf_size": 387863,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1139612774601061026&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "BERKELEY.EDU;BERKELEY.EDU",
        "email": "BERKELEY.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "74cdd7c855",
        "title": "Precise Asymptotic Analysis of Deep Random Feature Models",
        "site": "https://proceedings.mlr.press/v195/bosch23a.html",
        "author": "David Bosch; Ashkan Panahi; Babak Hassibi",
        "abstract": "We provide exact asymptotic expressions for the performance of regression by an $L-$layer deep random feature (RF) model, where the input is mapped through multiple random embedding and non-linear activation functions. For this purpose, we establish two key steps: First, we prove a novel universality result for RF models and deterministic data, by which we demonstrate that a deep random feature model is equivalent to a deep linear Gaussian model that matches it in the first and second moments, at each layer. Second, we make use of the convex Gaussian Min-Max theorem multiple times to obtain the exact behavior of deep RF models.  We further characterize the variation of the eigendistribution in different layers of the equivalent Gaussian model, demonstrating that depth has a tangible effect on model performance despite the fact that only the last layer of the model is being trained.",
        "bibtex": "@InProceedings{pmlr-v195-bosch23a,\n  title = \t {Precise Asymptotic Analysis of Deep Random Feature Models},\n  author =       {Bosch, David and Panahi, Ashkan and Hassibi, Babak},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4132--4179},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bosch23a/bosch23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bosch23a.html},\n  abstract = \t {We provide exact asymptotic expressions for the performance of regression by an $L-$layer deep random feature (RF) model, where the input is mapped through multiple random embedding and non-linear activation functions. For this purpose, we establish two key steps: First, we prove a novel universality result for RF models and deterministic data, by which we demonstrate that a deep random feature model is equivalent to a deep linear Gaussian model that matches it in the first and second moments, at each layer. Second, we make use of the convex Gaussian Min-Max theorem multiple times to obtain the exact behavior of deep RF models.  We further characterize the variation of the eigendistribution in different layers of the equivalent Gaussian model, demonstrating that depth has a tangible effect on model performance despite the fact that only the last layer of the model is being trained. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/bosch23a/bosch23a.pdf",
        "supp": "",
        "pdf_size": 600799,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1841630741297086626&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Data Science and AI, Computer Science and Engineering, Chalmers University of Technology; Department of Data Science and AI, Computer Science and Engineering, Chalmers University of Technology; Department of Electrical Engineering, California Institute of Technology",
        "aff_domain": "CHALMERS.SE;CHALMERS.SE;CALTECH.EDU",
        "email": "CHALMERS.SE;CHALMERS.SE;CALTECH.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Chalmers University of Technology;California Institute of Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.chalmers.se;https://www.caltech.edu",
        "aff_unique_abbr": "Chalmers;Caltech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "e08052b54a",
        "title": "Private Covariance Approximation and Eigenvalue-Gap Bounds for Complex Gaussian Perturbations",
        "site": "https://proceedings.mlr.press/v195/mangoubi23a.html",
        "author": "Oren Mangoubi; Nisheeth K. Vishnoi",
        "abstract": "We consider the problem of approximating a $d \\times d$ covariance matrix $M$ with a rank-$k$ matrix under $(\\varepsilon,\\delta)$-differential privacy. We present and analyze a complex variant of the Gaussian mechanism and show that the Frobenius norm of the difference between the matrix output by this mechanism and the best rank-$k$ approximation to $M$ is bounded by roughly $\\tilde{O}(\\sqrt{kd})$, whenever there is an appropriately large gap between the $k$\u2019th and the $k+1$\u2019th eigenvalues of $M$. This improves on previous work that requires that the gap between every pair of top-$k$ eigenvalues of $M$ is at least $\\sqrt{d}$ for a similar bound. Our analysis leverages the fact that the eigenvalues of complex matrix Brownian motion repel more than in the real case, and uses Dyson\u2019s stochastic differential equations governing the evolution of its eigenvalues to show that the eigenvalues of the matrix $M$ perturbed by complex Gaussian noise have large gaps with high probability. Our results contribute to the analysis of low-rank approximations under average-case perturbations and to an understanding of eigenvalue gaps for random matrices, which may be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v195-mangoubi23a,\n  title = \t {Private Covariance Approximation and Eigenvalue-Gap Bounds for Complex Gaussian Perturbations},\n  author =       {Mangoubi, Oren and Vishnoi, Nisheeth K.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1522--1587},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mangoubi23a/mangoubi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mangoubi23a.html},\n  abstract = \t {We consider the problem of approximating a $d \\times d$ covariance matrix $M$ with a rank-$k$ matrix under $(\\varepsilon,\\delta)$-differential privacy. We present and analyze a complex variant of the Gaussian mechanism and show that the Frobenius norm of the difference between the matrix output by this mechanism and the best rank-$k$ approximation to $M$ is bounded by roughly $\\tilde{O}(\\sqrt{kd})$, whenever there is an appropriately large gap between the $k$\u2019th and the $k+1$\u2019th eigenvalues of $M$. This improves on previous work that requires that the gap between every pair of top-$k$ eigenvalues of $M$ is at least $\\sqrt{d}$ for a similar bound. Our analysis leverages the fact that the eigenvalues of complex matrix Brownian motion repel more than in the real case, and uses Dyson\u2019s stochastic differential equations governing the evolution of its eigenvalues to show that the eigenvalues of the matrix $M$ perturbed by complex Gaussian noise have large gaps with high probability. Our results contribute to the analysis of low-rank approximations under average-case perturbations and to an understanding of eigenvalue gaps for random matrices, which may be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mangoubi23a/mangoubi23a.pdf",
        "supp": "",
        "pdf_size": 956085,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8417071671148207097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Worcester Polytechnic Institute; Yale University",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Worcester Polytechnic Institute;Yale University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wpi.edu;https://www.yale.edu",
        "aff_unique_abbr": "WPI;Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b7f74b2df5",
        "title": "Private Online Prediction from Experts:  Separations and Faster Rates",
        "site": "https://proceedings.mlr.press/v195/asi23a.html",
        "author": "Hilal Asi; Vitaly Feldman; Tomer Koren; Kunal Talwar",
        "abstract": "Online prediction from experts is a fundamental problem in machine learning and several works have studied this problem under privacy constraints. We propose and analyze new algorithms for this problem that improve over the regret bounds of the best existing algorithms for non-adaptive adversaries. For approximate differential privacy, our algorithms achieve regret bounds of $\\wt O(\\sqrt{T \\log d} + \\log d/\\eps)$ for the stochastic setting and $\\wt O(\\sqrt{T \\log d} + T^{1/3} \\log d/\\eps)$ for oblivious adversaries (where $d$ is the number of experts). For pure DP, our algorithms are the first to obtain sub-linear regret for oblivious adversaries in the high-dimensional regime $d \\ge T$. Moreover, we prove new lower bounds for adaptive adversaries. Our results imply that unlike the non-private setting, there is a strong separation between the optimal regret for adaptive and non-adaptive adversaries for this problem. Our lower bounds also show a separation between pure and approximate differential privacy for adaptive adversaries where the latter is necessary to achieve the non-private $O(\\sqrt{T})$ regret.",
        "bibtex": "@InProceedings{pmlr-v195-asi23a,\n  title = \t {Private Online Prediction from Experts:  Separations and Faster Rates},\n  author =       {Asi, Hilal and Feldman, Vitaly and Koren, Tomer and Talwar, Kunal},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {674--699},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/asi23a/asi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/asi23a.html},\n  abstract = \t {Online prediction from experts is a fundamental problem in machine learning and several works have studied this problem under privacy constraints. We propose and analyze new algorithms for this problem that improve over the regret bounds of the best existing algorithms for non-adaptive adversaries. For approximate differential privacy, our algorithms achieve regret bounds of $\\wt O(\\sqrt{T \\log d} + \\log d/\\eps)$ for the stochastic setting and $\\wt O(\\sqrt{T \\log d} + T^{1/3} \\log d/\\eps)$ for oblivious adversaries (where $d$ is the number of experts). For pure DP, our algorithms are the first to obtain sub-linear regret for oblivious adversaries in the high-dimensional regime $d \\ge T$. Moreover, we prove new lower bounds for adaptive adversaries. Our results imply that unlike the non-private setting, there is a strong separation between the optimal regret for adaptive and non-adaptive adversaries for this problem. Our lower bounds also show a separation between pure and approximate differential privacy for adaptive adversaries where the latter is necessary to achieve the non-private $O(\\sqrt{T})$ regret.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/asi23a/asi23a.pdf",
        "supp": "",
        "pdf_size": 362047,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7458851503997495747&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Apple; Apple; Tel Aviv University; Apple",
        "aff_domain": "gmail.com;gmail.com;tauex.tau.ac.il;kunaltalwar.org",
        "email": "gmail.com;gmail.com;tauex.tau.ac.il;kunaltalwar.org",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Apple;Tel Aviv University",
        "aff_unique_dep": "Apple Inc.;",
        "aff_unique_url": "https://www.apple.com;https://www.tau.ac.il",
        "aff_unique_abbr": "Apple;TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "2b8b6b3666",
        "title": "Projection-free Online Exp-concave Optimization",
        "site": "https://proceedings.mlr.press/v195/garber23a.html",
        "author": "Dan Garber; Ben Kretzu",
        "abstract": "We consider the setting of online convex optimization (OCO) with \\textit{exp-concave} losses. The best regret bound known for this setting is $O(n\\log{}T)$, where $n$ is the dimension and $T$ is the number of prediction rounds (treating all other quantities as constants and assuming $T$ is sufficiently large), and is attainable via the well-known Online Newton Step algorithm (ONS). However, ONS requires on each iteration to compute a projection (according to some matrix-induced norm) onto the feasible convex set, which is often computationally prohibitive in high-dimensional settings and when the feasible set admits a non-trivial structure. In this work we consider projection-free online algorithms for  exp-concave and smooth losses, where by projection-free we refer to algorithms that rely only on the availability of a linear optimization oracle (LOO) for the feasible set, which in many applications of interest admits much more efficient implementations than a projection oracle. We present an LOO-based ONS-style algorithm, which using overall $O(T)$ calls to a LOO, guarantees in worst case regret bounded by $\\widetilde{O}(n^{2/3}T^{2/3})$ (ignoring all quantities except for $n,T$). However, our algorithm is most interesting in an important and plausible low-dimensional data scenario: if the gradients  (approximately) span a subspace of dimension at most $\\rho$, $\\rho << n$, the regret bound improves to $\\widetilde{O}(\\rho^{2/3}T^{2/3})$, and by applying standard deterministic sketching techniques, both the space and average additional per-iteration runtime requirements are only $O(\\rho{}n)$ (instead of $O(n^2)$). This  improves upon recently proposed LOO-based algorithms for OCO which, while having the same state-of-the-art dependence on the horizon $T$, suffer from regret/oracle complexity that scales with $\\sqrt{n}$ or worse.",
        "bibtex": "@InProceedings{pmlr-v195-garber23a,\n  title = \t {Projection-free Online Exp-concave Optimization},\n  author =       {Garber, Dan and Kretzu, Ben},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1259--1284},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/garber23a/garber23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/garber23a.html},\n  abstract = \t {We consider the setting of online convex optimization (OCO) with \\textit{exp-concave} losses. The best regret bound known for this setting is $O(n\\log{}T)$, where $n$ is the dimension and $T$ is the number of prediction rounds (treating all other quantities as constants and assuming $T$ is sufficiently large), and is attainable via the well-known Online Newton Step algorithm (ONS). However, ONS requires on each iteration to compute a projection (according to some matrix-induced norm) onto the feasible convex set, which is often computationally prohibitive in high-dimensional settings and when the feasible set admits a non-trivial structure. In this work we consider projection-free online algorithms for  exp-concave and smooth losses, where by projection-free we refer to algorithms that rely only on the availability of a linear optimization oracle (LOO) for the feasible set, which in many applications of interest admits much more efficient implementations than a projection oracle. We present an LOO-based ONS-style algorithm, which using overall $O(T)$ calls to a LOO, guarantees in worst case regret bounded by $\\widetilde{O}(n^{2/3}T^{2/3})$ (ignoring all quantities except for $n,T$). However, our algorithm is most interesting in an important and plausible low-dimensional data scenario: if the gradients  (approximately) span a subspace of dimension at most $\\rho$, $\\rho << n$, the regret bound improves to $\\widetilde{O}(\\rho^{2/3}T^{2/3})$, and by applying standard deterministic sketching techniques, both the space and average additional per-iteration runtime requirements are only $O(\\rho{}n)$ (instead of $O(n^2)$). This  improves upon recently proposed LOO-based algorithms for OCO which, while having the same state-of-the-art dependence on the horizon $T$, suffer from regret/oracle complexity that scales with $\\sqrt{n}$ or worse.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/garber23a/garber23a.pdf",
        "supp": "",
        "pdf_size": 399756,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9214571342027100196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Technion - Israel Institute of Technology; Technion - Israel Institute of Technology",
        "aff_domain": "TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL",
        "email": "TECHNION.AC.IL;CAMPUS.TECHNION.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "074485f64d",
        "title": "Proper Losses, Moduli of Convexity, and Surrogate Regret Bounds",
        "site": "https://proceedings.mlr.press/v195/bao23a.html",
        "author": "Han Bao",
        "abstract": "Proper losses (or proper scoring rules) have been used for over half a century to elicit users\u2019 subjective probability from the observations. In the recent machine learning community, we often tackle downstream tasks such as classification and bipartite ranking with the elicited probabilities. Here, we engage in assessing the quality of the elicited probabilities with different proper losses, which can be characterized by surrogate regret bounds to describe the convergence speed of an estimated probability to the optimal one when optimizing a proper loss. This work contributes to a sharp analysis of surrogate regret bounds in two ways. First, we provide general surrogate regret bounds for proper losses measured by the $L^1$ distance. This abstraction eschews a tailor-made analysis of each downstream task and delineates how universally a loss function operates. Our analysis relies on a classical mathematical tool known as the moduli of convexity, which is of independent interest per se. Second, we evaluate the surrogate regret bounds with polynomials to identify the quantitative convergence rate. These devices enable us to compare different losses, with which we can confirm that the lower bound of the surrogate regret bounds is $\\Omega(\\epsilon^{1/2})$ for popular loss functions.",
        "bibtex": "@InProceedings{pmlr-v195-bao23a,\n  title = \t {Proper Losses, Moduli of Convexity, and Surrogate Regret Bounds},\n  author =       {Bao, Han},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {525--547},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/bao23a/bao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/bao23a.html},\n  abstract = \t {Proper losses (or proper scoring rules) have been used for over half a century to elicit users\u2019 subjective probability from the observations. In the recent machine learning community, we often tackle downstream tasks such as classification and bipartite ranking with the elicited probabilities. Here, we engage in assessing the quality of the elicited probabilities with different proper losses, which can be characterized by surrogate regret bounds to describe the convergence speed of an estimated probability to the optimal one when optimizing a proper loss. This work contributes to a sharp analysis of surrogate regret bounds in two ways. First, we provide general surrogate regret bounds for proper losses measured by the $L^1$ distance. This abstraction eschews a tailor-made analysis of each downstream task and delineates how universally a loss function operates. Our analysis relies on a classical mathematical tool known as the moduli of convexity, which is of independent interest per se. Second, we evaluate the surrogate regret bounds with polynomials to identify the quantitative convergence rate. These devices enable us to compare different losses, with which we can confirm that the lower bound of the surrogate regret bounds is $\\Omega(\\epsilon^{1/2})$ for popular loss functions. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/bao23a/bao23a.pdf",
        "supp": "",
        "pdf_size": 399581,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12222095789809963585&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Kyoto University",
        "aff_domain": "I.KYOTO-U.AC.JP",
        "email": "I.KYOTO-U.AC.JP",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Kyoto University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "Kyoto U",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "b63fc3e096",
        "title": "Provable Benefits of Representational Transfer in Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v195/agarwal23b.html",
        "author": "Alekh Agarwal; Yuda Song; Wen Sun; Kaiwen Wang; Mengdi Wang; Xuezhou Zhang",
        "abstract": "We study the problem of representational transfer in RL, where an agent first pretrains in a number of \\emph{source tasks} to discover a shared representation, which is subsequently used to learn a good policy in a \\emph{target task}. We propose a new notion of task relatedness between source and target tasks, and develop a novel approach for representational transfer under this assumption. Concretely, we show that given a generative access to source tasks, we can discover a representation, using which subsequent linear RL techniques quickly converge to a near-optimal policy in the target task. The sample complexity is close to knowing the ground truth features in the target task, and comparable to prior representation learning results in the source tasks. We complement our positive results with lower bounds without generative access, and validate our findings with empirical evaluation on rich observation MDPs that require deep exploration. In our experiments, we observe speed up in learning in the target by pre-training, and also validate the need for generative access in source tasks.",
        "bibtex": "@InProceedings{pmlr-v195-agarwal23b,\n  title = \t {Provable Benefits of Representational Transfer in Reinforcement Learning},\n  author =       {Agarwal, Alekh and Song, Yuda and Sun, Wen and Wang, Kaiwen and Wang, Mengdi and Zhang, Xuezhou},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2114--2187},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/agarwal23b/agarwal23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/agarwal23b.html},\n  abstract = \t {We study the problem of representational transfer in RL, where an agent first pretrains in a number of \\emph{source tasks} to discover a shared representation, which is subsequently used to learn a good policy in a \\emph{target task}. We propose a new notion of task relatedness between source and target tasks, and develop a novel approach for representational transfer under this assumption. Concretely, we show that given a generative access to source tasks, we can discover a representation, using which subsequent linear RL techniques quickly converge to a near-optimal policy in the target task. The sample complexity is close to knowing the ground truth features in the target task, and comparable to prior representation learning results in the source tasks. We complement our positive results with lower bounds without generative access, and validate our findings with empirical evaluation on rich observation MDPs that require deep exploration. In our experiments, we observe speed up in learning in the target by pre-training, and also validate the need for generative access in source tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/agarwal23b/agarwal23b.pdf",
        "supp": "",
        "pdf_size": 1222846,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7249427889127022455&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Google; Carnegie Mellon University; Cornell University; Cornell University; Princeton University; Princeton University",
        "aff_domain": "google.com;andrew.cmu.edu;cornell.edu;cornell.edu;princeton.edu;princeton.edu",
        "email": "google.com;andrew.cmu.edu;cornell.edu;cornell.edu;princeton.edu;princeton.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2;3;3",
        "aff_unique_norm": "Google;Carnegie Mellon University;Cornell University;Princeton University",
        "aff_unique_dep": "Google;;;",
        "aff_unique_url": "https://www.google.com;https://www.cmu.edu;https://www.cornell.edu;https://www.princeton.edu",
        "aff_unique_abbr": "Google;CMU;Cornell;Princeton",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0051a9819d",
        "title": "Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal",
        "site": "https://proceedings.mlr.press/v195/blanchard23a.html",
        "author": "Mo\u00efse Blanchard; Junhui Zhang; Patrick Jaillet",
        "abstract": "We give query complexity lower bounds for convex optimization and the related feasibility problem. We show that quadratic memory is necessary to achieve the optimal oracle complexity for first-order convex optimization. In particular, this shows that center-of-mass cutting-planes algorithms in dimension $d$ which use $\\tilde O(d^2)$ memory and $\\tilde O(d)$ queries are Pareto-optimal for both convex optimization and the feasibility problem, up to logarithmic factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions over the unit ball to $1/d^4$ accuracy, any deterministic first-order algorithms using at most $d^{2-\\delta}$ bits of memory must make $\\tilde\\Omega(d^{1+\\delta/3})$ queries, for any $\\delta\\in[0,1]$. For the feasibility problem, in which an algorithm only has access to a separation oracle, we show a stronger trade-off: for at most $d^{2-\\delta}$ memory, the number of queries required is $\\tilde\\Omega(d^{1+\\delta})$. This resolves a COLT 2019 open problem of Woodworth and Srebro.",
        "bibtex": "@InProceedings{pmlr-v195-blanchard23a,\n  title = \t {Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal},\n  author =       {Blanchard, Mo{\\\"i}se and Zhang, Junhui and Jaillet, Patrick},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4696--4736},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/blanchard23a/blanchard23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/blanchard23a.html},\n  abstract = \t {We give query complexity lower bounds for convex optimization and the related feasibility problem. We show that quadratic memory is necessary to achieve the optimal oracle complexity for first-order convex optimization. In particular, this shows that center-of-mass cutting-planes algorithms in dimension $d$ which use $\\tilde O(d^2)$ memory and $\\tilde O(d)$ queries are Pareto-optimal for both convex optimization and the feasibility problem, up to logarithmic factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions over the unit ball to $1/d^4$ accuracy, any deterministic first-order algorithms using at most $d^{2-\\delta}$ bits of memory must make $\\tilde\\Omega(d^{1+\\delta/3})$ queries, for any $\\delta\\in[0,1]$. For the feasibility problem, in which an algorithm only has access to a separation oracle, we show a stronger trade-off: for at most $d^{2-\\delta}$ memory, the number of queries required is $\\tilde\\Omega(d^{1+\\delta})$. This resolves a COLT 2019 open problem of Woodworth and Srebro.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/blanchard23a/blanchard23a.pdf",
        "supp": "",
        "pdf_size": 521002,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5875620243684142226&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;mit.edu;mit.edu",
        "email": "mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f05735ec20",
        "title": "Quantum Channel Certification with Incoherent Measurements",
        "site": "https://proceedings.mlr.press/v195/fawzi23a.html",
        "author": "Omar Fawzi; Nicolas Flammarion; Aur\u00e9lien Garivier; Aadil Oufkir",
        "abstract": "In the problem of quantum channel certification, we have black box access to a quantum process and would like to decide if this process matches some predefined specification or is $\\eps$-far from this specification. The objective is to achieve this task while minimizing the number of times the black box is used. Note that the state certification problem is a special case where the black box has no input. Here, we focus on two relevant extreme cases. The first one is when the predefined specification is a unitary channel, e.g., a gate in a quantum circuit.  In this case, we show that testing whether the black box is described by a fixed unitary or $\\eps$-far from it in the trace norm requires $\\Theta(d/\\eps^2)$ uses of the black box. The second setting we consider is when the predefined specification is a completely depolarizing channels with input dimension $\\din$ and output dimension $\\dout$. In this case, we prove that, in the non-adaptive setting, $\\Tilde{\\Theta}(\\din^2\\dout^{1.5}/\\eps^2)$ uses of the channel are necessary and sufficient to verify whether it is equal to the depolarizing channel or $\\eps$-far from it in the diamond norm. Finally, we prove a lower bound of $\\Omega(\\din^2\\dout/\\eps^2)$ for this problem in the adaptive setting. Note that the special case $\\din = 1$ corresponds to the well-studied quantum identity testing problem.",
        "bibtex": "@InProceedings{pmlr-v195-fawzi23a,\n  title = \t {Quantum Channel Certification with Incoherent Measurements},\n  author =       {Fawzi, Omar and Flammarion, Nicolas and Garivier, Aur{\\'e}lien and Oufkir, Aadil},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1822--1884},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/fawzi23a/fawzi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/fawzi23a.html},\n  abstract = \t {In the problem of quantum channel certification, we have black box access to a quantum process and would like to decide if this process matches some predefined specification or is $\\eps$-far from this specification. The objective is to achieve this task while minimizing the number of times the black box is used. Note that the state certification problem is a special case where the black box has no input. Here, we focus on two relevant extreme cases. The first one is when the predefined specification is a unitary channel, e.g., a gate in a quantum circuit.  In this case, we show that testing whether the black box is described by a fixed unitary or $\\eps$-far from it in the trace norm requires $\\Theta(d/\\eps^2)$ uses of the black box. The second setting we consider is when the predefined specification is a completely depolarizing channels with input dimension $\\din$ and output dimension $\\dout$. In this case, we prove that, in the non-adaptive setting, $\\Tilde{\\Theta}(\\din^2\\dout^{1.5}/\\eps^2)$ uses of the channel are necessary and sufficient to verify whether it is equal to the depolarizing channel or $\\eps$-far from it in the diamond norm. Finally, we prove a lower bound of $\\Omega(\\din^2\\dout/\\eps^2)$ for this problem in the adaptive setting. Note that the special case $\\din = 1$ corresponds to the well-studied quantum identity testing problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/fawzi23a/fawzi23a.pdf",
        "supp": "",
        "pdf_size": 580541,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2165332386189604521&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Univ Lyon, Inria, ENS Lyon, UCBL, LIP, F-69342, Lyon Cedex 07, France; EPFL, Lausanne, Switzerland; Univ Lyon, ENS de Lyon, UMPA UMR 5669, F-69364 Lyon Cedex 07, France; Univ Lyon, Inria, ENS Lyon, UCBL, LIP, F-69342, Lyon Cedex 07, France",
        "aff_domain": "ENS-LYON.FR;EPFL.CH;ENS-LYON.FR;ENS-LYON.FR",
        "email": "ENS-LYON.FR;EPFL.CH;ENS-LYON.FR;ENS-LYON.FR",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University Lyon;EPFL;ENS de Lyon",
        "aff_unique_dep": ";;UMPA UMR 5669",
        "aff_unique_url": "https://www.universite-lyon.fr;https://www.epfl.ch;https://www.ens-lyon.fr",
        "aff_unique_abbr": "Univ Lyon;EPFL;ENS de Lyon",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Lyon;Lausanne",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;Switzerland"
    },
    {
        "id": "bc5299233a",
        "title": "Quasi-Newton Steps for Efficient Online Exp-Concave Optimization",
        "site": "https://proceedings.mlr.press/v195/mhammedi23a.html",
        "author": "Zakaria Mhammedi; Khashayar Gatmiry",
        "abstract": "The aim of this paper is to design computationally-efficient and optimal algorithms for the online and stochastic exp-concave optimization settings. Typical algorithms for these settings, such as the Online Newton Step (ONS), can guarantee a $O(d\\ln T)$ bound on their regret after $T$ rounds, where $d$ is the dimension of the feasible set. However, such algorithms perform so-called \\emph{generalized projections} whenever their iterates step outside the feasible set. Such generalized projections require $\\Omega(d^3)$ arithmetic operations even for simple sets such a Euclidean ball, making the total runtime of ONS of order $d^3 T$ after $T$ rounds, in the worst-case. In this paper, we side-step generalized projections by using a self-concordant barrier as a regularizer to compute the Newton steps. This ensures that the iterates are always within the feasible set without requiring projections. This approach still requires the computation of the inverse of the Hessian of the barrier at every step. However, using stability properties of the Newton iterates, we show that the inverse of the Hessians can be efficiently approximated via Taylor expansions for most rounds, resulting in a $\\widetilde O(d^2 T +d^\\omega \\sqrt{T})$ total computational complexity, where $\\omega\\in(2,3]$ is the exponent of matrix multiplication. In the stochastic setting, we show that this translates into a $\\widetilde O(d^3/\\varepsilon)$ computational complexity for finding an $\\varepsilon$-optimal point, answering an open question by Koren 2013. We first prove these new results for the simple case where the feasible set is a Euclidean ball. Then, to move to general convex sets, we use a reduction to Online Convex Optimization over the Euclidean ball. Our final algorithm for general convex sets can be viewed as a more computationally-efficient version of ONS.",
        "bibtex": "@InProceedings{pmlr-v195-mhammedi23a,\n  title = \t {Quasi-Newton Steps for Efficient Online Exp-Concave Optimization},\n  author =       {Mhammedi, Zakaria and Gatmiry, Khashayar},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4473--4503},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mhammedi23a/mhammedi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mhammedi23a.html},\n  abstract = \t {The aim of this paper is to design computationally-efficient and optimal algorithms for the online and stochastic exp-concave optimization settings. Typical algorithms for these settings, such as the Online Newton Step (ONS), can guarantee a $O(d\\ln T)$ bound on their regret after $T$ rounds, where $d$ is the dimension of the feasible set. However, such algorithms perform so-called \\emph{generalized projections} whenever their iterates step outside the feasible set. Such generalized projections require $\\Omega(d^3)$ arithmetic operations even for simple sets such a Euclidean ball, making the total runtime of ONS of order $d^3 T$ after $T$ rounds, in the worst-case. In this paper, we side-step generalized projections by using a self-concordant barrier as a regularizer to compute the Newton steps. This ensures that the iterates are always within the feasible set without requiring projections. This approach still requires the computation of the inverse of the Hessian of the barrier at every step. However, using stability properties of the Newton iterates, we show that the inverse of the Hessians can be efficiently approximated via Taylor expansions for most rounds, resulting in a $\\widetilde O(d^2 T +d^\\omega \\sqrt{T})$ total computational complexity, where $\\omega\\in(2,3]$ is the exponent of matrix multiplication. In the stochastic setting, we show that this translates into a $\\widetilde O(d^3/\\varepsilon)$ computational complexity for finding an $\\varepsilon$-optimal point, answering an open question by Koren 2013. We first prove these new results for the simple case where the feasible set is a Euclidean ball. Then, to move to general convex sets, we use a reduction to Online Convex Optimization over the Euclidean ball. Our final algorithm for general convex sets can be viewed as a more computationally-efficient version of ONS.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mhammedi23a/mhammedi23a.pdf",
        "supp": "",
        "pdf_size": 530765,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5562257921119159677&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;mit.edu",
        "email": "mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "dfd1ecb770",
        "title": "Reaching Kesten-Stigum Threshold in the Stochastic Block Model under Node Corruptions",
        "site": "https://proceedings.mlr.press/v195/hua23a.html",
        "author": "Jingqiu Ding; Tommaso d\u2019Orsi; Yiding Hua; David Steurer",
        "abstract": "We study robust community detection in the context of node-corrupted stochastic block model,  where an adversary can arbitrarily modify all the edges incident to a fraction of the n vertices. We present the first polynomial-time algorithm that achieves weak recovery at the Kesten-Stigum threshold even in the presence of a small constant fraction of corrupted nodes. Prior to this work, even state-of-the-art robust algorithms were known to break under such node corruption adversaries, when close to the Kesten-Stigum threshold.We further extend our techniques to the $Z_2$ synchronization problem, where our algorithm reaches the optimal recovery threshold in the presence of similar strong adversarial perturbations.The key ingredient of our algorithm is a novel identifiability proof that leverages the push-out effect of the Grothendieck norm of principal submatrices.",
        "bibtex": "@InProceedings{pmlr-v195-hua23a,\n  title = \t {Reaching Kesten-Stigum Threshold in the Stochastic Block Model under Node Corruptions},\n  author =       {Ding, Jingqiu and d'Orsi, Tommaso and Hua, Yiding and Steurer, David},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4044--4071},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hua23a/hua23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hua23a.html},\n  abstract = \t {We study robust community detection in the context of node-corrupted stochastic block model,  where an adversary can arbitrarily modify all the edges incident to a fraction of the n vertices. We present the first polynomial-time algorithm that achieves weak recovery at the Kesten-Stigum threshold even in the presence of a small constant fraction of corrupted nodes. Prior to this work, even state-of-the-art robust algorithms were known to break under such node corruption adversaries, when close to the Kesten-Stigum threshold.We further extend our techniques to the $Z_2$ synchronization problem, where our algorithm reaches the optimal recovery threshold in the presence of similar strong adversarial perturbations.The key ingredient of our algorithm is a novel identifiability proof that leverages the push-out effect of the Grothendieck norm of principal submatrices.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hua23a/hua23a.pdf",
        "supp": "",
        "pdf_size": 377085,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13177231184771740094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich; ETH Z\u00fcrich; ETH Z\u00fcrich",
        "aff_domain": "inf.ethz.ch;inf.ethz.ch;inf.ethz.ch;inf.ethz.ch",
        "email": "inf.ethz.ch;inf.ethz.ch;inf.ethz.ch;inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "f3f590dc4b",
        "title": "Repeated Bilateral Trade Against a Smoothed Adversary",
        "site": "https://proceedings.mlr.press/v195/cesa-bianchi23a.html",
        "author": "Nicol\u00f2 Cesa-Bianchi; Tommaso R. Cesari; Roberto Colomboni; Federico Fusco; Stefano Leonardi",
        "abstract": "We study repeated bilateral trade where an adaptive $\\sigma$-smooth adversary generates the valuations of sellers and buyers. We provide a complete characterization of the regret regimes for fixed-price mechanisms under different feedback models in the two cases where the learner can post either the same or different prices to buyers and sellers.We begin by showing that the minimax regret after $T$ rounds is of order $\\sqrt{T}$ in the full-feedback scenario. Under partial feedback, any algorithm that has to post the same price to buyers and sellers suffers worst-case linear regret. However, when the learner can post two different prices at each round, we design an algorithm enjoying regret of order $T^{3/4}$ ignoring log factors.We prove that this rate is optimal by presenting a surprising $T^{3/4}$ lower bound, which is the main technical contribution of the paper.",
        "bibtex": "@InProceedings{pmlr-v195-cesa-bianchi23a,\n  title = \t {Repeated Bilateral Trade Against a Smoothed Adversary},\n  author =       {Cesa-Bianchi, Nicol{\\`o} and Cesari, Tommaso R. and Colomboni, Roberto and Fusco, Federico and Leonardi, Stefano},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1095--1130},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/cesa-bianchi23a/cesa-bianchi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/cesa-bianchi23a.html},\n  abstract = \t {We study repeated bilateral trade where an adaptive $\\sigma$-smooth adversary generates the valuations of sellers and buyers. We provide a complete characterization of the regret regimes for fixed-price mechanisms under different feedback models in the two cases where the learner can post either the same or different prices to buyers and sellers.We begin by showing that the minimax regret after $T$ rounds is of order $\\sqrt{T}$ in the full-feedback scenario. Under partial feedback, any algorithm that has to post the same price to buyers and sellers suffers worst-case linear regret. However, when the learner can post two different prices at each round, we design an algorithm enjoying regret of order $T^{3/4}$ ignoring log factors.We prove that this rate is optimal by presenting a surprising $T^{3/4}$ lower bound, which is the main technical contribution of the paper.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/cesa-bianchi23a/cesa-bianchi23a.pdf",
        "supp": "",
        "pdf_size": 481857,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7141958771382306067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Universit\u00e0 degli Studi di Milano+Politecnico di Milano, Milano, Italy; University of Ottawa, Ottawa, Canada; Universit\u00e0 degli Studi di Milano, Milano, Italy+Istituto Italiano di Tecnologia, Genova, Italy; Sapienza Universit\u00e0 di Roma, Roma, Italy; Sapienza Universit\u00e0 di Roma, Roma, Italy",
        "aff_domain": "UNIMI.IT;UOTTAWA.CA;UNIMI.IT;DIAG.UNIROMA1.IT;DIAG.IT",
        "email": "UNIMI.IT;UOTTAWA.CA;UNIMI.IT;DIAG.UNIROMA1.IT;DIAG.IT",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;0+3;4;4",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Milano;Politecnico di Milano;University of Ottawa;Istituto Italiano di Tecnologia;Sapienza Universit\u00e0 di Roma",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.unimi.it;https://www.polimi.it;https://www.uottawa.ca;https://www.iit.it;https://www.uniroma1.it",
        "aff_unique_abbr": "UniMi;Polimi;U of O;IIT;Sapienza",
        "aff_campus_unique_index": "1;2;1+3;4;4",
        "aff_campus_unique": ";Milano;Ottawa;Genova;Roma",
        "aff_country_unique_index": "0+0;1;0+0;0;0",
        "aff_country_unique": "Italy;Canada"
    },
    {
        "id": "d97dcf9971",
        "title": "Resolving the Mixing Time of the Langevin Algorithm to its Stationary Distribution for Log-Concave Sampling",
        "site": "https://proceedings.mlr.press/v195/altschuler23a.html",
        "author": "Jason Altschuler; Kunal Talwar",
        "abstract": "Sampling from a high-dimensional distribution is a fundamental task in statistics, engineering, and the sciences. A canonical approach is the Langevin Algorithm, i.e., the Markov chain for the discretized Langevin Diffusion. This is the sampling analog of Gradient Descent. Despite being studied for several decades in multiple communities, tight mixing bounds for this algorithm remain unresolved even in the seemingly simple setting of log-concave distributions over a bounded domain. This paper completely characterizes the mixing time of the Langevin Algorithm to its stationary distribution in this setting (and others). This mixing result can be combined with any bound on the discretization bias in order to sample from the stationary distribution of the Langevin Diffusion. In this way, we disentangle the study of the mixing and bias of the Langevin Algorithm.Our key insight is to analyze the Langevin Algorithm\u2019s convergence by using a new Lyapunov function: the shifted divergence, a quantity studied in the differential privacy literature. Briefly, this Lyapunov function is a version of the Renyi divergence that is smoothed in optimal transport distance, and we use the amount of smoothing to measure the Langevin Algorithm\u2019s progress. In addition to giving a short, simple proof of optimal mixing bounds, this analysis approach also has several additional appealing properties. First, our approach removes all unnecessary assumptions required by other sampling analyses. Second, our approach unifies many settings: it extends if the Langevin Algorithm uses projections, stochastic mini-batch gradients, or strongly convex potentials (whereby our mixing time improves exponentially). Third, our approach unifies many metrics: it proves mixing in the stringent notion of Renyi divergence, which immediately implies mixing in all common metrics via standard comparison inequalities. Fourth, our approach exploits convexity only through the contractivity of a gradient step\u2014reminiscent of how convexity is used in textbook proofs of Gradient Descent.",
        "bibtex": "@InProceedings{pmlr-v195-altschuler23a,\n  title = \t {Resolving the Mixing Time of the Langevin Algorithm to its Stationary Distribution for Log-Concave Sampling},\n  author =       {Altschuler, Jason and Talwar, Kunal},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2509--2510},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/altschuler23a/altschuler23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/altschuler23a.html},\n  abstract = \t {Sampling from a high-dimensional distribution is a fundamental task in statistics, engineering, and the sciences. A canonical approach is the Langevin Algorithm, i.e., the Markov chain for the discretized Langevin Diffusion. This is the sampling analog of Gradient Descent. Despite being studied for several decades in multiple communities, tight mixing bounds for this algorithm remain unresolved even in the seemingly simple setting of log-concave distributions over a bounded domain. This paper completely characterizes the mixing time of the Langevin Algorithm to its stationary distribution in this setting (and others). This mixing result can be combined with any bound on the discretization bias in order to sample from the stationary distribution of the Langevin Diffusion. In this way, we disentangle the study of the mixing and bias of the Langevin Algorithm.Our key insight is to analyze the Langevin Algorithm\u2019s convergence by using a new Lyapunov function: the shifted divergence, a quantity studied in the differential privacy literature. Briefly, this Lyapunov function is a version of the Renyi divergence that is smoothed in optimal transport distance, and we use the amount of smoothing to measure the Langevin Algorithm\u2019s progress. In addition to giving a short, simple proof of optimal mixing bounds, this analysis approach also has several additional appealing properties. First, our approach removes all unnecessary assumptions required by other sampling analyses. Second, our approach unifies many settings: it extends if the Langevin Algorithm uses projections, stochastic mini-batch gradients, or strongly convex potentials (whereby our mixing time improves exponentially). Third, our approach unifies many metrics: it proves mixing in the stringent notion of Renyi divergence, which immediately implies mixing in all common metrics via standard comparison inequalities. Fourth, our approach exploits convexity only through the contractivity of a gradient step\u2014reminiscent of how convexity is used in textbook proofs of Gradient Descent. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/altschuler23a/altschuler23a.pdf",
        "supp": "",
        "pdf_size": 50079,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4825211162764783773&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "NYU; Apple",
        "aff_domain": "NYU.EDU;APPLE.COM",
        "email": "NYU.EDU;APPLE.COM",
        "github": "",
        "project": "arXiv:2210.08448",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "New York University;Apple",
        "aff_unique_dep": ";Apple Inc.",
        "aff_unique_url": "https://www.nyu.edu;https://www.apple.com",
        "aff_unique_abbr": "NYU;Apple",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New York;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a91f1f8ff6",
        "title": "SGD learning on neural networks: leap complexity and saddle-to-saddle dynamics",
        "site": "https://proceedings.mlr.press/v195/abbe23a.html",
        "author": "Emmanuel Abbe; Enric Boix Adser\u00e0; Theodor Misiakiewicz",
        "abstract": "We investigate the time complexity of SGD learning on fully-connected neural networks with isotropic data. We put forward a complexity measure,{\\it the leap}, which measures how \u201chierarchical\u201d target functions are. For $d$-dimensional uniform Boolean or isotropic Gaussian data, our main conjecture states that the time complexity to learn a function $f$ with low-dimensional support is $$\\Tilde \\Theta (d^{\\max(\\mathrm{Leap}(f),2)}) \\,\\,.$$    We prove a version of this conjecture for a class of functions on Gaussian isotropic data and 2-layer neural networks, under additional technical assumptions on how SGD is run. We show that the training  sequentially learns the function support with a saddle-to-saddle dynamic. Our result departs from Abbe et al.\u201922 by going beyond leap 1 (merged-staircase functions), and by going beyond the mean-field and gradient flow approximations that prohibit the full complexity control obtained here.Finally, we note that this gives an SGD complexity for the full training trajectory that matches that of Correlational Statistical Query (CSQ) lower-bounds.",
        "bibtex": "@InProceedings{pmlr-v195-abbe23a,\n  title = \t {SGD learning on neural networks: leap complexity and saddle-to-saddle dynamics},\n  author =       {Abbe, Emmanuel and Adser{\\`a}, Enric Boix and Misiakiewicz, Theodor},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2552--2623},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/abbe23a/abbe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/abbe23a.html},\n  abstract = \t {   We investigate the time complexity of SGD learning on fully-connected neural networks with isotropic data. We put forward a complexity measure,{\\it the leap}, which measures how \u201chierarchical\u201d target functions are. For $d$-dimensional uniform Boolean or isotropic Gaussian data, our main conjecture states that the time complexity to learn a function $f$ with low-dimensional support is $$\\Tilde \\Theta (d^{\\max(\\mathrm{Leap}(f),2)}) \\,\\,.$$    We prove a version of this conjecture for a class of functions on Gaussian isotropic data and 2-layer neural networks, under additional technical assumptions on how SGD is run. We show that the training  sequentially learns the function support with a saddle-to-saddle dynamic. Our result departs from Abbe et al.\u201922 by going beyond leap 1 (merged-staircase functions), and by going beyond the mean-field and gradient flow approximations that prohibit the full complexity control obtained here.Finally, we note that this gives an SGD complexity for the full training trajectory that matches that of Correlational Statistical Query (CSQ) lower-bounds. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/abbe23a/abbe23a.pdf",
        "supp": "",
        "pdf_size": 1128127,
        "gs_citation": 124,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2688227740222571720&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "'Ecole polytechnique F'ed'erale de Lausanne; Department of Electrical Engineering and Computer Science, MIT; Department of Statistics, Stanford University",
        "aff_domain": "; ;",
        "email": "; ;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "EPFL;Massachusetts Institute of Technology;Stanford University",
        "aff_unique_dep": ";Department of Electrical Engineering and Computer Science;Department of Statistics",
        "aff_unique_url": "https://www.epfl.ch;https://web.mit.edu;https://www.stanford.edu",
        "aff_unique_abbr": "EPFL;MIT;Stanford",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Lausanne;Cambridge;Stanford",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "5c8f760bbb",
        "title": "SQ Lower Bounds for Learning Mixtures of Separated and Bounded Covariance Gaussians",
        "site": "https://proceedings.mlr.press/v195/diakonikolas23b.html",
        "author": "Ilias Diakonikolas; Daniel M. Kane; Thanasis Pittas; Nikos Zarifis",
        "abstract": "We study the complexity of learning mixtures of separated Gaussians with common unknown bounded covariance matrix. Specifically, we focus on learning Gaussian mixture models (GMMs) on $\\mathbb{R}^d$ of the form $P= \\sum_{i=1}^k w_i \\mathcal{N}(\\vec \\mu_i,\\vec \\Sigma_i)$, where $\\vec \\Sigma_i = \\vec \\Sigma \\preceq \\vec I$and $\\min_{i \\neq j} \\|\\vec \\mu_i - \\vec \\mu_j\\|_2 \\geq k^\\epsilon$ for some $\\epsilon>0$. Known learning algorithms for this family of GMMs have complexity $(dk)^{O(1/\\epsilon)}$. In this work, we prove that any Statistical Query (SQ) algorithm for this problem requires complexity at least  $d^{\\Omega(1/\\epsilon)}$. Our SQ lower bound implies a similar lower bound for low-degree polynomial tests. Our result provides evidence that known algorithms for this problem are nearly best possible.",
        "bibtex": "@InProceedings{pmlr-v195-diakonikolas23b,\n  title = \t {SQ Lower Bounds for Learning Mixtures of Separated and Bounded Covariance Gaussians},\n  author =       {Diakonikolas, Ilias and Kane, Daniel M. and Pittas, Thanasis and Zarifis, Nikos},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2319--2349},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/diakonikolas23b/diakonikolas23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/diakonikolas23b.html},\n  abstract = \t {We study the complexity of learning mixtures of separated Gaussians with common unknown bounded covariance matrix. Specifically, we focus on learning Gaussian mixture models (GMMs) on $\\mathbb{R}^d$ of the form $P= \\sum_{i=1}^k w_i \\mathcal{N}(\\vec \\mu_i,\\vec \\Sigma_i)$, where $\\vec \\Sigma_i = \\vec \\Sigma \\preceq \\vec I$and $\\min_{i \\neq j} \\|\\vec \\mu_i - \\vec \\mu_j\\|_2 \\geq k^\\epsilon$ for some $\\epsilon>0$. Known learning algorithms for this family of GMMs have complexity $(dk)^{O(1/\\epsilon)}$. In this work, we prove that any Statistical Query (SQ) algorithm for this problem requires complexity at least  $d^{\\Omega(1/\\epsilon)}$. Our SQ lower bound implies a similar lower bound for low-degree polynomial tests. Our result provides evidence that known algorithms for this problem are nearly best possible. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/diakonikolas23b/diakonikolas23b.pdf",
        "supp": "",
        "pdf_size": 505518,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6381251556998658230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Wisconsin Madison; University of California, San Diego; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": "CS.WISC.EDU;CS.UCSD.EDU;WISC.EDU;WISC.EDU",
        "email": "CS.WISC.EDU;CS.UCSD.EDU;WISC.EDU;WISC.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Wisconsin-Madison;University of California, San Diego",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "UW-Madison;UCSD",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Madison;San Diego",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3a04cc2ae1",
        "title": "STay-ON-the-Ridge: Guaranteed Convergence to Local Minimax Equilibrium in Nonconvex-Nonconcave Games",
        "site": "https://proceedings.mlr.press/v195/daskalakis23b.html",
        "author": "Constantinos Daskalakis; Noah Golowich; Stratis Skoulakis; Emmanouil Zampetakis",
        "abstract": "Min-max optimization problems involving nonconvex-nonconcave objectives have found important applications in adversarial training and other multi-agent learning settings. Yet, no known gradient descent-based method is guaranteed to converge to (even local notions of) min-max equilibrium in the nonconvex-nonconcave setting. For all known methods, there exist relatively simple objectives for which they cycle or exhibit other undesirable behavior different from converging to a point,  let alone to some game-theoretically meaningful one\u00a0\\citep{flokas2019poincare,hsieh2021limits}. The only known convergence guarantees hold under the strong assumption that the initialization is very close to a local min-max equilibrium\u00a0\\citep{wang2019solving}. Moreover, the afore-described challenges are not just theoretical curiosities. All known methods are  unstable  in  practice, even in simple settings.We propose the first method that is guaranteed to converge to a local min-max equilibrium for smooth nonconvex-nonconcave objectives. Our method is second-order and provably escapes limit cycles as long as it is initialized at an easy-to-find initial point. Both the definition of our method and its convergence analysis are motivated by the topological nature of the problem. In particular, our method is not designed to decrease some potential function, such as the distance of its iterate from the set of local min-max equilibria or the projected gradient of the objective, but is designed to satisfy a topological property that guarantees the avoidance of cycles and implies its convergence.",
        "bibtex": "@InProceedings{pmlr-v195-daskalakis23b,\n  title = \t {STay-ON-the-Ridge: Guaranteed Convergence to Local Minimax Equilibrium in Nonconvex-Nonconcave Games},\n  author =       {Daskalakis, Constantinos and Golowich, Noah and Skoulakis, Stratis and Zampetakis, Emmanouil},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5146--5198},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/daskalakis23b/daskalakis23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/daskalakis23b.html},\n  abstract = \t {   Min-max optimization problems involving nonconvex-nonconcave objectives have found important applications in adversarial training and other multi-agent learning settings. Yet, no known gradient descent-based method is guaranteed to converge to (even local notions of) min-max equilibrium in the nonconvex-nonconcave setting. For all known methods, there exist relatively simple objectives for which they cycle or exhibit other undesirable behavior different from converging to a point,  let alone to some game-theoretically meaningful one\u00a0\\citep{flokas2019poincare,hsieh2021limits}. The only known convergence guarantees hold under the strong assumption that the initialization is very close to a local min-max equilibrium\u00a0\\citep{wang2019solving}. Moreover, the afore-described challenges are not just theoretical curiosities. All known methods are  unstable  in  practice, even in simple settings.We propose the first method that is guaranteed to converge to a local min-max equilibrium for smooth nonconvex-nonconcave objectives. Our method is second-order and provably escapes limit cycles as long as it is initialized at an easy-to-find initial point. Both the definition of our method and its convergence analysis are motivated by the topological nature of the problem. In particular, our method is not designed to decrease some potential function, such as the distance of its iterate from the set of local min-max equilibria or the projected gradient of the objective, but is designed to satisfy a topological property that guarantees the avoidance of cycles and implies its convergence.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/daskalakis23b/daskalakis23b.pdf",
        "supp": "",
        "pdf_size": 3450365,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17477048518683307508&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne; University of California Berkeley",
        "aff_domain": "CSAIL.MIT.EDU;MIT.EDU;EPFL.CH;BERKELEY.COM",
        "email": "CSAIL.MIT.EDU;MIT.EDU;EPFL.CH;BERKELEY.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;EPFL;University of California, Berkeley",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://web.mit.edu;https://www.epfl.ch;https://www.berkeley.edu",
        "aff_unique_abbr": "MIT;EPFL;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "bb9ae29c6a",
        "title": "Self-Directed Linear Classification",
        "site": "https://proceedings.mlr.press/v195/diakonikolas23c.html",
        "author": "Ilias Diakonikolas; Vasilis Kontonis; Christos Tzamos; Nikos Zarifis",
        "abstract": "In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.We present two main results.If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner thatmakes $O(d \\log \\log(n))$ mistakes and classifies the entire dataset.If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficient self-directed learner that predicts the labels of $99%$ of the points in $X$ with mistake bound independent of $n$. In contrast, under a worst- or random-ordering, the number of mistakes must be at least $\\Omega(d \\log n)$, even when the points are drawn uniformly from the unit sphere and the learner only needs to predict the labels for $1%$ of them.",
        "bibtex": "@InProceedings{pmlr-v195-diakonikolas23c,\n  title = \t {Self-Directed Linear Classification},\n  author =       {Diakonikolas, Ilias and Kontonis, Vasilis and Tzamos, Christos and Zarifis, Nikos},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2919--2947},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/diakonikolas23c/diakonikolas23c.pdf},\n  url = \t {https://proceedings.mlr.press/v195/diakonikolas23c.html},\n  abstract = \t {In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.We present two main results.If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner thatmakes $O(d \\log \\log(n))$ mistakes and classifies the entire dataset.If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficient self-directed learner that predicts the labels of $99%$ of the points in $X$ with mistake bound independent of $n$. In contrast, under a worst- or random-ordering, the number of mistakes must be at least $\\Omega(d \\log n)$, even when the points are drawn uniformly from the unit sphere and the learner only needs to predict the labels for $1%$ of them. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/diakonikolas23c/diakonikolas23c.pdf",
        "supp": "",
        "pdf_size": 430890,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14184128479824740009&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "UW Madison; UW Madison; UW Madison + National and Kapodistrian University of Athens (NKUA); UW Madison",
        "aff_domain": "CS.WISC.EDU;WISC.EDU;WISC.EDU;WISC.EDU",
        "email": "CS.WISC.EDU;WISC.EDU;WISC.EDU;WISC.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0",
        "aff_unique_norm": "University of Wisconsin-Madison;National and Kapodistrian University of Athens",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.uoa.gr",
        "aff_unique_abbr": "UW-Madison;NKUA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Madison;",
        "aff_country_unique_index": "0;0;0+1;0",
        "aff_country_unique": "United States;Greece"
    },
    {
        "id": "3925c6a59e",
        "title": "Semi-Random Sparse Recovery in Nearly-Linear Time",
        "site": "https://proceedings.mlr.press/v195/kelner23a.html",
        "author": "Jonathan Kelner; Jerry Li; Allen X. Liu; Aaron Sidford; Kevin Tian",
        "abstract": "Sparse recovery is one of the most fundamental and well-studied inverse problems.Standard statistical formulations of the problem are provably solved by general convex programming techniques and more practical, fast (nearly-linear time) iterative methods. However, these latter \u201cfast algorithms\u201d have previously been observed to be brittle in various real-world settings.We investigate the brittleness of fast sparse recovery algorithms to generative model changes through the lens of studying their robustness to a \u201chelpful\u201d semi-random adversary, a framework for testing overfitting to input assumptions. We consider the following basic model: let $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ be a measurement matrix containing an unknown subset of rows $\\mathbf{G} \\in \\mathb{R}^{m \\times d}$ which are bounded and satisfy the restricted isometry property (RIP), but is otherwise arbitrary. Letting $x^\\star \\in \\mathbb{R}^d$ be $s$-sparse, and given either exact or noisy measurements, $b = \\mathbf{A} x^\\star$ or $b = \\mathbf{A} x^\\star + \\xi$, we design algorithms recovering $x^\\star$ information-theoretically optimally in nearly-linear time. We extend our algorithm to hold for weaker generative models relaxing our planted RIP row subset assumption to a natural weighted variant, and show that our method\u2019s guarantees naturally interpolate the quality of the measurement matrix to, in some parameter regimes, run in sublinear time.Our approach differs from that of prior fast iterative methods with provable guarantees under semi-random generative models [CG18, LSTZ20], which typically separate the problem of learning the planted instance from the estimation problem, i.e. they attempt to first learn the planted \u201cgood\u201d instance (in our case, the matrix $\\mathbf{G}$). However, natural conditions on a submatrix which make sparse recovery tractable, such as RIP, are NP-hard to verify and hence first learning a sufficient row reweighting appears challenging. We eschew this approach and design a new iterative method, tailored to the geometry of sparse recovery, which is provably robust to our semi-random model. Our hope is that our approach opens the door to new robust, efficient algorithms for other natural statistical inverse problems.",
        "bibtex": "@InProceedings{pmlr-v195-kelner23a,\n  title = \t {Semi-Random Sparse Recovery in Nearly-Linear Time},\n  author =       {Kelner, Jonathan and Li, Jerry and Liu, Allen X. and Sidford, Aaron and Tian, Kevin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2352--2398},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kelner23a/kelner23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kelner23a.html},\n  abstract = \t {Sparse recovery is one of the most fundamental and well-studied inverse problems.Standard statistical formulations of the problem are provably solved by general convex programming techniques and more practical, fast (nearly-linear time) iterative methods. However, these latter \u201cfast algorithms\u201d have previously been observed to be brittle in various real-world settings.We investigate the brittleness of fast sparse recovery algorithms to generative model changes through the lens of studying their robustness to a \u201chelpful\u201d semi-random adversary, a framework for testing overfitting to input assumptions. We consider the following basic model: let $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ be a measurement matrix containing an unknown subset of rows $\\mathbf{G} \\in \\mathb{R}^{m \\times d}$ which are bounded and satisfy the restricted isometry property (RIP), but is otherwise arbitrary. Letting $x^\\star \\in \\mathbb{R}^d$ be $s$-sparse, and given either exact or noisy measurements, $b = \\mathbf{A} x^\\star$ or $b = \\mathbf{A} x^\\star + \\xi$, we design algorithms recovering $x^\\star$ information-theoretically optimally in nearly-linear time. We extend our algorithm to hold for weaker generative models relaxing our planted RIP row subset assumption to a natural weighted variant, and show that our method\u2019s guarantees naturally interpolate the quality of the measurement matrix to, in some parameter regimes, run in sublinear time.Our approach differs from that of prior fast iterative methods with provable guarantees under semi-random generative models [CG18, LSTZ20], which typically separate the problem of learning the planted instance from the estimation problem, i.e. they attempt to first learn the planted \u201cgood\u201d instance (in our case, the matrix $\\mathbf{G}$). However, natural conditions on a submatrix which make sparse recovery tractable, such as RIP, are NP-hard to verify and hence first learning a sufficient row reweighting appears challenging. We eschew this approach and design a new iterative method, tailored to the geometry of sparse recovery, which is provably robust to our semi-random model. Our hope is that our approach opens the door to new robust, efficient algorithms for other natural statistical inverse problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/kelner23a/kelner23a.pdf",
        "supp": "",
        "pdf_size": 503891,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15589977471136470681&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "MIT; Microsoft Research; MIT; Stanford University; Microsoft Research",
        "aff_domain": "mit.edu;microsoft.com;mit.edu;stanford.edu;microsoft.com",
        "email": "mit.edu;microsoft.com;mit.edu;stanford.edu;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Microsoft;Stanford University",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://web.mit.edu;https://www.microsoft.com/en-us/research;https://www.stanford.edu",
        "aff_unique_abbr": "MIT;MSR;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "320ec57297",
        "title": "Sharp analysis of EM for learning mixtures of pairwise differences",
        "site": "https://proceedings.mlr.press/v195/dhawan23a.html",
        "author": "Abhishek Dhawan; Cheng Mao; Ashwin Pananjady",
        "abstract": "We consider a symmetric mixture of linear regressions with random samples from the pairwise comparison design, which can be seen as a noisy version of a type of Euclidean distance geometry problem. We analyze the expectation-maximization (EM) algorithm locally around the ground truth and establish that the sequence converges linearly, providing an $\\ell_\\infty$-norm guarantee on the estimation error of the iterates. Furthermore, we show that the limit of the EM sequence achieves the sharp rate of estimation in the $\\ell_2$-norm, matching the information-theoretically optimal constant. We also argue through simulation that convergence from a random initialization is much more delicate in this setting, and does not appear to occur in general. Our results show that the EM algorithm can exhibit several unique behaviors when the covariate distribution is suitably structured.",
        "bibtex": "@InProceedings{pmlr-v195-dhawan23a,\n  title = \t {Sharp analysis of EM for learning mixtures of pairwise differences},\n  author =       {Dhawan, Abhishek and Mao, Cheng and Pananjady, Ashwin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4384--4428},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/dhawan23a/dhawan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/dhawan23a.html},\n  abstract = \t {We consider a symmetric mixture of linear regressions with random samples from the pairwise comparison design, which can be seen as a noisy version of a type of Euclidean distance geometry problem. We analyze the expectation-maximization (EM) algorithm locally around the ground truth and establish that the sequence converges linearly, providing an $\\ell_\\infty$-norm guarantee on the estimation error of the iterates. Furthermore, we show that the limit of the EM sequence achieves the sharp rate of estimation in the $\\ell_2$-norm, matching the information-theoretically optimal constant. We also argue through simulation that convergence from a random initialization is much more delicate in this setting, and does not appear to occur in general. Our results show that the EM algorithm can exhibit several unique behaviors when the covariate distribution is suitably structured.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/dhawan23a/dhawan23a.pdf",
        "supp": "",
        "pdf_size": 673871,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6386910642007794435&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "School of Mathematics, Georgia Institute of Technology; School of Mathematics, Georgia Institute of Technology; Schools of Industrial and Systems Engineering and Electrical and Computer Engineering, Georgia Institute of Technology",
        "aff_domain": "GATECH.EDU;MATH.GATECH.EDU;GATECH.EDU",
        "email": "GATECH.EDU;MATH.GATECH.EDU;GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Mathematics",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5d2ba1caa9",
        "title": "Sharp thresholds in inference of planted subgraphs",
        "site": "https://proceedings.mlr.press/v195/mossel23a.html",
        "author": "Elchanan Mossel; Jonathan Niles-Weed; Youngtak Sohn; Nike Sun; Ilias Zadik",
        "abstract": "We connect the study of phase transitions in high-dimensional statistical inference to the study of threshold phenomena in random graphs. A major question in the study of the Erd\u0151s\u2013R\u00e9nyi random graph $G(n,p)$ is to understand the probability, as a function of $p$, that $G(n,p)$ contains a given subgraph $H=H_n$. This was studied for many specific examples of $H$, starting with classical work of Erd\u0151s and R\u00e9nyi (1960). More recent work studies this question for general $H$, both in building a general theory of sharp versus coarse transitions  (Friedgut and Bourgain 1999; Hatami, 2012) and in results on the location of the transition (Kahn and Kalai, 2007; Talagrand, 2010; Frankston, Kahn, Narayanan, Park, 2019; Park and Pham, 2022).In inference problems, one often studies the optimal accuracy of inference as a function of the amount of noise. In a variety of sparse recovery problems, an \u201call-or-nothing (AoN) phenomenon\u201d has been observed: Informally, as the amount of noise is gradually increased, at some critical threshold the inference problem undergoes a sharp jump from near-perfect recovery to near-zero accuracy (Gamarnik and Zadik, 2017; Reeves, Xu, Zadik, 2021). We can regard AoN as the natural inference analogue of the sharp threshold phenomenon in random graphs. In contrast with the general theorydeveloped for sharp thresholds of random graph properties, the AoNphenomenon has only been studied so far in specific inference settings, anda general theory behind its appearance remains elusive.In this paper we study the general problem of inferring a graph $H=H_n$ planted in an Erd\u0151s\u2013R\u00e9nyi random graph, thus naturally connecting the two lines of research mentioned above. We show that questions of AoN are closely connected to first moment thresholds, and to a generalization of the so-called Kahn\u2013Kalai expectation threshold that scans over subgraphs of $H$ of edge density at least $q$. In a variety of settings we characterize AoN, by showing that AoN occurs \\emph{if and only if} this \u201cgeneralized expectation threshold\u201d is roughly constant in $q$. Our proofs combine techniques from random graph theory and Bayesian inference.",
        "bibtex": "@InProceedings{pmlr-v195-mossel23a,\n  title = \t {Sharp thresholds in inference of planted subgraphs},\n  author =       {Mossel, Elchanan and Niles-Weed, Jonathan and Sohn, Youngtak and Sun, Nike and Zadik, Ilias},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5573--5577},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mossel23a/mossel23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mossel23a.html},\n  abstract = \t {We connect the study of phase transitions in high-dimensional statistical inference to the study of threshold phenomena in random graphs. A major question in the study of the Erd\u0151s\u2013R\u00e9nyi random graph $G(n,p)$ is to understand the probability, as a function of $p$, that $G(n,p)$ contains a given subgraph $H=H_n$. This was studied for many specific examples of $H$, starting with classical work of Erd\u0151s and R\u00e9nyi (1960). More recent work studies this question for general $H$, both in building a general theory of sharp versus coarse transitions  (Friedgut and Bourgain 1999; Hatami, 2012) and in results on the location of the transition (Kahn and Kalai, 2007; Talagrand, 2010; Frankston, Kahn, Narayanan, Park, 2019; Park and Pham, 2022).In inference problems, one often studies the optimal accuracy of inference as a function of the amount of noise. In a variety of sparse recovery problems, an \u201call-or-nothing (AoN) phenomenon\u201d has been observed: Informally, as the amount of noise is gradually increased, at some critical threshold the inference problem undergoes a sharp jump from near-perfect recovery to near-zero accuracy (Gamarnik and Zadik, 2017; Reeves, Xu, Zadik, 2021). We can regard AoN as the natural inference analogue of the sharp threshold phenomenon in random graphs. In contrast with the general theorydeveloped for sharp thresholds of random graph properties, the AoNphenomenon has only been studied so far in specific inference settings, anda general theory behind its appearance remains elusive.In this paper we study the general problem of inferring a graph $H=H_n$ planted in an Erd\u0151s\u2013R\u00e9nyi random graph, thus naturally connecting the two lines of research mentioned above. We show that questions of AoN are closely connected to first moment thresholds, and to a generalization of the so-called Kahn\u2013Kalai expectation threshold that scans over subgraphs of $H$ of edge density at least $q$. In a variety of settings we characterize AoN, by showing that AoN occurs \\emph{if and only if} this \u201cgeneralized expectation threshold\u201d is roughly constant in $q$. Our proofs combine techniques from random graph theory and Bayesian inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mossel23a/mossel23a.pdf",
        "supp": "",
        "pdf_size": 95069,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13046798814194943321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Mathematics and IDSS, MIT; Center for Data Science and Courant Institute of Mathematical Sciences, NYU; Department of Mathematics, MIT; Department of Mathematics, MIT; Department of Mathematics, MIT",
        "aff_domain": "MIT.EDU;CIMS.NYU.EDU;MIT.EDU;MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;CIMS.NYU.EDU;MIT.EDU;MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;New York University",
        "aff_unique_dep": "Department of Mathematics and IDSS;Center for Data Science, Courant Institute of Mathematical Sciences",
        "aff_unique_url": "https://web.mit.edu;https://www.nyu.edu",
        "aff_unique_abbr": "MIT;NYU",
        "aff_campus_unique_index": "1;2;2;2",
        "aff_campus_unique": ";New York;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "295afa7a55",
        "title": "Sharper Model-free Reinforcement Learning for Average-reward Markov Decision Processes",
        "site": "https://proceedings.mlr.press/v195/zhang23b.html",
        "author": "Zihan Zhang; Qiaomin Xie",
        "abstract": "We study model-free reinforcement learning (RL) algorithms for infinite-horizon average-reward Markov decision process (MDP), which is more appropriate for applications that involve continuingoperations not divided into episodes. In contrast to episodic/discounted MDPs, theoretical understanding of model-free RL algorithms is relatively inadequate for the average-reward setting. In this paper, we consider both the online setting and the setting with access to a simulator. We develop computationally efficient model-free algorithms that achieve sharper guarantees on regret/sample complexity compared with existing results.In the online setting, we design an algorithm, $\\mathtt{UCB-AVG}$, based on an optimistic variant of variance-reduced Q-learning. We show that $\\mathtt{UCB-AVG}$ achieves a regret bound $\\otilde(S^5A^2\\spn(h^*)\\sqrt{T})$ after $T$ steps, where $S\\times A$ is the size of state-action space, and     $\\mathrm{sp}(h^*)$ the span of the optimal bias function.\\footnote{We use the notation $\\widetilde{O}(\\cdot)$ to suppress constant and logarithmic factors.} Our result provides the first computationally efficient model-free algorithm that achieves the optimal dependence in $T$ (up to log factors) for weakly communicating MDPs, which is necessary for low regret \\citep{bartlett2009regal}. In contrast, prior results either are suboptimal in $T$ or require strong assumptions of ergodicity or uniformly mixing of MDPs. In the simulator setting, we adapt the idea of $\\mathtt{UCB-AVG}$ to develop a model-free algorithm that finds an $\\epsilon$-optimal policy with sample complexity $\\otilde\\left( {SA\\spn^2(h^*)\\epsilon^{-2}} + S^2A\\spn(h^*)\\epsilon^{-1} \\right).$ This sample complexity is near-optimal for weakly communicating MDPs, in view of the minimax lower bound $\\Omega(SA\\spn(^*)\\epsilon^{-2})$ established in\u00a0\\cite{wang2022average}. Existing work mainly focuses on ergodic MDPs and the results typically depend on $\\mix,$ the \\emph{worst-case} mixing time induced by a policy. We remark that  the diameter $D$ and mixing time $\\mix$ are both lower bounded by $\\spn(h^*)$, and $\\mix$ can be arbitrarily large for certain MDPs \\citep{wang2022average}.On the technical side, our approach integrates two key ideas: learning an $\\gamma$-discounted MDP as an approximation, and leveraging reference-advantage decomposition for variance reduction\u00a0\\citep{zhang2020almost} in optimistic Q-learning. As recognized in prior work, a naive approximation by discounted MDPs results in suboptimal guarantees. A distinguishing feature of our method is maintaining estimates of \\emph{value-difference} between state pairs to provide a sharper bound on the variance of reference advantage. We also crucially use a careful choice of the discounted factor $\\gamma$ to balance approximation error due to discounting and the statistical learning error, and we are able to maintain a good-quality reference value function with  $O(SA)$ space complexity.",
        "bibtex": "@InProceedings{pmlr-v195-zhang23b,\n  title = \t {Sharper Model-free Reinforcement Learning for Average-reward Markov Decision Processes},\n  author =       {Zhang, Zihan and Xie, Qiaomin},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5476--5477},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/zhang23b/zhang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/zhang23b.html},\n  abstract = \t {    We study model-free reinforcement learning (RL) algorithms for infinite-horizon average-reward Markov decision process (MDP), which is more appropriate for applications that involve continuingoperations not divided into episodes. In contrast to episodic/discounted MDPs, theoretical understanding of model-free RL algorithms is relatively inadequate for the average-reward setting. In this paper, we consider both the online setting and the setting with access to a simulator. We develop computationally efficient model-free algorithms that achieve sharper guarantees on regret/sample complexity compared with existing results.In the online setting, we design an algorithm, $\\mathtt{UCB-AVG}$, based on an optimistic variant of variance-reduced Q-learning. We show that $\\mathtt{UCB-AVG}$ achieves a regret bound $\\otilde(S^5A^2\\spn(h^*)\\sqrt{T})$ after $T$ steps, where $S\\times A$ is the size of state-action space, and     $\\mathrm{sp}(h^*)$ the span of the optimal bias function.\\footnote{We use the notation $\\widetilde{O}(\\cdot)$ to suppress constant and logarithmic factors.} Our result provides the first computationally efficient model-free algorithm that achieves the optimal dependence in $T$ (up to log factors) for weakly communicating MDPs, which is necessary for low regret \\citep{bartlett2009regal}. In contrast, prior results either are suboptimal in $T$ or require strong assumptions of ergodicity or uniformly mixing of MDPs. In the simulator setting, we adapt the idea of $\\mathtt{UCB-AVG}$ to develop a model-free algorithm that finds an $\\epsilon$-optimal policy with sample complexity $\\otilde\\left( {SA\\spn^2(h^*)\\epsilon^{-2}} + S^2A\\spn(h^*)\\epsilon^{-1} \\right).$ This sample complexity is near-optimal for weakly communicating MDPs, in view of the minimax lower bound $\\Omega(SA\\spn(^*)\\epsilon^{-2})$ established in\u00a0\\cite{wang2022average}. Existing work mainly focuses on ergodic MDPs and the results typically depend on $\\mix,$ the \\emph{worst-case} mixing time induced by a policy. We remark that  the diameter $D$ and mixing time $\\mix$ are both lower bounded by $\\spn(h^*)$, and $\\mix$ can be arbitrarily large for certain MDPs \\citep{wang2022average}.On the technical side, our approach integrates two key ideas: learning an $\\gamma$-discounted MDP as an approximation, and leveraging reference-advantage decomposition for variance reduction\u00a0\\citep{zhang2020almost} in optimistic Q-learning. As recognized in prior work, a naive approximation by discounted MDPs results in suboptimal guarantees. A distinguishing feature of our method is maintaining estimates of \\emph{value-difference} between state pairs to provide a sharper bound on the variance of reference advantage. We also crucially use a careful choice of the discounted factor $\\gamma$ to balance approximation error due to discounting and the statistical learning error, and we are able to maintain a good-quality reference value function with  $O(SA)$ space complexity. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/zhang23b/zhang23b.pdf",
        "supp": "",
        "pdf_size": 150354,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12655617969768523919&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Princeton University; University of Wisconsin-Madison",
        "aff_domain": "OUTLOOK.COM;WISC.EDU",
        "email": "OUTLOOK.COM;WISC.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Princeton University;University of Wisconsin-Madison",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.princeton.edu;https://www.wisc.edu",
        "aff_unique_abbr": "Princeton;UW-Madison",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2454ec3a05",
        "title": "Shortest Program Interpolation Learning",
        "site": "https://proceedings.mlr.press/v195/manoj23a.html",
        "author": "Naren Sarayu Manoj; Nathan Srebro",
        "abstract": "We prove that the Minimum Program Length learning rule exhibits tempered overfitting. We obtain tempered agnostic finite sample learning guarantees and characterize the asymptotic behavior in the presence of random label noise.",
        "bibtex": "@InProceedings{pmlr-v195-manoj23a,\n  title = \t {Shortest Program Interpolation Learning},\n  author =       {Manoj, Naren Sarayu and Srebro, Nathan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4881--4901},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/manoj23a/manoj23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/manoj23a.html},\n  abstract = \t {We prove that the Minimum Program Length learning rule exhibits tempered overfitting. We obtain tempered agnostic finite sample learning guarantees and characterize the asymptotic behavior in the presence of random label noise.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/manoj23a/manoj23a.pdf",
        "supp": "",
        "pdf_size": 385081,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15947719352038351398&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Toyota Technological Institute Chicago; Toyota Technological Institute Chicago",
        "aff_domain": "TTIC.EDU;TTIC.EDU",
        "email": "TTIC.EDU;TTIC.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Technological Institute at Chicago",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tti-chicago.org",
        "aff_unique_abbr": "TTI Chicago",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1984d2e98e",
        "title": "Simple Binary Hypothesis Testing under Local Differential Privacy and Communication Constraints",
        "site": "https://proceedings.mlr.press/v195/pensia23a.html",
        "author": "Ankit Pensia; Amir Reza Asadi; Varun Jog; Po-Ling Loh",
        "abstract": "We study simple binary hypothesis testing under local differential privacy (LDP) and communication constraints. Our results are either minimax optimal or instance optimal: the former hold for the set of distribution pairs with prescribed Hellinger divergence and total variation distance, whereas the latter hold for specific distribution pairs. For the sample complexity of simple hypothesis testing under pure LDP constraints, we establish instance-optimal bounds for distributions with binary support; minimax-optimal bounds for general distributions; and (approximately) instance-optimal, computationally efficient algorithms for general distributions. Under both privacy and communication constraints, we develop instance-optimal, computationally efficient algorithms that achieve minimal sample complexity (up to universal constants). Our results on instance-optimal algorithms hinge on identifying the extreme points of the joint range set of two distributions $p$ and $q$, defined as $\\mathcal{A} := \\{(\\mathbf{T} p, \\mathbf{T} q) | \\mathbf{T} \\in \\mathcal{C}\\}$, where $\\mathcal{C}$ is the set of channels characterizing the constraints.",
        "bibtex": "@InProceedings{pmlr-v195-pensia23a,\n  title = \t {Simple Binary Hypothesis Testing under Local Differential Privacy and Communication Constraints},\n  author =       {Pensia, Ankit and Asadi, Amir Reza and Jog, Varun and Loh, Po-Ling},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3229--3230},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/pensia23a/pensia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/pensia23a.html},\n  abstract = \t {We study simple binary hypothesis testing under local differential privacy (LDP) and communication constraints. Our results are either minimax optimal or instance optimal: the former hold for the set of distribution pairs with prescribed Hellinger divergence and total variation distance, whereas the latter hold for specific distribution pairs. For the sample complexity of simple hypothesis testing under pure LDP constraints, we establish instance-optimal bounds for distributions with binary support; minimax-optimal bounds for general distributions; and (approximately) instance-optimal, computationally efficient algorithms for general distributions. Under both privacy and communication constraints, we develop instance-optimal, computationally efficient algorithms that achieve minimal sample complexity (up to universal constants). Our results on instance-optimal algorithms hinge on identifying the extreme points of the joint range set of two distributions $p$ and $q$, defined as $\\mathcal{A} := \\{(\\mathbf{T} p, \\mathbf{T} q) | \\mathbf{T} \\in \\mathcal{C}\\}$, where $\\mathcal{C}$ is the set of channels characterizing the constraints.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/pensia23a/pensia23a.pdf",
        "supp": "",
        "pdf_size": 123328,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1484427813009876414&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Wisconsin-Madison; University of Cambridge; University of Cambridge; University of Cambridge",
        "aff_domain": "CS.WISC.EDU;STATSLAB.CAM.AC.UK;CAM.AC.UK;CAM.AC.UK",
        "email": "CS.WISC.EDU;STATSLAB.CAM.AC.UK;CAM.AC.UK;CAM.AC.UK",
        "github": "",
        "project": "arXiv:2301.03566",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Wisconsin-Madison;University of Cambridge",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.wisc.edu;https://www.cam.ac.uk",
        "aff_unique_abbr": "UW-Madison;Cambridge",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Madison;Cambridge",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "2a6e2ebad7",
        "title": "Sparse PCA Beyond Covariance Thresholding",
        "site": "https://proceedings.mlr.press/v195/novikov23a.html",
        "author": "Gleb Novikov",
        "abstract": "In the Wishart model for sparse PCAwe are given $n$ samples $Y_1,\\ldots,  Y_n$ drawn independently from a $d$-dimensional Gaussian distribution $N({0, Id + \\beta vv^\\top})$, where $\\beta > 0$ and $v\\in \\mathbb{R}^d$ is a $k$-sparse unit vector, and we wish to recover $v$ (up to sign).We show that if $n \\ge \\Omega(d)$, then for every $t \\ll k$ there exists an algorithm running in time $n\\cdot d^{O(t)}$ that solves this problem as long as\\[\\beta \\gtrsim \\frac{k}{\\sqrt{nt}}\\sqrt{\\ln({2 + td/k^2})}\\,.\\]Prior to this work, the best polynomial time algorithm in the regime $k\\approx \\sqrt{d}$, called \\emph{Covariance Thresholding} (proposed in  Krauthgamer et al. (2015) and analyzed in Deshpande and Montanari (2014))), required $\\beta \\gtrsim \\frac{k}{\\sqrt{n}}\\sqrt{\\ln({2 + d/k^2})}$.For large enough constant $t$ our algorithm runs in polynomial time and has better guarantees than Covariance Thresholding.Previously known algorithms with such guarantees required quasi-polynomial time $d^{O(\\log d)}$.Our idea is based on the idea of Alon et al. (1998) for reducing the clique size in the planted clique problem.Moreover, we show that it is possible to combine our techniques with recent results on sparse PCA with symmetric heavy-tailed noise d\u2019Orsi et al. (2022).Their model generalizes both sparse PCA and the planted clique problem.In particular, in the regime $k \\approx \\sqrt{d}$ we get the first polynomial time algorithm that works with symmetric heavy-tailed noise, while the algorithm from  d\u2019Orsi et al. (2022) requires quasi-polynomial time in these settings. As a consequence, we get an algorithm that solves a problem that captures both sparse PCA and planted clique and achieves best known guarantees for both of them.In addition, we show that our techniques work with sparse PCA with adversarial perturbations studied in d\u2019Orsi et al. (2020).This model generalizes not only sparse PCA, but also the sparse planted vector problem.As a consequence, we provide polynomial time algorithms for the sparse planted vector problem that have better guarantees thanthe state of the art in some regimes.",
        "bibtex": "@InProceedings{pmlr-v195-novikov23a,\n  title = \t {Sparse PCA Beyond Covariance Thresholding},\n  author =       {Novikov, Gleb},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4737--4776},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/novikov23a/novikov23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/novikov23a.html},\n  abstract = \t {In the Wishart model for sparse PCAwe are given $n$ samples $Y_1,\\ldots,  Y_n$ drawn independently from a $d$-dimensional Gaussian distribution $N({0, Id + \\beta vv^\\top})$, where $\\beta > 0$ and $v\\in \\mathbb{R}^d$ is a $k$-sparse unit vector, and we wish to recover $v$ (up to sign).We show that if $n \\ge \\Omega(d)$, then for every $t \\ll k$ there exists an algorithm running in time $n\\cdot d^{O(t)}$ that solves this problem as long as\\[\\beta \\gtrsim \\frac{k}{\\sqrt{nt}}\\sqrt{\\ln({2 + td/k^2})}\\,.\\]Prior to this work, the best polynomial time algorithm in the regime $k\\approx \\sqrt{d}$, called \\emph{Covariance Thresholding} (proposed in  Krauthgamer et al. (2015) and analyzed in Deshpande and Montanari (2014))), required $\\beta \\gtrsim \\frac{k}{\\sqrt{n}}\\sqrt{\\ln({2 + d/k^2})}$.For large enough constant $t$ our algorithm runs in polynomial time and has better guarantees than Covariance Thresholding.Previously known algorithms with such guarantees required quasi-polynomial time $d^{O(\\log d)}$.Our idea is based on the idea of Alon et al. (1998) for reducing the clique size in the planted clique problem.Moreover, we show that it is possible to combine our techniques with recent results on sparse PCA with symmetric heavy-tailed noise d\u2019Orsi et al. (2022).Their model generalizes both sparse PCA and the planted clique problem.In particular, in the regime $k \\approx \\sqrt{d}$ we get the first polynomial time algorithm that works with symmetric heavy-tailed noise, while the algorithm from  d\u2019Orsi et al. (2022) requires quasi-polynomial time in these settings. As a consequence, we get an algorithm that solves a problem that captures both sparse PCA and planted clique and achieves best known guarantees for both of them.In addition, we show that our techniques work with sparse PCA with adversarial perturbations studied in d\u2019Orsi et al. (2020).This model generalizes not only sparse PCA, but also the sparse planted vector problem.As a consequence, we provide polynomial time algorithms for the sparse planted vector problem that have better guarantees thanthe state of the art in some regimes.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/novikov23a/novikov23a.pdf",
        "supp": "",
        "pdf_size": 514166,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2333017211487641679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "ETH Zurich",
        "aff_domain": "inf.ethz.ch",
        "email": "inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "a5b9b739ea",
        "title": "Sparsity-aware generalization theory for deep neural networks",
        "site": "https://proceedings.mlr.press/v195/muthukumar23a.html",
        "author": "Ramchandran Muthukumar; Jeremias Sulam",
        "abstract": "Deep artificial neural networks achieve surprising generalization abilities that remain poorly understood. In this paper, we present a new approach to analyzing generalization for deep feed-forward ReLU networks that takes advantage of the degree of sparsity that is achieved in the hidden layer activations. By developing a framework that accounts for this reduced effective model size for each input sample, we are able to show fundamental trade-offs between sparsity and generalization. Importantly, our results make no strong assumptions about the degree of sparsity achieved by the model, and it improves over recent norm-based approaches. We  illustrate our results numerically, demonstrating non-vacuous bounds when coupled with data-dependent priors even in over-parametrized settings.",
        "bibtex": "@InProceedings{pmlr-v195-muthukumar23a,\n  title = \t {Sparsity-aware generalization theory for deep neural networks},\n  author =       {Muthukumar, Ramchandran and Sulam, Jeremias},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5311--5342},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/muthukumar23a/muthukumar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/muthukumar23a.html},\n  abstract = \t {Deep artificial neural networks achieve surprising generalization abilities that remain poorly understood. In this paper, we present a new approach to analyzing generalization for deep feed-forward ReLU networks that takes advantage of the degree of sparsity that is achieved in the hidden layer activations. By developing a framework that accounts for this reduced effective model size for each input sample, we are able to show fundamental trade-offs between sparsity and generalization. Importantly, our results make no strong assumptions about the degree of sparsity achieved by the model, and it improves over recent norm-based approaches. We  illustrate our results numerically, demonstrating non-vacuous bounds when coupled with data-dependent priors even in over-parametrized settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/muthukumar23a/muthukumar23a.pdf",
        "supp": "",
        "pdf_size": 685416,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16756549183930168320&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science & Mathematical Institute for Data Science, Johns Hopkins University; Department of Biomedical Engineering & Mathematical Institute for Data Science, Johns Hopkins University",
        "aff_domain": "JHU.EDU;JHU.EDU",
        "email": "JHU.EDU;JHU.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science & Mathematical Institute for Data Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9ab99c3085",
        "title": "Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems",
        "site": "https://proceedings.mlr.press/v195/lei23a.html",
        "author": "Yunwen Lei",
        "abstract": "Stochastic optimization has found wide applications in minimizing objective functions in machine learning, which motivates a lot of theoretical studies to understand its practical success. Most of existing studies focus on the convergence of optimization errors, while the generalization analysis of stochastic optimization is much lagging behind. This is especially the case for nonconvex and nonsmooth problems often encountered in practice. In this paper, we initialize a systematic stability and generalization analysis of stochastic optimization on nonconvex and nonsmooth problems. We introduce novel algorithmic stability measures and establish their quantitative connection on the gap between population gradients and empirical gradients, which is then further extended to study the gap between the Moreau envelope of the empirical risk and that of the population risk. To our knowledge, these quantitative connection between stability and generalization in terms of either gradients or Moreau envelopes have not been studied in the literature. We introduce a class of sampling-determined algorithms, for which we develop bounds for three stability measures. Finally, we apply these results to derive error bounds for stochastic gradient descent and its adaptive variant, where we show how to achieve an implicit regularization by tuning the step sizes and the number of iterations.",
        "bibtex": "@InProceedings{pmlr-v195-lei23a,\n  title = \t {Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems},\n  author =       {Lei, Yunwen},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {191--227},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/lei23a/lei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/lei23a.html},\n  abstract = \t {Stochastic optimization has found wide applications in minimizing objective functions in machine learning, which motivates a lot of theoretical studies to understand its practical success. Most of existing studies focus on the convergence of optimization errors, while the generalization analysis of stochastic optimization is much lagging behind. This is especially the case for nonconvex and nonsmooth problems often encountered in practice. In this paper, we initialize a systematic stability and generalization analysis of stochastic optimization on nonconvex and nonsmooth problems. We introduce novel algorithmic stability measures and establish their quantitative connection on the gap between population gradients and empirical gradients, which is then further extended to study the gap between the Moreau envelope of the empirical risk and that of the population risk. To our knowledge, these quantitative connection between stability and generalization in terms of either gradients or Moreau envelopes have not been studied in the literature. We introduce a class of sampling-determined algorithms, for which we develop bounds for three stability measures. Finally, we apply these results to derive error bounds for stochastic gradient descent and its adaptive variant, where we show how to achieve an implicit regularization by tuning the step sizes and the number of iterations.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/lei23a/lei23a.pdf",
        "supp": "",
        "pdf_size": 505693,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3543878268357801720&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics, The University of Hong Kong",
        "aff_domain": "HKU.HK",
        "email": "HKU.HK",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Hong Kong",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "id": "c61e295dc0",
        "title": "Statistical and Computational Limits for Tensor-on-Tensor Association Detection",
        "site": "https://proceedings.mlr.press/v195/diakonikolas23d.html",
        "author": "Ilias Diakonikolas; Daniel M. Kane; Yuetian Luo; Anru Zhang",
        "abstract": "In this paper, we consider the tensor-on-tensor association detection problem, where the goal is to detect whether there is an association between the tensor responses to tensor covariates linked via a low-rank tensor parameter. We first In this paper, we consider the tensor-on-tensor association detection problem, where the goal is to detect whether there is an association between the tensor responses to tensor covariates linked via a low-rank tensor parameter. We first develop tight bounds on the signal-to-noise ratio (SNR) such that the detection problem is statistically possible. We then provide testing procedures that succeed when the SNR is above the threshold. On the other hand, the statistical optimal tests often require computing the largest singular value of a given tensor, which can be NP-hard in general. To complement that, we develop efficient polynomial-time testing procedures with provable guarantees. We also develop matching lower bounds under the Statistical Query model and show that the SNRs required by the proposed polynomial-time algorithms are essential for computational efficiency. We identify a gap that appears between the SNR requirements of the optimal unconstrained-time tests and polynomial-time tests if and only if the sum of the tensor response order and the tensor covariate order is no less than three. To our best knowledge, this is the first complete characterization of the statistical and computational limits for the general tensor-on-tensor association detection problem. Our findings significantly generalize the results in the literature on signal detection in linear regression and low-rank matrix trace regression. Finally, the connection on the computational hardness of the detection problem and the corresponding estimation problem is discussed.",
        "bibtex": "@InProceedings{pmlr-v195-diakonikolas23d,\n  title = \t {Statistical and Computational Limits for Tensor-on-Tensor Association Detection},\n  author =       {Diakonikolas, Ilias and Kane, Daniel M. and Luo, Yuetian and Zhang, Anru},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5260--5310},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/diakonikolas23d/diakonikolas23d.pdf},\n  url = \t {https://proceedings.mlr.press/v195/diakonikolas23d.html},\n  abstract = \t {In this paper, we consider the tensor-on-tensor association detection problem, where the goal is to detect whether there is an association between the tensor responses to tensor covariates linked via a low-rank tensor parameter. We first In this paper, we consider the tensor-on-tensor association detection problem, where the goal is to detect whether there is an association between the tensor responses to tensor covariates linked via a low-rank tensor parameter. We first develop tight bounds on the signal-to-noise ratio (SNR) such that the detection problem is statistically possible. We then provide testing procedures that succeed when the SNR is above the threshold. On the other hand, the statistical optimal tests often require computing the largest singular value of a given tensor, which can be NP-hard in general. To complement that, we develop efficient polynomial-time testing procedures with provable guarantees. We also develop matching lower bounds under the Statistical Query model and show that the SNRs required by the proposed polynomial-time algorithms are essential for computational efficiency. We identify a gap that appears between the SNR requirements of the optimal unconstrained-time tests and polynomial-time tests if and only if the sum of the tensor response order and the tensor covariate order is no less than three. To our best knowledge, this is the first complete characterization of the statistical and computational limits for the general tensor-on-tensor association detection problem. Our findings significantly generalize the results in the literature on signal detection in linear regression and low-rank matrix trace regression. Finally, the connection on the computational hardness of the detection problem and the corresponding estimation problem is discussed.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/diakonikolas23d/diakonikolas23d.pdf",
        "supp": "",
        "pdf_size": 1211160,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17239139999170353209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Wisconsin-Madison; University of California, San Diego; The University of Chicago; Duke University",
        "aff_domain": "CS.WISC.EDU;CS.UCSD.EDU;UCHICAGO.EDU;DUKE.EDU",
        "email": "CS.WISC.EDU;CS.UCSD.EDU;UCHICAGO.EDU;DUKE.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "University of Wisconsin-Madison;University of California, San Diego;University of Chicago;Duke University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.wisc.edu;https://www.ucsd.edu;https://www.uchicago.edu;https://www.duke.edu",
        "aff_unique_abbr": "UW-Madison;UCSD;UChicago;Duke",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Madison;San Diego;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "73d384e26d",
        "title": "Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression",
        "site": "https://proceedings.mlr.press/v195/arpino23a.html",
        "author": "Gabriel Arpino; Ramji Venkataramanan",
        "abstract": "We consider the problem of mixed sparse linear regression with two components, where two k-sparse signals \u03b2_1, \u03b2_2 \u2208 R^p are to be recovered from n unlabelled noisy linear measurements. The sparsity is allowed to be sublinear in the dimension (k = o(p)), and the additive noise is assumed to be independent Gaussian with variance \u03c3^2. Prior work has shown that the problem suffers from a k/SNR^2 -to- k^2/SNR^2 statistical-to-computational gap, resembling other computationally challenging high- dimensional inference problems such as Sparse PCA and Robust Sparse Mean Estimation (Brennan and Bresler, 2020b); here SNR := \u2225\u03b21\u2225^2/\u03c3^2 = \u2225\u03b22\u2225^2/\u03c3^2 is the signal-to-noise ratio. We establish the existence of a more extensive k/SNR^2 -to- k^2 (SNR+1)^2/SNR^2 computational barrier for this problem through the method of low-degree polynomials, but show that the problem is computationally hard only in a very narrow symmetric parameter regime. We identify a smooth information-computation tradeoff between the sample complexity n and runtime exp( \u0398(k^2(SNR + 1)^2/(nSNR^2))) for any randomized algorithm in this hard regime. Via a simple reduction, this provides novel rigorous evidence for the existence of a computational barrier to solving exact support recovery in sparse phase retrieval with sample complexity n = o(k^2). Our second contribution is to analyze a simple thresholding algorithm which, outside of the narrow regime where the problem is hard, solves the associated mixed regression detection problem in O(np) time and matches the sample complexity required for (non-mixed) sparse linear regression of k(SNR+1)/SNR log p; this allows the recovery problem to be subsequently solved by state-of-the-art techniques from the dense case. As a special case of our results, we show that this simple algorithm is order-optimal among a large family of algorithms in solving exact signed support recovery in sparse linear regression. To the best of our knowledge, this is the first thorough study of the interplay between mixture symmetry, signal sparsity, and their joint impact on the computational hardness of mixed sparse linear regression.",
        "bibtex": "@InProceedings{pmlr-v195-arpino23a,\n  title = \t {Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression},\n  author =       {Arpino, Gabriel and Venkataramanan, Ramji},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {921--986},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/arpino23a/arpino23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/arpino23a.html},\n  abstract = \t {We consider the problem of mixed sparse linear regression with two components, where two k-sparse signals \u03b2_1, \u03b2_2 \u2208 R^p are to be recovered from n unlabelled noisy linear measurements. The sparsity is allowed to be sublinear in the dimension (k = o(p)), and the additive noise is assumed to be independent Gaussian with variance \u03c3^2. Prior work has shown that the problem suffers from a k/SNR^2 -to- k^2/SNR^2 statistical-to-computational gap, resembling other computationally challenging high- dimensional inference problems such as Sparse PCA and Robust Sparse Mean Estimation (Brennan and Bresler, 2020b); here SNR := \u2225\u03b21\u2225^2/\u03c3^2 = \u2225\u03b22\u2225^2/\u03c3^2 is the signal-to-noise ratio. We establish the existence of a more extensive k/SNR^2 -to- k^2 (SNR+1)^2/SNR^2 computational barrier for this problem through the method of low-degree polynomials, but show that the problem is computationally hard only in a very narrow symmetric parameter regime. We identify a smooth information-computation tradeoff between the sample complexity n and runtime exp( \u0398(k^2(SNR + 1)^2/(nSNR^2))) for any randomized algorithm in this hard regime. Via a simple reduction, this provides novel rigorous evidence for the existence of a computational barrier to solving exact support recovery in sparse phase retrieval with sample complexity n = o(k^2). Our second contribution is to analyze a simple thresholding algorithm which, outside of the narrow regime where the problem is hard, solves the associated mixed regression detection problem in O(np) time and matches the sample complexity required for (non-mixed) sparse linear regression of k(SNR+1)/SNR log p; this allows the recovery problem to be subsequently solved by state-of-the-art techniques from the dense case. As a special case of our results, we show that this simple algorithm is order-optimal among a large family of algorithms in solving exact signed support recovery in sparse linear regression. To the best of our knowledge, this is the first thorough study of the interplay between mixture symmetry, signal sparsity, and their joint impact on the computational hardness of mixed sparse linear regression.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/arpino23a/arpino23a.pdf",
        "supp": "",
        "pdf_size": 719095,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1179086423581372962&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Cambridge; University of Cambridge",
        "aff_domain": "CAM.AC.UK;CAM.AC.UK",
        "email": "CAM.AC.UK;CAM.AC.UK",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9b4473701c",
        "title": "Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective",
        "site": "https://proceedings.mlr.press/v195/simchowitz23a.html",
        "author": "Max Simchowitz; Abhishek Gupta; Kaiqing Zhang",
        "abstract": "Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call    \\emph{combinatorial distribution shift}, where (a) under the test- and training-distributions,  the labels $z$ are determined by pairs of features $(x,y)$, (b) the training  distribution has coverage of certain \\emph{marginal} distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is \\emph{not} covered by the training distribution. Focusing on the special case where the labels are given by \\emph{bilinear embeddings}  into a Hilbert space $\\mathcal H$: $\\mathbb{E}[z \\mid x,y ]=\u27e8f_{\\star}(x),g_{\\star}(y)\\rangle_{\\mathcal{H}}$, we aim to extrapolate to a test distribution domain that is {not} covered in training, or \\emph{bilinear combinatorial extrapolation}. Our setting generalizes a special case of matrix completion from missing-not-at-random data,  for which all existing results require the ground-truth matrices to be either \\emph{exactly low-rank}, or to exhibit very sharp spectral cutoffs.  In this work, we develop a series of theoretical results that enable bilinear combinatorial extrapolation under \\emph{gradual} spectral decay as observed in typical high-dimensional data, including novel algorithms, generalization guarantees, and linear-algebraic results. A key tool is a novel perturbation bound for the rank-$k$ singular value decomposition approximations between two matrices that depends on the \\emph{relative} spectral gap rather than the \\emph{absolute} spectral gap, a result we think may be of broader independent interest.",
        "bibtex": "@InProceedings{pmlr-v195-simchowitz23a,\n  title = \t {Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective},\n  author =       {Simchowitz, Max and Gupta, Abhishek and Zhang, Kaiqing},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3356--3468},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/simchowitz23a/simchowitz23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/simchowitz23a.html},\n  abstract = \t {Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call    \\emph{combinatorial distribution shift}, where (a) under the test- and training-distributions,  the labels $z$ are determined by pairs of features $(x,y)$, (b) the training  distribution has coverage of certain \\emph{marginal} distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is \\emph{not} covered by the training distribution. Focusing on the special case where the labels are given by \\emph{bilinear embeddings}  into a Hilbert space $\\mathcal H$: $\\mathbb{E}[z \\mid x,y ]=\u27e8f_{\\star}(x),g_{\\star}(y)\\rangle_{\\mathcal{H}}$, we aim to extrapolate to a test distribution domain that is {not} covered in training, or \\emph{bilinear combinatorial extrapolation}. Our setting generalizes a special case of matrix completion from missing-not-at-random data,  for which all existing results require the ground-truth matrices to be either \\emph{exactly low-rank}, or to exhibit very sharp spectral cutoffs.  In this work, we develop a series of theoretical results that enable bilinear combinatorial extrapolation under \\emph{gradual} spectral decay as observed in typical high-dimensional data, including novel algorithms, generalization guarantees, and linear-algebraic results. A key tool is a novel perturbation bound for the rank-$k$ singular value decomposition approximations between two matrices that depends on the \\emph{relative} spectral gap rather than the \\emph{absolute} spectral gap, a result we think may be of broader independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/simchowitz23a/simchowitz23a.pdf",
        "supp": "",
        "pdf_size": 1317617,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15824335602523840442&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "MIT, Cambridge, MA, 02139; University of Washington, Seattle, WA, 98105; University of Maryland, College Park, MD, 20740",
        "aff_domain": "MIT.EDU;CS.WASHINGTON.EDU;UMD.EDU",
        "email": "MIT.EDU;CS.WASHINGTON.EDU;UMD.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Washington;University of Maryland",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://web.mit.edu;https://www.washington.edu;https://www/umd.edu",
        "aff_unique_abbr": "MIT;UW;UMD",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Cambridge;Seattle;College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "43685bb094",
        "title": "Testing of Index-Invariant Properties in the Huge Object Model",
        "site": "https://proceedings.mlr.press/v195/chakraborty23a.html",
        "author": "Sourav Chakraborty; Eldar Fischer; Arijit Ghosh; Gopinath Mishra; Sayantan Sen",
        "abstract": "Distribution testing is a central part of property testing, with applications to various research areas, such as computational and statistical learning, information theory, and probabilistic program checking.    The original distribution testing model relies on samples drawn independently from the distribution to be tested. However, when the distribution in question is over the $n$-dimensional Hamming cube $\\left\\{0,1\\right\\}^{n}$ for a large $n$, even reading a few samples is infeasible. To address this, Goldreich and Ron [ITCS 2022] have defined a model called the \\emph{huge object model}, in which the samples may only be queried in a few places.For any sample/query model, the following three questions are considered fundamental: {\\bf (i)} understand what classes of objects can be  \u201clearned \\emph{easily}\", {\\bf (ii)} characterize {\\em testable properties}, that is, properties that can be tested in the given sample/query model using a constant number of samples/queries, and {\\bf (iii)} understand the {\\em gap} between {\\em adaptive} and {\\em non-adaptive} query/sample complexities.In this work, we study these questions for the huge object model for distribution testing. To do so, we initiate a study of a general class of distribution properties that are invariant under a permutation of the indices of the vectors in $\\left\\{0,1\\right\\}^{n}$, while still not being necessarily fully symmetric as per the definition used in traditional distribution testing.We prove that every distribution over  $\\left\\{0,1\\right\\}^{n}$ whose support has a bounded VC-dimension can be efficiently learned up to a permutation. The number of queries made by the algorithm depends only on the VC-dimension of the support of the distribution and is independent of $n$. This gives efficient testers for index-invariant distribution properties that admit a global VC-dimension bound. To complement this result, we argue that satisfying only index-invariance or only a VC-dimension bound is insufficient to guarantee a tester whose query complexity is independent of $n$. Moreover, we prove that the dependency of the sample and query complexities of our tester on the VC-dimension is essentially tight. As a second part of this work, we address the question of thenumber of queries required for non-adaptive testing. We show that it can be at most quadratic in the numberof queries required for an adaptive tester in the case of index-invariant properties. This contrasts with the tight (easily provable) exponential gap between adaptive and non-adaptive testers for general non-index-invariant properties. Finally, we provide an index-invariant property for which the quadratic gap between adaptive and non-adaptive query complexities for testing is almost tight.",
        "bibtex": "@InProceedings{pmlr-v195-chakraborty23a,\n  title = \t {Testing of Index-Invariant Properties in the Huge Object Model},\n  author =       {Chakraborty, Sourav and Fischer, Eldar and Ghosh, Arijit and Mishra, Gopinath and Sen, Sayantan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3065--3136},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/chakraborty23a/chakraborty23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/chakraborty23a.html},\n  abstract = \t {Distribution testing is a central part of property testing, with applications to various research areas, such as computational and statistical learning, information theory, and probabilistic program checking.    The original distribution testing model relies on samples drawn independently from the distribution to be tested. However, when the distribution in question is over the $n$-dimensional Hamming cube $\\left\\{0,1\\right\\}^{n}$ for a large $n$, even reading a few samples is infeasible. To address this, Goldreich and Ron [ITCS 2022] have defined a model called the \\emph{huge object model}, in which the samples may only be queried in a few places.For any sample/query model, the following three questions are considered fundamental: {\\bf (i)} understand what classes of objects can be  \u201clearned \\emph{easily}\", {\\bf (ii)} characterize {\\em testable properties}, that is, properties that can be tested in the given sample/query model using a constant number of samples/queries, and {\\bf (iii)} understand the {\\em gap} between {\\em adaptive} and {\\em non-adaptive} query/sample complexities.In this work, we study these questions for the huge object model for distribution testing. To do so, we initiate a study of a general class of distribution properties that are invariant under a permutation of the indices of the vectors in $\\left\\{0,1\\right\\}^{n}$, while still not being necessarily fully symmetric as per the definition used in traditional distribution testing.We prove that every distribution over  $\\left\\{0,1\\right\\}^{n}$ whose support has a bounded VC-dimension can be efficiently learned up to a permutation. The number of queries made by the algorithm depends only on the VC-dimension of the support of the distribution and is independent of $n$. This gives efficient testers for index-invariant distribution properties that admit a global VC-dimension bound. To complement this result, we argue that satisfying only index-invariance or only a VC-dimension bound is insufficient to guarantee a tester whose query complexity is independent of $n$. Moreover, we prove that the dependency of the sample and query complexities of our tester on the VC-dimension is essentially tight. As a second part of this work, we address the question of thenumber of queries required for non-adaptive testing. We show that it can be at most quadratic in the numberof queries required for an adaptive tester in the case of index-invariant properties. This contrasts with the tight (easily provable) exponential gap between adaptive and non-adaptive testers for general non-index-invariant properties. Finally, we provide an index-invariant property for which the quadratic gap between adaptive and non-adaptive query complexities for testing is almost tight.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/chakraborty23a/chakraborty23a.pdf",
        "supp": "",
        "pdf_size": 738485,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1377323645009028579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Indian Statistical Institute, Kolkata, India; Technion - Israel Institute of Technology, Israel; Indian Statistical Institute, Kolkata, India; University of Warwick, UK; National University of Singapore, Singapore + Indian Statistical Institute, Kolkata, India",
        "aff_domain": "GMAIL.COM;CS.TECHNION.AC.IL;GMAIL.COM;GMAIL.COM;GMAIL.COM",
        "email": "GMAIL.COM;CS.TECHNION.AC.IL;GMAIL.COM;GMAIL.COM;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;3+0",
        "aff_unique_norm": "Indian Statistical Institute;Technion - Israel Institute of Technology;University of Warwick;National University of Singapore",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.isical.ac.in;https://www.technion.ac.il/en/;https://www.warwick.ac.uk;https://www.nus.edu.sg",
        "aff_unique_abbr": "ISI;Technion;Warwick;NUS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kolkata;",
        "aff_country_unique_index": "0;1;0;2;3+0",
        "aff_country_unique": "India;Israel;United Kingdom;Singapore"
    },
    {
        "id": "abef7bdb37",
        "title": "The $k$-Cap Process on Geometric Random Graphs",
        "site": "https://proceedings.mlr.press/v195/reid23a.html",
        "author": "Mirabel E. Reid; Santosh S. Vempala",
        "abstract": "The $k$-cap (or $k$-winners-take-all) process on a graph works as follows: in each iteration, a subset of $k$ vertices of the graph are identified as winners; the next round winners are the vertices that have the highest total degree from the current winners, with ties broken randomly. This natural process is a simple model of firing activity and inhibition in the brain and has been found to have desirable robustness properties as an activation function. We study its convergence on directed geometric random graphs in any constant dimension, revealing rather surprising behavior, with the support of the current active set converging to lie in a small ball and the active set itself remaining essentially random within that.",
        "bibtex": "@InProceedings{pmlr-v195-reid23a,\n  title = \t {The $k$-Cap Process on Geometric Random Graphs},\n  author =       {Reid, Mirabel E. and Vempala, Santosh S.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3469--3509},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/reid23a/reid23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/reid23a.html},\n  abstract = \t {The $k$-cap (or $k$-winners-take-all) process on a graph works as follows: in each iteration, a subset of $k$ vertices of the graph are identified as winners; the next round winners are the vertices that have the highest total degree from the current winners, with ties broken randomly. This natural process is a simple model of firing activity and inhibition in the brain and has been found to have desirable robustness properties as an activation function. We study its convergence on directed geometric random graphs in any constant dimension, revealing rather surprising behavior, with the support of the current active set converging to lie in a small ball and the active set itself remaining essentially random within that.  }\n}",
        "pdf": "https://proceedings.mlr.press/v195/reid23a/reid23a.pdf",
        "supp": "",
        "pdf_size": 654628,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15636942994561414717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Georgia Tech; Georgia Tech",
        "aff_domain": "gatech.edu;gatech.edu",
        "email": "gatech.edu;gatech.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9483ef0049",
        "title": "The Aggregation\u2013Heterogeneity Trade-off in Federated Learning",
        "site": "https://proceedings.mlr.press/v195/zhao23b.html",
        "author": "Xuyang Zhao; Huiyuan Wang; Wei Lin",
        "abstract": "Conventional wisdom in machine learning holds that the more data you train your model on, the better the model can perform. Accordingly, a plethora of federated learning methods have been developed to aggregate as many local samples as possible. Contrary to this belief, this paper shows that aggregation of more data is not necessarily beneficial in the presence of heterogeneity, and reveals a fundamental trade-off between aggregation and heterogeneity in federated learning. We consider a general family of weighted $M$-estimators that interpolate between FedAvg and the local estimator, in which an aggregation rule is determined by the weights of local samples. We derive an upper bound for the estimation error of the weighted $M$-estimators, which decomposes into a bias term induced by heterogeneity and a variance term influenced by aggregation. A measure of heterogeneity, the federated smoothness $\\beta$, is introduced to simplify the general result. As an important consequence, the optimal aggregation rule for each local device is to aggregate only its $\\lfloor K^{2\\beta/(2\\beta+1)}/(n/\\sigma^2)^{1/(2\\beta+1)}\\rfloor\\vee 1$ closest neighbors among the $K$ devices, where $n$ is the local sample size and $\\sigma^2$ is the noise variance. Moreover, we show that our estimator, termed FedKNN, attains the minimax optimal rate over a certain parameter space characterized by $\\beta$. This optimal procedure depends crucially on the neighboring structure among devices in terms of the proximity of local parameters. Finally, we prove that without such prior knowledge no estimator can achieve a convergence rate faster than $O(\\sigma^2/n)$ and hence adaptation is impossible.",
        "bibtex": "@InProceedings{pmlr-v195-zhao23b,\n  title = \t {The Aggregation\u2013Heterogeneity Trade-off in Federated Learning},\n  author =       {Zhao, Xuyang and Wang, Huiyuan and Lin, Wei},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5478--5502},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/zhao23b/zhao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/zhao23b.html},\n  abstract = \t {Conventional wisdom in machine learning holds that the more data you train your model on, the better the model can perform. Accordingly, a plethora of federated learning methods have been developed to aggregate as many local samples as possible. Contrary to this belief, this paper shows that aggregation of more data is not necessarily beneficial in the presence of heterogeneity, and reveals a fundamental trade-off between aggregation and heterogeneity in federated learning. We consider a general family of weighted $M$-estimators that interpolate between FedAvg and the local estimator, in which an aggregation rule is determined by the weights of local samples. We derive an upper bound for the estimation error of the weighted $M$-estimators, which decomposes into a bias term induced by heterogeneity and a variance term influenced by aggregation. A measure of heterogeneity, the federated smoothness $\\beta$, is introduced to simplify the general result. As an important consequence, the optimal aggregation rule for each local device is to aggregate only its $\\lfloor K^{2\\beta/(2\\beta+1)}/(n/\\sigma^2)^{1/(2\\beta+1)}\\rfloor\\vee 1$ closest neighbors among the $K$ devices, where $n$ is the local sample size and $\\sigma^2$ is the noise variance. Moreover, we show that our estimator, termed FedKNN, attains the minimax optimal rate over a certain parameter space characterized by $\\beta$. This optimal procedure depends crucially on the neighboring structure among devices in terms of the proximity of local parameters. Finally, we prove that without such prior knowledge no estimator can achieve a convergence rate faster than $O(\\sigma^2/n)$ and hence adaptation is impossible.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/zhao23b/zhao23b.pdf",
        "supp": "",
        "pdf_size": 355286,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8811391870960897060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "School of Mathematical Sciences and Center for Statistical Science, Peking University; School of Mathematical Sciences and Center for Statistical Science, Peking University; School of Mathematical Sciences and Center for Statistical Science, Peking University",
        "aff_domain": "PKU.EDU.CN;PKU.EDU.CN;MATH.PKU.EDU.CN",
        "email": "PKU.EDU.CN;PKU.EDU.CN;MATH.PKU.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "School of Mathematical Sciences, Center for Statistical Science",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "80c4bea234",
        "title": "The Complexity of Markov Equilibrium in Stochastic Games",
        "site": "https://proceedings.mlr.press/v195/daskalakis23a.html",
        "author": "Constantinos Daskalakis; Noah Golowich; Kaiqing Zhang",
        "abstract": "We show that computing approximate stationary Markov coarse correlated equilibria (CCE) in general-sum stochastic games is PPAD-hard, even when there are two players, the game is turn-based, the discount factor is an absolute constant, and the approximation is an absolute constant. Our intractability results stand in sharp contrast to the results in normal-form games, where exact CCEs are efficiently computable. A fortiori, our results imply that, in the setting of multi-agent reinforcement learning (MARL), it is computationally hard to learn stationary Markov CCE policies in stochastic games, even when the interaction is two-player and turn-based, and both the discount factor and the desired approximation of the learned policies is an absolute constant. In turn, these results stand in sharp contrast to single-agent reinforcement learning (RL) where near-optimal stationary Markov policies can be computationally efficiently learned. Complementing our intractability results for stationary Markov CCEs, we provide a decentralized algorithm (assuming shared randomness among players) for learning a nonstationary Markov CCE policy with polynomial time and sample complexity in all problem parameters. Previous work for learning Markov CCE policies all required exponential time and sample complexity in the number of players. In balance, our work advocates for the use of nonstationary Markov CCE policies as a computationally and statistically tractable solution concept in MARL, advancing an important and outstanding frontier in machine learning.",
        "bibtex": "@InProceedings{pmlr-v195-daskalakis23a,\n  title = \t {The Complexity of Markov Equilibrium in Stochastic Games},\n  author =       {Daskalakis, Constantinos and Golowich, Noah and Zhang, Kaiqing},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4180--4234},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/daskalakis23a/daskalakis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/daskalakis23a.html},\n  abstract = \t {We show that computing approximate stationary Markov coarse correlated equilibria (CCE) in general-sum stochastic games is PPAD-hard, even when there are two players, the game is turn-based, the discount factor is an absolute constant, and the approximation is an absolute constant. Our intractability results stand in sharp contrast to the results in normal-form games, where exact CCEs are efficiently computable. A fortiori, our results imply that, in the setting of multi-agent reinforcement learning (MARL), it is computationally hard to learn stationary Markov CCE policies in stochastic games, even when the interaction is two-player and turn-based, and both the discount factor and the desired approximation of the learned policies is an absolute constant. In turn, these results stand in sharp contrast to single-agent reinforcement learning (RL) where near-optimal stationary Markov policies can be computationally efficiently learned. Complementing our intractability results for stationary Markov CCEs, we provide a decentralized algorithm (assuming shared randomness among players) for learning a nonstationary Markov CCE policy with polynomial time and sample complexity in all problem parameters. Previous work for learning Markov CCE policies all required exponential time and sample complexity in the number of players. In balance, our work advocates for the use of nonstationary Markov CCE policies as a computationally and statistically tractable solution concept in MARL, advancing an important and outstanding frontier in machine learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/daskalakis23a/daskalakis23a.pdf",
        "supp": "",
        "pdf_size": 624689,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13416584443490866696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "MIT, Cambridge, MA, 02139; MIT, Cambridge, MA, 02139; University of Maryland, College Park, MD, 20740",
        "aff_domain": "MIT.EDU;MIT.EDU;UMD.EDU",
        "email": "MIT.EDU;MIT.EDU;UMD.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Maryland",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www/umd.edu",
        "aff_unique_abbr": "MIT;UMD",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Cambridge;College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5284dae10c",
        "title": "The Computational Complexity of Finding Stationary Points in Non-Convex Optimization",
        "site": "https://proceedings.mlr.press/v195/hollender23a.html",
        "author": "Alexandros Hollender; Emmanouil Zampetakis",
        "abstract": "Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions $f$ over unrestricted $d$-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension $d$ of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:1.The problem of finding approximate stationary points over unrestricted domains is PLS-complete.2. For $d = 2$, we provide a zero-order algorithm for finding $\\varepsilon$-approximate stationary points that requires at most $O(1/\\varepsilon)$ value queries to the objective function.3. We show that any algorithm needs at least $\\Omega(1/\\varepsilon)$ queries to the objective function and/or its gradient to find $\\varepsilon$-approximate stationary points when $d=2$. Combined with the above, this characterizes the query complexity of this problem to be $\\Theta(1/\\varepsilon)$.4. For $d = 2$, we provide a zero-order algorithm for finding $\\varepsilon$-KKT points in constrained optimization problems that requires at most $O(1/\\sqrt{\\varepsilon})$ value queries to the objective function. This closes the gap between the works of Bubeck and Mikulincer (2020) and Vavasis (1993) and characterizes the query complexity of this problem to be $\\Theta(1/\\sqrt{\\varepsilon})$.5. We show that finding approximate KKT points in constrained optimization is reducible to finding approximate stationary points in unconstrained optimization but the converse is impossible.",
        "bibtex": "@InProceedings{pmlr-v195-hollender23a,\n  title = \t {The Computational Complexity of Finding Stationary Points in Non-Convex Optimization},\n  author =       {Hollender, Alexandros and Zampetakis, Emmanouil},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5571--5572},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hollender23a/hollender23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hollender23a.html},\n  abstract = \t {Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions $f$ over unrestricted $d$-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension $d$ of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:1.The problem of finding approximate stationary points over unrestricted domains is PLS-complete.2. For $d = 2$, we provide a zero-order algorithm for finding $\\varepsilon$-approximate stationary points that requires at most $O(1/\\varepsilon)$ value queries to the objective function.3. We show that any algorithm needs at least $\\Omega(1/\\varepsilon)$ queries to the objective function and/or its gradient to find $\\varepsilon$-approximate stationary points when $d=2$. Combined with the above, this characterizes the query complexity of this problem to be $\\Theta(1/\\varepsilon)$.4. For $d = 2$, we provide a zero-order algorithm for finding $\\varepsilon$-KKT points in constrained optimization problems that requires at most $O(1/\\sqrt{\\varepsilon})$ value queries to the objective function. This closes the gap between the works of Bubeck and Mikulincer (2020) and Vavasis (1993) and characterizes the query complexity of this problem to be $\\Theta(1/\\sqrt{\\varepsilon})$.5. We show that finding approximate KKT points in constrained optimization is reducible to finding approximate stationary points in unconstrained optimization but the converse is impossible.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/hollender23a/hollender23a.pdf",
        "supp": "",
        "pdf_size": 96284,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15098995547299889226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "\u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne; University of California, Berkeley",
        "aff_domain": "EPFL.CH;BERKELEY.EDU",
        "email": "EPFL.CH;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "EPFL;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.epfl.ch;https://www.berkeley.edu",
        "aff_unique_abbr": "EPFL;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "c8be94922f",
        "title": "The Expressive Power of Tuning Only the Normalization Layers",
        "site": "https://proceedings.mlr.press/v195/giannou23a.html",
        "author": "Angeliki Giannou; Shashank Rajput; Dimitris Papailiopoulos",
        "abstract": "Feature normalization transforms such as Batch and Layer-Normalization have become indispensable ingredients of state-of-the-art deep neural networks. Recent studies on fine-tuning large pretrained models indicate that just tuning the parameters of these affine transforms can achieve high accuracy for downstream tasks. These findings open the questions about the expressive power of tuning  the normalization layers of frozen networks. In this work, we take the first step towards this question and show that for random ReLU networks, finetuning only its normalization layers can reconstruct  any target network that is $O(\\sqrt{\\text{width}})$ times smaller. We show that this holds even for randomly sparsified networks, under sufficient overparameterization, in agreement with prior empirical work.",
        "bibtex": "@InProceedings{pmlr-v195-giannou23a,\n  title = \t {The Expressive Power of Tuning Only the Normalization Layers},\n  author =       {Giannou, Angeliki and Rajput, Shashank and Papailiopoulos, Dimitris},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4130--4131},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/giannou23a/giannou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/giannou23a.html},\n  abstract = \t {Feature normalization transforms such as Batch and Layer-Normalization have become indispensable ingredients of state-of-the-art deep neural networks. Recent studies on fine-tuning large pretrained models indicate that just tuning the parameters of these affine transforms can achieve high accuracy for downstream tasks. These findings open the questions about the expressive power of tuning  the normalization layers of frozen networks. In this work, we take the first step towards this question and show that for random ReLU networks, finetuning only its normalization layers can reconstruct  any target network that is $O(\\sqrt{\\text{width}})$ times smaller. We show that this holds even for randomly sparsified networks, under sufficient overparameterization, in agreement with prior empirical work.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/giannou23a/giannou23a.pdf",
        "supp": "",
        "pdf_size": 117370,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3808744033997755396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": "WISC.EDU;GMAIL.COM;PAPAIL.IO",
        "email": "WISC.EDU;GMAIL.COM;PAPAIL.IO",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ef22e880c7",
        "title": "The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks",
        "site": "https://proceedings.mlr.press/v195/cao23a.html",
        "author": "Yuan Cao; Difan Zou; Yuanzhi Li; Quanquan Gu",
        "abstract": "We study the implicit bias of batch normalization trained by gradient descent. We show that when learning a linear model with batch normalization for binary classification, gradient descent converges to a uniform margin classifier on the training data with an $\\exp(-\\Omega(\\log^2t))$ convergence rate. This distinguishes linear models with batch normalization from those without batch normalization in terms of both the type of implicit bias and the convergence rate. We then further extend our result to a class of two-layer, single-filter convolutional neural networks, and show that batch normalization has an implicit bias towards a patch-wise uniform margin. Based on two examples, we demonstrate that patch-wise uniform margin classifiers can outperform the maximum margin classifiers in certain learning problems. Our results contribute to a better theoretical understanding of batch normalization.",
        "bibtex": "@InProceedings{pmlr-v195-cao23a,\n  title = \t {The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks},\n  author =       {Cao, Yuan and Zou, Difan and Li, Yuanzhi and Gu, Quanquan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5699--5753},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/cao23a/cao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/cao23a.html},\n  abstract = \t {We study the implicit bias of batch normalization trained by gradient descent. We show that when learning a linear model with batch normalization for binary classification, gradient descent converges to a uniform margin classifier on the training data with an $\\exp(-\\Omega(\\log^2t))$ convergence rate. This distinguishes linear models with batch normalization from those without batch normalization in terms of both the type of implicit bias and the convergence rate. We then further extend our result to a class of two-layer, single-filter convolutional neural networks, and show that batch normalization has an implicit bias towards a patch-wise uniform margin. Based on two examples, we demonstrate that patch-wise uniform margin classifiers can outperform the maximum margin classifiers in certain learning problems. Our results contribute to a better theoretical understanding of batch normalization.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/cao23a/cao23a.pdf",
        "supp": "",
        "pdf_size": 582381,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13477506160825888579&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "The University of Hong Kong; The University of Hong Kong; Carnegie Mellon University; University of California, Los Angeles",
        "aff_domain": "SAMPLE.COM;CS.HKU.HK;ANDREW.CMU.EDU;CS.UCLA.EDU",
        "email": "SAMPLE.COM;CS.HKU.HK;ANDREW.CMU.EDU;CS.UCLA.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Hong Kong;Carnegie Mellon University;University of California, Los Angeles",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.hku.hk;https://www.cmu.edu;https://www.ucla.edu",
        "aff_unique_abbr": "HKU;CMU;UCLA",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Hong Kong SAR;;Los Angeles",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "f6a52eaf2e",
        "title": "The One-Inclusion Graph Algorithm is not Always Optimal",
        "site": "https://proceedings.mlr.press/v195/aden-ali23a.html",
        "author": "Ishaq Aden-Ali; Yeshwanth Cherapanamjeri; Abhishek Shetty; Nikita Zhivotovskiy",
        "abstract": "The one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth achieves an optimal in-expectation risk bound in the standard PAC classification setup. In one of the first COLT open problems, Warmuth conjectured that this prediction strategy always implies an optimal high probability bound on the risk, and hence is also an optimal PAC algorithm. We refute this conjecture in the strongest sense: for any practically interesting Vapnik-Chervonenkis class, we provide an in-expectation optimal one-inclusion graph algorithm whose high probability risk bound cannot go beyond that implied by Markov\u2019s inequality. Our construction of these poorly performing one-inclusion graph algorithms uses Varshamov-Tenengolts error correcting codes. Our negative result has several implications. First, it shows that the same poor high-probability performance is inherited by several recent prediction strategies based on generalizations of the one-inclusion graph algorithm. Second, our analysis shows yet another statistical problem that enjoys an estimator that is provably optimal in expectation via a leave-one-out argument, but fails in the high-probability regime. This discrepancy occurs despite the boundedness of the binary loss for which arguments based on concentration inequalities often provide sharp high probability risk bounds.",
        "bibtex": "@InProceedings{pmlr-v195-aden-ali23a,\n  title = \t {The One-Inclusion Graph Algorithm is not Always Optimal},\n  author =       {Aden-Ali, Ishaq and Cherapanamjeri, Yeshwanth and Shetty, Abhishek and Zhivotovskiy, Nikita},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {72--88},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/aden-ali23a/aden-ali23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/aden-ali23a.html},\n  abstract = \t {The one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth achieves an optimal in-expectation risk bound in the standard PAC classification setup. In one of the first COLT open problems, Warmuth conjectured that this prediction strategy always implies an optimal high probability bound on the risk, and hence is also an optimal PAC algorithm. We refute this conjecture in the strongest sense: for any practically interesting Vapnik-Chervonenkis class, we provide an in-expectation optimal one-inclusion graph algorithm whose high probability risk bound cannot go beyond that implied by Markov\u2019s inequality. Our construction of these poorly performing one-inclusion graph algorithms uses Varshamov-Tenengolts error correcting codes. Our negative result has several implications. First, it shows that the same poor high-probability performance is inherited by several recent prediction strategies based on generalizations of the one-inclusion graph algorithm. Second, our analysis shows yet another statistical problem that enjoys an estimator that is provably optimal in expectation via a leave-one-out argument, but fails in the high-probability regime. This discrepancy occurs despite the boundedness of the binary loss for which arguments based on concentration inequalities often provide sharp high probability risk bounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/aden-ali23a/aden-ali23a.pdf",
        "supp": "",
        "pdf_size": 283939,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6455067138614207&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering and Computer Science, UC Berkeley; Department of Electrical Engineering and Computer Science, UC Berkeley; Department of Electrical Engineering and Computer Science, UC Berkeley; Department of Statistics, UC Berkeley",
        "aff_domain": "BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU",
        "email": "BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "536a65c906",
        "title": "The Sample Complexity of Approximate Rejection Sampling With Applications to Smoothed Online Learning",
        "site": "https://proceedings.mlr.press/v195/block23a.html",
        "author": "Adam Block; Yury Polyanskiy",
        "abstract": "Suppose we are given access to $n$ independent samples from distribution $\\mu$ and we wish to output one of them with the goal of making the outputdistributed as close as possible to a target distribution $\\nu$.  In this workwe show that the optimal total variation distance as a function of $n$ is givenby $\\tilde\\Theta(\\frac{D}{f\u2019(n)})$ over the class of all pairs $\\nu,\\mu$ with a bounded $f$-divergence $D_f(\\nu\\|\\mu)\\leq D$. Previously, this question was studied only for the case when the Radon-Nikodym derivative of $\\nu$ with respect to $\\mu$ is uniformly bounded. We then consider an application in theseemingly very different field of smoothed online learning, where we show that recent results on the minimax regret and the regret of oracle-efficient algorithmsstill hold even under relaxed constraints on the adversary (to have bounded $f$-divergence, as opposed to bounded Radon-Nikodym derivative).  Finally, we also study efficacy of importance sampling for mean estimates uniformover a function class and compare importance sampling with rejectionsampling.",
        "bibtex": "@InProceedings{pmlr-v195-block23a,\n  title = \t {The Sample Complexity of Approximate Rejection Sampling With Applications to Smoothed Online Learning},\n  author =       {Block, Adam and Polyanskiy, Yury},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {228--273},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/block23a/block23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/block23a.html},\n  abstract = \t {Suppose we are given access to $n$ independent samples from distribution $\\mu$ and we wish to output one of them with the goal of making the outputdistributed as close as possible to a target distribution $\\nu$.  In this workwe show that the optimal total variation distance as a function of $n$ is givenby $\\tilde\\Theta(\\frac{D}{f\u2019(n)})$ over the class of all pairs $\\nu,\\mu$ with a bounded $f$-divergence $D_f(\\nu\\|\\mu)\\leq D$. Previously, this question was studied only for the case when the Radon-Nikodym derivative of $\\nu$ with respect to $\\mu$ is uniformly bounded. We then consider an application in theseemingly very different field of smoothed online learning, where we show that recent results on the minimax regret and the regret of oracle-efficient algorithmsstill hold even under relaxed constraints on the adversary (to have bounded $f$-divergence, as opposed to bounded Radon-Nikodym derivative).  Finally, we also study efficacy of importance sampling for mean estimates uniformover a function class and compare importance sampling with rejectionsampling.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/block23a/block23a.pdf",
        "supp": "",
        "pdf_size": 523724,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13313859641017145169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "MIT; MIT",
        "aff_domain": "mit.edu;mit.edu",
        "email": "mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9ad3e94d93",
        "title": "Ticketed Learning\u2013Unlearning Schemes",
        "site": "https://proceedings.mlr.press/v195/ghazi23a.html",
        "author": "Badih Ghazi; Pritish Kamath; Ravi Kumar; Pasin Manurangsi; Ayush Sekhari; Chiyuan Zhang",
        "abstract": "We consider the learning\u2013unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples.We propose a new ticketed model for learning\u2013unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) \u201cticket\u201d to each participating training example, in addition to retaining a small amount of \u201ccentral\u201d information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning\u2013unlearning schemes for a broad family of concept classes, including thresholds, parities, intersection-closed classes, among others.En route, we introduce the count-to-zero problem, where during unlearning, the goal is to simply know if there are any examples that survived. We give a ticketed learning\u2013unlearning scheme for this problem that relies on the construction of Sperner families with certain properties, which might be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v195-ghazi23a,\n  title = \t {Ticketed Learning\u2013Unlearning Schemes},\n  author =       {Ghazi, Badih and Kamath, Pritish and Kumar, Ravi and Manurangsi, Pasin and Sekhari, Ayush and Zhang, Chiyuan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5110--5139},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/ghazi23a/ghazi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/ghazi23a.html},\n  abstract = \t {We consider the learning\u2013unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples.We propose a new ticketed model for learning\u2013unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) \u201cticket\u201d to each participating training example, in addition to retaining a small amount of \u201ccentral\u201d information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning\u2013unlearning schemes for a broad family of concept classes, including thresholds, parities, intersection-closed classes, among others.En route, we introduce the count-to-zero problem, where during unlearning, the goal is to simply know if there are any examples that survived. We give a ticketed learning\u2013unlearning scheme for this problem that relies on the construction of Sperner families with certain properties, which might be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/ghazi23a/ghazi23a.pdf",
        "supp": "",
        "pdf_size": 561080,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7992917259923559512&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Google Research, Mountain View; Google Research, Mountain View; Google Research, Mountain View; Google Research, Thailand; Massachusetts Institute of Technology; Google Research, Mountain View",
        "aff_domain": "gmail.com;alum.mit.edu;gmail.com;google.com;mit.edu;google.com",
        "email": "gmail.com;alum.mit.edu;gmail.com;google.com;mit.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Google;Massachusetts Institute of Technology",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://web.mit.edu",
        "aff_unique_abbr": "Google;MIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Mountain View;Thailand;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Thailand"
    },
    {
        "id": "db6c232f18",
        "title": "Tight Bounds on the Hardness of Learning Simple Nonparametric Mixtures",
        "site": "https://proceedings.mlr.press/v195/tai23a.html",
        "author": "Wai Ming Tai; Bryon Aragam",
        "abstract": "We study the problem of learning nonparametric distributions in a finite mixture, and establish tight bounds on the sample complexity for learning the component distributions in such models.Namely, we are given i.i.d. samples from a pdf $f$ where $$f=w_1f_1+w_2f_2, \\quad w_1+w_2=1, \\quad w_1,w_2>0$$and we are interested in learning each component $f_i$.Without any assumptions on $f_i$, this problem is ill-posed.In order to identify the components $f_i$, we assume that each $f_i$ can be written as a convolution of a Gaussian and a compactly supported density $\\nu_i$ with $\\text{supp}(\\nu_1)\\cap \\text{supp}(\\nu_2)=\\emptyset$.Our main result shows that $(\\frac{1}{\\varepsilon})^{\\Omega(\\log\\log \\frac{1}{\\varepsilon})}$ samples are required for estimating each $f_i$. The proof relies on a quantitative Tauberian theorem that yields a fast rate of approximation with Gaussians, which may be of independent interest. To show this is tight, we also propose an algorithm that uses $(\\frac{1}{\\varepsilon})^{O(\\log\\log \\frac{1}{\\varepsilon})}$ samples to estimate each $f_i$. Unlike existing approaches to learning latent variable models based on moment-matching and tensor methods, our proof instead involves a delicate analysis of an ill-conditioned linear system via orthogonal functions.Combining these bounds, we conclude that the optimal sample complexity of this problem properly lies in between polynomial and exponential, which is not common in learning theory.",
        "bibtex": "@InProceedings{pmlr-v195-tai23a,\n  title = \t {Tight Bounds on the Hardness of Learning Simple Nonparametric Mixtures},\n  author =       {Tai, Wai Ming and Aragam, Bryon},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2849--2849},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/tai23a/tai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/tai23a.html},\n  abstract = \t {We study the problem of learning nonparametric distributions in a finite mixture, and establish tight bounds on the sample complexity for learning the component distributions in such models.Namely, we are given i.i.d. samples from a pdf $f$ where $$f=w_1f_1+w_2f_2, \\quad w_1+w_2=1, \\quad w_1,w_2>0$$and we are interested in learning each component $f_i$.Without any assumptions on $f_i$, this problem is ill-posed.In order to identify the components $f_i$, we assume that each $f_i$ can be written as a convolution of a Gaussian and a compactly supported density $\\nu_i$ with $\\text{supp}(\\nu_1)\\cap \\text{supp}(\\nu_2)=\\emptyset$.Our main result shows that $(\\frac{1}{\\varepsilon})^{\\Omega(\\log\\log \\frac{1}{\\varepsilon})}$ samples are required for estimating each $f_i$. The proof relies on a quantitative Tauberian theorem that yields a fast rate of approximation with Gaussians, which may be of independent interest. To show this is tight, we also propose an algorithm that uses $(\\frac{1}{\\varepsilon})^{O(\\log\\log \\frac{1}{\\varepsilon})}$ samples to estimate each $f_i$. Unlike existing approaches to learning latent variable models based on moment-matching and tensor methods, our proof instead involves a delicate analysis of an ill-conditioned linear system via orthogonal functions.Combining these bounds, we conclude that the optimal sample complexity of this problem properly lies in between polynomial and exponential, which is not common in learning theory.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/tai23a/tai23a.pdf",
        "supp": "",
        "pdf_size": 114319,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3190316269637075879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of Chicago; University of Chicago",
        "aff_domain": "CHICAGOBOOTH.EDU;CHICAGOBOOTH.EDU",
        "email": "CHICAGOBOOTH.EDU;CHICAGOBOOTH.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uchicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3083367051",
        "title": "Tight Guarantees for Interactive Decision Making with the Decision-Estimation Coefficient",
        "site": "https://proceedings.mlr.press/v195/foster23b.html",
        "author": "Dylan J. Foster; Noah Golowich; Yanjun Han",
        "abstract": "A foundational problem in reinforcement learning and interactive decision making is to understand what modeling assumptions lead to sample-efficient learning guarantees, and what algorithm design principles achieve optimal sample complexity. Recently, Foster et al. (2021) introduced the Decision- Estimation Coefficient (DEC), a measure of statistical complexity which leads to upper and lower bounds on the optimal sample complexity for a general class of problems encompassing bandits and reinforcement learning with function approximation. In this paper, we introduce a new variant of the DEC, the Constrained Decision-Estimation Coefficient, and use it to derive new lower bounds that improve upon prior work on three fronts:\u2022 they hold in expectation, with no restrictions on the class of algorithms under consideration.\u2022 they hold globally, and do not rely on the notion of localization used by Foster et al. (2021).\u2022 most interestingly, they allow the reference model with respect to which the DEC is defined to be improper, establishing that improper reference models play a fundamental role.We provide upper bounds on regret that scale with the same quantity, thereby closing all but one of the gaps between upper and lower bounds in Foster et al. (2021). Our results apply to both the regret framework and PAC framework, and make use of several new analysis and algorithm design techniques that we anticipate will find broader use.",
        "bibtex": "@InProceedings{pmlr-v195-foster23b,\n  title = \t {Tight Guarantees for Interactive Decision Making with the Decision-Estimation Coefficient},\n  author =       {Foster, Dylan J. and Golowich, Noah and Han, Yanjun},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {3969--4043},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/foster23b/foster23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/foster23b.html},\n  abstract = \t {A foundational problem in reinforcement learning and interactive decision making is to understand what modeling assumptions lead to sample-efficient learning guarantees, and what algorithm design principles achieve optimal sample complexity. Recently, Foster et al. (2021) introduced the Decision- Estimation Coefficient (DEC), a measure of statistical complexity which leads to upper and lower bounds on the optimal sample complexity for a general class of problems encompassing bandits and reinforcement learning with function approximation. In this paper, we introduce a new variant of the DEC, the Constrained Decision-Estimation Coefficient, and use it to derive new lower bounds that improve upon prior work on three fronts:\u2022 they hold in expectation, with no restrictions on the class of algorithms under consideration.\u2022 they hold globally, and do not rely on the notion of localization used by Foster et al. (2021).\u2022 most interestingly, they allow the reference model with respect to which the DEC is defined to be improper, establishing that improper reference models play a fundamental role.We provide upper bounds on regret that scale with the same quantity, thereby closing all but one of the gaps between upper and lower bounds in Foster et al. (2021). Our results apply to both the regret framework and PAC framework, and make use of several new analysis and algorithm design techniques that we anticipate will find broader use.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/foster23b/foster23b.pdf",
        "supp": "",
        "pdf_size": 735815,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13198743671491560724&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Microsoft Research; MIT; MIT",
        "aff_domain": "microsoft.com;mit.edu;mit.edu",
        "email": "microsoft.com;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Microsoft;Massachusetts Institute of Technology",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://web.mit.edu",
        "aff_unique_abbr": "MSR;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ae1c438e11",
        "title": "Tighter PAC-Bayes Bounds Through Coin-Betting",
        "site": "https://proceedings.mlr.press/v195/jang23a.html",
        "author": "Kyoungseok Jang; Kwang-Sung Jun; Ilja Kuzborskij; Francesco Orabona",
        "abstract": "We consider the problem of estimating the mean of a sequence of random elements $f(\\theta, X_1)$ $, \\ldots, $ $f(\\theta, X_n)$ where $f$ is a fixed scalar function, $S=(X_1, \\ldots, X_n)$ are independent random variables, and $\\theta$ is a possibly $S$-dependent parameter. An example of such a problem would be to estimate the generalization error of a neural network trained on $n$ examples where $f$ is a loss function. Classically, this problem is approached through concentration inequalities holding uniformly over compact parameter sets of functions $f$, for example as in Rademacher or VC type analysis. However, in many problems, such inequalities often yield numerically vacuous estimates. Recently, the \\emph{PAC-Bayes} framework has been proposed as a better alternative for this class of problems for its ability to often give numerically non-vacuous bounds. In this paper, we show that we can do even better: we show how to refine the proof strategy of the PAC-Bayes bounds and achieve \\emph{even tighter} guarantees. Our approach is based on the \\emph{coin-betting} framework that derives the numerically tightest known time-uniform concentration inequalities from the regret guarantees of online gambling algorithms. In particular, we derive the first PAC-Bayes concentration inequality based on the coin-betting approach that holds simultaneously for all sample sizes.  We demonstrate its tightness showing that by \\emph{relaxing} it we obtain a number of previous results in a closed form including Bernoulli-KL and empirical Bernstein inequalities. Finally, we propose an efficient algorithm to numerically calculate confidence sequences from our bound, which often generates nonvacuous confidence bounds even with one sample, unlike the state-of-the-art PAC-Bayes bounds.",
        "bibtex": "@InProceedings{pmlr-v195-jang23a,\n  title = \t {Tighter PAC-Bayes Bounds Through Coin-Betting},\n  author =       {Jang, Kyoungseok and Jun, Kwang-Sung and Kuzborskij, Ilja and Orabona, Francesco},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2240--2264},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/jang23a/jang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/jang23a.html},\n  abstract = \t {We consider the problem of estimating the mean of a sequence of random elements $f(\\theta, X_1)$ $, \\ldots, $ $f(\\theta, X_n)$ where $f$ is a fixed scalar function, $S=(X_1, \\ldots, X_n)$ are independent random variables, and $\\theta$ is a possibly $S$-dependent parameter. An example of such a problem would be to estimate the generalization error of a neural network trained on $n$ examples where $f$ is a loss function. Classically, this problem is approached through concentration inequalities holding uniformly over compact parameter sets of functions $f$, for example as in Rademacher or VC type analysis. However, in many problems, such inequalities often yield numerically vacuous estimates. Recently, the \\emph{PAC-Bayes} framework has been proposed as a better alternative for this class of problems for its ability to often give numerically non-vacuous bounds. In this paper, we show that we can do even better: we show how to refine the proof strategy of the PAC-Bayes bounds and achieve \\emph{even tighter} guarantees. Our approach is based on the \\emph{coin-betting} framework that derives the numerically tightest known time-uniform concentration inequalities from the regret guarantees of online gambling algorithms. In particular, we derive the first PAC-Bayes concentration inequality based on the coin-betting approach that holds simultaneously for all sample sizes.  We demonstrate its tightness showing that by \\emph{relaxing} it we obtain a number of previous results in a closed form including Bernoulli-KL and empirical Bernstein inequalities. Finally, we propose an efficient algorithm to numerically calculate confidence sequences from our bound, which often generates nonvacuous confidence bounds even with one sample, unlike the state-of-the-art PAC-Bayes bounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/jang23a/jang23a.pdf",
        "supp": "",
        "pdf_size": 568281,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6924668073968399574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Arizona; University of Arizona; Google DeepMind; Boston University",
        "aff_domain": "arizona.edu;cs.arizona.edu;google.com;orabona.com",
        "email": "arizona.edu;cs.arizona.edu;google.com;orabona.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Arizona;Google;Boston University",
        "aff_unique_dep": ";Google DeepMind;",
        "aff_unique_url": "https://www.arizona.edu;https://deepmind.com;https://www.bu.edu",
        "aff_unique_abbr": "UA;DeepMind;BU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "e72a700299",
        "title": "Toward L_\u221eRecovery of Nonlinear Functions: A Polynomial Sample Complexity Bound for Gaussian Random Fields",
        "site": "https://proceedings.mlr.press/v195/dong23a.html",
        "author": "Kefan Dong; Tengyu Ma",
        "abstract": "Many machine learning applications require learning a function with a small worst-case error over the entire input domain, that is, the $L_\\infty$-error, whereas most existing theoretical works only guarantee recovery in average errors such as the $L_2$-error.  $L_\\infty$-recovery from polynomial samples is even impossible for seemingly simple function classes such as constant-norm infinite-width two-layer neural nets. This paper makes some initial steps beyond the impossibility results by leveraging the randomness in the ground-truth functions. We prove a polynomial sample complexity bound for random ground-truth functions drawn from Gaussian random fields. Our key technical novelty is to prove that the degree-$k$ spherical harmonics components of a function from Gaussian random field cannot be spiky in that their $L_\\infty$/$L_2$ ratios are upperbounded by $O(d \\sqrt{\\ln k})$ with high probability. In contrast, the worst-case $L_\\infty$/$L_2$ ratio for degree-$k$ spherical harmonics is on the order of $\\Omega(\\min\\{d^{k/2},k^{d/2}\\})$.",
        "bibtex": "@InProceedings{pmlr-v195-dong23a,\n  title = \t {Toward L_\u221eRecovery of Nonlinear Functions: A Polynomial Sample Complexity Bound for Gaussian Random Fields},\n  author =       {Dong, Kefan and Ma, Tengyu},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {2877--2918},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/dong23a/dong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/dong23a.html},\n  abstract = \t {Many machine learning applications require learning a function with a small worst-case error over the entire input domain, that is, the $L_\\infty$-error, whereas most existing theoretical works only guarantee recovery in average errors such as the $L_2$-error.  $L_\\infty$-recovery from polynomial samples is even impossible for seemingly simple function classes such as constant-norm infinite-width two-layer neural nets. This paper makes some initial steps beyond the impossibility results by leveraging the randomness in the ground-truth functions. We prove a polynomial sample complexity bound for random ground-truth functions drawn from Gaussian random fields. Our key technical novelty is to prove that the degree-$k$ spherical harmonics components of a function from Gaussian random field cannot be spiky in that their $L_\\infty$/$L_2$ ratios are upperbounded by $O(d \\sqrt{\\ln k})$ with high probability. In contrast, the worst-case $L_\\infty$/$L_2$ ratio for degree-$k$ spherical harmonics is on the order of $\\Omega(\\min\\{d^{k/2},k^{d/2}\\})$. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/dong23a/dong23a.pdf",
        "supp": "",
        "pdf_size": 520067,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14963803176912476864&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "stanford.edu;stanford.edu",
        "email": "stanford.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2507e64e4e",
        "title": "Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincar\u00e9 Inequality",
        "site": "https://proceedings.mlr.press/v195/mousavi-hosseini23a.html",
        "author": "Alireza Mousavi-Hosseini; Tyler K. Farghly; Ye He; Krishna Balasubramanian; Murat A. Erdogdu",
        "abstract": "Langevin diffusions are rapidly convergent under appropriate functional inequality assumptions. Hence, it is natural to expect that with additional smoothness conditions to handle the discretization errors, their discretizations like the Langevin Monte Carlo (LMC) converge in a similar fashion. This research program was initiated by Vempala and Wibisono (2019), who established results under log-Sobolev inequalities. Chewi et al. (2022a) extended the results to handle the case of Poincar\u00e9 inequalities. In this paper, we go beyond Poincar\u00e9 inequalities, and push this research program to its limit. We do so by establishing upper and lower bounds for Langevin diffusions and LMC under weak Poincar\u00e9 inequalities that are satisfied by a large class of densities including polynomially-decaying heavy-tailed densities (i.e., Cauchy-type). Our results explicitly quantify the effect of the initializer on the performance of the LMC algorithm. In particular, we show that as the tail goes from sub-Gaussian, to sub-exponential, and finally to Cauchy-like, the dependency on the initial error goes from being logarithmic, to polynomial, and then finally to being exponential. This three-step phase transition is in particular unavoidable as demonstrated by our lower bounds, clearly defining the boundaries of LMC.",
        "bibtex": "@InProceedings{pmlr-v195-mousavi-hosseini23a,\n  title = \t {Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincar\u00e9 Inequality},\n  author =       {Mousavi-Hosseini, Alireza and Farghly, Tyler K. and He, Ye and Balasubramanian, Krishna and Erdogdu, Murat A.},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1--35},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/mousavi-hosseini23a/mousavi-hosseini23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/mousavi-hosseini23a.html},\n  abstract = \t {Langevin diffusions are rapidly convergent under appropriate functional inequality assumptions. Hence, it is natural to expect that with additional smoothness conditions to handle the discretization errors, their discretizations like the Langevin Monte Carlo (LMC) converge in a similar fashion. This research program was initiated by Vempala and Wibisono (2019), who established results under log-Sobolev inequalities. Chewi et al. (2022a) extended the results to handle the case of Poincar\u00e9 inequalities. In this paper, we go beyond Poincar\u00e9 inequalities, and push this research program to its limit. We do so by establishing upper and lower bounds for Langevin diffusions and LMC under weak Poincar\u00e9 inequalities that are satisfied by a large class of densities including polynomially-decaying heavy-tailed densities (i.e., Cauchy-type). Our results explicitly quantify the effect of the initializer on the performance of the LMC algorithm. In particular, we show that as the tail goes from sub-Gaussian, to sub-exponential, and finally to Cauchy-like, the dependency on the initial error goes from being logarithmic, to polynomial, and then finally to being exponential. This three-step phase transition is in particular unavoidable as demonstrated by our lower bounds, clearly defining the boundaries of LMC.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/mousavi-hosseini23a/mousavi-hosseini23a.pdf",
        "supp": "",
        "pdf_size": 408523,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1665913156639624685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science at the University of Toronto, and Vector Institute; Department of Statistics, University of Oxford, UK; Department of Mathematics, University of California, Davis; Department of Statistics, University of California, Davis; Department of Computer Science and Department of Statistical Sciences at the University of Toronto, and Vector Institute",
        "aff_domain": "cs.toronto.edu;stats.ox.ac.uk;ucdavis.edu;ucdavis.edu;cs.toronto.edu",
        "email": "cs.toronto.edu;stats.ox.ac.uk;ucdavis.edu;ucdavis.edu;cs.toronto.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "University of Toronto;University of Oxford;University of California, Davis",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics;Department of Mathematics",
        "aff_unique_url": "https://www.utoronto.ca;https://www.ox.ac.uk;https://www.ucdavis.edu",
        "aff_unique_abbr": "U of T;Oxford;UC Davis",
        "aff_campus_unique_index": "0;1;2;2;0",
        "aff_campus_unique": "Toronto;Oxford;Davis",
        "aff_country_unique_index": "0;1;2;2;0",
        "aff_country_unique": "Canada;United Kingdom;United States"
    },
    {
        "id": "3b3589e04a",
        "title": "U-Calibration: Forecasting for an Unknown Agent",
        "site": "https://proceedings.mlr.press/v195/kleinberg23a.html",
        "author": "Bobby Kleinberg; Renato Paes Leme; Jon Schneider; Yifeng Teng",
        "abstract": "We consider the problem of evaluating forecasts of binary events whose predictions are consumed by rational agents who take an action in response to a prediction, but whose utility is unknown to the forecaster. We show that optimizing forecasts for a single scoring rule (e.g., the Brier score) cannot guarantee low regret for all possible agents. In contrast, forecasts that are well-calibrated guarantee that all agents incur sublinear regret. However, calibration is not a necessary criterion here (it is possible for miscalibrated forecasts to provide good regret guarantees for all possible agents), and calibrated forecasting procedures have provably worse convergence rates than forecasting procedures targeting a single scoring rule.Motivated by this, we present a new metric for evaluating forecasts that we call U-calibration, equal to the maximal regret of the sequence of forecasts when evaluated under any bounded scoring rule. We show that sublinear U-calibration error is a necessary and sufficient condition for all agents to achieve sublinear regret guarantees. We additionally demonstrate how to compute the U-calibration error efficiently and provide an online algorithm that achieves $O(\\sqrt{T})$  U-calibration error (on par with optimal rates for optimizing for a single scoring rule, and bypassing lower bounds for the traditionally calibrated learning procedures). Finally, we discuss generalizations to the multiclass prediction setting.",
        "bibtex": "@InProceedings{pmlr-v195-kleinberg23a,\n  title = \t {U-Calibration: Forecasting for an Unknown Agent},\n  author =       {Kleinberg, Bobby and Leme, Renato Paes and Schneider, Jon and Teng, Yifeng},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5143--5145},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/kleinberg23a/kleinberg23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/kleinberg23a.html},\n  abstract = \t {We consider the problem of evaluating forecasts of binary events whose predictions are consumed by rational agents who take an action in response to a prediction, but whose utility is unknown to the forecaster. We show that optimizing forecasts for a single scoring rule (e.g., the Brier score) cannot guarantee low regret for all possible agents. In contrast, forecasts that are well-calibrated guarantee that all agents incur sublinear regret. However, calibration is not a necessary criterion here (it is possible for miscalibrated forecasts to provide good regret guarantees for all possible agents), and calibrated forecasting procedures have provably worse convergence rates than forecasting procedures targeting a single scoring rule.Motivated by this, we present a new metric for evaluating forecasts that we call U-calibration, equal to the maximal regret of the sequence of forecasts when evaluated under any bounded scoring rule. We show that sublinear U-calibration error is a necessary and sufficient condition for all agents to achieve sublinear regret guarantees. We additionally demonstrate how to compute the U-calibration error efficiently and provide an online algorithm that achieves $O(\\sqrt{T})$  U-calibration error (on par with optimal rates for optimizing for a single scoring rule, and bypassing lower bounds for the traditionally calibrated learning procedures). Finally, we discuss generalizations to the multiclass prediction setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/kleinberg23a/kleinberg23a.pdf",
        "supp": "",
        "pdf_size": 71183,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1139813953641999394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Cornell University; Google Research; Google Research; Google Research",
        "aff_domain": "CS.CORNELL.EDU;GOOGLE.COM;GOOGLE.COM;GOOGLE.COM",
        "email": "CS.CORNELL.EDU;GOOGLE.COM;GOOGLE.COM;GOOGLE.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Cornell University;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.cornell.edu;https://research.google",
        "aff_unique_abbr": "Cornell;Google Research",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4ba96cf7a5",
        "title": "Uniqueness of BP fixed point for the Potts model and applications to community detection",
        "site": "https://proceedings.mlr.press/v195/gu23a.html",
        "author": "Yuzhou Gu; Yury Polyanskiy",
        "abstract": "In the study of sparse stochastic block models (SBMs) one often needs to analyze a distributional recursion, known as the belief propagation (BP) recursion. Uniqueness of the fixed point of this recursion implies several results about the SBM, including optimal recovery algorithms for SBM (Mossel et al. (2016)) and SBM with side information (Mossel and Xu (2016)), and a formula for SBM mutual information (Abbe et al. (2021)). The 2-community case corresponds to an Ising model, for which Yu and Polyanskiy (2022) established uniqueness for all cases.In this paper we analyze the $q$-ary Potts model, i.e., broadcasting of $q$-ary spins on a Galton-Watson tree with expected offspring degree $d$ through Potts channels with second-largest eigenvalue $\\lambda$. We allow the intermediate vertices to be observed through noisy channels (side information). We prove that BP uniqueness holds with and without side information when $d\\lambda^2 \\ge 1 + C \\max\\{\\lambda, q^{-1}\\}\\log q$ for some absolute constant $C>0$ independent of $q,\\lambda,d$. For large $q$ and $\\lambda = o(1/\\log q)$, this is asymptotically achieving the Kesten-Stigum threshold $d\\lambda^2=1$. These results imply mutual information formulas and optimal recovery algorithms for the $q$-community SBM in the corresponding ranges.For $q\\ge 4$, Sly (2011); Mossel et al. (2022) showed that there exist choices of $q,\\lambda,d$ below Kesten-Stigum (i.e. $d\\lambda^2 < 1$) but reconstruction is possible. Somewhat surprisingly, we show that in such regimes BP uniqueness does not hold at least in the presence of weak side information.Our technical tool is a theory of $q$-ary symmetric channels, that we initiate here, generalizing the classical and widely-utilized information-theoretic characterization of BMS (binary memoryless symmetric) channels.",
        "bibtex": "@InProceedings{pmlr-v195-gu23a,\n  title = \t {Uniqueness of BP fixed point for the Potts model and applications to community detection},\n  author =       {Gu, Yuzhou and Polyanskiy, Yury},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {837--884},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gu23a/gu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gu23a.html},\n  abstract = \t {In the study of sparse stochastic block models (SBMs) one often needs to analyze a distributional recursion, known as the belief propagation (BP) recursion. Uniqueness of the fixed point of this recursion implies several results about the SBM, including optimal recovery algorithms for SBM (Mossel et al. (2016)) and SBM with side information (Mossel and Xu (2016)), and a formula for SBM mutual information (Abbe et al. (2021)). The 2-community case corresponds to an Ising model, for which Yu and Polyanskiy (2022) established uniqueness for all cases.In this paper we analyze the $q$-ary Potts model, i.e., broadcasting of $q$-ary spins on a Galton-Watson tree with expected offspring degree $d$ through Potts channels with second-largest eigenvalue $\\lambda$. We allow the intermediate vertices to be observed through noisy channels (side information). We prove that BP uniqueness holds with and without side information when $d\\lambda^2 \\ge 1 + C \\max\\{\\lambda, q^{-1}\\}\\log q$ for some absolute constant $C>0$ independent of $q,\\lambda,d$. For large $q$ and $\\lambda = o(1/\\log q)$, this is asymptotically achieving the Kesten-Stigum threshold $d\\lambda^2=1$. These results imply mutual information formulas and optimal recovery algorithms for the $q$-community SBM in the corresponding ranges.For $q\\ge 4$, Sly (2011); Mossel et al. (2022) showed that there exist choices of $q,\\lambda,d$ below Kesten-Stigum (i.e. $d\\lambda^2 < 1$) but reconstruction is possible. Somewhat surprisingly, we show that in such regimes BP uniqueness does not hold at least in the presence of weak side information.Our technical tool is a theory of $q$-ary symmetric channels, that we initiate here, generalizing the classical and widely-utilized information-theoretic characterization of BMS (binary memoryless symmetric) channels.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/gu23a/gu23a.pdf",
        "supp": "",
        "pdf_size": 484124,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2856453276148667976&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Masaschusetts Institute of Technology; Masaschusetts Institute of Technology",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "00a8592013",
        "title": "Universal Rates for Multiclass Learning",
        "site": "https://proceedings.mlr.press/v195/hanneke23a.html",
        "author": "Steve Hanneke; Shay Moran; Qian Zhang",
        "abstract": "We study universal rates for multiclass classification, establishing the optimal rates (up to log factors) for all hypothesis classes. This generalizes previous results on binary classification (Bousquet, Hanneke, Moran, van Handel, and Yehudayoff, 2021), and resolves an open question studied by Kalavasis, Velegkas, and Karbasi (2022) who handled the multiclass setting with a bounded number of class labels. In contrast, our result applies for any countable label space. Even for finite label space, our proofs provide a more precise bounds on the learning curves, as they do not depend on the number of labels. Specifically, we show that any class admits exponential rates if and only if it has no infinite Littlestone tree, and admits (near-)linear rates if and only if it has no infinite Daniely-Shalev-Shwartz-Littleston (DSL) tree, and otherwise requires arbitrarily slow rates. DSL trees are a new structure we define in this work, in which each node of the tree is given by a pseudo-cube of possible classifications of a given set of points. Pseudo-cubes are a structure, rooted in the work of Daniely and Shalev-Shwartz (2014), and recently shown by Brukhim, Carmon, Dinur, Moran, and Yehudayoff (2022) to characterize PAC learnability (i.e., uniform rates) for multiclass classification. We also resolve an open question of Kalavasis, Velegkas, and Karbasi (2022) regarding the equivalence of classes having infinite Graph-Littlestone (GL) trees versus infinite Natarajan-Littlestone (NL) trees, showing that they are indeed equivalent.",
        "bibtex": "@InProceedings{pmlr-v195-hanneke23a,\n  title = \t {Universal Rates for Multiclass Learning},\n  author =       {Hanneke, Steve and Moran, Shay and Zhang, Qian},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {5615--5681},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/hanneke23a/hanneke23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/hanneke23a.html},\n  abstract = \t {We study universal rates for multiclass classification, establishing the optimal rates (up to log factors) for all hypothesis classes. This generalizes previous results on binary classification (Bousquet, Hanneke, Moran, van Handel, and Yehudayoff, 2021), and resolves an open question studied by Kalavasis, Velegkas, and Karbasi (2022) who handled the multiclass setting with a bounded number of class labels. In contrast, our result applies for any countable label space. Even for finite label space, our proofs provide a more precise bounds on the learning curves, as they do not depend on the number of labels. Specifically, we show that any class admits exponential rates if and only if it has no infinite Littlestone tree, and admits (near-)linear rates if and only if it has no infinite Daniely-Shalev-Shwartz-Littleston (DSL) tree, and otherwise requires arbitrarily slow rates. DSL trees are a new structure we define in this work, in which each node of the tree is given by a pseudo-cube of possible classifications of a given set of points. Pseudo-cubes are a structure, rooted in the work of Daniely and Shalev-Shwartz (2014), and recently shown by Brukhim, Carmon, Dinur, Moran, and Yehudayoff (2022) to characterize PAC learnability (i.e., uniform rates) for multiclass classification. We also resolve an open question of Kalavasis, Velegkas, and Karbasi (2022) regarding the equivalence of classes having infinite Graph-Littlestone (GL) trees versus infinite Natarajan-Littlestone (NL) trees, showing that they are indeed equivalent. }\n}",
        "pdf": "https://proceedings.mlr.press/v195/hanneke23a/hanneke23a.pdf",
        "supp": "",
        "pdf_size": 675583,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12916203625919393945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Purdue University; Technion; Purdue University",
        "aff_domain": "GMAIL.COM;TECHNION.AC.IL;PURDUE.EDU",
        "email": "GMAIL.COM;TECHNION.AC.IL;PURDUE.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Purdue University;Technion - Israel Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.purdue.edu;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Purdue;Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "c84c62c0f3",
        "title": "Universality of Langevin Diffusion for Private Optimization, with Applications to Sampling from Rashomon Sets",
        "site": "https://proceedings.mlr.press/v195/ganesh23a.html",
        "author": "Arun Ganesh; Abhradeep Thakurta; Jalaj Upadhyay",
        "abstract": "In this paper we provide an algorithmic framework based on Langevin diffusion (LD) and its corresponding discretizations that allow us to simultaneously obtain: i) An algorithm for sampling from the exponential mechanism, whose privacy analysis does not depend on convexity, and which can be stopped at anytime without compromising privacy, and ii) tight uniform stability guarantees for the exponential mechanism. As a direct consequence, we obtain optimal excess empirical and population risk guarantees for (strongly) convex losses under both pure and approximate differential privacy (DP). The framework allows us to design a DP uniform sampler from a  Rashomon set. Rashomon sets are widely used in interpretable and robust machine learning, understanding variable importance, and characterizing fairness.",
        "bibtex": "@InProceedings{pmlr-v195-ganesh23a,\n  title = \t {Universality of Langevin Diffusion for Private Optimization, with Applications to Sampling from Rashomon Sets},\n  author =       {Ganesh, Arun and Thakurta, Abhradeep and Upadhyay, Jalaj},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {1730--1773},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/ganesh23a/ganesh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/ganesh23a.html},\n  abstract = \t {In this paper we provide an algorithmic framework based on Langevin diffusion (LD) and its corresponding discretizations that allow us to simultaneously obtain: i) An algorithm for sampling from the exponential mechanism, whose privacy analysis does not depend on convexity, and which can be stopped at anytime without compromising privacy, and ii) tight uniform stability guarantees for the exponential mechanism. As a direct consequence, we obtain optimal excess empirical and population risk guarantees for (strongly) convex losses under both pure and approximate differential privacy (DP). The framework allows us to design a DP uniform sampler from a  Rashomon set. Rashomon sets are widely used in interpretable and robust machine learning, understanding variable importance, and characterizing fairness.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/ganesh23a/ganesh23a.pdf",
        "supp": "",
        "pdf_size": 623443,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2758501162319385151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Google Research; Google DeepMind; Rutgers University",
        "aff_domain": "google.com;google.com;rutgers.edu",
        "email": "google.com;google.com;rutgers.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Google;Rutgers University",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://www.rutgers.edu",
        "aff_unique_abbr": "Google Research;Rutgers",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "b76be6c62e",
        "title": "Utilising the CLT Structure in Stochastic Gradient based Sampling : Improved Analysis and Faster Algorithms",
        "site": "https://proceedings.mlr.press/v195/das23b.html",
        "author": "Aniket Das; Dheeraj M. Nagaraj; Anant Raj",
        "abstract": "We consider stochastic approximations of sampling algorithms, such as Stochastic Gradient Langevin Dynamics (SGLD) and the Random Batch Method (RBM) for Interacting Particle Dynamcs (IPD). We observe that the noise introduced by the stochastic approximation is nearly Gaussian due to the Central Limit Theorem (CLT) while the driving Brownian motion is exactly Gaussian. We harness this structure to absorb the stochastic approximation error inside the diffusion process, and obtain improved convergence guarantees for these algorithms. For SGLD, we prove the first stable convergence rate in KL divergence without requiring uniform warm start, assuming the target density satisfies a Log-Sobolev Inequality. Our result implies superior first-order oracle complexity compared to prior works, under significantly milder assumptions. We also prove the first guarantees for SGLD under even weaker conditions such as H\u00f6lder smoothness and Poincare Inequality, thus bridging the gap between the state-of-the-art guarantees for LMC and SGLD. Our analysis motivates a new algorithm called covariance correction, which corrects for the additional noise introduced by the stochastic approximation by rescaling the strength of the diffusion. Finally, we apply our techniques to analyze RBM, and significantly improve upon the guarantees in prior works (such as removing exponential dependence on horizon), under minimal assumptions.",
        "bibtex": "@InProceedings{pmlr-v195-das23b,\n  title = \t {Utilising the CLT Structure in Stochastic Gradient based Sampling : Improved Analysis and Faster Algorithms},\n  author =       {Das, Aniket and Nagaraj, Dheeraj M. and Raj, Anant},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4072--4129},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/das23b/das23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/das23b.html},\n  abstract = \t {We consider stochastic approximations of sampling algorithms, such as Stochastic Gradient Langevin Dynamics (SGLD) and the Random Batch Method (RBM) for Interacting Particle Dynamcs (IPD). We observe that the noise introduced by the stochastic approximation is nearly Gaussian due to the Central Limit Theorem (CLT) while the driving Brownian motion is exactly Gaussian. We harness this structure to absorb the stochastic approximation error inside the diffusion process, and obtain improved convergence guarantees for these algorithms. For SGLD, we prove the first stable convergence rate in KL divergence without requiring uniform warm start, assuming the target density satisfies a Log-Sobolev Inequality. Our result implies superior first-order oracle complexity compared to prior works, under significantly milder assumptions. We also prove the first guarantees for SGLD under even weaker conditions such as H\u00f6lder smoothness and Poincare Inequality, thus bridging the gap between the state-of-the-art guarantees for LMC and SGLD. Our analysis motivates a new algorithm called covariance correction, which corrects for the additional noise introduced by the stochastic approximation by rescaling the strength of the diffusion. Finally, we apply our techniques to analyze RBM, and significantly improve upon the guarantees in prior works (such as removing exponential dependence on horizon), under minimal assumptions.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/das23b/das23b.pdf",
        "supp": "",
        "pdf_size": 646651,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3468688879846879675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Google Research, Bangalore, India; Google Research, Bangalore, India; University of Illinois Urbana-Champaign & Inria, Ecole Normale Sup\u00e9rieure",
        "aff_domain": "google.com;google.com;inria.fr",
        "email": "google.com;google.com;inria.fr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Google;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://illinois.edu",
        "aff_unique_abbr": "Google Research;UIUC",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Bangalore;Urbana-Champaign",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "9e5cc02483",
        "title": "VO$Q$L: Towards Optimal Regret in Model-free RL with Nonlinear Function Approximation",
        "site": "https://proceedings.mlr.press/v195/agarwal23a.html",
        "author": "Alekh Agarwal; Yujia Jin; Tong Zhang",
        "abstract": "We study time-inhomogeneous episodic reinforcement learning (RL) under general function approximation and sparse rewards. We design a new algorithm, Variance-weighted Optimistic $Q$-Learning (VO$Q$L), based on  $Q$-learning and bound its regret assuming closure under Bellman backups, and bounded Eluder dimension for the regression function class. As a special case, VO$Q$L achieves $\\widetilde{O}(d\\sqrt{TH}+d^6H^{5})$ regret over $T$ episodes for a horizon $H$ MDP under ($d$-dimensional) linear function approximation, which is asymptotically optimal. Our algorithm incorporates weighted regression-based upper and lower bounds on the optimal value function to obtain this improved regret. The algorithm is computationally efficient given a regression oracle over the function class, making this the first computationally tractable and statistically optimal approach for linear MDPs.",
        "bibtex": "@InProceedings{pmlr-v195-agarwal23a,\n  title = \t {VO$Q$L: Towards Optimal Regret in Model-free RL with Nonlinear Function Approximation},\n  author =       {Agarwal, Alekh and Jin, Yujia and Zhang, Tong},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {987--1063},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/agarwal23a/agarwal23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/agarwal23a.html},\n  abstract = \t {We study time-inhomogeneous episodic reinforcement learning (RL) under general function approximation and sparse rewards. We design a new algorithm, Variance-weighted Optimistic $Q$-Learning (VO$Q$L), based on  $Q$-learning and bound its regret assuming closure under Bellman backups, and bounded Eluder dimension for the regression function class. As a special case, VO$Q$L achieves $\\widetilde{O}(d\\sqrt{TH}+d^6H^{5})$ regret over $T$ episodes for a horizon $H$ MDP under ($d$-dimensional) linear function approximation, which is asymptotically optimal. Our algorithm incorporates weighted regression-based upper and lower bounds on the optimal value function to obtain this improved regret. The algorithm is computationally efficient given a regression oracle over the function class, making this the first computationally tractable and statistically optimal approach for linear MDPs.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/agarwal23a/agarwal23a.pdf",
        "supp": "",
        "pdf_size": 720294,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4346694173527079580&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; Stanford University; Google Research",
        "aff_domain": "google.com;stanford.edu;google.com",
        "email": "google.com;stanford.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Google;Stanford University",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://www.stanford.edu",
        "aff_unique_abbr": "Google Research;Stanford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Mountain View;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c828b5e999",
        "title": "Variance-Dependent Regret Bounds for Linear Bandits and Reinforcement Learning: Adaptivity and Computational Efficiency",
        "site": "https://proceedings.mlr.press/v195/zhao23a.html",
        "author": "Heyang Zhao; Jiafan He; Dongruo Zhou; Tong Zhang; Quanquan Gu",
        "abstract": "Recently, several studies \\citep{zhou2021nearly, zhang2021variance, kim2021improved, zhou2022computationally} have provided variance-dependent regret bounds for linear contextual bandits, which interpolates the regret for the worst-case regime and the deterministic reward regime. However, these algorithms are either computationally intractable or unable to handle unknown variance of the noise. In this paper, we present a novel solution to this open problem by proposing the \\emph{first computationally efficient} algorithm for linear bandits with heteroscedastic noise. Our algorithm is adaptive to the unknown variance of noise and achieves an $\\tilde{O}(d \\sqrt{\\sum_{k = 1}^K \\sigma_k^2} + d)$  regret, where $\\sigma_k^2$ is the \\emph{variance} of the noise at the round $k$, $d$ is the dimension of the contexts and $K$ is the total number of rounds. Our results are based on an adaptive variance-aware confidence set enabled by a new Freedman-type concentration inequality for self-normalized martingales and a multi-layer structure to stratify the context vectors into different layers with different uniform upper bounds on the uncertainty.    Furthermore, our approach can be extended to linear mixture Markov decision processes (MDPs) in reinforcement learning. We propose a variance-adaptive algorithm for linear mixture MDPs, which achieves a problem-dependent horizon-free regret bound that can gracefully reduce to a nearly constant regret for deterministic MDPs. Unlike existing nearly minimax optimal algorithms for linear mixture MDPs, our algorithm does not require explicit variance estimation of the transitional probabilities or the use of high-order moment estimators to attain horizon-free regret. We believe the techniques developed in this paper can have independent value for general online decision making problems.",
        "bibtex": "@InProceedings{pmlr-v195-zhao23a,\n  title = \t {Variance-Dependent Regret Bounds for Linear Bandits and Reinforcement Learning: Adaptivity and Computational Efficiency},\n  author =       {Zhao, Heyang and He, Jiafan and Zhou, Dongruo and Zhang, Tong and Gu, Quanquan},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4977--5020},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/zhao23a/zhao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v195/zhao23a.html},\n  abstract = \t {Recently, several studies \\citep{zhou2021nearly, zhang2021variance, kim2021improved, zhou2022computationally} have provided variance-dependent regret bounds for linear contextual bandits, which interpolates the regret for the worst-case regime and the deterministic reward regime. However, these algorithms are either computationally intractable or unable to handle unknown variance of the noise. In this paper, we present a novel solution to this open problem by proposing the \\emph{first computationally efficient} algorithm for linear bandits with heteroscedastic noise. Our algorithm is adaptive to the unknown variance of noise and achieves an $\\tilde{O}(d \\sqrt{\\sum_{k = 1}^K \\sigma_k^2} + d)$  regret, where $\\sigma_k^2$ is the \\emph{variance} of the noise at the round $k$, $d$ is the dimension of the contexts and $K$ is the total number of rounds. Our results are based on an adaptive variance-aware confidence set enabled by a new Freedman-type concentration inequality for self-normalized martingales and a multi-layer structure to stratify the context vectors into different layers with different uniform upper bounds on the uncertainty.    Furthermore, our approach can be extended to linear mixture Markov decision processes (MDPs) in reinforcement learning. We propose a variance-adaptive algorithm for linear mixture MDPs, which achieves a problem-dependent horizon-free regret bound that can gracefully reduce to a nearly constant regret for deterministic MDPs. Unlike existing nearly minimax optimal algorithms for linear mixture MDPs, our algorithm does not require explicit variance estimation of the transitional probabilities or the use of high-order moment estimators to attain horizon-free regret. We believe the techniques developed in this paper can have independent value for general online decision making problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/zhao23a/zhao23a.pdf",
        "supp": "",
        "pdf_size": 596863,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7541763715557950922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; Google Research and The Hong Kong University of Science and Technology; University of California, Los Angeles",
        "aff_domain": "CS.UCLA.EDU;UCLA.EDU;CS.UCLA.EDU;TONGZHANG-ML.ORG;CS.UCLA.EDU",
        "email": "CS.UCLA.EDU;UCLA.EDU;CS.UCLA.EDU;TONGZHANG-ML.ORG;CS.UCLA.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.ucla.edu;https://research.google",
        "aff_unique_abbr": "UCLA;Google Res.",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "87c83a583c",
        "title": "Weak Recovery Threshold for the Hypergraph Stochastic Block Model",
        "site": "https://proceedings.mlr.press/v195/gu23b.html",
        "author": "Yuzhou Gu; Yury Polyanskiy",
        "abstract": "We study the weak recovery problem on the $r$-uniform hypergraph stochastic block model ($r$-HSBM) with two balanced communities. In HSBM a random graph is constructed by placing hyperedges with higher density if all vertices of a hyperedge share the same binary label, and weak recovery asks to recover a non-trivial fraction of the labels. We introduce a multi-terminal version of strong data processing inequalities (SDPIs), which we call the multi-terminal SDPI, and use it to prove a variety of impossibility results for weak recovery. In particular, we prove that weak recovery is impossible below the Kesten-Stigum (KS) threshold if $r=3,4$, or a strength parameter $\\lambda$ is at least $\\frac 15$. Prior work Pal and Zhu (2021) established that weak recovery in HSBM is always possible above the KS threshold. Consequently, there is no information-computation gap for these cases, which (partially) resolves a conjecture of Angelini et al. (2015). To our knowledge this is the first impossibility result for HSBM weak recovery.As usual, we reduce the study of non-recovery of HSBM to the study of non-reconstruction in a related broadcasting on hypertrees (BOHT) model. While we show that BOHT\u2019s reconstruction threshold coincides with KS for $r=3,4$, surprisingly, we demonstrate that for $r\\ge 7$ reconstruction is possible also below KS. This shows an interesting phase transition in the parameter $r$, and suggests that for $r\\ge 7$, there might be an information-computation gap for the HSBM. For $r=5,6$ and large degree we propose an approach for showing non-reconstruction below KS, suggesting that $r=7$ is the correct threshold for onset of the new phase.",
        "bibtex": "@InProceedings{pmlr-v195-gu23b,\n  title = \t {Weak Recovery Threshold for the Hypergraph Stochastic Block Model},\n  author =       {Gu, Yuzhou and Polyanskiy, Yury},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {885--920},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/gu23b/gu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/gu23b.html},\n  abstract = \t {We study the weak recovery problem on the $r$-uniform hypergraph stochastic block model ($r$-HSBM) with two balanced communities. In HSBM a random graph is constructed by placing hyperedges with higher density if all vertices of a hyperedge share the same binary label, and weak recovery asks to recover a non-trivial fraction of the labels. We introduce a multi-terminal version of strong data processing inequalities (SDPIs), which we call the multi-terminal SDPI, and use it to prove a variety of impossibility results for weak recovery. In particular, we prove that weak recovery is impossible below the Kesten-Stigum (KS) threshold if $r=3,4$, or a strength parameter $\\lambda$ is at least $\\frac 15$. Prior work Pal and Zhu (2021) established that weak recovery in HSBM is always possible above the KS threshold. Consequently, there is no information-computation gap for these cases, which (partially) resolves a conjecture of Angelini et al. (2015). To our knowledge this is the first impossibility result for HSBM weak recovery.As usual, we reduce the study of non-recovery of HSBM to the study of non-reconstruction in a related broadcasting on hypertrees (BOHT) model. While we show that BOHT\u2019s reconstruction threshold coincides with KS for $r=3,4$, surprisingly, we demonstrate that for $r\\ge 7$ reconstruction is possible also below KS. This shows an interesting phase transition in the parameter $r$, and suggests that for $r\\ge 7$, there might be an information-computation gap for the HSBM. For $r=5,6$ and large degree we propose an approach for showing non-reconstruction below KS, suggesting that $r=7$ is the correct threshold for onset of the new phase.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/gu23b/gu23b.pdf",
        "supp": "",
        "pdf_size": 461768,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6277514508123810179&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Masaschusetts Institute of Technology; Masaschusetts Institute of Technology",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "94f882533b",
        "title": "Zeroth-order Optimization with Weak Dimension Dependency",
        "site": "https://proceedings.mlr.press/v195/yue23b.html",
        "author": "Pengyun Yue; Long Yang; Cong Fang; Zhouchen Lin",
        "abstract": "Zeroth-order optimization is a fundamental research topic that has been a focus of various learning tasks, such as black-box adversarial attacks, bandits, and reinforcement learning.  However, in theory, most complexity results  assert a linear dependency on the dimension of  optimization variable, which implies paralyzations of zeroth-order algorithms for high-dimensional problems and cannot explain their effectiveness  in practice.  In this paper, we present a novel zeroth-order optimization theory characterized by complexities that exhibit weak dependencies on dimensionality. The key contribution lies in the introduction of a new factor, denoted as $\\effdim_{\\alpha} = \\sup_{\\x\\in \\mathbb{R}^d} \\sum_{i=1}^d \\sigma_i^\\alpha(\\nabla^2 f(\\x))$ ($\\alpha>0$, $\\sigma_i(\\cdot)$ is the $i$-th singular value in non-increasing order), which effectively functions as a measure of dimensionality. The algorithms we propose demonstrate significantly reduced complexities when measured in terms of the factor  $\\effdim_{\\alpha}$. Specifically, we first study  a well-known zeroth-order algorithm from Nesterov and Spokoiny (2017) on quadratic objectives and show a complexity of $ \\mathcal{O}\\left(\\frac{\\effdim_1 }{\\sigma_d}\\log(1/\\epsilon)\\right) $ for the strongly convex setting.  For linear regression, such a complexity is dimension-free and outperforms the traditional result by a factor of $d$ under common conditions. Furthermore, we introduce novel algorithms that leverages the Heavy-ball mechanism to enhance the optimization process. By incorporating this acceleration scheme, our proposed algorithm exhibits a complexity of $ \\mathcal{O}\\left(\\frac{\\effdim_{1/2} }{\\sqrt{\\sigma_d}}\\cdot\\log{\\frac{L}{\\mu}}\\cdot\\log(1/\\epsilon)\\right) $. For linear regression, under some mild conditions, it is faster than state-of-the-art algorithms by $\\sqrt{d}$. We further expand the scope of the method to encompass generic smooth optimization problems, while incorporating an additional Hessian-smooth condition. By considering this extended framework, our approach becomes applicable to a broader range of optimization scenarios. The resultant algorithms demonstrate remarkable complexities, with dimension-independent dominant terms that surpass existing algorithms by an order in $d$ under appropriate conditions. Our analysis lays the foundation for investigating zeroth-order optimization methods for smooth functions within high-dimensional settings.",
        "bibtex": "@InProceedings{pmlr-v195-yue23b,\n  title = \t {Zeroth-order Optimization with Weak Dimension Dependency},\n  author =       {Yue, Pengyun and Yang, Long and Fang, Cong and Lin, Zhouchen},\n  booktitle = \t {Proceedings of Thirty Sixth Conference on Learning Theory},\n  pages = \t {4429--4472},\n  year = \t {2023},\n  editor = \t {Neu, Gergely and Rosasco, Lorenzo},\n  volume = \t {195},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v195/yue23b/yue23b.pdf},\n  url = \t {https://proceedings.mlr.press/v195/yue23b.html},\n  abstract = \t {Zeroth-order optimization is a fundamental research topic that has been a focus of various learning tasks, such as black-box adversarial attacks, bandits, and reinforcement learning.  However, in theory, most complexity results  assert a linear dependency on the dimension of  optimization variable, which implies paralyzations of zeroth-order algorithms for high-dimensional problems and cannot explain their effectiveness  in practice.  In this paper, we present a novel zeroth-order optimization theory characterized by complexities that exhibit weak dependencies on dimensionality. The key contribution lies in the introduction of a new factor, denoted as $\\effdim_{\\alpha} = \\sup_{\\x\\in \\mathbb{R}^d} \\sum_{i=1}^d \\sigma_i^\\alpha(\\nabla^2 f(\\x))$ ($\\alpha>0$, $\\sigma_i(\\cdot)$ is the $i$-th singular value in non-increasing order), which effectively functions as a measure of dimensionality. The algorithms we propose demonstrate significantly reduced complexities when measured in terms of the factor  $\\effdim_{\\alpha}$. Specifically, we first study  a well-known zeroth-order algorithm from Nesterov and Spokoiny (2017) on quadratic objectives and show a complexity of $ \\mathcal{O}\\left(\\frac{\\effdim_1 }{\\sigma_d}\\log(1/\\epsilon)\\right) $ for the strongly convex setting.  For linear regression, such a complexity is dimension-free and outperforms the traditional result by a factor of $d$ under common conditions. Furthermore, we introduce novel algorithms that leverages the Heavy-ball mechanism to enhance the optimization process. By incorporating this acceleration scheme, our proposed algorithm exhibits a complexity of $ \\mathcal{O}\\left(\\frac{\\effdim_{1/2} }{\\sqrt{\\sigma_d}}\\cdot\\log{\\frac{L}{\\mu}}\\cdot\\log(1/\\epsilon)\\right) $. For linear regression, under some mild conditions, it is faster than state-of-the-art algorithms by $\\sqrt{d}$. We further expand the scope of the method to encompass generic smooth optimization problems, while incorporating an additional Hessian-smooth condition. By considering this extended framework, our approach becomes applicable to a broader range of optimization scenarios. The resultant algorithms demonstrate remarkable complexities, with dimension-independent dominant terms that surpass existing algorithms by an order in $d$ under appropriate conditions. Our analysis lays the foundation for investigating zeroth-order optimization methods for smooth functions within high-dimensional settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v195/yue23b/yue23b.pdf",
        "supp": "",
        "pdf_size": 602260,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17928226008711413099&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "National Key Lab of General AI, School of Intelligence Science and Technology, Peking University; National Key Lab of General AI, School of Intelligence Science and Technology, Peking University; National Key Lab of General AI, School of Intelligence Science and Technology, Peking University+Institute for Artificial Intelligence, Peking University; National Key Lab of General AI, School of Intelligence Science and Technology, Peking University+Institute for Artificial Intelligence, Peking University+Peng Cheng Laboratory",
        "aff_domain": "pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn",
        "email": "pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+0;0+0+1",
        "aff_unique_norm": "Peking University;Pengcheng Laboratory",
        "aff_unique_dep": "School of Intelligence Science and Technology;Peng Cheng Laboratory",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.pcl.ac.cn",
        "aff_unique_abbr": "Peking University;PCL",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0;0+0+0",
        "aff_country_unique": "China"
    }
]