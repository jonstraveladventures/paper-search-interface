[
    {
        "id": "07facfc54b",
        "title": "A General Characterization of the Statistical Query Complexity",
        "site": "https://proceedings.mlr.press/v65/feldman17c.html",
        "author": "Vitaly Feldman",
        "abstract": "Statistical query (SQ) algorithms  are algorithms that have access to an \\em SQ oracle for the input distribution $D$ instead of i.i.d.\u00a0samples from $D$. Given a query function $\u03c6:X \\to [-1,1]$, the oracle returns an estimate of $\\bf E_x\u223cD[\u03c6(x)]$ within some tolerance $\\tau_\u03c6$ that roughly corresponds to the number of samples. In this work we demonstrate that the complexity of solving an arbitrary statistical problem using SQ algorithms can be captured by a relatively simple notion of statistical dimension that we introduce. SQ algorithms capture a broad spectrum of algorithmic approaches used in theory and practice, most notably, convex optimization techniques. Hence our statistical dimension allows to investigate the power of a variety of algorithmic approaches by analyzing a single linear-algebraic parameter.  Such characterizations were investigated over the past 20 years in learning theory but prior characterizations are restricted to the much simpler setting of classification problems relative to a fixed distribution on the domain.  Our characterization is also the first to precisely characterize the necessary tolerance of queries.  We give applications of our techniques to two open problems in learning theory and to algorithms that are subject to memory and communication constraints.",
        "bibtex": "@InProceedings{pmlr-v65-feldman17c,\n  title = \t {A General Characterization of the Statistical Query Complexity},\n  author = \t {Feldman, Vitaly},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {785--830},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/feldman17c/feldman17c.pdf},\n  url = \t {https://proceedings.mlr.press/v65/feldman17c.html},\n  abstract = \t {Statistical query (SQ) algorithms  are algorithms that have access to an \\em SQ oracle for the input distribution $D$ instead of i.i.d.\u00a0samples from $D$. Given a query function $\u03c6:X \\to [-1,1]$, the oracle returns an estimate of $\\bf E_x\u223cD[\u03c6(x)]$ within some tolerance $\\tau_\u03c6$ that roughly corresponds to the number of samples. In this work we demonstrate that the complexity of solving an arbitrary statistical problem using SQ algorithms can be captured by a relatively simple notion of statistical dimension that we introduce. SQ algorithms capture a broad spectrum of algorithmic approaches used in theory and practice, most notably, convex optimization techniques. Hence our statistical dimension allows to investigate the power of a variety of algorithmic approaches by analyzing a single linear-algebraic parameter.  Such characterizations were investigated over the past 20 years in learning theory but prior characterizations are restricted to the much simpler setting of classification problems relative to a fixed distribution on the domain.  Our characterization is also the first to precisely characterize the necessary tolerance of queries.  We give applications of our techniques to two open problems in learning theory and to algorithms that are subject to memory and communication constraints.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/feldman17c/feldman17c.pdf",
        "supp": "",
        "pdf_size": 650611,
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10853752082570086789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "IBM Research - Almaden",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "IBM",
        "aff_unique_dep": "IBM Research",
        "aff_unique_url": "https://www.ibm.com/research",
        "aff_unique_abbr": "IBM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Almaden",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "36a30eb351",
        "title": "A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics",
        "site": "https://proceedings.mlr.press/v65/zhang17b.html",
        "author": "Yuchen Zhang; Percy Liang; Moses Charikar",
        "abstract": "We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for non-convex optimization. The algorithm performs stochastic gradient descent, where in each step it injects appropriately scaled Gaussian noise to the update. We analyze the algorithm\u2019s hitting time to an arbitrary subset of the parameter space. Two results follow from our general theory: First, we prove that for empirical risk minimization, if the empirical risk is point-wise close to the (smooth) population risk, then the algorithm achieves an approximate local minimum of the population risk in polynomial time, escaping suboptimal local minima that only exist in the empirical risk. Second, we show that SGLD improves on one of the best known learnability results for learning linear classifiers under the zero-one loss.",
        "bibtex": "@InProceedings{pmlr-v65-zhang17b,\n  title = \t {A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics},\n  author = \t {Zhang, Yuchen and Liang, Percy and Charikar, Moses},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1980--2022},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/zhang17b/zhang17b.pdf},\n  url = \t {https://proceedings.mlr.press/v65/zhang17b.html},\n  abstract = \t {We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for non-convex optimization. The algorithm performs stochastic gradient descent, where in each step it injects appropriately scaled Gaussian noise to the update. We analyze the algorithm\u2019s hitting time to an arbitrary subset of the parameter space. Two results follow from our general theory: First, we prove that for empirical risk minimization, if the empirical risk is point-wise close to the (smooth) population risk, then the algorithm achieves an approximate local minimum of the population risk in polynomial time, escaping suboptimal local minima that only exist in the empirical risk. Second, we show that SGLD improves on one of the best known learnability results for learning linear classifiers under the zero-one loss.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/zhang17b/zhang17b.pdf",
        "supp": "",
        "pdf_size": 764390,
        "gs_citation": 261,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6494436923132481688&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Computer Science Department, Stanford University; Computer Science Department, Stanford University; Computer Science Department, Stanford University",
        "aff_domain": "CS.STANFORD.EDU;CS.STANFORD.EDU;CS.STANFORD.EDU",
        "email": "CS.STANFORD.EDU;CS.STANFORD.EDU;CS.STANFORD.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "64b8200b5e",
        "title": "A Second-order Look at Stability and Generalization",
        "site": "https://proceedings.mlr.press/v65/maurer17a.html",
        "author": "Andreas Maurer",
        "abstract": "Using differentiability assumptions on the loss function and a concentration inequality for bounded second order differences it is shown that the generalization error for classification with L2 regularisation obeys a Bernstein-type inequality.",
        "bibtex": "@InProceedings{pmlr-v65-maurer17a,\n  title = \t {A Second-order Look at Stability and Generalization},\n  author = \t {Maurer, Andreas},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1461--1475},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/maurer17a/maurer17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/maurer17a.html},\n  abstract = \t {Using differentiability assumptions on the loss function and a concentration inequality for bounded second order differences it is shown that the generalization error for classification with L2 regularisation obeys a Bernstein-type inequality.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/maurer17a/maurer17a.pdf",
        "supp": "",
        "pdf_size": 285392,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15690055369654911775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Adalbertstr 55, D-80799 Munich, Germany",
        "aff_domain": "ANDREAS-MAURER.EU",
        "email": "ANDREAS-MAURER.EU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "c270b19d28",
        "title": "A Unified Analysis of Stochastic Optimization Methods Using Jump System Theory and Quadratic Constraints",
        "site": "https://proceedings.mlr.press/v65/hu17b.html",
        "author": "Bin Hu; Peter Seiler; Anders Rantzer",
        "abstract": "We develop a simple routine unifying the analysis of several important recently-developed stochastic optimization methods including SAGA, Finito, and stochastic dual coordinate ascent (SDCA). First, we show an intrinsic connection between stochastic optimization methods and dynamic jump systems, and propose a general jump system model for stochastic optimization methods. Our proposed model recovers SAGA, SDCA, Finito, and SAG as special cases. Then we combine jump system theory with several simple quadratic inequalities to derive sufficient conditions for convergence rate certifications of the proposed jump system model under various assumptions (with or without individual convexity, etc). The derived conditions are linear matrix inequalities (LMIs) whose size roughly scale with the size of the training set. We make use of the symmetry in the stochastic optimization methods and reduce these LMIs to some equivalent small LMIs whose sizes are at most 3 by 3. We solve these small LMIs to provide analytical proofs of new convergence rates for SAGA, Finito and SDCA (with or without individual convexity). We also explain why our proposed LMI fails in analyzing SAG. We reveal a key difference between SAG and other methods, and briefly discuss how to extend our LMI analysis for SAG. An advantage of our approach is that the proposed analysis can be automated for a large class of stochastic methods under various assumptions (with or without individual convexity, etc).",
        "bibtex": "@InProceedings{pmlr-v65-hu17b,\n  title = \t {A Unified Analysis of Stochastic Optimization Methods Using Jump System Theory and Quadratic Constraints},\n  author = \t {Hu, Bin and Seiler, Peter and Rantzer, Anders},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1157--1189},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/hu17b/hu17b.pdf},\n  url = \t {https://proceedings.mlr.press/v65/hu17b.html},\n  abstract = \t {We develop a simple routine unifying the analysis of several important recently-developed stochastic optimization methods including SAGA, Finito, and stochastic dual coordinate ascent (SDCA). First, we show an intrinsic connection between stochastic optimization methods and dynamic jump systems, and propose a general jump system model for stochastic optimization methods. Our proposed model recovers SAGA, SDCA, Finito, and SAG as special cases. Then we combine jump system theory with several simple quadratic inequalities to derive sufficient conditions for convergence rate certifications of the proposed jump system model under various assumptions (with or without individual convexity, etc). The derived conditions are linear matrix inequalities (LMIs) whose size roughly scale with the size of the training set. We make use of the symmetry in the stochastic optimization methods and reduce these LMIs to some equivalent small LMIs whose sizes are at most 3 by 3. We solve these small LMIs to provide analytical proofs of new convergence rates for SAGA, Finito and SDCA (with or without individual convexity). We also explain why our proposed LMI fails in analyzing SAG. We reveal a key difference between SAG and other methods, and briefly discuss how to extend our LMI analysis for SAG. An advantage of our approach is that the proposed analysis can be automated for a large class of stochastic methods under various assumptions (with or without individual convexity, etc).}\n}",
        "pdf": "http://proceedings.mlr.press/v65/hu17b/hu17b.pdf",
        "supp": "",
        "pdf_size": 357891,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16632982208226071531&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Wisconsin Institute for Discovery, University of Wisconsin, Madison, USA; Department of Aerospace Engineering and Mechanics, University of Minnesota, Minneapolis, USA; Department of Automatic Control, Lund University, Lund, Sweden",
        "aff_domain": "WISC.EDU;UMN.EDU;CONTROL.LTH.SE",
        "email": "WISC.EDU;UMN.EDU;CONTROL.LTH.SE",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Wisconsin-Madison;University of Minnesota;Lund University",
        "aff_unique_dep": "Wisconsin Institute for Discovery;Department of Aerospace Engineering and Mechanics;Department of Automatic Control",
        "aff_unique_url": "https://www.wisc.edu;https://www.umn.edu;https://www.lunduniversity.lu.se",
        "aff_unique_abbr": "UW-Madison;UMN;LU",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Madison;Minneapolis;Lund",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Sweden"
    },
    {
        "id": "ed94b9abc5",
        "title": "Adaptivity to Noise Parameters in Nonparametric Active Learning",
        "site": "https://proceedings.mlr.press/v65/locatelli-andrea17a.html",
        "author": "Carpentier Alexandra Locatelli Andrea; Kpotufe Samory",
        "abstract": "This work addresses various open questions in the theory of active learning for nonparametric classification.  Our contributions are both statistical and algorithmic: \\beginitemize \\item We establish new minimax-rates for active learning under common noise conditions. These rates display interesting transitions \u2013 due to the interaction between noise smoothness and margin \u2013 not present in the passive setting. Some such transitions were previously conjectured, but remained unconfirmed.  \\item We present a generic algorithmic strategy for adaptivity to unknown noise smoothness and margin; our strategy achieves optimal rates in many general situations; furthermore, unlike in previous work, we avoid the need for adaptive confidence sets, resulting in strictly milder distributional requirements. \\enditemize",
        "bibtex": "@InProceedings{pmlr-v65-locatelli andrea17a,\n  title = \t {Adaptivity to Noise Parameters in Nonparametric Active Learning},\n  author = \t {Locatelli Andrea, Carpentier Alexandra and Samory, Kpotufe},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1383--1416},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/locatelli andrea17a/locatelli andrea17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/locatelli-andrea17a.html},\n  abstract = \t {This work addresses various open questions in the theory of active learning for nonparametric classification.  Our contributions are both statistical and algorithmic: \\beginitemize \\item We establish new minimax-rates for active learning under common noise conditions. These rates display interesting transitions \u2013 due to the interaction between noise smoothness and margin \u2013 not present in the passive setting. Some such transitions were previously conjectured, but remained unconfirmed.  \\item We present a generic algorithmic strategy for adaptivity to unknown noise smoothness and margin; our strategy achieves optimal rates in many general situations; furthermore, unlike in previous work, we avoid the need for adaptive confidence sets, resulting in strictly milder distributional requirements. \\enditemize}\n}",
        "pdf": "http://proceedings.mlr.press/v65/locatelli andrea17a/locatelli andrea17a.pdf",
        "supp": "",
        "pdf_size": 497807,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17378977624326924370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e47c4ae3c1",
        "title": "Algorithmic Chaining and the Role of Partial Feedback in Online Nonparametric Learning",
        "site": "https://proceedings.mlr.press/v65/cesa-bianchi17a.html",
        "author": "Nicol\u00f2 Cesa-Bianchi; Pierre Gaillard; Claudio Gentile; S\u00e9bastien Gerchinovitz",
        "abstract": "We investigate contextual online learning with nonparametric (Lipschitz) comparison classes under different assumptions on losses and feedback information. For full information feedback and Lipschitz losses, we design the first explicit algorithm achieving the minimax regret rate (up to log factors). In a partial feedback model motivated by second-price auctions, we obtain algorithms for Lipschitz and semi-Lipschitz losses with regret bounds improving on the known bounds for standard bandit feedback. Our analysis combines novel results for contextual second-price auctions with a novel algorithmic approach based on chaining. When the context space is Euclidean, our chaining approach is efficient and delivers an even better regret bound.",
        "bibtex": "@InProceedings{pmlr-v65-cesa-bianchi17a,\n  title = \t {Algorithmic Chaining and the Role of Partial Feedback in Online Nonparametric Learning},\n  author = \t {Cesa-Bianchi, Nicol\u00f2 and Gaillard, Pierre and Gentile, Claudio and Gerchinovitz, S\u00e9bastien},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {465--481},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/cesa-bianchi17a/cesa-bianchi17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/cesa-bianchi17a.html},\n  abstract = \t {We investigate contextual online learning with nonparametric (Lipschitz) comparison classes under different assumptions on losses and feedback information. For full information feedback and Lipschitz losses, we design the first explicit algorithm achieving the minimax regret rate (up to log factors). In a partial feedback model motivated by second-price auctions, we obtain algorithms for Lipschitz and semi-Lipschitz losses with regret bounds improving on the known bounds for standard bandit feedback. Our analysis combines novel results for contextual second-price auctions with a novel algorithmic approach based on chaining. When the context space is Euclidean, our chaining approach is efficient and delivers an even better regret bound.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/cesa-bianchi17a/cesa-bianchi17a.pdf",
        "supp": "",
        "pdf_size": 392095,
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10804245320059532455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Universit\u00e0 degli Studi di Milano, Milano, Italy; INRIA - Sierra Project-team, D\u00e9partement d\u2019Informatique de l\u2019\u00c9cole Normale Sup\u00e9rieure, Paris, France; Universit\u00e0 degli Studi dell\u2019Insubria, Varese, Italy; Universit\u00e9 Toulouse III - Paul Sabatier, Toulouse, France",
        "aff_domain": "UNIMI.IT;INRIA.FR;UNINSUBRIA.IT;MATH.UNIV-TOULOUSE.FR",
        "email": "UNIMI.IT;INRIA.FR;UNINSUBRIA.IT;MATH.UNIV-TOULOUSE.FR",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Milano;INRIA;Universit\u00e0 degli Studi dell\u2019Insubria;Universit\u00e9 Toulouse III - Paul Sabatier",
        "aff_unique_dep": ";D\u00e9partement d\u2019Informatique de l\u2019\u00c9cole Normale Sup\u00e9rieure;;",
        "aff_unique_url": "https://www.unimi.it;https://www.inria.fr;https://www.uninsubria.it;https://www.univ-toulouse.fr",
        "aff_unique_abbr": "UniMi;INRIA;;UT3",
        "aff_campus_unique_index": "0;1;2;3",
        "aff_campus_unique": "Milano;Paris;Varese;Toulouse",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Italy;France"
    },
    {
        "id": "b894cda361",
        "title": "An Improved Parametrization and Analysis of the EXP3++ Algorithm for Stochastic and Adversarial Bandits",
        "site": "https://proceedings.mlr.press/v65/seldin17a.html",
        "author": "Yevgeny Seldin; G\u00e1bor Lugosi",
        "abstract": "We present a new strategy for gap estimation in randomized algorithms for multiarmed bandits and combine it with the EXP3++ algorithm of Seldin and Slivkins (2014). In the stochastic regime the strategy reduces dependence of regret on a time horizon from $(\\ln t)^3$ to $(\\ln t)^2$ and eliminates an additive factor of order $\u2206e^1/\u2206^2$, where $\u2206$ is the minimal gap of a problem instance. In the adversarial regime regret guarantee remains unchanged.",
        "bibtex": "@InProceedings{pmlr-v65-seldin17a,\n  title = \t {An Improved Parametrization and Analysis of the {EXP3++} Algorithm for Stochastic and Adversarial Bandits},\n  author = \t {Seldin, Yevgeny and Lugosi, G\u00e1bor},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1743--1759},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/seldin17a/seldin17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/seldin17a.html},\n  abstract = \t {We present a new strategy for gap estimation in randomized algorithms for multiarmed bandits and combine it with the EXP3++ algorithm of Seldin and Slivkins (2014). In the stochastic regime the strategy reduces dependence of regret on a time horizon from $(\\ln t)^3$ to $(\\ln t)^2$ and eliminates an additive factor of order $\u2206e^1/\u2206^2$, where $\u2206$ is the minimal gap of a problem instance. In the adversarial regime regret guarantee remains unchanged.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/seldin17a/seldin17a.pdf",
        "supp": "",
        "pdf_size": 345521,
        "gs_citation": 117,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2317253245521929079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Copenhagen; ICREA and Pompeu Fabra University",
        "aff_domain": "DI.KU.DK;GMAIL.COM",
        "email": "DI.KU.DK;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Copenhagen;Pompeu Fabra University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ku.dk;https://www.upf.edu",
        "aff_unique_abbr": "UCPH;UPF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Denmark;Spain"
    },
    {
        "id": "26572338df",
        "title": "Bandits with Movement Costs and Adaptive Pricing",
        "site": "https://proceedings.mlr.press/v65/koren17a.html",
        "author": "Tomer Koren; Roi Livni; Yishay Mansour",
        "abstract": "We extend the model of Multi-Armed Bandit with unit switching cost to incorporate a metric between the actions. We consider the case where the metric over the actions can be modeled by a complete binary tree, and the distance between two leaves is the size of the subtree of their least common ancestor, which abstracts the case that the actions are points on the continuous interval $[0,1]$ and the switching cost is their distance. In this setting, we give a new algorithm that establishes a regret of $\\widetilde{O}(\\sqrt{k}T + T/k)$, where $k$ is the number of actions and $T$ is the time horizon. When the set of actions corresponds to whole $[0,1]$ interval we can exploit our method for the task of bandit learning with Lipschitz loss functions, where our algorithm achieves an optimal regret rate of $\\widetilde{\u0398}(T^2/3)$, which is the same rate one obtains when there is no penalty for movements. As our main application, we use our new algorithm to solve an adaptive pricing problem. Specifically, we consider the case of a single seller faced with a stream of patient buyers. Each buyer has a private value and a window of time in which they are interested in buying, and they buy at the lowest price in the window, if it is below their value. We show that with an appropriate discretization of the prices, the seller can achieve a regret of $\\widetilde{O}(T^2/3)$ compared to the best fixed price in hindsight, which outperform the previous regret bound of $\\widetilde{O}(T^3/4)$ for the problem.",
        "bibtex": "@InProceedings{pmlr-v65-koren17a,\n  title = \t {Bandits with Movement Costs and Adaptive Pricing},\n  author = \t {Koren, Tomer and Livni, Roi and Mansour, Yishay},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1242--1268},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/koren17a/koren17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/koren17a.html},\n  abstract = \t {We extend the model of Multi-Armed Bandit with unit switching cost to incorporate a metric between the actions. We consider the case where the metric over the actions can be modeled by a complete binary tree, and the distance between two leaves is the size of the subtree of their least common ancestor, which abstracts the case that the actions are points on the continuous interval $[0,1]$ and the switching cost is their distance. In this setting, we give a new algorithm that establishes a regret of $\\widetilde{O}(\\sqrt{k}T + T/k)$, where $k$ is the number of actions and $T$ is the time horizon. When the set of actions corresponds to whole $[0,1]$ interval we can exploit our method for the task of bandit learning with Lipschitz loss functions, where our algorithm achieves an optimal regret rate of $\\widetilde{\u0398}(T^2/3)$, which is the same rate one obtains when there is no penalty for movements. As our main application, we use our new algorithm to solve an adaptive pricing problem. Specifically, we consider the case of a single seller faced with a stream of patient buyers. Each buyer has a private value and a window of time in which they are interested in buying, and they buy at the lowest price in the window, if it is below their value. We show that with an appropriate discretization of the prices, the seller can achieve a regret of $\\widetilde{O}(T^2/3)$ compared to the best fixed price in hindsight, which outperform the previous regret bound of $\\widetilde{O}(T^3/4)$ for the problem. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/koren17a/koren17a.pdf",
        "supp": "",
        "pdf_size": 375627,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9822005672896008008&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Google; Princeton University, Computer Science Department; Tel Aviv University, Blavatnik School of Computer Science",
        "aff_domain": "google.com;cs.princeton.edu;tau.ac.il",
        "email": "google.com;cs.princeton.edu;tau.ac.il",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Google;Princeton University;Tel Aviv University",
        "aff_unique_dep": "Google;Computer Science Department;Blavatnik School of Computer Science",
        "aff_unique_url": "https://www.google.com;https://www.princeton.edu;https://www.tau.ac.il",
        "aff_unique_abbr": "Google;Princeton;TAU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "4c1a2376e0",
        "title": "Computationally Efficient Robust Sparse Estimation in High Dimensions",
        "site": "https://proceedings.mlr.press/v65/balakrishnan17a.html",
        "author": "Sivaraman Balakrishnan; Simon S. Du; Jerry Li; Aarti Singh",
        "abstract": "Many conventional statistical procedures are extremely sensitive to seemingly minor deviations from modeling assumptions. This problem is exacerbated in modern high-dimensional settings, where the problem dimension can grow with and possibly exceed the sample size.  We consider the problem of robust estimation of sparse functionals, and  provide a computationally and statistically efficient algorithm in the high-dimensional setting. Our theory identifies a unified set of deterministic conditions under which our algorithm guarantees accurate recovery.  By further establishing that these deterministic conditions hold with high-probability for a wide range of statistical models, our theory applies to many problems of considerable interest including sparse mean and covariance estimation; sparse linear regression; and sparse generalized linear models. In certain settings, such as the detection and estimation of sparse principal components in  the spiked covariance model, our general theory does not yield optimal sample complexity, and we provide a novel algorithm based on the same intuition which is able to take advantage of further structure of the problem to achieve nearly optimal rates.",
        "bibtex": "@InProceedings{pmlr-v65-balakrishnan17a,\n  title = \t {Computationally Efficient Robust Sparse Estimation in High Dimensions},\n  author = \t {Balakrishnan, Sivaraman and Du, Simon S. and Li, Jerry and Singh, Aarti},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {169--212},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/balakrishnan17a/balakrishnan17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/balakrishnan17a.html},\n  abstract = \t {Many conventional statistical procedures are extremely sensitive to seemingly minor deviations from modeling assumptions. This problem is exacerbated in modern high-dimensional settings, where the problem dimension can grow with and possibly exceed the sample size.  We consider the problem of robust estimation of sparse functionals, and  provide a computationally and statistically efficient algorithm in the high-dimensional setting. Our theory identifies a unified set of deterministic conditions under which our algorithm guarantees accurate recovery.  By further establishing that these deterministic conditions hold with high-probability for a wide range of statistical models, our theory applies to many problems of considerable interest including sparse mean and covariance estimation; sparse linear regression; and sparse generalized linear models. In certain settings, such as the detection and estimation of sparse principal components in  the spiked covariance model, our general theory does not yield optimal sample complexity, and we provide a novel algorithm based on the same intuition which is able to take advantage of further structure of the problem to achieve nearly optimal rates.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/balakrishnan17a/balakrishnan17a.pdf",
        "supp": "",
        "pdf_size": 393266,
        "gs_citation": 149,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12749702058885884931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistics, Carnegie Mellon University; Machine Learning Department, School of Computer Science, Carnegie Mellon University; Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology; Machine Learning Department, School of Computer Science, Carnegie Mellon University",
        "aff_domain": "stat.cmu.edu;cs.cmu.edu;mit.edu;cmu.edu",
        "email": "stat.cmu.edu;cs.cmu.edu;mit.edu;cmu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Statistics;Electrical Engineering and Computer Science Department",
        "aff_unique_url": "https://www.cmu.edu;https://web.mit.edu",
        "aff_unique_abbr": "CMU;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4dc77ad631",
        "title": "Corralling a Band of Bandit Algorithms",
        "site": "https://proceedings.mlr.press/v65/agarwal17b.html",
        "author": "Alekh Agarwal; Haipeng Luo; Behnam Neyshabur; Robert E. Schapire",
        "abstract": "We study the problem of combining multiple bandit algorithms (that is, online learning algorithms with partial feedback) with the goal of creating a master algorithm that performs almost as well as the best base algorithm \\it if it were to be run on its own.  The main challenge is that when run with a master, base algorithms unavoidably receive much less feedback and it is thus critical that the master not starve a base algorithm that might perform uncompetitively initially but would eventually outperform others if given enough feedback.  We address this difficulty by devising a version of Online Mirror Descent with a special mirror map together with a sophisticated learning rate scheme. We show that this approach manages to achieve a more delicate balance between exploiting and exploring base algorithms than previous works yielding superior regret bounds. Our results are applicable to many settings, such as multi-armed bandits, contextual bandits, and convex bandits. As examples, we present two main applications. The first is to create an algorithm that enjoys worst-case robustness while at the same time performing much better when the environment is relatively easy.  The second is to create an algorithm that works simultaneously under different assumptions of the environment, such as different priors or different loss structures.",
        "bibtex": "@InProceedings{pmlr-v65-agarwal17b,\n  title = \t {Corralling a Band of Bandit Algorithms},\n  author = \t {Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E.},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {12--38},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/agarwal17b/agarwal17b.pdf},\n  url = \t {https://proceedings.mlr.press/v65/agarwal17b.html},\n  abstract = \t {We study the problem of combining multiple bandit algorithms (that is, online learning algorithms with partial feedback) with the goal of creating a master algorithm that performs almost as well as the best base algorithm \\it if it were to be run on its own.  The main challenge is that when run with a master, base algorithms unavoidably receive much less feedback and it is thus critical that the master not starve a base algorithm that might perform uncompetitively initially but would eventually outperform others if given enough feedback.  We address this difficulty by devising a version of Online Mirror Descent with a special mirror map together with a sophisticated learning rate scheme. We show that this approach manages to achieve a more delicate balance between exploiting and exploring base algorithms than previous works yielding superior regret bounds. Our results are applicable to many settings, such as multi-armed bandits, contextual bandits, and convex bandits. As examples, we present two main applications. The first is to create an algorithm that enjoys worst-case robustness while at the same time performing much better when the environment is relatively easy.  The second is to create an algorithm that works simultaneously under different assumptions of the environment, such as different priors or different loss structures.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/agarwal17b/agarwal17b.pdf",
        "supp": "",
        "pdf_size": 479023,
        "gs_citation": 200,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=152061575041888154&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Microsoft Research, New York; Microsoft Research, New York; Toyota Technological Institute at Chicago; Microsoft Research, New York",
        "aff_domain": "microsoft.com;microsoft.com;ttic.edu;microsoft.com",
        "email": "microsoft.com;microsoft.com;ttic.edu;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Microsoft;Toyota Technological Institute at Chicago",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.tti-chicago.org",
        "aff_unique_abbr": "MSR;TTI Chicago",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "New York;Chicago",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "de4ea84bab",
        "title": "Correspondence retrieval",
        "site": "https://proceedings.mlr.press/v65/andoni17a.html",
        "author": "Alexandr Andoni; Daniel Hsu; Kevin Shi; Xiaorui Sun",
        "abstract": "This article studies the correspondence retrieval problem: a set of $k$ distinct but unknown points $\\mathbf{x}_1, \\mathbf{x}_2, \\dotsc, \\mathbf{x}_k \u2208\\mathbb{R}^d$ are to be recovered from the unordered collection of projection values $\u27e8\\mathbf{w}_i,\\mathbf{x}_1 \u27e9, \u27e8\\mathbf{w}_i,\\mathbf{x}_2 \u27e9, \\dotsc, \u27e8\\mathbf{w}_i,\\mathbf{x}_k \u27e9$ onto $n$ known measurement vectors $\\mathbf{w}_1, \\mathbf{w}_2, \\dotsc, \\mathbf{w}_n$.  Importantly, the correspondence of the $k$ projections ${\u27e8\\mathbf{w}_i,\\mathbf{x}_j \u27e9}_j=1^k$ across different measurements is unknown.  A special case of this problem is the well-studied problem of (real-valued) phase retrieval.  In the case of independent standard Gaussian measurement vectors, the main algorithm proposed in this work requires $n = d+1$ measurements to correctly return the $k$ unknown points with high probability.  This number of measurements is optimal, and it is smaller than the number of measurements required for a stronger \u201cfor all\u201d guarantee even in the phase retrieval setting.  The algorithm is based on reductions to the Shortest Vector Problem on certain random lattices, and employs the Lenstra, Lenstra, and Lov\u00e1sz (1982) basis reduction algorithm in a manner similar to the Lagarias & Odlyzko (1985) algorithm for solving random instances of Subset Sum.  Another algorithm, essentially due to Yi, Caramanis, & Sanghavi (2016), based on higher-order moments and tensor decompositions is shown to work in a setting where the projection values are corrupted by additive Gaussian noise, but it requires a significantly larger number of measurements.",
        "bibtex": "@InProceedings{pmlr-v65-andoni17a,\n  title = \t {Correspondence retrieval},\n  author = \t {Andoni, Alexandr and Hsu, Daniel and Shi, Kevin and Sun, Xiaorui},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {105--126},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/andoni17a/andoni17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/andoni17a.html},\n  abstract = \t {This article studies the correspondence retrieval problem: a set of $k$ distinct but unknown points $\\mathbf{x}_1, \\mathbf{x}_2, \\dotsc, \\mathbf{x}_k \u2208\\mathbb{R}^d$ are to be recovered from the unordered collection of projection values $\u27e8\\mathbf{w}_i,\\mathbf{x}_1 \u27e9, \u27e8\\mathbf{w}_i,\\mathbf{x}_2 \u27e9, \\dotsc, \u27e8\\mathbf{w}_i,\\mathbf{x}_k \u27e9$ onto $n$ known measurement vectors $\\mathbf{w}_1, \\mathbf{w}_2, \\dotsc, \\mathbf{w}_n$.  Importantly, the correspondence of the $k$ projections ${\u27e8\\mathbf{w}_i,\\mathbf{x}_j \u27e9}_j=1^k$ across different measurements is unknown.  A special case of this problem is the well-studied problem of (real-valued) phase retrieval.  In the case of independent standard Gaussian measurement vectors, the main algorithm proposed in this work requires $n = d+1$ measurements to correctly return the $k$ unknown points with high probability.  This number of measurements is optimal, and it is smaller than the number of measurements required for a stronger \u201cfor all\u201d guarantee even in the phase retrieval setting.  The algorithm is based on reductions to the Shortest Vector Problem on certain random lattices, and employs the Lenstra, Lenstra, and Lov\u00e1sz (1982) basis reduction algorithm in a manner similar to the Lagarias & Odlyzko (1985) algorithm for solving random instances of Subset Sum.  Another algorithm, essentially due to Yi, Caramanis, & Sanghavi (2016), based on higher-order moments and tensor decompositions is shown to work in a setting where the projection values are corrupted by additive Gaussian noise, but it requires a significantly larger number of measurements.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/andoni17a/andoni17a.pdf",
        "supp": "",
        "pdf_size": 357492,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17847135375065563472&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Department, Columbia University; Computer Science Department, Columbia University; Computer Science Department, Columbia University; Simons Institute for the Theory of Computing, UC Berkeley",
        "aff_domain": "CS.COLUMBIA.EDU;CS.COLUMBIA.EDU;CS.COLUMBIA.EDU;CS.COLUMBIA.EDU",
        "email": "CS.COLUMBIA.EDU;CS.COLUMBIA.EDU;CS.COLUMBIA.EDU;CS.COLUMBIA.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Columbia University;University of California, Berkeley",
        "aff_unique_dep": "Computer Science Department;Simons Institute for the Theory of Computing",
        "aff_unique_url": "https://www.columbia.edu;https://simons.berkeley.edu",
        "aff_unique_abbr": "Columbia;UC Berkeley",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "New York;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "235c7f8204",
        "title": "Depth Separation for Neural Networks",
        "site": "https://proceedings.mlr.press/v65/daniely17a.html",
        "author": "Amit Daniely",
        "abstract": "Let $f:\\mathbb{S}^d-1\\times \\mathbb{S}^d-1\\to\\mathbb{S}$ be a function of the form $f(x,x\u2019) = g(\u27e8x,x\u2019\u27e9)$ for $g:[-1,1]\\to \\mathbb{R}$. We give a simple proof that shows that poly-size depth two neural networks with (exponentially) bounded weights cannot approximate $f$ whenever $g$ cannot be approximated by a low degree polynomial. Moreover, for many $g$\u2019s, such as $g(x)=\\sin(\\pi d^3x)$, the number of neurons must be $2^\u03a9\\left(d\\log(d)\\right)$. Furthermore, the result holds w.r.t. the uniform distribution on $\\mathbb{S}^d-1\\times \\mathbb{S}^d-1$. As many functions of the above form can be well approximated by poly-size depth three networks with poly-bounded weights, this establishes a separation between depth two and depth three networks w.r.t. the uniform distribution on $\\mathbb{S}^d-1\\times \\mathbb{S}^d-1$.",
        "bibtex": "@InProceedings{pmlr-v65-daniely17a,\n  title = \t {Depth Separation for Neural Networks},\n  author = \t {Daniely, Amit},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {690--696},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/daniely17a/daniely17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/daniely17a.html},\n  abstract = \t {Let $f:\\mathbb{S}^d-1\\times \\mathbb{S}^d-1\\to\\mathbb{S}$ be a function of the form $f(x,x\u2019) = g(\u27e8x,x\u2019\u27e9)$ for $g:[-1,1]\\to \\mathbb{R}$. We give a simple proof that shows that poly-size depth two neural networks with (exponentially) bounded weights cannot approximate $f$ whenever $g$ cannot be approximated by a low degree polynomial. Moreover, for many $g$\u2019s, such as $g(x)=\\sin(\\pi d^3x)$, the number of neurons must be $2^\u03a9\\left(d\\log(d)\\right)$. Furthermore, the result holds w.r.t. the uniform distribution on $\\mathbb{S}^d-1\\times \\mathbb{S}^d-1$. As many functions of the above form can be well approximated by poly-size depth three networks with poly-bounded weights, this establishes a separation between depth two and depth three networks w.r.t. the uniform distribution on $\\mathbb{S}^d-1\\times \\mathbb{S}^d-1$.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/daniely17a/daniely17a.pdf",
        "supp": "",
        "pdf_size": 233077,
        "gs_citation": 105,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7106901131063635193&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Google Brain",
        "aff_domain": "MAIL.HUJI.AC.IL",
        "email": "MAIL.HUJI.AC.IL",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Brain",
        "aff_unique_url": "https://brain.google.com",
        "aff_unique_abbr": "Google Brain",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "91f95c86e0",
        "title": "Effective Semisupervised Learning on Manifolds",
        "site": "https://proceedings.mlr.press/v65/globerson17a.html",
        "author": "Amir Globerson; Roi Livni; Shai Shalev-Shwartz",
        "abstract": "The abundance of unlabeled data makes semi-supervised learning (SSL) an attractive approach for improving the accuracy of learning systems. However, we are still far from a complete theoretical understanding of the benefits of this learning scenario in terms of sample complexity. In particular, for many natural learning settings it can in fact be shown that SSL does not improve sample complexity. Thus far, the only case where SSL provably helps, without compatibility assumptions, is a recent combinatorial construction of Darnstadt et al. Deriving similar theoretical guarantees for more commonly used approaches to SSL remains a challenge. Here, we provide the first analysis of manifold based SSL, where there is a provable gap between supervised learning and SSL, and this gap can be arbitrarily large. Proving the required lower bound is a technical challenge, involving tools from geometric measure theory. The algorithm we analyse is similar to subspace clustering, and thus our results demonstrate that this method can be used to improve sample complexity.",
        "bibtex": "@InProceedings{pmlr-v65-globerson17a,\n  title = \t {Effective Semisupervised Learning on Manifolds},\n  author = \t {Globerson, Amir and Livni, Roi and Shalev-Shwartz, Shai},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {978--1003},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/globerson17a/globerson17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/globerson17a.html},\n  abstract = \t {The abundance of unlabeled data makes semi-supervised learning (SSL) an attractive approach for improving the accuracy of learning systems. However, we are still far from a complete theoretical understanding of the benefits of this learning scenario in terms of sample complexity. In particular, for many natural learning settings it can in fact be shown that SSL does not improve sample complexity. Thus far, the only case where SSL provably helps, without compatibility assumptions, is a recent combinatorial construction of Darnstadt et al. Deriving similar theoretical guarantees for more commonly used approaches to SSL remains a challenge. Here, we provide the first analysis of manifold based SSL, where there is a provable gap between supervised learning and SSL, and this gap can be arbitrarily large. Proving the required lower bound is a technical challenge, involving tools from geometric measure theory. The algorithm we analyse is similar to subspace clustering, and thus our results demonstrate that this method can be used to improve sample complexity.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/globerson17a/globerson17a.pdf",
        "supp": "",
        "pdf_size": 613002,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14890132209669324098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Computer Science, Tel Aviv University; School of Computer Science, Princeton University; School of Computer Science and Engineering, Hebrew University",
        "aff_domain": "TAU.AC.IL;CS.PRINCETON.EDU;CS.HUJI.AC.IL",
        "email": "TAU.AC.IL;CS.PRINCETON.EDU;CS.HUJI.AC.IL",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Tel Aviv University;Princeton University;Hebrew University",
        "aff_unique_dep": "School of Computer Science;School of Computer Science;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.tau.ac.il;https://www.princeton.edu;http://www.huji.ac.il",
        "aff_unique_abbr": "TAU;Princeton;HUJI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Tel Aviv;Princeton;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "397ead983c",
        "title": "Efficient Co-Training of Linear Separators under Weak Dependence",
        "site": "https://proceedings.mlr.press/v65/blum17a.html",
        "author": "Avrim Blum; Yishay Mansour",
        "abstract": "We develop the first polynomial-time algorithm for co-training of homogeneous linear separators under \\em weak dependence, a relaxation of the condition of independence given the label. Our algorithm learns from purely unlabeled data, except for a single labeled example to break symmetry of the two classes, and works for any data distribution having an inverse-polynomial margin and with center of mass at the origin.",
        "bibtex": "@InProceedings{pmlr-v65-blum17a,\n  title = \t {Efficient Co-Training of Linear Separators under Weak Dependence},\n  author = \t {Blum, Avrim and Mansour, Yishay},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {302--318},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/blum17a/blum17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/blum17a.html},\n  abstract = \t {We develop the first polynomial-time algorithm for co-training of homogeneous linear separators under \\em weak dependence, a relaxation of the condition of independence given the label. Our algorithm learns from purely unlabeled data, except for a single labeled example to break symmetry of the two classes, and works for any data distribution having an inverse-polynomial margin and with center of mass at the origin.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/blum17a/blum17a.pdf",
        "supp": "",
        "pdf_size": 327072,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12163223494926468446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Carnegie Mellon University, Computer Science Department; Tel Aviv University, Blavatnik School of Computer Science",
        "aff_domain": "CS.CMU.EDU;TAU.AC.IL",
        "email": "CS.CMU.EDU;TAU.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Carnegie Mellon University;Tel Aviv University",
        "aff_unique_dep": "Computer Science Department;Blavatnik School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu;https://www.tau.ac.il",
        "aff_unique_abbr": "CMU;TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "b2372564d6",
        "title": "Efficient PAC Learning from the Crowd",
        "site": "https://proceedings.mlr.press/v65/awasthi17a.html",
        "author": "Pranjal Awasthi; Avrim Blum; Nika Haghtalab; Yishay Mansour",
        "abstract": "In recent years crowdsourcing has become the method of choice for gathering labeled training data for learning algorithms. Standard approaches to crowdsourcing view the process of acquiring labeled data separately from the process of learning a classifier from the gathered data. This can give rise to computational and statistical challenges. For example, in most cases there are no known computationally efficient learning algorithms that are robust to the high level of noise that exists in crowdsourced data, and efforts to eliminate noise through voting often require a large number of queries per example. In this paper, we show how by interleaving the process of labeling and learning, we can attain computational efficiency with much less overhead in the labeling cost. In particular, we consider the \\em realizable setting where there exists a true target function in $\\mathcal{F}$ and consider a pool of labelers. When a noticeable fraction of the labelers are \\emphperfect, and the rest  behave arbitrarily, we show that any $\\mathcal{F}$ that can be efficiently learned in the traditional \\em realizable PAC model can be learned in a computationally efficient manner by querying the crowd, despite high amounts of noise in the responses. Moreover, we show that this can be done while each labeler only labels a constant number of examples and the number of labels requested per example, on average, is a constant. When no perfect labelers exist, a related task is to find a set of the labelers which are \\emphgood but not perfect. We show that we can identify  all good labelers, when at least the majority of labelers are good.",
        "bibtex": "@InProceedings{pmlr-v65-awasthi17a,\n  title = \t {Efficient PAC Learning from the Crowd},\n  author = \t {Awasthi, Pranjal and Blum, Avrim and Haghtalab, Nika and Mansour, Yishay},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {127--150},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/awasthi17a/awasthi17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/awasthi17a.html},\n  abstract = \t {In recent years crowdsourcing has become the method of choice for gathering labeled training data for learning algorithms. Standard approaches to crowdsourcing view the process of acquiring labeled data separately from the process of learning a classifier from the gathered data. This can give rise to computational and statistical challenges. For example, in most cases there are no known computationally efficient learning algorithms that are robust to the high level of noise that exists in crowdsourced data, and efforts to eliminate noise through voting often require a large number of queries per example. In this paper, we show how by interleaving the process of labeling and learning, we can attain computational efficiency with much less overhead in the labeling cost. In particular, we consider the \\em realizable setting where there exists a true target function in $\\mathcal{F}$ and consider a pool of labelers. When a noticeable fraction of the labelers are \\emphperfect, and the rest  behave arbitrarily, we show that any $\\mathcal{F}$ that can be efficiently learned in the traditional \\em realizable PAC model can be learned in a computationally efficient manner by querying the crowd, despite high amounts of noise in the responses. Moreover, we show that this can be done while each labeler only labels a constant number of examples and the number of labels requested per example, on average, is a constant. When no perfect labelers exist, a related task is to find a set of the labelers which are \\emphgood but not perfect. We show that we can identify  all good labelers, when at least the majority of labelers are good. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/awasthi17a/awasthi17a.pdf",
        "supp": "",
        "pdf_size": 329366,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9192080058742301647&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Rutgers University; Carnegie Mellon University; Carnegie Mellon University; Tel-Aviv University",
        "aff_domain": "CS.RUTGERS.EDU;CS.CMU.EDU;CS.CMU.EDU;TAU.AC.IL",
        "email": "CS.RUTGERS.EDU;CS.CMU.EDU;CS.CMU.EDU;TAU.AC.IL",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Rutgers University;Carnegie Mellon University;Tel Aviv University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.rutgers.edu;https://www.cmu.edu;https://www.tau.ac.il",
        "aff_unique_abbr": "Rutgers;CMU;TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "82f1be45d4",
        "title": "Empirical Risk Minimization for Stochastic Convex Optimization: $O(1/n)$- and $O(1/n^2)$-type of Risk Bounds",
        "site": "https://proceedings.mlr.press/v65/zhang17a.html",
        "author": "Lijun Zhang; Tianbao Yang; Rong Jin",
        "abstract": "Although there exist plentiful theories of empirical risk minimization (ERM) for supervised learning, current theoretical understandings of ERM for a related problem\u2014stochastic convex optimization (SCO), are limited. In this work, we strengthen the realm of ERM for SCO by exploiting smoothness and strong convexity conditions to improve the risk bounds. First, we establish an $\\widetilde{O}(d/n + \\sqrt{F}_*/n)$ risk bound when the random function is nonnegative, convex and smooth, and the expected function is Lipschitz continuous, where $d$ is the dimensionality of the problem, $n$ is the number of samples, and $F_*$ is the minimal risk. Thus, when $F_*$ is small we obtain an $\\widetilde{O}(d/n)$ risk bound, which is analogous to the $\\widetilde{O}(1/n)$ optimistic rate of ERM for supervised learning. Second, if the objective function is also $\u03bb$-strongly convex, we prove an $\\widetilde{O}(d/n  + \u03baF_*/n )$ risk bound where $\u03ba$ is the condition number, and improve it to $O(1/[\u03bbn^2] + \u03baF_*/n)$ when $n=\\widetilde{\u03a9}(\u03bad)$. As a result, we obtain an $O(\u03ba/n^2)$ risk bound under the condition that $n$ is large and $F_*$ is small, which to the best of our knowledge, is the first $O(1/n^2)$-type of risk bound of ERM. Third, we stress that the above results are established in a unified framework, which allows us to derive new risk bounds under weaker conditions, e.g., without convexity of the random function.  Finally, we demonstrate that to achieve an $O(1/[\u03bbn^2] + \u03baF_*/n)$ risk bound for supervised learning,  the $\\widetilde{\u03a9}(\u03bad)$ requirement on $n$ can be replaced with $\u03a9(\u03ba^2)$, which is dimensionality-independent.",
        "bibtex": "@InProceedings{pmlr-v65-zhang17a,\n  title = \t {Empirical Risk Minimization for Stochastic Convex Optimization: ${O}(1/n)$- and ${O}(1/n^2)$-type of Risk Bounds},\n  author = \t {Zhang, Lijun and Yang, Tianbao and Jin, Rong},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1954--1979},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/zhang17a/zhang17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/zhang17a.html},\n  abstract = \t {Although there exist plentiful theories of empirical risk minimization (ERM) for supervised learning, current theoretical understandings of ERM for a related problem\u2014stochastic convex optimization (SCO), are limited. In this work, we strengthen the realm of ERM for SCO by exploiting smoothness and strong convexity conditions to improve the risk bounds. First, we establish an $\\widetilde{O}(d/n + \\sqrt{F}_*/n)$ risk bound when the random function is nonnegative, convex and smooth, and the expected function is Lipschitz continuous, where $d$ is the dimensionality of the problem, $n$ is the number of samples, and $F_*$ is the minimal risk. Thus, when $F_*$ is small we obtain an $\\widetilde{O}(d/n)$ risk bound, which is analogous to the $\\widetilde{O}(1/n)$ optimistic rate of ERM for supervised learning. Second, if the objective function is also $\u03bb$-strongly convex, we prove an $\\widetilde{O}(d/n  + \u03baF_*/n )$ risk bound where $\u03ba$ is the condition number, and improve it to $O(1/[\u03bbn^2] + \u03baF_*/n)$ when $n=\\widetilde{\u03a9}(\u03bad)$. As a result, we obtain an $O(\u03ba/n^2)$ risk bound under the condition that $n$ is large and $F_*$ is small, which to the best of our knowledge, is the first $O(1/n^2)$-type of risk bound of ERM. Third, we stress that the above results are established in a unified framework, which allows us to derive new risk bounds under weaker conditions, e.g., without convexity of the random function.  Finally, we demonstrate that to achieve an $O(1/[\u03bbn^2] + \u03baF_*/n)$ risk bound for supervised learning,  the $\\widetilde{\u03a9}(\u03bad)$ requirement on $n$ can be replaced with $\u03a9(\u03ba^2)$, which is dimensionality-independent.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/zhang17a/zhang17a.pdf",
        "supp": "",
        "pdf_size": 319433,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10154963558951285999&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; Department of Computer Science, the University of Iowa, Iowa City, IA 52242, USA; Alibaba Group, Seattle, USA",
        "aff_domain": "LAMDA.NJU.EDU.CN;UIOWA.EDU;ALIBABA-INC.COM",
        "email": "LAMDA.NJU.EDU.CN;UIOWA.EDU;ALIBABA-INC.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Nanjing University;University of Iowa;Alibaba Group",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology;Department of Computer Science;",
        "aff_unique_url": "http://www.nju.edu.cn;https://www.uiowa.edu;https://www.alibaba.com",
        "aff_unique_abbr": "Nanjing U;UIowa;Alibaba",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Nanjing;Iowa City;Seattle",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "2e5e4e0850",
        "title": "Exact tensor completion with sum-of-squares",
        "site": "https://proceedings.mlr.press/v65/potechin17a.html",
        "author": "Aaron Potechin; David Steurer",
        "abstract": "We obtain the first polynomial-time algorithm for exact tensor completion that improves over the bound implied by reduction to matrix completion. The algorithm recovers an unknown 3-tensor with $r$ incoherent, orthogonal components in $\\mathbb R^n$ from $r\u22c5\\tilde O(n^1.5)$ randomly observed entries of the tensor. This bound improves over the previous best one of $r\u22c5\\tilde O(n^2)$ by reduction to exact matrix completion. Our bound also matches the best known results for the easier problem of approximate tensor completion (Barak & Moitra, 2015). Our algorithm and analysis extends seminal results for exact matrix completion (Candes & Recht, 2009) to the tensor setting via the sum-of-squares method. The main technical challenge is to show that a small number of randomly chosen monomials are enough to construct a degree-3 polynomial with precisely planted orthogonal global optima over the sphere and that this fact can be certified within the sum-of-squares proof system.",
        "bibtex": "@InProceedings{pmlr-v65-potechin17a,\n  title = \t {Exact tensor completion with sum-of-squares},\n  author = \t {Potechin, Aaron and Steurer, David},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1619--1673},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/potechin17a/potechin17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/potechin17a.html},\n  abstract = \t {We obtain the first polynomial-time algorithm for exact tensor completion that improves over the bound implied by reduction to matrix completion. The algorithm recovers an unknown 3-tensor with $r$ incoherent, orthogonal components in $\\mathbb R^n$ from $r\u22c5\\tilde O(n^1.5)$ randomly observed entries of the tensor. This bound improves over the previous best one of $r\u22c5\\tilde O(n^2)$ by reduction to exact matrix completion. Our bound also matches the best known results for the easier problem of approximate tensor completion (Barak & Moitra, 2015). Our algorithm and analysis extends seminal results for exact matrix completion (Candes & Recht, 2009) to the tensor setting via the sum-of-squares method. The main technical challenge is to show that a small number of randomly chosen monomials are enough to construct a degree-3 polynomial with precisely planted orthogonal global optima over the sphere and that this fact can be certified within the sum-of-squares proof system.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/potechin17a/potechin17a.pdf",
        "supp": "",
        "pdf_size": 476350,
        "gs_citation": 84,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3697436745390882759&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Institute for Advanced Study, Princeton; Cornell University + Institute for Advanced Study, Princeton",
        "aff_domain": "math.ias.edu;cs.cornell.edu",
        "email": "math.ias.edu;cs.cornell.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0",
        "aff_unique_norm": "Institute for Advanced Study;Cornell University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://ias.edu;https://www.cornell.edu",
        "aff_unique_abbr": "IAS;Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Princeton;",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "93699a0cf3",
        "title": "Fast Rates for Empirical Risk Minimization of Strict Saddle Problems",
        "site": "https://proceedings.mlr.press/v65/gonen17a.html",
        "author": "Alon Gonen; Shai Shalev-Shwartz",
        "abstract": "We derive bounds on the sample complexity of empirical risk minimization (ERM) in the context of minimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniques may pave the way for statistical analyses of additional strict saddle problems.",
        "bibtex": "@InProceedings{pmlr-v65-gonen17a,\n  title = \t {Fast Rates for Empirical Risk Minimization of Strict Saddle Problems},\n  author = \t {Gonen, Alon and Shalev-Shwartz, Shai},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1043--1063},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/gonen17a/gonen17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/gonen17a.html},\n  abstract = \t {We derive bounds on the sample complexity of empirical risk minimization (ERM) in the context of minimizing non-convex risks that admit the strict saddle property. Recent progress in non-convex optimization has yielded efficient algorithms for minimizing such functions. Our results imply that these efficient algorithms are statistically stable and also generalize well. In particular, we derive fast rates which resemble the bounds that are often attained in the strongly convex setting. We specify our bounds to Principal Component Analysis and Independent Component Analysis. Our results and techniques may pave the way for statistical analyses of additional strict saddle problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/gonen17a/gonen17a.pdf",
        "supp": "",
        "pdf_size": 284590,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3514350042696553113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel; School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel",
        "aff_domain": "CS.HUJI.AC.IL;CS.HUJI.AC.IL",
        "email": "CS.HUJI.AC.IL;CS.HUJI.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hebrew University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.huji.ac.il",
        "aff_unique_abbr": "HUJI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Jerusalem",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "326e5bf44a",
        "title": "Fast and robust tensor decomposition with applications to dictionary learning",
        "site": "https://proceedings.mlr.press/v65/schramm17a.html",
        "author": "Tselil Schramm; David Steurer",
        "abstract": "We develop fast spectral algorithms for tensor decomposition that match the robustness guarantees of the best known polynomial-time algorithms for this problem based on the sum-of-squares (SOS) semidefinite programming hierarchy. Our algorithms can decompose a 4-tensor with $n$-dimensional orthonormal components in the presence of error with constant spectral norm (when viewed as an $n^2$-by-$n^2$ matrix).  The running time is $n^5$ which is close to linear in the input size $n^4$. We also obtain algorithms with similar running time to learn sparsely-used orthogonal dictionaries even when feature representations have constant relative sparsity and non-independent coordinates. The only previous polynomial-time algorithms to solve these problem are based on solving large semidefinite programs.  In contrast, our algorithms are easy to implement directly and are based on spectral projections and tensor-mode rearrangements. Or work is inspired by recent of Hopkins, Schramm, Shi, and Steurer (STOC\u201916) that shows how fast spectral algorithms can achieve the guarantees of SOS for average-case problems.  In this work, we introduce general techniques to capture the guarantees of SOS for worst-case problems.",
        "bibtex": "@InProceedings{pmlr-v65-schramm17a,\n  title = \t {Fast and robust tensor decomposition with applications to dictionary learning},\n  author = \t {Schramm, Tselil and Steurer, David},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1760--1793},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/schramm17a/schramm17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/schramm17a.html},\n  abstract = \t { We develop fast spectral algorithms for tensor decomposition that match the robustness guarantees of the best known polynomial-time algorithms for this problem based on the sum-of-squares (SOS) semidefinite programming hierarchy. Our algorithms can decompose a 4-tensor with $n$-dimensional orthonormal components in the presence of error with constant spectral norm (when viewed as an $n^2$-by-$n^2$ matrix).  The running time is $n^5$ which is close to linear in the input size $n^4$. We also obtain algorithms with similar running time to learn sparsely-used orthogonal dictionaries even when feature representations have constant relative sparsity and non-independent coordinates. The only previous polynomial-time algorithms to solve these problem are based on solving large semidefinite programs.  In contrast, our algorithms are easy to implement directly and are based on spectral projections and tensor-mode rearrangements. Or work is inspired by recent of Hopkins, Schramm, Shi, and Steurer (STOC\u201916) that shows how fast spectral algorithms can achieve the guarantees of SOS for average-case problems.  In this work, we introduce general techniques to capture the guarantees of SOS for worst-case problems. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/schramm17a/schramm17a.pdf",
        "supp": "",
        "pdf_size": 340952,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2059957879699412969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "UC Berkeley; Cornell and IAS",
        "aff_domain": "CS.BERKELEY.EDU;CS.CORNELL.EDU",
        "email": "CS.BERKELEY.EDU;CS.CORNELL.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Berkeley;Cornell University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UC Berkeley;Cornell",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "467b6c1905",
        "title": "Fast rates for online learning in Linearly Solvable Markov Decision Processes",
        "site": "https://proceedings.mlr.press/v65/neu17a.html",
        "author": "Gergely Neu; Vicen\u00e7 G\u00f3mez",
        "abstract": "We study the problem of online learning in a class of Markov decision processes known as \\emphlinearly solvable MDPs. In the stationary version of this problem, a learner interacts with its environment by directly controlling the state transitions, attempting to balance a fixed state-dependent cost and a certain smooth cost penalizing extreme control inputs. In the current paper, we consider an online setting where the state costs may change arbitrarily between consecutive rounds, and the learner only observes the costs at the end of each respective round. We are interested in constructing algorithms for the learner that guarantee small regret against the best stationary control policy chosen in full knowledge of the cost sequence. Our main result is showing that the smoothness of the control cost enables the simple algorithm of \\emphfollowing the leader to achieve a regret of order $\\log^2 T$ after $T$ rounds, vastly improving on the best known regret bound of order $T^3/4$ for this setting.",
        "bibtex": "@InProceedings{pmlr-v65-neu17a,\n  title = \t {Fast rates for online learning in {L}inearly {S}olvable {M}arkov {D}ecision {P}rocesses},\n  author = \t {Neu, Gergely and G\u00f3mez, Vicen\u00e7},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1567--1588},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/neu17a/neu17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/neu17a.html},\n  abstract = \t {We study the problem of online learning in a class of Markov decision processes known as \\emphlinearly solvable MDPs. In the stationary version of this problem, a learner interacts with its environment by directly controlling the state transitions, attempting to balance a fixed state-dependent cost and a certain smooth cost penalizing extreme control inputs. In the current paper, we consider an online setting where the state costs may change arbitrarily between consecutive rounds, and the learner only observes the costs at the end of each respective round. We are interested in constructing algorithms for the learner that guarantee small regret against the best stationary control policy chosen in full knowledge of the cost sequence. Our main result is showing that the smoothness of the control cost enables the simple algorithm of \\emphfollowing the leader to achieve a regret of order $\\log^2 T$ after $T$ rounds, vastly improving on the best known regret bound of order $T^3/4$ for this setting. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/neu17a/neu17a.pdf",
        "supp": "",
        "pdf_size": 312814,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12881061123542469756&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Universitat Pompeu Fabra, Barcelona, Spain; Universitat Pompeu Fabra, Barcelona, Spain",
        "aff_domain": "GMAIL.COM;UPF.EDU",
        "email": "GMAIL.COM;UPF.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universitat Pompeu Fabra",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upf.edu/",
        "aff_unique_abbr": "UPF",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "90d6ea40eb",
        "title": "Fundamental limits of symmetric low-rank matrix estimation",
        "site": "https://proceedings.mlr.press/v65/lelarge17a.html",
        "author": "Marc Lelarge; L\u00e9o Miolane",
        "abstract": "We consider the high-dimensional inference problem where the signal is a low-rank symmetric matrix which is corrupted by an additive Gaussian noise. Given a probabilistic model for the low-rank matrix, we compute the limit in the large dimension setting for the mutual information between the signal and the observations, as well as the matrix minimum mean square error, while the rank of the signal remains constant. We unify and generalize a number of recent works on PCA, sparse PCA, submatrix localization or community detection by computing the information-theoretic limits for these problems in the high noise regime. This allows to locate precisely the information-theoretic thresholds for the above mentioned problems.",
        "bibtex": "@InProceedings{pmlr-v65-lelarge17a,\n  title = \t {Fundamental limits of symmetric low-rank matrix estimation},\n  author = \t {Lelarge, Marc and Miolane, L\u00e9o},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1297--1301},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/lelarge17a/lelarge17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/lelarge17a.html},\n  abstract = \t {We consider the high-dimensional inference problem where the signal is a low-rank symmetric matrix which is corrupted by an additive Gaussian noise. Given a probabilistic model for the low-rank matrix, we compute the limit in the large dimension setting for the mutual information between the signal and the observations, as well as the matrix minimum mean square error, while the rank of the signal remains constant. We unify and generalize a number of recent works on PCA, sparse PCA, submatrix localization or community detection by computing the information-theoretic limits for these problems in the high noise regime. This allows to locate precisely the information-theoretic thresholds for the above mentioned problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/lelarge17a/lelarge17a.pdf",
        "supp": "",
        "pdf_size": 190758,
        "gs_citation": 241,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1072613666598302403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Safran Tech, Magny-Les-Hameaux, France + D\u00b4epartement d\u2019informatique, \u00b4Ecole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France + INRIA; D\u00b4epartement d\u2019informatique, \u00b4Ecole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France + INRIA",
        "aff_domain": "ENS.FR;INRIA.FR",
        "email": "ENS.FR;INRIA.FR",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;1+2",
        "aff_unique_norm": "Safran Tech;Ecole Normale Sup\u00e9rieure;INRIA",
        "aff_unique_dep": ";D\u00b4epartement d\u2019informatique;",
        "aff_unique_url": "https://www.safrantech.com;https://www.ens.fr;https://www.inria.fr",
        "aff_unique_abbr": ";ENS;INRIA",
        "aff_campus_unique_index": "0+1;1",
        "aff_campus_unique": "Magny-Les-Hameaux;Paris;",
        "aff_country_unique_index": "0+0+0;0+0",
        "aff_country_unique": "France"
    },
    {
        "id": "6c328b2618",
        "title": "Further and stronger analogy between sampling and optimization: Langevin Monte Carlo and gradient descent",
        "site": "https://proceedings.mlr.press/v65/dalalyan17a.html",
        "author": "Arnak Dalalyan",
        "abstract": "In this paper, we revisit the recently established theoretical guarantees for the convergence of the Langevin Monte Carlo algorithm of sampling from a smooth and (strongly) log-concave density. We improve the existing results when the convergence is measured in the Wasserstein distance and provide further insights on the very tight relations between, on the one hand, the Langevin Monte Carlo for sampling and, on the other hand, the gradient descent for optimization. Finally, we also establish guarantees for the convergence of a version of the Langevin Monte Carlo algorithm that is based on noisy evaluations of the gradient.",
        "bibtex": "@InProceedings{pmlr-v65-dalalyan17a,\n  title = \t {Further and stronger analogy between sampling and optimization: Langevin Monte Carlo and gradient descent},\n  author = \t {Dalalyan, Arnak},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {678--689},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/dalalyan17a/dalalyan17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/dalalyan17a.html},\n  abstract = \t {In this paper, we revisit the recently established theoretical guarantees for the convergence of the Langevin Monte Carlo algorithm of sampling from a smooth and (strongly) log-concave density. We improve the existing results when the convergence is measured in the Wasserstein distance and provide further insights on the very tight relations between, on the one hand, the Langevin Monte Carlo for sampling and, on the other hand, the gradient descent for optimization. Finally, we also establish guarantees for the convergence of a version of the Langevin Monte Carlo algorithm that is based on noisy evaluations of the gradient.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/dalalyan17a/dalalyan17a.pdf",
        "supp": "",
        "pdf_size": 341898,
        "gs_citation": 218,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3255237727801777878&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "ENSAE/CREST/Universit \u00b4e Paris Saclay",
        "aff_domain": "ensae.fr",
        "email": "ensae.fr",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "ENSAE",
        "aff_unique_dep": "CREST",
        "aff_unique_url": "https://www.ensae.fr",
        "aff_unique_abbr": "ENSAE",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "9dab5f7f64",
        "title": "Generalization for Adaptively-chosen Estimators via Stable Median",
        "site": "https://proceedings.mlr.press/v65/feldman17a.html",
        "author": "Vitaly Feldman; Thomas Steinke",
        "abstract": "Datasets are often reused to perform multiple statistical analyses in an adaptive way, in which each analysis may depend on the outcomes of previous analyses on the same dataset. Standard statistical guarantees do not account for these dependencies and little is known about how to provably avoid overfitting and false discovery in the adaptive setting. We consider a natural formalization of this problem in which the goal is to design an algorithm that, given a limited number of i.i.d.\u00a0samples from an unknown distribution, can answer adaptively-chosen queries about that distribution. We present an algorithm that estimates the expectations of $k$ arbitrary adaptively-chosen real-valued estimators using a number of samples that scales as $\\sqrt{k}$. The answers given by our algorithm are essentially as accurate as if fresh samples were used to evaluate each estimator. In contrast, prior work yields error guarantees that scale with the worst-case sensitivity of each estimator. We also give a version of our algorithm that can be used to verify answers to such queries where the sample complexity depends logarithmically on the number of queries $k$ (as in the reusable holdout technique). Our algorithm is based on a simple approximate median algorithm that satisfies the strong stability guarantees of differential privacy. Our techniques provide a new approach for analyzing the generalization guarantees of differentially private algorithms.",
        "bibtex": "@InProceedings{pmlr-v65-feldman17a,\n  title = \t {Generalization for Adaptively-chosen Estimators via Stable Median},\n  author = \t {Feldman, Vitaly and Steinke, Thomas},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {728--757},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/feldman17a/feldman17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/feldman17a.html},\n  abstract = \t {Datasets are often reused to perform multiple statistical analyses in an adaptive way, in which each analysis may depend on the outcomes of previous analyses on the same dataset. Standard statistical guarantees do not account for these dependencies and little is known about how to provably avoid overfitting and false discovery in the adaptive setting. We consider a natural formalization of this problem in which the goal is to design an algorithm that, given a limited number of i.i.d.\u00a0samples from an unknown distribution, can answer adaptively-chosen queries about that distribution. We present an algorithm that estimates the expectations of $k$ arbitrary adaptively-chosen real-valued estimators using a number of samples that scales as $\\sqrt{k}$. The answers given by our algorithm are essentially as accurate as if fresh samples were used to evaluate each estimator. In contrast, prior work yields error guarantees that scale with the worst-case sensitivity of each estimator. We also give a version of our algorithm that can be used to verify answers to such queries where the sample complexity depends logarithmically on the number of queries $k$ (as in the reusable holdout technique). Our algorithm is based on a simple approximate median algorithm that satisfies the strong stability guarantees of differential privacy. Our techniques provide a new approach for analyzing the generalization guarantees of differentially private algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/feldman17a/feldman17a.pdf",
        "supp": "",
        "pdf_size": 445424,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10880501869578900385&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "IBM Research \u2013 Almaden; IBM Research \u2013 Almaden",
        "aff_domain": "post.harvard.edu;thomas-steinke.net",
        "email": "post.harvard.edu;thomas-steinke.net",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "IBM",
        "aff_unique_dep": "IBM Research",
        "aff_unique_url": "https://www.ibm.com/research",
        "aff_unique_abbr": "IBM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Almaden",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "aa826a225d",
        "title": "Greed Is Good: Near-Optimal Submodular Maximization via Greedy Optimization",
        "site": "https://proceedings.mlr.press/v65/feldman17b.html",
        "author": "Moran Feldman; Christopher Harshaw; Amin Karbasi",
        "abstract": "It is known that greedy methods perform well for maximizing \\textitmonotone submodular functions. At the same time, such methods perform poorly in the face of non-monotonicity.  In this paper, we show\u2014arguably, surprisingly\u2014that invoking the classical greedy algorithm $O(\\sqrt{k})$-times leads to the (currently) fastest deterministic algorithm, called RepeatedGreedy, for maximizing a general submodular function subject to $k$-independent system constraints. RepeatedGreedy achieves $(1 + O(1/\\sqrt{k}))k$ approximation using $O(nr\\sqrt{k})$ function evaluations (here, $n$ and $r$ denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only \\textitonce and obtain the (currently) fastest randomized algorithm, called SampleGreedy, for maximizing a submodular function subject to $k$-extendible system constraints (a subclass of $k$-independent system constrains). SampleGreedy achieves $(k + 3)$-approximation with only $O(nr/k)$ function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than $ k + 1/2 - \\varepsilon$. To further support our theoretical results, we compare the performance of RepeatedGreedy and SampleGreedy with prior art in a concrete application (movie recommendation). We consistently observe that while SampleGreedy achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.",
        "bibtex": "@InProceedings{pmlr-v65-feldman17b,\n  title = \t {Greed Is Good: Near-Optimal Submodular Maximization via Greedy Optimization},\n  author = \t {Feldman, Moran and Harshaw, Christopher and Karbasi, Amin},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {758--784},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/feldman17b/feldman17b.pdf},\n  url = \t {https://proceedings.mlr.press/v65/feldman17b.html},\n  abstract = \t {It is known that greedy methods perform well for maximizing \\textitmonotone submodular functions. At the same time, such methods perform poorly in the face of non-monotonicity.  In this paper, we show\u2014arguably, surprisingly\u2014that invoking the classical greedy algorithm $O(\\sqrt{k})$-times leads to the (currently) fastest deterministic algorithm, called RepeatedGreedy, for maximizing a general submodular function subject to $k$-independent system constraints. RepeatedGreedy achieves $(1 + O(1/\\sqrt{k}))k$ approximation using $O(nr\\sqrt{k})$ function evaluations (here, $n$ and $r$ denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only \\textitonce and obtain the (currently) fastest randomized algorithm, called SampleGreedy, for maximizing a submodular function subject to $k$-extendible system constraints (a subclass of $k$-independent system constrains). SampleGreedy achieves $(k + 3)$-approximation with only $O(nr/k)$ function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than $ k + 1/2 - \\varepsilon$. To further support our theoretical results, we compare the performance of RepeatedGreedy and SampleGreedy with prior art in a concrete application (movie recommendation). We consistently observe that while SampleGreedy achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/feldman17b/feldman17b.pdf",
        "supp": "",
        "pdf_size": 2272505,
        "gs_citation": 99,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2762311189176434931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics and Computer Science, The Open University of Israel; Department of Computer Science, Yale Institute for Network Science, Yale University; Department of Electrical Engineering and Computer Science, Yale Institute for Network Science, Yale University",
        "aff_domain": "OPENU.AC.IL;YALE.EDU;YALE.EDU",
        "email": "OPENU.AC.IL;YALE.EDU;YALE.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Open University of Israel;Yale University",
        "aff_unique_dep": "Department of Mathematics and Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.openu.ac.il;https://www.yale.edu",
        "aff_unique_abbr": "OUI;Yale",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";New Haven",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "263c0daf27",
        "title": "High Dimensional Regression with Binary Coefficients. Estimating Squared Error and a Phase Transtition",
        "site": "https://proceedings.mlr.press/v65/david17a.html",
        "author": "Gamarnik David; Zadik Ilias",
        "abstract": "We consider a sparse linear regression model $Y=X\u03b2^*+W$ where $X$ is $n\\times p$ matrix Gaussian i.i.d.  entries, $W$ is $n\\times 1$ noise vector with i.i.d. mean zero Gaussian entries and standard deviation $\u03c3$, and $\u03b2^*$ is $p\\times 1$ binary vector with support size (sparsity)  $k$. Using a  novel conditional second moment method  we obtain a tight up to a multiplicative constant approximation of the optimal squared error $\\min_\u03b2\\|Y-X\u03b2\\|_2$, where the minimization is over all $k$-sparse binary vectors $\u03b2$. The approximation reveals interesting structural properties of the underlying regression problem. In particular, \\beginenumerate \\item [(a)] We establish that $n^*=2k\\log p/\\log (2k/\u03c3^2+1)$ is a phase transition point with the following \u201call-or-nothing\u201d property. When $n$ exceeds $n^*$,  $(2k)^-1\\|\\beta_2-\u03b2^*\\|_0\u22480$, and when $n$ is  below $n^*$, $(2k)^-1\\|\\beta_2-\u03b2^*\\|_0\u22481$, where $\\beta_2$ is the optimal solution achieving the smallest squared error. As a corollary  $n^*$ is the asymptotic threshold for recovering $\u03b2^*$  information theoretically. Note that $n^*$ is asymptotically below the threshold  $n_\\text{LASSO}/CS=(2k+\u03c3^2)\\log p$, above which the LASSO and Compressive Sensing methods are able to recover $\u03b2^*$. \\item [(b)] We compute the squared error for an intermediate problem $\\min_\u03b2\\|Y-X\u03b2\\|_2$ where the minimization is restricted to vectors $\u03b2$ with $\\|\u03b2-\u03b2^*\\|_0=2k \u03b6$, for some fixed ratio $\u03b6\u2208[0,1]$. We show that a lower bound part $\u0393(\u03b6)$ of the estimate, which essentially corresponds to the estimate based on the first moment method, undergoes a phase transition  at three different thresholds, namely $n_\\text{inf},1=\u03c3^2\\log p$, which is information theoretic bound for recovering $\u03b2^*$ when $k=1$ and $\u03c3$ is large, then at $n^*$ and finally at $n_\\text{LASSO}/CS$. \\item [(c)] We establish a certain Overlap Gap Property (OGP) on the space of all $k$-sparse binary vectors $\u03b2$ when $n\\le ck\\log p$ for sufficiently small constant $c$. By drawing a connection with a similar OGP exhibited by many randomly generated constraint satisfaction problems and statistical physics models, we conjecture that OGP is the source of algorithmic hardness of solving the minimization problem $\\min_\u03b2\\|Y-X\u03b2\\|_2$ in the regime $n",
        "bibtex": "@InProceedings{pmlr-v65-david17a,\n  title = \t {High Dimensional Regression with Binary Coefficients. Estimating Squared Error and a Phase Transtition},\n  author = \t {David, Gamarnik and Ilias, Zadik},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {948--953},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/david17a/david17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/david17a.html},\n  abstract = \t {We consider a sparse linear regression model $Y=X\u03b2^*+W$ where $X$ is $n\\times p$ matrix Gaussian i.i.d.  entries, $W$ is $n\\times 1$ noise vector with i.i.d. mean zero Gaussian entries and standard deviation $\u03c3$, and $\u03b2^*$ is $p\\times 1$ binary vector with support size (sparsity)  $k$. Using a  novel conditional second moment method  we obtain a tight up to a multiplicative constant approximation of the optimal squared error $\\min_\u03b2\\|Y-X\u03b2\\|_2$, where the minimization is over all $k$-sparse binary vectors $\u03b2$. The approximation reveals interesting structural properties of the underlying regression problem. In particular, \\beginenumerate \\item [(a)] We establish that $n^*=2k\\log p/\\log (2k/\u03c3^2+1)$ is a phase transition point with the following \u201call-or-nothing\u201d property. When $n$ exceeds $n^*$,  $(2k)^-1\\|\\beta_2-\u03b2^*\\|_0\u22480$, and when $n$ is  below $n^*$, $(2k)^-1\\|\\beta_2-\u03b2^*\\|_0\u22481$, where $\\beta_2$ is the optimal solution achieving the smallest squared error. As a corollary  $n^*$ is the asymptotic threshold for recovering $\u03b2^*$  information theoretically. Note that $n^*$ is asymptotically below the threshold  $n_\\text{LASSO}/CS=(2k+\u03c3^2)\\log p$, above which the LASSO and Compressive Sensing methods are able to recover $\u03b2^*$. \\item [(b)] We compute the squared error for an intermediate problem $\\min_\u03b2\\|Y-X\u03b2\\|_2$ where the minimization is restricted to vectors $\u03b2$ with $\\|\u03b2-\u03b2^*\\|_0=2k \u03b6$, for some fixed ratio $\u03b6\u2208[0,1]$. We show that a lower bound part $\u0393(\u03b6)$ of the estimate, which essentially corresponds to the estimate based on the first moment method, undergoes a phase transition  at three different thresholds, namely $n_\\text{inf},1=\u03c3^2\\log p$, which is information theoretic bound for recovering $\u03b2^*$ when $k=1$ and $\u03c3$ is large, then at $n^*$ and finally at $n_\\text{LASSO}/CS$. \\item [(c)] We establish a certain Overlap Gap Property (OGP) on the space of all $k$-sparse binary vectors $\u03b2$ when $n\\le ck\\log p$ for sufficiently small constant $c$. By drawing a connection with a similar OGP exhibited by many randomly generated constraint satisfaction problems and statistical physics models, we conjecture that OGP is the source of algorithmic hardness of solving the minimization problem $\\min_\u03b2\\|Y-X\u03b2\\|_2$ in the regime $n",
        "pdf": "http://proceedings.mlr.press/v65/david17a/david17a.pdf",
        "supp": "",
        "pdf_size": 246848,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16016671545376356725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "https://arxiv.org/abs/1701.04455",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d6abed9a2e",
        "title": "Homotopy Analysis for Tensor PCA",
        "site": "https://proceedings.mlr.press/v65/anandkumar17a.html",
        "author": "Anima Anandkumar; Yuan Deng; Rong Ge; Hossein Mobahi",
        "abstract": "Developing efficient and guaranteed nonconvex algorithms has been an important challenge in modern machine learning. Algorithms with good empirical performance such as stochastic gradient descent often lack theoretical guarantees. In this paper, we analyze the class of homotopy or continuation methods for global optimization of nonconvex functions. These  methods start from an objective function that is efficient to optimize (e.g. convex), and progressively modify it to obtain the required objective, and the solutions are passed along the homotopy path. For the challenging problem of tensor PCA, we prove global convergence of the homotopy method  in the \u201chigh noise\u201d regime.   The signal-to-noise requirement for our algorithm is tight in the sense that it matches the recovery guarantee for the \\em best degree-$4$ sum-of-squares algorithm. In addition, we prove a phase transition along the homotopy path for  tensor PCA. This allows us to simplify the homotopy method to a local search algorithm, viz., tensor power iterations, with a specific initialization and a noise injection procedure, while retaining the theoretical guarantees.",
        "bibtex": "@InProceedings{pmlr-v65-anandkumar17a,\n  title = \t {Homotopy Analysis for Tensor PCA},\n  author = \t {Anandkumar, Anima and Deng, Yuan and Ge, Rong and Mobahi, Hossein},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {79--104},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/anandkumar17a/anandkumar17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/anandkumar17a.html},\n  abstract = \t {Developing efficient and guaranteed nonconvex algorithms has been an important challenge in modern machine learning. Algorithms with good empirical performance such as stochastic gradient descent often lack theoretical guarantees. In this paper, we analyze the class of homotopy or continuation methods for global optimization of nonconvex functions. These  methods start from an objective function that is efficient to optimize (e.g. convex), and progressively modify it to obtain the required objective, and the solutions are passed along the homotopy path. For the challenging problem of tensor PCA, we prove global convergence of the homotopy method  in the \u201chigh noise\u201d regime.   The signal-to-noise requirement for our algorithm is tight in the sense that it matches the recovery guarantee for the \\em best degree-$4$ sum-of-squares algorithm. In addition, we prove a phase transition along the homotopy path for  tensor PCA. This allows us to simplify the homotopy method to a local search algorithm, viz., tensor power iterations, with a specific initialization and a noise injection procedure, while retaining the theoretical guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/anandkumar17a/anandkumar17a.pdf",
        "supp": "",
        "pdf_size": 1328215,
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13142626973904501333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "University of California, Irvine; Duke University; Duke University; Google Research",
        "aff_domain": "UCI.EDU;CS.DUKE.EDU;CS.DUKE.EDU;CSAIL.MIT.EDU",
        "email": "UCI.EDU;CS.DUKE.EDU;CS.DUKE.EDU;CSAIL.MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "University of California, Irvine;Duke University;Google",
        "aff_unique_dep": ";;Google Research",
        "aff_unique_url": "https://www.uci.edu;https://www.duke.edu;https://research.google",
        "aff_unique_abbr": "UCI;Duke;Google Research",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Irvine;;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ff655df6e7",
        "title": "Ignoring Is a Bliss:  Learning with Large Noise Through Reweighting-Minimization",
        "site": "https://proceedings.mlr.press/v65/vainsencher17a.html",
        "author": "Daniel Vainsencher; Shie Mannor; Huan Xu",
        "abstract": "We consider learning in the presence of  arbitrary noise that can overwhelm the signal in terms of magnitude on a fraction of data points observed (aka outliers). Standard approaches based on minimizing empirical loss can fail miserably and lead to arbitrary bad solutions in this setting. We propose an approach that iterates between finding a solution with minimal empirical loss and re-weighting the data, reinforcing data points where the previous solution works well.  We show that our approach can handle arbitrarily large noise, is robust as having a non-trivial breakdown point, and converges linearly under certain conditions. The intuitive idea of our approach is to automatically exclude \u201cdifficult\u201d data points from model fitting. More importantly (and perhaps surprisingly), we validate this intuition by establishing guarantees for generalization and iteration complexity that \\em essentially ignore the presence of outliers",
        "bibtex": "@InProceedings{pmlr-v65-vainsencher17a,\n  title = \t {Ignoring Is a Bliss:  Learning with Large Noise Through Reweighting-Minimization},\n  author = \t {Vainsencher, Daniel and Mannor, Shie and Xu, Huan},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1849--1881},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/vainsencher17a/vainsencher17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/vainsencher17a.html},\n  abstract = \t { We consider learning in the presence of  arbitrary noise that can overwhelm the signal in terms of magnitude on a fraction of data points observed (aka outliers). Standard approaches based on minimizing empirical loss can fail miserably and lead to arbitrary bad solutions in this setting. We propose an approach that iterates between finding a solution with minimal empirical loss and re-weighting the data, reinforcing data points where the previous solution works well.  We show that our approach can handle arbitrarily large noise, is robust as having a non-trivial breakdown point, and converges linearly under certain conditions. The intuitive idea of our approach is to automatically exclude \u201cdifficult\u201d data points from model fitting. More importantly (and perhaps surprisingly), we validate this intuition by establishing guarantees for generalization and iteration complexity that \\em essentially ignore the presence of outliers }\n}",
        "pdf": "http://proceedings.mlr.press/v65/vainsencher17a/vainsencher17a.pdf",
        "supp": "",
        "pdf_size": 597843,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3927224079371141198&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Voleon; Faculty of Electrical Engineering, Technion Israel Institute of Technology; School of Industrial and Systems Engineering, Georgia Institute of Technology",
        "aff_domain": "GMAIL.COM;EE.TECHNION.AC.IL;ISYE.GATECH.EDU",
        "email": "GMAIL.COM;EE.TECHNION.AC.IL;ISYE.GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Voleon;Technion Israel Institute of Technology;Georgia Institute of Technology",
        "aff_unique_dep": ";Faculty of Electrical Engineering;School of Industrial and Systems Engineering",
        "aff_unique_url": ";https://www.technion.ac.il;https://www.gatech.edu",
        "aff_unique_abbr": ";Technion;Georgia Tech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Atlanta",
        "aff_country_unique_index": "1;2",
        "aff_country_unique": ";Israel;United States"
    },
    {
        "id": "c931a8f1d8",
        "title": "Inapproximability of VC Dimension and Littlestone\u2019s Dimension",
        "site": "https://proceedings.mlr.press/v65/manurangsi17a.html",
        "author": "Pasin Manurangsi; Aviad Rubinstein",
        "abstract": "We study the complexity of computing the VC Dimension and Littlestone\u2019s Dimension. Given an explicit description of a finite universe and a concept class (a binary matrix whose $(x,C)$-th entry is $1$ iff element $x$ belongs to concept $C$), both can be computed exactly in quasi-polynomial time ($n^O(\\log n)$). Assuming the randomized Exponential Time Hypothesis (ETH), we prove nearly matching lower bounds on the running time, that hold even for \\em approximation algorithms.",
        "bibtex": "@InProceedings{pmlr-v65-manurangsi17a,\n  title = \t {Inapproximability of VC Dimension and Littlestone\u2019s Dimension},\n  author = \t {Manurangsi, Pasin and Rubinstein, Aviad},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1432--1460},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/manurangsi17a/manurangsi17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/manurangsi17a.html},\n  abstract = \t {We study the complexity of computing the VC Dimension and Littlestone\u2019s Dimension. Given an explicit description of a finite universe and a concept class (a binary matrix whose $(x,C)$-th entry is $1$ iff element $x$ belongs to concept $C$), both can be computed exactly in quasi-polynomial time ($n^O(\\log n)$). Assuming the randomized Exponential Time Hypothesis (ETH), we prove nearly matching lower bounds on the running time, that hold even for \\em approximation algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/manurangsi17a/manurangsi17a.pdf",
        "supp": "",
        "pdf_size": 661123,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16330240009593452656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "20ebc2a4aa",
        "title": "Learning Disjunctions of Predicates",
        "site": "https://proceedings.mlr.press/v65/bshouty17a.html",
        "author": "Nader H. Bshouty; Dana Drachsler-Cohen; Martin Vechev; Eran Yahav",
        "abstract": "Let $\\mathcal F$ be a set of boolean functions. We give an algorithm for learning $\\mathcal F_\u2228:={\\vee_f\u2208Sf | S\u2286\\mathcal {F}}$ from membership queries. Our algorithm asks at most $|\\mathcal {F}|\u22c5\\rm OPT(\\mathcal {F}_\u2228)$ membership queries where $\\rm OPT(\\mathcal{F}_\u2228)$ is the minimum worst case number of membership queries for learning $\\mathcal{F}_\u2228$. When $\\mathcal{F}$ is a set of halfspaces over a constant dimension space or a set of variable inequalities, our algorithm runs in polynomial time. The problem we address has a practical importance in the field of program synthesis, where the goal is to synthesize a program meeting some requirements. Program synthesis has become popular especially in settings aimed to help end users. In such settings, the requirements are not provided upfront and the synthesizer can only learn them by posing membership queries to the end user. Our work completes such synthesizers with the ability to learn the exact requirements while bounding the number of membership queries.",
        "bibtex": "@InProceedings{pmlr-v65-bshouty17a,\n  title = \t {Learning Disjunctions of Predicates},\n  author = \t {Bshouty, Nader H. and Drachsler-Cohen, Dana and Vechev, Martin and Yahav, Eran},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {346--369},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/bshouty17a/bshouty17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/bshouty17a.html},\n  abstract = \t {Let $\\mathcal F$ be a set of boolean functions. We give an algorithm for learning $\\mathcal F_\u2228:={\\vee_f\u2208Sf | S\u2286\\mathcal {F}}$ from membership queries. Our algorithm asks at most $|\\mathcal {F}|\u22c5\\rm OPT(\\mathcal {F}_\u2228)$ membership queries where $\\rm OPT(\\mathcal{F}_\u2228)$ is the minimum worst case number of membership queries for learning $\\mathcal{F}_\u2228$. When $\\mathcal{F}$ is a set of halfspaces over a constant dimension space or a set of variable inequalities, our algorithm runs in polynomial time. The problem we address has a practical importance in the field of program synthesis, where the goal is to synthesize a program meeting some requirements. Program synthesis has become popular especially in settings aimed to help end users. In such settings, the requirements are not provided upfront and the synthesizer can only learn them by posing membership queries to the end user. Our work completes such synthesizers with the ability to learn the exact requirements while bounding the number of membership queries. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/bshouty17a/bshouty17a.pdf",
        "supp": "",
        "pdf_size": 901337,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6040888362573889718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Technion; Technion; ETH Zurich; Technion",
        "aff_domain": "CS.TECHNION.AC.IL;CS.TECHNION.AC.IL;INF.ETHZ.CH;CS.TECHNION.AC.IL",
        "email": "CS.TECHNION.AC.IL;CS.TECHNION.AC.IL;INF.ETHZ.CH;CS.TECHNION.AC.IL",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology;ETH Zurich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.ethz.ch",
        "aff_unique_abbr": "Technion;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Israel;Switzerland"
    },
    {
        "id": "6e6bc9fa24",
        "title": "Learning Multivariate Log-concave Distributions",
        "site": "https://proceedings.mlr.press/v65/diakonikolas17a.html",
        "author": "Ilias Diakonikolas; Daniel M. Kane; Alistair Stewart",
        "abstract": "We study the problem of estimating multivariate log-concave probability density functions. We prove the first sample complexity upper bound for learning log-concave densities on $\\mathbb{R}^d$, for all $d \u22651$. Prior to our work, no upper bound on the sample complexity of this learning problem was known for the case of $d>3$. In more detail, we give an estimator that, for any $d \\ge 1$ and $\u03b5>0$, draws $\\tilde{O}_d \\left( (1/\u03b5)^(d+5)/2 \\right)$ samples from an unknown target log-concave density on $R^d$, and outputs a hypothesis that (with high probability) is $\u03b5$-close to the target, in total variation distance. Our upper bound on the sample complexity comes close to the known lower bound of $\\Omega_d \\left( (1/\u03b5)^(d+1)/2 \\right)$ for this problem.",
        "bibtex": "@InProceedings{pmlr-v65-diakonikolas17a,\n  title = \t {Learning Multivariate Log-concave Distributions},\n  author = \t {Diakonikolas, Ilias and Kane, Daniel M. and Stewart, Alistair},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {711--727},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/diakonikolas17a/diakonikolas17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/diakonikolas17a.html},\n  abstract = \t {We study the problem of estimating multivariate log-concave probability density functions. We prove the first sample complexity upper bound for learning log-concave densities on $\\mathbb{R}^d$, for all $d \u22651$. Prior to our work, no upper bound on the sample complexity of this learning problem was known for the case of $d>3$. In more detail, we give an estimator that, for any $d \\ge 1$ and $\u03b5>0$, draws $\\tilde{O}_d \\left( (1/\u03b5)^(d+5)/2 \\right)$ samples from an unknown target log-concave density on $R^d$, and outputs a hypothesis that (with high probability) is $\u03b5$-close to the target, in total variation distance. Our upper bound on the sample complexity comes close to the known lower bound of $\\Omega_d \\left( (1/\u03b5)^(d+1)/2 \\right)$ for this problem. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/diakonikolas17a/diakonikolas17a.pdf",
        "supp": "",
        "pdf_size": 316319,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7261007715908924458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Southern California; University of California, San Diego; University of Southern California",
        "aff_domain": "usc.edu;cs.ucsd.edu;gmail.com",
        "email": "usc.edu;cs.ucsd.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;University of California, San Diego",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.usc.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "USC;UCSD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Los Angeles;San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fb85463d33",
        "title": "Learning Non-Discriminatory Predictors",
        "site": "https://proceedings.mlr.press/v65/woodworth17a.html",
        "author": "Blake Woodworth; Suriya Gunasekar; Mesrob I. Ohannessian; Nathan Srebro",
        "abstract": "We consider learning a predictor which is non-discriminatory with respect to a \u201cprotected attribute\u201d according to the notion of \u201cequalized odds\u201d proposed by Hardt et al. (2016).  We study the problem of learning such a non-discriminatory predictor from a finite training set, both statistically and computationally.  We show that a post-hoc correction approach, as suggested by Hardt et al, can be highly suboptimal, present a nearly-optimal statistical procedure, argue that the associated computational problem is intractable, and suggest a second moment relaxation of the non-discrimination definition for which learning is tractable.",
        "bibtex": "@InProceedings{pmlr-v65-woodworth17a,\n  title = \t {Learning Non-Discriminatory Predictors},\n  author = \t {Woodworth, Blake and Gunasekar, Suriya and Ohannessian, Mesrob I. and Srebro, Nathan},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1920--1953},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/woodworth17a/woodworth17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/woodworth17a.html},\n  abstract = \t {We consider learning a predictor which is non-discriminatory with respect to a \u201cprotected attribute\u201d according to the notion of \u201cequalized odds\u201d proposed by Hardt et al. (2016).  We study the problem of learning such a non-discriminatory predictor from a finite training set, both statistically and computationally.  We show that a post-hoc correction approach, as suggested by Hardt et al, can be highly suboptimal, present a nearly-optimal statistical procedure, argue that the associated computational problem is intractable, and suggest a second moment relaxation of the non-discrimination definition for which learning is tractable.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/woodworth17a/woodworth17a.pdf",
        "supp": "",
        "pdf_size": 436895,
        "gs_citation": 474,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11108072644108171110&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Toyota Technological Institute at Chicago; Department of Computer Science, Toyota Technological Institute at Chicago; Department of Computer Science, Toyota Technological Institute at Chicago; Department of Computer Science, Toyota Technological Institute at Chicago",
        "aff_domain": "TTIC.EDU;TTIC.EDU;TTIC.EDU;TTIC.EDU",
        "email": "TTIC.EDU;TTIC.EDU;TTIC.EDU;TTIC.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Toyota Technological Institute at Chicago",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tti-chicago.org",
        "aff_unique_abbr": "TTI Chicago",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "90c3dc42d1",
        "title": "Learning with Limited Rounds of Adaptivity: Coin Tossing, Multi-Armed Bandits, and Ranking from Pairwise Comparisons",
        "site": "https://proceedings.mlr.press/v65/agarwal17c.html",
        "author": "Arpit Agarwal; Shivani Agarwal; Sepehr Assadi; Sanjeev Khanna",
        "abstract": "In many learning settings, active/adaptive querying is possible, but the number of rounds of adaptivity is limited. We study the relationship between query complexity and adaptivity in identifying the $k$ most biased coins among a set of $n$ coins with unknown biases. This problem is a common abstraction of many well-studied problems, including the problem of identifying the $k$ best arms in a stochastic multi-armed bandit, and the problem of top-$k$ ranking from pairwise comparisons. An $r$-round adaptive algorithm for the $k$ most biased coins problem specifies in each round the set of coin tosses to be performed based on the observed outcomes in earlier rounds, and outputs the set of $k$ most biased coins at the end of $r$ rounds. When $r=1$, the algorithm is known as \\em non-adaptive; when $r$ is unbounded, the algorithm is known as \\em fully adaptive. While the power of adaptivity in reducing query complexity is well known, full adaptivity requires repeated interaction with the coin tossing (feedback generation) mechanism, and is highly sequential, since the set of coins to be tossed in each round can only be determined after we have observed the outcomes of the coin tosses from the previous round. In contrast, algorithms with only few rounds of adaptivity require fewer rounds of interaction with the feedback generation mechanism, and offer the benefits of parallelism in algorithmic decision-making. Motivated by these considerations, we consider the question of how much adaptivity is needed to realize the optimal worst case query complexity for identifying the $k$ most biased coins. Given any positive integer $r$, we derive essentially matching upper and lower bounds on the query complexity of $r$-round algorithms. We then show that $\u0398(\\log^*n)$ rounds are both necessary and sufficient for achieving the optimal worst case query complexity for identifying the $k$ most biased coins. In particular, our algorithm achieves the optimal query complexity in at most $\\log^*n$ rounds, which implies that on any realistic input, $5$ parallel rounds of exploration suffice to achieve the optimal worst-case sample complexity. The best known algorithm prior to our work required $\u0398(\\log n)$ rounds to achieve the optimal worst case query complexity even for the special case of $k=1$.",
        "bibtex": "@InProceedings{pmlr-v65-agarwal17c,\n  title = \t {Learning with Limited Rounds of Adaptivity: Coin Tossing, Multi-Armed Bandits, and Ranking from Pairwise Comparisons},\n  author = \t {Agarwal, Arpit and Agarwal, Shivani and Assadi, Sepehr and Khanna, Sanjeev},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {39--75},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/agarwal17c/agarwal17c.pdf},\n  url = \t {https://proceedings.mlr.press/v65/agarwal17c.html},\n  abstract = \t {In many learning settings, active/adaptive querying is possible, but the number of rounds of adaptivity is limited. We study the relationship between query complexity and adaptivity in identifying the $k$ most biased coins among a set of $n$ coins with unknown biases. This problem is a common abstraction of many well-studied problems, including the problem of identifying the $k$ best arms in a stochastic multi-armed bandit, and the problem of top-$k$ ranking from pairwise comparisons. An $r$-round adaptive algorithm for the $k$ most biased coins problem specifies in each round the set of coin tosses to be performed based on the observed outcomes in earlier rounds, and outputs the set of $k$ most biased coins at the end of $r$ rounds. When $r=1$, the algorithm is known as \\em non-adaptive; when $r$ is unbounded, the algorithm is known as \\em fully adaptive. While the power of adaptivity in reducing query complexity is well known, full adaptivity requires repeated interaction with the coin tossing (feedback generation) mechanism, and is highly sequential, since the set of coins to be tossed in each round can only be determined after we have observed the outcomes of the coin tosses from the previous round. In contrast, algorithms with only few rounds of adaptivity require fewer rounds of interaction with the feedback generation mechanism, and offer the benefits of parallelism in algorithmic decision-making. Motivated by these considerations, we consider the question of how much adaptivity is needed to realize the optimal worst case query complexity for identifying the $k$ most biased coins. Given any positive integer $r$, we derive essentially matching upper and lower bounds on the query complexity of $r$-round algorithms. We then show that $\u0398(\\log^*n)$ rounds are both necessary and sufficient for achieving the optimal worst case query complexity for identifying the $k$ most biased coins. In particular, our algorithm achieves the optimal query complexity in at most $\\log^*n$ rounds, which implies that on any realistic input, $5$ parallel rounds of exploration suffice to achieve the optimal worst-case sample complexity. The best known algorithm prior to our work required $\u0398(\\log n)$ rounds to achieve the optimal worst case query complexity even for the special case of $k=1$. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/agarwal17c/agarwal17c.pdf",
        "supp": "",
        "pdf_size": 508295,
        "gs_citation": 120,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5928487796165736343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer and Information Science, University of Pennsylvania; Department of Computer and Information Science, University of Pennsylvania; Department of Computer and Information Science, University of Pennsylvania; Department of Computer and Information Science, University of Pennsylvania",
        "aff_domain": "seas.upenn.edu;seas.upenn.edu;cis.upenn.edu;cis.upenn.edu",
        "email": "seas.upenn.edu;seas.upenn.edu;cis.upenn.edu;cis.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Computer and Information Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "83b2d716ef",
        "title": "Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems",
        "site": "https://proceedings.mlr.press/v65/balcan17a.html",
        "author": "Maria-Florina Balcan; Vaishnavh Nagarajan; Ellen Vitercik; Colin White",
        "abstract": "Max-cut, clustering, and many other partitioning problems that are of significant importance to machine learning and other scientific fields are NP-hard, a reality that has motivated researchers to develop a wealth of approximation algorithms and heuristics. Although the best algorithm to use typically depends on the specific application domain, a worst-case analysis is often used to compare algorithms. This may be misleading if worst-case instances occur infrequently, and thus there is a demand for optimization methods which return the algorithm configuration best suited for the given application\u2019s typical inputs. Recently, Gupta and Roughgarden introduced the first learning-theoretic framework to rigorously study this problem, using it to analyze classes of greedy heuristics, parameter tuning in gradient descent, and other problems. We study this algorithm configuration problem for clustering, max-cut, and other partitioning problems, such as integer quadratic programming, by designing computationally efficient and sample efficient learning algorithms which receive samples from an application-specific distribution over problem instances and learn a partitioning algorithm with high expected performance. Our algorithms learn over common integer quadratic programming and clustering algorithm families: SDP rounding algorithms and agglomerative clustering algorithms with dynamic programming. For our sample complexity analysis, we provide tight bounds on the pseudodimension of these algorithm classes,  and show that surprisingly, even for classes of algorithms parameterized by a single parameter, the pseudo-dimension is superconstant. In this way, our work both contributes to the foundations of algorithm configuration and pushes the boundaries of learning theory, since the algorithm classes we analyze consist of multi-stage optimization procedures and are significantly more complex than classes typically studied in learning theory.",
        "bibtex": "@InProceedings{pmlr-v65-balcan17a,\n  title = \t {Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems},\n  author = \t {Balcan, Maria-Florina and Nagarajan, Vaishnavh and Vitercik, Ellen and White, Colin},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {213--274},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/balcan17a/balcan17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/balcan17a.html},\n  abstract = \t {Max-cut, clustering, and many other partitioning problems that are of significant importance to machine learning and other scientific fields are NP-hard, a reality that has motivated researchers to develop a wealth of approximation algorithms and heuristics. Although the best algorithm to use typically depends on the specific application domain, a worst-case analysis is often used to compare algorithms. This may be misleading if worst-case instances occur infrequently, and thus there is a demand for optimization methods which return the algorithm configuration best suited for the given application\u2019s typical inputs. Recently, Gupta and Roughgarden introduced the first learning-theoretic framework to rigorously study this problem, using it to analyze classes of greedy heuristics, parameter tuning in gradient descent, and other problems. We study this algorithm configuration problem for clustering, max-cut, and other partitioning problems, such as integer quadratic programming, by designing computationally efficient and sample efficient learning algorithms which receive samples from an application-specific distribution over problem instances and learn a partitioning algorithm with high expected performance. Our algorithms learn over common integer quadratic programming and clustering algorithm families: SDP rounding algorithms and agglomerative clustering algorithms with dynamic programming. For our sample complexity analysis, we provide tight bounds on the pseudodimension of these algorithm classes,  and show that surprisingly, even for classes of algorithms parameterized by a single parameter, the pseudo-dimension is superconstant. In this way, our work both contributes to the foundations of algorithm configuration and pushes the boundaries of learning theory, since the algorithm classes we analyze consist of multi-stage optimization procedures and are significantly more complex than classes typically studied in learning theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/balcan17a/balcan17a.pdf",
        "supp": "",
        "pdf_size": 1108870,
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7267754027764849339&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213",
        "aff_domain": "CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU",
        "email": "CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU;CS.CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6b97da71f7",
        "title": "Lower Bounds on Regret for Noisy Gaussian Process Bandit Optimization",
        "site": "https://proceedings.mlr.press/v65/scarlett17a.html",
        "author": "Jonathan Scarlett; Ilija Bogunovic; Volkan Cevher",
        "abstract": "In this paper, we consider the problem of sequentially optimizing a black-box function $f$ based on noisy samples and bandit feedback.  We assume that $f$ is smooth in the sense of having a bounded norm in some reproducing kernel Hilbert space (RKHS), yielding a commonly-considered non-Bayesian form of Gaussian process bandit optimization.  We provide algorithm-independent lower bounds on the simple regret, measuring the suboptimality of a single point reported after $T$ rounds, and on the cumulative regret, measuring the sum of regrets over the $T$ chosen points. For the isotropic squared-exponential kernel in $d$ dimensions, we find that an average simple regret of $\u03b5$ requires $T = \u03a9\\big(\\frac1\u03b5^2 (\\log\\frac1\u03b5)^d/2\\big)$, and the average cumulative regret is at least $\u03a9\\big( \\sqrt{T}(\\log T)^d \\big)$, thus matching existing upper bounds up to the replacement of $d/2$ by $d+O(1)$ in both cases.  For the Mat\u00e9rn-$\u03bd$ kernel, we give analogous bounds of the form $\u03a9\\big( (\\frac1\u03b5)^2+d/\u03bd\\big)$ and $\u03a9\\big( T^\\frac\u03bd+ d2\u03bd+ d \\big)$, and discuss the resulting gaps to the existing upper bounds.",
        "bibtex": "@InProceedings{pmlr-v65-scarlett17a,\n  title = \t {Lower Bounds on Regret for Noisy {G}aussian Process Bandit Optimization},\n  author = \t {Scarlett, Jonathan and Bogunovic, Ilija and Cevher, Volkan},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1723--1742},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/scarlett17a/scarlett17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/scarlett17a.html},\n  abstract = \t {In this paper, we consider the problem of sequentially optimizing a black-box function $f$ based on noisy samples and bandit feedback.  We assume that $f$ is smooth in the sense of having a bounded norm in some reproducing kernel Hilbert space (RKHS), yielding a commonly-considered non-Bayesian form of Gaussian process bandit optimization.  We provide algorithm-independent lower bounds on the simple regret, measuring the suboptimality of a single point reported after $T$ rounds, and on the cumulative regret, measuring the sum of regrets over the $T$ chosen points. For the isotropic squared-exponential kernel in $d$ dimensions, we find that an average simple regret of $\u03b5$ requires $T = \u03a9\\big(\\frac1\u03b5^2 (\\log\\frac1\u03b5)^d/2\\big)$, and the average cumulative regret is at least $\u03a9\\big( \\sqrt{T}(\\log T)^d \\big)$, thus matching existing upper bounds up to the replacement of $d/2$ by $d+O(1)$ in both cases.  For the Mat\u00e9rn-$\u03bd$ kernel, we give analogous bounds of the form $\u03a9\\big( (\\frac1\u03b5)^2+d/\u03bd\\big)$ and $\u03a9\\big( T^\\frac\u03bd+ d2\u03bd+ d \\big)$, and discuss the resulting gaps to the existing upper bounds.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/scarlett17a/scarlett17a.pdf",
        "supp": "",
        "pdf_size": 403822,
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14285476587870443324&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Laboratory for Information and Inference Systems (LIONS) + \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Laboratory for Information and Inference Systems (LIONS) + \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Laboratory for Information and Inference Systems (LIONS) + \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "aff_domain": "EPFL.CH;EPFL.CH;EPFL.CH",
        "email": "EPFL.CH;EPFL.CH;EPFL.CH",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1",
        "aff_unique_norm": "Laboratory for Information and Inference Systems;EPFL",
        "aff_unique_dep": "Information and Inference Systems;",
        "aff_unique_url": ";https://www.epfl.ch",
        "aff_unique_abbr": "LIONS;EPFL",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1;1;1",
        "aff_country_unique": ";Switzerland"
    },
    {
        "id": "e8e95bd0cd",
        "title": "Matrix Completion from $O(n)$ Samples in Linear Time",
        "site": "https://proceedings.mlr.press/v65/gamarnik17a.html",
        "author": "David Gamarnik; Quan Li; Hongyi Zhang",
        "abstract": "We consider the problem of reconstructing a rank-$k$ $n \\times n$ matrix $M$ from a sampling of its entries. Under a certain incoherence assumption on $M$ and for the case when both the  rank and the condition number of $M$ are bounded, it was shown in (Cand\u00e8s and Recht, 2009; Cand\u00e8s and Tao, 2010; Keshavan et al., 2010; Recht, 2011; Jain et al., 2012; Hardt, 2014) that $M$ can be recovered exactly or approximately (depending on some trade-off between accuracy and computational complexity) using $O(n \u2009\\text{poly}(\\log n))$ samples in super-linear time $O(n^a \u2009\\text{poly}(\\log n))$ for some constant $a \u22651$. In this paper, we propose a new matrix completion algorithm using a novel sampling scheme based on a union of independent sparse random regular bipartite graphs. We show that under the same conditions w.h.p. our algorithm recovers an $\u03b5$-approximation of $M$ in terms of the Frobenius norm using $O(n \\log^2(1/\u03b5))$ samples and in linear time $O(n \\log^2(1/\u03b5))$. This provides the best known bounds both on the sample complexity and computational cost for reconstructing (approximately) an unknown low-rank matrix. The novelty of  our algorithm  is two new steps of thresholding singular values and rescaling singular vectors in the application of the \u201cvanilla\u201d alternating minimization algorithm. The structure of sparse random regular graphs is used heavily for controlling the impact of these regularization steps.",
        "bibtex": "@InProceedings{pmlr-v65-gamarnik17a,\n  title = \t {Matrix Completion from $O(n)$ Samples in Linear Time},\n  author = \t {Gamarnik, David and Li, Quan and Zhang, Hongyi},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {940--947},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/gamarnik17a/gamarnik17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/gamarnik17a.html},\n  abstract = \t {We consider the problem of reconstructing a rank-$k$ $n \\times n$ matrix $M$ from a sampling of its entries. Under a certain incoherence assumption on $M$ and for the case when both the  rank and the condition number of $M$ are bounded, it was shown in (Cand\u00e8s and Recht, 2009; Cand\u00e8s and Tao, 2010; Keshavan et al., 2010; Recht, 2011; Jain et al., 2012; Hardt, 2014) that $M$ can be recovered exactly or approximately (depending on some trade-off between accuracy and computational complexity) using $O(n \u2009\\text{poly}(\\log n))$ samples in super-linear time $O(n^a \u2009\\text{poly}(\\log n))$ for some constant $a \u22651$. In this paper, we propose a new matrix completion algorithm using a novel sampling scheme based on a union of independent sparse random regular bipartite graphs. We show that under the same conditions w.h.p. our algorithm recovers an $\u03b5$-approximation of $M$ in terms of the Frobenius norm using $O(n \\log^2(1/\u03b5))$ samples and in linear time $O(n \\log^2(1/\u03b5))$. This provides the best known bounds both on the sample complexity and computational cost for reconstructing (approximately) an unknown low-rank matrix. The novelty of  our algorithm  is two new steps of thresholding singular values and rescaling singular vectors in the application of the \u201cvanilla\u201d alternating minimization algorithm. The structure of sparse random regular graphs is used heavily for controlling the impact of these regularization steps.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/gamarnik17a/gamarnik17a.pdf",
        "supp": "",
        "pdf_size": 246734,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11957238242440165929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "MIT.EDU;MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1f0444365a",
        "title": "Memory and Communication Efficient Distributed Stochastic Optimization with Minibatch Prox",
        "site": "https://proceedings.mlr.press/v65/wang17a.html",
        "author": "Jialei Wang; Weiran Wang; Nathan Srebro",
        "abstract": "We present and analyze statistically optimal, communication and memory efficient distributed stochastic optimization algorithms with near-linear speedups (up to $\\log$-factors).  This improves over prior work which includes methods with near-linear speedups but polynomial communication requirements (accelerated minibatch SGD) and communication efficient methods which do not exhibit any runtime speedups over a naive single-machine approach.  We first analyze a distributed SVRG variant as a distributed stochastic optimization method and show that it can achieve near-linear speedups with logarithmic rounds of communication, at the cost of high memory requirements. We then present a novel method, MB-DSVRG, which trades off memory for communication and still allows for optimization with communication which scales only logarithmically with the desired accuracy while also being memory efficient.  MB-DSVRG is based on a minibatch prox procedure, solving a non-linearized subproblem on a minibatch at each iteration.  We provide a novel analysis for this procedure which achieves the statistical optimal rate regardless of minibatch size and smoothness, and thus significantly improving on prior work.",
        "bibtex": "@InProceedings{pmlr-v65-wang17a,\n  title = \t {Memory and Communication Efficient Distributed Stochastic Optimization with Minibatch Prox},\n  author = \t {Wang, Jialei and Wang, Weiran and Srebro, Nathan},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1882--1919},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/wang17a/wang17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/wang17a.html},\n  abstract = \t {We present and analyze statistically optimal, communication and memory efficient distributed stochastic optimization algorithms with near-linear speedups (up to $\\log$-factors).  This improves over prior work which includes methods with near-linear speedups but polynomial communication requirements (accelerated minibatch SGD) and communication efficient methods which do not exhibit any runtime speedups over a naive single-machine approach.  We first analyze a distributed SVRG variant as a distributed stochastic optimization method and show that it can achieve near-linear speedups with logarithmic rounds of communication, at the cost of high memory requirements. We then present a novel method, MB-DSVRG, which trades off memory for communication and still allows for optimization with communication which scales only logarithmically with the desired accuracy while also being memory efficient.  MB-DSVRG is based on a minibatch prox procedure, solving a non-linearized subproblem on a minibatch at each iteration.  We provide a novel analysis for this procedure which achieves the statistical optimal rate regardless of minibatch size and smoothness, and thus significantly improving on prior work.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/wang17a/wang17a.pdf",
        "supp": "",
        "pdf_size": 415973,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1556220149972827525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Chicago; Toyota Technological Institute at Chicago; Toyota Technological Institute at Chicago",
        "aff_domain": "uchicago.edu;ttic.edu;ttic.edu",
        "email": "uchicago.edu;ttic.edu;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Chicago;Toyota Technological Institute at Chicago",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uchicago.edu;https://www.tti-chicago.org",
        "aff_unique_abbr": "UChicago;TTI Chicago",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Chicago",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b373bdba5e",
        "title": "Memoryless Sequences for Differentiable Losses",
        "site": "https://proceedings.mlr.press/v65/frongillo17a.html",
        "author": "Rafael Frongillo; Andrew Nobel",
        "abstract": "One way to define the \u201crandomness\u201d of a fixed individual sequence is to ask how hard it is to predict.  When prediction error is measured via squared loss, it has been established that memoryless sequences (which are, in a precise sense, hard to predict) have some of the stochastic attributes of truly random sequences.  In this paper, we ask how changing the loss function used changes the set of memoryless sequences, and in particular, the stochastic attributes they possess.  We answer this question for differentiable convex loss functions using tools from property elicitation, showing that the property elicited by the loss determines the stochastic attributes of the corresponding memoryless sequences.  We apply our results to price calibration in prediction markets.",
        "bibtex": "@InProceedings{pmlr-v65-frongillo17a,\n  title = \t {Memoryless Sequences for Differentiable Losses},\n  author = \t {Frongillo, Rafael and Nobel, Andrew},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {925--939},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/frongillo17a/frongillo17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/frongillo17a.html},\n  abstract = \t {One way to define the \u201crandomness\u201d of a fixed individual sequence is to ask how hard it is to predict.  When prediction error is measured via squared loss, it has been established that memoryless sequences (which are, in a precise sense, hard to predict) have some of the stochastic attributes of truly random sequences.  In this paper, we ask how changing the loss function used changes the set of memoryless sequences, and in particular, the stochastic attributes they possess.  We answer this question for differentiable convex loss functions using tools from property elicitation, showing that the property elicited by the loss determines the stochastic attributes of the corresponding memoryless sequences.  We apply our results to price calibration in prediction markets.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/frongillo17a/frongillo17a.pdf",
        "supp": "",
        "pdf_size": 225926,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4907859839704712445&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "CU Boulder; UNC Chapel Hill",
        "aff_domain": "COLORADO.EDU;EMAIL.UNC.EDU",
        "email": "COLORADO.EDU;EMAIL.UNC.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Colorado Boulder;University of North Carolina at Chapel Hill",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.colorado.edu;https://www.unc.edu",
        "aff_unique_abbr": "CU Boulder;UNC",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Boulder;Chapel Hill",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9ba81c7f1e",
        "title": "Mixing Implies Lower Bounds for Space Bounded Learning",
        "site": "https://proceedings.mlr.press/v65/moshkovitz17a.html",
        "author": "Dana Moshkovitz; Michal Moshkovitz",
        "abstract": "One can learn any hypothesis class H with O(log |H|) labeled examples. Alas, learning with so few examples requires saving the examples in memory, and this requires |X|^(O(log|H|)) memory states, where X is the set of all labeled examples. This motivates the question of how many labeled examples are needed in case the memory is bounded. Previous work showed, using techniques such as linear algebra and Fourier analysis, that parities cannot be learned with bounded memory and less than |H|^(Omega(1)) examples. One might wonder whether a general combinatorial condition exists for unlearnability with bounded memory, as we have with the condition  VCdim(H) = Infinity for PAC unlearnability. In this paper we give such a condition. We show that if an hypothesis class H, when viewed as a bipartite graph between hypotheses H and labeled examples X, is mixing, then learning it requires |H|^(Omega(1)) examples under a certain bound on the memory. Note that the class of parities is mixing. Moreover, as an immediate corollary, we get that most hypothesis classes are unlearnable with bounded memory. Our proof technique is combinatorial in nature and very different from previous analyses.",
        "bibtex": "@InProceedings{pmlr-v65-moshkovitz17a,\n  title = \t {Mixing Implies Lower Bounds for Space Bounded Learning},\n  author = \t {Moshkovitz, Dana and Moshkovitz, Michal},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1516--1566},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/moshkovitz17a/moshkovitz17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/moshkovitz17a.html},\n  abstract = \t {One can learn any hypothesis class H with O(log |H|) labeled examples. Alas, learning with so few examples requires saving the examples in memory, and this requires |X|^(O(log|H|)) memory states, where X is the set of all labeled examples. This motivates the question of how many labeled examples are needed in case the memory is bounded. Previous work showed, using techniques such as linear algebra and Fourier analysis, that parities cannot be learned with bounded memory and less than |H|^(Omega(1)) examples. One might wonder whether a general combinatorial condition exists for unlearnability with bounded memory, as we have with the condition  VCdim(H) = Infinity for PAC unlearnability. In this paper we give such a condition. We show that if an hypothesis class H, when viewed as a bipartite graph between hypotheses H and labeled examples X, is mixing, then learning it requires |H|^(Omega(1)) examples under a certain bound on the memory. Note that the class of parities is mixing. Moreover, as an immediate corollary, we get that most hypothesis classes are unlearnable with bounded memory. Our proof technique is combinatorial in nature and very different from previous analyses.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/moshkovitz17a/moshkovitz17a.pdf",
        "supp": "",
        "pdf_size": 445876,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12859624994446107437&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, UT Austin; The Edmond and Lily Safra Center for Brain Sciences, Hebrew University",
        "aff_domain": "CS.UTEXAS.EDU;MAIL.HUJI.AC.IL",
        "email": "CS.UTEXAS.EDU;MAIL.HUJI.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Texas at Austin;Hebrew University",
        "aff_unique_dep": "Department of Computer Science;The Edmond and Lily Safra Center for Brain Sciences",
        "aff_unique_url": "https://www.utexas.edu;https://huji.ac.il",
        "aff_unique_abbr": "UT Austin;HUJI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "778a6e9128",
        "title": "Multi-Observation Elicitation",
        "site": "https://proceedings.mlr.press/v65/casalaina-martin17a.html",
        "author": "Sebastian Casalaina-Martin; Rafael Frongillo; Tom Morgan; Bo Waggoner",
        "abstract": "We study loss functions that measure the accuracy of a prediction based on multiple data points simultaneously. To our knowledge, such loss functions have not been studied before in the area of property elicitation or in machine learning more broadly. As compared to traditional loss functions that take only a single data point, these multi-observation loss functions can in some cases drastically reduce the dimensionality of the hypothesis required. In elicitation, this corresponds to requiring many fewer reports; in empirical risk minimization, it corresponds to algorithms on a hypothesis space of much smaller dimension. We explore some examples of the tradeoff between dimensionality and number of observations, give some geometric characterizations and intuition for relating loss functions and the properties that they elicit, and discuss some implications for both elicitation and machine-learning contexts.",
        "bibtex": "@InProceedings{pmlr-v65-casalaina-martin17a,\n  title = \t {Multi-Observation Elicitation},\n  author = \t {Casalaina-Martin, Sebastian and Frongillo, Rafael and Morgan, Tom and Waggoner, Bo},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {449--464},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/casalaina-martin17a/casalaina-martin17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/casalaina-martin17a.html},\n  abstract = \t {We study loss functions that measure the accuracy of a prediction based on multiple data points simultaneously. To our knowledge, such loss functions have not been studied before in the area of property elicitation or in machine learning more broadly. As compared to traditional loss functions that take only a single data point, these multi-observation loss functions can in some cases drastically reduce the dimensionality of the hypothesis required. In elicitation, this corresponds to requiring many fewer reports; in empirical risk minimization, it corresponds to algorithms on a hypothesis space of much smaller dimension. We explore some examples of the tradeoff between dimensionality and number of observations, give some geometric characterizations and intuition for relating loss functions and the properties that they elicit, and discuss some implications for both elicitation and machine-learning contexts.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/casalaina-martin17a/casalaina-martin17a.pdf",
        "supp": "",
        "pdf_size": 978202,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11919288971263166798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "CU Boulder; CU Boulder; Harvard; UPenn",
        "aff_domain": "MATH.COLORADO.EDU;COLORADO.EDU;SEAS.HARVARD.EDU;SEAS.UPENN.EDU",
        "email": "MATH.COLORADO.EDU;COLORADO.EDU;SEAS.HARVARD.EDU;SEAS.UPENN.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Colorado Boulder;Harvard University;University of Pennsylvania",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.colorado.edu;https://www.harvard.edu;https://www.upenn.edu",
        "aff_unique_abbr": "CU Boulder;Harvard;UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "688d8b3aac",
        "title": "Nearly Optimal Sampling Algorithms for Combinatorial Pure Exploration",
        "site": "https://proceedings.mlr.press/v65/chen17a.html",
        "author": "Lijie Chen; Anupam Gupta; Jian Li; Mingda Qiao; Ruosong Wang",
        "abstract": "We study the combinatorial pure exploration problem \\textscBest-Set in a stochastic multi-armed bandit game. In an \\textscBest-Set instance, we are given $n$ stochastic arms with unknown reward distributions, as well as a family $\\mathcal{F}$ of feasible subsets over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify the feasible subset in $\\mathcal{F}$ with the maximum total weight, using as few samples as possible. The problem generalizes the classical best arm identification problem and the top-$k$ arm identification problem, both of which have attracted significant attention in recent years. We provide a novel \\textitinstance-wise lower bound for the sample complexity of the problem, as well as a nontrivial sampling algorithm, matching the lower bound up to a factor of $\\ln|\\mathcal{F}|$. For an important class of combinatorial families (including spanning trees, matchings, and path constraints), we also provide polynomial time implementation of the sampling algorithm, using the equivalence of separation and optimization for convex program, and the notion of approximate Pareto curves in multi-objective optimization (note that $|\\mathcal{F}|$ can be exponential in $n$). We also show that the $\\ln|\\mathcal{F}|$ factor is inevitable in general, through a nontrivial lower bound construction utilizing a combinatorial structure resembling the Nisan-Wigderson design. Our results significantly improve several previous results for several important combinatorial constraints, and provide a tighter understanding of the general \\textscBest-Set problem. We further introduce an even more general problem, formulated in geometric terms. We are given $n$ Gaussian arms with unknown means and unit variance. Consider the $n$-dimensional Euclidean space $\\mathbb{R}^n$, and a collection $\\mathcal{O}$ of disjoint subsets. Our goal is to determine the subset in $\\mathcal{O}$ that contains the mean profile (which is the $n$-dimensional vector of the means), using as few samples as possible. The problem generalizes most pure exploration bandit problems studied in the literature. We provide the first nearly optimal sample complexity upper and lower bounds for the problem.",
        "bibtex": "@InProceedings{pmlr-v65-chen17a,\n  title = \t {Nearly Optimal Sampling Algorithms for Combinatorial Pure Exploration},\n  author = \t {Chen, Lijie and Gupta, Anupam and Li, Jian and Qiao, Mingda and Wang, Ruosong},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {482--534},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/chen17a/chen17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/chen17a.html},\n  abstract = \t { We study the combinatorial pure exploration problem \\textscBest-Set in a stochastic multi-armed bandit game. In an \\textscBest-Set instance, we are given $n$ stochastic arms with unknown reward distributions, as well as a family $\\mathcal{F}$ of feasible subsets over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify the feasible subset in $\\mathcal{F}$ with the maximum total weight, using as few samples as possible. The problem generalizes the classical best arm identification problem and the top-$k$ arm identification problem, both of which have attracted significant attention in recent years. We provide a novel \\textitinstance-wise lower bound for the sample complexity of the problem, as well as a nontrivial sampling algorithm, matching the lower bound up to a factor of $\\ln|\\mathcal{F}|$. For an important class of combinatorial families (including spanning trees, matchings, and path constraints), we also provide polynomial time implementation of the sampling algorithm, using the equivalence of separation and optimization for convex program, and the notion of approximate Pareto curves in multi-objective optimization (note that $|\\mathcal{F}|$ can be exponential in $n$). We also show that the $\\ln|\\mathcal{F}|$ factor is inevitable in general, through a nontrivial lower bound construction utilizing a combinatorial structure resembling the Nisan-Wigderson design. Our results significantly improve several previous results for several important combinatorial constraints, and provide a tighter understanding of the general \\textscBest-Set problem. We further introduce an even more general problem, formulated in geometric terms. We are given $n$ Gaussian arms with unknown means and unit variance. Consider the $n$-dimensional Euclidean space $\\mathbb{R}^n$, and a collection $\\mathcal{O}$ of disjoint subsets. Our goal is to determine the subset in $\\mathcal{O}$ that contains the mean profile (which is the $n$-dimensional vector of the means), using as few samples as possible. The problem generalizes most pure exploration bandit problems studied in the literature. We provide the first nearly optimal sample complexity upper and lower bounds for the problem. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/chen17a/chen17a.pdf",
        "supp": "",
        "pdf_size": 511120,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8526171267874965184&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China; Computer Science Department, Carnegie Mellon University, Pittsburgh, USA; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China",
        "aff_domain": "MAILS.TSINGHUA.EDU.CN;CS.CMU.EDU;MAIL.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN",
        "email": "MAILS.TSINGHUA.EDU.CN;CS.CMU.EDU;MAIL.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tsinghua University;Carnegie Mellon University",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences (IIIS);Computer Science Department",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.cmu.edu",
        "aff_unique_abbr": "Tsinghua;CMU",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Beijing;Pittsburgh",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "3d8e9dbefe",
        "title": "Nearly-tight VC-dimension bounds for piecewise linear neural networks",
        "site": "https://proceedings.mlr.press/v65/harvey17a.html",
        "author": "Nick Harvey; Christopher Liaw; Abbas Mehrabian",
        "abstract": "We prove new upper and lower bounds on the VC-dimension of deep neural networks with the ReLU activation function. These bounds are tight for almost the entire range of parameters. Letting $W$ be the number of weights and $L$ be the number of layers, we prove that the VC-dimension is $O(W L \\log(W))$, and provide examples with VC-dimension $\u03a9( W L \\log(W/L) )$. This improves both the previously known upper bounds and lower bounds. In terms of the number $U$ of non-linear units, we prove a tight bound $\u0398(W U)$ on the VC-dimension. All of these results generalize to arbitrary piecewise linear activation functions.",
        "bibtex": "@InProceedings{pmlr-v65-harvey17a,\n  title = \t {Nearly-tight {VC}-dimension bounds for piecewise linear neural networks},\n  author = \t {Harvey, Nick and Liaw, Christopher and Mehrabian, Abbas},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1064--1068},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/harvey17a/harvey17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/harvey17a.html},\n  abstract = \t {We prove new upper and lower bounds on the VC-dimension of deep neural networks with the ReLU activation function. These bounds are tight for almost the entire range of parameters. Letting $W$ be the number of weights and $L$ be the number of layers, we prove that the VC-dimension is $O(W L \\log(W))$, and provide examples with VC-dimension $\u03a9( W L \\log(W/L) )$. This improves both the previously known upper bounds and lower bounds. In terms of the number $U$ of non-linear units, we prove a tight bound $\u0398(W U)$ on the VC-dimension. All of these results generalize to arbitrary piecewise linear activation functions.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/harvey17a/harvey17a.pdf",
        "supp": "",
        "pdf_size": 157733,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",
        "aff_domain": "CS.UBC.CA;CS.UBC.CA;GMAIL.COM",
        "email": "CS.UBC.CA;CS.UBC.CA;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Vancouver",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9706dedfab",
        "title": "Noisy Population Recovery from Unknown Noise",
        "site": "https://proceedings.mlr.press/v65/lovett17a.html",
        "author": "Shachar Lovett; Jiapeng Zhang",
        "abstract": "The noisy population recovery problem is a statistical inference problem, which is a special case of the problem of learning mixtures of product distributions. Given an unknown distribution on $n$-bit strings with support of size $k$, and given access only to noisy samples from it, where each bit is flipped independently with some unknown noise probability, estimate from a few samples the underlying parameters of the model. Previous work [De et al., FOCS 2016] designed polynomial time algorithms which work under the assumption that the noise parameters are known exactly. In this work, we remove this assumption, and show how to recover the underlying parameters, even when the noise is unknown, in quasi-polynomial time.",
        "bibtex": "@InProceedings{pmlr-v65-lovett17a,\n  title = \t {Noisy Population Recovery from Unknown Noise},\n  author = \t {Lovett, Shachar and Zhang, Jiapeng},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1417--1431},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/lovett17a/lovett17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/lovett17a.html},\n  abstract = \t { The noisy population recovery problem is a statistical inference problem, which is a special case of the problem of learning mixtures of product distributions. Given an unknown distribution on $n$-bit strings with support of size $k$, and given access only to noisy samples from it, where each bit is flipped independently with some unknown noise probability, estimate from a few samples the underlying parameters of the model. Previous work [De et al., FOCS 2016] designed polynomial time algorithms which work under the assumption that the noise parameters are known exactly. In this work, we remove this assumption, and show how to recover the underlying parameters, even when the noise is unknown, in quasi-polynomial time. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/lovett17a/lovett17a.pdf",
        "supp": "",
        "pdf_size": 291303,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4371506303462950312&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Computer Science and Engineering department, University of California, San Diego; Computer Science and Engineering department, University of California, San Diego",
        "aff_domain": "ucsd.edu;gmail.com",
        "email": "ucsd.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Computer Science and Engineering department",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d9ff8842f7",
        "title": "Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis",
        "site": "https://proceedings.mlr.press/v65/raginsky17a.html",
        "author": "Maxim Raginsky; Alexander Rakhlin; Matus Telgarsky",
        "abstract": "Stochastic Gradient Langevin Dynamics (SGLD) is a popular variant of Stochastic Gradient Descent, where properly scaled isotropic Gaussian noise is added to an unbiased estimate of the gradient at each iteration. This modest change allows SGLD to escape local minima and suffices to guarantee asymptotic convergence to global minimizers for sufficiently regular non-convex objectives. The present work provides a nonasymptotic analysis in the context of non-convex learning problems, giving finite-time guarantees for SGLD to find approximate minimizers of both empirical and population risks. As in the asymptotic setting, our analysis relates the discrete-time SGLD Markov chain to a continuous-time diffusion process. A new tool that drives the results is the use of weighted transportation cost inequalities to quantify the rate of convergence of SGLD to a stationary distribution in the Euclidean $2$-Wasserstein distance.",
        "bibtex": "@InProceedings{pmlr-v65-raginsky17a,\n  title = \t {Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis},\n  author = \t {Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1674--1703},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/raginsky17a/raginsky17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/raginsky17a.html},\n  abstract = \t {Stochastic Gradient Langevin Dynamics (SGLD) is a popular variant of Stochastic Gradient Descent, where properly scaled isotropic Gaussian noise is added to an unbiased estimate of the gradient at each iteration. This modest change allows SGLD to escape local minima and suffices to guarantee asymptotic convergence to global minimizers for sufficiently regular non-convex objectives. The present work provides a nonasymptotic analysis in the context of non-convex learning problems, giving finite-time guarantees for SGLD to find approximate minimizers of both empirical and population risks. As in the asymptotic setting, our analysis relates the discrete-time SGLD Markov chain to a continuous-time diffusion process. A new tool that drives the results is the use of weighted transportation cost inequalities to quantify the rate of convergence of SGLD to a stationary distribution in the Euclidean $2$-Wasserstein distance.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/raginsky17a/raginsky17a.pdf",
        "supp": "",
        "pdf_size": 376148,
        "gs_citation": 636,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7583767910728977063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Illinois; University of Pennsylvania; University of Illinois+Simons Institute",
        "aff_domain": "ILLINOIS.EDU;WHARTON.UPENN.EDU;ILLINOIS.EDU",
        "email": "ILLINOIS.EDU;WHARTON.UPENN.EDU;ILLINOIS.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2",
        "aff_unique_norm": "University of Illinois;University of Pennsylvania;Simons Institute for the Theory of Computing",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.illinois.edu;https://www.upenn.edu;https://simons.berkeley.edu",
        "aff_unique_abbr": "UIUC;UPenn;SITC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6240b68d4f",
        "title": "On Equivalence of Martingale Tail Bounds and Deterministic Regret Inequalities",
        "site": "https://proceedings.mlr.press/v65/rakhlin17a.html",
        "author": "Alexander Rakhlin; Karthik Sridharan",
        "abstract": "We study an equivalence of (i) deterministic pathwise statements appearing in the online learning literature (termed \\emphregret bounds), (ii) high-probability tail bounds for the supremum of a collection of martingales (of a specific form arising from uniform laws of large numbers), and (iii) in-expectation bounds for the supremum. By virtue of the equivalence, we prove exponential tail bounds for norms of Banach space valued martingales via deterministic regret bounds for the online mirror descent algorithm with an adaptive step size. We show that the phenomenon extends beyond the setting of online linear optimization and present the equivalence for the supervised online learning setting.",
        "bibtex": "@InProceedings{pmlr-v65-rakhlin17a,\n  title = \t {On Equivalence of Martingale Tail Bounds and Deterministic Regret Inequalities},\n  author = \t {Rakhlin, Alexander and Sridharan, Karthik},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1704--1722},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/rakhlin17a/rakhlin17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/rakhlin17a.html},\n  abstract = \t {We study an equivalence of (i) deterministic pathwise statements appearing in the online learning literature (termed \\emphregret bounds), (ii) high-probability tail bounds for the supremum of a collection of martingales (of a specific form arising from uniform laws of large numbers), and (iii) in-expectation bounds for the supremum. By virtue of the equivalence, we prove exponential tail bounds for norms of Banach space valued martingales via deterministic regret bounds for the online mirror descent algorithm with an adaptive step size. We show that the phenomenon extends beyond the setting of online linear optimization and present the equivalence for the supervised online learning setting. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/rakhlin17a/rakhlin17a.pdf",
        "supp": "",
        "pdf_size": 432660,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=383379897701277535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Pennsylvania; Cornell University",
        "aff_domain": "wharton.upenn.edu;cs.cornell.edu",
        "email": "wharton.upenn.edu;cs.cornell.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Pennsylvania;Cornell University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.upenn.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UPenn;Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a5cfa502d4",
        "title": "On Learning vs. Refutation",
        "site": "https://proceedings.mlr.press/v65/vadhan17a.html",
        "author": "Salil Vadhan",
        "abstract": "Building on the work of Daniely et al. (STOC 2014, COLT 2016), we study the connection between computationally efficient PAC learning and refutation of constraint satisfaction problems.  Specifically, we prove that for every concept class $\\mathcal{P}$, PAC-learning $\\mathcal{P}$ is \\em polynomially equivalent to \u201crandom-right-hand-side-refuting\u201d (\u201cRRHS-refuting\u201d) a dual class $\\mathcal{P}^*$, where RRHS-refutation of a class $\\mathcal{Q}$ refers to refuting systems of equations where the constraints are (worst-case) functions from the class $\\mathcal{Q}$ but the right-hand-sides of the equations are uniform and independent random bits. The reduction from refutation to PAC learning can be viewed as an abstraction of (part of) the work of Daniely, Linial, and Shalev-Schwartz (STOC 2014). The converse, however, is new, and is based on a combination of techniques from pseudorandomness (Yao \u201882) with boosting (Schapire \u201890).  In addition, we show that PAC-learning the class of $\\mathit{DNF}$ formulas is polynomially equivalent to PAC-learning its dual class $\\mathit{DNF}^*$, and thus PAC-learning $\\mathit{DNF}$ is equivalent to RRHS-refutation of $\\mathit{DNF}$, suggesting an avenue to obtain stronger lower bounds for PAC-learning $\\mathit{DNF}$ than the quasipolynomial lower bound that was obtained by Daniely and Shalev-Schwartz (COLT 2016) assuming the hardness of refuting $k$-SAT.",
        "bibtex": "@InProceedings{pmlr-v65-vadhan17a,\n  title = \t {On Learning vs. Refutation},\n  author = \t {Vadhan, Salil},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1835--1848},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/vadhan17a/vadhan17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/vadhan17a.html},\n  abstract = \t {Building on the work of Daniely et al. (STOC 2014, COLT 2016), we study the connection between computationally efficient PAC learning and refutation of constraint satisfaction problems.  Specifically, we prove that for every concept class $\\mathcal{P}$, PAC-learning $\\mathcal{P}$ is \\em polynomially equivalent to \u201crandom-right-hand-side-refuting\u201d (\u201cRRHS-refuting\u201d) a dual class $\\mathcal{P}^*$, where RRHS-refutation of a class $\\mathcal{Q}$ refers to refuting systems of equations where the constraints are (worst-case) functions from the class $\\mathcal{Q}$ but the right-hand-sides of the equations are uniform and independent random bits. The reduction from refutation to PAC learning can be viewed as an abstraction of (part of) the work of Daniely, Linial, and Shalev-Schwartz (STOC 2014). The converse, however, is new, and is based on a combination of techniques from pseudorandomness (Yao \u201882) with boosting (Schapire \u201890).  In addition, we show that PAC-learning the class of $\\mathit{DNF}$ formulas is polynomially equivalent to PAC-learning its dual class $\\mathit{DNF}^*$, and thus PAC-learning $\\mathit{DNF}$ is equivalent to RRHS-refutation of $\\mathit{DNF}$, suggesting an avenue to obtain stronger lower bounds for PAC-learning $\\mathit{DNF}$ than the quasipolynomial lower bound that was obtained by Daniely and Shalev-Schwartz (COLT 2016) assuming the hardness of refuting $k$-SAT.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/vadhan17a/vadhan17a.pdf",
        "supp": "",
        "pdf_size": 356555,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11461786184219453304&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "School of Engineering & Applied Sciences, Harvard University, Cambridge, Massachusetts, USA + Shing-Tung Yau Center and the Department of Applied Mathematics at National Chiao-Tung University in Hsinchu, Taiwan",
        "aff_domain": "seas.harvard.edu",
        "email": "seas.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "Harvard University;National Chiao-Tung University",
        "aff_unique_dep": "School of Engineering & Applied Sciences;Department of Applied Mathematics",
        "aff_unique_url": "https://www.harvard.edu;https://www.nctu.edu.tw",
        "aff_unique_abbr": "Harvard;NCTU",
        "aff_campus_unique_index": "0+1",
        "aff_campus_unique": "Cambridge;Taiwan",
        "aff_country_unique_index": "0+1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "f91555c1bc",
        "title": "On the Ability of Neural Nets to Express Distributions",
        "site": "https://proceedings.mlr.press/v65/lee17a.html",
        "author": "Holden Lee; Rong Ge; Tengyu Ma; Andrej Risteski; Sanjeev Arora",
        "abstract": "Deep neural nets have caused a revolution in many classification tasks. A related ongoing revolution\u2014also theoretically not understood\u2014concerns their ability to serve as generative models for complicated types of data such as images and texts. These models are trained using ideas like variational autoencoders and Generative Adversarial Networks. We take a first cut at explaining the expressivity of multilayer nets by giving a sufficient criterion for a function to be approximable by a neural network with $n$ hidden layers. A key ingredient is Barron\u2019s Theorem (Barron, 1993), which gives a Fourier criterion for approximability of a function by a neural network with 1 hidden layer. We show that a composition of $n$ functions which satisfy certain Fourier conditions (\u201cBarron functions\u201d) can be approximated by a $n+1$-layer neural network. For probability distributions, this translates into a criterion for a probability distribution to be approximable in Wasserstein distance\u2014a natural metric on probability distributions\u2014by a neural network applied to a fixed base distribution (e.g., multivariate gaussian). Building up recent lower bound work, we also give an example function that shows that composition of Barron functions is more expressive than Barron functions alone.",
        "bibtex": "@InProceedings{pmlr-v65-lee17a,\n  title = \t {On the Ability of Neural Nets to Express Distributions},\n  author = \t {Lee, Holden and Ge, Rong and Ma, Tengyu and Risteski, Andrej and Arora, Sanjeev},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1271--1296},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/lee17a/lee17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/lee17a.html},\n  abstract = \t {Deep neural nets have caused a revolution in many classification tasks. A related ongoing revolution\u2014also theoretically not understood\u2014concerns their ability to serve as generative models for complicated types of data such as images and texts. These models are trained using ideas like variational autoencoders and Generative Adversarial Networks. We take a first cut at explaining the expressivity of multilayer nets by giving a sufficient criterion for a function to be approximable by a neural network with $n$ hidden layers. A key ingredient is Barron\u2019s Theorem (Barron, 1993), which gives a Fourier criterion for approximability of a function by a neural network with 1 hidden layer. We show that a composition of $n$ functions which satisfy certain Fourier conditions (\u201cBarron functions\u201d) can be approximated by a $n+1$-layer neural network. For probability distributions, this translates into a criterion for a probability distribution to be approximable in Wasserstein distance\u2014a natural metric on probability distributions\u2014by a neural network applied to a fixed base distribution (e.g., multivariate gaussian). Building up recent lower bound work, we also give an example function that shows that composition of Barron functions is more expressive than Barron functions alone.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/lee17a/lee17a.pdf",
        "supp": "",
        "pdf_size": 440191,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15151913730816421546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Princeton University, Mathematics Department; Duke University, Computer Science Department; Princeton University, Computer Science Department; Princeton University, Computer Science Department; Princeton University, Computer Science Department",
        "aff_domain": "PRINCETON.EDU;CS.DUKE.EDU;CS.PRINCETON.EDU;PRINCETON.EDU;CS.PRINCETON.EDU",
        "email": "PRINCETON.EDU;CS.DUKE.EDU;CS.PRINCETON.EDU;PRINCETON.EDU;CS.PRINCETON.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Princeton University;Duke University",
        "aff_unique_dep": "Mathematics Department;Computer Science Department",
        "aff_unique_url": "https://www.princeton.edu;https://www.duke.edu",
        "aff_unique_abbr": "Princeton;Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "10527d67ae",
        "title": "Online Learning Without Prior Information",
        "site": "https://proceedings.mlr.press/v65/cutkosky17a.html",
        "author": "Ashok Cutkosky; Kwabena Boahen",
        "abstract": "The vast majority of optimization and online learning algorithms today require some prior information about the data (often in the form of bounds on gradients or on the optimal parameter value). When this information is not available, these algorithms require laborious manual tuning of various hyperparameters, motivating the search for algorithms that can adapt to the data with no prior information. We  describe a frontier of new lower bounds on the performance of such algorithms, reflecting a tradeoff between a term that depends on the optimal parameter value and a term that depends on the gradients\u2019 rate of growth. Further, we construct a family of algorithms whose performance matches any desired point on this frontier, which no previous algorithm reaches.",
        "bibtex": "@InProceedings{pmlr-v65-cutkosky17a,\n  title = \t {Online Learning Without Prior Information},\n  author = \t {Cutkosky, Ashok and Boahen, Kwabena},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {643--677},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/cutkosky17a/cutkosky17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/cutkosky17a.html},\n  abstract = \t {The vast majority of optimization and online learning algorithms today require some prior information about the data (often in the form of bounds on gradients or on the optimal parameter value). When this information is not available, these algorithms require laborious manual tuning of various hyperparameters, motivating the search for algorithms that can adapt to the data with no prior information. We  describe a frontier of new lower bounds on the performance of such algorithms, reflecting a tradeoff between a term that depends on the optimal parameter value and a term that depends on the gradients\u2019 rate of growth. Further, we construct a family of algorithms whose performance matches any desired point on this frontier, which no previous algorithm reaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/cutkosky17a/cutkosky17a.pdf",
        "supp": "",
        "pdf_size": 392754,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10395901326292119255&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "CS.STANFORD.EDU;STANFORD.EDU",
        "email": "CS.STANFORD.EDU;STANFORD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9e448de7bd",
        "title": "Open Problem: First-Order Regret Bounds for Contextual Bandits",
        "site": "https://proceedings.mlr.press/v65/agarwal17a.html",
        "author": "Alekh Agarwal; Akshay Krishnamurthy; John Langford; Haipeng Luo; Schapire Robert E.",
        "abstract": "We describe two open problems related to first order regret bounds for contextual bandits. The first asks for an algorithm with a regret bound of $\\tilde{\\mathcal{O}}(\\sqrt{L_\u22c6}K \\ln N)$ where there are $K$ actions, $N$ policies, and $L_\u22c6$ is the cumulative loss of the best policy. The second asks for an optimization-oracle-efficient algorithm with regret $\\tilde{\\mathcal{O}}(L_\u22c6^{2/3}poly(K, \\ln(N/\u03b4)))$.  We describe some positive results, such as an inefficient algorithm for the second problem, and some partial negative results.",
        "bibtex": "@InProceedings{pmlr-v65-agarwal17a,\n  title = \t {Open Problem: First-Order Regret Bounds for Contextual Bandits},\n  author = \t {Agarwal, Alekh and Krishnamurthy, Akshay and Langford, John and Luo, Haipeng and E., Schapire Robert},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {4--7},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/agarwal17a/agarwal17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/agarwal17a.html},\n  abstract = \t {We describe two open problems related to first order regret bounds for contextual bandits. The first asks for an algorithm with a regret bound of $\\tilde{\\mathcal{O}}(\\sqrt{L_\u22c6}K \\ln N)$ where there are $K$ actions, $N$ policies, and $L_\u22c6$ is the cumulative loss of the best policy. The second asks for an optimization-oracle-efficient algorithm with regret $\\tilde{\\mathcal{O}}(L_\u22c6^{2/3}poly(K, \\ln(N/\u03b4)))$.  We describe some positive results, such as an inefficient algorithm for the second problem, and some partial negative results. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/agarwal17a/agarwal17a.pdf",
        "supp": "",
        "pdf_size": 259577,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15084713172796477470&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft Research, NYC; University of Massachusetts, Amherst; Microsoft Research, NYC; Microsoft Research, NYC; Microsoft Research, NYC",
        "aff_domain": "microsoft.com;cs.umass.edu;microsoft.com;microsoft.com;microsoft.com",
        "email": "microsoft.com;cs.umass.edu;microsoft.com;microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Microsoft;University of Massachusetts Amherst",
        "aff_unique_dep": "Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.umass.edu",
        "aff_unique_abbr": "MSR;UMass Amherst",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "New York City;Amherst",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "63f88dc860",
        "title": "Open Problem: Meeting Times for Learning Random Automata",
        "site": "https://proceedings.mlr.press/v65/fish17a.html",
        "author": "Benjamin Fish; Lev Reyzin",
        "abstract": "Learning automata is a foundational problem in computational learning theory. However, even efficiently learning random DFAs is hard. A natural restriction of this problem is to consider learning random DFAs under the uniform distribution. To date, this problem has no non-trivial lower bounds nor algorithms faster than brute force. In this note, we propose a method to find faster algorithms for this problem. We reduce the learning problem to a conjecture about meeting times of random walks over random DFAs, which may be of independent interest to prove.",
        "bibtex": "@InProceedings{pmlr-v65-fish17a,\n  title = \t {Open Problem: Meeting Times for Learning Random Automata},\n  author = \t {Fish, Benjamin and Reyzin, Lev},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {8--11},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/fish17a/fish17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/fish17a.html},\n  abstract = \t {Learning automata is a foundational problem in computational learning theory. However, even efficiently learning random DFAs is hard. A natural restriction of this problem is to consider learning random DFAs under the uniform distribution. To date, this problem has no non-trivial lower bounds nor algorithms faster than brute force. In this note, we propose a method to find faster algorithms for this problem. We reduce the learning problem to a conjecture about meeting times of random walks over random DFAs, which may be of independent interest to prove.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/fish17a/fish17a.pdf",
        "supp": "",
        "pdf_size": 150434,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9318692201650022692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Mathematics, University of Illinois at Chicago; Department of Mathematics, University of Illinois at Chicago",
        "aff_domain": "UIC.EDU;MATH.UIC.EDU",
        "email": "UIC.EDU;MATH.UIC.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois at Chicago",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.uic.edu",
        "aff_unique_abbr": "UIC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7404a01fbc",
        "title": "Optimal learning via local entropies and sample compression",
        "site": "https://proceedings.mlr.press/v65/nikita17a.html",
        "author": "Zhivotovskiy Nikita",
        "abstract": "Under margin assumptions, we prove several risk bounds, represented via the distribution dependent local entropies of the classes or the sizes of specific sample compression schemes. In some cases, our guarantees are optimal up to constant factors for families of classes. We discuss limitations of our approach and give several applications. In particular, we provide a new tight PAC bound for the hard-margin SVM, an extended analysis of certain empirical risk minimizers under log-concave distributions, a new variant of an online to batch conversion, and distribution dependent localized bounds in the aggregation framework. As a part of our results, we give a new upper bound for the uniform deviations under Bernstein assumptions, which may be of independent interest. The proofs for the sample compression schemes are based on the moment method combined with the analysis of voting algorithms.",
        "bibtex": "@InProceedings{pmlr-v65-nikita17a,\n  title = \t {Optimal learning via local entropies and sample compression},\n  author = \t {Nikita, Zhivotovskiy},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {2023--2065},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/nikita17a/nikita17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/nikita17a.html},\n  abstract = \t {Under margin assumptions, we prove several risk bounds, represented via the distribution dependent local entropies of the classes or the sizes of specific sample compression schemes. In some cases, our guarantees are optimal up to constant factors for families of classes. We discuss limitations of our approach and give several applications. In particular, we provide a new tight PAC bound for the hard-margin SVM, an extended analysis of certain empirical risk minimizers under log-concave distributions, a new variant of an online to batch conversion, and distribution dependent localized bounds in the aggregation framework. As a part of our results, we give a new upper bound for the uniform deviations under Bernstein assumptions, which may be of independent interest. The proofs for the sample compression schemes are based on the moment method combined with the analysis of voting algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/nikita17a/nikita17a.pdf",
        "supp": "",
        "pdf_size": 329136,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8033085606816035796&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Skolkovo Institute of Science and Technology + Institute for Information Transmission Problems, Moscow",
        "aff_domain": "phystech.edu",
        "email": "phystech.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;Institute for Information Transmission Problems",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.skoltech.ru;",
        "aff_unique_abbr": "Skoltech;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "242ec6dba9",
        "title": "Predicting with Distributions",
        "site": "https://proceedings.mlr.press/v65/kearns17a.html",
        "author": "Michael Kearns; Zhiwei Steven Wu",
        "abstract": "We consider a new learning model in which a joint distribution over vector pairs $(x,y)$ is determined by an unknown function $c(x)$ that maps input vectors $x$ not to individual outputs, but to entire \\em distributions\\/ over output vectors $y$.  Our main results take the form of rather general reductions from our model to algorithms for PAC learning the function class and the distribution class separately, and show that virtually every such combination yields an efficient algorithm in our model.  Our methods include a randomized reduction to classification noise and an application of Le Cam\u2019s method to obtain robust learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v65-kearns17a,\n  title = \t {Predicting with Distributions},\n  author = \t {Kearns, Michael and Wu, Zhiwei Steven},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1214--1241},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/kearns17a/kearns17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/kearns17a.html},\n  abstract = \t {  We consider a new learning model in which a joint distribution over vector pairs $(x,y)$ is determined by an unknown function $c(x)$ that maps input vectors $x$ not to individual outputs, but to entire \\em distributions\\/ over output vectors $y$.  Our main results take the form of rather general reductions from our model to algorithms for PAC learning the function class and the distribution class separately, and show that virtually every such combination yields an efficient algorithm in our model.  Our methods include a randomized reduction to classification noise and an application of Le Cam\u2019s method to obtain robust learning algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/kearns17a/kearns17a.pdf",
        "supp": "",
        "pdf_size": 375919,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "CIS.UPENN.EDU;CIS.UPENN.EDU",
        "email": "CIS.UPENN.EDU;CIS.UPENN.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "89b42fdc0a",
        "title": "Preface: Conference on Learning Theory (COLT), 2017",
        "site": "https://proceedings.mlr.press/v65/kale17a.html",
        "author": "Satyen Kale; Ohad Shamir",
        "abstract": "",
        "bibtex": "@InProceedings{pmlr-v65-kale17a,\n  title = \t {Preface: Conference on Learning Theory (COLT), 2017},\n  author = \t {Kale, Satyen and Shamir, Ohad},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1--3},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/kale17a/kale17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/kale17a.html}\n}",
        "pdf": "http://proceedings.mlr.press/v65/kale17a/kale17a.pdf",
        "supp": "",
        "pdf_size": 67400,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7433PGGalEQJ:scholar.google.com/&scioq=Preface:+Conference+on+Learning+Theory+(COLT),+2017&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Google Research; Department of Computer Science and Applied Mathematics, Weizmann University",
        "aff_domain": "GOOGLE.COM;WEIZMANN.AC.IL",
        "email": "GOOGLE.COM;WEIZMANN.AC.IL",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Google;Weizmann University",
        "aff_unique_dep": "Google Research;Department of Computer Science and Applied Mathematics",
        "aff_unique_url": "https://research.google;https://www.weizmann.ac.il",
        "aff_unique_abbr": "Google Research;Weizmann",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "79b2500147",
        "title": "Quadratic Upper Bound for Recursive Teaching Dimension of Finite VC Classes",
        "site": "https://proceedings.mlr.press/v65/hu17a.html",
        "author": "Lunjia Hu; Ruihan Wu; Tianhong Li; Liwei Wang",
        "abstract": "In this work we study the quantitative relation between the recursive teaching dimension (RTD) and the VC dimension (VCD) of concept classes of finite sizes. The RTD of a concept class $\\mathcal C\u2286{0,1}^n$ , introduced by Zilles et al. (2011), is a combinatorial complexity measure characterized by the worst-case number of examples necessary to identify a concept in $\\mathcal C$ according to the recursive teaching model. For any finite concept class $\\mathcal C\u2286{0,1}^n$ with $\\mathrm{VCD}(\\mathcal C) = d$, Simon and Zilles (2015) posed an open problem $\\mathrm{RTD}(\\mathcal C) = O(d)$, i.e., is RTD linearly upper bounded by VCD? Previously, the best known result is an exponential upper bound $\\mathrm{RTD}(\\mathcal C) = O(d\\cdot2^d)$, due to Chen et al. (2016). In this paper, we show a quadratic upper bound: $\\mathrm{RTD}(\\mathcal C) = O(d^2)$, much closer to an answer to the open problem. We also discuss the challenges in fully solving the problem.",
        "bibtex": "@InProceedings{pmlr-v65-hu17a,\n  title = \t {Quadratic Upper Bound for Recursive Teaching Dimension of Finite VC Classes},\n  author = \t {Hu, Lunjia and Wu, Ruihan and Li, Tianhong and Wang, Liwei},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1147--1156},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/hu17a/hu17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/hu17a.html},\n  abstract = \t {In this work we study the quantitative relation between the recursive teaching dimension (RTD) and the VC dimension (VCD) of concept classes of finite sizes. The RTD of a concept class $\\mathcal C\u2286{0,1}^n$ , introduced by Zilles et al. (2011), is a combinatorial complexity measure characterized by the worst-case number of examples necessary to identify a concept in $\\mathcal C$ according to the recursive teaching model. For any finite concept class $\\mathcal C\u2286{0,1}^n$ with $\\mathrm{VCD}(\\mathcal C) = d$, Simon and Zilles (2015) posed an open problem $\\mathrm{RTD}(\\mathcal C) = O(d)$, i.e., is RTD linearly upper bounded by VCD? Previously, the best known result is an exponential upper bound $\\mathrm{RTD}(\\mathcal C) = O(d\\cdot2^d)$, due to Chen et al. (2016). In this paper, we show a quadratic upper bound: $\\mathrm{RTD}(\\mathcal C) = O(d^2)$, much closer to an answer to the open problem. We also discuss the challenges in fully solving the problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/hu17a/hu17a.pdf",
        "supp": "",
        "pdf_size": 258902,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15431951417599853147&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Key Laboratory of Machine Perception, School of Electronics Engineering and Computer Sciences, Peking University, China",
        "aff_domain": "MAILS.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN;CIS.PKU.EDU.CN",
        "email": "MAILS.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN;CIS.PKU.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Tsinghua University;Peking University",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;School of Electronics Engineering and Computer Sciences",
        "aff_unique_url": "https://www.tsinghua.edu.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "Tsinghua;Peking U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "c1325f0f94",
        "title": "Rates of estimation for determinantal point processes",
        "site": "https://proceedings.mlr.press/v65/brunel17a.html",
        "author": "Victor-Emmanuel Brunel; Ankur Moitra; Philippe Rigollet; John Urschel",
        "abstract": "Determinantal point processes (DPPs) have wide-ranging applications in machine learning, where they are used to enforce the notion of diversity in subset selection problems. Many estimators have been proposed, but surprisingly the basic properties of the maximum likelihood estimator (MLE) have received little attention. In this paper, we study the local geometry of the expected log-likelihood function to prove several rates of convergence for the MLE. We also give a complete characterization of the case where the MLE converges at a parametric rate. Even in the latter case, we also exhibit a potential curse of dimensionality where the asymptotic variance of the MLE is exponentially large in the dimension of the problem.",
        "bibtex": "@InProceedings{pmlr-v65-brunel17a,\n  title = \t {Rates of estimation for determinantal point processes},\n  author = \t {Brunel, Victor-Emmanuel and Moitra, Ankur and Rigollet, Philippe and Urschel, John},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {343--345},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/brunel17a/brunel17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/brunel17a.html},\n  abstract = \t {Determinantal point processes (DPPs) have wide-ranging applications in machine learning, where they are used to enforce the notion of diversity in subset selection problems. Many estimators have been proposed, but surprisingly the basic properties of the maximum likelihood estimator (MLE) have received little attention. In this paper, we study the local geometry of the expected log-likelihood function to prove several rates of convergence for the MLE. We also give a complete characterization of the case where the MLE converges at a parametric rate. Even in the latter case, we also exhibit a potential curse of dimensionality where the asymptotic variance of the MLE is exponentially large in the dimension of the problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/brunel17a/brunel17a.pdf",
        "supp": "",
        "pdf_size": 173811,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8535741240118721539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Massachusetts Institute of Technology, Department of Mathematics; Massachusetts Institute of Technology, Department of Mathematics; Massachusetts Institute of Technology, Department of Mathematics; Massachusetts Institute of Technology, Department of Mathematics",
        "aff_domain": "MIT.EDU;MIT.EDU;MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU;MIT.EDU;MIT.EDU",
        "github": "",
        "project": "arXiv:1706.00961",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3452ba0299",
        "title": "Reliably Learning the ReLU in Polynomial Time",
        "site": "https://proceedings.mlr.press/v65/goel17a.html",
        "author": "Surbhi Goel; Varun Kanade; Adam Klivans; Justin Thaler",
        "abstract": "We give the first dimension-efficient algorithms for learning Rectified Linear Units (ReLUs), which are functions of the form $\\mathbf{x} \\mapsto \\mathsf{max}(0, \u00a0\\mathbf{w} \u22c5\\mathbf{x})$ with $\\mathbf{w} \u2208\\mathbb{S}^n-1$. Our algorithm works in the challenging Reliable Agnostic learning model of Kalai, Kanade and Mansour (2012) where the learner is given access to a distribution $\\mathcal{D}$ on labeled examples but the labeling may be arbitrary.  We construct a hypothesis that simultaneously minimizes the false-positive rate and the loss on inputs given positive labels by $\\mathcal{D}$, for any convex, bounded, and Lipschitz loss function. The algorithm runs in polynomial-time (in $n$) with respect to \\em any distribution on $\\mathbb{S}^n-1$ (the unit sphere in $n$ dimensions) and for any error parameter $\u03b5= \u03a9(1 / \\log n)$ (this yields a PTAS for a question raised by F. Bach on the complexity of maximizing ReLUs).  These results are in contrast to known efficient algorithms for reliably learning linear threshold functions, where $\u03b5$ must be $\u03a9(1)$ and strong assumptions are required on the marginal distribution. We can compose our results to obtain the first set of efficient algorithms for learning constant-depth networks of ReLU with fixed polynomial-dependence in the dimension. For depth-2 networks of sigmoids, we obtain the first algorithms that have a polynomial dependency in \\em all parameters. Our techniques combine kernel methods and polynomial approximations with a \u201cdual-loss\u201d approach to convex programming. As a byproduct we obtain a number of applications including the first set of efficient algorithms for \u201cconvex piecewise-linear fitting\u201d and the first efficient algorithms for noisy polynomial reconstruction of low-weight polynomials on the unit sphere.",
        "bibtex": "@InProceedings{pmlr-v65-goel17a,\n  title = \t {Reliably Learning the ReLU in Polynomial Time},\n  author = \t {Goel, Surbhi and Kanade, Varun and Klivans, Adam and Thaler, Justin},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1004--1042},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/goel17a/goel17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/goel17a.html},\n  abstract = \t {We give the first dimension-efficient algorithms for learning Rectified Linear Units (ReLUs), which are functions of the form $\\mathbf{x} \\mapsto \\mathsf{max}(0, \u00a0\\mathbf{w} \u22c5\\mathbf{x})$ with $\\mathbf{w} \u2208\\mathbb{S}^n-1$. Our algorithm works in the challenging Reliable Agnostic learning model of Kalai, Kanade and Mansour (2012) where the learner is given access to a distribution $\\mathcal{D}$ on labeled examples but the labeling may be arbitrary.  We construct a hypothesis that simultaneously minimizes the false-positive rate and the loss on inputs given positive labels by $\\mathcal{D}$, for any convex, bounded, and Lipschitz loss function. The algorithm runs in polynomial-time (in $n$) with respect to \\em any distribution on $\\mathbb{S}^n-1$ (the unit sphere in $n$ dimensions) and for any error parameter $\u03b5= \u03a9(1 / \\log n)$ (this yields a PTAS for a question raised by F. Bach on the complexity of maximizing ReLUs).  These results are in contrast to known efficient algorithms for reliably learning linear threshold functions, where $\u03b5$ must be $\u03a9(1)$ and strong assumptions are required on the marginal distribution. We can compose our results to obtain the first set of efficient algorithms for learning constant-depth networks of ReLU with fixed polynomial-dependence in the dimension. For depth-2 networks of sigmoids, we obtain the first algorithms that have a polynomial dependency in \\em all parameters. Our techniques combine kernel methods and polynomial approximations with a \u201cdual-loss\u201d approach to convex programming. As a byproduct we obtain a number of applications including the first set of efficient algorithms for \u201cconvex piecewise-linear fitting\u201d and the first efficient algorithms for noisy polynomial reconstruction of low-weight polynomials on the unit sphere. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/goel17a/goel17a.pdf",
        "supp": "",
        "pdf_size": 466203,
        "gs_citation": 149,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12760509511767609434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of Texas at Austin; University of Oxford and Alan Turing Institute; University of Texas at Austin; Georgetown University",
        "aff_domain": "cs.utexas.edu;cs.ox.ac.uk;cs.utexas.edu;georgetown.edu",
        "email": "cs.utexas.edu;cs.ox.ac.uk;cs.utexas.edu;georgetown.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Texas at Austin;University of Oxford;Georgetown University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.utexas.edu;https://www.ox.ac.uk;https://www.georgetown.edu",
        "aff_unique_abbr": "UT Austin;Oxford;GU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Austin;Oxford;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "d509fc9ab4",
        "title": "Robust and Proper Learning for Mixtures of Gaussians via Systems of Polynomial Inequalities",
        "site": "https://proceedings.mlr.press/v65/li17a.html",
        "author": "Jerry Li; Ludwig Schmidt",
        "abstract": "Learning a Gaussian mixture model (GMM) is a fundamental statistical problem. One common notion of learning a GMM is proper learning: here, the goal is to find a mixture of $k$ Gaussians $\\mathcal{M}$ that is close to the unknown density $f$ from which we draw samples. The distance between $\\mathcal{M}$ and $f$ is often measured in the total variation / $L_1$-distance. Our main result is an algorithm for learning a mixture of $k$ univariate Gaussians that is \\emphnearly-optimal for any fixed $k$.  It is well known that the sample complexity of properly learning a univariate $k$-GMM is $O(k / \u03b5^2)$.  However, the best prior \\emphrunning time for this problem is $\\widetilde{O}(1 / \u03b5^3k-1)$; in particular, the dependence between $1/\u03b5$ and $k$ is exponential.  In this paper, we significantly improve this dependence by replacing the $1/\u03b5$ term with $\\log 1/\u03b5$, while only increasing the exponent moderately.  Specifically, the running time of our algorithm is $(k \u22c5\\log 1/ \u03b5)^O(k^4) + \\widetilde{O}(k / \u03b5^2)$.  For any fixed $k$, the $\\widetilde{O}(k / \u03b5^2)$ term dominates our running time, and thus our algorithm runs in time which is \\emphnearly-linear in the number of samples drawn.  Achieving a running time of $\\text{poly}(k, 1 / \u03b5)$ for proper learning of $k$-GMMs has recently been stated as an open problem by multiple researchers, and we make progress on this question. Our main algorithmic ingredient is a new connection between proper learning of parametric distributions and systems of polynomial inequalities.  We leverage results for piecewise polynomial approximation of GMMs and reduce the learning problem to a much smaller sub-problem.  While tihs sub-problem is still non-convex, its size depends only logarithmically on the final accuracy $\u03b5$.  Hence we can invoke computationally expensive methods for solving the sub-problem. We show that our connection is also useful in the multivariate setting, where we get new results for learning a mixture of two spherical Gaussians.  A variant of our approach is also within reach of modern computer algebra systems.  Experiments for learning a 2-GMM show promising results: our algorithm improves over the popular Expectation-Maximization (EM) algorithm in the noisy setting.",
        "bibtex": "@InProceedings{pmlr-v65-li17a,\n  title = \t {Robust and Proper Learning for Mixtures of Gaussians via Systems of Polynomial Inequalities},\n  author = \t {Li, Jerry and Schmidt, Ludwig},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1302--1382},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/li17a/li17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/li17a.html},\n  abstract = \t {Learning a Gaussian mixture model (GMM) is a fundamental statistical problem. One common notion of learning a GMM is proper learning: here, the goal is to find a mixture of $k$ Gaussians $\\mathcal{M}$ that is close to the unknown density $f$ from which we draw samples. The distance between $\\mathcal{M}$ and $f$ is often measured in the total variation / $L_1$-distance. Our main result is an algorithm for learning a mixture of $k$ univariate Gaussians that is \\emphnearly-optimal for any fixed $k$.  It is well known that the sample complexity of properly learning a univariate $k$-GMM is $O(k / \u03b5^2)$.  However, the best prior \\emphrunning time for this problem is $\\widetilde{O}(1 / \u03b5^3k-1)$; in particular, the dependence between $1/\u03b5$ and $k$ is exponential.  In this paper, we significantly improve this dependence by replacing the $1/\u03b5$ term with $\\log 1/\u03b5$, while only increasing the exponent moderately.  Specifically, the running time of our algorithm is $(k \u22c5\\log 1/ \u03b5)^O(k^4) + \\widetilde{O}(k / \u03b5^2)$.  For any fixed $k$, the $\\widetilde{O}(k / \u03b5^2)$ term dominates our running time, and thus our algorithm runs in time which is \\emphnearly-linear in the number of samples drawn.  Achieving a running time of $\\text{poly}(k, 1 / \u03b5)$ for proper learning of $k$-GMMs has recently been stated as an open problem by multiple researchers, and we make progress on this question. Our main algorithmic ingredient is a new connection between proper learning of parametric distributions and systems of polynomial inequalities.  We leverage results for piecewise polynomial approximation of GMMs and reduce the learning problem to a much smaller sub-problem.  While tihs sub-problem is still non-convex, its size depends only logarithmically on the final accuracy $\u03b5$.  Hence we can invoke computationally expensive methods for solving the sub-problem. We show that our connection is also useful in the multivariate setting, where we get new results for learning a mixture of two spherical Gaussians.  A variant of our approach is also within reach of modern computer algebra systems.  Experiments for learning a 2-GMM show promising results: our algorithm improves over the popular Expectation-Maximization (EM) algorithm in the noisy setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/li17a/li17a.pdf",
        "supp": "",
        "pdf_size": 769271,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13096631208226846539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Massachusetts Institute of Technology, Cambridge, MA, 02139, USA",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f7abcb03bd",
        "title": "Sample complexity of population recovery",
        "site": "https://proceedings.mlr.press/v65/polyanskiy17a.html",
        "author": "Yury Polyanskiy; Ananda Theertha Suresh; Yihong Wu",
        "abstract": "The problem of population recovery refers to estimating a distribution based on incomplete or corrupted samples.  Consider a random poll of sample size $n$ conducted on a population of individuals, where each pollee is asked to answer $d$ binary questions.  We consider one of the two polling impediments: \\beginitemize \\item in lossy population recovery, a pollee may skip each question with probability $\u03b5$; \\item in noisy population recovery, a pollee may lie on each question with probability $\u03b5$. \\enditemize Given $n$ lossy or noisy samples, the goal is to estimate the probabilities of all $2^d$ binary vectors simultaneously within accuracy $\u03b4$ with high probability. This paper settles the sample complexity of population recovery.  For lossy model, the optimal sample complexity is $\\tilde\u0398(\u03b4^ -2\\max{\\frac\u03b51-\u03b5,1})$, improving the state of the art by Moitra and Saks in several ways: a lower bound is established, the upper bound is improved and the result is dimension-free. Surprisingly, the sample complexity undergoes a phase transition from parametric to nonparametric rate when $\u03b5$ exceeds $1/2$. For noisy population recovery, the sharp sample complexity turns out to be dimension-dependent and scales as $\\exp(\u0398(d^1/3 \\log^2/3(1/\u03b4)))$ except for the trivial cases of $\u03b5=0,1/2$ or $1$. For both models, our estimators simply compute the empirical mean of a certain function, which is found by pre-solving a linear program (LP). Curiously, the dual LP can be understood as Le Cam\u2019s method for lower-bounding the minimax risk, thus establishing the statistical optimality of the proposed estimators. The value of the LP is determined by complex-analytic methods.",
        "bibtex": "@InProceedings{pmlr-v65-polyanskiy17a,\n  title = \t {Sample complexity of population recovery},\n  author = \t {Polyanskiy, Yury and Suresh, Ananda Theertha and Wu, Yihong},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1589--1618},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/polyanskiy17a/polyanskiy17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/polyanskiy17a.html},\n  abstract = \t {The problem of population recovery refers to estimating a distribution based on incomplete or corrupted samples.  Consider a random poll of sample size $n$ conducted on a population of individuals, where each pollee is asked to answer $d$ binary questions.  We consider one of the two polling impediments: \\beginitemize \\item in lossy population recovery, a pollee may skip each question with probability $\u03b5$; \\item in noisy population recovery, a pollee may lie on each question with probability $\u03b5$. \\enditemize Given $n$ lossy or noisy samples, the goal is to estimate the probabilities of all $2^d$ binary vectors simultaneously within accuracy $\u03b4$ with high probability. This paper settles the sample complexity of population recovery.  For lossy model, the optimal sample complexity is $\\tilde\u0398(\u03b4^ -2\\max{\\frac\u03b51-\u03b5,1})$, improving the state of the art by Moitra and Saks in several ways: a lower bound is established, the upper bound is improved and the result is dimension-free. Surprisingly, the sample complexity undergoes a phase transition from parametric to nonparametric rate when $\u03b5$ exceeds $1/2$. For noisy population recovery, the sharp sample complexity turns out to be dimension-dependent and scales as $\\exp(\u0398(d^1/3 \\log^2/3(1/\u03b4)))$ except for the trivial cases of $\u03b5=0,1/2$ or $1$. For both models, our estimators simply compute the empirical mean of a certain function, which is found by pre-solving a linear program (LP). Curiously, the dual LP can be understood as Le Cam\u2019s method for lower-bounding the minimax risk, thus establishing the statistical optimality of the proposed estimators. The value of the LP is determined by complex-analytic methods. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/polyanskiy17a/polyanskiy17a.pdf",
        "supp": "",
        "pdf_size": 609886,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6360474801336891909&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of EECS, MIT, Cambridge, MA, USA; Google Research, New York, NY, USA; Department of Statistics and Data Science, Yale University, New Haven, CT, USA",
        "aff_domain": "mit.edu;google.com;yale.edu",
        "email": "mit.edu;google.com;yale.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google;Yale University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Google Research;Department of Statistics and Data Science",
        "aff_unique_url": "https://web.mit.edu;https://research.google;https://www.yale.edu",
        "aff_unique_abbr": "MIT;Google Research;Yale",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Cambridge;New York;New Haven",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0a4cf33492",
        "title": "Sampling from a log-concave distribution with compact support with proximal Langevin Monte Carlo",
        "site": "https://proceedings.mlr.press/v65/brosse17a.html",
        "author": "Nicolas Brosse; Alain Durmus; \u00c9ric Moulines; Marcelo Pereyra",
        "abstract": "This paper presents a detailed theoretical analysis of the Langevin Monte Carlo sampling algorithm recently introduced in Durmus et al. (Efficient Bayesian computation by proximal Markov chain Monte Carlo: when Langevin meets Moreau, 2016) when applied to log-concave probability distributions that are restricted to a convex body $K$. This method relies on a regularisation procedure involving the Moreau-Yosida envelope of the indicator function associated with $K$. Explicit convergence bounds in total variation norm and in Wasserstein distance of order $1$ are established. In particular, we show that the complexity of this algorithm given a first order oracle is polynomial in the dimension of the state space. Finally, some numerical experiments are presented to compare our method with competing MCMC approaches from the literature.",
        "bibtex": "@InProceedings{pmlr-v65-brosse17a,\n  title = \t {Sampling from a log-concave distribution with compact support with proximal Langevin Monte Carlo},\n  author = \t {Brosse, Nicolas and Durmus, Alain and Moulines, \u00c9ric and Pereyra, Marcelo},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {319--342},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/brosse17a/brosse17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/brosse17a.html},\n  abstract = \t { This paper presents a detailed theoretical analysis of the Langevin Monte Carlo sampling algorithm recently introduced in Durmus et al. (Efficient Bayesian computation by proximal Markov chain Monte Carlo: when Langevin meets Moreau, 2016) when applied to log-concave probability distributions that are restricted to a convex body $K$. This method relies on a regularisation procedure involving the Moreau-Yosida envelope of the indicator function associated with $K$. Explicit convergence bounds in total variation norm and in Wasserstein distance of order $1$ are established. In particular, we show that the complexity of this algorithm given a first order oracle is polynomial in the dimension of the state space. Finally, some numerical experiments are presented to compare our method with competing MCMC approaches from the literature.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/brosse17a/brosse17a.pdf",
        "supp": "",
        "pdf_size": 488696,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7544021756888583766&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Centre de Mathematiques Appliquees, UMR 7641, Ecole Polytechnique, France; LTCI, Telecom ParisTech 46 rue Barrault, 75634 Paris Cedex 13, France; Centre de Mathematiques Appliquees, UMR 7641, Ecole Polytechnique, France; School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, EH14 4AS, U.K.",
        "aff_domain": "polytechnique.edu;telecom-paristech.fr;polytechnique.edu;hw.ac.uk",
        "email": "polytechnique.edu;telecom-paristech.fr;polytechnique.edu;hw.ac.uk",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Ecole Polytechnique;Telecom ParisTech;Heriot-Watt University",
        "aff_unique_dep": "Centre de Mathematiques Appliquees;LTCI;School of Mathematical and Computer Sciences",
        "aff_unique_url": "https://www.polytechnique.edu;https://www.telecom-paristech.fr;https://www.hw.ac.uk",
        "aff_unique_abbr": "Polytechnique;Telecom ParisTech;HWU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Paris;Edinburgh",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "562ce355d6",
        "title": "Solving SDPs for synchronization and MaxCut problems via the Grothendieck inequality",
        "site": "https://proceedings.mlr.press/v65/mei17a.html",
        "author": "Song Mei; Theodor Misiakiewicz; Andrea Montanari; Roberto Imbuzeiro Oliveira",
        "abstract": "A number of statistical estimation problems can be addressed by semidefinite programs (SDP). While SDPs are solvable in polynomial time using interior point methods, in practice generic SDP solvers do not scale well to high-dimensional problems. In order to cope with this problem, Burer and Monteiro proposed a non-convex rank-constrained formulation, which has good performance in practice but is still poorly understood theoretically. In this paper we study the rank-constrained version of SDPs arising in MaxCut and in $\\mathbb Z_2$ and $\\rm SO(d)$ synchronization problems. We establish a Grothendieck-type inequality that proves that all the local maxima and  dangerous saddle points are within a small multiplicative gap from the global maximum. We use this structural information to prove that SDPs can be solved within a known accuracy, by applying the Riemannian trust-region method to this non-convex problem, while constraining the rank to be  of order one. For the MaxCut problem, our inequality implies that any local maximizer of the rank-constrained SDP provides a $(1 - 1/(k-1)) \\times 0.878$ approximation of the MaxCut, when the rank is fixed to $k$. We then apply our results to data matrices generated according to the Gaussian $\\mathbb Z_2$ synchronization problem, and the two-groups stochastic block model with large bounded degree. We prove that the error achieved by local maximizers undergoes a phase transition at the same threshold as for information-theoretically optimal methods.",
        "bibtex": "@InProceedings{pmlr-v65-mei17a,\n  title = \t {Solving SDPs for synchronization and MaxCut problems via the Grothendieck inequality},\n  author = \t {Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea and Oliveira, Roberto Imbuzeiro},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1476--1515},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/mei17a/mei17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/mei17a.html},\n  abstract = \t { A number of statistical estimation problems can be addressed by semidefinite programs (SDP). While SDPs are solvable in polynomial time using interior point methods, in practice generic SDP solvers do not scale well to high-dimensional problems. In order to cope with this problem, Burer and Monteiro proposed a non-convex rank-constrained formulation, which has good performance in practice but is still poorly understood theoretically. In this paper we study the rank-constrained version of SDPs arising in MaxCut and in $\\mathbb Z_2$ and $\\rm SO(d)$ synchronization problems. We establish a Grothendieck-type inequality that proves that all the local maxima and  dangerous saddle points are within a small multiplicative gap from the global maximum. We use this structural information to prove that SDPs can be solved within a known accuracy, by applying the Riemannian trust-region method to this non-convex problem, while constraining the rank to be  of order one. For the MaxCut problem, our inequality implies that any local maximizer of the rank-constrained SDP provides a $(1 - 1/(k-1)) \\times 0.878$ approximation of the MaxCut, when the rank is fixed to $k$. We then apply our results to data matrices generated according to the Gaussian $\\mathbb Z_2$ synchronization problem, and the two-groups stochastic block model with large bounded degree. We prove that the error achieved by local maximizers undergoes a phase transition at the same threshold as for information-theoretically optimal methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/mei17a/mei17a.pdf",
        "supp": "",
        "pdf_size": 766842,
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2243863601407162853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Institute for Computational and Mathematical Engineering, Stanford University; Departement de Physique, Ecole Normale Sup\u00e9rieure; Department of Electrical Engineering and Department of Statistics, Stanford University; Instituto Nacional de Matem\u00e1tica Pura e Aplicada (IMPA)",
        "aff_domain": "stanford.edu;ens.fr;stanford.edu;impa.br",
        "email": "stanford.edu;ens.fr;stanford.edu;impa.br",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Stanford University;Ecole Normale Sup\u00e9rieure;Instituto Nacional de Matem\u00e1tica Pura e Aplicada",
        "aff_unique_dep": "Institute for Computational and Mathematical Engineering;Departement de Physique;",
        "aff_unique_url": "https://www.stanford.edu;https://www.ens.fr;http://www.impa.br",
        "aff_unique_abbr": "Stanford;ENS;IMPA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;1;0;2",
        "aff_country_unique": "United States;France;Brazil"
    },
    {
        "id": "871a013edd",
        "title": "Sparse Stochastic Bandits",
        "site": "https://proceedings.mlr.press/v65/kwon17a.html",
        "author": "Joon Kwon; Vianney Perchet; Claire Vernade",
        "abstract": "In the classical multi-armed bandit problem, $d$ arms are available to the decision maker who pulls them sequentially in order to maximize his cumulative reward. Guarantees can be obtained on a relative quantity called regret, which scales linearly with $d$ (or with $\\sqrt{d}$ in the minimax sense). We here consider the \\emphsparse case of this classical problem in the sense that only a small number of arms, namely $s",
        "bibtex": "@InProceedings{pmlr-v65-kwon17a,\n  title = \t {Sparse Stochastic Bandits},\n  author = \t {Kwon, Joon and Perchet, Vianney and Vernade, Claire},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1269--1270},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/kwon17a/kwon17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/kwon17a.html},\n  abstract = \t {In the classical multi-armed bandit problem, $d$ arms are available to the decision maker who pulls them sequentially in order to maximize his cumulative reward. Guarantees can be obtained on a relative quantity called regret, which scales linearly with $d$ (or with $\\sqrt{d}$ in the minimax sense). We here consider the \\emphsparse case of this classical problem in the sense that only a small number of arms, namely $s",
        "pdf": "http://proceedings.mlr.press/v65/kwon17a/kwon17a.pdf",
        "supp": "",
        "pdf_size": 128840,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=701894210549023514&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "CMAP, \u00c9cole polytechnique, Universit\u00e9 Paris\u2013Saclay; CMLA, \u00c9cole Normale Sup\u00e9rieure Paris\u2013Saclay & Criteo Research, Paris; LTCI, T\u00e9l\u00e9com ParisTech",
        "aff_domain": "ens-lyon.org;normalesup.org;telecom-paristech.fr",
        "email": "ens-lyon.org;normalesup.org;telecom-paristech.fr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Ecole Polytechnique;\u00c9cole Normale Sup\u00e9rieure Paris\u2013Saclay;T\u00e9l\u00e9com ParisTech",
        "aff_unique_dep": "CMAP;CMLA;LTCI",
        "aff_unique_url": "https://www.ensae.fr/;https://www.ensparis-saclay.fr;https://www.telecom-paris.fr",
        "aff_unique_abbr": "\u00c9cole polytechnique;ENS Paris-Saclay;T\u00e9l\u00e9com ParisTech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Paris\u2013Saclay;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "264f87d582",
        "title": "Square Hellinger Subadditivity for Bayesian Networks and its Applications to Identity Testing",
        "site": "https://proceedings.mlr.press/v65/daskalakis17a.html",
        "author": "Constantinos Daskalakis; Qinxuan Pan",
        "abstract": "We show that the square Hellinger distance between two Bayesian networks on the same directed graph, $G$, is subadditive with respect to the neighborhoods of $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two Bayesian networks on the same DAG, our inequality states that the square Hellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the sum, $\\sum_v H^2(P_{v} \u222a\\Pi_v, Q_{v} \u222a\\Pi_v)$, of the square Hellinger distances between the marginals of $P$ and $Q$ on every node $v$ and its parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the conditionals but the marginals of $P$ and $Q$. We derive a similar inequality for more general Markov Random Fields. As an application of our inequality, we show that distinguishing whether two (unknown) Bayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy $P=Q$ vs $d_\\rm TV(P,Q)>\u03b5$ can be performed from $\\tilde{O}(|\u03a3|^3/4(d+1) \u22c5n/\u03b5^2)$ samples, where $d$ is the maximum in-degree of the DAG and $\u03a3$ the domain of each variable of the Bayesian networks. If $P$ and $Q$ are defined on potentially different and potentially unknown trees, the sample complexity becomes $\\tilde{O}(|\u03a3|^4.5 n/\u03b5^2)$. In both cases the dependence of the sample complexity on $n, \u03b5$ is optimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product distributions over ${0,1}^n$ and $Q$ is known, the sample complexity becomes $O(\\sqrt{n}/\u03b5^2)$, which is optimal up to constant factors.",
        "bibtex": "@InProceedings{pmlr-v65-daskalakis17a,\n  title = \t {Square Hellinger Subadditivity for Bayesian Networks and its Applications to Identity Testing},\n  author = \t {Daskalakis, Constantinos and Pan, Qinxuan},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {697--703},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/daskalakis17a/daskalakis17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/daskalakis17a.html},\n  abstract = \t {We show that the square Hellinger distance between two Bayesian networks on the same directed graph, $G$, is subadditive with respect to the neighborhoods of $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two Bayesian networks on the same DAG, our inequality states that the square Hellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the sum, $\\sum_v H^2(P_{v} \u222a\\Pi_v, Q_{v} \u222a\\Pi_v)$, of the square Hellinger distances between the marginals of $P$ and $Q$ on every node $v$ and its parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the conditionals but the marginals of $P$ and $Q$. We derive a similar inequality for more general Markov Random Fields. As an application of our inequality, we show that distinguishing whether two (unknown) Bayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy $P=Q$ vs $d_\\rm TV(P,Q)>\u03b5$ can be performed from $\\tilde{O}(|\u03a3|^3/4(d+1) \u22c5n/\u03b5^2)$ samples, where $d$ is the maximum in-degree of the DAG and $\u03a3$ the domain of each variable of the Bayesian networks. If $P$ and $Q$ are defined on potentially different and potentially unknown trees, the sample complexity becomes $\\tilde{O}(|\u03a3|^4.5 n/\u03b5^2)$. In both cases the dependence of the sample complexity on $n, \u03b5$ is optimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product distributions over ${0,1}^n$ and $Q$ is known, the sample complexity becomes $O(\\sqrt{n}/\u03b5^2)$, which is optimal up to constant factors.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/daskalakis17a/daskalakis17a.pdf",
        "supp": "",
        "pdf_size": 199701,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=280360598016641932&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "EECS and CSAIL, MIT; EECS and CSAIL, MIT",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "https://arxiv.org/abs/1612.03164",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Electrical Engineering & Computer Science and Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c0691b07f0",
        "title": "Stochastic Composite Least-Squares Regression with Convergence Rate $O(1/n)$",
        "site": "https://proceedings.mlr.press/v65/flammarion17a.html",
        "author": "Nicolas Flammarion; Francis Bach",
        "abstract": "We consider the minimization of composite objective functions composed of the expectation of quadratic functions and an arbitrary convex function. We study the stochastic dual averaging algorithm with a constant step-size, showing that it leads to a convergence rate of O(1/n) without strong convexity assumptions. This thus extends earlier results on least-squares regression with the Euclidean geometry to (a) all convex regularizers and constraints, and (b) all geometries represented by a Bregman divergence. This is achieved by a new proof technique that relates stochastic and deterministic recursions",
        "bibtex": "@InProceedings{pmlr-v65-flammarion17a,\n  title = \t {Stochastic Composite Least-Squares Regression with Convergence Rate $O(1/n)$},\n  author = \t {Flammarion, Nicolas and Bach, Francis},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {831--875},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/flammarion17a/flammarion17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/flammarion17a.html},\n  abstract = \t {We consider the minimization of composite objective functions composed of the expectation of quadratic functions and an arbitrary convex function. We study the stochastic dual averaging algorithm with a constant step-size, showing that it leads to a convergence rate of O(1/n) without strong convexity assumptions. This thus extends earlier results on least-squares regression with the Euclidean geometry to (a) all convex regularizers and constraints, and (b) all geometries represented by a Bregman divergence. This is achieved by a new proof technique that relates stochastic and deterministic recursions}\n}",
        "pdf": "http://proceedings.mlr.press/v65/flammarion17a/flammarion17a.pdf",
        "supp": "",
        "pdf_size": 560631,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14290510051191074679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "INRIA - Sierra Project-team + D\u00b4epartement d\u2019Informatique de l\u2019Ecole Normale Sup \u00b4erieure (CNRS - ENS - INRIA); INRIA - Sierra Project-team + D\u00b4epartement d\u2019Informatique de l\u2019Ecole Normale Sup \u00b4erieure (CNRS - ENS - INRIA)",
        "aff_domain": "ENS.FR;ENS.FR",
        "email": "ENS.FR;ENS.FR",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "INRIA;Ecole Normale Sup\u00e9rieure",
        "aff_unique_dep": "Sierra Project-team;D\u00e9partement d\u2019Informatique",
        "aff_unique_url": "https://www.inria.fr;https://www.ens.fr",
        "aff_unique_abbr": "INRIA;ENS",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "France"
    },
    {
        "id": "123de0332a",
        "title": "Submodular Optimization under Noise",
        "site": "https://proceedings.mlr.press/v65/hassidim17a.html",
        "author": "Avinatan Hassidim; Yaron Singer",
        "abstract": "We consider the problem of maximizing a monotone submodular function under noise.  Since the 1970s there has been a great deal of work on optimization of submodular functions under various constraints, resulting in algorithms that provide desirable approximation guarantees.  In many applications, however, we do not have access to the submodular function we aim to optimize, but rather to some erroneous or noisy version of it.  This raises the question of whether provable guarantees are obtainable in the presence of error and noise. We provide initial answers by focusing on the problem of maximizing a monotone submodular function under a cardinality constraint when given access to a noisy oracle of the function.  We show that there is an algorithm whose approximation ratio is arbitrarily close to the optimal $1-1/e$ when the cardinality is sufficiently large.  The algorithm can be applied in a variety of related problems including maximizing approximately submodular functions, and optimization with correlated noise.  When the noise is adversarial we show that no non-trivial approximation guarantee can be obtained.",
        "bibtex": "@InProceedings{pmlr-v65-hassidim17a,\n  title = \t {Submodular Optimization under Noise},\n  author = \t {Hassidim, Avinatan and Singer, Yaron},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1069--1122},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/hassidim17a/hassidim17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/hassidim17a.html},\n  abstract = \t {We consider the problem of maximizing a monotone submodular function under noise.  Since the 1970s there has been a great deal of work on optimization of submodular functions under various constraints, resulting in algorithms that provide desirable approximation guarantees.  In many applications, however, we do not have access to the submodular function we aim to optimize, but rather to some erroneous or noisy version of it.  This raises the question of whether provable guarantees are obtainable in the presence of error and noise. We provide initial answers by focusing on the problem of maximizing a monotone submodular function under a cardinality constraint when given access to a noisy oracle of the function.  We show that there is an algorithm whose approximation ratio is arbitrarily close to the optimal $1-1/e$ when the cardinality is sufficiently large.  The algorithm can be applied in a variety of related problems including maximizing approximately submodular functions, and optimization with correlated noise.  When the noise is adversarial we show that no non-trivial approximation guarantee can be obtained.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/hassidim17a/hassidim17a.pdf",
        "supp": "",
        "pdf_size": 585877,
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2502057030850210893&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Bar Ilan University+Google; Harvard University",
        "aff_domain": "CS.BIU.AC.IL;SEAS.HARVARD.EDU",
        "email": "CS.BIU.AC.IL;SEAS.HARVARD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2",
        "aff_unique_norm": "Bar-Ilan University;Google;Harvard University",
        "aff_unique_dep": ";Google;",
        "aff_unique_url": "https://www.biu.ac.il;https://www.google.com;https://www.harvard.edu",
        "aff_unique_abbr": "BIU;Google;Harvard",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0+1;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "fa8dd7977a",
        "title": "Surprising properties of dropout in deep networks",
        "site": "https://proceedings.mlr.press/v65/helmbold17a.html",
        "author": "David P. Helmbold; Philip M. Long",
        "abstract": "We analyze dropout in deep networks with rectified linear units and the quadratic loss. Our results expose surprising differences between the behavior of dropout and more traditional regularizers like weight decay. For example, on some simple data sets dropout training produces negative weights even though the output is the sum of the inputs. This provides a counterpoint to the suggestion that dropout discourages co-adaptation of weights. We also  show that the dropout penalty can grow exponentially in the depth of the network while the weight-decay penalty remains essentially linear, and that dropout is insensitive to various re-scalings of the input features, outputs, and network weights. This last insensitivity implies that there are no isolated local minima of the dropout training criterion. Our work uncovers new properties of dropout, extends our understanding of why dropout succeeds, and lays the foundation for further progress.",
        "bibtex": "@InProceedings{pmlr-v65-helmbold17a,\n  title = \t {Surprising properties of dropout in deep networks},\n  author = \t {Helmbold, David P. and Long, Philip M.},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1123--1146},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/helmbold17a/helmbold17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/helmbold17a.html},\n  abstract = \t {We analyze dropout in deep networks with rectified linear units and the quadratic loss. Our results expose surprising differences between the behavior of dropout and more traditional regularizers like weight decay. For example, on some simple data sets dropout training produces negative weights even though the output is the sum of the inputs. This provides a counterpoint to the suggestion that dropout discourages co-adaptation of weights. We also  show that the dropout penalty can grow exponentially in the depth of the network while the weight-decay penalty remains essentially linear, and that dropout is insensitive to various re-scalings of the input features, outputs, and network weights. This last insensitivity implies that there are no isolated local minima of the dropout training criterion. Our work uncovers new properties of dropout, extends our understanding of why dropout succeeds, and lays the foundation for further progress.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/helmbold17a/helmbold17a.pdf",
        "supp": "",
        "pdf_size": 378194,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2187947446801503343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Computer Science, University of California, Santa Cruz; Google",
        "aff_domain": "SOE.UCSC.EDU;GOOGLE.COM",
        "email": "SOE.UCSC.EDU;GOOGLE.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Santa Cruz;Google",
        "aff_unique_dep": "Department of Computer Science;Google",
        "aff_unique_url": "https://www.ucsc.edu;https://www.google.com",
        "aff_unique_abbr": "UCSC;Google",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Santa Cruz;Mountain View",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9ce205f28e",
        "title": "Ten Steps of EM Suffice for Mixtures of Two Gaussians",
        "site": "https://proceedings.mlr.press/v65/daskalakis17b.html",
        "author": "Constantinos Daskalakis; Christos Tzamos; Manolis Zampetakis",
        "abstract": "The Expectation-Maximization (EM) algorithm is a widely used method for maximum likelihood estimation in models with latent variables. For estimating mixtures of Gaussians, its iteration can be viewed as a soft version of the k-means clustering algorithm. Despite its wide use and applications, there are essentially no known convergence guarantees for this method. We provide global convergence guarantees for  mixtures of two Gaussians with known covariance matrices. We show that the population version of EM, where the algorithm is given access to infinitely many samples from the mixture, converges geometrically to the correct mean vectors, and provide simple, closed-form expressions for the convergence rate. As a simple illustration, we show that, in one dimension, ten steps of the EM algorithm initialized at infinity result in less than $1%$ error estimation of the means. In the finite sample regime, we show that, under a random initialization, $\\tilde{O}(d/\u03b5^2)$ samples suffice to compute the unknown vectors to within $\u03b5$ in Mahalanobis distance, where $d$ is the dimension. In particular, the error rate of the EM based estimator is $\\tilde{O}\\left(\\sqrt{d} \\over n\\right)$ where $n$ is the number of samples, which is optimal up to logarithmic factors.",
        "bibtex": "@InProceedings{pmlr-v65-daskalakis17b,\n  title = \t {Ten Steps of EM Suffice for Mixtures of Two Gaussians},\n  author = \t {Daskalakis, Constantinos and Tzamos, Christos and Zampetakis, Manolis},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {704--710},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/daskalakis17b/daskalakis17b.pdf},\n  url = \t {https://proceedings.mlr.press/v65/daskalakis17b.html},\n  abstract = \t {The Expectation-Maximization (EM) algorithm is a widely used method for maximum likelihood estimation in models with latent variables. For estimating mixtures of Gaussians, its iteration can be viewed as a soft version of the k-means clustering algorithm. Despite its wide use and applications, there are essentially no known convergence guarantees for this method. We provide global convergence guarantees for  mixtures of two Gaussians with known covariance matrices. We show that the population version of EM, where the algorithm is given access to infinitely many samples from the mixture, converges geometrically to the correct mean vectors, and provide simple, closed-form expressions for the convergence rate. As a simple illustration, we show that, in one dimension, ten steps of the EM algorithm initialized at infinity result in less than $1%$ error estimation of the means. In the finite sample regime, we show that, under a random initialization, $\\tilde{O}(d/\u03b5^2)$ samples suffice to compute the unknown vectors to within $\u03b5$ in Mahalanobis distance, where $d$ is the dimension. In particular, the error rate of the EM based estimator is $\\tilde{O}\\left(\\sqrt{d} \\over n\\right)$ where $n$ is the number of samples, which is optimal up to logarithmic factors.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/daskalakis17b/daskalakis17b.pdf",
        "supp": "",
        "pdf_size": 426911,
        "gs_citation": 155,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12231039515737483022&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "EECS and CSAIL, MIT; EECS and CSAIL, MIT; EECS and CSAIL, MIT",
        "aff_domain": "MIT.EDU;GMAIL.COM;MIT.EDU",
        "email": "MIT.EDU;GMAIL.COM;MIT.EDU",
        "github": "",
        "project": "arXiv:1609.00368",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Electrical Engineering & Computer Science and Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "87a931359f",
        "title": "Testing Bayesian Networks",
        "site": "https://proceedings.mlr.press/v65/canonne17a.html",
        "author": "Clement L. Canonne; Ilias Diakonikolas; Daniel M. Kane; Alistair Stewart",
        "abstract": "This work initiates a systematic investigation of testing \\em high-dimensional structured distributions by focusing on testing \\em Bayesian networks \u2013 the prototypical family of directed graphical models. A Bayesian network is defined by a directed acyclic graph, where we associate a random variable with each node. The value at any particular node is conditionally independent of all the other non-descendant nodes once its parents are fixed. Specifically, we study the properties of identity testing and closeness testing of Bayesian networks. Our main contribution is the first non-trivial efficient testing algorithms for these problems and corresponding information-theoretic lower bounds. For a wide range of parameter settings, our testing algorithms have sample complexity \\em sublinear in the dimension and are sample-optimal, up to constant factors.",
        "bibtex": "@InProceedings{pmlr-v65-canonne17a,\n  title = \t {Testing Bayesian Networks},\n  author = \t {Canonne, Clement L. and Diakonikolas, Ilias and Kane, Daniel M. and Stewart, Alistair},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {370--448},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/canonne17a/canonne17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/canonne17a.html},\n  abstract = \t {This work initiates a systematic investigation of testing \\em high-dimensional structured distributions by focusing on testing \\em Bayesian networks \u2013 the prototypical family of directed graphical models. A Bayesian network is defined by a directed acyclic graph, where we associate a random variable with each node. The value at any particular node is conditionally independent of all the other non-descendant nodes once its parents are fixed. Specifically, we study the properties of identity testing and closeness testing of Bayesian networks. Our main contribution is the first non-trivial efficient testing algorithms for these problems and corresponding information-theoretic lower bounds. For a wide range of parameter settings, our testing algorithms have sample complexity \\em sublinear in the dimension and are sample-optimal, up to constant factors.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/canonne17a/canonne17a.pdf",
        "supp": "",
        "pdf_size": 642220,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13294372330123632134&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Columbia University; University of Southern California; University of California, San Diego; University of Southern California",
        "aff_domain": "CS.COLUMBIA.EDU;USC.EDU;CS.UCSD.EDU;GMAIL.COM",
        "email": "CS.COLUMBIA.EDU;USC.EDU;CS.UCSD.EDU;GMAIL.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Columbia University;University of Southern California;University of California, San Diego",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.columbia.edu;https://www.usc.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "Columbia;USC;UCSD",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Los Angeles;San Diego",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "539ae75063",
        "title": "The Hidden Hubs Problem",
        "site": "https://proceedings.mlr.press/v65/kannan17a.html",
        "author": "Ravindran Kannan; Santosh Vempala",
        "abstract": "We introduce the following \\em hidden hubs model $H(n,k,\\sigma_0, \\sigma_1)$: the input is an $n \\times n$ random matrix $A$ with a subset $S$ of $k$ special rows (hubs); entries in rows outside $S$ are generated from the Gaussian distribution $p_0 = N(0,\\sigma_0^2)$, while for each row in $S$, an unknown subset of $k$ of its entries are generated from $p_1 = N(0,\\sigma_1^2)$, $\\sigma_1>\\sigma_0$, and the rest of the entries from $p_0$. The special rows with higher variance entries can be viewed as hidden higher-degree hubs. The problem we address is to identify the hubs efficiently. The planted Gaussian Submatrix Model is the special case where the higher variance entries must all lie in a $k \\times k$ submatrix. If $k\u2265c\\sqrt{n}\\ln n$, just the row sums are sufficient to find $S$ in the general model. For the Gaussian submatrix problem (and the related planted clique problem), this can be improved by a $\\sqrt\\ln n$ factor to $k \\ge c\\sqrt{n}$ by spectral or combinatorial methods. We give a polynomial-time algorithm to identify all the hidden hubs with high probability for $k \\ge n^0.5-\u03b4$ for some $\u03b4>0$, when $\\sigma_1^2>2\\sigma_0^2$.  The algorithm extends to the setting where planted entries might have different variances, each at least $\\sigma_1^2$. We also show a nearly matching lower bound: for $\\sigma_1^2 \\le 2\\sigma_0^2$, there is no polynomial-time Statistical Query algorithm for distinguishing between a matrix whose entries are all from $N(0,\\sigma_0^2)$ and a matrix with $k=n^0.5-\u03b4$ hidden hubs for any $\u03b4>0$. The lower bound as well as the algorithm are related to whether the chi-squared distance of the two distributions diverges. At the critical value $\\sigma_1^2=2\\sigma_0^2$, we show that the hidden hubs problem can be solved for $k\u2265c\\sqrt n(\\ln n)^1/4$, improving on the naive row sum-based method.",
        "bibtex": "@InProceedings{pmlr-v65-kannan17a,\n  title = \t {The Hidden Hubs Problem},\n  author = \t {Kannan, Ravindran and Vempala, Santosh},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1190--1213},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/kannan17a/kannan17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/kannan17a.html},\n  abstract = \t {We introduce the following \\em hidden hubs model $H(n,k,\\sigma_0, \\sigma_1)$: the input is an $n \\times n$ random matrix $A$ with a subset $S$ of $k$ special rows (hubs); entries in rows outside $S$ are generated from the Gaussian distribution $p_0 = N(0,\\sigma_0^2)$, while for each row in $S$, an unknown subset of $k$ of its entries are generated from $p_1 = N(0,\\sigma_1^2)$, $\\sigma_1>\\sigma_0$, and the rest of the entries from $p_0$. The special rows with higher variance entries can be viewed as hidden higher-degree hubs. The problem we address is to identify the hubs efficiently. The planted Gaussian Submatrix Model is the special case where the higher variance entries must all lie in a $k \\times k$ submatrix. If $k\u2265c\\sqrt{n}\\ln n$, just the row sums are sufficient to find $S$ in the general model. For the Gaussian submatrix problem (and the related planted clique problem), this can be improved by a $\\sqrt\\ln n$ factor to $k \\ge c\\sqrt{n}$ by spectral or combinatorial methods. We give a polynomial-time algorithm to identify all the hidden hubs with high probability for $k \\ge n^0.5-\u03b4$ for some $\u03b4>0$, when $\\sigma_1^2>2\\sigma_0^2$.  The algorithm extends to the setting where planted entries might have different variances, each at least $\\sigma_1^2$. We also show a nearly matching lower bound: for $\\sigma_1^2 \\le 2\\sigma_0^2$, there is no polynomial-time Statistical Query algorithm for distinguishing between a matrix whose entries are all from $N(0,\\sigma_0^2)$ and a matrix with $k=n^0.5-\u03b4$ hidden hubs for any $\u03b4>0$. The lower bound as well as the algorithm are related to whether the chi-squared distance of the two distributions diverges. At the critical value $\\sigma_1^2=2\\sigma_0^2$, we show that the hidden hubs problem can be solved for $k\u2265c\\sqrt n(\\ln n)^1/4$, improving on the naive row sum-based method.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/kannan17a/kannan17a.pdf",
        "supp": "",
        "pdf_size": 351946,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17669905484534634205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft Research India; School of Computer Science, Georgia Tech",
        "aff_domain": "MICROSOFT.COM;GATECH.EDU",
        "email": "MICROSOFT.COM;GATECH.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Microsoft;Georgia Institute of Technology",
        "aff_unique_dep": "Microsoft Research India;School of Computer Science",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-india;https://www.gatech.edu",
        "aff_unique_abbr": "MSR India;Georgia Tech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Atlanta",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "fabae8f9d5",
        "title": "The Price of Selection in Differential Privacy",
        "site": "https://proceedings.mlr.press/v65/bafna17a.html",
        "author": "Mitali Bafna; Jonathan Ullman",
        "abstract": "In the differentially private top-$k$ selection problem, we are given a dataset $X \u2208\\pmo^n \\times d$, in which each row belongs to an individual and each column corresponds to some binary attribute, and our goal is to find a set of $k \u226ad$ columns whose means are approximately as large as possible.  Differential privacy requires that our choice of these $k$ columns does not depend too much on any on individual\u2019s dataset.  This problem can be solved using the well known exponential mechanism and composition properties of differential privacy.  In the high-accuracy regime, where we require the error of the selection procedure to be to be smaller than the so-called sampling error $\u03b1\u2248\\sqrt\\ln(d)/n$, this procedure succeeds given a dataset of size $n \u2273k \\ln(d)$. We prove a matching lower bound, showing that a dataset of size $n \u2273k \\ln(d)$ is necessary for private top-$k$ selection in this high-accuracy regime.  Our lower bound shows that selecting the $k$ largest columns requires more data than simply estimating the value of those $k$ columns, which can be done using a dataset of size just $n \u2273k$.",
        "bibtex": "@InProceedings{pmlr-v65-bafna17a,\n  title = \t {The Price of Selection in Differential Privacy},\n  author = \t {Bafna, Mitali and Ullman, Jonathan},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {151--168},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/bafna17a/bafna17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/bafna17a.html},\n  abstract = \t {In the differentially private top-$k$ selection problem, we are given a dataset $X \u2208\\pmo^n \\times d$, in which each row belongs to an individual and each column corresponds to some binary attribute, and our goal is to find a set of $k \u226ad$ columns whose means are approximately as large as possible.  Differential privacy requires that our choice of these $k$ columns does not depend too much on any on individual\u2019s dataset.  This problem can be solved using the well known exponential mechanism and composition properties of differential privacy.  In the high-accuracy regime, where we require the error of the selection procedure to be to be smaller than the so-called sampling error $\u03b1\u2248\\sqrt\\ln(d)/n$, this procedure succeeds given a dataset of size $n \u2273k \\ln(d)$. We prove a matching lower bound, showing that a dataset of size $n \u2273k \\ln(d)$ is necessary for private top-$k$ selection in this high-accuracy regime.  Our lower bound shows that selecting the $k$ largest columns requires more data than simply estimating the value of those $k$ columns, which can be done using a dataset of size just $n \u2273k$. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/bafna17a/bafna17a.pdf",
        "supp": "",
        "pdf_size": 318034,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6940225144147921504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "IIT Madras + Northeastern University; Northeastern University",
        "aff_domain": "gmail.com;ccs.neu.edu",
        "email": "gmail.com;ccs.neu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "Indian Institute of Technology Madras;Northeastern University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iitm.ac.in;https://www.northeastern.edu",
        "aff_unique_abbr": "IITM;NEU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Madras;",
        "aff_country_unique_index": "0+1;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "fec077b0c2",
        "title": "The Sample Complexity of Optimizing a Convex Function",
        "site": "https://proceedings.mlr.press/v65/balkanski17a.html",
        "author": "Eric Balkanski; Yaron Singer",
        "abstract": "In this paper we study optimization from samples of convex functions. There are many scenarios in which we do not know the function we wish to optimize but can learn it from data.  In such cases,  we are interested in bounding the number of samples required to optimize the function.   Our main result shows that in general,  the number of samples required to obtain a non-trivial approximation to the optimum of a convex function is exponential in its dimension, even when the function is PAC-learnable. We also obtain strong lower bounds for strongly convex and Lipschitz continuous functions. On the positive side, we show that there are interesting classes of functions and distributions for which the sample complexity is polynomial in the dimension of the function.",
        "bibtex": "@InProceedings{pmlr-v65-balkanski17a,\n  title = \t {The Sample Complexity of Optimizing a Convex Function},\n  author = \t {Balkanski, Eric and Singer, Yaron},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {275--301},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/balkanski17a/balkanski17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/balkanski17a.html},\n  abstract = \t {In this paper we study optimization from samples of convex functions. There are many scenarios in which we do not know the function we wish to optimize but can learn it from data.  In such cases,  we are interested in bounding the number of samples required to optimize the function.   Our main result shows that in general,  the number of samples required to obtain a non-trivial approximation to the optimum of a convex function is exponential in its dimension, even when the function is PAC-learnable. We also obtain strong lower bounds for strongly convex and Lipschitz continuous functions. On the positive side, we show that there are interesting classes of functions and distributions for which the sample complexity is polynomial in the dimension of the function.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/balkanski17a/balkanski17a.pdf",
        "supp": "",
        "pdf_size": 711844,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7765296828350090859&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Harvard University; Harvard University",
        "aff_domain": "G.HARVARD.EDU;SEAS.HARVARD.EDU",
        "email": "G.HARVARD.EDU;SEAS.HARVARD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "42e020cc13",
        "title": "The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime",
        "site": "https://proceedings.mlr.press/v65/simchowitz17a.html",
        "author": "Max Simchowitz; Kevin Jamieson; Benjamin Recht",
        "abstract": "We propose a novel technique for analyzing adaptive sampling called the Simulator. Our approach differs from the existing methods by considering not how much information could be gathered by any fixed sampling strategy, but how difficult it is to distinguish a good sampling strategy from a bad one given the limited amount of data collected up to any given time. This change of perspective allows us to match the strength of both Fano and change-of-measure techniques, without succumbing to the limitations of either method. For concreteness, we apply our techniques to a structured multi-arm bandit problem in the fixed-confidence pure exploration setting, where we show that the constraints on the means imply a substantial gap between the moderate-confidence sample complexity, and the asymptotic sample complexity as the confidence delta tends to zero, as found in the literature. We also prove the first instance-based lower bounds for the top-k problem which incorporate the appropriate log-factors. Moreover, our lower bounds zero-in on the number of times each individual arm needs to be pulled, uncovering new phenomena which are drowned out in the aggregate sample complexity. Our new analysis inspires a simple and near-optimal algorithm for the best-arm and top-k identification, the first practical algorithm of its kind for the latter problem which removes extraneous log factors, and outperforms the state-of-the-art in experiments.",
        "bibtex": "@InProceedings{pmlr-v65-simchowitz17a,\n  title = \t {The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime},\n  author = \t {Simchowitz, Max and Jamieson, Kevin and Recht, Benjamin},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {1794--1834},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/simchowitz17a/simchowitz17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/simchowitz17a.html},\n  abstract = \t { We propose a novel technique for analyzing adaptive sampling called the Simulator. Our approach differs from the existing methods by considering not how much information could be gathered by any fixed sampling strategy, but how difficult it is to distinguish a good sampling strategy from a bad one given the limited amount of data collected up to any given time. This change of perspective allows us to match the strength of both Fano and change-of-measure techniques, without succumbing to the limitations of either method. For concreteness, we apply our techniques to a structured multi-arm bandit problem in the fixed-confidence pure exploration setting, where we show that the constraints on the means imply a substantial gap between the moderate-confidence sample complexity, and the asymptotic sample complexity as the confidence delta tends to zero, as found in the literature. We also prove the first instance-based lower bounds for the top-k problem which incorporate the appropriate log-factors. Moreover, our lower bounds zero-in on the number of times each individual arm needs to be pulled, uncovering new phenomena which are drowned out in the aggregate sample complexity. Our new analysis inspires a simple and near-optimal algorithm for the best-arm and top-k identification, the first practical algorithm of its kind for the latter problem which removes extraneous log factors, and outperforms the state-of-the-art in experiments. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/simchowitz17a/simchowitz17a.pdf",
        "supp": "",
        "pdf_size": 763843,
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8187382585917387551&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, Berkeley, CA 94720 USA; University of California, Berkeley, CA 94720 USA; University of California, Berkeley, CA 94720 USA",
        "aff_domain": "BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU",
        "email": "BERKELEY.EDU;BERKELEY.EDU;BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c0680fbe65",
        "title": "Thompson Sampling for the MNL-Bandit",
        "site": "https://proceedings.mlr.press/v65/agrawal17a.html",
        "author": "Shipra Agrawal; Vashist Avadhanula; Vineet Goyal; Assaf Zeevi",
        "abstract": "We consider a sequential subset selection problem under parameter uncertainty, where at each time step, the decision maker selects a subset of cardinality $K$ from $N$ possible  items (arms), and observes a (bandit) feedback in the form of the index of one of the items in said subset, or none. Each item in the index set is ascribed a certain value (reward), and the feedback is governed by a Multinomial Logit (MNL) choice model whose parameters are a priori unknown.  The objective of the decision maker is to maximize the expected cumulative rewards over a finite horizon $T$, or alternatively, minimize the regret relative to an oracle that knows the MNL parameters.  We refer to this as the MNL-Bandit problem. This problem is representative of a larger family of exploration-exploitation problems that involve a combinatorial objective, and arise in several important application domains. We present an approach to adapt Thompson Sampling to this problem and show that it achieves near-optimal regret as well as attractive numerical performance.",
        "bibtex": "@InProceedings{pmlr-v65-agrawal17a,\n  title = \t {Thompson Sampling for the MNL-Bandit},\n  author = \t {Agrawal, Shipra and Avadhanula, Vashist and Goyal, Vineet and Zeevi, Assaf},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {76--78},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/agrawal17a/agrawal17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/agrawal17a.html},\n  abstract = \t {We consider a sequential subset selection problem under parameter uncertainty, where at each time step, the decision maker selects a subset of cardinality $K$ from $N$ possible  items (arms), and observes a (bandit) feedback in the form of the index of one of the items in said subset, or none. Each item in the index set is ascribed a certain value (reward), and the feedback is governed by a Multinomial Logit (MNL) choice model whose parameters are a priori unknown.  The objective of the decision maker is to maximize the expected cumulative rewards over a finite horizon $T$, or alternatively, minimize the regret relative to an oracle that knows the MNL parameters.  We refer to this as the MNL-Bandit problem. This problem is representative of a larger family of exploration-exploitation problems that involve a combinatorial objective, and arise in several important application domains. We present an approach to adapt Thompson Sampling to this problem and show that it achieves near-optimal regret as well as attractive numerical performance.  }\n}",
        "pdf": "http://proceedings.mlr.press/v65/agrawal17a/agrawal17a.pdf",
        "supp": "",
        "pdf_size": 133722,
        "gs_citation": 139,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3985633607735737183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Industrial Engineering and Operations Research, Columbia University; Decision Risk and Operations, Columbia Business School + Industrial Engineering and Operations Research, Columbia University; Industrial Engineering and Operations Research, Columbia University; Decision Risk and Operations, Columbia Business School",
        "aff_domain": "COLUMBIA.EDU;GSB.COLUMBIA.EDU;IEOR.COLUMBIA.EDU;GSB.COLUMBIA.EDU",
        "email": "COLUMBIA.EDU;GSB.COLUMBIA.EDU;IEOR.COLUMBIA.EDU;GSB.COLUMBIA.EDU",
        "github": "",
        "project": "https://arxiv.org/abs/1706.00977",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;1",
        "aff_unique_norm": "Columbia University;Columbia Business School",
        "aff_unique_dep": "Industrial Engineering and Operations Research;Decision Risk and Operations",
        "aff_unique_url": "https://www.columbia.edu;https://www.gsb.columbia.edu",
        "aff_unique_abbr": "Columbia;CBS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fe62ff6e52",
        "title": "Thresholding Based Outlier Robust PCA",
        "site": "https://proceedings.mlr.press/v65/cherapanamjeri17a.html",
        "author": "Yeshwanth Cherapanamjeri; Prateek Jain; Praneeth Netrapalli",
        "abstract": "We consider the problem of outlier robust PCA (\\textbfOR-PCA) where the goal is to recover principal directions despite the presence of outlier data points. That is, given a data matrix $M^*$, where $(1-\u03b1)$ fraction of the points are noisy samples from a low-dimensional subspace while $\u03b1$ fraction of the points can be arbitrary outliers, the goal is to recover the subspace accurately. Existing results for \\textbfOR-PCA\u00a0have serious drawbacks: while some results are quite weak in the presence of noise, other results have runtime quadratic in dimension, rendering them impractical for large scale applications. In this work, we provide a novel thresholding based iterative algorithm with per-iteration complexity at most linear in the data size. Moreover, the fraction of outliers, $\u03b1$, that our method can handle is tight up to constants while providing nearly optimal computational complexity for a general noise setting. For the special case where the inliers are obtained from a low-dimensional subspace with additive Gaussian noise, we show that a modification of our thresholding based method leads to significant improvement in recovery error (of the subspace) even in the presence of a large fraction of outliers.",
        "bibtex": "@InProceedings{pmlr-v65-cherapanamjeri17a,\n  title = \t {Thresholding Based Outlier Robust PCA},\n  author = \t {Cherapanamjeri, Yeshwanth and Jain, Prateek and Netrapalli, Praneeth},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {593--628},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/cherapanamjeri17a/cherapanamjeri17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/cherapanamjeri17a.html},\n  abstract = \t {We consider the problem of outlier robust PCA (\\textbfOR-PCA) where the goal is to recover principal directions despite the presence of outlier data points. That is, given a data matrix $M^*$, where $(1-\u03b1)$ fraction of the points are noisy samples from a low-dimensional subspace while $\u03b1$ fraction of the points can be arbitrary outliers, the goal is to recover the subspace accurately. Existing results for \\textbfOR-PCA\u00a0have serious drawbacks: while some results are quite weak in the presence of noise, other results have runtime quadratic in dimension, rendering them impractical for large scale applications. In this work, we provide a novel thresholding based iterative algorithm with per-iteration complexity at most linear in the data size. Moreover, the fraction of outliers, $\u03b1$, that our method can handle is tight up to constants while providing nearly optimal computational complexity for a general noise setting. For the special case where the inliers are obtained from a low-dimensional subspace with additive Gaussian noise, we show that a modification of our thresholding based method leads to significant improvement in recovery error (of the subspace) even in the presence of a large fraction of outliers.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/cherapanamjeri17a/cherapanamjeri17a.pdf",
        "supp": "",
        "pdf_size": 504830,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8986175696382521849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Microsoft Research, India; Microsoft Research, India; Microsoft Research, India",
        "aff_domain": "MICROSOFT.COM;MICROSOFT.COM;MICROSOFT.COM",
        "email": "MICROSOFT.COM;MICROSOFT.COM;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/india.aspx",
        "aff_unique_abbr": "MSR India",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "5ad342b925",
        "title": "Tight Bounds for Bandit Combinatorial Optimization",
        "site": "https://proceedings.mlr.press/v65/cohen17a.html",
        "author": "Alon Cohen; Tamir Hazan; Tomer Koren",
        "abstract": "We revisit the study of optimal regret rates in bandit combinatorial optimization\u2014a fundamental framework for sequential decision making under uncertainty that abstracts numerous combinatorial prediction problems. We prove that the attainable regret in this setting grows as $\\widetilde\u0398(k^3/2\\sqrt{d}T)$ where $d$ is the dimension of the problem and $k$ is a bound over the maximal instantaneous loss, disproving a conjecture of Audibert, Bubeck, and Lugosi (2013) who argued that the optimal rate should be of the form $\\widetilde\u0398(k\\sqrt{d}T)$. Our bounds apply to several important instances of the framework, and in particular, imply a tight bound for the well-studied bandit shortest path problem. By that, we also resolve an open problem posed by Cesa-Bianchi and Lugosi (2012).",
        "bibtex": "@InProceedings{pmlr-v65-cohen17a,\n  title = \t {Tight Bounds for Bandit Combinatorial Optimization},\n  author = \t {Cohen, Alon and Hazan, Tamir and Koren, Tomer},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {629--642},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/cohen17a/cohen17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/cohen17a.html},\n  abstract = \t {We revisit the study of optimal regret rates in bandit combinatorial optimization\u2014a fundamental framework for sequential decision making under uncertainty that abstracts numerous combinatorial prediction problems. We prove that the attainable regret in this setting grows as $\\widetilde\u0398(k^3/2\\sqrt{d}T)$ where $d$ is the dimension of the problem and $k$ is a bound over the maximal instantaneous loss, disproving a conjecture of Audibert, Bubeck, and Lugosi (2013) who argued that the optimal rate should be of the form $\\widetilde\u0398(k\\sqrt{d}T)$. Our bounds apply to several important instances of the framework, and in particular, imply a tight bound for the well-studied bandit shortest path problem. By that, we also resolve an open problem posed by Cesa-Bianchi and Lugosi (2012).}\n}",
        "pdf": "http://proceedings.mlr.press/v65/cohen17a/cohen17a.pdf",
        "supp": "",
        "pdf_size": 264745,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4234118511454951625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Technion\u2014Israel Institute of Technology; Technion\u2014Israel Institute of Technology; Google",
        "aff_domain": "technion.ac.il;technion.ac.il;google.com",
        "email": "technion.ac.il;technion.ac.il;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Technion\u2014Israel Institute of Technology;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.google.com",
        "aff_unique_abbr": "Technion;Google",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "cba661af99",
        "title": "Towards Instance Optimal Bounds for Best Arm Identification",
        "site": "https://proceedings.mlr.press/v65/chen17b.html",
        "author": "Lijie Chen; Jian Li; Mingda Qiao",
        "abstract": "In the classical best arm identification (Best-$1$-Arm) problem, we are given $n$ stochastic bandit arms, each associated with a reward distribution with an unknown mean. Upon each play of an arm, we can get a reward sampled i.i.d. from its reward distribution. We would like to identify the arm with the largest mean with probability at least $1-\u03b4$, using as few samples as possible. The problem has a long history and understanding its sample complexity has attracted significant attention since the last decade. However, the optimal sample complexity of the problem is still unknown. Recently, Chen and Li (2016) made an interesting conjecture, called gap-entropy conjecture, concerning the instance optimal sample complexity of Best-$1$-Arm. Given a Best-$1$-Arm instance $I$ (i.e., a set of arms), let $\\mu_[i]$ denote the $i$th largest mean and $\\Delta_[i]=\\mu_[1]-\\mu_[i]$ denote the corresponding gap. $H(I)=\\sum_i=2^n\\Delta_[i]^-2$ denotes the complexity of the instance. The gap-entropy conjecture states that for any instance $I$, $\u03a9\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)\\right)$ is an instance lower bound, where $\\mathsf{Ent}(I)$ is an entropy-like term determined by the gaps, and there is a $\u03b4$-correct algorithm for Best-$1$-Arm with sample complexity $O\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)+\\Delta_[2]^-2\\ln\\ln\\Delta_[2]^-1\\right)$. We note that $\u0398\\left(\\Delta_[2]^-2\\ln\\ln\\Delta_[2]^-1\\right)$ is necessary and sufficient to solve the two-arm instance with the best and second best arms. If the conjecture is true, we would have a complete understanding of the instance-wise sample complexity of Best-$1$-Arm (up to constant factors). In this paper, we make significant progress towards a complete resolution of the gap-entropy conjecture. For the upper bound, we provide a highly nontrivial algorithm which requires \\[O\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)+\\Delta_[2]^-2\\ln\\ln\\Delta_[2]^-1\\mathrmpolylog(n,\u03b4^-1)\\right)\\]samples in expectation for any instance $I$. For the lower bound, we show that for any Gaussian Best-$1$-Arm instance with gaps of the form $2^-k$, any $\u03b4$-correct monotone algorithm requires at least \\[\u03a9\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)\\right)\\]samples in expectation. Here, a monotone algorithm is one which uses no more samples (in expectation) on $I\u2019$ than on $I$, if $I\u2019$ is a sub-instance of $I$ obtained by removing some sub-optimal arms.",
        "bibtex": "@InProceedings{pmlr-v65-chen17b,\n  title = \t {Towards Instance Optimal Bounds for Best Arm Identification},\n  author = \t {Chen, Lijie and Li, Jian and Qiao, Mingda},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {535--592},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/chen17b/chen17b.pdf},\n  url = \t {https://proceedings.mlr.press/v65/chen17b.html},\n  abstract = \t { In the classical best arm identification (Best-$1$-Arm) problem, we are given $n$ stochastic bandit arms, each associated with a reward distribution with an unknown mean. Upon each play of an arm, we can get a reward sampled i.i.d. from its reward distribution. We would like to identify the arm with the largest mean with probability at least $1-\u03b4$, using as few samples as possible. The problem has a long history and understanding its sample complexity has attracted significant attention since the last decade. However, the optimal sample complexity of the problem is still unknown. Recently, Chen and Li (2016) made an interesting conjecture, called gap-entropy conjecture, concerning the instance optimal sample complexity of Best-$1$-Arm. Given a Best-$1$-Arm instance $I$ (i.e., a set of arms), let $\\mu_[i]$ denote the $i$th largest mean and $\\Delta_[i]=\\mu_[1]-\\mu_[i]$ denote the corresponding gap. $H(I)=\\sum_i=2^n\\Delta_[i]^-2$ denotes the complexity of the instance. The gap-entropy conjecture states that for any instance $I$, $\u03a9\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)\\right)$ is an instance lower bound, where $\\mathsf{Ent}(I)$ is an entropy-like term determined by the gaps, and there is a $\u03b4$-correct algorithm for Best-$1$-Arm with sample complexity $O\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)+\\Delta_[2]^-2\\ln\\ln\\Delta_[2]^-1\\right)$. We note that $\u0398\\left(\\Delta_[2]^-2\\ln\\ln\\Delta_[2]^-1\\right)$ is necessary and sufficient to solve the two-arm instance with the best and second best arms. If the conjecture is true, we would have a complete understanding of the instance-wise sample complexity of Best-$1$-Arm (up to constant factors). In this paper, we make significant progress towards a complete resolution of the gap-entropy conjecture. For the upper bound, we provide a highly nontrivial algorithm which requires \\[O\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)+\\Delta_[2]^-2\\ln\\ln\\Delta_[2]^-1\\mathrmpolylog(n,\u03b4^-1)\\right)\\]samples in expectation for any instance $I$. For the lower bound, we show that for any Gaussian Best-$1$-Arm instance with gaps of the form $2^-k$, any $\u03b4$-correct monotone algorithm requires at least \\[\u03a9\\left(H(I)\u22c5\\left(\\ln\u03b4^-1 + \\mathsf{Ent}(I)\\right)\\right)\\]samples in expectation. Here, a monotone algorithm is one which uses no more samples (in expectation) on $I\u2019$ than on $I$, if $I\u2019$ is a sub-instance of $I$ obtained by removing some sub-optimal arms. }\n}",
        "pdf": "http://proceedings.mlr.press/v65/chen17b/chen17b.pdf",
        "supp": "",
        "pdf_size": 527086,
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11702088259586469363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China; Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China",
        "aff_domain": "MAILS.TSINGHUA.EDU.CN;MAIL.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN",
        "email": "MAILS.TSINGHUA.EDU.CN;MAIL.TSINGHUA.EDU.CN;MAILS.TSINGHUA.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences (IIIS)",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "7b33589c63",
        "title": "Two-Sample Tests for Large Random Graphs Using Network Statistics",
        "site": "https://proceedings.mlr.press/v65/ghoshdastidar17a.html",
        "author": "Debarghya Ghoshdastidar; Maurilio Gutzeit; Alexandra Carpentier; Ulrike von Luxburg",
        "abstract": "We consider a two-sample hypothesis testing problem, where the\ndistributions are defined on the space of undirected graphs, and one\nhas access to only one observation from each model. A motivating\nexample for this problem is comparing the friendship networks on\nFacebook and LinkedIn. The practical approach to such problems is to\ncompare the networks based on certain network statistics. In this\npaper, we present a general principle for two-sample hypothesis\ntesting in such scenarios without making any assumption about the\nnetwork generation process. The main contribution of the paper is a\ngeneral formulation of the problem based on concentration of network\nstatistics, and consequently, a consistent two-sample test that\narises as the natural solution for this problem. We also show that\nthe proposed test is minimax optimal for certain network statistics.",
        "bibtex": "@InProceedings{pmlr-v65-ghoshdastidar17a,\n  title = \t {Two-Sample Tests for Large Random Graphs Using Network Statistics},\n  author = \t {Ghoshdastidar, Debarghya and Gutzeit, Maurilio and Carpentier, Alexandra and von Luxburg, Ulrike},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {954--977},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/ghoshdastidar17a/ghoshdastidar17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/ghoshdastidar17a.html},\n  abstract = \t {We consider a two-sample hypothesis testing problem, where the\ndistributions are defined on the space of undirected graphs, and one\nhas access to only one observation from each model. A motivating\nexample for this problem is comparing the friendship networks on\nFacebook and LinkedIn. The practical approach to such problems is to\ncompare the networks based on certain network statistics. In this\npaper, we present a general principle for two-sample hypothesis\ntesting in such scenarios without making any assumption about the\nnetwork generation process. The main contribution of the paper is a\ngeneral formulation of the problem based on concentration of network\nstatistics, and consequently, a consistent two-sample test that\narises as the natural solution for this problem. We also show that\nthe proposed test is minimax optimal for certain network statistics.\n}\n}",
        "pdf": "http://proceedings.mlr.press/v65/ghoshdastidar17a/ghoshdastidar17a.pdf",
        "supp": "",
        "pdf_size": 294904,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15182587532565602070&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of T\u00fcbingen; Department of Mathematics, University of Potsdam; Department of Mathematics, University of Potsdam; Department of Computer Science, University of T\u00fcbingen",
        "aff_domain": "UNI-TUEBINGEN.DE;UNI-POTSDAM.DE;UNI-POTSDAM.DE;INFORMATIK.UNI-TUEBINGEN.DE",
        "email": "UNI-TUEBINGEN.DE;UNI-POTSDAM.DE;UNI-POTSDAM.DE;INFORMATIK.UNI-TUEBINGEN.DE",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of T\u00fcbingen;University of Potsdam",
        "aff_unique_dep": "Department of Computer Science;Department of Mathematics",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.uni-potsdam.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "a974dc1327",
        "title": "ZigZag: A New Approach to Adaptive Online Learning",
        "site": "https://proceedings.mlr.press/v65/foster17a.html",
        "author": "Dylan J. Foster; Alexander Rakhlin; Karthik Sridharan",
        "abstract": "We develop a new family of algorithms for the online learning setting with regret against any data sequence bounded by the empirical Rademacher complexity of that sequence. To develop a general theory of when this type of adaptive regret bound is achievable we establish a connection to the theory of decoupling inequalities for martingales in Banach spaces. When the hypothesis class is a set of linear functions bounded in some norm, such a regret bound is achievable if and only if the norm satisfies certain decoupling inequalities for martingales. Donald Burkholder\u2019s celebrated geometric characterization of decoupling inequalities (1984) states that such an inequality holds if and only if there exists a special function called a Burkholder function satisfying certain restricted concavity properties. Our online learning algorithms are efficient in terms of queries to this function. We realize our general theory by giving new efficient and adaptive algorithms for classes including $\\ell_p$ norms, group norms, and reproducing kernel Hilbert spaces. The empirical Rademacher complexity regret bound implies \u2014 when used in the i.i.d. setting \u2014 a data-dependent complexity bound for excess risk after online-to-batch conversion. To showcase the power of the empirical Rademacher complexity regret bound, we derive improved rates for a supervised learning generalization of the online learning with low rank experts task and for the online matrix prediction task. In addition to obtaining tight data-dependent regret bounds, our algorithms enjoy improved efficiency over previous techniques based on Rademacher complexity, automatically work in the infinite horizon setting, and adapt to scale. To obtain such adaptive methods, we introduce novel machinery, and the resulting algorithms are not based on the standard tools of online convex optimization. We conclude with a number of open problems and new directions, both algorithmic and information-theoretic.",
        "bibtex": "@InProceedings{pmlr-v65-foster17a,\n  title = \t {ZigZag: A New Approach to Adaptive Online Learning},\n  author = \t {Foster, Dylan J. and Rakhlin, Alexander and Sridharan, Karthik},\n  booktitle = \t {Proceedings of the 2017 Conference on Learning Theory},\n  pages = \t {876--924},\n  year = \t {2017},\n  editor = \t {Kale, Satyen and Shamir, Ohad},\n  volume = \t {65},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--10 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v65/foster17a/foster17a.pdf},\n  url = \t {https://proceedings.mlr.press/v65/foster17a.html},\n  abstract = \t {We develop a new family of algorithms for the online learning setting with regret against any data sequence bounded by the empirical Rademacher complexity of that sequence. To develop a general theory of when this type of adaptive regret bound is achievable we establish a connection to the theory of decoupling inequalities for martingales in Banach spaces. When the hypothesis class is a set of linear functions bounded in some norm, such a regret bound is achievable if and only if the norm satisfies certain decoupling inequalities for martingales. Donald Burkholder\u2019s celebrated geometric characterization of decoupling inequalities (1984) states that such an inequality holds if and only if there exists a special function called a Burkholder function satisfying certain restricted concavity properties. Our online learning algorithms are efficient in terms of queries to this function. We realize our general theory by giving new efficient and adaptive algorithms for classes including $\\ell_p$ norms, group norms, and reproducing kernel Hilbert spaces. The empirical Rademacher complexity regret bound implies \u2014 when used in the i.i.d. setting \u2014 a data-dependent complexity bound for excess risk after online-to-batch conversion. To showcase the power of the empirical Rademacher complexity regret bound, we derive improved rates for a supervised learning generalization of the online learning with low rank experts task and for the online matrix prediction task. In addition to obtaining tight data-dependent regret bounds, our algorithms enjoy improved efficiency over previous techniques based on Rademacher complexity, automatically work in the infinite horizon setting, and adapt to scale. To obtain such adaptive methods, we introduce novel machinery, and the resulting algorithms are not based on the standard tools of online convex optimization. We conclude with a number of open problems and new directions, both algorithmic and information-theoretic.}\n}",
        "pdf": "http://proceedings.mlr.press/v65/foster17a/foster17a.pdf",
        "supp": "",
        "pdf_size": 735618,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3627274139432661011&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Cornell University; University of Pennsylvania; Cornell University",
        "aff_domain": "CS.CORNELL.EDU;WHARTON.UPENN.EDU;CS.CORNELL.EDU",
        "email": "CS.CORNELL.EDU;WHARTON.UPENN.EDU;CS.CORNELL.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Cornell University;University of Pennsylvania",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cornell.edu;https://www.upenn.edu",
        "aff_unique_abbr": "Cornell;UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    }
]