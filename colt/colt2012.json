[
    {
        "id": "686997afee",
        "title": "(weak) Calibration is Computationally Hard",
        "site": "https://proceedings.mlr.press/v23/hazan12a.html",
        "author": "Elad Hazan; Sham M. Kakade",
        "abstract": "We show that the existence of a computationally efficient calibration algorithm, with a low weak calibration rate, would imply the existence of an efficient algorithm for computing approximate Nash equilibria \u2013 thus implying the unlikely conclusion that every problem in \\emphPPAD is solvable in polynomial time.",
        "bibtex": "@InProceedings{pmlr-v23-hazan12a,\n  title = \t {(weak) Calibration is Computationally Hard},\n  author = \t {Hazan, Elad and Kakade, Sham M.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {3.1--3.10},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/hazan12a/hazan12a.pdf},\n  url = \t {https://proceedings.mlr.press/v23/hazan12a.html},\n  abstract = \t {We show that the existence of a computationally efficient calibration algorithm, with a low weak calibration rate, would imply the existence of an efficient algorithm for computing approximate Nash equilibria \u2013 thus implying the unlikely conclusion that every problem in \\emphPPAD is solvable in polynomial time.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/hazan12a/hazan12a.pdf",
        "supp": "",
        "pdf_size": 278626,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15728424189657225321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Technion - Israel Institute of Technology; Microsoft Research, New England",
        "aff_domain": "ie.technion.ac.il;microsoft.com",
        "email": "ie.technion.ac.il;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technion - Israel Institute of Technology;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.microsoft.com/en-us/research/group/newengland",
        "aff_unique_abbr": "Technion;MSR",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New England",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "328ec13393",
        "title": "A Characterization of Scoring Rules for Linear Properties",
        "site": "https://proceedings.mlr.press/v23/abernethy12.html",
        "author": "Jacob D. Abernethy; Rafael M. Frongillo",
        "abstract": "We consider the design of proper scoring rules, equivalently proper losses, when the goal is to elicit some function, known as a property, of the underlying distribution. We provide a full characterization of the class of proper scoring rules when the property is linear as a function of the input distribution. A key conclusion is that any such scoring rule can be written in the form of a Bregman divergence for some convex function. We also apply our results to the design of prediction market mechanisms, showing a strong equivalence between scoring rules for linear properties and automated prediction market makers.",
        "bibtex": "@InProceedings{pmlr-v23-abernethy12,\n  title = \t {A Characterization of Scoring Rules for Linear Properties},\n  author = \t {Abernethy, Jacob D. and Frongillo, Rafael M.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {27.1--27.13},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/abernethy12/abernethy12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/abernethy12.html},\n  abstract = \t {We consider the design of proper scoring rules, equivalently proper losses, when the goal is to elicit some function, known as a property, of the underlying distribution. We provide a full characterization of the class of proper scoring rules when the property is linear as a function of the input distribution. A key conclusion is that any such scoring rule can be written in the form of a Bregman divergence for some convex function. We also apply our results to the design of prediction market mechanisms, showing a strong equivalence between scoring rules for linear properties and automated prediction market makers.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/abernethy12/abernethy12.pdf",
        "supp": "",
        "pdf_size": 364111,
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13724691242456306232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Computer and Information Science, University of Pennsylvania, Philadelphia, PA; Computer Science Division, University of California at Berkeley",
        "aff_domain": "SEAS.UPENN.EDU;CS.BERKELEY.EDU",
        "email": "SEAS.UPENN.EDU;CS.BERKELEY.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Pennsylvania;University of California, Berkeley",
        "aff_unique_dep": "Computer and Information Science;Computer Science Division",
        "aff_unique_url": "https://www.upenn.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UPenn;UC Berkeley",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Philadelphia;Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7fadc8a8f5",
        "title": "A Conjugate Property between Loss Functions and Uncertainty Sets in Classification Problems",
        "site": "https://proceedings.mlr.press/v23/kanamori12.html",
        "author": "Takafumi Kanamori; Akiko Takeda; Taiji Suzuki",
        "abstract": "In binary classification problems, mainly two approaches have been proposed; one is loss function approach and the other is minimum distance approach. The loss function approach is applied to major learning algorithms such as support vector machine (SVM) and boosting methods. The loss function represents the penalty of the decision function on the training samples. In the learning algorithm, the empirical mean of the loss function is minimized to obtain the classifier. Against a backdrop of the development of mathematical programming, nowadays learning algorithms based on loss functions are widely applied to real-world data analysis. In addition, statistical properties of such learning algorithms are well-understood based on a lots of theoretical works. On the other hand, some learning methods such as \u03c5-SVM, mini-max probability machine (MPM) can be formulated as minimum distance problems. In the minimum distance approach, firstly, the so-called uncertainty set is defined for each binary label based on the training samples. Then, the best separating hyperplane between the two uncertainty sets is employed as the decision function. This is regarded as an extension of the maximum-margin approach. The minimum distance approach is considered to be useful to construct the statistical models with an intuitive geometric interpretation, and the interpretation is helpful to develop the learning algorithms. However, the statistical properties of the minimum distance approach have not been intensively studied. In this paper, we consider the relation between the above two approaches. We point out that the uncertainty set in the minimum distance approach is described by using the level set of the conjugate of the loss function. Based on such relation, we study statistical properties of the minimum distance approach.",
        "bibtex": "@InProceedings{pmlr-v23-kanamori12,\n  title = \t {A Conjugate Property between Loss Functions and Uncertainty Sets in Classification Problems},\n  author = \t {Kanamori, Takafumi and Takeda, Akiko and Suzuki, Taiji},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {29.1--29.23},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/kanamori12/kanamori12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/kanamori12.html},\n  abstract = \t {In binary classification problems, mainly two approaches have been proposed; one is loss function approach and the other is minimum distance approach. The loss function approach is applied to major learning algorithms such as support vector machine (SVM) and boosting methods. The loss function represents the penalty of the decision function on the training samples. In the learning algorithm, the empirical mean of the loss function is minimized to obtain the classifier. Against a backdrop of the development of mathematical programming, nowadays learning algorithms based on loss functions are widely applied to real-world data analysis. In addition, statistical properties of such learning algorithms are well-understood based on a lots of theoretical works. On the other hand, some learning methods such as \u03c5-SVM, mini-max probability machine (MPM) can be formulated as minimum distance problems. In the minimum distance approach, firstly, the so-called uncertainty set is defined for each binary label based on the training samples. Then, the best separating hyperplane between the two uncertainty sets is employed as the decision function. This is regarded as an extension of the maximum-margin approach. The minimum distance approach is considered to be useful to construct the statistical models with an intuitive geometric interpretation, and the interpretation is helpful to develop the learning algorithms. However, the statistical properties of the minimum distance approach have not been intensively studied. In this paper, we consider the relation between the above two approaches. We point out that the uncertainty set in the minimum distance approach is described by using the level set of the conjugate of the loss function. Based on such relation, we study statistical properties of the minimum distance approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/kanamori12/kanamori12.pdf",
        "supp": "",
        "pdf_size": 469109,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9279280112130111662&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Nagoya University; Keio University; The University of Tokyo",
        "aff_domain": "IS.NAGOYA-U.AC.JP;AE.KEIO.AC.JP;STAT.T.U-TOKYO.AC.JP",
        "email": "IS.NAGOYA-U.AC.JP;AE.KEIO.AC.JP;STAT.T.U-TOKYO.AC.JP",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Nagoya University;Keio University;University of Tokyo",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nagoya-u.ac.jp;https://www.keio.ac.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Nagoya U;Keio;UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "d994f37b99",
        "title": "A Correlation Clustering Approach to Link Classification in Signed Networks",
        "site": "https://proceedings.mlr.press/v23/cesa-bianchi12.html",
        "author": "Nicol\u00f3 Cesa-Bianchi; Claudio Gentile; Fabio Vitale; Giovanni Zappella",
        "abstract": "Motivated by social balance theory, we develop a theory of link classification in signed networks using the correlation clustering index as measure of label regularity. We derive learning bounds in terms of correlation clustering within three fundamental transductive learning settings: online, batch and active. Our main algorithmic contribution is in the active setting, where we introduce a new family of efficient link classifiers based on covering the input graph with small circuits. These are the first active algorithms for link classification with mistake bounds that hold for arbitrary signed networks.",
        "bibtex": "@InProceedings{pmlr-v23-cesa-bianchi12,\n  title = \t {A Correlation Clustering Approach to Link Classification in Signed Networks},\n  author = \t {Cesa-Bianchi, Nicol\u00f3 and Gentile, Claudio and Vitale, Fabio and Zappella, Giovanni},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {34.1--34.20},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/cesa-bianchi12/cesa-bianchi12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/cesa-bianchi12.html},\n  abstract = \t {Motivated by social balance theory, we develop a theory of link classification in signed networks using the correlation clustering index as measure of label regularity. We derive learning bounds in terms of correlation clustering within three fundamental transductive learning settings: online, batch and active. Our main algorithmic contribution is in the active setting, where we introduce a new family of efficient link classifiers based on covering the input graph with small circuits. These are the first active algorithms for link classification with mistake bounds that hold for arbitrary signed networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/cesa-bianchi12/cesa-bianchi12.pdf",
        "supp": "",
        "pdf_size": 546570,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8840986026555431162&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 17,
        "aff": "Dept. of Computer Science, Universit `a degli Studi di Milano, Italy; DiSTA, Universit `a dell\u2019Insubria, Italy; Dept. of Computer Science, Universit `a degli Studi di Milano, Italy; Dept. of Mathematics, Universit `a degli Studi di Milano, Italy",
        "aff_domain": "UNIMI.IT;UNINSUBRIA.IT;UNIMI.IT;UNIMI.IT",
        "email": "UNIMI.IT;UNINSUBRIA.IT;UNIMI.IT;UNIMI.IT",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Milano;Universit\u00e0 dell\u2019Insubria",
        "aff_unique_dep": "Dept. of Computer Science;DiSTA",
        "aff_unique_url": "https://www.unimi.it;https://www.uninsubria.it",
        "aff_unique_abbr": "UniMi;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9c63139012",
        "title": "A Method of Moments for Mixture Models and Hidden Markov Models",
        "site": "https://proceedings.mlr.press/v23/anandkumar12.html",
        "author": "Animashree Anandkumar; Daniel Hsu; Sham M. Kakade",
        "abstract": "Mixture models are a fundamental tool in applied statistics and machine learning for treating data taken from multiple subpopulations. The current practice for estimating the parameters of such models relies on local search heuristics (\\emphe.g., the EM algorithm) which are prone to failure, and existing consistent methods are unfavorable due to their high computational and sample complexity which typically scale exponentially with the number of mixture components. This work develops an efficient \\emphmethod of moments approach to parameter estimation for a broad class of high-dimensional mixture models with many components, including multi-view mixtures of Gaussians (such as mixtures of axis-aligned Gaussians) and hidden Markov models. The new method leads to rigorous unsupervised learning results for mixture models that were not achieved by previous works; and, because of its simplicity, it offers a viable alternative to EM for practical deployment.",
        "bibtex": "@InProceedings{pmlr-v23-anandkumar12,\n  title = \t {A Method of Moments for Mixture Models and Hidden Markov Models},\n  author = \t {Anandkumar, Animashree and Hsu, Daniel and Kakade, Sham M.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {33.1--33.34},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/anandkumar12/anandkumar12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/anandkumar12.html},\n  abstract = \t {Mixture models are a fundamental tool in applied statistics and machine learning for treating data taken from multiple subpopulations. The current practice for estimating the parameters of such models relies on local search heuristics (\\emphe.g., the EM algorithm) which are prone to failure, and existing consistent methods are unfavorable due to their high computational and sample complexity which typically scale exponentially with the number of mixture components. This work develops an efficient \\emphmethod of moments approach to parameter estimation for a broad class of high-dimensional mixture models with many components, including multi-view mixtures of Gaussians (such as mixtures of axis-aligned Gaussians) and hidden Markov models. The new method leads to rigorous unsupervised learning results for mixture models that were not achieved by previous works; and, because of its simplicity, it offers a viable alternative to EM for practical deployment.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/anandkumar12/anandkumar12.pdf",
        "supp": "",
        "pdf_size": 600489,
        "gs_citation": 400,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6234838543497690685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 19,
        "aff": "University of California, Irvine; Microsoft Research; Microsoft Research",
        "aff_domain": "UCI.EDU;MICROSOFT.COM;MICROSOFT.COM",
        "email": "UCI.EDU;MICROSOFT.COM;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Irvine;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.uci.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "UCI;MSR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Irvine;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "aa750f4bc0",
        "title": "Active Learning Using Smooth Relative Regret Approximations with Applications",
        "site": "https://proceedings.mlr.press/v23/ailon12.html",
        "author": "Nir Ailon; Ron Begleiter; Esther Ezra",
        "abstract": "The disagreement coefficient of Hanneke has become a central concept in proving active learning rates. It has been shown in various ways that a concept class with low complexity together with a bound on the disagreement coefficient at an optimal solution allows active learning rates that are superior to passive learning ones. We present a different tool for pool based active learning which follows from the existence of a certain uniform version of low disagreement coefficient, but is not equivalent to it. In fact, we present two fundamental active learning problems of significant interest for which our approach allows nontrivial active learning bounds. However, any general purpose method relying on the disagreement coefficient bounds only fails to guarantee any useful bounds for these problems. The tool we use is based on the learner\u2019s ability to compute an estimator of the difference between the loss of any hypotheses and some fixed \u201cpivotal\u201d hypothesis to within an absolute error of at most \u03b5 times the \\emphl_1 distance (the disagreement measure) between the two hypotheses. We prove that such an estimator implies the existence of a learning algorithm which, at each iteration, reduces its excess risk to within a constant factor. Each iteration replaces the current pivotal hypothesis with the minimizer of the estimated loss difference function with respect to the previous pivotal hypothesis. The label complexity essentially becomes that of computing this estimator. The two applications of interest are: learning to rank from pairwise preferences, and clustering with side information (a.k.a. semi-supervised clustering). They are both fundamental, and have started receiving more attention from active learning theoreticians and practitioners. Keywords: active learning, learning to rank from pairwise preferences, semi-supervised clustering, clustering with side information, disagreement coefficient, smooth relative regret approximation.",
        "bibtex": "@InProceedings{pmlr-v23-ailon12,\n  title = \t {Active Learning Using Smooth Relative Regret Approximations with Applications},\n  author = \t {Ailon, Nir and Begleiter, Ron and Ezra, Esther},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {19.1--19.20},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/ailon12/ailon12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/ailon12.html},\n  abstract = \t {The disagreement coefficient of Hanneke has become a central concept in proving active learning rates. It has been shown in various ways that a concept class with low complexity together with a bound on the disagreement coefficient at an optimal solution allows active learning rates that are superior to passive learning ones. We present a different tool for pool based active learning which follows from the existence of a certain uniform version of low disagreement coefficient, but is not equivalent to it. In fact, we present two fundamental active learning problems of significant interest for which our approach allows nontrivial active learning bounds. However, any general purpose method relying on the disagreement coefficient bounds only fails to guarantee any useful bounds for these problems. The tool we use is based on the learner\u2019s ability to compute an estimator of the difference between the loss of any hypotheses and some fixed \u201cpivotal\u201d hypothesis to within an absolute error of at most \u03b5 times the \\emphl_1 distance (the disagreement measure) between the two hypotheses. We prove that such an estimator implies the existence of a learning algorithm which, at each iteration, reduces its excess risk to within a constant factor. Each iteration replaces the current pivotal hypothesis with the minimizer of the estimated loss difference function with respect to the previous pivotal hypothesis. The label complexity essentially becomes that of computing this estimator. The two applications of interest are: learning to rank from pairwise preferences, and clustering with side information (a.k.a. semi-supervised clustering). They are both fundamental, and have started receiving more attention from active learning theoreticians and practitioners. Keywords: active learning, learning to rank from pairwise preferences, semi-supervised clustering, clustering with side information, disagreement coefficient, smooth relative regret approximation.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/ailon12/ailon12.pdf",
        "supp": "",
        "pdf_size": 478574,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3135306828810454609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Dept. of Computer Science, Technion IIT, Haifa, Israel; Dept. of Computer Science, Technion IIT, Haifa, Israel; Courant Institute of Mathematical Science, NYU, New York, NY",
        "aff_domain": "cs.technion.ac.il;cs.technion.ac.il;courant.nyu.edu",
        "email": "cs.technion.ac.il;cs.technion.ac.il;courant.nyu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Technion IIT;New York University",
        "aff_unique_dep": "Dept. of Computer Science;Courant Institute of Mathematical Science",
        "aff_unique_url": "https://www.technion.ac.il;https://www.courant.nyu.edu",
        "aff_unique_abbr": "Technion;NYU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Haifa;New York",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "6faeb53a30",
        "title": "Analysis of Thompson Sampling for the Multi-armed Bandit Problem",
        "site": "https://proceedings.mlr.press/v23/agrawal12.html",
        "author": "Shipra Agrawal; Navin Goyal",
        "abstract": "The multi-armed bandit problem is a popular model for studying exploration/exploitation trade-off in sequential decision problems. Many algorithms are now available for this well-studied problem. One of the earliest algorithms, given by W. R. Thompson, dates back to 1933. This algorithm, referred to as Thompson Sampling, is a natural Bayesian algorithm. The basic idea is to choose an arm to play according to its probability of being the best arm. Thompson Sampling algorithm has experimentally been shown to be close to optimal. In addition, it is efficient to implement and exhibits several desirable properties such as small regret for delayed feedback. However, theoretical understanding of this algorithm was quite limited. In this paper, for the first time, we show that Thompson Sampling algorithm achieves logarithmic expected regret for the stochastic multi-armed bandit problem. More precisely, for the stochastic two-armed bandit problem, the expected regret in time T is O(\\frac\\ln T\u2206 + \\frac1\u2206^3). And, for the stochastic N-armed bandit problem, the expected regret in time T is O(\\left[\\left(\\sum_i=2^N \\frac1\\Delta_i^2\\right)^2\\right] \\ln T). Our bounds are optimal but for the dependence on \\Delta_i and the constant factors in big-Oh.",
        "bibtex": "@InProceedings{pmlr-v23-agrawal12,\n  title = \t {Analysis of Thompson Sampling for the Multi-armed Bandit Problem},\n  author = \t {Agrawal, Shipra and Goyal, Navin},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {39.1--39.26},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/agrawal12.html},\n  abstract = \t {The multi-armed bandit problem is a popular model for studying exploration/exploitation trade-off in sequential decision problems. Many algorithms are now available for this well-studied problem. One of the earliest algorithms, given by W. R. Thompson, dates back to 1933. This algorithm, referred to as Thompson Sampling, is a natural Bayesian algorithm. The basic idea is to choose an arm to play according to its probability of being the best arm. Thompson Sampling algorithm has experimentally been shown to be close to optimal. In addition, it is efficient to implement and exhibits several desirable properties such as small regret for delayed feedback. However, theoretical understanding of this algorithm was quite limited. In this paper, for the first time, we show that Thompson Sampling algorithm achieves logarithmic expected regret for the stochastic multi-armed bandit problem. More precisely, for the stochastic two-armed bandit problem, the expected regret in time T is O(\\frac\\ln T\u2206 + \\frac1\u2206^3). And, for the stochastic N-armed bandit problem, the expected regret in time T is O(\\left[\\left(\\sum_i=2^N \\frac1\\Delta_i^2\\right)^2\\right] \\ln T). Our bounds are optimal but for the dependence on \\Delta_i and the constant factors in big-Oh.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf",
        "supp": "",
        "pdf_size": 535728,
        "gs_citation": 1708,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=605721521293281764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Microsoft Research India; Microsoft Research India",
        "aff_domain": "MICROSOFT.COM;MICROSOFT.COM",
        "email": "MICROSOFT.COM;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research India",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-india",
        "aff_unique_abbr": "MSR India",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "d7731a5fde",
        "title": "Attribute-Efficient Learning andWeight-Degree Tradeoffs for Polynomial Threshold Functions",
        "site": "https://proceedings.mlr.press/v23/servedio12.html",
        "author": "Rocco Servedio; Li-Yang Tan; Justin Thaler",
        "abstract": "We study the challenging problem of learning decision lists attribute-efficiently, giving both positive and negative results. Our main positive result is a new tradeoff between the running time and mistake bound for learning length-\\emphk decision lists over \\emphn Boolean variables. When the allowed running time is relatively high, our new mistake bound improves significantly on the mistake bound of the best previous algorithm of Klivans and Servedio (Klivans and Servedio, 2006). Our main negative result is a new lower bound on the \\emphweight of any degree-\\emphd polynomial threshold function (PTF) that computes a particular decision list over \\emphk variables (the \u201cODD-MAX-BIT\u201d function). The main result of Beigel (Beigel, 1994) is a weight lower bound of 2^\u03a9(\\emphk/\\emphd^2), which was shown to be essentially optimal for \\emphd \u2264 \\emphk^1/3 by Klivans and Servedio. Here we prove a 2^\u03a9(\u221a\\emphk/d)  lower bound, which improves on Beigel\u2019s lower bound for \\emphd > \\emphk^1/3. This lower bound establishes strong limitations on the effectiveness of the Klivans and Servedio approach and suggests that it may be difficult to improve on our positive result. The main tool used in our lower bound is a new variant of Markov\u2019s classical inequality which may be of independent interest; it provides a bound on the derivative of a univariate polynomial in terms of both its degree \\emphand the size of its coefficients.",
        "bibtex": "@InProceedings{pmlr-v23-servedio12,\n  title = \t {Attribute-Efficient Learning andWeight-Degree Tradeoffs for Polynomial Threshold Functions},\n  author = \t {Servedio, Rocco and Tan, Li-Yang and Thaler, Justin},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {14.1--14.19},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/servedio12/servedio12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/servedio12.html},\n  abstract = \t {We study the challenging problem of learning decision lists attribute-efficiently, giving both positive and negative results. Our main positive result is a new tradeoff between the running time and mistake bound for learning length-\\emphk decision lists over \\emphn Boolean variables. When the allowed running time is relatively high, our new mistake bound improves significantly on the mistake bound of the best previous algorithm of Klivans and Servedio (Klivans and Servedio, 2006). Our main negative result is a new lower bound on the \\emphweight of any degree-\\emphd polynomial threshold function (PTF) that computes a particular decision list over \\emphk variables (the \u201cODD-MAX-BIT\u201d function). The main result of Beigel (Beigel, 1994) is a weight lower bound of 2^\u03a9(\\emphk/\\emphd^2), which was shown to be essentially optimal for \\emphd \u2264 \\emphk^1/3 by Klivans and Servedio. Here we prove a 2^\u03a9(\u221a\\emphk/d)  lower bound, which improves on Beigel\u2019s lower bound for \\emphd > \\emphk^1/3. This lower bound establishes strong limitations on the effectiveness of the Klivans and Servedio approach and suggests that it may be difficult to improve on our positive result. The main tool used in our lower bound is a new variant of Markov\u2019s classical inequality which may be of independent interest; it provides a bound on the derivative of a univariate polynomial in terms of both its degree \\emphand the size of its coefficients.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/servedio12/servedio12.pdf",
        "supp": "",
        "pdf_size": 461201,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8324943157704618153&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, Columbia University; Department of Computer Science, Columbia University; School of Engineering and Applied Sciences, Harvard University",
        "aff_domain": "CS.COLUMBIA.EDU;CS.COLUMBIA.EDU;SEAS.HARVARD.EDU",
        "email": "CS.COLUMBIA.EDU;CS.COLUMBIA.EDU;SEAS.HARVARD.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Columbia University;Harvard University",
        "aff_unique_dep": "Department of Computer Science;School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.columbia.edu;https://www.harvard.edu",
        "aff_unique_abbr": "Columbia;Harvard",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f4001b5a2d",
        "title": "Autonomous Exploration For Navigating In MDPs",
        "site": "https://proceedings.mlr.press/v23/lim12.html",
        "author": "Shiau Hong Lim; Peter Auer",
        "abstract": "While intrinsically motivated learning agents hold considerable promise to overcome limitations of more supervised learning systems, quantitative evaluation and theoretical analysis of such agents are difficult. We propose to consider a restricted setting for autonomous learning where systematic evaluation of learning performance is possible. In this setting the agent needs to learn to navigate in a Markov Decision Process where extrinsic rewards are not present or are ignored. We present a learning algorithm for this scenario and evaluate it by the amount of exploration it uses to learn the environment.",
        "bibtex": "@InProceedings{pmlr-v23-lim12,\n  title = \t {Autonomous Exploration For Navigating In MDPs},\n  author = \t {Lim, Shiau Hong and Auer, Peter},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {40.1--40.24},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/lim12/lim12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/lim12.html},\n  abstract = \t {While intrinsically motivated learning agents hold considerable promise to overcome limitations of more supervised learning systems, quantitative evaluation and theoretical analysis of such agents are difficult. We propose to consider a restricted setting for autonomous learning where systematic evaluation of learning performance is possible. In this setting the agent needs to learn to navigate in a Markov Decision Process where extrinsic rewards are not present or are ignored. We present a learning algorithm for this scenario and evaluate it by the amount of exploration it uses to learn the environment.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/lim12/lim12.pdf",
        "supp": "",
        "pdf_size": 469127,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6065117633924257015&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Montanuniversit\u00e4t Leoben; Montanuniversit\u00e4t Leoben",
        "aff_domain": "gmail.com;unileoben.ac.at",
        "email": "gmail.com;unileoben.ac.at",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Montanuniversit\u00e4t Leoben",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.montanuni-leoben.at",
        "aff_unique_abbr": "MUL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "e4e1de0211",
        "title": "Competitive Classification and Closeness Testing",
        "site": "https://proceedings.mlr.press/v23/acharya12.html",
        "author": "Jayadev Acharya; Hirakendu Das; Ashkan Jafarpour; Alon Orlitsky; Shengjun Pan; Ananda Suresh",
        "abstract": "We study the problems of \\emphclassification and \\emphcloseness testing. A \\emphclassifier associates a test sequence with the one of two training sequences that was generated by the same distribution. A \\emphcloseness test determines whether two sequences were generated by the same or by different distributions. For both problems all natural algorithms are \\emphsymmetric \u2013 they make the same decision under all symbol relabelings. With no assumptions on the distributions\u2019 support size or relative distance, we construct a classifier and closeness test that require at most O(n^3/2) samples to attain the n-sample accuracy of the best symmetric classifier or closeness test designed with knowledge of the underlying distributions. Both algorithms run in time linear in the number of samples. Conversely we also show that for any classifier or closeness test, there are distributions that require \u03a9(n^7/6) samples to achieve the n-sample accuracy of the best symmetric algorithm that knows the underlying distributions.",
        "bibtex": "@InProceedings{pmlr-v23-acharya12,\n  title = \t {Competitive Classification and Closeness Testing},\n  author = \t {Acharya, Jayadev and Das, Hirakendu and Jafarpour, Ashkan and Orlitsky, Alon and Pan, Shengjun and Suresh, Ananda},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {22.1--22.18},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/acharya12/acharya12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/acharya12.html},\n  abstract = \t {We study the problems of \\emphclassification and \\emphcloseness testing. A \\emphclassifier associates a test sequence with the one of two training sequences that was generated by the same distribution. A \\emphcloseness test determines whether two sequences were generated by the same or by different distributions. For both problems all natural algorithms are \\emphsymmetric \u2013 they make the same decision under all symbol relabelings. With no assumptions on the distributions\u2019 support size or relative distance, we construct a classifier and closeness test that require at most O(n^3/2) samples to attain the n-sample accuracy of the best symmetric classifier or closeness test designed with knowledge of the underlying distributions. Both algorithms run in time linear in the number of samples. Conversely we also show that for any classifier or closeness test, there are distributions that require \u03a9(n^7/6) samples to achieve the n-sample accuracy of the best symmetric algorithm that knows the underlying distributions.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/acharya12/acharya12.pdf",
        "supp": "",
        "pdf_size": 438290,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15199528437902888209&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of California San Diego, La Jolla, CA 92093; University of California San Diego, La Jolla, CA 92093; University of California San Diego, La Jolla, CA 92093; University of California San Diego, La Jolla, CA 92093; University of California San Diego, La Jolla, CA 92093; University of California San Diego, La Jolla, CA 92093",
        "aff_domain": "UCSD.EDU;UCSD.EDU;UCSD.EDU;UCSD.EDU;UCSD.EDU;UCSD.EDU",
        "email": "UCSD.EDU;UCSD.EDU;UCSD.EDU;UCSD.EDU;UCSD.EDU;UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "31fcc9f37a",
        "title": "Computational Bounds on Statistical Query Learning",
        "site": "https://proceedings.mlr.press/v23/feldman12a.html",
        "author": "Vitaly Feldman; Varun Kanade",
        "abstract": "We study the complexity of learning in Kearns\u2019 well-known \\emphstatistical query (SQ) learning model (Kearns, 1993). A number of previous works have addressed the definition and estimation of the information-theoretic bounds on the SQ learning complexity, in other words, bounds on the query complexity. Here we give the first strictly computational upper and lower bounds on the complexity of several types of learning in the SQ model. As it was already observed, the known characterization of distribution-specific SQ learning (Blum, et al. 1994) implies that for weak learning over a fixed distribution, the query complexity and computational complexity are essentially the same. In contrast, we show that for both distribution-specific and distribution-independent (strong) learning there exists a concept class of polynomial query complexity that is not efficiently learnable unless RP = NP. We then prove that our distribution-specific lower bound is essentially tight by showing that for every concept class \\emphC of polynomial query complexity there exists a polynomial time algorithm that given access to random points from any distribution \\emphD and an NP oracle, can SQ learn \\emphC over \\emphD. We also consider a restriction of the SQ model, the correlational statistical query (CSQ) model (Bshouty and Feldman, 2001; Feldman, 2008) of learning which is closely-related to Valiant\u2019s model of evolvability (Valiant, 2007). We show a similar separation result for distribution-independent CSQ learning under a stronger assumption: there exists a concept class of polynomial CSQ query complexity which is not efficiently learnable unless every problem in W[P] has a randomized fixed parameter tractable algorithm.",
        "bibtex": "@InProceedings{pmlr-v23-feldman12a,\n  title = \t {Computational Bounds on Statistical Query Learning},\n  author = \t {Feldman, Vitaly and Kanade, Varun},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {16.1--16.22},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/feldman12a/feldman12a.pdf},\n  url = \t {https://proceedings.mlr.press/v23/feldman12a.html},\n  abstract = \t {We study the complexity of learning in Kearns\u2019 well-known \\emphstatistical query (SQ) learning model (Kearns, 1993). A number of previous works have addressed the definition and estimation of the information-theoretic bounds on the SQ learning complexity, in other words, bounds on the query complexity. Here we give the first strictly computational upper and lower bounds on the complexity of several types of learning in the SQ model. As it was already observed, the known characterization of distribution-specific SQ learning (Blum, et al. 1994) implies that for weak learning over a fixed distribution, the query complexity and computational complexity are essentially the same. In contrast, we show that for both distribution-specific and distribution-independent (strong) learning there exists a concept class of polynomial query complexity that is not efficiently learnable unless RP = NP. We then prove that our distribution-specific lower bound is essentially tight by showing that for every concept class \\emphC of polynomial query complexity there exists a polynomial time algorithm that given access to random points from any distribution \\emphD and an NP oracle, can SQ learn \\emphC over \\emphD. We also consider a restriction of the SQ model, the correlational statistical query (CSQ) model (Bshouty and Feldman, 2001; Feldman, 2008) of learning which is closely-related to Valiant\u2019s model of evolvability (Valiant, 2007). We show a similar separation result for distribution-independent CSQ learning under a stronger assumption: there exists a concept class of polynomial CSQ query complexity which is not efficiently learnable unless every problem in W[P] has a randomized fixed parameter tractable algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/feldman12a/feldman12a.pdf",
        "supp": "",
        "pdf_size": 445868,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6511457750764465838&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "IBM Almaden Research Center; SEAS, Harvard University",
        "aff_domain": "POST.HARVARD.EDU;FAS.HARVARD.EDU",
        "email": "POST.HARVARD.EDU;FAS.HARVARD.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "IBM;Harvard University",
        "aff_unique_dep": "Research Center;School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.ibm.com/research;https://www.seas.harvard.edu",
        "aff_unique_abbr": "IBM;SEAS",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Almaden;Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "712b3ef93e",
        "title": "Consistency of Nearest Neighbor Classification under Selective Sampling",
        "site": "https://proceedings.mlr.press/v23/dasgupta12.html",
        "author": "Sanjoy Dasgupta",
        "abstract": "This paper studies nearest neighbor classification in a model where unlabeled data points arrive in a stream, and the learner decides, for each one, whether to ask for its label. Are there generic ways to augment or modify any selective sampling strategy so as to ensure the consistency of the resulting nearest neighbor classifier?",
        "bibtex": "@InProceedings{pmlr-v23-dasgupta12,\n  title = \t {Consistency of Nearest Neighbor Classification under Selective Sampling},\n  author = \t {Dasgupta, Sanjoy},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {18.1--18.15},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/dasgupta12/dasgupta12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/dasgupta12.html},\n  abstract = \t {This paper studies nearest neighbor classification in a model where unlabeled data points arrive in a stream, and the learner decides, for each one, whether to ask for its label. Are there generic ways to augment or modify any selective sampling strategy so as to ensure the consistency of the resulting nearest neighbor classifier?}\n}",
        "pdf": "http://proceedings.mlr.press/v23/dasgupta12/dasgupta12.pdf",
        "supp": "",
        "pdf_size": 352015,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16242752967588462797&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "aff": "9500 Gilman Drive #0404, La Jolla, CA 92093",
        "aff_domain": "CS.UCSD.EDU",
        "email": "CS.UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a001676a2d",
        "title": "Differentially Private Online Learning",
        "site": "https://proceedings.mlr.press/v23/jain12.html",
        "author": "Prateek Jain; Pravesh Kothari; Abhradeep Thakurta",
        "abstract": "In this paper, we consider the problem of preserving privacy in the context of online learning. Online learning involves learning from data in real-time, due to which the learned model as well as its predictions are continuously changing. This makes preserving privacy of each data point significantly more challenging as its effect on the learned model can be easily tracked by observing changes in the subsequent predictions. Furthermore, with more and more online systems (e.g. search engines like Bing, Google etc.) trying to learn their customers\u2019 behavior by leveraging their access to sensitive customer data (through cookies etc.), the problem of privacy preserving online learning has become critical. We study the problem in the framework of online convex programming (OCP) \u2013 a popular online learning setting with several theoretical and practical implications \u2013 while using differential privacy as the formal measure of privacy. For this problem, we provide a generic framework that can be used to convert any given OCP algorithm into a private OCP algorithm with provable privacy as well as regret guarantees (utility), provided that the given OCP algorithm satisfies the following two criteria: 1) linearly decreasing sensitivity, i.e., the effect of the new data points on the learned model decreases linearly, 2) sub-linear regret. We then illustrate our approach by converting two popular OCP algorithms into corresponding differentially private algorithms while guaranteeing \\emph\u00d5(\u221aT)  regret for strongly convex functions. Next, we consider the practically important class of online linear regression problems, for which we generalize the approach by Dwork et al. (2010a) to provide a differentially private algorithm with just poly-log regret. Finally, we show that our online learning framework can be used to provide differentially private algorithms for the offline learning problem as well. For the offline learning problem, our approach guarantees \\emphbetter error bounds and is more practical than the existing state-of-the-art methods (Chaudhuri et al., 2011; Rubinstein et al., 2009).",
        "bibtex": "@InProceedings{pmlr-v23-jain12,\n  title = \t {Differentially Private Online Learning},\n  author = \t {Jain, Prateek and Kothari, Pravesh and Thakurta, Abhradeep},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {24.1--24.34},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/jain12/jain12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/jain12.html},\n  abstract = \t {In this paper, we consider the problem of preserving privacy in the context of online learning. Online learning involves learning from data in real-time, due to which the learned model as well as its predictions are continuously changing. This makes preserving privacy of each data point significantly more challenging as its effect on the learned model can be easily tracked by observing changes in the subsequent predictions. Furthermore, with more and more online systems (e.g. search engines like Bing, Google etc.) trying to learn their customers\u2019 behavior by leveraging their access to sensitive customer data (through cookies etc.), the problem of privacy preserving online learning has become critical. We study the problem in the framework of online convex programming (OCP) \u2013 a popular online learning setting with several theoretical and practical implications \u2013 while using differential privacy as the formal measure of privacy. For this problem, we provide a generic framework that can be used to convert any given OCP algorithm into a private OCP algorithm with provable privacy as well as regret guarantees (utility), provided that the given OCP algorithm satisfies the following two criteria: 1) linearly decreasing sensitivity, i.e., the effect of the new data points on the learned model decreases linearly, 2) sub-linear regret. We then illustrate our approach by converting two popular OCP algorithms into corresponding differentially private algorithms while guaranteeing \\emph\u00d5(\u221aT)  regret for strongly convex functions. Next, we consider the practically important class of online linear regression problems, for which we generalize the approach by Dwork et al. (2010a) to provide a differentially private algorithm with just poly-log regret. Finally, we show that our online learning framework can be used to provide differentially private algorithms for the offline learning problem as well. For the offline learning problem, our approach guarantees \\emphbetter error bounds and is more practical than the existing state-of-the-art methods (Chaudhuri et al., 2011; Rubinstein et al., 2009).}\n}",
        "pdf": "http://proceedings.mlr.press/v23/jain12/jain12.pdf",
        "supp": "",
        "pdf_size": 763544,
        "gs_citation": 296,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12330796004705389353&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Microsoft Research India; University of Texas at Austin; Pennsylvania State University",
        "aff_domain": "MICROSOFT.COM;CS.UTEXAS.EDU;CSE.PSU.EDU",
        "email": "MICROSOFT.COM;CS.UTEXAS.EDU;CSE.PSU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Microsoft;University of Texas at Austin;Pennsylvania State University",
        "aff_unique_dep": "Microsoft Research India;;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-india;https://www.utexas.edu;https://www.psu.edu",
        "aff_unique_abbr": "MSR India;UT Austin;PSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "d22f5651e2",
        "title": "Distance Preserving Embeddings for General n-Dimensional Manifolds",
        "site": "https://proceedings.mlr.press/v23/verma12.html",
        "author": "Nakul Verma",
        "abstract": "Low dimensional embeddings of manifold data have gained popularity in the last decade. However, a systematic finite sample analysis of manifold embedding algorithms largely eludes researchers. Here we present two algorithms that, given access to just the samples, embed the underlying n- dimensional manifold into R^d (where d only depends on some key manifold properties such as its intrinsic dimension, volume and curvature) and \\emphguarantee to approximately preserve all interpoint geodesic distances.",
        "bibtex": "@InProceedings{pmlr-v23-verma12,\n  title = \t {Distance Preserving Embeddings for General $n$-Dimensional Manifolds},\n  author = \t {Verma, Nakul},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {32.1--32.28},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/verma12/verma12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/verma12.html},\n  abstract = \t {Low dimensional embeddings of manifold data have gained popularity in the last decade. However, a systematic finite sample analysis of manifold embedding algorithms largely eludes researchers. Here we present two algorithms that, given access to just the samples, embed the underlying n- dimensional manifold into R^d (where d only depends on some key manifold properties such as its intrinsic dimension, volume and curvature) and \\emphguarantee to approximately preserve all interpoint geodesic distances.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/verma12/verma12.pdf",
        "supp": "",
        "pdf_size": 690403,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3451316743146650487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Department of Computer Science and Engineering, University of California, San Diego",
        "aff_domain": "CS.UCSD.EDU",
        "email": "CS.UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "757dd968f9",
        "title": "Distributed Learning, Communication Complexity and Privacy",
        "site": "https://proceedings.mlr.press/v23/balcan12a.html",
        "author": "Maria Florina Balcan; Avrim Blum; Shai Fine; Yishay Mansour",
        "abstract": "We consider the problem of PAC-learning from distributed data and analyze fundamental communication complexity questions involved. We provide general upper and lower bounds on the amount of communication needed to learn well, showing that in addition to VC-dimension and covering number, quantities such as the teaching-dimension and mistake-bound of a class play an important role. We also present tight results for a number of common concept classes including conjunctions, parity functions, and decision lists. For linear separators, we show that for non-concentrated distributions, we can use a version of the Perceptron algorithm to learn with much less communication than the number of updates given by the usual margin bound. We also show how boosting can be performed in a generic manner in the distributed setting to achieve communication with only logarithmic dependence on 1/\u03b5 for any concept class, and demonstrate how recent work on agnostic learning from class-conditional queries can be used to achieve low communication in agnostic settings as well. We additionally present an analysis of privacy, considering both differential privacy and a notion of distributional privacy that is especially appealing in this context.",
        "bibtex": "@InProceedings{pmlr-v23-balcan12a,\n  title = \t {Distributed Learning, Communication Complexity and Privacy},\n  author = \t {Balcan, Maria Florina and Blum, Avrim and Fine, Shai and Mansour, Yishay},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {26.1--26.22},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/balcan12a/balcan12a.pdf},\n  url = \t {https://proceedings.mlr.press/v23/balcan12a.html},\n  abstract = \t {We consider the problem of PAC-learning from distributed data and analyze fundamental communication complexity questions involved. We provide general upper and lower bounds on the amount of communication needed to learn well, showing that in addition to VC-dimension and covering number, quantities such as the teaching-dimension and mistake-bound of a class play an important role. We also present tight results for a number of common concept classes including conjunctions, parity functions, and decision lists. For linear separators, we show that for non-concentrated distributions, we can use a version of the Perceptron algorithm to learn with much less communication than the number of updates given by the usual margin bound. We also show how boosting can be performed in a generic manner in the distributed setting to achieve communication with only logarithmic dependence on 1/\u03b5 for any concept class, and demonstrate how recent work on agnostic learning from class-conditional queries can be used to achieve low communication in agnostic settings as well. We additionally present an analysis of privacy, considering both differential privacy and a notion of distributional privacy that is especially appealing in this context.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/balcan12a/balcan12a.pdf",
        "supp": "",
        "pdf_size": 445249,
        "gs_citation": 231,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3519378176865696693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "aff": "Georgia Institute of Technology; Carnegie Mellon University; IBM Research; Tel Aviv University",
        "aff_domain": "CC.GATECH.EDU;CS.CMU.EDU;IL.IBM.COM;TAU.AC.IL",
        "email": "CC.GATECH.EDU;CS.CMU.EDU;IL.IBM.COM;TAU.AC.IL",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Georgia Institute of Technology;Carnegie Mellon University;IBM;Tel Aviv University",
        "aff_unique_dep": ";;IBM Research;",
        "aff_unique_url": "https://www.gatech.edu;https://www.cmu.edu;https://www.ibm.com/research;https://www.tau.ac.il",
        "aff_unique_abbr": "Georgia Tech;CMU;IBM;TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "7fc3cd149c",
        "title": "Divergences and Risks for Multiclass Experiments",
        "site": "https://proceedings.mlr.press/v23/garcia12.html",
        "author": "Dario Garc\u00eda-Garc\u00eda; Robert C. Williamson",
        "abstract": "Csisz\u00e1r\u2019s $f$-divergence is a way to measure the similarity of two probability distributions. We study the extension of $f$-divergence to more than two distributions to measure their joint similarity. By exploiting classical results from the comparison of experiments literature we prove the resulting divergence satisfies all the same properties as the traditional binary one. Considering the multidistribution case actually makes the proofs simpler. The key to these results is a formal bridge between these multidistribution $f$-divergences and Bayes risks for multiclass classification problems.",
        "bibtex": "@InProceedings{pmlr-v23-garcia12,\n  title = \t {Divergences and Risks for Multiclass Experiments},\n  author = \t {Garc\u00eda-Garc\u00eda, Dario and Williamson, Robert C.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {28.1--28.20},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/garcia12/garcia12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/garcia12.html},\n  abstract = \t {Csisz\u00e1r\u2019s $f$-divergence is a way to measure the similarity of two probability distributions. We study the extension of $f$-divergence to more than two distributions to measure their joint similarity. By exploiting classical results from the comparison of experiments literature we prove the resulting divergence satisfies all the same properties as the traditional binary one. Considering the multidistribution case actually makes the proofs simpler. The key to these results is a formal bridge between these multidistribution $f$-divergences and Bayes risks for multiclass classification problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/garcia12/garcia12.pdf",
        "supp": "",
        "pdf_size": 516194,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7611620018868223579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Australian National University and NICTA, Canberra ACT 0200, Australia; Australian National University and NICTA, Canberra ACT 0200, Australia",
        "aff_domain": "ANU.EDU.AU;ANU.EDU.AU",
        "email": "ANU.EDU.AU;ANU.EDU.AU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Canberra",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "7d1b39ad6a",
        "title": "Exact Recovery of Sparsely-Used Dictionaries",
        "site": "https://proceedings.mlr.press/v23/spielman12.html",
        "author": "Daniel A. Spielman; Huan Wang; John Wright",
        "abstract": "We consider the problem of learning sparsely used dictionaries with an arbitrary square dictionary and a random, sparse coefficient matrix. We prove that \\emphO(n log \\emphn) samples are sufficient to uniquely determine the coefficient matrix. Based on this proof, we design a polynomial-time algorithm, called Exact Recovery of Sparsely-Used Dictionaries (ER-SpUD), and prove that it probably recovers the dictionary and coefficient matrix when the coefficient matrix is sufficiently sparse. Simulation results show that ER-SpUD reveals the true dictionary as well as the coefficients with probability higher than many state-of-the-art algorithms.",
        "bibtex": "@InProceedings{pmlr-v23-spielman12,\n  title = \t {Exact Recovery of Sparsely-Used Dictionaries},\n  author = \t {Spielman, Daniel A. and Wang, Huan and Wright, John},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {37.1--37.18},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/spielman12/spielman12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/spielman12.html},\n  abstract = \t {We consider the problem of learning sparsely used dictionaries with an arbitrary square dictionary and a random, sparse coefficient matrix. We prove that \\emphO(n log \\emphn) samples are sufficient to uniquely determine the coefficient matrix. Based on this proof, we design a polynomial-time algorithm, called Exact Recovery of Sparsely-Used Dictionaries (ER-SpUD), and prove that it probably recovers the dictionary and coefficient matrix when the coefficient matrix is sufficiently sparse. Simulation results show that ER-SpUD reveals the true dictionary as well as the coefficients with probability higher than many state-of-the-art algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/spielman12/spielman12.pdf",
        "supp": "",
        "pdf_size": 460509,
        "gs_citation": 326,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2863385351030696858&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "Department of Computer Science, Yale University; Department of Computer Science, Yale University; Department of Electrical Engineering, Columbia University",
        "aff_domain": "CS.YALE.EDU;YALE.EDU;EE.COLUMBIA.EDU",
        "email": "CS.YALE.EDU;YALE.EDU;EE.COLUMBIA.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Yale University;Columbia University",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical Engineering",
        "aff_unique_url": "https://www.yale.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Yale;Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ffb4a0c49d",
        "title": "Generalization Bounds for Online Learning Algorithms with Pairwise Loss Functions",
        "site": "https://proceedings.mlr.press/v23/wang12.html",
        "author": "Yuyang Wang; Roni Khardon; Dmitry Pechyony; Rosie Jones",
        "abstract": "Efficient online learning with pairwise loss functions is a crucial component in building largescale learning system that maximizes the area under the Receiver Operator Characteristic (ROC) curve. In this paper we investigate the generalization performance of online learning algorithms with pairwise loss functions. We show that the existing proof techniques for generalization bounds of online algorithms with a pointwise loss can not be directly applied to pairwise losses. Using the Hoeffding-Azuma inequality and various proof techniques for the risk bounds in the batch learning, we derive data-dependent bounds for the average risk of the sequence of hypotheses generated by an arbitrary online learner in terms of an easily computable statistic, and show how to extract a low risk hypothesis from the sequence. In addition, we analyze a natural extension of the perceptron algorithm for the bipartite ranking problem providing a bound on the empirical pairwise loss. Combining these results we get a complete risk analysis of the proposed algorithm.",
        "bibtex": "@InProceedings{pmlr-v23-wang12,\n  title = \t {Generalization Bounds for Online Learning Algorithms with Pairwise Loss Functions},\n  author = \t {Wang, Yuyang and Khardon, Roni and Pechyony, Dmitry and Jones, Rosie},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {13.1--13.22},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/wang12/wang12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/wang12.html},\n  abstract = \t {Efficient online learning with pairwise loss functions is a crucial component in building largescale learning system that maximizes the area under the Receiver Operator Characteristic (ROC) curve. In this paper we investigate the generalization performance of online learning algorithms with pairwise loss functions. We show that the existing proof techniques for generalization bounds of online algorithms with a pointwise loss can not be directly applied to pairwise losses. Using the Hoeffding-Azuma inequality and various proof techniques for the risk bounds in the batch learning, we derive data-dependent bounds for the average risk of the sequence of hypotheses generated by an arbitrary online learner in terms of an easily computable statistic, and show how to extract a low risk hypothesis from the sequence. In addition, we analyze a natural extension of the perceptron algorithm for the bipartite ranking problem providing a bound on the empirical pairwise loss. Combining these results we get a complete risk analysis of the proposed algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/wang12/wang12.pdf",
        "supp": "",
        "pdf_size": 573449,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6381688787383175764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, Tufts University, Medford, MA 02155, USA; Department of Computer Science, Tufts University, Medford, MA 02155, USA; Akamai Technologies, 8 Cambridge Center, Cambridge, MA 02142, USA; Akamai Technologies, 8 Cambridge Center, Cambridge, MA 02142, USA",
        "aff_domain": "CS.TUFTS.EDU;CS.TUFTS.EDU;AKAMAI.COM;AKAMAI.COM",
        "email": "CS.TUFTS.EDU;CS.TUFTS.EDU;AKAMAI.COM;AKAMAI.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Tufts University;Akamai Technologies",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.tufts.edu;https://www.akamai.com",
        "aff_unique_abbr": "Tufts;Akamai",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Medford;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c41083e068",
        "title": "Kernels Based Tests with Non-asymptotic Bootstrap Approaches for Two-sample Problems",
        "site": "https://proceedings.mlr.press/v23/fromont12.html",
        "author": "Magalie Fromont; B\u00c3\u00a9atrice Laurent; Matthieu Lerasle; Patricia Reynaud-Bouret",
        "abstract": "Considering either two independent i.i.d. samples, or two independent samples generated from a heteroscedastic regression model, or two independent Poisson processes, we address the question of testing equality of their respective distributions. We first propose single testing procedures based on a general symmetric kernel. The corresponding critical values are chosen from a wild or permutation bootstrap approach, and the obtained tests are exactly (and not just asymptotically) of level. We then introduce an aggregation method, which enables to overcome the difficulty of choosing a kernel and/or the parameters of the kernel. We derive non-asymptotic properties for the aggregated tests, proving that they may be optimal in a classical statistical sense.",
        "bibtex": "@InProceedings{pmlr-v23-fromont12,\n  title = \t {Kernels Based Tests with Non-asymptotic Bootstrap Approaches for Two-sample Problems},\n  author = \t {Fromont, Magalie and Laurent, B\u00c3\u00a9atrice and Lerasle, Matthieu and Reynaud-Bouret, Patricia},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {23.1--23.23},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/fromont12/fromont12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/fromont12.html},\n  abstract = \t {Considering either two independent i.i.d. samples, or two independent samples generated from a heteroscedastic regression model, or two independent Poisson processes, we address the question of testing equality of their respective distributions. We first propose single testing procedures based on a general symmetric kernel. The corresponding critical values are chosen from a wild or permutation bootstrap approach, and the obtained tests are exactly (and not just asymptotically) of level. We then introduce an aggregation method, which enables to overcome the difficulty of choosing a kernel and/or the parameters of the kernel. We derive non-asymptotic properties for the aggregated tests, proving that they may be optimal in a classical statistical sense.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/fromont12/fromont12.pdf",
        "supp": "",
        "pdf_size": 489576,
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8959031920287275802&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 19,
        "aff": "CREST Ensai / IRMAR - Campus de Ker-Lann - BP 37203 - 35172 Bruz Cedex (FRANCE); IMT, INSA Toulouse - 135 av. de Rangueil - 31077 Toulouse Cedex 4 (FRANCE); CNRS Universit \u00b4e de Nice Sophia-Antipolis - 06108 Nice Cedex 2 (FRANCE); CNRS Universit \u00b4e de Nice Sophia-Antipolis - 06108 Nice Cedex 2 (FRANCE)",
        "aff_domain": "ensai.fr;insa-toulouse.fr;unice.fr;unice.fr",
        "email": "ensai.fr;insa-toulouse.fr;unice.fr;unice.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "CREST Ensai;INSA Toulouse;Universit\u00e9 de Nice Sophia-Antipolis",
        "aff_unique_dep": "IRMAR;;CNRS",
        "aff_unique_url": ";https://www.insa-toulouse.fr;https://www.unice.fr",
        "aff_unique_abbr": ";INSA Toulouse;UNice",
        "aff_campus_unique_index": "0;1;2;2",
        "aff_campus_unique": "Ker-Lann;Toulouse;Nice",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "f50cfb0388",
        "title": "L1 Covering Numbers for Uniformly Bounded Convex Functions",
        "site": "https://proceedings.mlr.press/v23/guntuboyina12.html",
        "author": "Adityanand Guntuboyina; Bodhisattva Sen",
        "abstract": "In this paper we study the covering numbers of the space of convex and uniformly bounded functions in multi-dimension. We find optimal upper and lower bounds for the \u03b5-covering number \\emphM(\\emphC([\\empha, b]^\\emphd, \\emphB), \u03b5, \\emphL_1) in terms of the relevant constants, where \\emphd > 1, \\empha < \\emphb \u2208 \\emphR, \\emphB > 0, and \\emphC([\\empha, b]^\\emphd, \\emphB) denotes the set of all convex functions on [\\empha, b]^\\emphd that are uniformly bounded by \\emphB. We summarize previously known results on covering numbers for convex functions and also provide alternate proofs of some known results. Our results have direct implications in the study of rates of convergence of empirical minimization procedures as well as optimal convergence rates in the numerous convexity constrained function estimation problems.",
        "bibtex": "@InProceedings{pmlr-v23-guntuboyina12,\n  title = \t {L1 Covering Numbers for Uniformly Bounded Convex Functions},\n  author = \t {Guntuboyina, Adityanand and Sen, Bodhisattva},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {12.1--12.13},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/guntuboyina12/guntuboyina12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/guntuboyina12.html},\n  abstract = \t {In this paper we study the covering numbers of the space of convex and uniformly bounded functions in multi-dimension. We find optimal upper and lower bounds for the \u03b5-covering number \\emphM(\\emphC([\\empha, b]^\\emphd, \\emphB), \u03b5, \\emphL_1) in terms of the relevant constants, where \\emphd > 1, \\empha < \\emphb \u2208 \\emphR, \\emphB > 0, and \\emphC([\\empha, b]^\\emphd, \\emphB) denotes the set of all convex functions on [\\empha, b]^\\emphd that are uniformly bounded by \\emphB. We summarize previously known results on covering numbers for convex functions and also provide alternate proofs of some known results. Our results have direct implications in the study of rates of convergence of empirical minimization procedures as well as optimal convergence rates in the numerous convexity constrained function estimation problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/guntuboyina12/guntuboyina12.pdf",
        "supp": "",
        "pdf_size": 345808,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4006446482081673855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Statistics, University of California, Berkeley; Statistical Laboratory, University of Cambridge",
        "aff_domain": "stat.berkeley.edu;statslab.cam.ac.uk",
        "email": "stat.berkeley.edu;statslab.cam.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Berkeley;University of Cambridge",
        "aff_unique_dep": "Department of Statistics;Statistical Laboratory",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cam.ac.uk",
        "aff_unique_abbr": "UC Berkeley;Cambridge",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Berkeley;Cambridge",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "b29dde93ec",
        "title": "Learning DNF Expressions from Fourier Spectrum",
        "site": "https://proceedings.mlr.press/v23/feldman12b.html",
        "author": "Vitaly Feldman",
        "abstract": "Since its introduction by Valiant in 1984, PAC learning of DNF expressions remains one of the central problems in learning theory. We consider this problem in the setting where the underlying distribution is uniform, or more generally, a product distribution. Kalai, Samorodnitsky, and Teng (2009b) showed that in this setting a DNF expression can be efficiently approximated from its \u201cheavy\u201d low-degree Fourier coefficients alone. This is in contrast to previous approaches where boosting was used and thus Fourier coefficients of the target function modified by various distributions were needed. This property is crucial for learning of DNF expressions over smoothed product distributions, a learning model introduced by Kalai et al. (2009b) and inspired by the seminal smoothed analysis model of Spielman and Teng (2004). We introduce a new approach to learning (or approximating) a polynomial threshold functions which is based on creating a function with range [-1, 1] that approximately agrees with the unknown function on low-degree Fourier coefficients. We then describe conditions under which this is sufficient for learning polynomial threshold functions. Our approach yields a new, simple algorithm for approximating any polynomial-size DNF expression from its \u201cheavy\u201d low-degree Fourier coefficients alone. This algorithm greatly simplifies the proof of learnability of DNF expressions over smoothed product distributions and is simpler than all previous algorithm for PAC learning of DNF expression using membership queries. We also describe an application of our algorithm to learning monotone DNF expressions over product distributions. Building on the work of Servedio (2004), we give an algorithm that runs in time poly((\\emphs\u22c5 log (\\emphs/\u03b5))^log (\\emphs/\u03b5), \\emphn), where \\emphs is the size of the DNF expression and \u03b5 is the accuracy. This improves on poly((\\emphs\u22c5 log (\\emphns/\u03b5))^log (\\emphs/\u03b5)\u22c5 log(1/\u03b5), \\emphn) bound of Servedio (2004).",
        "bibtex": "@InProceedings{pmlr-v23-feldman12b,\n  title = \t {Learning DNF Expressions from Fourier Spectrum},\n  author = \t {Feldman, Vitaly},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {17.1--17.19},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/feldman12b/feldman12b.pdf},\n  url = \t {https://proceedings.mlr.press/v23/feldman12b.html},\n  abstract = \t {Since its introduction by Valiant in 1984, PAC learning of DNF expressions remains one of the central problems in learning theory. We consider this problem in the setting where the underlying distribution is uniform, or more generally, a product distribution. Kalai, Samorodnitsky, and Teng (2009b) showed that in this setting a DNF expression can be efficiently approximated from its \u201cheavy\u201d low-degree Fourier coefficients alone. This is in contrast to previous approaches where boosting was used and thus Fourier coefficients of the target function modified by various distributions were needed. This property is crucial for learning of DNF expressions over smoothed product distributions, a learning model introduced by Kalai et al. (2009b) and inspired by the seminal smoothed analysis model of Spielman and Teng (2004). We introduce a new approach to learning (or approximating) a polynomial threshold functions which is based on creating a function with range [-1, 1] that approximately agrees with the unknown function on low-degree Fourier coefficients. We then describe conditions under which this is sufficient for learning polynomial threshold functions. Our approach yields a new, simple algorithm for approximating any polynomial-size DNF expression from its \u201cheavy\u201d low-degree Fourier coefficients alone. This algorithm greatly simplifies the proof of learnability of DNF expressions over smoothed product distributions and is simpler than all previous algorithm for PAC learning of DNF expression using membership queries. We also describe an application of our algorithm to learning monotone DNF expressions over product distributions. Building on the work of Servedio (2004), we give an algorithm that runs in time poly((\\emphs\u22c5 log (\\emphs/\u03b5))^log (\\emphs/\u03b5), \\emphn), where \\emphs is the size of the DNF expression and \u03b5 is the accuracy. This improves on poly((\\emphs\u22c5 log (\\emphns/\u03b5))^log (\\emphs/\u03b5)\u22c5 log(1/\u03b5), \\emphn) bound of Servedio (2004).}\n}",
        "pdf": "http://proceedings.mlr.press/v23/feldman12b/feldman12b.pdf",
        "supp": "",
        "pdf_size": 431438,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3461299295483420287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "896fec6298",
        "title": "Learning Functions of Halfspaces Using Prefix Covers",
        "site": "https://proceedings.mlr.press/v23/gopalan12.html",
        "author": "Parikshit Gopalan; Adam R. Klivans; Raghu Meka",
        "abstract": "We present a simple query-algorithm for learning arbitrary functions of k halfspaces under any product distribution on the Boolean hypercube. Our algorithms learn any function of k halfspaces to within accuracy \u03b5 in time \\emphO((nk/\u03b5)^k+1) under any product distribution on 0, 1^\\emphn using read-once branching programs as a hypothesis. This gives the first \\emphpoly(n, 1/\u03b5) algorithm for learning even the intersection of 2 halfspaces under the uniform distribution on 0, 1^\\emphn previously known algorithms had an exponential dependence either on the accuracy parameter \u03b5 or the dimension \\emphn. To prove this result, we identify a new structural property of Boolean functions that yields learnability with queries: that of having a small prefix cover.",
        "bibtex": "@InProceedings{pmlr-v23-gopalan12,\n  title = \t {Learning Functions of Halfspaces Using Prefix Covers},\n  author = \t {Gopalan, Parikshit and Klivans, Adam R. and Meka, Raghu},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {15.1--15.10},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/gopalan12/gopalan12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/gopalan12.html},\n  abstract = \t {We present a simple query-algorithm for learning arbitrary functions of k halfspaces under any product distribution on the Boolean hypercube. Our algorithms learn any function of k halfspaces to within accuracy \u03b5 in time \\emphO((nk/\u03b5)^k+1) under any product distribution on 0, 1^\\emphn using read-once branching programs as a hypothesis. This gives the first \\emphpoly(n, 1/\u03b5) algorithm for learning even the intersection of 2 halfspaces under the uniform distribution on 0, 1^\\emphn previously known algorithms had an exponential dependence either on the accuracy parameter \u03b5 or the dimension \\emphn. To prove this result, we identify a new structural property of Boolean functions that yields learnability with queries: that of having a small prefix cover.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/gopalan12/gopalan12.pdf",
        "supp": "",
        "pdf_size": 294106,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15572764556443615482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "MSR Silicon Valley, Mountain View, California; Department of Computer Science, UT Austin; IAS, Princeton",
        "aff_domain": "microsoft.com;cs.utexas.edu;ias.edu",
        "email": "microsoft.com;cs.utexas.edu;ias.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Microsoft;University of Texas at Austin;Institute for Advanced Study",
        "aff_unique_dep": "Microsoft Research;Department of Computer Science;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-silicon-valley;https://www.utexas.edu;https://www.ias.edu",
        "aff_unique_abbr": "MSR;UT Austin;IAS",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Silicon Valley;Austin;Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "03a370975e",
        "title": "Learning Valuation Functions",
        "site": "https://proceedings.mlr.press/v23/balcan12b.html",
        "author": "Maria Florina Balcan; Florin Constantin; Satoru Iwata; Lei Wang",
        "abstract": "A core element of microeconomics and game theory is that consumers have valuation functions over bundles of goods and that these valuations functions drive their purchases. A common assumption is that these functions are subadditive meaning that the value given to a bundle is at most the sum of values on the individual items. In this paper, we provide nearly tight guarantees on the efficient learnability of subadditive valuations. We also provide nearly tight bounds for the subclass of XOS (fractionally subadditive) valuations, also widely used in the literature. We additionally leverage the structure of valuations in a number of interesting subclasses and obtain algorithms with stronger learning guarantees.",
        "bibtex": "@InProceedings{pmlr-v23-balcan12b,\n  title = \t {Learning Valuation Functions},\n  author = \t {Balcan, Maria Florina and Constantin, Florin and Iwata, Satoru and Wang, Lei},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {4.1--4.24},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/balcan12b/balcan12b.pdf},\n  url = \t {https://proceedings.mlr.press/v23/balcan12b.html},\n  abstract = \t {A core element of microeconomics and game theory is that consumers have valuation functions over bundles of goods and that these valuations functions drive their purchases. A common assumption is that these functions are subadditive meaning that the value given to a bundle is at most the sum of values on the individual items. In this paper, we provide nearly tight guarantees on the efficient learnability of subadditive valuations. We also provide nearly tight bounds for the subclass of XOS (fractionally subadditive) valuations, also widely used in the literature. We additionally leverage the structure of valuations in a number of interesting subclasses and obtain algorithms with stronger learning guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/balcan12b/balcan12b.pdf",
        "supp": "",
        "pdf_size": 577496,
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5038968911214889005&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Georgia Institute of Technology, Atlanta, GA; A9.com, Palo Alto, CA; Kyoto University, Japan; Microsoft AdCenter, Bellevue, WA",
        "aff_domain": "CC.GATECH.EDU;GMAIL.COM;KURIMS.KYOTO-U.AC.JP;MICROSOFT.COM",
        "email": "CC.GATECH.EDU;GMAIL.COM;KURIMS.KYOTO-U.AC.JP;MICROSOFT.COM",
        "github": "",
        "project": "http://bit.ly/ls774D",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Georgia Institute of Technology;A9.com;Kyoto University;Microsoft",
        "aff_unique_dep": ";;;AdCenter",
        "aff_unique_url": "https://www.gatech.edu;https://www.a9.com;https://www.kyoto-u.ac.jp;https://www.microsoft.com",
        "aff_unique_abbr": "Georgia Tech;A9;Kyoto U;Microsoft",
        "aff_campus_unique_index": "0;1;3",
        "aff_campus_unique": "Atlanta;Palo Alto;;Bellevue",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "12a5849838",
        "title": "Near-Optimal Algorithms for Online Matrix Prediction",
        "site": "https://proceedings.mlr.press/v23/hazan12b.html",
        "author": "Elad Hazan; Satyen Kale; Shai Shalev-Shwartz",
        "abstract": "In several online prediction problems of recent interest the comparison class is composed of matrices with bounded entries. For example, in the online max-cut problem, the comparison class is matrices which represent cuts of a given graph and in online gambling the comparison class is matrices which represent permutations over n teams. Another important example is online collaborative filtering in which a widely used comparison class is the set of matrices with a small trace norm. In this paper we isolate a property of matrices, which we call (\u03b2,\u03c4)-decomposability, and derive an efficient online learning algorithm, that enjoys a regret bound of \\emph\u00d5(\u221a\u03b2\u03c4T ) for all problems in which the comparison class is composed of (\u03b2,\u03c4)-decomposable matrices. By analyzing the decomposability of cut matrices, low trace-norm matrices and triangular matrices, we derive near optimal regret bounds for online max-cut, online collaborative filtering and online gambling. In particular, this resolves (in the affirmative) an open problem posed by Abernethy (2010); Kleinberg et al. (2010). Finally, we derive lower bounds for the three problems and show that our upper bounds are optimal up to logarithmic factors. In particular, our lower bound for the online collaborative filtering problem resolves another open problem posed by Shamir and Srebro (2011).",
        "bibtex": "@InProceedings{pmlr-v23-hazan12b,\n  title = \t {Near-Optimal Algorithms for Online Matrix Prediction},\n  author = \t {Hazan, Elad and Kale, Satyen and Shalev-Shwartz, Shai},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {38.1--38.13},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/hazan12b/hazan12b.pdf},\n  url = \t {https://proceedings.mlr.press/v23/hazan12b.html},\n  abstract = \t {In several online prediction problems of recent interest the comparison class is composed of matrices with bounded entries. For example, in the online max-cut problem, the comparison class is matrices which represent cuts of a given graph and in online gambling the comparison class is matrices which represent permutations over n teams. Another important example is online collaborative filtering in which a widely used comparison class is the set of matrices with a small trace norm. In this paper we isolate a property of matrices, which we call (\u03b2,\u03c4)-decomposability, and derive an efficient online learning algorithm, that enjoys a regret bound of \\emph\u00d5(\u221a\u03b2\u03c4T ) for all problems in which the comparison class is composed of (\u03b2,\u03c4)-decomposable matrices. By analyzing the decomposability of cut matrices, low trace-norm matrices and triangular matrices, we derive near optimal regret bounds for online max-cut, online collaborative filtering and online gambling. In particular, this resolves (in the affirmative) an open problem posed by Abernethy (2010); Kleinberg et al. (2010). Finally, we derive lower bounds for the three problems and show that our upper bounds are optimal up to logarithmic factors. In particular, our lower bound for the online collaborative filtering problem resolves another open problem posed by Shamir and Srebro (2011).}\n}",
        "pdf": "http://proceedings.mlr.press/v23/hazan12b/hazan12b.pdf",
        "supp": "",
        "pdf_size": 368171,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9236717159630620115&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 19,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0f1f30ccff",
        "title": "New Bounds for Learning Intervals with Implications for Semi-Supervised Learning",
        "site": "https://proceedings.mlr.press/v23/helmbold12.html",
        "author": "David P. Helmbold; Philip M. Long",
        "abstract": "We study learning of initial intervals in the prediction model. We show that for each distribution \\emphD over the domain, there is an algorithm \\emphA_D, whose probability of a mistake in round m is at most \\emph(\u00bd + o(1))/m. We also show that the best possible bound that can be achieved in the case in which the same algorithm \\emphA must be applied for all distributions \\emphD is at least (^1\u2044_\u221a\\emphe - o(1))^1\u2044_\\emphm > (^3\u2044_5-o(1))^1\u2044_\\emphm. Informally, \u201cknowing\u201d the distribution \\emphD enables an algorithm to reduce its error rate by a constant factor strictly greater than 1. As advocated by Ben-David et al. (2008), knowledge of \\emphD can be viewed as an idealized proxy for a large number of unlabeled examples.",
        "bibtex": "@InProceedings{pmlr-v23-helmbold12,\n  title = \t {New Bounds for Learning Intervals with Implications for Semi-Supervised Learning},\n  author = \t {Helmbold, David P. and Long, Philip M.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {30.1--30.15},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/helmbold12/helmbold12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/helmbold12.html},\n  abstract = \t {We study learning of initial intervals in the prediction model. We show that for each distribution \\emphD over the domain, there is an algorithm \\emphA_D, whose probability of a mistake in round m is at most \\emph(\u00bd + o(1))/m. We also show that the best possible bound that can be achieved in the case in which the same algorithm \\emphA must be applied for all distributions \\emphD is at least (^1\u2044_\u221a\\emphe - o(1))^1\u2044_\\emphm > (^3\u2044_5-o(1))^1\u2044_\\emphm. Informally, \u201cknowing\u201d the distribution \\emphD enables an algorithm to reduce its error rate by a constant factor strictly greater than 1. As advocated by Ben-David et al. (2008), knowledge of \\emphD can be viewed as an idealized proxy for a large number of unlabeled examples.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/helmbold12/helmbold12.pdf",
        "supp": "",
        "pdf_size": 383337,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5464142400029293241&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, University of California at Santa Cruz; NEC Labs America",
        "aff_domain": "SOE.UCSC.EDU;SV.NEC-LABS.COM",
        "email": "SOE.UCSC.EDU;SV.NEC-LABS.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Santa Cruz;NEC Labs America",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.ucsc.edu;https://www.nec-labs.com",
        "aff_unique_abbr": "UCSC;NEC LA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Santa Cruz;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "90bbc266f6",
        "title": "Online Optimization with Gradual Variations",
        "site": "https://proceedings.mlr.press/v23/chiang12.html",
        "author": "Chao-Kai Chiang; Tianbao Yang; Chia-Jung Lee; Mehrdad Mahdavi; Chi-Jen Lu; Rong Jin; Shenghuo Zhu",
        "abstract": "We study the online convex optimization problem, in which an online algorithm has to make repeated decisions with convex loss functions and hopes to achieve a small regret. We consider a natural restriction of this problem in which the loss functions have a small deviation, measured by the sum of the distances between every two consecutive loss functions, according to some distance metrics. We show that for the linear and general smooth convex loss functions, an online algorithm modified from the gradient descend algorithm can achieve a regret which only scales as the square root of the deviation. For the closely related problem of prediction with expert advice, we show that an online algorithm modified  from the multiplicative update algorithm can also achieve a similar regret bound for a different measure of deviation. Finally, for loss functions which are strictly convex, we show that an online algorithm modified from the online Newton step algorithm can achieve a regret which is only logarithmic in terms of the deviation, and as an application, we can also have such a logarithmic regret for the portfolio management problem.",
        "bibtex": "@InProceedings{pmlr-v23-chiang12,\n  title = \t {Online Optimization with Gradual Variations},\n  author = \t {Chiang, Chao-Kai and Yang, Tianbao and Lee, Chia-Jung and Mahdavi, Mehrdad and Lu, Chi-Jen and Jin, Rong and Zhu, Shenghuo},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {6.1--6.20},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/chiang12/chiang12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/chiang12.html},\n  abstract = \t {We study the online convex optimization problem, in which an online algorithm has to make repeated decisions with convex loss functions and hopes to achieve a small regret. We consider a natural restriction of this problem in which the loss functions have a small deviation, measured by the sum of the distances between every two consecutive loss functions, according to some distance metrics. We show that for the linear and general smooth convex loss functions, an online algorithm modified from the gradient descend algorithm can achieve a regret which only scales as the square root of the deviation. For the closely related problem of prediction with expert advice, we show that an online algorithm modified  from the multiplicative update algorithm can also achieve a similar regret bound for a different measure of deviation. Finally, for loss functions which are strictly convex, we show that an online algorithm modified from the online Newton step algorithm can achieve a regret which is only logarithmic in terms of the deviation, and as an application, we can also have such a logarithmic regret for the portfolio management problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/chiang12/chiang12.pdf",
        "supp": "",
        "pdf_size": 447423,
        "gs_citation": 284,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6069896665199418204&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "aff": "Institute of Information Science, Academia Sinica, Taipei, Taiwan + Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, 48824, USA; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, 48824, USA; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, 48824, USA; NEC Laboratories America, Cupertino, CA, 95014, USA",
        "aff_domain": "iis.sinica.edu.tw;msu.edu;iis.sinica.edu.tw;cse.msu.edu;iis.sinica.edu.tw;cse.msu.edu;sv.nec-labs.com",
        "email": "iis.sinica.edu.tw;msu.edu;iis.sinica.edu.tw;cse.msu.edu;iis.sinica.edu.tw;cse.msu.edu;sv.nec-labs.com",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;0;2;0;2;3",
        "aff_unique_norm": "Academia Sinica;National Taiwan University;Michigan State University;NEC Laboratories America",
        "aff_unique_dep": "Institute of Information Science;Department of Computer Science and Information Engineering;Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.sinica.edu.tw;https://www.ntu.edu.tw;https://www.msu.edu;https://www.nec-labs.com",
        "aff_unique_abbr": "AS;NTU;MSU;NEC Labs",
        "aff_campus_unique_index": "0+0;1;0;1;0;1;2",
        "aff_campus_unique": "Taiwan;East Lansing;Cupertino",
        "aff_country_unique_index": "0+0;1;0;1;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "7b6d7af654",
        "title": "Open Problem: Better Bounds for Online Logistic Regression",
        "site": "https://proceedings.mlr.press/v23/mcmahan12.html",
        "author": "H. Brendan McMahan; Matthew Streeter",
        "abstract": "Known algorithms applied to online logistic regression on a feasible set of \\emphL_2 diameter \\emphD achieve regret bounds like \\emphO(\\emphe^D log \\emphT) in one dimension, but we show a bound of \\emphO(\u221a\\emphD  + log \\emphT) is possible in a binary 1-dimensional problem. Thus, we pose the following question: Is it possible to achieve a regret bound for online logistic regression that is \\emphO(poly(\\emphD) log(\\emphT))? Even if this is not possible in general, it would be interesting to have a bound that reduces to our bound in the one-dimensional case.",
        "bibtex": "@InProceedings{pmlr-v23-mcmahan12,\n  title = \t {Open Problem: Better Bounds for Online Logistic Regression},\n  author = \t {McMahan, H. Brendan and Streeter, Matthew},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {44.1--44.3},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/mcmahan12/mcmahan12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/mcmahan12.html},\n  abstract = \t {Known algorithms applied to online logistic regression on a feasible set of \\emphL_2 diameter \\emphD achieve regret bounds like \\emphO(\\emphe^D log \\emphT) in one dimension, but we show a bound of \\emphO(\u221a\\emphD  + log \\emphT) is possible in a binary 1-dimensional problem. Thus, we pose the following question: Is it possible to achieve a regret bound for online logistic regression that is \\emphO(poly(\\emphD) log(\\emphT))? Even if this is not possible in general, it would be interesting to have a bound that reduces to our bound in the one-dimensional case.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/mcmahan12/mcmahan12.pdf",
        "supp": "",
        "pdf_size": 229555,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=522229806783837907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Google Inc., Seattle, WA; Google Inc., Pittsburgh, PA",
        "aff_domain": "GOOGLE.COM;GOOGLE.COM",
        "email": "GOOGLE.COM;GOOGLE.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seattle;Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "382011a0f6",
        "title": "Open Problem: Does AdaBoost Always Cycle?",
        "site": "https://proceedings.mlr.press/v23/rudin12.html",
        "author": "Cynthia Rudin; Robert E. Schapire; Ingrid Daubechies",
        "abstract": "We pose the question of whether the distributions computed by AdaBoost always converge to a cycle.",
        "bibtex": "@InProceedings{pmlr-v23-rudin12,\n  title = \t {Open Problem: Does AdaBoost Always Cycle?},\n  author = \t {Rudin, Cynthia and Schapire, Robert E. and Daubechies, Ingrid},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {46.1--46.4},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/rudin12/rudin12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/rudin12.html},\n  abstract = \t {We pose the question of whether the distributions computed by AdaBoost always converge to a cycle.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/rudin12/rudin12.pdf",
        "supp": "",
        "pdf_size": 201700,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Massachusetts Institute of Technology, MIT Sloan School of Management, Cambridge MA 02142 USA; Princeton University, Department of Computer Science, 35 Olden Street, Princeton, NJ 08540 USA; Duke University, Department of Mathematics, 111 Physics, Durham, NC 27708 USA",
        "aff_domain": "MIT.EDU;CS.PRINCETON.EDU;MATH.DUKE.EDU",
        "email": "MIT.EDU;CS.PRINCETON.EDU;MATH.DUKE.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;Princeton University;Duke University",
        "aff_unique_dep": "MIT Sloan School of Management;Department of Computer Science;Department of Mathematics",
        "aff_unique_url": "https://web.mit.edu;https://www.princeton.edu;https://www.duke.edu",
        "aff_unique_abbr": "MIT;Princeton;Duke",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Cambridge;Princeton;Durham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1355c3b479",
        "title": "Open Problem: Is Averaging Needed for Strongly Convex Stochastic Gradient Descent?",
        "site": "https://proceedings.mlr.press/v23/shamir12.html",
        "author": "Ohad Shamir",
        "abstract": "Stochastic gradient descent (SGD) is a simple and very popular iterative method to solve stochastic optimization problems which arise in machine learning. A common practice is to return the average of the SGD iterates. While the utility of this is well-understood for general convex problems, the situation is much less clear for strongly convex problems (such as solving SVM). Although the standard analysis in the strongly convex case requires averaging, it was recently shown that this actually degrades the convergence rate, and a better rate is obtainable by averaging just a suffix of the iterates. The question we pose is whether averaging is needed at all to get optimal rates.",
        "bibtex": "@InProceedings{pmlr-v23-shamir12,\n  title = \t {Open Problem: Is Averaging Needed for Strongly Convex Stochastic Gradient Descent?},\n  author = \t {Shamir, Ohad},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {47.1--47.3},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/shamir12/shamir12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/shamir12.html},\n  abstract = \t {Stochastic gradient descent (SGD) is a simple and very popular iterative method to solve stochastic optimization problems which arise in machine learning. A common practice is to return the average of the SGD iterates. While the utility of this is well-understood for general convex problems, the situation is much less clear for strongly convex problems (such as solving SVM). Although the standard analysis in the strongly convex case requires averaging, it was recently shown that this actually degrades the convergence rate, and a better rate is obtainable by averaging just a suffix of the iterates. The question we pose is whether averaging is needed at all to get optimal rates.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/shamir12/shamir12.pdf",
        "supp": "",
        "pdf_size": 223069,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11367625609270202145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Microsoft Research New England",
        "aff_domain": "microsoft.com",
        "email": "microsoft.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-new-england",
        "aff_unique_abbr": "MSR NE",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New England",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1d1f1177ff",
        "title": "Open Problem: Learning Dynamic Network Models from a Static Snapshot",
        "site": "https://proceedings.mlr.press/v23/ramon12.html",
        "author": "Jan Ramon; Constantin Comendant",
        "abstract": "In this paper we consider the problem of learning a graph generating process given the evolving graph at a single point in time. Given a graph of sufficient size, can we learn the (repeatable) process that generated it? We formalize the generic problem and then consider two simple instances which are variations on the well-know graph generation models by Erd\u00f3s-R\u00e9nyi and Albert-Barabasi.",
        "bibtex": "@InProceedings{pmlr-v23-ramon12,\n  title = \t {Open Problem: Learning Dynamic Network Models from a Static Snapshot},\n  author = \t {Ramon, Jan and Comendant, Constantin},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {45.1--45.3},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/ramon12/ramon12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/ramon12.html},\n  abstract = \t {In this paper we consider the problem of learning a graph generating process given the evolving graph at a single point in time. Given a graph of sufficient size, can we learn the (repeatable) process that generated it? We formalize the generic problem and then consider two simple instances which are variations on the well-know graph generation models by Erd\u00f3s-R\u00e9nyi and Albert-Barabasi.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/ramon12/ramon12.pdf",
        "supp": "",
        "pdf_size": 190262,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11536280645691789221&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Computer Science Dept., KU Leuven; Computer Science Dept., KU Leuven",
        "aff_domain": "CS.KULEUVEN.BE;CS.KULEUVEN.BE",
        "email": "CS.KULEUVEN.BE;CS.KULEUVEN.BE",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "Computer Science Dept.",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "cd144aaa93",
        "title": "Open Problem: Regret Bounds for Thompson Sampling",
        "site": "https://proceedings.mlr.press/v23/li12.html",
        "author": "Lihong Li; Olivier Chapelle",
        "abstract": "",
        "bibtex": "@InProceedings{pmlr-v23-li12,\n  title = \t {Open Problem: Regret Bounds for Thompson Sampling},\n  author = \t {Li, Lihong and Chapelle, Olivier},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {43.1--43.3},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/li12/li12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/li12.html}\n}",
        "pdf": "http://proceedings.mlr.press/v23/li12/li12.pdf",
        "supp": "",
        "pdf_size": 173273,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15467962437559331003&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Yahoo! Research, Santa Clara, CA 95054; Criteo, Palo Alto, CA 94301 + Yahoo Research",
        "aff_domain": "YAHOO-INC.COM;CRITEO.COM",
        "email": "YAHOO-INC.COM;CRITEO.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Yahoo! Research;Criteo;Yahoo",
        "aff_unique_dep": ";;Yahoo Research",
        "aff_unique_url": "https://research.yahoo.com;https://www.criteo.com;https://research.yahoo.com",
        "aff_unique_abbr": "Yahoo! Res;;Yahoo Research",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Santa Clara;Palo Alto;",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6668fc39c8",
        "title": "PAC-Bayesian Bound for Gaussian Process Regression and Multiple Kernel Additive Model",
        "site": "https://proceedings.mlr.press/v23/suzuki12.html",
        "author": "Taiji Suzuki",
        "abstract": "We develop a PAC-Bayesian bound for the convergence rate of a Bayesian variant of Multiple Kernel Learning (MKL) that is an estimation method for the sparse additive model. Standard analyses for MKL require a strong condition on the design analogous to the restricted eigenvalue condition for the analysis of Lasso and Dantzig selector. In this paper, we apply PAC-Bayesian technique to show that the Bayesian variant of MKL achieves the optimal convergence rate without such strong conditions on the design. Basically our approach is a combination of PAC-Bayes and recently developed theories of non-parametric Gaussian process regressions. Our bound is developed in a fixed design situation. Our analysis includes the existing result of Gaussian process as a special case and the proof is much simpler by virtue of PAC-Bayesian technique. We also give the convergence rate of the Bayesian variant of Group Lasso as a finite dimensional special case.",
        "bibtex": "@InProceedings{pmlr-v23-suzuki12,\n  title = \t {PAC-Bayesian Bound for Gaussian Process Regression and Multiple Kernel Additive Model},\n  author = \t {Suzuki, Taiji},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {8.1--8.20},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/suzuki12/suzuki12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/suzuki12.html},\n  abstract = \t {We develop a PAC-Bayesian bound for the convergence rate of a Bayesian variant of Multiple Kernel Learning (MKL) that is an estimation method for the sparse additive model. Standard analyses for MKL require a strong condition on the design analogous to the restricted eigenvalue condition for the analysis of Lasso and Dantzig selector. In this paper, we apply PAC-Bayesian technique to show that the Bayesian variant of MKL achieves the optimal convergence rate without such strong conditions on the design. Basically our approach is a combination of PAC-Bayes and recently developed theories of non-parametric Gaussian process regressions. Our bound is developed in a fixed design situation. Our analysis includes the existing result of Gaussian process as a special case and the proof is much simpler by virtue of PAC-Bayesian technique. We also give the convergence rate of the Bayesian variant of Group Lasso as a finite dimensional special case.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/suzuki12/suzuki12.pdf",
        "supp": "",
        "pdf_size": 474913,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16853014365077186481&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "The University of Tokyo",
        "aff_domain": "STAT.T.U-TOKYO.AC.JP",
        "email": "STAT.T.U-TOKYO.AC.JP",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "5cf0682208",
        "title": "Preface",
        "site": "https://proceedings.mlr.press/v23/mannor12.html",
        "author": "Shie Mannor; Nathan Srebro; Robert C. Williamson",
        "abstract": "Preface to the Proceedings of the 25th Annual Conference on Learning Theory June 25-27, 2012, Edinburgh, Scotland.",
        "bibtex": "@InProceedings{pmlr-v23-mannor12,\n  title = \t {Preface},\n  author = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {1.1--1.2},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/mannor12/mannor12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/mannor12.html},\n  abstract = \t {Preface to the Proceedings of the 25th Annual Conference on Learning Theory June 25-27, 2012, Edinburgh, Scotland.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/mannor12/mannor12.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14141043608347785016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "49930c5d12",
        "title": "Private Convex Empirical Risk Minimization and High-dimensional Regression",
        "site": "https://proceedings.mlr.press/v23/kifer12.html",
        "author": "Daniel Kifer; Adam Smith; Abhradeep Thakurta",
        "abstract": "We consider \\emphdifferentially private algorithms for convex empirical risk minimization (ERM). Differential privacy (Dwork et al., 2006b) is a recently introduced notion of privacy which guarantees that an algorithm\u2019s output does not depend on the data of any individual in the dataset. This is crucial in fields that handle sensitive data, such as genomics, collaborative filtering, and economics. Our motivation is the design of private algorithms for sparse learning problems, in which one aims to find solutions (e.g., regression parameters) with few non-zero coefficients. To this end: (a) We significantly extend the analysis of the \u201cobjective perturbation\u201d algorithm of Chaudhuri et al. (2011) for convex ERM problems. We show that their method can be modified to use less noise (be more accurate), and to apply to problems with hard constraints and non-differentiable regularizers. We also give a tighter, data-dependent analysis of the additional error introduced by their method. A key tool in our analysis is a new nontrivial limit theorem for differential privacy which is of independent interest: if a sequence of differentially private algorithms converges, in a \\emphweak sense, then the limit algorithm is also differentially private. In particular, our methods give the best known algorithms for differentially private linear regression. These methods work in settings where the number of parameters p is less than the number of samples n. (b) We give the first two private algorithms for \\emphsparse regression problems in high-dimensional settings, where p is much larger than n. We analyze their performance for linear regression: under standard assumptions on the data, our algorithms have vanishing empirical risk for n = poly(s, \\log p) when there exists a good regression vector with s nonzero coefficients. Our algorithms demonstrate that randomized algorithms for sparse regression problems can be both stable and accurate - a combination which is impossible for deterministic algorithms.",
        "bibtex": "@InProceedings{pmlr-v23-kifer12,\n  title = \t {Private Convex Empirical Risk Minimization and High-dimensional Regression},\n  author = \t {Kifer, Daniel and Smith, Adam and Thakurta, Abhradeep},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {25.1--25.40},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/kifer12/kifer12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/kifer12.html},\n  abstract = \t {We consider \\emphdifferentially private algorithms for convex empirical risk minimization (ERM). Differential privacy (Dwork et al., 2006b) is a recently introduced notion of privacy which guarantees that an algorithm\u2019s output does not depend on the data of any individual in the dataset. This is crucial in fields that handle sensitive data, such as genomics, collaborative filtering, and economics. Our motivation is the design of private algorithms for sparse learning problems, in which one aims to find solutions (e.g., regression parameters) with few non-zero coefficients. To this end: (a) We significantly extend the analysis of the \u201cobjective perturbation\u201d algorithm of Chaudhuri et al. (2011) for convex ERM problems. We show that their method can be modified to use less noise (be more accurate), and to apply to problems with hard constraints and non-differentiable regularizers. We also give a tighter, data-dependent analysis of the additional error introduced by their method. A key tool in our analysis is a new nontrivial limit theorem for differential privacy which is of independent interest: if a sequence of differentially private algorithms converges, in a \\emphweak sense, then the limit algorithm is also differentially private. In particular, our methods give the best known algorithms for differentially private linear regression. These methods work in settings where the number of parameters p is less than the number of samples n. (b) We give the first two private algorithms for \\emphsparse regression problems in high-dimensional settings, where p is much larger than n. We analyze their performance for linear regression: under standard assumptions on the data, our algorithms have vanishing empirical risk for n = poly(s, \\log p) when there exists a good regression vector with s nonzero coefficients. Our algorithms demonstrate that randomized algorithms for sparse regression problems can be both stable and accurate - a combination which is impossible for deterministic algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/kifer12/kifer12.pdf",
        "supp": "",
        "pdf_size": 703368,
        "gs_citation": 504,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8574447684348501195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science and Engineering; Department of Computer Science and Engineering; Department of Computer Science and Engineering",
        "aff_domain": "CSE.PSU.EDU;CSE.PSU.EDU;CSE.PSU.EDU",
        "email": "CSE.PSU.EDU;CSE.PSU.EDU;CSE.PSU.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://cse.ucsd.edu",
        "aff_unique_abbr": "UCSD CSE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "33c7d6c654",
        "title": "Random Design Analysis of Ridge Regression",
        "site": "https://proceedings.mlr.press/v23/hsu12.html",
        "author": "Daniel Hsu; Sham M. Kakade; Tong Zhang",
        "abstract": "This work gives a simultaneous analysis of both the ordinary least squares estimator and the ridge regression estimator in the random design setting under mild assumptions on the covariate/response distributions. In particular, the analysis provides sharp results on the \u201cout-of-sample\u201d prediction error, as opposed to the \u201cin-sample\u201d (fixed design) error. The analysis also reveals the effect of errors in the estimated covariance structure, as well as the effect of modeling errors; neither of which effects are present in the fixed design setting. The proof of the main results are based on a simple decomposition lemma combined with concentration inequalities for random vectors and matrices.",
        "bibtex": "@InProceedings{pmlr-v23-hsu12,\n  title = \t {Random Design Analysis of Ridge Regression},\n  author = \t {Hsu, Daniel and Kakade, Sham M. and Zhang, Tong},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {9.1--9.24},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/hsu12/hsu12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/hsu12.html},\n  abstract = \t {This work gives a simultaneous analysis of both the ordinary least squares estimator and the ridge regression estimator in the random design setting under mild assumptions on the covariate/response distributions. In particular, the analysis provides sharp results on the \u201cout-of-sample\u201d prediction error, as opposed to the \u201cin-sample\u201d (fixed design) error. The analysis also reveals the effect of errors in the estimated covariance structure, as well as the effect of modeling errors; neither of which effects are present in the fixed design setting. The proof of the main results are based on a simple decomposition lemma combined with concentration inequalities for random vectors and matrices.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/hsu12/hsu12.pdf",
        "supp": "",
        "pdf_size": 427260,
        "gs_citation": 186,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2259134116609045780&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Microsoft Research; Microsoft Research; Rutgers University",
        "aff_domain": "microsoft.com;microsoft.com;stat.rutgers.edu",
        "email": "microsoft.com;microsoft.com;stat.rutgers.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Microsoft;Rutgers University",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.rutgers.edu",
        "aff_unique_abbr": "MSR;Rutgers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a9b3b9db34",
        "title": "Rare Probability Estimation under Regularly Varying Heavy Tails",
        "site": "https://proceedings.mlr.press/v23/ohannessian12.html",
        "author": "Mesrob I. Ohannessian; Munther A. Dahleh",
        "abstract": "This paper studies the problem of estimating the probability of symbols that have occurred very rarely, in samples drawn independently from an unknown, possibly infinite, discrete distribution. In particular, we study the multiplicative consistency of estimators, defined as the ratio of the estimate to the true quantity converging to one. We first show that the classical Good-Turing estimator is not universally consistent in this sense, despite enjoying favorable additive properties. We then use Karamata\u2019s theory of regular variation to prove that regularly varying heavy tails are sufficient for consistency. At the core of this result is a multiplicative concentration that we establish both by extending the McAllester-Ortiz additive concentration for the missing mass to all rare probabilities and by exploiting regular variation. We also derive a family of estimators which, in addition to being consistent, address some of the shortcomings of the Good-Turing estimator. For example, they perform smoothing implicitly and have the absolute discounting structure of many heuristic algorithms. This also establishes a discrete parallel to extreme value theory, and many of the techniques therein can be adapted to the framework that we set forth.",
        "bibtex": "@InProceedings{pmlr-v23-ohannessian12,\n  title = \t {Rare Probability Estimation under Regularly Varying Heavy Tails},\n  author = \t {Ohannessian, Mesrob I. and Dahleh, Munther A.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {21.1--21.24},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/ohannessian12/ohannessian12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/ohannessian12.html},\n  abstract = \t {This paper studies the problem of estimating the probability of symbols that have occurred very rarely, in samples drawn independently from an unknown, possibly infinite, discrete distribution. In particular, we study the multiplicative consistency of estimators, defined as the ratio of the estimate to the true quantity converging to one. We first show that the classical Good-Turing estimator is not universally consistent in this sense, despite enjoying favorable additive properties. We then use Karamata\u2019s theory of regular variation to prove that regularly varying heavy tails are sufficient for consistency. At the core of this result is a multiplicative concentration that we establish both by extending the McAllester-Ortiz additive concentration for the missing mass to all rare probabilities and by exploiting regular variation. We also derive a family of estimators which, in addition to being consistent, address some of the shortcomings of the Good-Turing estimator. For example, they perform smoothing implicitly and have the absolute discounting structure of many heuristic algorithms. This also establishes a discrete parallel to extreme value theory, and many of the techniques therein can be adapted to the framework that we set forth.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/ohannessian12/ohannessian12.pdf",
        "supp": "",
        "pdf_size": 604065,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15679990907378103656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "LIDS, MIT, 32 Vassar Street, Cambridge, MA 02139; LIDS, MIT, 32 Vassar Street, Cambridge, MA 02139",
        "aff_domain": "MIT.EDU;MIT.EDU",
        "email": "MIT.EDU;MIT.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6926ecd568",
        "title": "Reconstruction from Anisotropic Random Measurements",
        "site": "https://proceedings.mlr.press/v23/rudelson12.html",
        "author": "Mark Rudelson; Shuheng Zhou",
        "abstract": "Random matrices are widely used in sparse recovery problems, and the relevant properties of matrices with i.i.d. entries are well understood. The current paper discusses the recently introduced Restricted Eigenvalue (RE) condition, which is among the most general assumptions on the matrix, guaranteeing recovery. We prove a reduction principle showing that the RE condition can be guaranteed by checking the restricted isometry on a certain family of low-dimensional subspaces. This principle allows us to establish the RE condition for several broad classes of random matrices with dependent entries, including random matrices with subgaussian rows and non-trivial covariance structure, as well as matrices with independent rows, and uniformly bounded entries.",
        "bibtex": "@InProceedings{pmlr-v23-rudelson12,\n  title = \t {Reconstruction from Anisotropic Random Measurements},\n  author = \t {Rudelson, Mark and Zhou, Shuheng},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {10.1--10.24},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/rudelson12/rudelson12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/rudelson12.html},\n  abstract = \t {Random matrices are widely used in sparse recovery problems, and the relevant properties of matrices with i.i.d. entries are well understood. The current paper discusses the recently introduced Restricted Eigenvalue (RE) condition, which is among the most general assumptions on the matrix, guaranteeing recovery. We prove a reduction principle showing that the RE condition can be guaranteed by checking the restricted isometry on a certain family of low-dimensional subspaces. This principle allows us to establish the RE condition for several broad classes of random matrices with dependent entries, including random matrices with subgaussian rows and non-trivial covariance structure, as well as matrices with independent rows, and uniformly bounded entries.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/rudelson12/rudelson12.pdf",
        "supp": "",
        "pdf_size": 525690,
        "gs_citation": 303,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7382039266314094691&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 20,
        "aff": "Department of Mathematics, University of Michigan; Department of Statistics, University of Michigan",
        "aff_domain": "UMICH.EDU;UMICH.EDU",
        "email": "UMICH.EDU;UMICH.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "28c8f91963",
        "title": "Robust Interactive Learning",
        "site": "https://proceedings.mlr.press/v23/balcan12c.html",
        "author": "Maria Florina Balcan; Steve Hanneke",
        "abstract": "In this paper we propose and study a generalization of the standard active-learning model where a more general type of queries including class conditional queries and mistake queries are allowed. Such queries have been quite useful in applications, but have been lacking theoretical understanding. In this work, we characterize the power of such queries under several well-known noise models. We give nearly tight upper and lower bounds on the number of queries needed to learn both for the general agnostic setting and for the bounded noise model. We further show that our methods can be made adaptive to the (unknown) noise rate, with only negligible loss in query complexity.",
        "bibtex": "@InProceedings{pmlr-v23-balcan12c,\n  title = \t {Robust Interactive Learning},\n  author = \t {Balcan, Maria Florina and Hanneke, Steve},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {20.1--20.34},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/balcan12c/balcan12c.pdf},\n  url = \t {https://proceedings.mlr.press/v23/balcan12c.html},\n  abstract = \t {In this paper we propose and study a generalization of the standard active-learning model where a more general type of queries including class conditional queries and mistake queries are allowed. Such queries have been quite useful in applications, but have been lacking theoretical understanding. In this work, we characterize the power of such queries under several well-known noise models. We give nearly tight upper and lower bounds on the number of queries needed to learn both for the general agnostic setting and for the bounded noise model. We further show that our methods can be made adaptive to the (unknown) noise rate, with only negligible loss in query complexity.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/balcan12c/balcan12c.pdf",
        "supp": "",
        "pdf_size": 647523,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14234716992812584352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "Georgia Institute of Technology, School of Computer Science; Carnegie Mellon University, Department of Statistics",
        "aff_domain": "CC.GATECH.EDU;STAT.CMU.EDU",
        "email": "CC.GATECH.EDU;STAT.CMU.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Georgia Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science;Department of Statistics",
        "aff_unique_url": "https://www.gatech.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Georgia Tech;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "16dfbad8a9",
        "title": "Spectral Clustering of Graphs with General Degrees in the Extended Planted Partition Model",
        "site": "https://proceedings.mlr.press/v23/chaudhuri12.html",
        "author": "Kamalika Chaudhuri; Fan Chung; Alexander Tsiatas",
        "abstract": "In this paper, we examine a spectral clustering algorithm for similarity graphs drawn from a simple random graph model, where nodes are allowed to have varying degrees, and we provide theoretical bounds on its performance. The random graph model we study is the Extended Planted Partition (EPP) model, a variant of the classical planted partition model. The standard approach to spectral clustering of graphs is to compute the bottom \\emphk singular vectors or eigenvectors of a suitable graph Laplacian, project the nodes of the graph onto these vectors, and then use an iterative clustering algorithm on the projected nodes. However a challenge with applying this approach to graphs generated from the EPP model is that unnormalized Laplacians do not work, and normalized Laplacians do not concentrate well when the graph has a number of low degree nodes. We resolve this issue by introducing the notion of a degree-corrected graph Laplacian. For graphs with many low degree nodes, degree correction has a regularizing effect on the Laplacian. Our spectral clustering algorithm projects the nodes in the graph onto the bottom \\emphk right singular vectors of the degree-corrected random-walk Laplacian, and clusters the nodes in this subspace. We show guarantees on the performance of this algorithm, demonstrating that it outputs the correct partition under a wide range of parameter values. Unlike some previous work, our algorithm does not require access to any generative parameters of the model.",
        "bibtex": "@InProceedings{pmlr-v23-chaudhuri12,\n  title = \t {Spectral Clustering of Graphs with General Degrees in the Extended Planted Partition Model},\n  author = \t {Chaudhuri, Kamalika and Chung, Fan and Tsiatas, Alexander},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {35.1--35.23},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/chaudhuri12/chaudhuri12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/chaudhuri12.html},\n  abstract = \t {In this paper, we examine a spectral clustering algorithm for similarity graphs drawn from a simple random graph model, where nodes are allowed to have varying degrees, and we provide theoretical bounds on its performance. The random graph model we study is the Extended Planted Partition (EPP) model, a variant of the classical planted partition model. The standard approach to spectral clustering of graphs is to compute the bottom \\emphk singular vectors or eigenvectors of a suitable graph Laplacian, project the nodes of the graph onto these vectors, and then use an iterative clustering algorithm on the projected nodes. However a challenge with applying this approach to graphs generated from the EPP model is that unnormalized Laplacians do not work, and normalized Laplacians do not concentrate well when the graph has a number of low degree nodes. We resolve this issue by introducing the notion of a degree-corrected graph Laplacian. For graphs with many low degree nodes, degree correction has a regularizing effect on the Laplacian. Our spectral clustering algorithm projects the nodes in the graph onto the bottom \\emphk right singular vectors of the degree-corrected random-walk Laplacian, and clusters the nodes in this subspace. We show guarantees on the performance of this algorithm, demonstrating that it outputs the correct partition under a wide range of parameter values. Unlike some previous work, our algorithm does not require access to any generative parameters of the model.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/chaudhuri12/chaudhuri12.pdf",
        "supp": "",
        "pdf_size": 428174,
        "gs_citation": 277,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7021529718848699743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Computer Science and Engineering, University of California, San Diego; Department of Computer Science and Engineering, University of California, San Diego; Department of Computer Science and Engineering, University of California, San Diego",
        "aff_domain": "CS.UCSD.EDU;CS.UCSD.EDU;CS.UCSD.EDU",
        "email": "CS.UCSD.EDU;CS.UCSD.EDU;CS.UCSD.EDU",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2b53d1a872",
        "title": "The Best of Both Worlds: Stochastic and Adversarial Bandits",
        "site": "https://proceedings.mlr.press/v23/bubeck12b.html",
        "author": "S\u00e9bastien Bubeck; Aleksandrs Slivkins",
        "abstract": "We present a new bandit algorithm, SAO (Stochastic and Adversarial Optimal) whose regret is (essentially) optimal both for adversarial rewards and for stochastic rewards. Specifically, SAO combines the \\emphO(\u221a\\emphn) worst-case regret of Exp3 (Auer et al., 2002b) and the (poly)logarithmic regret of UCB1 (Auer et al., 2002a) for stochastic rewards. Adversarial rewards and stochastic rewards are the two main settings in the literature on multi-armed bandits (MAB). Prior work on MAB treats them separately, and does not attempt to jointly optimize for both. This result falls into the general agenda to design algorithms that combine the optimal worst-case performance with improved guarantees for \u201cnice\u201d problem instances.",
        "bibtex": "@InProceedings{pmlr-v23-bubeck12b,\n  title = \t {The Best of Both Worlds: Stochastic and Adversarial Bandits},\n  author = \t {Bubeck, S\u00e9bastien and Slivkins, Aleksandrs},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {42.1--42.23},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/bubeck12b/bubeck12b.pdf},\n  url = \t {https://proceedings.mlr.press/v23/bubeck12b.html},\n  abstract = \t {We present a new bandit algorithm, SAO (Stochastic and Adversarial Optimal) whose regret is (essentially) optimal both for adversarial rewards and for stochastic rewards. Specifically, SAO combines the \\emphO(\u221a\\emphn) worst-case regret of Exp3 (Auer et al., 2002b) and the (poly)logarithmic regret of UCB1 (Auer et al., 2002a) for stochastic rewards. Adversarial rewards and stochastic rewards are the two main settings in the literature on multi-armed bandits (MAB). Prior work on MAB treats them separately, and does not attempt to jointly optimize for both. This result falls into the general agenda to design algorithms that combine the optimal worst-case performance with improved guarantees for \u201cnice\u201d problem instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/bubeck12b/bubeck12b.pdf",
        "supp": "",
        "pdf_size": 508475,
        "gs_citation": 292,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7480977112649567881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Department of Operations Research and Financial Engineering, Princeton University; Microsoft Research",
        "aff_domain": "PRINCETON.EDU;MICROSOFT.COM",
        "email": "PRINCETON.EDU;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Princeton University;Microsoft",
        "aff_unique_dep": "Department of Operations Research and Financial Engineering;Microsoft Research",
        "aff_unique_url": "https://www.princeton.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Princeton;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "213d2e1252",
        "title": "The Optimality of Jeffreys Prior for Online Density Estimation and the Asymptotic Normality of Maximum Likelihood Estimators",
        "site": "https://proceedings.mlr.press/v23/hedayati12.html",
        "author": "Fares Hedayati; Peter L. Bartlett",
        "abstract": "We study online learning under logarithmic loss with regular parametric models. We show that a Bayesian strategy predicts optimally only if it uses Jeffreys prior. This result was known for canonical exponential families; we extend it to parametric models for which the maximum likelihood estimator is asymptotically normal. The optimal prediction strategy, normalized maximum likelihood, depends on the number \\emphn of rounds of the game, in general. However, when a Bayesian strategy is optimal, normalized maximum likelihood becomes independent of \\emphn. Our proof uses this to exploit the asymptotics of normalized maximum likelihood. The asymptotic normality of the maximum likelihood estimator is responsible for the necessity of Jeffreys prior.",
        "bibtex": "@InProceedings{pmlr-v23-hedayati12,\n  title = \t {The Optimality of Jeffreys Prior for Online Density Estimation and the Asymptotic Normality of Maximum Likelihood Estimators},\n  author = \t {Hedayati, Fares and Bartlett, Peter L.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {7.1--7.13},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/hedayati12/hedayati12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/hedayati12.html},\n  abstract = \t {We study online learning under logarithmic loss with regular parametric models. We show that a Bayesian strategy predicts optimally only if it uses Jeffreys prior. This result was known for canonical exponential families; we extend it to parametric models for which the maximum likelihood estimator is asymptotically normal. The optimal prediction strategy, normalized maximum likelihood, depends on the number \\emphn of rounds of the game, in general. However, when a Bayesian strategy is optimal, normalized maximum likelihood becomes independent of \\emphn. Our proof uses this to exploit the asymptotics of normalized maximum likelihood. The asymptotic normality of the maximum likelihood estimator is responsible for the necessity of Jeffreys prior.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/hedayati12/hedayati12.pdf",
        "supp": "",
        "pdf_size": 327600,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12359844024391567733&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 19,
        "aff": "University of California at Berkeley; University of California at Berkeley+Queensland University of Technology",
        "aff_domain": "eecs.berkeley.edu;cs.berkeley.edu",
        "email": "eecs.berkeley.edu;cs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "University of California, Berkeley;Queensland University of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.qut.edu.au",
        "aff_unique_abbr": "UC Berkeley;QUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0+1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "c009485d0d",
        "title": "Tight Bounds on Proper Equivalence Query Learning of DNF",
        "site": "https://proceedings.mlr.press/v23/hellerstein12.html",
        "author": "Lisa Hellerstein; Devorah Kletenik; Linda Sellie; Rocco Servedio",
        "abstract": "We prove a new structural lemma for partial Boolean functions \\emphf, which we call the \\emphseed lemma for \\emphDNF. Using the lemma, we give the first subexponential algorithm for proper learning of poly(\\emphn)-term DNF in Angluin\u2019s Equivalence Query (EQ) model. The algorithm has time and query complexity 2^(\u00d5\u221a\\emphn), which is optimal. We also give a new result on certificates for DNF-size, a simple algorithm for properly PAC-learning DNF, and new results on EQ-learning log \\emphn-term DNF and decision trees.",
        "bibtex": "@InProceedings{pmlr-v23-hellerstein12,\n  title = \t {Tight Bounds on Proper Equivalence Query Learning of DNF},\n  author = \t {Hellerstein, Lisa and Kletenik, Devorah and Sellie, Linda and Servedio, Rocco},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {31.1--31.18},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/hellerstein12/hellerstein12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/hellerstein12.html},\n  abstract = \t {We prove a new structural lemma for partial Boolean functions \\emphf, which we call the \\emphseed lemma for \\emphDNF. Using the lemma, we give the first subexponential algorithm for proper learning of poly(\\emphn)-term DNF in Angluin\u2019s Equivalence Query (EQ) model. The algorithm has time and query complexity 2^(\u00d5\u221a\\emphn), which is optimal. We also give a new result on certificates for DNF-size, a simple algorithm for properly PAC-learning DNF, and new results on EQ-learning log \\emphn-term DNF and decision trees.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/hellerstein12/hellerstein12.pdf",
        "supp": "",
        "pdf_size": 468251,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7689906035503977408&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Polytechnic Institute of NYU; Polytechnic Institute of NYU; ; Columbia University",
        "aff_domain": "POLY.EDU;CIS.POLY.EDU;MAC.COM;CS.COLUMBIA.EDU",
        "email": "POLY.EDU;CIS.POLY.EDU;MAC.COM;CS.COLUMBIA.EDU",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "New York University Polytechnic School of Engineering;Columbia University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://engineering.nyu.edu;https://www.columbia.edu",
        "aff_unique_abbr": "NYU Poly;Columbia",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brooklyn;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ab9f1b8a94",
        "title": "Toward Understanding Complex Spaces: Graph Laplacians on Manifolds with Singularities and Boundaries",
        "site": "https://proceedings.mlr.press/v23/belkin12.html",
        "author": "Mikhail Belkin; Qichao Que; Yusu Wang; Xueyuan Zhou",
        "abstract": "In manifold learning, algorithms based on graph Laplacian constructed from data have received considerable attention both in practical applications and theoretical analysis. Much of the existing work has been done under the assumption that the data is sampled from a manifold without boundaries and singularities or that the functions of interest are evaluated away from such points. At the same time, it can be argued that singularities and boundaries are an important aspect of the geometry of realistic data. Boundaries occur whenever the process generating data has a bounding constraint; while singularities appear when two different manifolds intersect or if a process undergoes a \u201cphase transition\", changing non-smoothly as a function of a parameter. In this paper we consider the behavior of graph Laplacians at points at or near boundaries and two main types of other singularities:",
        "bibtex": "@InProceedings{pmlr-v23-belkin12,\n  title = \t {Toward Understanding Complex Spaces: Graph Laplacians on Manifolds with Singularities and Boundaries},\n  author = \t {Belkin, Mikhail and Que, Qichao and Wang, Yusu and Zhou, Xueyuan},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {36.1--36.26},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/belkin12/belkin12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/belkin12.html},\n  abstract = \t {In manifold learning, algorithms based on graph Laplacian constructed from data have received considerable attention both in practical applications and theoretical analysis. Much of the existing work has been done under the assumption that the data is sampled from a manifold without boundaries and singularities or that the functions of interest are evaluated away from such points. At the same time, it can be argued that singularities and boundaries are an important aspect of the geometry of realistic data. Boundaries occur whenever the process generating data has a bounding constraint; while singularities appear when two different manifolds intersect or if a process undergoes a \u201cphase transition\", changing non-smoothly as a function of a parameter. In this paper we consider the behavior of graph Laplacians at points at or near boundaries and two main types of other singularities:",
        "pdf": "http://proceedings.mlr.press/v23/belkin12/belkin12.pdf",
        "supp": "",
        "pdf_size": 4273174,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14288940480770657987&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "The Ohio State University, Columbus, OH 43210, USA; The Ohio State University, Columbus, OH 43210, USA; The Ohio State University, Columbus, OH 43210, USA; Department of Computer Science, University of Chicago, USA",
        "aff_domain": "cse.ohio-state.edu;cse.ohio-state.edu;cse.ohio-state.edu;uchicago.edu",
        "email": "cse.ohio-state.edu;cse.ohio-state.edu;cse.ohio-state.edu;uchicago.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Ohio State University;University of Chicago",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.osu.edu;https://www.uchicago.edu",
        "aff_unique_abbr": "OSU;UChicago",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "76971109ff",
        "title": "Toward a Noncommutative Arithmetic-geometric Mean Inequality: Conjectures, Case-studies, and Consequences",
        "site": "https://proceedings.mlr.press/v23/recht12.html",
        "author": "Benjamin Recht; Christopher Re",
        "abstract": "Randomized algorithms that base iteration-level decisions on samples from some pool are ubiquitous in machine learning and optimization. Examples include stochastic gradient descent and randomized coordinate descent. This paper makes progress at theoretically evaluating the difference in performance between sampling with- and without-replacement in such algorithms. Focusing on least means squares optimization, we formulate a noncommutative arithmetic-geometric mean inequality that would prove that the expected convergence rate of without-replacement sampling is faster than that of with-replacement sampling. We demonstrate that this inequality holds for many classes of random matrices and for some pathological examples as well. We provide a deterministic worst-case bound on the gap between the discrepancy between the two sampling models, and explore some of the impediments to proving this inequality in full generality. We detail the consequences of this inequality for stochastic gradient descent and the randomized Kaczmarz algorithm for solving linear systems.",
        "bibtex": "@InProceedings{pmlr-v23-recht12,\n  title = \t {Toward a Noncommutative Arithmetic-geometric Mean Inequality: Conjectures, Case-studies, and Consequences},\n  author = \t {Recht, Benjamin and Re, Christopher},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {11.1--11.24},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/recht12/recht12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/recht12.html},\n  abstract = \t {Randomized algorithms that base iteration-level decisions on samples from some pool are ubiquitous in machine learning and optimization. Examples include stochastic gradient descent and randomized coordinate descent. This paper makes progress at theoretically evaluating the difference in performance between sampling with- and without-replacement in such algorithms. Focusing on least means squares optimization, we formulate a noncommutative arithmetic-geometric mean inequality that would prove that the expected convergence rate of without-replacement sampling is faster than that of with-replacement sampling. We demonstrate that this inequality holds for many classes of random matrices and for some pathological examples as well. We provide a deterministic worst-case bound on the gap between the discrepancy between the two sampling models, and explore some of the impediments to proving this inequality in full generality. We detail the consequences of this inequality for stochastic gradient descent and the randomized Kaczmarz algorithm for solving linear systems.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/recht12/recht12.pdf",
        "supp": "",
        "pdf_size": 523352,
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8749895726896397315&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison; Department of Computer Sciences, University of Wisconsin-Madison",
        "aff_domain": "CS.WISC.EDU;CS.WISC.EDU",
        "email": "CS.WISC.EDU;CS.WISC.EDU",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "Department of Computer Sciences",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2fd962350a",
        "title": "Towards Minimax Policies for Online Linear Optimization with Bandit Feedback",
        "site": "https://proceedings.mlr.press/v23/bubeck12a.html",
        "author": "S\u00e9bastien Bubeck; Nicol\u00f3 Cesa-Bianchi; Sham M. Kakade",
        "abstract": "We address the online linear optimization problem with bandit feedback. Our contribution is twofold. First, we provide an algorithm (based on exponential weights) with a regret of order $\\sqrt{dn \\log N}$ for any finite action set with $N$ actions, under the assumption that the instantaneous loss is bounded by 1. This shaves off an extraneous $\\sqrt{d}$ factor compared to previous works, and gives a regret bound of order $d\\sqrt{n \\log n}$ for any compact set of actions. Without further assumptions on the action set, this last bound is minimax optimal up to a logarithmic factor. Interestingly, our result also shows that the minimax regret for bandit linear optimization with expert advice in $d$ dimension is the same as for the basic $d$-armed bandit with expert advice. Our second contribution is to show how to use the Mirror Descent algorithm to obtain computationally efficient strategies with minimax optimal regret bounds in specific examples. More precisely we study two canonical action sets: the hypercube and the Euclidean ball. In the former case, we obtain the first computationally efficient algorithm with a $d\\sqrt{n}$ regret, thus improving by a factor $\\sqrt{d \\log n}$ over the best known result for a computationally efficient algorithm. In the latter case, our approach gives the first algorithm with a $\\sqrt{dn \\log n}$, again shaving off an extraneous $\\sqrt{d}$ compared to previous works.",
        "bibtex": "@InProceedings{pmlr-v23-bubeck12a,\n  title = \t {Towards Minimax Policies for Online Linear Optimization with Bandit Feedback},\n  author = \t {Bubeck, S\u00e9bastien and Cesa-Bianchi, Nicol\u00f3 and Kakade, Sham M.},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {41.1--41.14},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/bubeck12a/bubeck12a.pdf},\n  url = \t {https://proceedings.mlr.press/v23/bubeck12a.html},\n  abstract = \t {We address the online linear optimization problem with bandit feedback. Our contribution is twofold. First, we provide an algorithm (based on exponential weights) with a regret of order $\\sqrt{dn \\log N}$ for any finite action set with $N$ actions, under the assumption that the instantaneous loss is bounded by 1. This shaves off an extraneous $\\sqrt{d}$ factor compared to previous works, and gives a regret bound of order $d\\sqrt{n \\log n}$ for any compact set of actions. Without further assumptions on the action set, this last bound is minimax optimal up to a logarithmic factor. Interestingly, our result also shows that the minimax regret for bandit linear optimization with expert advice in $d$ dimension is the same as for the basic $d$-armed bandit with expert advice. Our second contribution is to show how to use the Mirror Descent algorithm to obtain computationally efficient strategies with minimax optimal regret bounds in specific examples. More precisely we study two canonical action sets: the hypercube and the Euclidean ball. In the former case, we obtain the first computationally efficient algorithm with a $d\\sqrt{n}$ regret, thus improving by a factor $\\sqrt{d \\log n}$ over the best known result for a computationally efficient algorithm. In the latter case, our approach gives the first algorithm with a $\\sqrt{dn \\log n}$, again shaving off an extraneous $\\sqrt{d}$ compared to previous works.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/bubeck12a/bubeck12a.pdf",
        "supp": "",
        "pdf_size": 310468,
        "gs_citation": 180,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9641300104309460036&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 22,
        "aff": "Department of Operations Research and Financial Engineering, Princeton University; Department of Computer Science, Universit `a degli Studi di Milano; Microsoft Research New England",
        "aff_domain": "PRINCETON.EDU;UNIMI.IT;MICROSOFT.COM",
        "email": "PRINCETON.EDU;UNIMI.IT;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Universit\u00e0 degli Studi di Milano;Microsoft",
        "aff_unique_dep": "Department of Operations Research and Financial Engineering;Department of Computer Science;Microsoft Research",
        "aff_unique_url": "https://www.princeton.edu;https://www.unimi.it;https://www.microsoft.com/en-us/research/group/microsoft-research-new-england",
        "aff_unique_abbr": "Princeton;UniMi;MSR NE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New England",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "80c42b822d",
        "title": "Unified Algorithms for Online Learning and Competitive Analysis",
        "site": "https://proceedings.mlr.press/v23/buchbinder12.html",
        "author": "Niv Buchbinder; Shahar Chen; Joshep (Seffi) Naor; Ohad Shamir",
        "abstract": "Online learning and competitive analysis are two widely studied frameworks for online decisionmaking settings. Despite the frequent similarity of the problems they study, there are significant differences in their assumptions, goals and techniques, hindering a unified analysis and richer interplay between the two. In this paper, we provide several contributions in this direction. We provide a single unified algorithm which by parameter tuning, interpolates between optimal regret for learning from experts (in online learning) and optimal competitive ratio for the metrical task systems problem (MTS) (in competitive analysis), improving on the results of Blum and Burch (1997). The algorithm also allows us to obtain new regret bounds against \u201cdrifting\u201d experts, which might be of independent interest. Moreover, our approach allows us to go beyond experts/MTS, obtaining similar unifying results for structured action sets and \u201ccombinatorial experts\", whenever the setting has a certain matroid structure.",
        "bibtex": "@InProceedings{pmlr-v23-buchbinder12,\n  title = \t {Unified Algorithms for Online Learning and Competitive Analysis},\n  author = \t {Buchbinder, Niv and Chen, Shahar and Naor, Joshep (Seffi) and Shamir, Ohad},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {5.1--5.18},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/buchbinder12/buchbinder12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/buchbinder12.html},\n  abstract = \t {Online learning and competitive analysis are two widely studied frameworks for online decisionmaking settings. Despite the frequent similarity of the problems they study, there are significant differences in their assumptions, goals and techniques, hindering a unified analysis and richer interplay between the two. In this paper, we provide several contributions in this direction. We provide a single unified algorithm which by parameter tuning, interpolates between optimal regret for learning from experts (in online learning) and optimal competitive ratio for the metrical task systems problem (MTS) (in competitive analysis), improving on the results of Blum and Burch (1997). The algorithm also allows us to obtain new regret bounds against \u201cdrifting\u201d experts, which might be of independent interest. Moreover, our approach allows us to go beyond experts/MTS, obtaining similar unifying results for structured action sets and \u201ccombinatorial experts\", whenever the setting has a certain matroid structure.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/buchbinder12/buchbinder12.pdf",
        "supp": "",
        "pdf_size": 415308,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12623327186414547184&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Computer Science Department, Open University of Israel; Department of Computer Science, Technion, Israel; Department of Computer Science, Technion, Israel; Microsoft Research New England",
        "aff_domain": "GMAIL.COM;CS.TECHNION.AC.IL;CS.TECHNION.AC.IL;MICROSOFT.COM",
        "email": "GMAIL.COM;CS.TECHNION.AC.IL;CS.TECHNION.AC.IL;MICROSOFT.COM",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Open University of Israel;Technion;Microsoft",
        "aff_unique_dep": "Computer Science Department;Department of Computer Science;Microsoft Research",
        "aff_unique_url": "https://www.openu.ac.il;https://www.technion.ac.il;https://www.microsoft.com/en-us/research/group/microsoft-research-new-england",
        "aff_unique_abbr": "OUI;Technion;MSR NE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New England",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "0e0c40acaf",
        "title": "Unsupervised SVMs: On the Complexity of the Furthest Hyperplane Problem",
        "site": "https://proceedings.mlr.press/v23/karnin12.html",
        "author": "Zohar Karnin; Edo Liberty; Shachar Lovett; Roy Schwartz; Omri Weinstein",
        "abstract": "This paper introduces the Furthest Hyperplane Problem (FHP), which is an unsupervised counterpart of Support Vector Machines. Given a set of n points in R^d, the objective is to produce the hyperplane (passing through the origin) which maximizes the separation margin, that is, the minimal distance between the hyperplane and any input point. To the best of our knowledge, this is the first paper achieving provable results regarding FHP. We provide both lower and upper bounds to this NP-hard problem. First, we give a simple randomized algorithm whose running time is n^O(1/\u03b8^2) where \u03b8is the optimal separation margin. We show that its exponential dependency on 1/\u03b8^2 is tight, up to sub-polynomial factors, assuming SAT cannot be solved in sub-exponential time. Next, we give an efficient approximation algorithm. For any \u03b1\u2208[0, 1], the algorithm produces a hyperplane whose distance from at least 1 - 3\u03b1fraction of the points is at least \u03b1times the optimal separation margin. Finally, we show that FHP does not admit a PTAS by presenting a gap preserving reduction from a particular version of the PCP theorem.",
        "bibtex": "@InProceedings{pmlr-v23-karnin12,\n  title = \t {Unsupervised SVMs: On the Complexity of the Furthest Hyperplane Problem},\n  author = \t {Karnin, Zohar and Liberty, Edo and Lovett, Shachar and Schwartz, Roy and Weinstein, Omri},\n  booktitle = \t {Proceedings of the 25th Annual Conference on Learning Theory},\n  pages = \t {2.1--2.17},\n  year = \t {2012},\n  editor = \t {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},\n  volume = \t {23},\n  series = \t {Proceedings of Machine Learning Research},\n  address = \t {Edinburgh, Scotland},\n  month = \t {25--27 Jun},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v23/karnin12/karnin12.pdf},\n  url = \t {https://proceedings.mlr.press/v23/karnin12.html},\n  abstract = \t {This paper introduces the Furthest Hyperplane Problem (FHP), which is an unsupervised counterpart of Support Vector Machines. Given a set of n points in R^d, the objective is to produce the hyperplane (passing through the origin) which maximizes the separation margin, that is, the minimal distance between the hyperplane and any input point. To the best of our knowledge, this is the first paper achieving provable results regarding FHP. We provide both lower and upper bounds to this NP-hard problem. First, we give a simple randomized algorithm whose running time is n^O(1/\u03b8^2) where \u03b8is the optimal separation margin. We show that its exponential dependency on 1/\u03b8^2 is tight, up to sub-polynomial factors, assuming SAT cannot be solved in sub-exponential time. Next, we give an efficient approximation algorithm. For any \u03b1\u2208[0, 1], the algorithm produces a hyperplane whose distance from at least 1 - 3\u03b1fraction of the points is at least \u03b1times the optimal separation margin. Finally, we show that FHP does not admit a PTAS by presenting a gap preserving reduction from a particular version of the PCP theorem.}\n}",
        "pdf": "http://proceedings.mlr.press/v23/karnin12/karnin12.pdf",
        "supp": "",
        "pdf_size": 451372,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18153301364035590313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Yahoo! Research; Yahoo! Research; IAS, Institute for Advanced Studies; Technion + Yahoo! Research; Princeton + Yahoo! Research",
        "aff_domain": "YAHOO-INC.COM;YAHOO-INC.COM;MATH.IAS.EDU;CS.TECHNION.AC.IL;CS.PRINCETON.EDU",
        "email": "YAHOO-INC.COM;YAHOO-INC.COM;MATH.IAS.EDU;CS.TECHNION.AC.IL;CS.PRINCETON.EDU",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2+0;3+0",
        "aff_unique_norm": "Yahoo!;Institute for Advanced Studies;Technion - Israel Institute of Technology;Princeton University",
        "aff_unique_dep": "Yahoo! Research;;;",
        "aff_unique_url": "https://research.yahoo.com;https://www.ias.edu;https://www.technion.ac.il/en/;https://www.princeton.edu",
        "aff_unique_abbr": "Yahoo!;IAS;Technion;Princeton",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1+0;0+0",
        "aff_country_unique": "United States;Israel"
    }
]