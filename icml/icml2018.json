[
    {
        "title": "$D^2$: Decentralized Training over Decentralized Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2485",
        "id": "2485",
        "author_site": "Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, Ji Liu",
        "author": "Hanlin Tang; Xiangru Lian; Ming Yan; Ce Zhang; Ji Liu",
        "abstract": "While training a machine learning model using multiple workers, each of which collects data from its own data source, it would be useful when the data collected from different workers are",
        "bibtex": "@InProceedings{pmlr-v80-tang18a,\n  title = \t {$D^2$: Decentralized Training over Decentralized Data},\n  author =       {Tang, Hanlin and Lian, Xiangru and Yan, Ming and Zhang, Ce and Liu, Ji},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4848--4856},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tang18a/tang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tang18a.html},\n  abstract = \t {While training a machine learning model using multiple workers, each of which collects data from its own data source, it would be useful when the data collected from different workers are",
        "pdf": "http://proceedings.mlr.press/v80/tang18a/tang18a.pdf",
        "supp": "",
        "pdf_size": 433277,
        "gs_citation": 441,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3430870096823557813&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/tang18a.html"
    },
    {
        "title": "A Boo(n) for Evaluating Architecture Performance",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2260",
        "id": "2260",
        "author_site": "Ondrej Bajgar, Rudolf Kadlec, Jan Kleindienst",
        "author": "Ondrej Bajgar; Rudolf Kadlec; Jan Kleindienst",
        "abstract": "We point out important problems with the common practice of using the best single model performance for comparing deep learning architectures, and we propose a method that corrects these flaws. Each time a model is trained, one gets a different result due to random factors in the training process, which include random parameter initialization and random data shuffling. Reporting the best single model performance does not appropriately address this stochasticity. We propose a normalized expected best-out-of-$n$ performance ($\\text{Boo}_n$) as a way to correct these problems.",
        "bibtex": "@InProceedings{pmlr-v80-bajgar18a,\n  title = \t {A Boo(n) for Evaluating Architecture Performance},\n  author =       {Bajgar, Ondrej and Kadlec, Rudolf and Kleindienst, Jan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {334--343},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bajgar18a/bajgar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bajgar18a.html},\n  abstract = \t {We point out important problems with the common practice of using the best single model performance for comparing deep learning architectures, and we propose a method that corrects these flaws. Each time a model is trained, one gets a different result due to random factors in the training process, which include random parameter initialization and random data shuffling. Reporting the best single model performance does not appropriately address this stochasticity. We propose a normalized expected best-out-of-$n$ performance ($\\text{Boo}_n$) as a way to correct these problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bajgar18a/bajgar18a.pdf",
        "supp": "",
        "pdf_size": 2201120,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6114335001118425042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "IBM Watson, Prague AI Research & Development Lab + Deepmind; IBM Watson, Prague AI Research & Development Lab; IBM Watson, Prague AI Research & Development Lab",
        "aff_domain": "bajgar.org; ; ",
        "email": "bajgar.org; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/bajgar18a.html",
        "aff_unique_index": "0+1;0;0",
        "aff_unique_norm": "IBM;DeepMind",
        "aff_unique_dep": "AI Research & Development Lab;",
        "aff_unique_url": "https://www.ibm.com/watson;https://deepmind.com",
        "aff_unique_abbr": "IBM;DeepMind",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague;",
        "aff_country_unique_index": "0+1;0;0",
        "aff_country_unique": "Czech Republic;United Kingdom"
    },
    {
        "title": "A Classification-Based Study of Covariate Shift in GAN Distributions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2413",
        "id": "2413",
        "author_site": "Shibani Santurkar, Ludwig Schmidt, Aleksander Madry",
        "author": "Shibani Santurkar; Ludwig Schmidt; Aleksander Madry",
        "abstract": "A basic, and still largely unanswered, question in the context of Generative Adversarial Networks (GANs) is whether they are truly able to capture all the fundamental characteristics of the distributions they are trained on. In particular, evaluating the diversity of GAN distributions is challenging and existing methods provide only a partial understanding of this issue. In this paper, we develop quantitative and scalable tools for assessing the diversity of GAN distributions. Specifically, we take a classification-based perspective and view loss of diversity as a form of covariate shift introduced by GANs. We examine two specific forms of such shift: mode collapse and boundary distortion. In contrast to prior work, our methods need only minimal human supervision and can be readily applied to state-of-the-art GANs on large, canonical datasets. Examining popular GANs using our tools indicates that these GANs have significant problems in reproducing the more distributional properties of their training dataset.",
        "bibtex": "@InProceedings{pmlr-v80-santurkar18a,\n  title = \t {A Classification-Based Study of Covariate Shift in {GAN} Distributions},\n  author =       {Santurkar, Shibani and Schmidt, Ludwig and Madry, Aleksander},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4480--4489},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/santurkar18a/santurkar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/santurkar18a.html},\n  abstract = \t {A basic, and still largely unanswered, question in the context of Generative Adversarial Networks (GANs) is whether they are truly able to capture all the fundamental characteristics of the distributions they are trained on. In particular, evaluating the diversity of GAN distributions is challenging and existing methods provide only a partial understanding of this issue. In this paper, we develop quantitative and scalable tools for assessing the diversity of GAN distributions. Specifically, we take a classification-based perspective and view loss of diversity as a form of covariate shift introduced by GANs. We examine two specific forms of such shift: mode collapse and boundary distortion. In contrast to prior work, our methods need only minimal human supervision and can be readily applied to state-of-the-art GANs on large, canonical datasets. Examining popular GANs using our tools indicates that these GANs have significant problems in reproducing the more distributional properties of their training dataset.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/santurkar18a/santurkar18a.pdf",
        "supp": "",
        "pdf_size": 1354123,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13732016296542149652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;mit.edu;mit.edu",
        "email": "mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/santurkar18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2152",
        "id": "2152",
        "author_site": "Alp Yurtsever, Olivier Fercoq, Francesco Locatello, Volkan Cevher",
        "author": "Alp Yurtsever; Olivier Fercoq; Francesco Locatello; Volkan Cevher",
        "abstract": "We propose a conditional gradient framework for a composite convex minimization template with broad applications. Our approach combines smoothing and homotopy techniques under the CGM framework, and provably achieves the optimal convergence rate. We demonstrate that the same rate holds if the linear subproblems are solved approximately with additive or multiplicative error. In contrast with the relevant work, we are able to characterize the convergence when the non-smooth term is an indicator function. Specific applications of our framework include the non-smooth minimization, semidefinite programming, and minimization with linear inclusion constraints over a compact domain. Numerical evidence demonstrates the benefits of our framework.",
        "bibtex": "@InProceedings{pmlr-v80-yurtsever18a,\n  title = \t {A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming},\n  author =       {Yurtsever, Alp and Fercoq, Olivier and Locatello, Francesco and Cevher, Volkan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5727--5736},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yurtsever18a/yurtsever18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yurtsever18a.html},\n  abstract = \t {We propose a conditional gradient framework for a composite convex minimization template with broad applications. Our approach combines smoothing and homotopy techniques under the CGM framework, and provably achieves the optimal convergence rate. We demonstrate that the same rate holds if the linear subproblems are solved approximately with additive or multiplicative error. In contrast with the relevant work, we are able to characterize the convergence when the non-smooth term is an indicator function. Specific applications of our framework include the non-smooth minimization, semidefinite programming, and minimization with linear inclusion constraints over a compact domain. Numerical evidence demonstrates the benefits of our framework.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yurtsever18a/yurtsever18a.pdf",
        "supp": "",
        "pdf_size": 1650001,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8576383688772335408&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "LIONS, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; LTCI, T\u00e9l\u00e9com ParisTech, Universit\u00e9 Paris-Saclay, France; BMI, Dept. of Computer Science, ETH Zurich, Switzerland + Empirical Inference, Max Planck Institute for Intelligent Systems, Germany; LIONS, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland",
        "aff_domain": "epfl.ch; ; ; ",
        "email": "epfl.ch; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/yurtsever18a.html",
        "aff_unique_index": "0;1;2+3;0",
        "aff_unique_norm": "EPFL;T\u00e9l\u00e9com ParisTech;ETH Zurich;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "LIONS;LTCI;Dept. of Computer Science;Empirical Inference",
        "aff_unique_url": "https://www.epfl.ch;https://www.telecom-paris.fr;https://www.ethz.ch;https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": "EPFL;T\u00e9l\u00e9com ParisTech;ETHZ;MPI-IS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0+2;0",
        "aff_country_unique": "Switzerland;France;Germany"
    },
    {
        "title": "A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2143",
        "id": "2143",
        "author_site": "Konstantin Mishchenko, Franck Iutzeler, J\u00e9r\u00f4me Malick, Massih-Reza Amini",
        "author": "Konstantin Mishchenko; Franck Iutzeler; J\u00e9r\u00f4me Malick; Massih-Reza Amini",
        "abstract": "Distributed learning aims at computing high-quality models by training over scattered data. This covers a diversity of scenarios, including computer clusters or mobile agents. One of the main challenges is then to deal with heterogeneous machines and unreliable communications. In this setting, we propose and analyze a flexible asynchronous optimization algorithm for solving nonsmooth learning problems. Unlike most existing methods, our algorithm is adjustable to various levels of communication costs, machines computational powers, and data distribution evenness. We prove that the algorithm converges linearly with a fixed learning rate that does not depend on communication delays nor on the number of machines. Although long delays in communication may slow down performance, no delay can break convergence.",
        "bibtex": "@InProceedings{pmlr-v80-mishchenko18a,\n  title = \t {A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning},\n  author =       {Mishchenko, Konstantin and Iutzeler, Franck and Malick, J{\\'e}r{\\^o}me and Amini, Massih-Reza},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3587--3595},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mishchenko18a/mishchenko18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mishchenko18a.html},\n  abstract = \t {Distributed learning aims at computing high-quality models by training over scattered data. This covers a diversity of scenarios, including computer clusters or mobile agents. One of the main challenges is then to deal with heterogeneous machines and unreliable communications. In this setting, we propose and analyze a flexible asynchronous optimization algorithm for solving nonsmooth learning problems. Unlike most existing methods, our algorithm is adjustable to various levels of communication costs, machines computational powers, and data distribution evenness. We prove that the algorithm converges linearly with a fixed learning rate that does not depend on communication delays nor on the number of machines. Although long delays in communication may slow down performance, no delay can break convergence.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mishchenko18a/mishchenko18a.pdf",
        "supp": "",
        "pdf_size": 759633,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17011057571118643633&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "King Abdullah University of Science & Technology; Univ. Grenoble Alpes; CNRS and LJK; Univ. Grenoble Alpes",
        "aff_domain": "univ-grenoble-alpes.fr;univ-grenoble-alpes.fr; ;univ-grenoble-alpes.fr",
        "email": "univ-grenoble-alpes.fr;univ-grenoble-alpes.fr; ;univ-grenoble-alpes.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/mishchenko18a.html",
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "King Abdullah University of Science and Technology;Universit\u00e9 Grenoble Alpes;CNRS",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.kast.kau.edu.sa;https://www.univ-grenoble-alpes.fr;https://www.cnrs.fr",
        "aff_unique_abbr": "KAUST;UGA;CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Saudi Arabia;France"
    },
    {
        "title": "A Distributed Second-Order Algorithm You Can Trust",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2457",
        "id": "2457",
        "author_site": "Celestine Mendler-D\u00fcnner, Aurelien Lucchi, Matilde Gargiani, Yatao Bian, Thomas Hofmann, Martin Jaggi",
        "author": "Celestine Duenner; Aurelien Lucchi; Matilde Gargiani; An Bian; Thomas Hofmann; Martin Jaggi",
        "abstract": "Due to the rapid growth of data and computational resources, distributed optimization has become an active research area in recent years. While first-order methods seem to dominate the field, second-order methods are nevertheless attractive as they potentially require fewer communication rounds to converge. However, there are significant drawbacks that impede their wide adoption, such as the computation and the communication of a large Hessian matrix. In this paper we present a new algorithm for distributed training of generalized linear models that only requires the computation of diagonal blocks of the Hessian matrix on the individual workers. To deal with this approximate information we propose an adaptive approach that - akin to trust-region methods - dynamically adapts the auxiliary model to compensate for modeling errors. We provide theoretical rates of convergence for a wide class of problems including $L_1$-regularized objectives. We also demonstrate that our approach achieves state-of-the-art results on multiple large benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v80-duenner18a,\n  title = \t {A Distributed Second-Order Algorithm You Can Trust},\n  author =       {Duenner, Celestine and Lucchi, Aurelien and Gargiani, Matilde and Bian, An and Hofmann, Thomas and Jaggi, Martin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1358--1366},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/duenner18a/duenner18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/duenner18a.html},\n  abstract = \t {Due to the rapid growth of data and computational resources, distributed optimization has become an active research area in recent years. While first-order methods seem to dominate the field, second-order methods are nevertheless attractive as they potentially require fewer communication rounds to converge. However, there are significant drawbacks that impede their wide adoption, such as the computation and the communication of a large Hessian matrix. In this paper we present a new algorithm for distributed training of generalized linear models that only requires the computation of diagonal blocks of the Hessian matrix on the individual workers. To deal with this approximate information we propose an adaptive approach that - akin to trust-region methods - dynamically adapts the auxiliary model to compensate for modeling errors. We provide theoretical rates of convergence for a wide class of problems including $L_1$-regularized objectives. We also demonstrate that our approach achieves state-of-the-art results on multiple large benchmark datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/duenner18a/duenner18a.pdf",
        "supp": "",
        "pdf_size": 741193,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2829208213047515443&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "IBM Research \u2013 Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; Albert-Ludwigs-Universit\u00e4t, Freiburg, Germany; ETH, Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; EPFL, Lausanne, Switzerland",
        "aff_domain": "zurich.ibm.com; ; ; ; ; ",
        "email": "zurich.ibm.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/duenner18a.html",
        "aff_unique_index": "0;1;2;1;1;3",
        "aff_unique_norm": "IBM;ETH Zurich;Albert-Ludwigs-Universit\u00e4t Freiburg;EPFL",
        "aff_unique_dep": "Research;;;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.ethz.ch;https://www.uni-freiburg.de;https://www.epfl.ch",
        "aff_unique_abbr": "IBM;ETH;ALU Freiburg;EPFL",
        "aff_campus_unique_index": "0;0;1;0;0;2",
        "aff_campus_unique": "Z\u00fcrich;Freiburg;Lausanne",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "title": "A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2327",
        "id": "2327",
        "author_site": "Beilun Wang, Arshdeep Sekhon, Yanjun Qi",
        "author": "Beilun Wang; Arshdeep Sekhon; Yanjun Qi",
        "abstract": "We consider the problem of including additional knowledge in estimating sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often in bioinformatics and neuroimaging applications. Previous joint sGGM estimators either fail to use existing knowledge or cannot scale-up to many tasks (large $K$) under a high-dimensional (large $p$) situation. In this paper, we propose a novel \\underline{J}oint \\underline{E}lementary \\underline{E}stimator incorporating additional \\underline{K}nowledge (JEEK) to infer multiple related sparse Gaussian Graphical models from large-scale heterogeneous data. Using domain knowledge as weights, we design a novel hybrid norm as the minimization objective to enforce the superposition of two weighted sparsity constraints, one on the shared interactions and the other on the task-specific structural patterns. This enables JEEK to elegantly consider various forms of existing knowledge based on the domain at hand and avoid the need to design knowledge-specific optimization. JEEK is solved through a fast and entry-wise parallelizable solution that largely improves the computational efficiency of the state-of-the-art $O(p^5K^4)$ to $O(p^2K^4)$. We conduct a rigorous statistical analysis showing that JEEK achieves the same convergence rate $O(\\log(Kp)/n_{tot})$ as the state-of-the-art estimators that are much harder to compute. Empirically, on multiple synthetic datasets and one real-world data from neuroscience, JEEP outperforms the speed of the state-of-arts significantly while achieving the same level of prediction accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-wang18f,\n  title = \t {A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse {G}aussian Graphical Models},\n  author =       {Wang, Beilun and Sekhon, Arshdeep and Qi, Yanjun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5161--5170},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18f/wang18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18f.html},\n  abstract = \t {We consider the problem of including additional knowledge in estimating sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often in bioinformatics and neuroimaging applications. Previous joint sGGM estimators either fail to use existing knowledge or cannot scale-up to many tasks (large $K$) under a high-dimensional (large $p$) situation. In this paper, we propose a novel \\underline{J}oint \\underline{E}lementary \\underline{E}stimator incorporating additional \\underline{K}nowledge (JEEK) to infer multiple related sparse Gaussian Graphical models from large-scale heterogeneous data. Using domain knowledge as weights, we design a novel hybrid norm as the minimization objective to enforce the superposition of two weighted sparsity constraints, one on the shared interactions and the other on the task-specific structural patterns. This enables JEEK to elegantly consider various forms of existing knowledge based on the domain at hand and avoid the need to design knowledge-specific optimization. JEEK is solved through a fast and entry-wise parallelizable solution that largely improves the computational efficiency of the state-of-the-art $O(p^5K^4)$ to $O(p^2K^4)$. We conduct a rigorous statistical analysis showing that JEEK achieves the same convergence rate $O(\\log(Kp)/n_{tot})$ as the state-of-the-art estimators that are much harder to compute. Empirically, on multiple synthetic datasets and one real-world data from neuroscience, JEEP outperforms the speed of the state-of-arts significantly while achieving the same level of prediction accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18f/wang18f.pdf",
        "supp": "",
        "pdf_size": 517644,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12183443188962650844&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia",
        "aff_domain": "virginia.edu; ;virginia.edu",
        "email": "virginia.edu; ;virginia.edu",
        "github": "",
        "project": "http://www.jointnets.org/",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wang18f.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2420",
        "id": "2420",
        "author_site": "Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, Douglas Eck",
        "author": "Adam Roberts; Jesse Engel; Colin Raffel; Curtis Hawthorne; Douglas Eck",
        "abstract": "The Variational Autoencoder (VAE) has proven to be an effective model for producing semantically meaningful latent representations for natural data. However, it has thus far seen limited application to sequential data, and, as we demonstrate, existing recurrent VAE models have difficulty modeling sequences with long-term structure. To address this issue, we propose the use of a hierarchical decoder, which first outputs embeddings for subsequences of the input and then uses these embeddings to generate each subsequence independently. This structure encourages the model to utilize its latent code, thereby avoiding the \"posterior collapse\" problem which remains an issue for recurrent VAEs. We apply this architecture to modeling sequences of musical notes and find that it exhibits dramatically better sampling, interpolation, and reconstruction performance than a \"flat\" baseline model. An implementation of our \"MusicVAE\" is available online at https://goo.gl/magenta/musicvae-code.",
        "bibtex": "@InProceedings{pmlr-v80-roberts18a,\n  title = \t {A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music},\n  author =       {Roberts, Adam and Engel, Jesse and Raffel, Colin and Hawthorne, Curtis and Eck, Douglas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4364--4373},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/roberts18a/roberts18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/roberts18a.html},\n  abstract = \t {The Variational Autoencoder (VAE) has proven to be an effective model for producing semantically meaningful latent representations for natural data. However, it has thus far seen limited application to sequential data, and, as we demonstrate, existing recurrent VAE models have difficulty modeling sequences with long-term structure. To address this issue, we propose the use of a hierarchical decoder, which first outputs embeddings for subsequences of the input and then uses these embeddings to generate each subsequence independently. This structure encourages the model to utilize its latent code, thereby avoiding the \"posterior collapse\" problem which remains an issue for recurrent VAEs. We apply this architecture to modeling sequences of musical notes and find that it exhibits dramatically better sampling, interpolation, and reconstruction performance than a \"flat\" baseline model. An implementation of our \"MusicVAE\" is available online at https://goo.gl/magenta/musicvae-code.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/roberts18a/roberts18a.pdf",
        "supp": "",
        "pdf_size": 1383631,
        "gs_citation": 676,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12434115155218414759&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Google Brain, Mountain View, CA, USA; Google Brain, Mountain View, CA, USA; Google Brain, Mountain View, CA, USA; Google Brain, Mountain View, CA, USA; Google Brain, Mountain View, CA, USA",
        "aff_domain": "google.com; ; ; ; ",
        "email": "google.com; ; ; ; ",
        "github": "",
        "project": "https://goo.gl/magenta/musicvae-code",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/roberts18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Brain",
        "aff_unique_url": "https://brain.google.com",
        "aff_unique_abbr": "Google Brain",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2096",
        "id": "2096",
        "author_site": "Xiao Zhang, Lingxiao Wang, Yaodong Yu, Quanquan Gu",
        "author": "Xiao Zhang; Lingxiao Wang; Yaodong Yu; Quanquan Gu",
        "abstract": "We propose a primal-dual based framework for analyzing the global optimality of nonconvex low-rank matrix recovery. Our analysis are based on the restricted strongly convex and smooth conditions, which can be verified for a broad family of loss functions. In addition, our analytic framework can directly handle the widely-used incoherence constraints through the lens of duality. We illustrate the applicability of the proposed framework to matrix completion and one-bit matrix completion, and prove that all these problems have no spurious local minima. Our results not only improve the sample complexity required for characterizing the global optimality of matrix completion, but also resolve an open problem in Ge et al. (2017) regarding one-bit matrix completion. Numerical experiments show that primal-dual based algorithm can successfully recover the global optimum for various low-rank problems.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18m,\n  title = \t {A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery},\n  author =       {Zhang, Xiao and Wang, Lingxiao and Yu, Yaodong and Gu, Quanquan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5862--5871},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18m/zhang18m.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18m.html},\n  abstract = \t {We propose a primal-dual based framework for analyzing the global optimality of nonconvex low-rank matrix recovery. Our analysis are based on the restricted strongly convex and smooth conditions, which can be verified for a broad family of loss functions. In addition, our analytic framework can directly handle the widely-used incoherence constraints through the lens of duality. We illustrate the applicability of the proposed framework to matrix completion and one-bit matrix completion, and prove that all these problems have no spurious local minima. Our results not only improve the sample complexity required for characterizing the global optimality of matrix completion, but also resolve an open problem in Ge et al. (2017) regarding one-bit matrix completion. Numerical experiments show that primal-dual based algorithm can successfully recover the global optimum for various low-rank problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18m/zhang18m.pdf",
        "supp": "",
        "pdf_size": 914740,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13872427026415116458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA; Department of Computer Science, University of California, Los Angeles, Los Angeles, CA 90095, USA; Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA; Department of Computer Science, University of California, Los Angeles, Los Angeles, CA 90095, USA",
        "aff_domain": "virginia.edu;ucla.edu;virginia.edu;cs.ucla.edu",
        "email": "virginia.edu;ucla.edu;virginia.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/zhang18m.html",
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Virginia;University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.virginia.edu;https://www.ucla.edu",
        "aff_unique_abbr": "UVA;UCLA",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Charlottesville;Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Probabilistic Theory of Supervised Similarity Learning for Pointwise ROC Curve Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2118",
        "id": "2118",
        "author_site": "Robin Vogel, Aur\u00e9lien Bellet, St\u00e9phan Cl\u00e9men\u00e7on",
        "author": "Robin Vogel; Aur\u00e9lien Bellet; St\u00e9phan Cl\u00e9men\u00e7on",
        "abstract": "The performance of many machine learning techniques depends on the choice of an appropriate similarity or distance measure on the input space. Similarity learning (or metric learning) aims at building such a measure from training data so that observations with the same (resp. different) label are as close (resp. far) as possible. In this paper, similarity learning is investigated from the perspective of pairwise bipartite ranking, where the goal is to rank the elements of a database by decreasing order of the probability that they share the same label with some query data point, based on the similarity scores. A natural performance criterion in this setting is pointwise ROC optimization: maximize the true positive rate under a fixed false positive rate. We study this novel perspective on similarity learning through a rigorous probabilistic framework. The empirical version of the problem gives rise to a constrained optimization formulation involving U-statistics, for which we derive universal learning rates as well as faster rates under a noise assumption on the data distribution. We also address the large-scale setting by analyzing the effect of sampling-based approximations. Our theoretical results are supported by illustrative numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v80-vogel18a,\n  title = \t {A Probabilistic Theory of Supervised Similarity Learning for Pointwise {ROC} Curve Optimization},\n  author =       {Vogel, Robin and Bellet, Aur{\\'e}lien and Cl{\\'e}men{\\c{c}}on, St{\\'e}phan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5065--5074},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/vogel18a/vogel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/vogel18a.html},\n  abstract = \t {The performance of many machine learning techniques depends on the choice of an appropriate similarity or distance measure on the input space. Similarity learning (or metric learning) aims at building such a measure from training data so that observations with the same (resp. different) label are as close (resp. far) as possible. In this paper, similarity learning is investigated from the perspective of pairwise bipartite ranking, where the goal is to rank the elements of a database by decreasing order of the probability that they share the same label with some query data point, based on the similarity scores. A natural performance criterion in this setting is pointwise ROC optimization: maximize the true positive rate under a fixed false positive rate. We study this novel perspective on similarity learning through a rigorous probabilistic framework. The empirical version of the problem gives rise to a constrained optimization formulation involving U-statistics, for which we derive universal learning rates as well as faster rates under a noise assumption on the data distribution. We also address the large-scale setting by analyzing the effect of sampling-based approximations. Our theoretical results are supported by illustrative numerical experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/vogel18a/vogel18a.pdf",
        "supp": "",
        "pdf_size": 682763,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16356770266294379276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "T\u00e9l\u00e9com ParisTech, Paris, France+IDEMIA, Colombes, France; INRIA, France; T\u00e9l\u00e9com ParisTech, Paris, France",
        "aff_domain": "telecom-paristech.fr; ; ",
        "email": "telecom-paristech.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/vogel18a.html",
        "aff_unique_index": "0+1;2;0",
        "aff_unique_norm": "T\u00e9l\u00e9com ParisTech;IDEMIA;INRIA",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.telecom-paristech.fr;https://www.idemia.com;https://www.inria.fr",
        "aff_unique_abbr": "TP;;INRIA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Paris;",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "A Progressive Batching L-BFGS Method for Machine Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2059",
        "id": "2059",
        "author_site": "Vijaya Raghavendra Bollapragada, Jorge Nocedal, Dheevatsa Mudigere, Hao-Jun M Shi, Peter Tang",
        "author": "Raghu Bollapragada; Jorge Nocedal; Dheevatsa Mudigere; Hao-Jun Shi; Ping Tak Peter Tang",
        "abstract": "The standard L-BFGS method relies on gradient approximations that are not dominated by noise, so that search directions are descent directions, the line search is reliable, and quasi-Newton updating yields useful quadratic models of the objective function. All of this appears to call for a full batch approach, but since small batch sizes give rise to faster algorithms with better generalization properties, L-BFGS is currently not considered an algorithm of choice for large-scale machine learning applications. One need not, however, choose between the two extremes represented by the full batch or highly stochastic regimes, and may instead follow a progressive batching approach in which the sample size increases during the course of the optimization. In this paper, we present a new version of the L-BFGS algorithm that combines three basic components - progressive batching, a stochastic line search, and stable quasi-Newton updating - and that performs well on training logistic regression and deep neural networks. We provide supporting convergence theory for the method.",
        "bibtex": "@InProceedings{pmlr-v80-bollapragada18a,\n  title = \t {A Progressive Batching L-{BFGS} Method for Machine Learning},\n  author =       {Bollapragada, Raghu and Nocedal, Jorge and Mudigere, Dheevatsa and Shi, Hao-Jun and Tang, Ping Tak Peter},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {620--629},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bollapragada18a/bollapragada18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bollapragada18a.html},\n  abstract = \t {The standard L-BFGS method relies on gradient approximations that are not dominated by noise, so that search directions are descent directions, the line search is reliable, and quasi-Newton updating yields useful quadratic models of the objective function. All of this appears to call for a full batch approach, but since small batch sizes give rise to faster algorithms with better generalization properties, L-BFGS is currently not considered an algorithm of choice for large-scale machine learning applications. One need not, however, choose between the two extremes represented by the full batch or highly stochastic regimes, and may instead follow a progressive batching approach in which the sample size increases during the course of the optimization. In this paper, we present a new version of the L-BFGS algorithm that combines three basic components - progressive batching, a stochastic line search, and stable quasi-Newton updating - and that performs well on training logistic regression and deep neural networks. We provide supporting convergence theory for the method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bollapragada18a/bollapragada18a.pdf",
        "supp": "",
        "pdf_size": 667612,
        "gs_citation": 214,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6233779136949865644&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Industrial Engineering and Management Sciences, Northwestern University, Evanston, IL, USA+Intel Corporation, Santa Clara, CA, USA; Intel Corporation, Bangalore, India; Department of Industrial Engineering and Management Sciences, Northwestern University, Evanston, IL, USA; Department of Industrial Engineering and Management Sciences, Northwestern University, Evanston, IL, USA+Intel Corporation, Santa Clara, CA, USA; Intel Corporation, Santa Clara, CA, USA",
        "aff_domain": "u.northwestern.edu;intel.com;northwestern.edu;u.northwestern.edu;intel.com",
        "email": "u.northwestern.edu;intel.com;northwestern.edu;u.northwestern.edu;intel.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/bollapragada18a.html",
        "aff_unique_index": "0+1;1;0;0+1;1",
        "aff_unique_norm": "Northwestern University;Intel",
        "aff_unique_dep": "Department of Industrial Engineering and Management Sciences;Intel Corporation",
        "aff_unique_url": "https://www.northwestern.edu;https://www.intel.com",
        "aff_unique_abbr": "NU;Intel",
        "aff_campus_unique_index": "0+1;2;0;0+1;1",
        "aff_campus_unique": "Evanston;Santa Clara;Bangalore",
        "aff_country_unique_index": "0+0;1;0;0+0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "title": "A Reductions Approach to Fair Classification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2361",
        "id": "2361",
        "author_site": "Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford, Hanna Wallach",
        "author": "Alekh Agarwal; Alina Beygelzimer; Miroslav Dudik; John Langford; Hanna Wallach",
        "abstract": "We present a systematic approach for achieving fairness in a binary classification setting. While we focus on two well-known quantitative definitions of fairness, our approach encompasses many other previously studied definitions as special cases. The key idea is to reduce fair classification to a sequence of cost-sensitive classification problems, whose solutions yield a randomized classifier with the lowest (empirical) error subject to the desired constraints. We introduce two reductions that work for any representation of the cost-sensitive classifier and compare favorably to prior baselines on a variety of data sets, while overcoming several of their disadvantages.",
        "bibtex": "@InProceedings{pmlr-v80-agarwal18a,\n  title = \t {A Reductions Approach to Fair Classification},\n  author =       {Agarwal, Alekh and Beygelzimer, Alina and Dudik, Miroslav and Langford, John and Wallach, Hanna},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {60--69},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/agarwal18a/agarwal18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/agarwal18a.html},\n  abstract = \t {We present a systematic approach for achieving fairness in a binary classification setting. While we focus on two well-known quantitative definitions of fairness, our approach encompasses many other previously studied definitions as special cases. The key idea is to reduce fair classification to a sequence of cost-sensitive classification problems, whose solutions yield a randomized classifier with the lowest (empirical) error subject to the desired constraints. We introduce two reductions that work for any representation of the cost-sensitive classifier and compare favorably to prior baselines on a variety of data sets, while overcoming several of their disadvantages.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/agarwal18a/agarwal18a.pdf",
        "supp": "",
        "pdf_size": 811994,
        "gs_citation": 1454,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16870675827052455946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Microsoft Research, New York; Yahoo! Research, New York; Microsoft Research, New York; Microsoft Research, New York; Microsoft Research, New York",
        "aff_domain": "microsoft.com;gmail.com;microsoft.com;microsoft.com;microsoft.com",
        "email": "microsoft.com;gmail.com;microsoft.com;microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/agarwal18a.html",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Microsoft;Yahoo! Research",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://research.yahoo.com",
        "aff_unique_abbr": "MSR;Yahoo! Res",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Robust Approach to Sequential Information Theoretic Planning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2372",
        "id": "2372",
        "author_site": "Sue Zheng, Jason Pacheco, John Fisher",
        "author": "Sue Zheng; Jason Pacheco; John Fisher",
        "abstract": "In many sequential planning applications a natural approach to generating high quality plans is to maximize an information reward such as mutual information (MI). Unfortunately, MI lacks a closed form in all but trivial models, and so must be estimated. In applications where the cost of plan execution is expensive, one desires planning estimates which admit theoretical guarantees. Through the use of robust M-estimators we obtain bounds on absolute deviation of estimated MI. Moreover, we propose a sequential algorithm which integrates inference and planning by maximally reusing particles in each stage. We validate the utility of using robust estimators in the sequential approach on a Gaussian Markov Random Field wherein information measures have a closed form. Lastly, we demonstrate the benefits of our integrated approach in the context of sequential experiment design for inferring causal regulatory networks from gene expression levels. Our method shows improvements over a recent method which selects intervention experiments based on the same MI objective.",
        "bibtex": "@InProceedings{pmlr-v80-zheng18b,\n  title = \t {A Robust Approach to Sequential Information Theoretic Planning},\n  author =       {Zheng, Sue and Pacheco, Jason and Fisher, John},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5941--5949},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zheng18b/zheng18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zheng18b.html},\n  abstract = \t {In many sequential planning applications a natural approach to generating high quality plans is to maximize an information reward such as mutual information (MI). Unfortunately, MI lacks a closed form in all but trivial models, and so must be estimated. In applications where the cost of plan execution is expensive, one desires planning estimates which admit theoretical guarantees. Through the use of robust M-estimators we obtain bounds on absolute deviation of estimated MI. Moreover, we propose a sequential algorithm which integrates inference and planning by maximally reusing particles in each stage. We validate the utility of using robust estimators in the sequential approach on a Gaussian Markov Random Field wherein information measures have a closed form. Lastly, we demonstrate the benefits of our integrated approach in the context of sequential experiment design for inferring causal regulatory networks from gene expression levels. Our method shows improvements over a recent method which selects intervention experiments based on the same MI objective.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zheng18b/zheng18b.pdf",
        "supp": "",
        "pdf_size": 615802,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10315666285805028450&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Computer Science and Arti\ufb01cial Intelligence Lab, Massachusetts Institute of Technology, Boston, MA, USA; Computer Science and Arti\ufb01cial Intelligence Lab, Massachusetts Institute of Technology, Boston, MA, USA; Computer Science and Arti\ufb01cial Intelligence Lab, Massachusetts Institute of Technology, Boston, MA, USA",
        "aff_domain": "csail.mit.edu; ; ",
        "email": "csail.mit.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zheng18b.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Arti\ufb01cial Intelligence Lab",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Semantic Loss Function for Deep Learning with Symbolic Knowledge",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2431",
        "id": "2431",
        "author_site": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van den Broeck",
        "author": "Jingyi Xu; Zilu Zhang; Tal Friedman; Yitao Liang; Guy Broeck",
        "abstract": "This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.",
        "bibtex": "@InProceedings{pmlr-v80-xu18h,\n  title = \t {A Semantic Loss Function for Deep Learning with Symbolic Knowledge},\n  author =       {Xu, Jingyi and Zhang, Zilu and Friedman, Tal and Liang, Yitao and Van den Broeck, Guy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5502--5511},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18h/xu18h.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18h.html},\n  abstract = \t {This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18h/xu18h.pdf",
        "supp": "",
        "pdf_size": 428958,
        "gs_citation": 619,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2687938736648965063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "Department of Computer Science, University of California Los Angeles, Los Angeles, CA, USA; Peking University, Beijing, China; Department of Computer Science, University of California Los Angeles, Los Angeles, CA, USA; Department of Computer Science, University of California Los Angeles, Los Angeles, CA, USA; Department of Computer Science, University of California Los Angeles, Los Angeles, CA, USA",
        "aff_domain": "cs.ucla.edu;pku.edu.cn;cs.ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "email": "cs.ucla.edu;pku.edu.cn;cs.ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/xu18h.html",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles;Peking University",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.ucla.edu;http://www.pku.edu.cn",
        "aff_unique_abbr": "UCLA;Peking U",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Los Angeles;Beijing",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2016",
        "id": "2016",
        "author_site": "Kaiwen Zhou, Fanhua Shang, James Cheng",
        "author": "Kaiwen Zhou; Fanhua Shang; James Cheng",
        "abstract": "Recent years have witnessed exciting progress in the study of stochastic variance reduced gradient methods (e.g., SVRG, SAGA), their accelerated variants (e.g, Katyusha) and their extensions in many different settings (e.g., online, sparse, asynchronous, distributed). Among them, accelerated methods enjoy improved convergence rates but have complex coupling structures, which makes them hard to be extended to more settings (e.g., sparse and asynchronous) due to the existence of perturbation. In this paper, we introduce a simple stochastic variance reduced algorithm (MiG), which enjoys the best-known convergence rates for both strongly convex and non-strongly convex problems. Moreover, we also present its efficient sparse and asynchronous variants, and theoretically analyze its convergence rates in these settings. Finally, extensive experiments for various machine learning problems such as logistic regression are given to illustrate the practical improvement in both serial and asynchronous settings.",
        "bibtex": "@InProceedings{pmlr-v80-zhou18c,\n  title = \t {A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates},\n  author =       {Zhou, Kaiwen and Shang, Fanhua and Cheng, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5980--5989},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhou18c/zhou18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhou18c.html},\n  abstract = \t {Recent years have witnessed exciting progress in the study of stochastic variance reduced gradient methods (e.g., SVRG, SAGA), their accelerated variants (e.g, Katyusha) and their extensions in many different settings (e.g., online, sparse, asynchronous, distributed). Among them, accelerated methods enjoy improved convergence rates but have complex coupling structures, which makes them hard to be extended to more settings (e.g., sparse and asynchronous) due to the existence of perturbation. In this paper, we introduce a simple stochastic variance reduced algorithm (MiG), which enjoys the best-known convergence rates for both strongly convex and non-strongly convex problems. Moreover, we also present its efficient sparse and asynchronous variants, and theoretically analyze its convergence rates in these settings. Finally, extensive experiments for various machine learning problems such as logistic regression are given to illustrate the practical improvement in both serial and asynchronous settings.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhou18c/zhou18c.pdf",
        "supp": "",
        "pdf_size": 607469,
        "gs_citation": 103,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10559564034192177508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; School of Artificial Intelligence, Xidian University, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong",
        "aff_domain": "link.cuhk.edu.hk;xidian.edu.cn;cse.cuhk.edu.hk",
        "email": "link.cuhk.edu.hk;xidian.edu.cn;cse.cuhk.edu.hk",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhou18c.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Xidian University",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Artificial Intelligence",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.xidian.edu.cn/",
        "aff_unique_abbr": "CUHK;Xidian",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "A Spectral Approach to Gradient Estimation for Implicit Distributions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2490",
        "id": "2490",
        "author_site": "Jiaxin Shi, Shengyang Sun, Jun Zhu",
        "author": "Jiaxin Shi; Shengyang Sun; Jun Zhu",
        "abstract": "Recently there have been increasing interests in learning and inference with implicit distributions (i.e., distributions without tractable densities). To this end, we develop a gradient estimator for implicit distributions based on Stein\u2019s identity and a spectral decomposition of kernel operators, where the eigenfunctions are approximated by the Nystr{\u00f6}m method. Unlike the previous works that only provide estimates at the sample points, our approach directly estimates the gradient function, thus allows for a simple and principled out-of-sample extension. We provide theoretical results on the error bound of the estimator and discuss the bias-variance tradeoff in practice. The effectiveness of our method is demonstrated by applications to gradient-free Hamiltonian Monte Carlo and variational inference with implicit distributions. Finally, we discuss the intuition behind the estimator by drawing connections between the Nystr{\u00f6}m method and kernel PCA, which indicates that the estimator can automatically adapt to the geometry of the underlying distribution.",
        "bibtex": "@InProceedings{pmlr-v80-shi18a,\n  title = \t {A Spectral Approach to Gradient Estimation for Implicit Distributions},\n  author =       {Shi, Jiaxin and Sun, Shengyang and Zhu, Jun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4644--4653},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/shi18a/shi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/shi18a.html},\n  abstract = \t {Recently there have been increasing interests in learning and inference with implicit distributions (i.e., distributions without tractable densities). To this end, we develop a gradient estimator for implicit distributions based on Stein\u2019s identity and a spectral decomposition of kernel operators, where the eigenfunctions are approximated by the Nystr{\u00f6}m method. Unlike the previous works that only provide estimates at the sample points, our approach directly estimates the gradient function, thus allows for a simple and principled out-of-sample extension. We provide theoretical results on the error bound of the estimator and discuss the bias-variance tradeoff in practice. The effectiveness of our method is demonstrated by applications to gradient-free Hamiltonian Monte Carlo and variational inference with implicit distributions. Finally, we discuss the intuition behind the estimator by drawing connections between the Nystr{\u00f6}m method and kernel PCA, which indicates that the estimator can automatically adapt to the geometry of the underlying distribution.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/shi18a/shi18a.pdf",
        "supp": "",
        "pdf_size": 2788871,
        "gs_citation": 109,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=34252178022681098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University; Dept. of Comp. Sci., University of Toronto; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn; ;tsinghua.edu.cn",
        "email": "mails.tsinghua.edu.cn; ;tsinghua.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/shi18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tsinghua University;University of Toronto",
        "aff_unique_dep": "Dept. of Comp. Sci. & Tech.;Department of Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.utoronto.ca",
        "aff_unique_abbr": "THU;U of T",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "title": "A Spline Theory of Deep Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2302",
        "id": "2302",
        "author_site": "Randall Balestriero, Richard Baraniuk",
        "author": "Randall Balestriero;  baraniuk",
        "abstract": "We build a rigorous bridge between deep networks (DNs) and approximation theory via spline functions and operators. Our key result is that a large class of DNs can be written as a composition of",
        "bibtex": "@InProceedings{pmlr-v80-balestriero18b,\n  title = \t {A Spline Theory of Deep Learning},\n  author =       {Balestriero, Randall and richard baraniuk},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {374--383},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balestriero18b.html},\n  abstract = \t {We build a rigorous bridge between deep networks (DNs) and approximation theory via spline functions and operators. Our key result is that a large class of DNs can be written as a composition of",
        "pdf": "http://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf",
        "supp": "",
        "pdf_size": 1240927,
        "gs_citation": 160,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7364962308217978144&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "ECE Department, Rice University, Houston, TX, USA; ECE Department, Rice University, Houston, TX, USA",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/balestriero18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "ECE Department",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2279",
        "id": "2279",
        "author_site": "Weili Nie, Yang Zhang, Ankit Patel",
        "author": "Weili Nie; Yang Zhang; Ankit Patel",
        "abstract": "Backpropagation-based visualizations have been proposed to interpret convolutional neural networks (CNNs), however a theory is missing to justify their behaviors: Guided backpropagation (GBP) and deconvolutional network (DeconvNet) generate more human-interpretable but less class-sensitive visualizations than saliency map. Motivated by this, we develop a theoretical explanation revealing that GBP and DeconvNet are essentially doing (partial) image recovery which is unrelated to the network decisions. Specifically, our analysis shows that the backward ReLU introduced by GBP and DeconvNet, and the local connections in CNNs are the two main causes of compelling visualizations. Extensive experiments are provided that support the theoretical analysis.",
        "bibtex": "@InProceedings{pmlr-v80-nie18a,\n  title = \t {A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations},\n  author =       {Nie, Weili and Zhang, Yang and Patel, Ankit},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3809--3818},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nie18a/nie18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nie18a.html},\n  abstract = \t {Backpropagation-based visualizations have been proposed to interpret convolutional neural networks (CNNs), however a theory is missing to justify their behaviors: Guided backpropagation (GBP) and deconvolutional network (DeconvNet) generate more human-interpretable but less class-sensitive visualizations than saliency map. Motivated by this, we develop a theoretical explanation revealing that GBP and DeconvNet are essentially doing (partial) image recovery which is unrelated to the network decisions. Specifically, our analysis shows that the backward ReLU introduced by GBP and DeconvNet, and the local connections in CNNs are the two main causes of compelling visualizations. Extensive experiments are provided that support the theoretical analysis.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nie18a/nie18a.pdf",
        "supp": "",
        "pdf_size": 1567999,
        "gs_citation": 189,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7254168770426119962&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical and Computer Engineering, Rice University, Houston, USA; Department of Computer Science, Rice University, Houston, USA; Department of Neuroscience, Baylor College of Medicine, Houston, USA",
        "aff_domain": "rice.edu; ;rice.edu",
        "email": "rice.edu; ;rice.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/nie18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Rice University;Baylor College of Medicine",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Neuroscience",
        "aff_unique_url": "https://www.rice.edu;https://www.bcm.edu",
        "aff_unique_abbr": "Rice;BCM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Two-Step Computation of the Exact GAN Wasserstein Distance",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2363",
        "id": "2363",
        "author_site": "Huidong Liu, Xianfeng GU, Samaras Dimitris",
        "author": "Huidong Liu; Xianfeng GU; Dimitris Samaras",
        "abstract": "In this paper, we propose a two-step method to compute the Wasserstein distance in Wasserstein Generative Adversarial Networks (WGANs): 1) The convex part of our objective can be solved by linear programming; 2) The non-convex residual can be approximated by a deep neural network. We theoretically prove that the proposed formulation is equivalent to the discrete Monge-Kantorovich dual formulation. Furthermore, we give the approximation error bound of the Wasserstein distance and the error bound of generalizing the Wasserstein distance from discrete to continuous distributions. Our approach optimizes the exact Wasserstein distance, obviating the need for weight clipping previously used in WGANs. Results on synthetic data show that the our method computes the Wasserstein distance more accurately. Qualitative and quantitative results on MNIST, LSUN and CIFAR-10 datasets show that the proposed method is more efficient than state-of-the-art WGAN methods, and still produces images of comparable quality.",
        "bibtex": "@InProceedings{pmlr-v80-liu18d,\n  title = \t {A Two-Step Computation of the Exact {GAN} {W}asserstein Distance},\n  author =       {Liu, Huidong and GU, Xianfeng and Samaras, Dimitris},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3159--3168},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18d/liu18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18d.html},\n  abstract = \t {In this paper, we propose a two-step method to compute the Wasserstein distance in Wasserstein Generative Adversarial Networks (WGANs): 1) The convex part of our objective can be solved by linear programming; 2) The non-convex residual can be approximated by a deep neural network. We theoretically prove that the proposed formulation is equivalent to the discrete Monge-Kantorovich dual formulation. Furthermore, we give the approximation error bound of the Wasserstein distance and the error bound of generalizing the Wasserstein distance from discrete to continuous distributions. Our approach optimizes the exact Wasserstein distance, obviating the need for weight clipping previously used in WGANs. Results on synthetic data show that the our method computes the Wasserstein distance more accurately. Qualitative and quantitative results on MNIST, LSUN and CIFAR-10 datasets show that the proposed method is more efficient than state-of-the-art WGAN methods, and still produces images of comparable quality.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18d/liu18d.pdf",
        "supp": "",
        "pdf_size": 2533197,
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15437339123623208074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Stony Brook University, New York, USA; Department of Computer Science, Stony Brook University, New York, USA; Department of Computer Science, Stony Brook University, New York, USA",
        "aff_domain": "cs.stonybrook.edu;cs.stonybrook.edu;cs.stonybrook.edu",
        "email": "cs.stonybrook.edu;cs.stonybrook.edu;cs.stonybrook.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/liu18d.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "A Unified Framework for Structured Low-rank Matrix Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1930",
        "id": "1930",
        "author_site": "Pratik Kumar Jawanpuria, Bamdev Mishra",
        "author": "Pratik Jawanpuria; Bamdev Mishra",
        "abstract": "We consider the problem of learning a low-rank matrix, constrained to lie in a linear subspace, and introduce a novel factorization for modeling such matrices. A salient feature of the proposed factorization scheme is it decouples the low-rank and the structural constraints onto separate factors. We formulate the optimization problem on the Riemannian spectrahedron manifold, where the Riemannian framework allows to develop computationally efficient conjugate gradient and trust-region algorithms. Experiments on problems such as standard/robust/non-negative matrix completion, Hankel matrix learning and multi-task learning demonstrate the efficacy of our approach.",
        "bibtex": "@InProceedings{pmlr-v80-jawanpuria18a,\n  title = \t {A Unified Framework for Structured Low-rank Matrix Learning},\n  author =       {Jawanpuria, Pratik and Mishra, Bamdev},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2254--2263},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jawanpuria18a/jawanpuria18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jawanpuria18a.html},\n  abstract = \t {We consider the problem of learning a low-rank matrix, constrained to lie in a linear subspace, and introduce a novel factorization for modeling such matrices. A salient feature of the proposed factorization scheme is it decouples the low-rank and the structural constraints onto separate factors. We formulate the optimization problem on the Riemannian spectrahedron manifold, where the Riemannian framework allows to develop computationally efficient conjugate gradient and trust-region algorithms. Experiments on problems such as standard/robust/non-negative matrix completion, Hankel matrix learning and multi-task learning demonstrate the efficacy of our approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jawanpuria18a/jawanpuria18a.pdf",
        "supp": "",
        "pdf_size": 551043,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4059619168821059141&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Microsoft, India; Microsoft, India",
        "aff_domain": "microsoft.com;microsoft.com",
        "email": "microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/jawanpuria18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Corporation",
        "aff_unique_url": "https://www.microsoft.com/en-in",
        "aff_unique_abbr": "Microsoft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2020",
        "id": "2020",
        "author_site": "Akifumi Okuno, Tetsuya Hada, Hidetoshi Shimodaira",
        "author": "Akifumi Okuno; Tetsuya Hada; Hidetoshi Shimodaira",
        "abstract": "A simple framework Probabilistic Multi-view Graph Embedding (PMvGE) is proposed for multi-view feature learning with many-to-many associations so that it generalizes various existing multi-view methods. PMvGE is a probabilistic model for predicting new associations via graph embedding of the nodes of data vectors with links of their associations. Multi-view data vectors with many-to-many associations are transformed by neural networks to feature vectors in a shared space, and the probability of new association between two data vectors is modeled by the inner product of their feature vectors. While existing multi-view feature learning techniques can treat only either of many-to-many association or non-linear transformation, PMvGE can treat both simultaneously. By combining Mercer\u2019s theorem and the universal approximation theorem, we prove that PMvGE learns a wide class of similarity measures across views. Our likelihood-based estimator enables efficient computation of non-linear transformations of data vectors in large-scale datasets by minibatch SGD, and numerical experiments illustrate that PMvGE outperforms existing multi-view methods.",
        "bibtex": "@InProceedings{pmlr-v80-okuno18a,\n  title = \t {A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks},\n  author =       {Okuno, Akifumi and Hada, Tetsuya and Shimodaira, Hidetoshi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3888--3897},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/okuno18a/okuno18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/okuno18a.html},\n  abstract = \t {A simple framework Probabilistic Multi-view Graph Embedding (PMvGE) is proposed for multi-view feature learning with many-to-many associations so that it generalizes various existing multi-view methods. PMvGE is a probabilistic model for predicting new associations via graph embedding of the nodes of data vectors with links of their associations. Multi-view data vectors with many-to-many associations are transformed by neural networks to feature vectors in a shared space, and the probability of new association between two data vectors is modeled by the inner product of their feature vectors. While existing multi-view feature learning techniques can treat only either of many-to-many association or non-linear transformation, PMvGE can treat both simultaneously. By combining Mercer\u2019s theorem and the universal approximation theorem, we prove that PMvGE learns a wide class of similarity measures across views. Our likelihood-based estimator enables efficient computation of non-linear transformations of data vectors in large-scale datasets by minibatch SGD, and numerical experiments illustrate that PMvGE outperforms existing multi-view methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/okuno18a/okuno18a.pdf",
        "supp": "",
        "pdf_size": 600553,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3269255786686532538&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Graduate School of Informatics, Kyoto University, Kyoto, Japan + RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; Recruit Technologies Co., Ltd., Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan + RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan",
        "aff_domain": "sys.i.kyoto-u.ac.jp; ; ",
        "email": "sys.i.kyoto-u.ac.jp; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/okuno18a.html",
        "aff_unique_index": "0+1;2;0+1",
        "aff_unique_norm": "Kyoto University;RIKEN Center for Advanced Intelligence Project;Recruit Technologies Co., Ltd.",
        "aff_unique_dep": "Graduate School of Informatics;Advanced Intelligence Project;",
        "aff_unique_url": "https://www.kyoto-u.ac.jp;https://aipcenter.riken.jp/en/;https://www.recruit-tech.co.jp",
        "aff_unique_abbr": "Kyoto U;RIKEN AIP;",
        "aff_campus_unique_index": "0+1;0+1",
        "aff_campus_unique": "Kyoto;Tokyo;",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "ADMM and Accelerated ADMM as Continuous Dynamical Systems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2396",
        "id": "2396",
        "author_site": "Guilherme Franca, Daniel Robinson, Rene Vidal",
        "author": "Guilherme Franca; Daniel Robinson; Rene Vidal",
        "abstract": "Recently, there has been an increasing interest in using tools from dynamical systems to analyze the behavior of simple optimization algorithms such as gradient descent and accelerated variants. This paper strengthens such connections by deriving the differential equations that model the continuous limit of the sequence of iterates generated by the alternating direction method of multipliers, as well as an accelerated variant. We employ the direct method of Lyapunov to analyze the stability of critical points of the dynamical systems and to obtain associated convergence rates.",
        "bibtex": "@InProceedings{pmlr-v80-franca18a,\n  title = \t {{ADMM} and Accelerated {ADMM} as Continuous Dynamical Systems},\n  author =       {Franca, Guilherme and Robinson, Daniel and Vidal, Rene},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1559--1567},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/franca18a/franca18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/franca18a.html},\n  abstract = \t {Recently, there has been an increasing interest in using tools from dynamical systems to analyze the behavior of simple optimization algorithms such as gradient descent and accelerated variants. This paper strengthens such connections by deriving the differential equations that model the continuous limit of the sequence of iterates generated by the alternating direction method of multipliers, as well as an accelerated variant. We employ the direct method of Lyapunov to analyze the stability of critical points of the dynamical systems and to obtain associated convergence rates.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/franca18a/franca18a.pdf",
        "supp": "",
        "pdf_size": 411787,
        "gs_citation": 93,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10100674881409400810&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Mathematical Institute for Data Science, Johns Hopkins University, Baltimore MD 21218, USA; Mathematical Institute for Data Science, Johns Hopkins University, Baltimore MD 21218, USA; Mathematical Institute for Data Science, Johns Hopkins University, Baltimore MD 21218, USA",
        "aff_domain": "jhu.edu; ; ",
        "email": "jhu.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/franca18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Mathematical Institute for Data Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Accelerated Spectral Ranking",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1999",
        "id": "1999",
        "author_site": "Arpit Agarwal, Prathamesh Patil, Shivani Agarwal",
        "author": "Arpit Agarwal; Prathamesh Patil; Shivani Agarwal",
        "abstract": "The problem of rank aggregation from pairwise and multiway comparisons has a wide range of implications, ranging from recommendation systems to sports rankings to social choice. Some of the most popular algorithms for this problem come from the class of spectral ranking algorithms; these include the rank centrality (RC) algorithm for pairwise comparisons, which returns consistent estimates under the Bradley-Terry-Luce (BTL) model for pairwise comparisons (Negahban et al., 2017), and its generalization, the Luce spectral ranking (LSR) algorithm, which returns consistent estimates under the more general multinomial logit (MNL) model for multiway comparisons (Maystre & Grossglauser, 2015). In this paper, we design a provably faster spectral ranking algorithm, which we call accelerated spectral ranking (ASR), that is also consistent under the MNL/BTL models. Our accelerated algorithm is achieved by designing a random walk that has a faster mixing time than the random walks associated with previous algorithms. In addition to a faster algorithm, our results yield improved sample complexity bounds for recovery of the MNL/BTL parameters: to the best of our knowledge, we give the first general sample complexity bounds for recovering the parameters of the MNL model from multiway comparisons under any (connected) comparison graph (and improve significantly over previous bounds for the BTL model for pairwise comparisons). We also give a message-passing interpretation of our algorithm, which suggests a decentralized distributed implementation. Our experiments on several real-world and synthetic datasets confirm that our new ASR algorithm is indeed orders of magnitude faster than existing algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-agarwal18b,\n  title = \t {Accelerated Spectral Ranking},\n  author =       {Agarwal, Arpit and Patil, Prathamesh and Agarwal, Shivani},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {70--79},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/agarwal18b/agarwal18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/agarwal18b.html},\n  abstract = \t {The problem of rank aggregation from pairwise and multiway comparisons has a wide range of implications, ranging from recommendation systems to sports rankings to social choice. Some of the most popular algorithms for this problem come from the class of spectral ranking algorithms; these include the rank centrality (RC) algorithm for pairwise comparisons, which returns consistent estimates under the Bradley-Terry-Luce (BTL) model for pairwise comparisons (Negahban et al., 2017), and its generalization, the Luce spectral ranking (LSR) algorithm, which returns consistent estimates under the more general multinomial logit (MNL) model for multiway comparisons (Maystre & Grossglauser, 2015). In this paper, we design a provably faster spectral ranking algorithm, which we call accelerated spectral ranking (ASR), that is also consistent under the MNL/BTL models. Our accelerated algorithm is achieved by designing a random walk that has a faster mixing time than the random walks associated with previous algorithms. In addition to a faster algorithm, our results yield improved sample complexity bounds for recovery of the MNL/BTL parameters: to the best of our knowledge, we give the first general sample complexity bounds for recovering the parameters of the MNL model from multiway comparisons under any (connected) comparison graph (and improve significantly over previous bounds for the BTL model for pairwise comparisons). We also give a message-passing interpretation of our algorithm, which suggests a decentralized distributed implementation. Our experiments on several real-world and synthetic datasets confirm that our new ASR algorithm is indeed orders of magnitude faster than existing algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/agarwal18b/agarwal18b.pdf",
        "supp": "",
        "pdf_size": 514273,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17059082101801262373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer and Information Science, University of Pennsylvania, Philadelphia, USA; Department of Computer and Information Science, University of Pennsylvania, Philadelphia, USA; Department of Computer and Information Science, University of Pennsylvania, Philadelphia, USA",
        "aff_domain": "seas.upenn.edu; ;seas.upenn.edu",
        "email": "seas.upenn.edu; ;seas.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/agarwal18b.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Computer and Information Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Accelerating Greedy Coordinate Descent Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2201",
        "id": "2201",
        "author_site": "Haihao Lu, Robert Freund, Vahab Mirrokni",
        "author": "Haihao Lu; Robert Freund; Vahab Mirrokni",
        "abstract": "We introduce and study two algorithms to accelerate greedy coordinate descent in theory and in practice: Accelerated Semi-Greedy Coordinate Descent (ASCD) and Accelerated Greedy Coordinate Descent (AGCD). On the theory side, our main results are for ASCD: we show that ASCD achieves $O(1/k^2)$ convergence, and it also achieves accelerated linear convergence for strongly convex functions. On the empirical side, while both AGCD and ASCD outperform Accelerated Randomized Coordinate Descent on most instances in our numerical experiments, we note that AGCD significantly outperforms the other two methods in our experiments, in spite of a lack of theoretical guarantees for this method. To complement this empirical finding for AGCD, we present an explanation why standard proof techniques for acceleration cannot work for AGCD, and we further introduce a technical condition under which AGCD is guaranteed to have accelerated convergence. Finally, we confirm that this technical condition holds in our numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v80-lu18b,\n  title = \t {Accelerating Greedy Coordinate Descent Methods},\n  author =       {Lu, Haihao and Freund, Robert and Mirrokni, Vahab},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3257--3266},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lu18b/lu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lu18b.html},\n  abstract = \t {We introduce and study two algorithms to accelerate greedy coordinate descent in theory and in practice: Accelerated Semi-Greedy Coordinate Descent (ASCD) and Accelerated Greedy Coordinate Descent (AGCD). On the theory side, our main results are for ASCD: we show that ASCD achieves $O(1/k^2)$ convergence, and it also achieves accelerated linear convergence for strongly convex functions. On the empirical side, while both AGCD and ASCD outperform Accelerated Randomized Coordinate Descent on most instances in our numerical experiments, we note that AGCD significantly outperforms the other two methods in our experiments, in spite of a lack of theoretical guarantees for this method. To complement this empirical finding for AGCD, we present an explanation why standard proof techniques for acceleration cannot work for AGCD, and we further introduce a technical condition under which AGCD is guaranteed to have accelerated convergence. Finally, we confirm that this technical condition holds in our numerical experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lu18b/lu18b.pdf",
        "supp": "",
        "pdf_size": 2701412,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17992057767685673233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Mathematics and Operations Research Center, MIT; Sloan School of Management, MIT; Google Research",
        "aff_domain": "mit.edu; ; ",
        "email": "mit.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lu18b.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google",
        "aff_unique_dep": "Department of Mathematics and Operations Research Center;Google Research",
        "aff_unique_url": "https://web.mit.edu;https://research.google",
        "aff_unique_abbr": "MIT;Google Research",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Cambridge;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Accelerating Natural Gradient with Higher-Order Invariance",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2386",
        "id": "2386",
        "author_site": "Yang Song, Jiaming Song, Stefano Ermon",
        "author": "Yang Song; Jiaming Song; Stefano Ermon",
        "abstract": "An appealing property of the natural gradient is that it is invariant to arbitrary differentiable reparameterizations of the model. However, this invariance property requires infinitesimal steps and is lost in practical implementations with small but finite step sizes. In this paper, we study invariance properties from a combined perspective of Riemannian geometry and numerical differential equation solving. We define the order of invariance of a numerical method to be its convergence order to an invariant solution. We propose to use higher-order integrators and geodesic corrections to obtain more invariant optimization trajectories. We prove the numerical convergence properties of geodesic corrected updates and show that they can be as computational efficient as plain natural gradient. Experimentally, we demonstrate that invariance leads to faster optimization and our techniques improve on traditional natural gradient in deep neural network training and natural policy gradient for reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v80-song18a,\n  title = \t {Accelerating Natural Gradient with Higher-Order Invariance},\n  author =       {Song, Yang and Song, Jiaming and Ermon, Stefano},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4713--4722},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/song18a/song18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/song18a.html},\n  abstract = \t {An appealing property of the natural gradient is that it is invariant to arbitrary differentiable reparameterizations of the model. However, this invariance property requires infinitesimal steps and is lost in practical implementations with small but finite step sizes. In this paper, we study invariance properties from a combined perspective of Riemannian geometry and numerical differential equation solving. We define the order of invariance of a numerical method to be its convergence order to an invariant solution. We propose to use higher-order integrators and geodesic corrections to obtain more invariant optimization trajectories. We prove the numerical convergence properties of geodesic corrected updates and show that they can be as computational efficient as plain natural gradient. Experimentally, we demonstrate that invariance leads to faster optimization and our techniques improve on traditional natural gradient in deep neural network training and natural policy gradient for reinforcement learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/song18a/song18a.pdf",
        "supp": "",
        "pdf_size": 4703724,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17686115985744822983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Department, Stanford University; Computer Science Department, Stanford University; Computer Science Department, Stanford University",
        "aff_domain": "cs.stanford.edu;cs.stanford.edu;cs.stanford.edu",
        "email": "cs.stanford.edu;cs.stanford.edu;cs.stanford.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/song18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Accurate Inference for Adaptive Linear Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2060",
        "id": "2060",
        "author_site": "Yash Deshpande, Lester Mackey, Vasilis Syrgkanis, Matt Taddy",
        "author": "Yash Deshpande; Lester Mackey; Vasilis Syrgkanis; Matt Taddy",
        "abstract": "Estimators computed from adaptively collected data do not behave like their non-adaptive brethren.Rather, the sequential dependence of the collection policy can lead to severe distributional biases that persist even in the infinite data limit. We develop a general method \u2013",
        "bibtex": "@InProceedings{pmlr-v80-deshpande18a,\n  title = \t {Accurate Inference for Adaptive Linear Models},\n  author =       {Deshpande, Yash and Mackey, Lester and Syrgkanis, Vasilis and Taddy, Matt},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1194--1203},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/deshpande18a/deshpande18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/deshpande18a.html},\n  abstract = \t {Estimators computed from adaptively collected data do not behave like their non-adaptive brethren.Rather, the sequential dependence of the collection policy can lead to severe distributional biases that persist even in the infinite data limit. We develop a general method \u2013",
        "pdf": "http://proceedings.mlr.press/v80/deshpande18a/deshpande18a.pdf",
        "supp": "",
        "pdf_size": 610881,
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13503132869501181430&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/deshpande18a.html"
    },
    {
        "title": "Accurate Uncertainties for Deep Learning Using Calibrated Regression",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2486",
        "id": "2486",
        "author_site": "Volodymyr Kuleshov, Nathan Fenner, Stefano Ermon",
        "author": "Volodymyr Kuleshov; Nathan Fenner; Stefano Ermon",
        "abstract": "Methods for reasoning under uncertainty are a key building block of accurate and reliable machine learning systems. Bayesian methods provide a general framework to quantify uncertainty. However, because of model misspecification and the use of approximate inference, Bayesian uncertainty estimates are often inaccurate {\u2014} for example, a 90% credible interval may not contain the true outcome 90% of the time. Here, we propose a simple procedure for calibrating any regression algorithm; when applied to Bayesian and probabilistic models, it is guaranteed to produce calibrated uncertainty estimates given enough data. Our procedure is inspired by Platt scaling and extends previous work on classification. We evaluate this approach on Bayesian linear regression, feedforward, and recurrent neural networks, and find that it consistently outputs well-calibrated credible intervals while improving performance on time series forecasting and model-based reinforcement learning tasks.",
        "bibtex": "@InProceedings{pmlr-v80-kuleshov18a,\n  title = \t {Accurate Uncertainties for Deep Learning Using Calibrated Regression},\n  author =       {Kuleshov, Volodymyr and Fenner, Nathan and Ermon, Stefano},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2796--2804},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kuleshov18a/kuleshov18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kuleshov18a.html},\n  abstract = \t {Methods for reasoning under uncertainty are a key building block of accurate and reliable machine learning systems. Bayesian methods provide a general framework to quantify uncertainty. However, because of model misspecification and the use of approximate inference, Bayesian uncertainty estimates are often inaccurate {\u2014} for example, a 90% credible interval may not contain the true outcome 90% of the time. Here, we propose a simple procedure for calibrating any regression algorithm; when applied to Bayesian and probabilistic models, it is guaranteed to produce calibrated uncertainty estimates given enough data. Our procedure is inspired by Platt scaling and extends previous work on classification. We evaluate this approach on Bayesian linear regression, feedforward, and recurrent neural networks, and find that it consistently outputs well-calibrated credible intervals while improving performance on time series forecasting and model-based reinforcement learning tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kuleshov18a/kuleshov18a.pdf",
        "supp": "",
        "pdf_size": 2841541,
        "gs_citation": 813,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8482992625396609385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Stanford University; Afresh Technologies; Stanford University",
        "aff_domain": "afreshtechnologies.com; ; ",
        "email": "afreshtechnologies.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kuleshov18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;Afresh Technologies",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;",
        "aff_unique_abbr": "Stanford;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "title": "Active Learning with Logged Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1990",
        "id": "1990",
        "author_site": "Songbai Yan, Kamalika Chaudhuri, Tara Javidi",
        "author": "Songbai Yan; Kamalika Chaudhuri; Tara Javidi",
        "abstract": "We consider active learning with logged data, where labeled examples are drawn conditioned on a predetermined logging policy, and the goal is to learn a classifier on the entire population, not just conditioned on the logging policy. Prior work addresses this problem either when only logged data is available, or purely in a controlled random experimentation setting where the logged data is ignored. In this work, we combine both approaches to provide an algorithm that uses logged data to bootstrap and inform experimentation, thus achieving the best of both worlds. Our work is inspired by a connection between controlled random experimentation and active learning, and modifies existing disagreement-based active learning algorithms to exploit logged data.",
        "bibtex": "@InProceedings{pmlr-v80-yan18a,\n  title = \t {Active Learning with Logged Data},\n  author =       {Yan, Songbai and Chaudhuri, Kamalika and Javidi, Tara},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5521--5530},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yan18a/yan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yan18a.html},\n  abstract = \t {We consider active learning with logged data, where labeled examples are drawn conditioned on a predetermined logging policy, and the goal is to learn a classifier on the entire population, not just conditioned on the logging policy. Prior work addresses this problem either when only logged data is available, or purely in a controlled random experimentation setting where the logged data is ignored. In this work, we combine both approaches to provide an algorithm that uses logged data to bootstrap and inform experimentation, thus achieving the best of both worlds. Our work is inspired by a connection between controlled random experimentation and active learning, and modifies existing disagreement-based active learning algorithms to exploit logged data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yan18a/yan18a.pdf",
        "supp": "",
        "pdf_size": 340861,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13270152641202404995&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, San Diego; University of California, San Diego; University of California, San Diego",
        "aff_domain": "eng.ucsd.edu; ; ",
        "email": "eng.ucsd.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/yan18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Active Testing: An Efficient and Robust Framework for Estimating Accuracy",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1946",
        "id": "1946",
        "author_site": "Phuc Nguyen, Deva Ramanan, Charless Fowlkes",
        "author": "Phuc Nguyen; Deva Ramanan; Charless Fowlkes",
        "abstract": "Much recent work on large-scale visual recogni- tion aims to scale up learning to massive, noisily- annotated datasets. We address the problem of scaling-up the evaluation of such models to large- scale datasets with noisy labels. Current protocols for doing so require a human user to either vet (re-annotate) a small fraction of the testset and ignore the rest, or else correct errors in annotation as they are found through manual inspection of results. In this work, we re-formulate the problem as one of active testing, and examine strategies for efficiently querying a user so as to obtain an accurate performance estimate with minimal vet- ting. We demonstrate the effectiveness of our proposed active testing framework on estimating two performance metrics, Precision@K and mean Average Precisions, for two popular Computer Vi- sion tasks, multilabel classification and instance segmentation, respectively. We further show that our approach is able to siginificantly save human annotation effort and more robust than alterna- tive evaluation protocols.",
        "bibtex": "@InProceedings{pmlr-v80-nguyen18d,\n  title = \t {Active Testing: An Efficient and Robust Framework for Estimating Accuracy},\n  author =       {Nguyen, Phuc and Ramanan, Deva and Fowlkes, Charless},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3759--3768},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nguyen18d/nguyen18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nguyen18d.html},\n  abstract = \t {Much recent work on large-scale visual recogni- tion aims to scale up learning to massive, noisily- annotated datasets. We address the problem of scaling-up the evaluation of such models to large- scale datasets with noisy labels. Current protocols for doing so require a human user to either vet (re-annotate) a small fraction of the testset and ignore the rest, or else correct errors in annotation as they are found through manual inspection of results. In this work, we re-formulate the problem as one of active testing, and examine strategies for efficiently querying a user so as to obtain an accurate performance estimate with minimal vet- ting. We demonstrate the effectiveness of our proposed active testing framework on estimating two performance metrics, Precision@K and mean Average Precisions, for two popular Computer Vi- sion tasks, multilabel classification and instance segmentation, respectively. We further show that our approach is able to siginificantly save human annotation effort and more robust than alterna- tive evaluation protocols.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nguyen18d/nguyen18d.pdf",
        "supp": "",
        "pdf_size": 1778911,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5028600704012464713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, Irvine; Carnegie Mellon University; University of California, Irvine",
        "aff_domain": "uci.edu; ; ",
        "email": "uci.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/nguyen18d.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Irvine;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uci.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UCI;CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Irvine;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2446",
        "id": "2446",
        "author_site": "Noam Shazeer, Mitchell Stern",
        "author": "Noam Shazeer; Mitchell Stern",
        "abstract": "In several recently proposed stochastic optimization methods (e.g. RMSProp, Adam, Adadelta), parameter updates are scaled by the inverse square roots of exponential moving averages of squared past gradients. Maintaining these per-parameter second-moment estimators requires memory equal to the number of parameters. For the case of neural network weight matrices, we propose maintaining only the per-row and per-column sums of these moving averages, and estimating the per-parameter second moments based on these sums. We demonstrate empirically that this method produces similar results to the baseline. Secondly, we show that adaptive methods can produce larger-than-desired updates when the decay rate of the second moment accumulator is too slow. We propose update clipping and a gradually increasing decay rate scheme as remedies. Combining these methods and dropping momentum, we achieve comparable results to the published Adam regime in training the Transformer model on the WMT 2014 English-German machine translation task, while using very little auxiliary storage in the optimizer. Finally, we propose scaling the parameter updates based on the scale of the parameters themselves.",
        "bibtex": "@InProceedings{pmlr-v80-shazeer18a,\n  title = \t {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},\n  author =       {Shazeer, Noam and Stern, Mitchell},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4596--4604},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/shazeer18a/shazeer18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/shazeer18a.html},\n  abstract = \t {In several recently proposed stochastic optimization methods (e.g. RMSProp, Adam, Adadelta), parameter updates are scaled by the inverse square roots of exponential moving averages of squared past gradients. Maintaining these per-parameter second-moment estimators requires memory equal to the number of parameters. For the case of neural network weight matrices, we propose maintaining only the per-row and per-column sums of these moving averages, and estimating the per-parameter second moments based on these sums. We demonstrate empirically that this method produces similar results to the baseline. Secondly, we show that adaptive methods can produce larger-than-desired updates when the decay rate of the second moment accumulator is too slow. We propose update clipping and a gradually increasing decay rate scheme as remedies. Combining these methods and dropping momentum, we achieve comparable results to the published Adam regime in training the Transformer model on the WMT 2014 English-German machine translation task, while using very little auxiliary storage in the optimizer. Finally, we propose scaling the parameter updates based on the scale of the parameters themselves.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/shazeer18a/shazeer18a.pdf",
        "supp": "",
        "pdf_size": 326317,
        "gs_citation": 1122,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12975446790619053694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA + University of California, Berkeley, California, USA",
        "aff_domain": "google.com; ",
        "email": "google.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/shazeer18a.html",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Google;University of California, Berkeley",
        "aff_unique_dep": "Google Brain;",
        "aff_unique_url": "https://brain.google.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Google Brain;UC Berkeley",
        "aff_campus_unique_index": "0;0+1",
        "aff_campus_unique": "Mountain View;Berkeley",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1996",
        "id": "1996",
        "author_site": "Huasen Wu, Xueying Guo, Xin Liu",
        "author": "Huasen Wu; Xueying Guo; Xin Liu",
        "abstract": "In this paper, we propose and study opportunistic bandits - a new variant of bandits where the regret of pulling a suboptimal arm varies under different environmental conditions, such as network load or produce price. When the load/price is low, so is the cost/regret of pulling a suboptimal arm (e.g., trying a suboptimal network configuration). Therefore, intuitively, we could explore more when the load/price is low and exploit more when the load/price is high. Inspired by this intuition, we propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff for opportunistic bandits. We prove that AdaUCB achieves O(log T) regret with a smaller coefficient than the traditional UCB algorithm. Furthermore, AdaUCB achieves O(1) regret with respect to T if the exploration cost is zero when the load level is below a certain threshold. Last, based on both synthetic data and real-world traces, experimental results show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load/price fluctuations.",
        "bibtex": "@InProceedings{pmlr-v80-wu18b,\n  title = \t {Adaptive Exploration-Exploitation Tradeoff for Opportunistic Bandits},\n  author =       {Wu, Huasen and Guo, Xueying and Liu, Xin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5306--5314},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18b/wu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18b.html},\n  abstract = \t {In this paper, we propose and study opportunistic bandits - a new variant of bandits where the regret of pulling a suboptimal arm varies under different environmental conditions, such as network load or produce price. When the load/price is low, so is the cost/regret of pulling a suboptimal arm (e.g., trying a suboptimal network configuration). Therefore, intuitively, we could explore more when the load/price is low and exploit more when the load/price is high. Inspired by this intuition, we propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff for opportunistic bandits. We prove that AdaUCB achieves O(log T) regret with a smaller coefficient than the traditional UCB algorithm. Furthermore, AdaUCB achieves O(1) regret with respect to T if the exploration cost is zero when the load level is below a certain threshold. Last, based on both synthetic data and real-world traces, experimental results show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load/price fluctuations.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18b/wu18b.pdf",
        "supp": "",
        "pdf_size": 354713,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15084906264021988299&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Twitter Inc., San Francisco, California, USA + University of California, Davis, California, USA; University of California, Davis, California, USA; University of California, Davis, California, USA",
        "aff_domain": "twitter.com;ucdavis.edu;ucdavis.edu",
        "email": "twitter.com;ucdavis.edu;ucdavis.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wu18b.html",
        "aff_unique_index": "0+1;1;1",
        "aff_unique_norm": "Twitter Inc.;University of California, Davis",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://twitter.com;https://www.ucdavis.edu",
        "aff_unique_abbr": "Twitter;UC Davis",
        "aff_campus_unique_index": "0+1;1;1",
        "aff_campus_unique": "San Francisco;Davis",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Adaptive Sampled Softmax with Kernel Based Sampling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1953",
        "id": "1953",
        "author_site": "Guy Blanc, Steffen Rendle",
        "author": "Guy Blanc; Steffen Rendle",
        "abstract": "Softmax is the most commonly used output function for multiclass problems and is widely used in areas such as vision, natural language processing, and recommendation. A softmax model has linear costs in the number of classes which makes it too expensive for many real-world problems. A common approach to speed up training involves sampling only some of the classes at each training step. It is known that this method is biased and that the bias increases the more the sampling distribution deviates from the output distribution. Nevertheless, almost all recent work uses simple sampling distributions that require a large sample size to mitigate the bias. In this work, we propose a new class of kernel based sampling methods and develop an efficient sampling algorithm. Kernel based sampling adapts to the model as it is trained, thus resulting in low bias. It can also be easily applied to many models because it relies only on the model\u2019s last hidden layer. We empirically study the trade-off of bias, sampling distribution and sample size and show that kernel based sampling results in low bias with few samples.",
        "bibtex": "@InProceedings{pmlr-v80-blanc18a,\n  title = \t {Adaptive Sampled Softmax with Kernel Based Sampling},\n  author =       {Blanc, Guy and Rendle, Steffen},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {590--599},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/blanc18a/blanc18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/blanc18a.html},\n  abstract = \t {Softmax is the most commonly used output function for multiclass problems and is widely used in areas such as vision, natural language processing, and recommendation. A softmax model has linear costs in the number of classes which makes it too expensive for many real-world problems. A common approach to speed up training involves sampling only some of the classes at each training step. It is known that this method is biased and that the bias increases the more the sampling distribution deviates from the output distribution. Nevertheless, almost all recent work uses simple sampling distributions that require a large sample size to mitigate the bias. In this work, we propose a new class of kernel based sampling methods and develop an efficient sampling algorithm. Kernel based sampling adapts to the model as it is trained, thus resulting in low bias. It can also be easily applied to many models because it relies only on the model\u2019s last hidden layer. We empirically study the trade-off of bias, sampling distribution and sample size and show that kernel based sampling results in low bias with few samples.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/blanc18a/blanc18a.pdf",
        "supp": "",
        "pdf_size": 469770,
        "gs_citation": 93,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=189574298446718909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Google, Mountain View, USA+Work done during internship at Google, Mountain View, USA; Google, Mountain View, USA",
        "aff_domain": "gmail.com;google.com",
        "email": "gmail.com;google.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/blanc18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google;",
        "aff_unique_dep": "Google;",
        "aff_unique_url": "https://www.google.com;",
        "aff_unique_abbr": "Google;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "title": "Adaptive Three Operator Splitting",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1871",
        "id": "1871",
        "author_site": "Fabian Pedregosa, Gauthier Gidel",
        "author": "Fabian Pedregosa; Gauthier Gidel",
        "abstract": "We propose and analyze a novel adaptive step size variant of the Davis-Yin three operator splitting, a method that can solve optimization problems composed of a sum of a smooth term for which we have access to its gradient and an arbitrary number of potentially non-smooth terms for which we have access to their proximal operator. The proposed method leverages local information of the objective function, allowing for larger step sizes while preserving the convergence properties of the original method. It only requires two extra function evaluations per iteration and does not depend on any step size hyperparameter besides an initial estimate. We provide a convergence rate analysis of this method, showing sublinear convergence rate for general convex functions and linear convergence under stronger assumptions, matching the best known rates of its non adaptive variant. Finally, an empirical comparison with related methods on 6 different problems illustrates the computational advantage of the adaptive step size strategy.",
        "bibtex": "@InProceedings{pmlr-v80-pedregosa18a,\n  title = \t {Adaptive Three Operator Splitting},\n  author =       {Pedregosa, Fabian and Gidel, Gauthier},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4085--4094},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pedregosa18a/pedregosa18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pedregosa18a.html},\n  abstract = \t {We propose and analyze a novel adaptive step size variant of the Davis-Yin three operator splitting, a method that can solve optimization problems composed of a sum of a smooth term for which we have access to its gradient and an arbitrary number of potentially non-smooth terms for which we have access to their proximal operator. The proposed method leverages local information of the objective function, allowing for larger step sizes while preserving the convergence properties of the original method. It only requires two extra function evaluations per iteration and does not depend on any step size hyperparameter besides an initial estimate. We provide a convergence rate analysis of this method, showing sublinear convergence rate for general convex functions and linear convergence under stronger assumptions, matching the best known rates of its non adaptive variant. Finally, an empirical comparison with related methods on 6 different problems illustrates the computational advantage of the adaptive step size strategy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pedregosa18a/pedregosa18a.pdf",
        "supp": "",
        "pdf_size": 859810,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15067592884842077408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California at Berkeley, USA+Department of Computer Science, ETH Zurich, Switzerland; Mila - Universit\u00e9 de Montr\u00e9al, Canada",
        "aff_domain": "bianp.net; ",
        "email": "bianp.net; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/pedregosa18a.html",
        "aff_unique_index": "0+1;2",
        "aff_unique_norm": "University of California, Berkeley;ETH Zurich;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": ";Department of Computer Science;Mila",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ethz.ch;https://www.usherbrooke.ca",
        "aff_unique_abbr": "UC Berkeley;ETHZ;UdeM",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Berkeley;;Montr\u00e9al",
        "aff_country_unique_index": "0+1;2",
        "aff_country_unique": "United States;Switzerland;Canada"
    },
    {
        "title": "Addressing Function Approximation Error in Actor-Critic Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2227",
        "id": "2227",
        "author_site": "Scott Fujimoto, Herke van Hoof, David Meger",
        "author": "Scott Fujimoto; Herke Hoof; David Meger",
        "abstract": "In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.",
        "bibtex": "@InProceedings{pmlr-v80-fujimoto18a,\n  title = \t {Addressing Function Approximation Error in Actor-Critic Methods},\n  author =       {Fujimoto, Scott and van Hoof, Herke and Meger, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1587--1596},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fujimoto18a.html},\n  abstract = \t {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf",
        "supp": "",
        "pdf_size": 2256703,
        "gs_citation": 7345,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2930747733592680111&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "McGill University, Montreal, Canada; University of Amsterdam, Amsterdam, Netherlands; McGill University, Montreal, Canada",
        "aff_domain": "mail.mcgill.ca; ; ",
        "email": "mail.mcgill.ca; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/fujimoto18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "McGill University;University of Amsterdam",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.mcgill.ca;https://www.uva.nl",
        "aff_unique_abbr": "McGill;UvA",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Montreal;Amsterdam",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;Netherlands"
    },
    {
        "title": "Adversarial Attack on Graph Structured Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2294",
        "id": "2294",
        "author_site": "Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, Le Song",
        "author": "Hanjun Dai; Hui Li; Tian Tian; Xin Huang; Lin Wang; Jun Zhu; Le Song",
        "abstract": "Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool deep learning models by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. We further propose attack methods based on genetic algorithms and gradient descent in the scenario where additional prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers.",
        "bibtex": "@InProceedings{pmlr-v80-dai18b,\n  title = \t {Adversarial Attack on Graph Structured Data},\n  author =       {Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1115--1124},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dai18b/dai18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dai18b.html},\n  abstract = \t {Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool deep learning models by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. We further propose attack methods based on genetic algorithms and gradient descent in the scenario where additional prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dai18b/dai18b.pdf",
        "supp": "",
        "pdf_size": 524153,
        "gs_citation": 981,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6114225754307834218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Georgia Institute of Technology; Ant Financial; Tsinghua University; Ant Financial; Ant Financial; Tsinghua University; Georgia Institute of Technology+Ant Financial",
        "aff_domain": "gatech.edu; ; ; ; ; ; ",
        "email": "gatech.edu; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/dai18b.html",
        "aff_unique_index": "0;1;2;1;1;2;0+1",
        "aff_unique_norm": "Georgia Institute of Technology;Ant Financial;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.gatech.edu;https://www.antgroup.com;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Georgia Tech;Ant Financial;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;1;1;0+1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "b5a2a8306f",
        "title": "Adversarial Distillation of Bayesian Neural Network Posteriors",
        "site": "https://proceedings.mlr.press/v80/wang18i.html",
        "author": "Kuan-Chieh Wang; Paul Vicol; James Lucas; Li Gu; Roger Grosse; Richard Zemel",
        "abstract": "Bayesian neural networks (BNNs) allow us to reason about uncertainty in a principled way. Stochastic Gradient Langevin Dynamics (SGLD) enables efficient BNN learning by drawing samples from the BNN posterior using mini-batches. However, SGLD and its extensions require storage of many copies of the model parameters, a potentially prohibitive cost, especially for large neural networks. We propose a framework, Adversarial Posterior Distillation, to distill the SGLD samples using a Generative Adversarial Network (GAN). At test-time, samples are generated by the GAN. We show that this distillation framework incurs no loss in performance on recent BNN applications including anomaly detection, active learning, and defense against adversarial attacks. By construction, our framework distills not only the Bayesian predictive distribution, but the posterior itself. This allows one to compute quantities such as the approximate model variance, which is useful in downstream tasks. To our knowledge, these are the first results applying MCMC-based BNNs to the aforementioned applications.",
        "bibtex": "@InProceedings{pmlr-v80-wang18i,\n  title = \t {Adversarial Distillation of {B}ayesian Neural Network Posteriors},\n  author =       {Wang, Kuan-Chieh and Vicol, Paul and Lucas, James and Gu, Li and Grosse, Roger and Zemel, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5190--5199},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18i/wang18i.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18i.html},\n  abstract = \t {Bayesian neural networks (BNNs) allow us to reason about uncertainty in a principled way. Stochastic Gradient Langevin Dynamics (SGLD) enables efficient BNN learning by drawing samples from the BNN posterior using mini-batches. However, SGLD and its extensions require storage of many copies of the model parameters, a potentially prohibitive cost, especially for large neural networks. We propose a framework, Adversarial Posterior Distillation, to distill the SGLD samples using a Generative Adversarial Network (GAN). At test-time, samples are generated by the GAN. We show that this distillation framework incurs no loss in performance on recent BNN applications including anomaly detection, active learning, and defense against adversarial attacks. By construction, our framework distills not only the Bayesian predictive distribution, but the posterior itself. This allows one to compute quantities such as the approximate model variance, which is useful in downstream tasks. To our knowledge, these are the first results applying MCMC-based BNNs to the aforementioned applications.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18i/wang18i.pdf",
        "supp": "",
        "pdf_size": 1024065,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8595967760145130464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of Toronto + Vector Institute; University of Toronto + Vector Institute; University of Toronto + Vector Institute; University of Toronto; University of Toronto + Vector Institute; University of Toronto + Vector Institute",
        "aff_domain": "cs.toronto.edu; ; ; ; ; ",
        "email": "cs.toronto.edu; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0+1;0+1;0+1;0;0+1;0+1",
        "aff_unique_norm": "University of Toronto;Vector Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utoronto.ca;https://vectorinstitute.ai/",
        "aff_unique_abbr": "U of T;Vector Institute",
        "aff_campus_unique_index": ";;;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0;0;0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Adversarial Learning with Local Coordinate Coding",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1902",
        "id": "1902",
        "author_site": "Jiezhang Cao, Yong Guo, Qingyao Wu, Chunhua Shen, Junzhou Huang, Mingkui Tan",
        "author": "Jiezhang Cao; Yong Guo; Qingyao Wu; Chunhua Shen; Junzhou Huang; Mingkui Tan",
        "abstract": "Generative adversarial networks (GANs) aim to generate realistic data from some prior distribution (e.g., Gaussian noises). However, such prior distribution is often independent of real data and thus may lose semantic information (e.g., geometric structure or content in images) of data. In practice, the semantic information might be represented by some latent distribution learned from data, which, however, is hard to be used for sampling in GANs. In this paper, rather than sampling from the pre-defined prior distribution, we propose a Local Coordinate Coding (LCC) based sampling method to improve GANs. We derive a generalization bound for LCC based GANs and prove that a small dimensional input is sufficient to achieve good generalization. Extensive experiments on various real-world datasets demonstrate the effectiveness of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v80-cao18a,\n  title = \t {Adversarial Learning with Local Coordinate Coding},\n  author =       {Cao, Jiezhang and Guo, Yong and Wu, Qingyao and Shen, Chunhua and Huang, Junzhou and Tan, Mingkui},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {707--715},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cao18a/cao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cao18a.html},\n  abstract = \t {Generative adversarial networks (GANs) aim to generate realistic data from some prior distribution (e.g., Gaussian noises). However, such prior distribution is often independent of real data and thus may lose semantic information (e.g., geometric structure or content in images) of data. In practice, the semantic information might be represented by some latent distribution learned from data, which, however, is hard to be used for sampling in GANs. In this paper, rather than sampling from the pre-defined prior distribution, we propose a Local Coordinate Coding (LCC) based sampling method to improve GANs. We derive a generalization bound for LCC based GANs and prove that a small dimensional input is sufficient to achieve good generalization. Extensive experiments on various real-world datasets demonstrate the effectiveness of the proposed method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cao18a/cao18a.pdf",
        "supp": "",
        "pdf_size": 6142299,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5978486756433222565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Software Engineering, South China University of Technology, China; School of Software Engineering, South China University of Technology, China; School of Software Engineering, South China University of Technology, China; School of Computer Science, The University of Adelaide, Australia; Tencent AI Lab, China + University of Texas at Arlington, America; School of Software Engineering, South China University of Technology, China",
        "aff_domain": "scut.edu.cn;scut.edu.cn;scut.edu.cn;adelaide.edu.au;tencent.com;scut.edu.cn",
        "email": "scut.edu.cn;scut.edu.cn;scut.edu.cn;adelaide.edu.au;tencent.com;scut.edu.cn",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/cao18a.html",
        "aff_unique_index": "0;0;0;1;2+3;0",
        "aff_unique_norm": "South China University of Technology;University of Adelaide;Tencent;University of Texas at Arlington",
        "aff_unique_dep": "School of Software Engineering;School of Computer Science;Tencent AI Lab;",
        "aff_unique_url": "https://www.scut.edu.cn;https://www.adelaide.edu.au;https://ai.tencent.com;https://www.uta.edu",
        "aff_unique_abbr": "SCUT;Adelaide;Tencent AI Lab;UTA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0+2;0",
        "aff_country_unique": "China;Australia;United States"
    },
    {
        "title": "Adversarial Regression with Multiple Learners",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2481",
        "id": "2481",
        "author_site": "Liang Tong, Sixie Yu, Scott Alfeld, Yevgeniy Vorobeychik",
        "author": "Liang Tong; Sixie Yu; Scott Alfeld;  vorobeychik",
        "abstract": "Despite the considerable success enjoyed by machine learning techniques in practice, numerous studies demonstrated that many approaches are vulnerable to attacks. An important class of such attacks involves adversaries changing features at test time to cause incorrect predictions. Previous investigations of this problem pit a single learner against an adversary. However, in many situations an adversary\u2019s decision is aimed at a collection of learners, rather than specifically targeted at each independently. We study the problem of adversarial linear regression with multiple learners. We approximate the resulting game by exhibiting an upper bound on learner loss functions, and show that the resulting game has a unique symmetric equilibrium. We present an algorithm for computing this equilibrium, and show through extensive experiments that equilibrium models are significantly more robust than conventional regularized linear regression.",
        "bibtex": "@InProceedings{pmlr-v80-tong18a,\n  title = \t {Adversarial Regression with Multiple Learners},\n  author =       {Tong, Liang and Yu, Sixie and Alfeld, Scott and yevgeniy vorobeychik},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4946--4954},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tong18a/tong18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tong18a.html},\n  abstract = \t {Despite the considerable success enjoyed by machine learning techniques in practice, numerous studies demonstrated that many approaches are vulnerable to attacks. An important class of such attacks involves adversaries changing features at test time to cause incorrect predictions. Previous investigations of this problem pit a single learner against an adversary. However, in many situations an adversary\u2019s decision is aimed at a collection of learners, rather than specifically targeted at each independently. We study the problem of adversarial linear regression with multiple learners. We approximate the resulting game by exhibiting an upper bound on learner loss functions, and show that the resulting game has a unique symmetric equilibrium. We present an algorithm for computing this equilibrium, and show through extensive experiments that equilibrium models are significantly more robust than conventional regularized linear regression.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tong18a/tong18a.pdf",
        "supp": "",
        "pdf_size": 792883,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11851981725937878010&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Department of EECS, Vanderbilt University; Department of EECS, Vanderbilt University; Computer Science Department, Amherst College; Department of EECS, Vanderbilt University",
        "aff_domain": "gmail.com; ; ;gmail.com",
        "email": "gmail.com; ; ;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/tong18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Vanderbilt University;Amherst College",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Computer Science Department",
        "aff_unique_url": "https://www.vanderbilt.edu;https://www.amherst.edu",
        "aff_unique_abbr": "Vanderbilt;Amherst",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Adversarial Risk and the Dangers of Evaluating Against Weak Attacks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2138",
        "id": "2138",
        "author_site": "Jonathan Uesato, Brendan O'Donoghue, Pushmeet Kohli, A\u00e4ron van den Oord",
        "author": "Jonathan Uesato; Brendan O\u2019Donoghue; Pushmeet Kohli; Aaron Oord",
        "abstract": "This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. We motivate",
        "bibtex": "@InProceedings{pmlr-v80-uesato18a,\n  title = \t {Adversarial Risk and the Dangers of Evaluating Against Weak Attacks},\n  author =       {Uesato, Jonathan and O'Donoghue, Brendan and Kohli, Pushmeet and van den Oord, Aaron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5025--5034},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/uesato18a/uesato18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/uesato18a.html},\n  abstract = \t {This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. We motivate",
        "pdf": "http://proceedings.mlr.press/v80/uesato18a/uesato18a.pdf",
        "supp": "",
        "pdf_size": 307147,
        "gs_citation": 706,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11987569658631907048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "DeepMind; DeepMind; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ",
        "email": "google.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/uesato18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Adversarial Time-to-Event Modeling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2332",
        "id": "2332",
        "author_site": "Paidamoyo Chapfuwa, Chenyang Tao, Chunyuan Li, Courtney Page, Benjamin Goldstein, Lawrence Carin, Ricardo Henao",
        "author": "Paidamoyo Chapfuwa; Chenyang Tao; Chunyuan Li; Courtney Page; Benjamin Goldstein; Lawrence Carin Duke; Ricardo Henao",
        "abstract": "Modern health data science applications leverage abundant molecular and electronic health data, providing opportunities for machine learning to build statistical models to support clinical practice. Time-to-event analysis, also called survival analysis, stands as one of the most representative examples of such statistical models. We present a deep-network-based approach that leverages adversarial learning to address a key challenge in modern time-to-event modeling: nonparametric estimation of event-time distributions. We also introduce a principled cost function to exploit information from censored events (events that occur subsequent to the observation window). Unlike most time-to-event models, we focus on the estimation of time-to-event distributions, rather than time ordering. We validate our model on both benchmark and real datasets, demonstrating that the proposed formulation yields significant performance gains relative to a parametric alternative, which we also propose.",
        "bibtex": "@InProceedings{pmlr-v80-chapfuwa18a,\n  title = \t {Adversarial Time-to-Event Modeling},\n  author =       {Chapfuwa, Paidamoyo and Tao, Chenyang and Li, Chunyuan and Page, Courtney and Goldstein, Benjamin and Duke, Lawrence Carin and Henao, Ricardo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {735--744},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chapfuwa18a/chapfuwa18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chapfuwa18a.html},\n  abstract = \t {Modern health data science applications leverage abundant molecular and electronic health data, providing opportunities for machine learning to build statistical models to support clinical practice. Time-to-event analysis, also called survival analysis, stands as one of the most representative examples of such statistical models. We present a deep-network-based approach that leverages adversarial learning to address a key challenge in modern time-to-event modeling: nonparametric estimation of event-time distributions. We also introduce a principled cost function to exploit information from censored events (events that occur subsequent to the observation window). Unlike most time-to-event models, we focus on the estimation of time-to-event distributions, rather than time ordering. We validate our model on both benchmark and real datasets, demonstrating that the proposed formulation yields significant performance gains relative to a parametric alternative, which we also propose.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chapfuwa18a/chapfuwa18a.pdf",
        "supp": "",
        "pdf_size": 674229,
        "gs_citation": 130,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2862325105848484148&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Duke University; Duke University; Duke University; Duke University; Duke University; Duke University; Duke University",
        "aff_domain": "duke.edu; ; ; ; ; ; ",
        "email": "duke.edu; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/chapfuwa18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Adversarially Regularized Autoencoders",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2267",
        "id": "2267",
        "author_site": "Jake Zhao, Yoon Kim, Kelly Zhang, Alexander Rush, Yann LeCun",
        "author": "Junbo Zhao; Yoon Kim; Kelly Zhang; Alexander Rush; Yann LeCun",
        "abstract": "Deep latent variable models, trained using variational autoencoders or generative adversarial networks, are now a key technique for representation learning of continuous structures. However, applying similar methods to discrete structures, such as text sequences or discretized images, has proven to be more challenging. In this work, we propose a more flexible method for training deep latent variable models of discrete structures. Our approach is based on the recently proposed Wasserstein Autoencoder (WAE) which formalizes adversarial autoencoders as an optimal transport problem. We first extend this framework to model discrete sequences, and then further explore different learned priors targeting a controllable representation. Unlike many other latent variable generative models for text, this adversarially regularized autoencoder (ARAE) allows us to generate fluent textual outputs as well as perform manipulations in the latent space to induce change in the output space. Finally we show that the latent representation can be trained to perform unaligned textual style transfer, giving improvements both in automatic measures and human evaluation.",
        "bibtex": "@InProceedings{pmlr-v80-zhao18b,\n  title = \t {Adversarially Regularized Autoencoders},\n  author =       {Zhao, Junbo and Kim, Yoon and Zhang, Kelly and Rush, Alexander and LeCun, Yann},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5902--5911},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhao18b/zhao18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhao18b.html},\n  abstract = \t {Deep latent variable models, trained using variational autoencoders or generative adversarial networks, are now a key technique for representation learning of continuous structures. However, applying similar methods to discrete structures, such as text sequences or discretized images, has proven to be more challenging. In this work, we propose a more flexible method for training deep latent variable models of discrete structures. Our approach is based on the recently proposed Wasserstein Autoencoder (WAE) which formalizes adversarial autoencoders as an optimal transport problem. We first extend this framework to model discrete sequences, and then further explore different learned priors targeting a controllable representation. Unlike many other latent variable generative models for text, this adversarially regularized autoencoder (ARAE) allows us to generate fluent textual outputs as well as perform manipulations in the latent space to induce change in the output space. Finally we show that the latent representation can be trained to perform unaligned textual style transfer, giving improvements both in automatic measures and human evaluation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhao18b/zhao18b.pdf",
        "supp": "",
        "pdf_size": 507083,
        "gs_citation": 391,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5024716526871945774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, New York University + Facebook AI Research; School of Engineering and Applied Sciences, Harvard University; Department of Computer Science, New York University; School of Engineering and Applied Sciences, Harvard University; Department of Computer Science, New York University + Facebook AI Research",
        "aff_domain": "cs.nyu.edu; ; ; ; ",
        "email": "cs.nyu.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/zhao18b.html",
        "aff_unique_index": "0+1;2;0;2;0+1",
        "aff_unique_norm": "New York University;Meta;Harvard University",
        "aff_unique_dep": "Department of Computer Science;Facebook AI Research;School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.nyu.edu;https://research.facebook.com;https://www.harvard.edu",
        "aff_unique_abbr": "NYU;FAIR;Harvard",
        "aff_campus_unique_index": "0;2;0;2;0",
        "aff_campus_unique": "New York;;Cambridge",
        "aff_country_unique_index": "0+0;0;0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Alternating Randomized Block Coordinate Descent",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2445",
        "id": "2445",
        "author_site": "Jelena Diakonikolas, Orecchia Lorenzo",
        "author": "Jelena Diakonikolas; Lorenzo Orecchia",
        "abstract": "Block-coordinate descent algorithms and alternating minimization methods are fundamental optimization algorithms and an important primitive in large-scale optimization and machine learning. While various block-coordinate-descent-type methods have been studied extensively, only alternating minimization \u2013 which applies to the setting of only two blocks \u2013 is known to have convergence time that scales independently of the least smooth block. A natural question is then: is the setting of two blocks special? We show that the answer is \u201cno\u201d as long as the least smooth block can be optimized exactly \u2013 an assumption that is also needed in the setting of alternating minimization. We do so by introducing a novel algorithm AR-BCD, whose convergence time scales independently of the least smooth (possibly non-smooth) block. The basic algorithm generalizes both alternating minimization and randomized block coordinate (gradient) descent, and we also provide its accelerated version \u2013 AAR-BCD.",
        "bibtex": "@InProceedings{pmlr-v80-diakonikolas18a,\n  title = \t {Alternating Randomized Block Coordinate Descent},\n  author =       {Diakonikolas, Jelena and Orecchia, Lorenzo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1224--1232},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/diakonikolas18a/diakonikolas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/diakonikolas18a.html},\n  abstract = \t {Block-coordinate descent algorithms and alternating minimization methods are fundamental optimization algorithms and an important primitive in large-scale optimization and machine learning. While various block-coordinate-descent-type methods have been studied extensively, only alternating minimization \u2013 which applies to the setting of only two blocks \u2013 is known to have convergence time that scales independently of the least smooth block. A natural question is then: is the setting of two blocks special? We show that the answer is \u201cno\u201d as long as the least smooth block can be optimized exactly \u2013 an assumption that is also needed in the setting of alternating minimization. We do so by introducing a novel algorithm AR-BCD, whose convergence time scales independently of the least smooth (possibly non-smooth) block. The basic algorithm generalizes both alternating minimization and randomized block coordinate (gradient) descent, and we also provide its accelerated version \u2013 AAR-BCD.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/diakonikolas18a/diakonikolas18a.pdf",
        "supp": "",
        "pdf_size": 604579,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14414016285162838230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Boston University, Boston, MA, USA; Department of Computer Science, Boston University, Boston, MA, USA",
        "aff_domain": "bu.edu;bu.edu",
        "email": "bu.edu;bu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/diakonikolas18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1885",
        "id": "1885",
        "author_site": "Li Shen, Peng Sun, Yitong Wang, Wei Liu, Tong Zhang",
        "author": "Li Shen; Peng Sun; Yitong Wang; Wei Liu; Tong Zhang",
        "abstract": "We propose a novel algorithmic framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-gradient (VMOR-HPE) method with a global convergence guarantee for the maximal monotone operator inclusion problem. Its iteration complexities and local linear convergence rate are provided, which theoretically demonstrate that a large over-relaxed step-size contributes to accelerating the proposed VMOR-HPE as a byproduct. Specifically, we find that a large class of primal and primal-dual operator splitting algorithms are all special cases of VMOR-HPE. Hence, the proposed framework offers a new insight into these operator splitting algorithms. In addition, we apply VMOR-HPE to the Karush-Kuhn-Tucker (KKT) generalized equation of linear equality constrained multi-block composite convex optimization, yielding a new algorithm, namely nonsymmetric Proximal Alternating Direction Method of Multipliers with a preconditioned Extra-gradient step in which the preconditioned metric is generated by a blockwise Barzilai-Borwein line search technique (PADMM-EBB). We also establish iteration complexities of PADMM-EBB in terms of the KKT residual. Finally, we apply PADMM-EBB to handle the nonnegative dual graph regularized low-rank representation problem. Promising results on synthetic and real datasets corroborate the efficacy of PADMM-EBB.",
        "bibtex": "@InProceedings{pmlr-v80-shen18b,\n  title = \t {An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-Gradient Method},\n  author =       {Shen, Li and Sun, Peng and Wang, Yitong and Liu, Wei and Zhang, Tong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4634--4643},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/shen18b/shen18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/shen18b.html},\n  abstract = \t {We propose a novel algorithmic framework of Variable Metric Over-Relaxed Hybrid Proximal Extra-gradient (VMOR-HPE) method with a global convergence guarantee for the maximal monotone operator inclusion problem. Its iteration complexities and local linear convergence rate are provided, which theoretically demonstrate that a large over-relaxed step-size contributes to accelerating the proposed VMOR-HPE as a byproduct. Specifically, we find that a large class of primal and primal-dual operator splitting algorithms are all special cases of VMOR-HPE. Hence, the proposed framework offers a new insight into these operator splitting algorithms. In addition, we apply VMOR-HPE to the Karush-Kuhn-Tucker (KKT) generalized equation of linear equality constrained multi-block composite convex optimization, yielding a new algorithm, namely nonsymmetric Proximal Alternating Direction Method of Multipliers with a preconditioned Extra-gradient step in which the preconditioned metric is generated by a blockwise Barzilai-Borwein line search technique (PADMM-EBB). We also establish iteration complexities of PADMM-EBB in terms of the KKT residual. Finally, we apply PADMM-EBB to handle the nonnegative dual graph regularized low-rank representation problem. Promising results on synthetic and real datasets corroborate the efficacy of PADMM-EBB.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/shen18b/shen18b.pdf",
        "supp": "",
        "pdf_size": 636289,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=765942142512588482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China",
        "aff_domain": "gmail.com;gmail.com;tencent.com;columbia.edu;tongzhang-ml.org",
        "email": "gmail.com;gmail.com;tencent.com;columbia.edu;tongzhang-ml.org",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/shen18b.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "AI Lab",
        "aff_unique_url": "https://ai.tencent.com",
        "aff_unique_abbr": "Tencent AI Lab",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "An Alternative View: When Does SGD Escape Local Minima?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1941",
        "id": "1941",
        "author_site": "Bobby Kleinberg, Yuanzhi Li, Yang Yuan",
        "author": "Bobby Kleinberg; Yuanzhi Li; Yang Yuan",
        "abstract": "Stochastic gradient descent (SGD) is widely used in machine learning. Although being commonly viewed as a fast but not accurate version of gradient descent (GD), it always finds better solutions than GD for modern neural networks. In order to understand this phenomenon, we take an alternative view that SGD is working on the convolved (thus smoothed) version of the loss function. We show that, even if the function $f$ has many bad local minima or saddle points, as long as for every point $x$, the weighted average of the gradients of its neighborhoods is one point convex with respect to the desired solution $x^*$, SGD will get close to, and then stay around $x^*$ with constant probability. Our result identifies a set of functions that SGD provably works, which is much larger than the set of convex functions. Empirically, we observe that the loss surface of neural networks enjoys nice one point convexity properties locally, therefore our theorem helps explain why SGD works so well for neural networks.",
        "bibtex": "@InProceedings{pmlr-v80-kleinberg18a,\n  title = \t {An Alternative View: When Does {SGD} Escape Local Minima?},\n  author =       {Kleinberg, Bobby and Li, Yuanzhi and Yuan, Yang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2698--2707},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kleinberg18a/kleinberg18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kleinberg18a.html},\n  abstract = \t {Stochastic gradient descent (SGD) is widely used in machine learning. Although being commonly viewed as a fast but not accurate version of gradient descent (GD), it always finds better solutions than GD for modern neural networks. In order to understand this phenomenon, we take an alternative view that SGD is working on the convolved (thus smoothed) version of the loss function. We show that, even if the function $f$ has many bad local minima or saddle points, as long as for every point $x$, the weighted average of the gradients of its neighborhoods is one point convex with respect to the desired solution $x^*$, SGD will get close to, and then stay around $x^*$ with constant probability. Our result identifies a set of functions that SGD provably works, which is much larger than the set of convex functions. Empirically, we observe that the loss surface of neural networks enjoys nice one point convexity properties locally, therefore our theorem helps explain why SGD works so well for neural networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kleinberg18a/kleinberg18a.pdf",
        "supp": "",
        "pdf_size": 2048487,
        "gs_citation": 404,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11184559678618975092&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Cornell University; Department of Computer Science, Princeton University; Department of Computer Science, Cornell University",
        "aff_domain": "cs.cornell.edu;princeton.edu;cs.cornell.edu",
        "email": "cs.cornell.edu;princeton.edu;cs.cornell.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kleinberg18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Cornell University;Princeton University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.cornell.edu;https://www.princeton.edu",
        "aff_unique_abbr": "Cornell;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "An Efficient Semismooth Newton based Algorithm for Convex Clustering",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2003",
        "id": "2003",
        "author_site": "Yancheng Yuan, Defeng Sun, Kim-Chuan Toh",
        "author": "Yancheng Yuan; Defeng Sun; Kim-Chuan Toh",
        "abstract": "Clustering is a fundamental problem in unsupervised learning. Popular methods like K-means, may suffer from instability as they are prone to get stuck in its local minima. Recently, the sumof-norms (SON) model (also known as clustering path), which is a convex relaxation of hierarchical clustering model, has been proposed in (Lindsten et al., 2011) and (Hocking et al., 2011). Although numerical algorithms like alternating direction method of multipliers (ADMM) and alternating minimization algorithm (AMA) have been proposed to solve convex clustering model (Chi & Lange, 2015), it is known to be very challenging to solve large-scale problems. In this paper, we propose a semismooth Newton based augmented Lagrangian method for large-scale convex clustering problems. Extensive numerical experiments on both simulated and real data demonstrate that our algorithm is highly efficient and robust for solving large-scale problems. Moreover, the numerical results also show the superior performance and scalability of our algorithm comparing to existing first-order methods.",
        "bibtex": "@InProceedings{pmlr-v80-yuan18a,\n  title = \t {An Efficient Semismooth {N}ewton based Algorithm for Convex Clustering},\n  author =       {Yuan, Yancheng and Sun, Defeng and Toh, Kim-Chuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5718--5726},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yuan18a/yuan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yuan18a.html},\n  abstract = \t {Clustering is a fundamental problem in unsupervised learning. Popular methods like K-means, may suffer from instability as they are prone to get stuck in its local minima. Recently, the sumof-norms (SON) model (also known as clustering path), which is a convex relaxation of hierarchical clustering model, has been proposed in (Lindsten et al., 2011) and (Hocking et al., 2011). Although numerical algorithms like alternating direction method of multipliers (ADMM) and alternating minimization algorithm (AMA) have been proposed to solve convex clustering model (Chi & Lange, 2015), it is known to be very challenging to solve large-scale problems. In this paper, we propose a semismooth Newton based augmented Lagrangian method for large-scale convex clustering problems. Extensive numerical experiments on both simulated and real data demonstrate that our algorithm is highly efficient and robust for solving large-scale problems. Moreover, the numerical results also show the superior performance and scalability of our algorithm comparing to existing first-order methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yuan18a/yuan18a.pdf",
        "supp": "",
        "pdf_size": 614053,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12197157380889470115&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Mathematics, National University of Singapore; Department of Applied Mathematics, Hong Kong Polytechnic University; Department of Mathematics, National University of Singapore",
        "aff_domain": "u.nus.edu; ; ",
        "email": "u.nus.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/yuan18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "National University of Singapore;Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Mathematics;Department of Applied Mathematics",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.polyu.edu.hk",
        "aff_unique_abbr": "NUS;PolyU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "title": "An Efficient, Generalized Bellman Update For Cooperative Inverse Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1969",
        "id": "1969",
        "author_site": "Dhruv Malik, Malayandi Palaniappan, Jaime Fisac, Dylan Hadfield-Menell, Stuart Russell, Anca Dragan",
        "author": "Dhruv Malik; Malayandi Palaniappan; Jaime Fisac; Dylan Hadfield-Menell; Stuart Russell; Anca Dragan",
        "abstract": "Our goal is for AI systems to correctly identify and act according to their human user\u2019s objectives. Cooperative Inverse Reinforcement Learning (CIRL) formalizes this value alignment problem as a two-player game between a human and robot, in which only the human knows the parameters of the reward function: the robot needs to learn them as the interaction unfolds. Previous work showed that CIRL can be solved as a POMDP, but with an action space size exponential in the size of the reward parameter space. In this work, we exploit a specific property of CIRL: the human is a full information agent. This enables us to derive an optimality-preserving modification to the standard Bellman update, which reduces the complexity of the problem by an exponential factor. Additionally, we show that our modified Bellman update allows us to relax CIRL\u2019s assumption of human rationality. We apply this update to a variety of POMDP solvers, including exact methods, point-based methods, and Monte Carlo Tree Search methods. We find that it enables us to scale CIRL to non-trivial problems, with larger reward parameter spaces, and larger action spaces for both robot and human. In solutions to these larger problems, the human exhibits pedagogical (teaching) behavior, while the robot interprets it as such and attains higher value for the human.",
        "bibtex": "@InProceedings{pmlr-v80-malik18a,\n  title = \t {An Efficient, Generalized {B}ellman Update For Cooperative Inverse Reinforcement Learning},\n  author =       {Malik, Dhruv and Palaniappan, Malayandi and Fisac, Jaime and Hadfield-Menell, Dylan and Russell, Stuart and Dragan, Anca},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3394--3402},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/malik18a/malik18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/malik18a.html},\n  abstract = \t {Our goal is for AI systems to correctly identify and act according to their human user\u2019s objectives. Cooperative Inverse Reinforcement Learning (CIRL) formalizes this value alignment problem as a two-player game between a human and robot, in which only the human knows the parameters of the reward function: the robot needs to learn them as the interaction unfolds. Previous work showed that CIRL can be solved as a POMDP, but with an action space size exponential in the size of the reward parameter space. In this work, we exploit a specific property of CIRL: the human is a full information agent. This enables us to derive an optimality-preserving modification to the standard Bellman update, which reduces the complexity of the problem by an exponential factor. Additionally, we show that our modified Bellman update allows us to relax CIRL\u2019s assumption of human rationality. We apply this update to a variety of POMDP solvers, including exact methods, point-based methods, and Monte Carlo Tree Search methods. We find that it enables us to scale CIRL to non-trivial problems, with larger reward parameter spaces, and larger action spaces for both robot and human. In solutions to these larger problems, the human exhibits pedagogical (teaching) behavior, while the robot interprets it as such and attains higher value for the human.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/malik18a/malik18a.pdf",
        "supp": "",
        "pdf_size": 624117,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7171111478658500342&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu; ; ; ; ",
        "email": "berkeley.edu;berkeley.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/malik18a.html",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "An Estimation and Analysis Framework for the Rasch Model",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1977",
        "id": "1977",
        "author_site": "Andrew Lan, Mung Chiang, Christoph Studer",
        "author": "Andrew Lan; Mung Chiang; Christoph Studer",
        "abstract": "The Rasch model is widely used for item response analysis in applications ranging from recommender systems to psychology, education, and finance. While a number of estimators have been proposed for the Rasch model over the last decades, the associated analytical performance guarantees are mostly asymptotic. This paper provides a framework that relies on a novel linear minimum mean-squared error (L-MMSE) estimator which enables an exact, nonasymptotic, and closed-form analysis of the parameter estimation error under the Rasch model. The proposed framework provides guidelines on the number of items and responses required to attain low estimation errors in tests or surveys. We furthermore demonstrate its efficacy on a number of real-world collaborative filtering datasets, which reveals that the proposed L-MMSE estimator performs on par with state-of-the-art nonlinear estimators in terms of predictive performance.",
        "bibtex": "@InProceedings{pmlr-v80-lan18a,\n  title = \t {An Estimation and Analysis Framework for the {R}asch Model},\n  author =       {Lan, Andrew and Chiang, Mung and Studer, Christoph},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2883--2891},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lan18a/lan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lan18a.html},\n  abstract = \t {The Rasch model is widely used for item response analysis in applications ranging from recommender systems to psychology, education, and finance. While a number of estimators have been proposed for the Rasch model over the last decades, the associated analytical performance guarantees are mostly asymptotic. This paper provides a framework that relies on a novel linear minimum mean-squared error (L-MMSE) estimator which enables an exact, nonasymptotic, and closed-form analysis of the parameter estimation error under the Rasch model. The proposed framework provides guidelines on the number of items and responses required to attain low estimation errors in tests or surveys. We furthermore demonstrate its efficacy on a number of real-world collaborative filtering datasets, which reveals that the proposed L-MMSE estimator performs on par with state-of-the-art nonlinear estimators in terms of predictive performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lan18a/lan18a.pdf",
        "supp": "",
        "pdf_size": 611549,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4332114051574172661&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Electrical Engineering, Princeton University; Purdue University; School of Electrical and Computer Engineering, Cornell University",
        "aff_domain": "princeton.edu; ; ",
        "email": "princeton.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lan18a.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Purdue University;Cornell University",
        "aff_unique_dep": "Department of Electrical Engineering;;School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.princeton.edu;https://www.purdue.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Princeton;Purdue;Cornell",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Ithaca",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "An Inference-Based Policy Gradient Method for Learning Options",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2432",
        "id": "2432",
        "author_site": "Matthew Smith, Herke van Hoof, Joelle Pineau",
        "author": "Matthew Smith; Herke Hoof; Joelle Pineau",
        "abstract": "In the pursuit of increasingly intelligent learning systems, abstraction plays a vital role in enabling sophisticated decisions to be made in complex environments. The options framework provides formalism for such abstraction over sequences of decisions. However most models require that options be given a priori, presumably specified by hand, which is neither efficient, nor scalable. Indeed, it is preferable to learn options directly from interaction with the environment. Despite several efforts, this remains a difficult problem. In this work we develop a novel policy gradient method for the automatic learning of policies with options. This algorithm uses inference methods to simultaneously improve all of the options available to an agent, and thus can be employed in an off-policy manner, without observing option labels. The differentiable inference procedure employed yields options that can be easily interpreted. Empirical results confirm these attributes, and indicate that our algorithm has an improved sample efficiency relative to state-of-the-art in learning options end-to-end.",
        "bibtex": "@InProceedings{pmlr-v80-smith18a,\n  title = \t {An Inference-Based Policy Gradient Method for Learning Options},\n  author =       {Smith, Matthew and van Hoof, Herke and Pineau, Joelle},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4703--4712},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/smith18a/smith18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/smith18a.html},\n  abstract = \t {In the pursuit of increasingly intelligent learning systems, abstraction plays a vital role in enabling sophisticated decisions to be made in complex environments. The options framework provides formalism for such abstraction over sequences of decisions. However most models require that options be given a priori, presumably specified by hand, which is neither efficient, nor scalable. Indeed, it is preferable to learn options directly from interaction with the environment. Despite several efforts, this remains a difficult problem. In this work we develop a novel policy gradient method for the automatic learning of policies with options. This algorithm uses inference methods to simultaneously improve all of the options available to an agent, and thus can be employed in an off-policy manner, without observing option labels. The differentiable inference procedure employed yields options that can be easily interpreted. Empirical results confirm these attributes, and indicate that our algorithm has an improved sample efficiency relative to state-of-the-art in learning options end-to-end.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/smith18a/smith18a.pdf",
        "supp": "",
        "pdf_size": 718150,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8204006548424630686&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, McGill University, Quebec, Canada; Informatics Institute, University of Amsterdam, The Netherlands; Department of Computer Science, McGill University, Quebec, Canada",
        "aff_domain": "mail.mcgill.ca; ;mcgill.ca",
        "email": "mail.mcgill.ca; ;mcgill.ca",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/smith18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "McGill University;University of Amsterdam",
        "aff_unique_dep": "Department of Computer Science;Informatics Institute",
        "aff_unique_url": "https://www.mcgill.ca;https://www.uva.nl",
        "aff_unique_abbr": "McGill;UvA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Quebec;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;Netherlands"
    },
    {
        "title": "An Iterative, Sketching-based Framework for Ridge Regression",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1895",
        "id": "1895",
        "author_site": "Agniva Chowdhury, Jiasen Yang, Petros Drineas",
        "author": "Agniva Chowdhury; Jiasen Yang; Petros Drineas",
        "abstract": "Ridge regression is a variant of regularized least squares regression that is particularly suitable in settings where the number of predictor variables greatly exceeds the number of observations. We present a simple, iterative, sketching-based algorithm for ridge regression that guarantees high-quality approximations to the optimal solution vector. Our analysis builds upon two simple structural results that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized linear algebra. An important contribution of our work is the analysis of the behavior of subsampled ridge regression problems when the ridge leverage scores are used: we prove that accurate approximations can be achieved by a sample whose size depends on the degrees of freedom of the ridge-regression problem rather than the dimensions of the design matrix. Our experimental evaluations verify our theoretical results on both real and synthetic data.",
        "bibtex": "@InProceedings{pmlr-v80-chowdhury18a,\n  title = \t {An Iterative, Sketching-based Framework for Ridge Regression},\n  author =       {Chowdhury, Agniva and Yang, Jiasen and Drineas, Petros},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {989--998},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chowdhury18a/chowdhury18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chowdhury18a.html},\n  abstract = \t {Ridge regression is a variant of regularized least squares regression that is particularly suitable in settings where the number of predictor variables greatly exceeds the number of observations. We present a simple, iterative, sketching-based algorithm for ridge regression that guarantees high-quality approximations to the optimal solution vector. Our analysis builds upon two simple structural results that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized linear algebra. An important contribution of our work is the analysis of the behavior of subsampled ridge regression problems when the ridge leverage scores are used: we prove that accurate approximations can be achieved by a sample whose size depends on the degrees of freedom of the ridge-regression problem rather than the dimensions of the design matrix. Our experimental evaluations verify our theoretical results on both real and synthetic data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chowdhury18a/chowdhury18a.pdf",
        "supp": "",
        "pdf_size": 2136886,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6697221761583437964&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, Purdue University; Department of Statistics, Purdue University; Department of Computer Science, Purdue University",
        "aff_domain": "purdue.edu; ; ",
        "email": "purdue.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chowdhury18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1992",
        "id": "1992",
        "author_site": "Qianxiao Li, IHPC Shuji Hao",
        "author": "Qianxiao Li; Shuji Hao",
        "abstract": "Deep learning is formulated as a discrete-time optimal control problem. This allows one to characterize necessary conditions for optimality and develop training algorithms that do not rely on gradients with respect to the trainable parameters. In particular, we introduce the discrete-time method of successive approximations (MSA), which is based on the Pontryagin\u2019s maximum principle, for training neural networks. A rigorous error estimate for the discrete MSA is obtained, which sheds light on its dynamics and the means to stabilize the algorithm. The developed methods are applied to train, in a rather principled way, neural networks with weights that are constrained to take values in a discrete set. We obtain competitive performance and interestingly, very sparse weights in the case of ternary networks, which may be useful in model deployment in low-memory devices.",
        "bibtex": "@InProceedings{pmlr-v80-li18b,\n  title = \t {An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks},\n  author =       {Li, Qianxiao and Hao, Shuji},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2985--2994},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18b/li18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18b.html},\n  abstract = \t {Deep learning is formulated as a discrete-time optimal control problem. This allows one to characterize necessary conditions for optimality and develop training algorithms that do not rely on gradients with respect to the trainable parameters. In particular, we introduce the discrete-time method of successive approximations (MSA), which is based on the Pontryagin\u2019s maximum principle, for training neural networks. A rigorous error estimate for the discrete MSA is obtained, which sheds light on its dynamics and the means to stabilize the algorithm. The developed methods are applied to train, in a rather principled way, neural networks with weights that are constrained to take values in a discrete set. We obtain competitive performance and interestingly, very sparse weights in the case of ternary networks, which may be useful in model deployment in low-memory devices.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18b/li18b.pdf",
        "supp": "",
        "pdf_size": 1192627,
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6252296046431903031&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Institute of High Performance Computing, Singapore; Institute of High Performance Computing, Singapore",
        "aff_domain": "ihpc.a-star.edu.sg; ",
        "email": "ihpc.a-star.edu.sg; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/li18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Institute of High Performance Computing",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ihpc.a-star.edu.sg",
        "aff_unique_abbr": "IHPC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "title": "Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2211",
        "id": "2211",
        "author_site": "Hideaki Imamura, Issei Sato, Masashi Sugiyama",
        "author": "Hideaki Imamura; Issei Sato; Masashi Sugiyama",
        "abstract": "While crowdsourcing has become an important means to label data, there is great interest in estimating the ground truth from unreliable labels produced by crowdworkers. The Dawid and Skene (DS) model is one of the most well-known models in the study of crowdsourcing. Despite its practical popularity, theoretical error analysis for the DS model has been conducted only under restrictive assumptions on class priors, confusion matrices, or the number of labels each worker provides. In this paper, we derive a minimax error rate under more practical setting for a broader class of crowdsourcing models including the DS model as a special case. We further propose the worker clustering model, which is more practical than the DS model under real crowdsourcing settings. The wide applicability of our theoretical analysis allows us to immediately investigate the behavior of this proposed model, which can not be analyzed by existing studies. Experimental results showed that there is a strong similarity between the lower bound of the minimax error rate derived by our theoretical analysis and the empirical error of the estimated value.",
        "bibtex": "@InProceedings{pmlr-v80-imamura18a,\n  title = \t {Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model},\n  author =       {Imamura, Hideaki and Sato, Issei and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2147--2156},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/imamura18a/imamura18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/imamura18a.html},\n  abstract = \t {While crowdsourcing has become an important means to label data, there is great interest in estimating the ground truth from unreliable labels produced by crowdworkers. The Dawid and Skene (DS) model is one of the most well-known models in the study of crowdsourcing. Despite its practical popularity, theoretical error analysis for the DS model has been conducted only under restrictive assumptions on class priors, confusion matrices, or the number of labels each worker provides. In this paper, we derive a minimax error rate under more practical setting for a broader class of crowdsourcing models including the DS model as a special case. We further propose the worker clustering model, which is more practical than the DS model under real crowdsourcing settings. The wide applicability of our theoretical analysis allows us to immediately investigate the behavior of this proposed model, which can not be analyzed by existing studies. Experimental results showed that there is a strong similarity between the lower bound of the minimax error rate derived by our theoretical analysis and the empirical error of the estimated value.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/imamura18a/imamura18a.pdf",
        "supp": "",
        "pdf_size": 6643682,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7703940495110454435&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Tokyo, Tokyo, Japan+RIKEN, Tokyo, Japan; The University of Tokyo, Tokyo, Japan+RIKEN, Tokyo, Japan; The University of Tokyo, Tokyo, Japan+RIKEN, Tokyo, Japan",
        "aff_domain": "ms.k.u-tokyo.ac.jp; ; ",
        "email": "ms.k.u-tokyo.ac.jp; ; ",
        "github": "https://github.com/HideakiImamura/MinimaxErrorRate",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/imamura18a.html",
        "aff_unique_index": "0+1;0+1;0+1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Analyzing Uncertainty in Neural Machine Translation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2292",
        "id": "2292",
        "author_site": "Myle Ott, Michael Auli, David Grangier, Marc'Aurelio Ranzato",
        "author": "Myle Ott; Michael Auli; David Grangier; Marc\u2019Aurelio Ranzato",
        "abstract": "Machine translation is a popular test bed for research in neural sequence-to-sequence models but despite much recent research, there is still a lack of understanding of these models. Practitioners report performance degradation with large beams, the under-estimation of rare words and a lack of diversity in the final translations. Our study relates some of these issues to the inherent uncertainty of the task, due to the existence of multiple valid translations for a single source sentence, and to the extrinsic uncertainty caused by noisy training data. We propose tools and metrics to assess how uncertainty in the data is captured by the model distribution and how it affects search strategies that generate translations. Our results show that search works remarkably well but that the models tend to spread too much probability mass over the hypothesis space. Next, we propose tools to assess model calibration and show how to easily fix some shortcomings of current models. We release both code and multiple human reference translations for two popular benchmarks.",
        "bibtex": "@InProceedings{pmlr-v80-ott18a,\n  title = \t {Analyzing Uncertainty in Neural Machine Translation},\n  author =       {Ott, Myle and Auli, Michael and Grangier, David and Ranzato, Marc'Aurelio},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3956--3965},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ott18a/ott18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ott18a.html},\n  abstract = \t {Machine translation is a popular test bed for research in neural sequence-to-sequence models but despite much recent research, there is still a lack of understanding of these models. Practitioners report performance degradation with large beams, the under-estimation of rare words and a lack of diversity in the final translations. Our study relates some of these issues to the inherent uncertainty of the task, due to the existence of multiple valid translations for a single source sentence, and to the extrinsic uncertainty caused by noisy training data. We propose tools and metrics to assess how uncertainty in the data is captured by the model distribution and how it affects search strategies that generate translations. Our results show that search works remarkably well but that the models tend to spread too much probability mass over the hypothesis space. Next, we propose tools to assess model calibration and show how to easily fix some shortcomings of current models. We release both code and multiple human reference translations for two popular benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ott18a/ott18a.pdf",
        "supp": "",
        "pdf_size": 1971529,
        "gs_citation": 292,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1522001537063991105&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Facebook AI Research, USA; Facebook AI Research, USA; Facebook AI Research, USA; Facebook AI Research, USA",
        "aff_domain": "fb.com; ; ; ",
        "email": "fb.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ott18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Analyzing the Robustness of Nearest Neighbors to Adversarial Examples",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2076",
        "id": "2076",
        "author_site": "Yizhen Wang, Somesh Jha, Kamalika Chaudhuri",
        "author": "Yizhen Wang; Somesh Jha; Kamalika Chaudhuri",
        "abstract": "Motivated by safety-critical applications, test-time attacks on classifiers via adversarial examples has recently received a great deal of attention. However, there is a general lack of understanding on why adversarial examples arise; whether they originate due to inherent properties of data or due to lack of training samples remains ill-understood. In this work, we introduce a theoretical framework analogous to bias-variance theory for understanding these effects. We use our framework to analyze the robustness of a canonical non-parametric classifier {\u2013} the k-nearest neighbors. Our analysis shows that its robustness properties depend critically on the value of k {\u2013} the classifier may be inherently non-robust for small k, but its robustness approaches that of the Bayes Optimal classifier for fast-growing k. We propose a novel modified 1-nearest neighbor classifier, and guarantee its robustness in the large sample limit. Our experiments suggest that this classifier may have good robustness properties even for reasonable data set sizes.",
        "bibtex": "@InProceedings{pmlr-v80-wang18c,\n  title = \t {Analyzing the Robustness of Nearest Neighbors to Adversarial Examples},\n  author =       {Wang, Yizhen and Jha, Somesh and Chaudhuri, Kamalika},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5133--5142},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18c/wang18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18c.html},\n  abstract = \t {Motivated by safety-critical applications, test-time attacks on classifiers via adversarial examples has recently received a great deal of attention. However, there is a general lack of understanding on why adversarial examples arise; whether they originate due to inherent properties of data or due to lack of training samples remains ill-understood. In this work, we introduce a theoretical framework analogous to bias-variance theory for understanding these effects. We use our framework to analyze the robustness of a canonical non-parametric classifier {\u2013} the k-nearest neighbors. Our analysis shows that its robustness properties depend critically on the value of k {\u2013} the classifier may be inherently non-robust for small k, but its robustness approaches that of the Bayes Optimal classifier for fast-growing k. We propose a novel modified 1-nearest neighbor classifier, and guarantee its robustness in the large sample limit. Our experiments suggest that this classifier may have good robustness properties even for reasonable data set sizes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18c/wang18c.pdf",
        "supp": "",
        "pdf_size": 728161,
        "gs_citation": 177,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15228068536645268692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, San Diego; University of Wisconsin-Madison; University of California, San Diego",
        "aff_domain": "ucsd.edu;cs.wisc.edu;cs.ucsd.edu",
        "email": "ucsd.edu;cs.wisc.edu;cs.ucsd.edu",
        "github": "https://github.com/EricYizhenWang/robust_nn_icml",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wang18c.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, San Diego;University of Wisconsin-Madison",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsd.edu;https://www.wisc.edu",
        "aff_unique_abbr": "UCSD;UW-Madison",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "San Diego;Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Anonymous Walk Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1875",
        "id": "1875",
        "author_site": "Sergey Ivanov, Evgeny Burnaev",
        "author": "Sergey Ivanov; Evgeny Burnaev",
        "abstract": "The task of representing entire graphs has seen a surge of prominent results, mainly due to learning convolutional neural networks (CNNs) on graph-structured data. While CNNs demonstrate state-of-the-art performance in graph classification task, such methods are supervised and therefore steer away from the original problem of network representation in task-agnostic manner. Here, we coherently propose an approach for embedding entire graphs and show that our feature representations with SVM classifier increase classification accuracy of CNN algorithms and traditional graph kernels. For this we describe a recently discovered graph object,",
        "bibtex": "@InProceedings{pmlr-v80-ivanov18a,\n  title = \t {Anonymous Walk Embeddings},\n  author =       {Ivanov, Sergey and Burnaev, Evgeny},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2186--2195},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ivanov18a/ivanov18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ivanov18a.html},\n  abstract = \t {The task of representing entire graphs has seen a surge of prominent results, mainly due to learning convolutional neural networks (CNNs) on graph-structured data. While CNNs demonstrate state-of-the-art performance in graph classification task, such methods are supervised and therefore steer away from the original problem of network representation in task-agnostic manner. Here, we coherently propose an approach for embedding entire graphs and show that our feature representations with SVM classifier increase classification accuracy of CNN algorithms and traditional graph kernels. For this we describe a recently discovered graph object,",
        "pdf": "http://proceedings.mlr.press/v80/ivanov18a/ivanov18a.pdf",
        "supp": "",
        "pdf_size": 558827,
        "gs_citation": 244,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14558299451586877033&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Skolkovo Institute of Science and Technology, Moscow, Russia+Criteo Research, Paris, France; Skolkovo Institute of Science and Technology, Moscow, Russia",
        "aff_domain": "skolkovotech.ru; ",
        "email": "skolkovotech.ru; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/ivanov18a.html",
        "aff_unique_index": "0+1;0",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;Criteo Research",
        "aff_unique_dep": ";Research",
        "aff_unique_url": "https://www.skoltech.ru;https://research.criteo.com",
        "aff_unique_abbr": "Skoltech;",
        "aff_campus_unique_index": "0+1;0",
        "aff_campus_unique": "Moscow;Paris",
        "aff_country_unique_index": "0+1;0",
        "aff_country_unique": "Russian Federation;France"
    },
    {
        "title": "Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2473",
        "id": "2473",
        "author_site": "Shuaiwen Wang, Wenda Zhou, Haihao Lu, Arian Maleki, Vahab Mirrokni",
        "author": "Shuaiwen Wang; Wenda Zhou; Haihao Lu; Arian Maleki; Vahab Mirrokni",
        "abstract": "We study the parameter tuning problem for the penalized regression model. Finding the optimal choice of the regularization parameter is a challenging problem in high-dimensional regimes where both the number of observations n and the number of parameters p are large. We propose two frameworks to obtain a computationally efficient approximation ALO of the leave-one-out cross validation (LOOCV) risk for nonsmooth losses and regularizers. Our two frameworks are based on the primal and dual formulations of the penalized regression model. We prove the equivalence of the two approaches under smoothness conditions. This equivalence enables us to justify the accuracy of both methods under such conditions. We use our approaches to obtain a risk estimate for several standard problems, including generalized LASSO, nuclear norm regularization and support vector machines. We experimentally demonstrate the effectiveness of our results for non-differentiable cases.",
        "bibtex": "@InProceedings{pmlr-v80-wang18m,\n  title = \t {Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions},\n  author =       {Wang, Shuaiwen and Zhou, Wenda and Lu, Haihao and Maleki, Arian and Mirrokni, Vahab},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5228--5237},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18m/wang18m.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18m.html},\n  abstract = \t {We study the parameter tuning problem for the penalized regression model. Finding the optimal choice of the regularization parameter is a challenging problem in high-dimensional regimes where both the number of observations n and the number of parameters p are large. We propose two frameworks to obtain a computationally efficient approximation ALO of the leave-one-out cross validation (LOOCV) risk for nonsmooth losses and regularizers. Our two frameworks are based on the primal and dual formulations of the penalized regression model. We prove the equivalence of the two approaches under smoothness conditions. This equivalence enables us to justify the accuracy of both methods under such conditions. We use our approaches to obtain a risk estimate for several standard problems, including generalized LASSO, nuclear norm regularization and support vector machines. We experimentally demonstrate the effectiveness of our results for non-differentiable cases.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18m/wang18m.pdf",
        "supp": "",
        "pdf_size": 4282873,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7517160253492394187&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, Columbia University, New York, USA; Department of Statistics, Columbia University, New York, USA; Mathematics Department and Operation Research Center, Massachusetts Institute of Technology, Massachusetts, USA; Department of Statistics, Columbia University, New York, USA; Google Research, New York, USA",
        "aff_domain": "columbia.edu;columbia.edu; ;stat.columbia.edu; ",
        "email": "columbia.edu;columbia.edu; ;stat.columbia.edu; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/wang18m.html",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Columbia University;Massachusetts Institute of Technology;Google",
        "aff_unique_dep": "Department of Statistics;Mathematics Department and Operation Research Center;Google Research",
        "aff_unique_url": "https://www.columbia.edu;https://web.mit.edu;https://research.google",
        "aff_unique_abbr": "Columbia;MIT;Google Research",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "New York;Massachusetts",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Approximate message passing for amplitude based optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2297",
        "id": "2297",
        "author_site": "Junjie Ma, Ji Xu, Arian Maleki",
        "author": "Junjie Ma; Ji Xu; Arian Maleki",
        "abstract": "We consider an $\\ell_2$-regularized non-convex optimization problem for recovering signals from their noisy phaseless observations. We design and study the performance of a message passing algorithm that aims to solve this optimization problem. We consider the asymptotic setting $m,n \\rightarrow \\infty$, $m/n \\rightarrow \\delta$ and obtain sharp performance bounds, where $m$ is the number of measurements and $n$ is the signal dimension. We show that for complex signals the algorithm can perform accurate recovery with only $m=\\left ( \\frac{64}{\\pi^2}-4\\right)n\\approx 2.5n$ measurements. Also, we provide sharp analysis on the sensitivity of the algorithm to noise. We highlight the following facts about our message passing algorithm: (i) Adding $\\ell_2$ regularization to the non-convex loss function can be beneficial even in the noiseless setting; (ii) spectral initialization has marginal impact on the performance of the algorithm.",
        "bibtex": "@InProceedings{pmlr-v80-ma18e,\n  title = \t {Approximate message passing for amplitude based optimization},\n  author =       {Ma, Junjie and Xu, Ji and Maleki, Arian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3365--3374},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ma18e/ma18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ma18e.html},\n  abstract = \t {We consider an $\\ell_2$-regularized non-convex optimization problem for recovering signals from their noisy phaseless observations. We design and study the performance of a message passing algorithm that aims to solve this optimization problem. We consider the asymptotic setting $m,n \\rightarrow \\infty$, $m/n \\rightarrow \\delta$ and obtain sharp performance bounds, where $m$ is the number of measurements and $n$ is the signal dimension. We show that for complex signals the algorithm can perform accurate recovery with only $m=\\left ( \\frac{64}{\\pi^2}-4\\right)n\\approx 2.5n$ measurements. Also, we provide sharp analysis on the sensitivity of the algorithm to noise. We highlight the following facts about our message passing algorithm: (i) Adding $\\ell_2$ regularization to the non-convex loss function can be beneficial even in the noiseless setting; (ii) spectral initialization has marginal impact on the performance of the algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ma18e/ma18e.pdf",
        "supp": "",
        "pdf_size": 574764,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1081128494450264932&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics, Columbia University, New York, USA+Department of Computer Science, Columbia University, New York, USA; Department of Statistics, Columbia University, New York, USA+Department of Computer Science, Columbia University, New York, USA; Department of Statistics, Columbia University, New York, USA",
        "aff_domain": "columbia.edu;cs.columbia.edu;stat.columbia.edu",
        "email": "columbia.edu;cs.columbia.edu;stat.columbia.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ma18e.html",
        "aff_unique_index": "0+0;0+0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0+0;0+0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0+0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Approximation Algorithms for Cascading Prediction Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2035",
        "id": "2035",
        "author": "Matthew Streeter",
        "abstract": "We present an approximation algorithm that takes a pool of pre-trained models as input and produces from it a cascaded model with similar accuracy but lower average-case cost. Applied to state-of-the-art ImageNet classification models, this yields up to a 2x reduction in floating point multiplications, and up to a 6x reduction in average-case memory I/O. The auto-generated cascades exhibit intuitive properties, such as using lower-resolution input for easier images and requiring higher prediction confidence when using a computationally cheaper model.",
        "bibtex": "@InProceedings{pmlr-v80-streeter18a,\n  title = \t {Approximation Algorithms for Cascading Prediction Models},\n  author =       {Streeter, Matthew},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4752--4760},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/streeter18a/streeter18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/streeter18a.html},\n  abstract = \t {We present an approximation algorithm that takes a pool of pre-trained models as input and produces from it a cascaded model with similar accuracy but lower average-case cost. Applied to state-of-the-art ImageNet classification models, this yields up to a 2x reduction in floating point multiplications, and up to a 6x reduction in average-case memory I/O. The auto-generated cascades exhibit intuitive properties, such as using lower-resolution input for easier images and requiring higher prediction confidence when using a computationally cheaper model.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/streeter18a/streeter18a.pdf",
        "supp": "",
        "pdf_size": 374031,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12226736627624482370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research",
        "aff_domain": "google.com",
        "email": "google.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/streeter18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Approximation Guarantees for Adaptive Sampling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1882",
        "id": "1882",
        "author_site": "Eric Balkanski, Yaron Singer",
        "author": "Eric Balkanski; Yaron Singer",
        "abstract": "In this paper we analyze an adaptive sampling approach for submodular maximization. Adaptive sampling is a technique that has recently been shown to achieve a constant factor approximation guarantee for submodular maximization under a cardinality constraint with exponentially fewer adaptive rounds than any previously studied constant factor approximation algorithm for this problem. Adaptivity quantifies the number of sequential rounds that an algorithm makes when function evaluations can be executed in parallel and is the parallel running time of an algorithm, up to low order terms. Adaptive sampling achieves its exponential speedup at the expense of approximation. In theory, it is guaranteed to produce a solution that is a 1/3 approximation to the optimum. Nevertheless, experiments show that adaptive sampling techniques achieve far better values in practice. In this paper we provide theoretical justification for this phenomenon. In particular, we show that under very mild conditions of curvature of a function, adaptive sampling techniques achieve an approximation arbitrarily close to 1/2 while maintaining their low adaptivity. Furthermore, we show that the approximation ratio approaches 1 in direct relationship to a homogeneity property of the submodular function. In addition, we conduct experiments on real data sets in which the curvature and homogeneity properties can be easily manipulated and demonstrate the relationship between approximation and curvature, as well as the effectiveness of adaptive sampling in practice.",
        "bibtex": "@InProceedings{pmlr-v80-balkanski18a,\n  title = \t {Approximation Guarantees for Adaptive Sampling},\n  author =       {Balkanski, Eric and Singer, Yaron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {384--393},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balkanski18a/balkanski18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balkanski18a.html},\n  abstract = \t {In this paper we analyze an adaptive sampling approach for submodular maximization. Adaptive sampling is a technique that has recently been shown to achieve a constant factor approximation guarantee for submodular maximization under a cardinality constraint with exponentially fewer adaptive rounds than any previously studied constant factor approximation algorithm for this problem. Adaptivity quantifies the number of sequential rounds that an algorithm makes when function evaluations can be executed in parallel and is the parallel running time of an algorithm, up to low order terms. Adaptive sampling achieves its exponential speedup at the expense of approximation. In theory, it is guaranteed to produce a solution that is a 1/3 approximation to the optimum. Nevertheless, experiments show that adaptive sampling techniques achieve far better values in practice. In this paper we provide theoretical justification for this phenomenon. In particular, we show that under very mild conditions of curvature of a function, adaptive sampling techniques achieve an approximation arbitrarily close to 1/2 while maintaining their low adaptivity. Furthermore, we show that the approximation ratio approaches 1 in direct relationship to a homogeneity property of the submodular function. In addition, we conduct experiments on real data sets in which the curvature and homogeneity properties can be easily manipulated and demonstrate the relationship between approximation and curvature, as well as the effectiveness of adaptive sampling in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balkanski18a/balkanski18a.pdf",
        "supp": "",
        "pdf_size": 1790880,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15957816581874108040&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Harvard University; Harvard University",
        "aff_domain": "g.harvard.edu;seas.harvard.edu",
        "email": "g.harvard.edu;seas.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/balkanski18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Asynchronous Byzantine Machine Learning (the case of SGD)",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1963",
        "id": "1963",
        "author_site": "Georgios Damaskinos, El Mahdi El Mhamdi, Rachid Guerraoui, Rhicheek Patra, Mahsa Taziki",
        "author": "Georgios Damaskinos; El Mahdi El Mhamdi; Rachid Guerraoui; Rhicheek Patra; Mahsa Taziki",
        "abstract": "Asynchronous distributed machine learning solutions have proven very effective so far, but always assuming perfectly functioning workers. In practice, some of the workers can however exhibit Byzantine behavior, caused by hardware failures, software bugs, corrupt data, or even malicious attacks. We introduce Kardam, the first distributed asynchronous stochastic gradient descent (SGD) algorithm that copes with Byzantine workers. Kardam consists of two complementary components: a filtering and a dampening component. The first is scalar-based and ensures resilience against 1/3 Byzantine workers. Essentially, this filter leverages the Lipschitzness of cost functions and acts as a self-stabilizer against Byzantine workers that would attempt to corrupt the progress of SGD. The dampening component bounds the convergence rate by adjusting to stale information through a generic gradient weighting scheme. We prove that Kardam guarantees almost sure convergence in the presence of asynchrony and Byzantine behavior, and we derive its convergence rate. We evaluate Kardam on the CIFAR100 and EMNIST datasets and measure its overhead with respect to non Byzantine-resilient solutions. We empirically show that Kardam does not introduce additional noise to the learning procedure but does induce a slowdown (the cost of Byzantine resilience) that we both theoretically and empirically show to be less than f/n, where f is the number of Byzantine failures tolerated and n the total number of workers. Interestingly, we also empirically observe that the dampening component is interesting in its own right for it enables to build an SGD algorithm that outperforms alternative staleness-aware asynchronous competitors in environments with honest workers.",
        "bibtex": "@InProceedings{pmlr-v80-damaskinos18a,\n  title = \t {Asynchronous {B}yzantine Machine Learning (the case of {SGD})},\n  author =       {Damaskinos, Georgios and El Mhamdi, El Mahdi and Guerraoui, Rachid and Patra, Rhicheek and Taziki, Mahsa},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1145--1154},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/damaskinos18a/damaskinos18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/damaskinos18a.html},\n  abstract = \t {Asynchronous distributed machine learning solutions have proven very effective so far, but always assuming perfectly functioning workers. In practice, some of the workers can however exhibit Byzantine behavior, caused by hardware failures, software bugs, corrupt data, or even malicious attacks. We introduce Kardam, the first distributed asynchronous stochastic gradient descent (SGD) algorithm that copes with Byzantine workers. Kardam consists of two complementary components: a filtering and a dampening component. The first is scalar-based and ensures resilience against 1/3 Byzantine workers. Essentially, this filter leverages the Lipschitzness of cost functions and acts as a self-stabilizer against Byzantine workers that would attempt to corrupt the progress of SGD. The dampening component bounds the convergence rate by adjusting to stale information through a generic gradient weighting scheme. We prove that Kardam guarantees almost sure convergence in the presence of asynchrony and Byzantine behavior, and we derive its convergence rate. We evaluate Kardam on the CIFAR100 and EMNIST datasets and measure its overhead with respect to non Byzantine-resilient solutions. We empirically show that Kardam does not introduce additional noise to the learning procedure but does induce a slowdown (the cost of Byzantine resilience) that we both theoretically and empirically show to be less than f/n, where f is the number of Byzantine failures tolerated and n the total number of workers. Interestingly, we also empirically observe that the dampening component is interesting in its own right for it enables to build an SGD algorithm that outperforms alternative staleness-aware asynchronous competitors in environments with honest workers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/damaskinos18a/damaskinos18a.pdf",
        "supp": "",
        "pdf_size": 627463,
        "gs_citation": 136,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7761726425458216568&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch;epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch;epfl.ch;epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/damaskinos18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Asynchronous Decentralized Parallel Stochastic Gradient Descent",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2423",
        "id": "2423",
        "author_site": "Xiangru Lian, Wei Zhang, Ce Zhang, Ji Liu",
        "author": "Xiangru Lian; Wei Zhang; Ce Zhang; Ji Liu",
        "abstract": "Most commonly used distributed machine learning systems are either synchronous or centralized asynchronous. Synchronous algorithms like AllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous algorithms using a parameter server suffer from 1) communication bottleneck at parameter servers when workers are many, and 2) significantly worse convergence when the traffic to parameter server is congested. Can we design an algorithm that is robust in a heterogeneous environment, while being communication efficient and maintaining the best-possible convergence rate? In this paper, we propose an asynchronous decentralized stochastic gradient decent algorithm (AD-PSGD) satisfying all above expectations. Our theoretical analysis shows AD-PSGD converges at the optimal $O(1/\\sqrt{K})$ rate as SGD and has linear speedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of decentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and standard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a heterogeneous environment. When training ResNet-50 on ImageNet with up to 128 GPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each epoch can be up to 4-8x faster than its synchronous counterparts in a network-sharing HPC environment. To the best of our knowledge, AD-PSGD is the first asynchronous algorithm that achieves a similar epoch-wise convergence rate as AllReduce-SGD, at an over 100-GPU scale.",
        "bibtex": "@InProceedings{pmlr-v80-lian18a,\n  title = \t {Asynchronous Decentralized Parallel Stochastic Gradient Descent},\n  author =       {Lian, Xiangru and Zhang, Wei and Zhang, Ce and Liu, Ji},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3043--3052},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lian18a/lian18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lian18a.html},\n  abstract = \t {Most commonly used distributed machine learning systems are either synchronous or centralized asynchronous. Synchronous algorithms like AllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous algorithms using a parameter server suffer from 1) communication bottleneck at parameter servers when workers are many, and 2) significantly worse convergence when the traffic to parameter server is congested. Can we design an algorithm that is robust in a heterogeneous environment, while being communication efficient and maintaining the best-possible convergence rate? In this paper, we propose an asynchronous decentralized stochastic gradient decent algorithm (AD-PSGD) satisfying all above expectations. Our theoretical analysis shows AD-PSGD converges at the optimal $O(1/\\sqrt{K})$ rate as SGD and has linear speedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of decentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and standard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a heterogeneous environment. When training ResNet-50 on ImageNet with up to 128 GPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each epoch can be up to 4-8x faster than its synchronous counterparts in a network-sharing HPC environment. To the best of our knowledge, AD-PSGD is the first asynchronous algorithm that achieves a similar epoch-wise convergence rate as AllReduce-SGD, at an over 100-GPU scale.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lian18a/lian18a.pdf",
        "supp": "",
        "pdf_size": 4495666,
        "gs_citation": 627,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8815722379168752168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Rochester; IBM T. J. Watson Research Center; Department of Computer Science, ETH Zurich; Tencent AI lab, Seattle, USA",
        "aff_domain": "mail.xrlian.com; ; ; ",
        "email": "mail.xrlian.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/lian18a.html",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "University of Rochester;IBM;ETH Zurich;Tencent",
        "aff_unique_dep": "Department of Computer Science;IBM;Department of Computer Science;AI lab",
        "aff_unique_url": "https://www.rochester.edu;https://www.ibm.com/research/watson;https://www.ethz.ch;https://ai.tencent.com",
        "aff_unique_abbr": "U of R;IBM;ETHZ;Tencent AI lab",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";T. J. Watson;Seattle",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "title": "Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1877",
        "id": "1877",
        "author_site": "Umut Simsekli, Cagatay Yildiz, Thanh Huy Nguyen, Ali Taylan Cemgil, Ga\u00ebl RICHARD",
        "author": "Umut Simsekli; Cagatay Yildiz; Than Huy Nguyen; Taylan Cemgil; Gael Richard",
        "abstract": "Recent studies have illustrated that stochastic gradient Markov Chain Monte Carlo techniques have a strong potential in non-convex optimization, where local and global convergence guarantees can be shown under certain conditions. By building up on this recent theory, in this study, we develop an asynchronous-parallel stochastic L-BFGS algorithm for non-convex optimization. The proposed algorithm is suitable for both distributed and shared-memory settings. We provide formal theoretical analysis and show that the proposed method achieves an ergodic convergence rate of ${\\cal O}(1/\\sqrt{N})$ ($N$ being the total number of iterations) and it can achieve a linear speedup under certain conditions. We perform several experiments on both synthetic and real datasets. The results support our theory and show that the proposed algorithm provides a significant speedup over the recently proposed synchronous distributed L-BFGS algorithm.",
        "bibtex": "@InProceedings{pmlr-v80-simsekli18a,\n  title = \t {Asynchronous Stochastic Quasi-{N}ewton {MCMC} for Non-Convex Optimization},\n  author =       {Simsekli, Umut and Yildiz, Cagatay and Nguyen, Than Huy and Cemgil, Taylan and Richard, Gael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4674--4683},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/simsekli18a/simsekli18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/simsekli18a.html},\n  abstract = \t {Recent studies have illustrated that stochastic gradient Markov Chain Monte Carlo techniques have a strong potential in non-convex optimization, where local and global convergence guarantees can be shown under certain conditions. By building up on this recent theory, in this study, we develop an asynchronous-parallel stochastic L-BFGS algorithm for non-convex optimization. The proposed algorithm is suitable for both distributed and shared-memory settings. We provide formal theoretical analysis and show that the proposed method achieves an ergodic convergence rate of ${\\cal O}(1/\\sqrt{N})$ ($N$ being the total number of iterations) and it can achieve a linear speedup under certain conditions. We perform several experiments on both synthetic and real datasets. The results support our theory and show that the proposed algorithm provides a significant speedup over the recently proposed synchronous distributed L-BFGS algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/simsekli18a/simsekli18a.pdf",
        "supp": "",
        "pdf_size": 1625625,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9961455064611467128&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "LTCI, T\u00b4el\u00b4ecom ParisTech, Universit\u00b4e Paris-Saclay, 75013, Paris, France; Department of Computer Science, Aalto University, Espoo, 02150, Finland; LTCI, T\u00b4el\u00b4ecom ParisTech, Universit\u00b4e Paris-Saclay, 75013, Paris, France; LTCI, T\u00b4el\u00b4ecom ParisTech, Universit\u00b4e Paris-Saclay, 75013, Paris, France; Department of Computer Engineering, Bo\u02d8gazic\u00b8i University, 34342, Bebek, Istanbul, Turkey",
        "aff_domain": "telecom-paristech.fr; ; ; ; ",
        "email": "telecom-paristech.fr; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/simsekli18a.html",
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "T\u00e9l\u00e9com ParisTech;Aalto University;Bogazici University",
        "aff_unique_dep": "LTCI;Department of Computer Science;Department of Computer Engineering",
        "aff_unique_url": "https://www.telecom-paris.fr;https://www.aalto.fi;https://www.boun.edu.tr",
        "aff_unique_abbr": "T\u00e9l\u00e9com ParisTech;Aalto;Bogazici",
        "aff_campus_unique_index": "0;1;0;0;2",
        "aff_campus_unique": "Paris;Espoo;Istanbul",
        "aff_country_unique_index": "0;1;0;0;2",
        "aff_country_unique": "France;Finland;T\u00fcrkiye"
    },
    {
        "title": "Attention-based Deep Multiple Instance Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2029",
        "id": "2029",
        "author_site": "Maximilian Ilse, Jakub Tomczak, Max Welling",
        "author": "Maximilian Ilse; Jakub Tomczak; Max Welling",
        "abstract": "Multiple instance learning (MIL) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this paper, we state the MIL problem as learning the Bernoulli distribution of the bag label where the bag label probability is fully parameterized by neural networks. Furthermore, we propose a neural network-based permutation-invariant aggregation operator that corresponds to the attention mechanism. Notably, an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag label. We show empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacrificing interpretability.",
        "bibtex": "@InProceedings{pmlr-v80-ilse18a,\n  title = \t {Attention-based Deep Multiple Instance Learning},\n  author =       {Ilse, Maximilian and Tomczak, Jakub and Welling, Max},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2127--2136},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ilse18a/ilse18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ilse18a.html},\n  abstract = \t {Multiple instance learning (MIL) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this paper, we state the MIL problem as learning the Bernoulli distribution of the bag label where the bag label probability is fully parameterized by neural networks. Furthermore, we propose a neural network-based permutation-invariant aggregation operator that corresponds to the attention mechanism. Notably, an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag label. We show empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacrificing interpretability.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ilse18a/ilse18a.pdf",
        "supp": "",
        "pdf_size": 2328134,
        "gs_citation": 2439,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10689360653942822671&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "University of Amsterdam, the Netherlands; University of Amsterdam, the Netherlands; University of Amsterdam, the Netherlands",
        "aff_domain": "uva.nl;uva.nl; ",
        "email": "uva.nl;uva.nl; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ilse18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Amsterdam",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uva.nl",
        "aff_unique_abbr": "UvA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "title": "Augment and Reduce: Stochastic Inference for Large Categorical Distributions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1936",
        "id": "1936",
        "author_site": "Francisco Ruiz, Michalis Titsias, Adji Bousso Dieng, David Blei",
        "author": "Francisco Ruiz; Michalis Titsias; Adji Bousso Dieng; David Blei",
        "abstract": "Categorical distributions are ubiquitous in machine learning, e.g., in classification, language models, and recommendation systems. However, when the number of possible outcomes is very large, using categorical distributions becomes computationally expensive, as the complexity scales linearly with the number of outcomes. To address this problem, we propose augment and reduce (A&R), a method to alleviate the computational complexity. A&R uses two ideas: latent variable augmentation and stochastic variational inference. It maximizes a lower bound on the marginal likelihood of the data. Unlike existing methods which are specific to softmax, A&R is more general and is amenable to other categorical models, such as multinomial probit. On several large-scale classification problems, we show that A&R provides a tighter bound on the marginal likelihood and has better predictive performance than existing approaches.",
        "bibtex": "@InProceedings{pmlr-v80-ruiz18a,\n  title = \t {Augment and Reduce: Stochastic Inference for Large Categorical Distributions},\n  author =       {Ruiz, Francisco and Titsias, Michalis and Dieng, Adji Bousso and Blei, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4403--4412},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ruiz18a/ruiz18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ruiz18a.html},\n  abstract = \t {Categorical distributions are ubiquitous in machine learning, e.g., in classification, language models, and recommendation systems. However, when the number of possible outcomes is very large, using categorical distributions becomes computationally expensive, as the complexity scales linearly with the number of outcomes. To address this problem, we propose augment and reduce (A&R), a method to alleviate the computational complexity. A&R uses two ideas: latent variable augmentation and stochastic variational inference. It maximizes a lower bound on the marginal likelihood of the data. Unlike existing methods which are specific to softmax, A&R is more general and is amenable to other categorical models, such as multinomial probit. On several large-scale classification problems, we show that A&R provides a tighter bound on the marginal likelihood and has better predictive performance than existing approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ruiz18a/ruiz18a.pdf",
        "supp": "",
        "pdf_size": 542994,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6203433774032292612&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ruiz18a.html"
    },
    {
        "title": "Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2408",
        "id": "2408",
        "author_site": "Amjad Almahairi, Sai Rajeswar, Alessandro Sordoni, Philip Bachman, Aaron Courville",
        "author": "Amjad Almahairi; Sai Rajeshwar; Alessandro Sordoni; Philip Bachman; Aaron Courville",
        "abstract": "Learning inter-domain mappings from unpaired data can improve performance in structured prediction tasks, such as image segmentation, by reducing the need for paired data. CycleGAN was recently proposed for this problem, but critically assumes the underlying inter-domain mapping is approximately deterministic and one-to-one. This assumption renders the model ineffective for tasks requiring flexible, many-to-many mappings. We propose a new model, called Augmented CycleGAN, which learns many-to-many mappings between domains. We examine Augmented CycleGAN qualitatively and quantitatively on several image datasets.",
        "bibtex": "@InProceedings{pmlr-v80-almahairi18a,\n  title = \t {Augmented {C}ycle{GAN}: Learning Many-to-Many Mappings from Unpaired Data},\n  author =       {Almahairi, Amjad and Rajeshwar, Sai and Sordoni, Alessandro and Bachman, Philip and Courville, Aaron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {195--204},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/almahairi18a/almahairi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/almahairi18a.html},\n  abstract = \t {Learning inter-domain mappings from unpaired data can improve performance in structured prediction tasks, such as image segmentation, by reducing the need for paired data. CycleGAN was recently proposed for this problem, but critically assumes the underlying inter-domain mapping is approximately deterministic and one-to-one. This assumption renders the model ineffective for tasks requiring flexible, many-to-many mappings. We propose a new model, called Augmented CycleGAN, which learns many-to-many mappings between domains. We examine Augmented CycleGAN qualitatively and quantitatively on several image datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/almahairi18a/almahairi18a.pdf",
        "supp": "",
        "pdf_size": 5582399,
        "gs_citation": 563,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15826263633535493096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Montreal Institute for Learning Algorithms (MILA), Canada; Montreal Institute for Learning Algorithms (MILA), Canada; Microsoft Research Montreal, Canada; Microsoft Research Montreal, Canada; Montreal Institute for Learning Algorithms (MILA), Canada + CIFAR Fellow",
        "aff_domain": "umontreal.ca; ; ; ; ",
        "email": "umontreal.ca; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/almahairi18a.html",
        "aff_unique_index": "0;0;1;1;0+2",
        "aff_unique_norm": "Montreal Institute for Learning Algorithms;Microsoft;CIFAR",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://mila.quebec;https://www.microsoft.com/en-us/research/group/microsoft-research-montreal;https://www.cifar.ca",
        "aff_unique_abbr": "MILA;MSR Montreal;CIFAR",
        "aff_campus_unique_index": "1;1;",
        "aff_campus_unique": ";Montreal",
        "aff_country_unique_index": "0;0;0;0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2050",
        "id": "2050",
        "author_site": "Ahmed M. Alaa, Mihaela van der Schaar",
        "author": "Ahmed Alaa; Mihaela Schaar",
        "abstract": "Clinical prognostic models derived from largescale healthcare data can inform critical diagnostic and therapeutic decisions. To enable off-theshelf usage of machine learning (ML) in prognostic research, we developed AUTOPROGNOSIS: a system for automating the design of predictive modeling pipelines tailored for clinical prognosis. AUTOPROGNOSIS optimizes ensembles of pipeline configurations efficiently using a novel batched Bayesian optimization (BO) algorithm that learns a low-dimensional decomposition of the pipelines\u2019 high-dimensional hyperparameter space in concurrence with the BO procedure. This is achieved by modeling the pipelines\u2019 performances as a black-box function with a Gaussian process prior, and modeling the \u201csimilarities\u201d between the pipelines\u2019 baseline algorithms via a sparse additive kernel with a Dirichlet prior. Meta-learning is used to warmstart BO with external data from \u201csimilar\u201d patient cohorts by calibrating the priors using an algorithm that mimics the empirical Bayes method. The system automatically explains its predictions by presenting the clinicians with logical association rules that link patients\u2019 features to predicted risk strata. We demonstrate the utility of AUTOPROGNOSIS using 10 major patient cohorts representing various aspects of cardiovascular patient care.",
        "bibtex": "@InProceedings{pmlr-v80-alaa18b,\n  title = \t {{A}uto{P}rognosis: Automated Clinical Prognostic Modeling via {B}ayesian Optimization with Structured Kernel Learning},\n  author =       {Alaa, Ahmed and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {139--148},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/alaa18b/alaa18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/alaa18b.html},\n  abstract = \t {Clinical prognostic models derived from largescale healthcare data can inform critical diagnostic and therapeutic decisions. To enable off-theshelf usage of machine learning (ML) in prognostic research, we developed AUTOPROGNOSIS: a system for automating the design of predictive modeling pipelines tailored for clinical prognosis. AUTOPROGNOSIS optimizes ensembles of pipeline configurations efficiently using a novel batched Bayesian optimization (BO) algorithm that learns a low-dimensional decomposition of the pipelines\u2019 high-dimensional hyperparameter space in concurrence with the BO procedure. This is achieved by modeling the pipelines\u2019 performances as a black-box function with a Gaussian process prior, and modeling the \u201csimilarities\u201d between the pipelines\u2019 baseline algorithms via a sparse additive kernel with a Dirichlet prior. Meta-learning is used to warmstart BO with external data from \u201csimilar\u201d patient cohorts by calibrating the priors using an algorithm that mimics the empirical Bayes method. The system automatically explains its predictions by presenting the clinicians with logical association rules that link patients\u2019 features to predicted risk strata. We demonstrate the utility of AUTOPROGNOSIS using 10 major patient cohorts representing various aspects of cardiovascular patient care.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/alaa18b/alaa18b.pdf",
        "supp": "",
        "pdf_size": 439056,
        "gs_citation": 125,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=52948101831469297&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of California, Los Angeles, USA+University of Oxford, Oxford, UK+Alan Turing Institute, London, UK; University of California, Los Angeles, USA+University of Oxford, Oxford, UK+Alan Turing Institute, London, UK",
        "aff_domain": "ucla.edu; ",
        "email": "ucla.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/alaa18b.html",
        "aff_unique_index": "0+1+2;0+1+2",
        "aff_unique_norm": "University of California, Los Angeles;University of Oxford;Alan Turing Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucla.edu;https://www.ox.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "UCLA;Oxford;ATI",
        "aff_campus_unique_index": "0+1+2;0+1+2",
        "aff_campus_unique": "Los Angeles;Oxford;London",
        "aff_country_unique_index": "0+1+1;0+1+1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Automatic Goal Generation for Reinforcement Learning Agents",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2287",
        "id": "2287",
        "author_site": "Carlos Florensa, David Held, Xinyang Geng, Pieter Abbeel",
        "author": "Carlos Florensa; David Held; Xinyang Geng; Pieter Abbeel",
        "abstract": "Reinforcement learning (RL) is a powerful technique to train an agent to perform a task; however, an agent that is trained using RL is only capable of achieving the single task that is specified via its reward function. Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks, such as navigating to varying positions in a room or moving objects to varying locations. Instead, we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing in its environment. We use a generator network to propose tasks for the agent to try to accomplish, each task being specified as reaching a certain parametrized subset of the state-space. The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent, thus automatically producing a curriculum. We show that, by using this framework, an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment, even when only sparse rewards are available. Videos and code available at https://sites.google.com/view/goalgeneration4rl.",
        "bibtex": "@InProceedings{pmlr-v80-florensa18a,\n  title = \t {Automatic Goal Generation for Reinforcement Learning Agents},\n  author =       {Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1515--1528},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/florensa18a/florensa18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/florensa18a.html},\n  abstract = \t {Reinforcement learning (RL) is a powerful technique to train an agent to perform a task; however, an agent that is trained using RL is only capable of achieving the single task that is specified via its reward function. Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks, such as navigating to varying positions in a room or moving objects to varying locations. Instead, we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing in its environment. We use a generator network to propose tasks for the agent to try to accomplish, each task being specified as reaching a certain parametrized subset of the state-space. The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent, thus automatically producing a curriculum. We show that, by using this framework, an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment, even when only sparse rewards are available. Videos and code available at https://sites.google.com/view/goalgeneration4rl.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/florensa18a/florensa18a.pdf",
        "supp": "",
        "pdf_size": 6505428,
        "gs_citation": 530,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5836114268256047177&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, UC Berkeley+International Computer Science Institute (ICSI); Department of Computer Science, CMU; Department of Computer Science, UC Berkeley; International Computer Science Institute (ICSI)",
        "aff_domain": "berkeley.edu;andrew.cmu.edu; ; ",
        "email": "berkeley.edu;andrew.cmu.edu; ; ",
        "github": "",
        "project": "https://sites.google.com/view/goalgeneration4rl",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/florensa18a.html",
        "aff_unique_index": "0+1;2;0;1",
        "aff_unique_norm": "University of California, Berkeley;International Computer Science Institute;Carnegie Mellon University",
        "aff_unique_dep": "Department of Computer Science;;Department of Computer Science",
        "aff_unique_url": "https://www.berkeley.edu;https://www.icsi.berkeley.edu/;https://www.cmu.edu",
        "aff_unique_abbr": "UC Berkeley;ICSI;CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Autoregressive Convolutional Neural Networks for Asynchronous Time Series",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2310",
        "id": "2310",
        "author_site": "Mikolaj Binkowski, Gautier Marti, Philippe Donnat",
        "author": "Mikolaj Binkowski; Gautier Marti; Philippe Donnat",
        "abstract": "We propose Significance-Offset Convolutional Neural Network, a deep convolutional network architecture for regression of multivariate asynchronous time series. The model is inspired by standard autoregressive (AR) models and gating mechanisms used in recurrent neural networks. It involves an AR-like weighting system, where the final predictor is obtained as a weighted sum of adjusted regressors, while the weights are data-dependent functions learnt through a convolutional network. The architecture was designed for applications on asynchronous time series and is evaluated on such datasets: a hedge fund proprietary dataset of over 2 million quotes for a credit derivative index, an artificially generated noisy autoregressive series and UCI household electricity consumption dataset. The proposed architecture achieves promising results as compared to convolutional and recurrent neural networks.",
        "bibtex": "@InProceedings{pmlr-v80-binkowski18a,\n  title = \t {Autoregressive Convolutional Neural Networks for Asynchronous Time Series},\n  author =       {Binkowski, Mikolaj and Marti, Gautier and Donnat, Philippe},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {580--589},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/binkowski18a/binkowski18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/binkowski18a.html},\n  abstract = \t {We propose Significance-Offset Convolutional Neural Network, a deep convolutional network architecture for regression of multivariate asynchronous time series. The model is inspired by standard autoregressive (AR) models and gating mechanisms used in recurrent neural networks. It involves an AR-like weighting system, where the final predictor is obtained as a weighted sum of adjusted regressors, while the weights are data-dependent functions learnt through a convolutional network. The architecture was designed for applications on asynchronous time series and is evaluated on such datasets: a hedge fund proprietary dataset of over 2 million quotes for a credit derivative index, an artificially generated noisy autoregressive series and UCI household electricity consumption dataset. The proposed architecture achieves promising results as compared to convolutional and recurrent neural networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/binkowski18a/binkowski18a.pdf",
        "supp": "",
        "pdf_size": 3194306,
        "gs_citation": 216,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16946741031490973459&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics, Imperial College London, London, UK+Hellebore Capital Limited, London, UK; Hellebore Capital Limited, London, UK+Laboratoire d\u2019informatique, Ecole Polytechnique, Palaiseau, France; Laboratoire d\u2019informatique, Ecole Polytechnique, Palaiseau, France",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/binkowski18a.html",
        "aff_unique_index": "0+1;1+2;2",
        "aff_unique_norm": "Imperial College London;Hellebore Capital Limited;Ecole Polytechnique",
        "aff_unique_dep": "Department of Mathematics;;Laboratoire d\u2019informatique",
        "aff_unique_url": "https://www.imperial.ac.uk;;https://www.polytechnique.edu",
        "aff_unique_abbr": "Imperial;;Polytechnique",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "London;;Palaiseau",
        "aff_country_unique_index": "0+0;0+1;1",
        "aff_country_unique": "United Kingdom;France"
    },
    {
        "title": "Autoregressive Quantile Networks for Generative Modeling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2416",
        "id": "2416",
        "author_site": "Georg Ostrovski, Will Dabney, Remi Munos",
        "author": "Georg Ostrovski; Will Dabney; Remi Munos",
        "abstract": "We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling than those commonly used, that implicitly captures the distribution using quantile regression. AIQN is able to achieve superior perceptual quality and improvements in evaluation metrics, without incurring a loss of sample diversity. The method can be applied to many existing models and architectures. In this work we extend the PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using Inception scores, FID, non-cherry-picked samples, and inpainting results. We consistently observe that AIQN yields a highly stable algorithm that improves perceptual quality while maintaining a highly diverse distribution.",
        "bibtex": "@InProceedings{pmlr-v80-ostrovski18a,\n  title = \t {Autoregressive Quantile Networks for Generative Modeling},\n  author =       {Ostrovski, Georg and Dabney, Will and Munos, Remi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3936--3945},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ostrovski18a/ostrovski18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ostrovski18a.html},\n  abstract = \t {We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling than those commonly used, that implicitly captures the distribution using quantile regression. AIQN is able to achieve superior perceptual quality and improvements in evaluation metrics, without incurring a loss of sample diversity. The method can be applied to many existing models and architectures. In this work we extend the PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using Inception scores, FID, non-cherry-picked samples, and inpainting results. We consistently observe that AIQN yields a highly stable algorithm that improves perceptual quality while maintaining a highly diverse distribution.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ostrovski18a/ostrovski18a.pdf",
        "supp": "",
        "pdf_size": 1884375,
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16792387402580682598&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "google.com;google.com; ",
        "email": "google.com;google.com; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ostrovski18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "BOCK : Bayesian Optimization with Cylindrical Kernels",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2230",
        "id": "2230",
        "author_site": "ChangYong Oh, Efstratios Gavves, Max Welling",
        "author": "ChangYong Oh; Efstratios Gavves; Max Welling",
        "abstract": "A major challenge in Bayesian Optimization is the boundary issue where an algorithm spends too many evaluations near the boundary of its search space. In this paper, we propose BOCK, Bayesian Optimization with Cylindrical Kernels, whose basic idea is to transform the ball geometry of the search space using a cylindrical transformation. Because of the transformed geometry, the Gaussian Process-based surrogate model spends less budget searching near the boundary, while concentrating its efforts relatively more near the center of the search region, where we expect the solution to be located. We evaluate BOCK extensively, showing that it is not only more accurate and efficient, but it also scales successfully to problems with a dimensionality as high as 500. We show that the better accuracy and scalability of BOCK even allows optimizing modestly sized neural network layers, as well as neural network hyperparameters.",
        "bibtex": "@InProceedings{pmlr-v80-oh18a,\n  title = \t {{BOCK} : {B}ayesian Optimization with Cylindrical Kernels},\n  author =       {Oh, ChangYong and Gavves, Efstratios and Welling, Max},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3868--3877},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/oh18a/oh18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/oh18a.html},\n  abstract = \t {A major challenge in Bayesian Optimization is the boundary issue where an algorithm spends too many evaluations near the boundary of its search space. In this paper, we propose BOCK, Bayesian Optimization with Cylindrical Kernels, whose basic idea is to transform the ball geometry of the search space using a cylindrical transformation. Because of the transformed geometry, the Gaussian Process-based surrogate model spends less budget searching near the boundary, while concentrating its efforts relatively more near the center of the search region, where we expect the solution to be located. We evaluate BOCK extensively, showing that it is not only more accurate and efficient, but it also scales successfully to problems with a dimensionality as high as 500. We show that the better accuracy and scalability of BOCK even allows optimizing modestly sized neural network layers, as well as neural network hyperparameters.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/oh18a/oh18a.pdf",
        "supp": "",
        "pdf_size": 2344395,
        "gs_citation": 180,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13127766314643227872&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "QUvA Lab, Informatic Institute, University of Amsterdam, Amsterdam, Netherlands+Canadian Institute for Advanced Research, Toronto, Canada; QUvA Lab, Informatic Institute, University of Amsterdam, Amsterdam, Netherlands; QUvA Lab, Informatic Institute, University of Amsterdam, Amsterdam, Netherlands+Canadian Institute for Advanced Research, Toronto, Canada",
        "aff_domain": "uva.nl; ; ",
        "email": "uva.nl; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/oh18a.html",
        "aff_unique_index": "0+1;0;0+1",
        "aff_unique_norm": "University of Amsterdam;Canadian Institute for Advanced Research",
        "aff_unique_dep": "Informatic Institute;",
        "aff_unique_url": "https://www.uva.nl;https://www.cifar.ca",
        "aff_unique_abbr": "UvA;CIFAR",
        "aff_campus_unique_index": "0+1;0;0+1",
        "aff_campus_unique": "Amsterdam;Toronto",
        "aff_country_unique_index": "0+1;0;0+1",
        "aff_country_unique": "Netherlands;Canada"
    },
    {
        "title": "BOHB: Robust and Efficient Hyperparameter Optimization at Scale",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2387",
        "id": "2387",
        "author_site": "Stefan Falkner, Aaron Klein, Frank Hutter",
        "author": "Stefan Falkner; Aaron Klein; Frank Hutter",
        "abstract": "Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. Here, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.",
        "bibtex": "@InProceedings{pmlr-v80-falkner18a,\n  title = \t {{BOHB}: Robust and Efficient Hyperparameter Optimization at Scale},\n  author =       {Falkner, Stefan and Klein, Aaron and Hutter, Frank},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1437--1446},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/falkner18a/falkner18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/falkner18a.html},\n  abstract = \t {Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. Here, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/falkner18a/falkner18a.pdf",
        "supp": "",
        "pdf_size": 551850,
        "gs_citation": 1488,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7414210775058292852&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Computer Science, University of Freiburg, Freiburg, Germany; Department of Computer Science, University of Freiburg, Freiburg, Germany; Department of Computer Science, University of Freiburg, Freiburg, Germany",
        "aff_domain": "informatik.uni-freiburg.de; ; ",
        "email": "informatik.uni-freiburg.de; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/falkner18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "Uni Freiburg",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Freiburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Bandits with Delayed, Aggregated Anonymous Feedback",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2212",
        "id": "2212",
        "author_site": "Ciara Pike-Burke, Shipra Agrawal, Csaba Szepesvari, Steffen Gr\u00fcnew\u00e4lder",
        "author": "Ciara Pike-Burke; Shipra Agrawal; Csaba Szepesvari; Steffen Grunewalder",
        "abstract": "We study a variant of the stochastic $K$-armed bandit problem, which we call \"bandits with delayed, aggregated anonymous feedback\u201d. In this problem, when the player pulls an arm, a reward is generated, however it is not immediately observed. Instead, at the end of each round the player observes only the sum of a number of previously generated rewards which happen to arrive in the given round. The rewards are stochastically delayed and due to the aggregated nature of the observations, the information of which arm led to a particular reward is lost. The question is what is the cost of the information loss due to this delayed, aggregated anonymous feedback? Previous works have studied bandits with stochastic, non-anonymous delays and found that the regret increases only by an additive factor relating to the expected delay. In this paper, we show that this additive regret increase can be maintained in the harder delayed, aggregated anonymous feedback setting when the expected delay (or a bound on it) is known. We provide an algorithm that matches the worst case regret of the non-anonymous problem exactly when the delays are bounded, and up to logarithmic factors or an additive variance term for unbounded delays.",
        "bibtex": "@InProceedings{pmlr-v80-pike-burke18a,\n  title = \t {Bandits with Delayed, Aggregated Anonymous Feedback},\n  author =       {Pike-Burke, Ciara and Agrawal, Shipra and Szepesvari, Csaba and Grunewalder, Steffen},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4105--4113},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pike-burke18a/pike-burke18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pike-burke18a.html},\n  abstract = \t {We study a variant of the stochastic $K$-armed bandit problem, which we call \"bandits with delayed, aggregated anonymous feedback\u201d. In this problem, when the player pulls an arm, a reward is generated, however it is not immediately observed. Instead, at the end of each round the player observes only the sum of a number of previously generated rewards which happen to arrive in the given round. The rewards are stochastically delayed and due to the aggregated nature of the observations, the information of which arm led to a particular reward is lost. The question is what is the cost of the information loss due to this delayed, aggregated anonymous feedback? Previous works have studied bandits with stochastic, non-anonymous delays and found that the regret increases only by an additive factor relating to the expected delay. In this paper, we show that this additive regret increase can be maintained in the harder delayed, aggregated anonymous feedback setting when the expected delay (or a bound on it) is known. We provide an algorithm that matches the worst case regret of the non-anonymous problem exactly when the delays are bounded, and up to logarithmic factors or an additive variance term for unbounded delays.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pike-burke18a/pike-burke18a.pdf",
        "supp": "",
        "pdf_size": 1884442,
        "gs_citation": 148,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11604459165457187544&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Mathematics and Statistics, Lancaster University, Lancaster, UK; Department of Industrial Engineering and Operations Research, Columbia University, New York, NY, USA; DeepMind, London, UK + Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Mathematics and Statistics, Lancaster University, Lancaster, UK",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/pike-burke18a.html",
        "aff_unique_index": "0;1;2+3;0",
        "aff_unique_norm": "Lancaster University;Columbia University;DeepMind;University of Alberta",
        "aff_unique_dep": "Department of Mathematics and Statistics;Department of Industrial Engineering and Operations Research;;Department of Computing Science",
        "aff_unique_url": "https://www.lancaster.ac.uk;https://www.columbia.edu;https://deepmind.com;https://www.ualberta.ca",
        "aff_unique_abbr": "Lancaster;Columbia;DeepMind;UAlberta",
        "aff_campus_unique_index": "0;1;2+3;0",
        "aff_campus_unique": "Lancaster;New York;London;Edmonton",
        "aff_country_unique_index": "0;1;0+2;0",
        "aff_country_unique": "United Kingdom;United States;Canada"
    },
    {
        "title": "Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1919",
        "id": "1919",
        "author_site": "Wenlong Lyu, Fan Yang, Changhao Yan, Dian Zhou, Xuan Zeng",
        "author": "Wenlong Lyu; Fan Yang; Changhao Yan; Dian Zhou; Xuan Zeng",
        "abstract": "Bayesian optimization methods are promising for the optimization of black-box functions that are expensive to evaluate. In this paper, a novel batch Bayesian optimization approach is proposed. The parallelization is realized via a multi-objective ensemble of multiple acquisition functions. In each iteration, the multi-objective optimization of the multiple acquisition functions is performed to search for the Pareto front of the acquisition functions. The batch of inputs are then selected from the Pareto front. The Pareto front represents the best trade-off between the multiple acquisition functions. Such a policy for batch Bayesian optimization can significantly improve the efficiency of optimization. The proposed method is compared with several state-of-the-art batch Bayesian optimization algorithms using analytical benchmark functions and real-world analog integrated circuits. The experimental results show that the proposed method is competitive compared with the state-of-the-art algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-lyu18a,\n  title = \t {Batch {B}ayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design},\n  author =       {Lyu, Wenlong and Yang, Fan and Yan, Changhao and Zhou, Dian and Zeng, Xuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3306--3314},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lyu18a/lyu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lyu18a.html},\n  abstract = \t {Bayesian optimization methods are promising for the optimization of black-box functions that are expensive to evaluate. In this paper, a novel batch Bayesian optimization approach is proposed. The parallelization is realized via a multi-objective ensemble of multiple acquisition functions. In each iteration, the multi-objective optimization of the multiple acquisition functions is performed to search for the Pareto front of the acquisition functions. The batch of inputs are then selected from the Pareto front. The Pareto front represents the best trade-off between the multiple acquisition functions. Such a policy for batch Bayesian optimization can significantly improve the efficiency of optimization. The proposed method is compared with several state-of-the-art batch Bayesian optimization algorithms using analytical benchmark functions and real-world analog integrated circuits. The experimental results show that the proposed method is competitive compared with the state-of-the-art algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lyu18a/lyu18a.pdf",
        "supp": "",
        "pdf_size": 641280,
        "gs_citation": 194,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18060661280078108001&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/lyu18a.html"
    },
    {
        "title": "Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1950",
        "id": "1950",
        "author_site": "Trevor Campbell, Tamara Broderick",
        "author": "Trevor Campbell; Tamara Broderick",
        "abstract": "Coherent uncertainty quantification is a key strength of Bayesian methods. But modern algorithms for approximate Bayesian posterior inference often sacrifice accurate posterior uncertainty estimation in the pursuit of scalability. This work shows that previous Bayesian coreset construction algorithms\u2014which build a small, weighted subset of the data that approximates the full dataset\u2014are no exception. We demonstrate that these algorithms scale the coreset log-likelihood suboptimally, resulting in underestimated posterior uncertainty. To address this shortcoming, we develop greedy iterative geodesic ascent (GIGA), a novel algorithm for Bayesian coreset construction that scales the coreset log-likelihood optimally. GIGA provides geometric decay in posterior approximation error as a function of coreset size, and maintains the fast running time of its predecessors. The paper concludes with validation of GIGA on both synthetic and real datasets, demonstrating that it reduces posterior approximation error by orders of magnitude compared with previous coreset constructions.",
        "bibtex": "@InProceedings{pmlr-v80-campbell18a,\n  title = \t {{B}ayesian Coreset Construction via Greedy Iterative Geodesic Ascent},\n  author =       {Campbell, Trevor and Broderick, Tamara},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {698--706},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/campbell18a/campbell18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/campbell18a.html},\n  abstract = \t {Coherent uncertainty quantification is a key strength of Bayesian methods. But modern algorithms for approximate Bayesian posterior inference often sacrifice accurate posterior uncertainty estimation in the pursuit of scalability. This work shows that previous Bayesian coreset construction algorithms\u2014which build a small, weighted subset of the data that approximates the full dataset\u2014are no exception. We demonstrate that these algorithms scale the coreset log-likelihood suboptimally, resulting in underestimated posterior uncertainty. To address this shortcoming, we develop greedy iterative geodesic ascent (GIGA), a novel algorithm for Bayesian coreset construction that scales the coreset log-likelihood optimally. GIGA provides geometric decay in posterior approximation error as a function of coreset size, and maintains the fast running time of its predecessors. The paper concludes with validation of GIGA on both synthetic and real datasets, demonstrating that it reduces posterior approximation error by orders of magnitude compared with previous coreset constructions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/campbell18a/campbell18a.pdf",
        "supp": "",
        "pdf_size": 1034646,
        "gs_citation": 163,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=662866254282688281&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States",
        "aff_domain": "mit.edu; ",
        "email": "mit.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/campbell18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Bayesian Model Selection for Change Point Detection and Clustering",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2308",
        "id": "2308",
        "author_site": "othmane mazhar, Cristian R. Rojas, Inst. of Technology Carlo Fischione, Mohammad Reza Hesamzadeh",
        "author": "Othmane Mazhar; Cristian Rojas; Carlo Fischione;  Mohammad Reza Hesamzadeh",
        "abstract": "We address a generalization of change point detection with the purpose of detecting the change locations and the levels of clusters of a piecewise constant signal. Our approach is to model it as a nonparametric penalized least square model selection on a family of models indexed over the collection of partitions of the design points and propose a computationally efficient algorithm to approximately solve it. Statistically, minimizing such a penalized criterion yields an approximation to the maximum a-posteriori probability (MAP) estimator. The criterion is then analyzed and an oracle inequality is derived using a Gaussian concentration inequality. The oracle inequality is used to derive on one hand conditions for consistency and on the other hand an adaptive upper bound on the expected square risk of the estimator, which statistically motivates our approximation. Finally, we apply our algorithm to simulated data to experimentally validate the statistical guarantees and illustrate its behavior.",
        "bibtex": "@InProceedings{pmlr-v80-mazhar18a,\n  title = \t {{B}ayesian Model Selection for Change Point Detection and Clustering},\n  author =       {Mazhar, Othmane and Rojas, Cristian and Fischione, Carlo and edit Mohammad Reza Hesamzadeh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3433--3442},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mazhar18a/mazhar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mazhar18a.html},\n  abstract = \t {We address a generalization of change point detection with the purpose of detecting the change locations and the levels of clusters of a piecewise constant signal. Our approach is to model it as a nonparametric penalized least square model selection on a family of models indexed over the collection of partitions of the design points and propose a computationally efficient algorithm to approximately solve it. Statistically, minimizing such a penalized criterion yields an approximation to the maximum a-posteriori probability (MAP) estimator. The criterion is then analyzed and an oracle inequality is derived using a Gaussian concentration inequality. The oracle inequality is used to derive on one hand conditions for consistency and on the other hand an adaptive upper bound on the expected square risk of the estimator, which statistically motivates our approximation. Finally, we apply our algorithm to simulated data to experimentally validate the statistical guarantees and illustrate its behavior.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mazhar18a/mazhar18a.pdf",
        "supp": "",
        "pdf_size": 716138,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13071393329181990561&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden",
        "aff_domain": "kth.se; ; ; ",
        "email": "kth.se; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/mazhar18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "title": "Bayesian Optimization of Combinatorial Structures",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2444",
        "id": "2444",
        "author_site": "Ricardo Baptista, Matthias Poloczek",
        "author": "Ricardo Baptista; Matthias Poloczek",
        "abstract": "The optimization of expensive-to-evaluate black-box functions over combinatorial structures is an ubiquitous task in machine learning, engineering and the natural sciences. The combinatorial explosion of the search space and costly evaluations pose challenges for current techniques in discrete optimization and machine learning, and critically require new algorithmic ideas. This article proposes, to the best of our knowledge, the first algorithm to overcome these challenges, based on an adaptive, scalable model that identifies useful combinatorial structure even when data is scarce. Our acquisition function pioneers the use of semidefinite programming to achieve efficiency and scalability. Experimental evaluations demonstrate that this algorithm consistently outperforms other methods from combinatorial and Bayesian optimization.",
        "bibtex": "@InProceedings{pmlr-v80-baptista18a,\n  title = \t {{B}ayesian Optimization of Combinatorial Structures},\n  author =       {Baptista, Ricardo and Poloczek, Matthias},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {462--471},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/baptista18a/baptista18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/baptista18a.html},\n  abstract = \t {The optimization of expensive-to-evaluate black-box functions over combinatorial structures is an ubiquitous task in machine learning, engineering and the natural sciences. The combinatorial explosion of the search space and costly evaluations pose challenges for current techniques in discrete optimization and machine learning, and critically require new algorithmic ideas. This article proposes, to the best of our knowledge, the first algorithm to overcome these challenges, based on an adaptive, scalable model that identifies useful combinatorial structure even when data is scarce. Our acquisition function pioneers the use of semidefinite programming to achieve efficiency and scalability. Experimental evaluations demonstrate that this algorithm consistently outperforms other methods from combinatorial and Bayesian optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/baptista18a/baptista18a.pdf",
        "supp": "",
        "pdf_size": 1067465,
        "gs_citation": 179,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1602326552169762893&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Center for Computational Engineering, Massachusetts Institute of Technology, Cambridge, MA+Dept. of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ; Dept. of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ",
        "aff_domain": "mit.edu;email.arizona.edu",
        "email": "mit.edu;email.arizona.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/baptista18a.html",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Arizona",
        "aff_unique_dep": "Center for Computational Engineering;Dept. of Systems and Industrial Engineering",
        "aff_unique_url": "https://web.mit.edu;https://arizona.edu",
        "aff_unique_abbr": "MIT;U of A",
        "aff_campus_unique_index": "0+1;1",
        "aff_campus_unique": "Cambridge;Tucson",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Bayesian Quadrature for Multiple Related Integrals",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1890",
        "id": "1890",
        "author_site": "Xiaoyue Xi, Francois-Xavier Briol, Mark Girolami",
        "author": "Xiaoyue Xi; Francois-Xavier Briol; Mark Girolami",
        "abstract": "Bayesian probabilistic numerical methods are a set of tools providing posterior distributions on the output of numerical methods. The use of these methods is usually motivated by the fact that they can represent our uncertainty due to incomplete/finite information about the continuous mathematical problem being approximated. In this paper, we demonstrate that this paradigm can provide additional advantages, such as the possibility of transferring information between several numerical methods. This allows users to represent uncertainty in a more faithful manner and, as a by-product, provide increased numerical efficiency. We propose the first such numerical method by extending the well-known Bayesian quadrature algorithm to the case where we are interested in computing the integral of several related functions. We then prove convergence rates for the method in the well-specified and misspecified cases, and demonstrate its efficiency in the context of multi-fidelity models for complex engineering systems and a problem of global illumination in computer graphics.",
        "bibtex": "@InProceedings{pmlr-v80-xi18a,\n  title = \t {{B}ayesian Quadrature for Multiple Related Integrals},\n  author =       {Xi, Xiaoyue and Briol, Francois-Xavier and Girolami, Mark},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5373--5382},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xi18a/xi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xi18a.html},\n  abstract = \t {Bayesian probabilistic numerical methods are a set of tools providing posterior distributions on the output of numerical methods. The use of these methods is usually motivated by the fact that they can represent our uncertainty due to incomplete/finite information about the continuous mathematical problem being approximated. In this paper, we demonstrate that this paradigm can provide additional advantages, such as the possibility of transferring information between several numerical methods. This allows users to represent uncertainty in a more faithful manner and, as a by-product, provide increased numerical efficiency. We propose the first such numerical method by extending the well-known Bayesian quadrature algorithm to the case where we are interested in computing the integral of several related functions. We then prove convergence rates for the method in the well-specified and misspecified cases, and demonstrate its efficiency in the context of multi-fidelity models for complex engineering systems and a problem of global illumination in computer graphics.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xi18a/xi18a.pdf",
        "supp": "",
        "pdf_size": 1327841,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12349734568256006214&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Mathematics, Imperial College London + Department of Statistics, University of Warwick + The Alan Turing Institute for Data Science and AI; Department of Mathematics, Imperial College London + Department of Statistics, University of Warwick + The Alan Turing Institute for Data Science and AI; Department of Mathematics, Imperial College London + Department of Statistics, University of Warwick + The Alan Turing Institute for Data Science and AI",
        "aff_domain": "imperial.ac.uk;warwick.ac.uk;imperial.ac.uk",
        "email": "imperial.ac.uk;warwick.ac.uk;imperial.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/xi18a.html",
        "aff_unique_index": "0+1+2;0+1+2;0+1+2",
        "aff_unique_norm": "Imperial College London;University of Warwick;Alan Turing Institute",
        "aff_unique_dep": "Department of Mathematics;Department of Statistics;Data Science and AI",
        "aff_unique_url": "https://www.imperial.ac.uk;https://warwick.ac.uk;https://turing.ac.uk",
        "aff_unique_abbr": "Imperial;Warwick;ATI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0+0+0;0+0+0;0+0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Bayesian Uncertainty Estimation for Batch Normalized Deep Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2039",
        "id": "2039",
        "author_site": "Mattias Teye, Hossein Azizpour, Kevin Smith",
        "author": "Mattias Teye; Hossein Azizpour; Kevin Smith",
        "abstract": "We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models. We further demonstrate that this finding allows us to make meaningful estimates of the model uncertainty using conventional architectures, without modifications to the network or the training procedure. Our approach is thoroughly validated by measuring the quality of uncertainty in a series of empirical experiments on different tasks. It outperforms baselines with strong statistical significance, and displays competitive performance with recent Bayesian approaches.",
        "bibtex": "@InProceedings{pmlr-v80-teye18a,\n  title = \t {{B}ayesian Uncertainty Estimation for Batch Normalized Deep Networks},\n  author =       {Teye, Mattias and Azizpour, Hossein and Smith, Kevin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4907--4916},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/teye18a/teye18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/teye18a.html},\n  abstract = \t {We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models. We further demonstrate that this finding allows us to make meaningful estimates of the model uncertainty using conventional architectures, without modifications to the network or the training procedure. Our approach is thoroughly validated by measuring the quality of uncertainty in a series of empirical experiments on different tasks. It outperforms baselines with strong statistical significance, and displays competitive performance with recent Bayesian approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/teye18a/teye18a.pdf",
        "supp": "",
        "pdf_size": 1073845,
        "gs_citation": 309,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17902835651299889830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden + Electronic Arts, SEED, Stockholm, Sweden; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Science for Life Laboratory",
        "aff_domain": "kth.se;kth.se;kth.se",
        "email": "kth.se;kth.se;kth.se",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/teye18a.html",
        "aff_unique_index": "0+1;0;2",
        "aff_unique_norm": "KTH Royal Institute of Technology;Electronic Arts;Science for Life Laboratory",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;SEED;",
        "aff_unique_url": "https://www.kth.se;https://www.ea.com;https://www.scilifelab.se",
        "aff_unique_abbr": "KTH;EA;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stockholm;",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "title": "Been There, Done That: Meta-Learning with Episodic Recall",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2252",
        "id": "2252",
        "author_site": "Samuel Ritter, Jane Wang, Zeb Kurth-Nelson, Siddhant Jayakumar, Charles Blundell, Razvan Pascanu, Matthew Botvinick",
        "author": "Samuel Ritter; Jane Wang; Zeb Kurth-Nelson; Siddhant Jayakumar; Charles Blundell; Razvan Pascanu; Matthew Botvinick",
        "abstract": "Meta-learning agents excel at rapidly learning new tasks from open-ended task distributions; yet, they forget what they learn about each task as soon as the next begins. When tasks reoccur {\u2013} as they do in natural environments {\u2013} meta-learning agents must explore again instead of immediately exploiting previously discovered solutions. We propose a formalism for generating open-ended yet repetitious environments, then develop a meta-learning architecture for solving these environments. This architecture melds the standard LSTM working memory with a differentiable neural episodic memory. We explore the capabilities of agents with this episodic LSTM in five meta-learning environments with reoccurring tasks, ranging from bandits to navigation and stochastic sequential decision problems.",
        "bibtex": "@InProceedings{pmlr-v80-ritter18a,\n  title = \t {Been There, Done That: Meta-Learning with Episodic Recall},\n  author =       {Ritter, Samuel and Wang, Jane and Kurth-Nelson, Zeb and Jayakumar, Siddhant and Blundell, Charles and Pascanu, Razvan and Botvinick, Matthew},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4354--4363},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ritter18a/ritter18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ritter18a.html},\n  abstract = \t {Meta-learning agents excel at rapidly learning new tasks from open-ended task distributions; yet, they forget what they learn about each task as soon as the next begins. When tasks reoccur {\u2013} as they do in natural environments {\u2013} meta-learning agents must explore again instead of immediately exploiting previously discovered solutions. We propose a formalism for generating open-ended yet repetitious environments, then develop a meta-learning architecture for solving these environments. This architecture melds the standard LSTM working memory with a differentiable neural episodic memory. We explore the capabilities of agents with this episodic LSTM in five meta-learning environments with reoccurring tasks, ranging from bandits to navigation and stochastic sequential decision problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ritter18a/ritter18a.pdf",
        "supp": "",
        "pdf_size": 1323092,
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9549897005198634962&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "DeepMind, London, UK+Princeton Neuroscience Institute, Princeton, NJ; DeepMind, London, UK; DeepMind, London, UK+MPS-UCL Centre for Computational Psychiatry, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK+Gatsby Computational Neuroscience Unit, UCL, London, UK",
        "aff_domain": "google.com; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/ritter18a.html",
        "aff_unique_index": "0+1;0;0+2;0;0;0;0+2",
        "aff_unique_norm": "DeepMind;Princeton University;University College London",
        "aff_unique_dep": ";Princeton Neuroscience Institute;Centre for Computational Psychiatry",
        "aff_unique_url": "https://deepmind.com;https://www.princeton.edu;https://www.ucl.ac.uk",
        "aff_unique_abbr": "DeepMind;Princeton;UCL",
        "aff_campus_unique_index": "0+1;0;0+0;0;0;0;0+0",
        "aff_campus_unique": "London;Princeton",
        "aff_country_unique_index": "0+1;0;0+0;0;0;0;0+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Best Arm Identification in Linear Bandits with Linear Dimension Dependency",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1983",
        "id": "1983",
        "author_site": "Chao Tao, Sa\u00fal A. Blanco, Yuan Zhou",
        "author": "Chao Tao; Sa\u00fal Blanco; Yuan Zhou",
        "abstract": "We study the best arm identification problem in linear bandits, where the mean reward of each arm depends linearly on an unknown $d$-dimensional parameter vector $\\theta$, and the goal is to identify the arm with the largest expected reward. We first design and analyze a novel randomized $\\theta$ estimator based on the solution to the convex relaxation of an optimal $G$-allocation experiment design problem. Using this estimator, we describe an algorithm whose sample complexity depends linearly on the dimension $d$, as well as an algorithm with sample complexity dependent on the reward gaps of the best $d$ arms, matching the lower bound arising from the ordinary top-arm identification problem. We finally compare the empirical performance of our algorithms with other state-of-the-art algorithms in terms of both sample complexity and computational time.",
        "bibtex": "@InProceedings{pmlr-v80-tao18a,\n  title = \t {Best Arm Identification in Linear Bandits with Linear Dimension Dependency},\n  author =       {Tao, Chao and Blanco, Sa{\\'u}l and Zhou, Yuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4877--4886},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tao18a/tao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tao18a.html},\n  abstract = \t {We study the best arm identification problem in linear bandits, where the mean reward of each arm depends linearly on an unknown $d$-dimensional parameter vector $\\theta$, and the goal is to identify the arm with the largest expected reward. We first design and analyze a novel randomized $\\theta$ estimator based on the solution to the convex relaxation of an optimal $G$-allocation experiment design problem. Using this estimator, we describe an algorithm whose sample complexity depends linearly on the dimension $d$, as well as an algorithm with sample complexity dependent on the reward gaps of the best $d$ arms, matching the lower bound arising from the ordinary top-arm identification problem. We finally compare the empirical performance of our algorithms with other state-of-the-art algorithms in terms of both sample complexity and computational time.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tao18a/tao18a.pdf",
        "supp": "",
        "pdf_size": 612495,
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6756749867328494216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Indiana University at Bloomington, Indiana, USA+Institute for Theoretical Computer Science, Shanghai University of Finance and Economics, Shanghai, China+Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Illinois, USA; Department of Computer Science, Indiana University at Bloomington, Indiana, USA; Department of Computer Science, Indiana University at Bloomington, Indiana, USA+Institute for Theoretical Computer Science, Shanghai University of Finance and Economics, Shanghai, China+Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Illinois, USA",
        "aff_domain": "iu.edu; ;iu.edu",
        "email": "iu.edu; ;iu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/tao18a.html",
        "aff_unique_index": "0+1+2;0;0+1+2",
        "aff_unique_norm": "Indiana University;Shanghai University of Finance and Economics;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science;Institute for Theoretical Computer Science;Department of Industrial and Enterprise Systems Engineering",
        "aff_unique_url": "https://www.indiana.edu;http://www.sufe.edu.cn;https://illinois.edu",
        "aff_unique_abbr": "IU;SUFE;UIUC",
        "aff_campus_unique_index": "0+1+2;0;0+1+2",
        "aff_campus_unique": "Bloomington;Shanghai;Urbana-Champaign",
        "aff_country_unique_index": "0+1+0;0;0+1+0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2040",
        "id": "2040",
        "author_site": "Ashkan Norouzi-Fard, Jakub Tarnawski, Slobodan Mitrovic, Amir Zandieh, Aidasadat Mousavifar, Ola Svensson",
        "author": "Ashkan Norouzi-Fard; Jakub Tarnawski; Slobodan Mitrovic; Amir Zandieh; Aidasadat Mousavifar; Ola Svensson",
        "abstract": "Many tasks in machine learning and data mining, such as data diversification, non-parametric learning, kernel machines, clustering etc., require extracting a small but representative summary from a massive dataset. Often, such problems can be posed as maximizing a submodular set function subject to a cardinality constraint. We consider this question in the streaming setting, where elements arrive over time at a fast pace and thus we need to design an efficient, low-memory algorithm. One such method, proposed by Badanidiyuru et al. (2014), always finds a 0.5-approximate solution. Can this approximation factor be improved? We answer this question affirmatively by designing a new algorithm Salsa for streaming submodular maximization. It is the first low-memory, singlepass algorithm that improves the factor 0.5, under the natural assumption that elements arrive in a random order. We also show that this assumption is necessary, i.e., that there is no such algorithm with better than 0.5-approximation when elements arrive in arbitrary order. Our experiments demonstrate that Salsa significantly outperforms the state of the art in applications related to exemplar-based clustering, social graph analysis, and recommender systems.",
        "bibtex": "@InProceedings{pmlr-v80-norouzi-fard18a,\n  title = \t {Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams},\n  author =       {Norouzi-Fard, Ashkan and Tarnawski, Jakub and Mitrovic, Slobodan and Zandieh, Amir and Mousavifar, Aidasadat and Svensson, Ola},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3829--3838},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/norouzi-fard18a/norouzi-fard18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/norouzi-fard18a.html},\n  abstract = \t {Many tasks in machine learning and data mining, such as data diversification, non-parametric learning, kernel machines, clustering etc., require extracting a small but representative summary from a massive dataset. Often, such problems can be posed as maximizing a submodular set function subject to a cardinality constraint. We consider this question in the streaming setting, where elements arrive over time at a fast pace and thus we need to design an efficient, low-memory algorithm. One such method, proposed by Badanidiyuru et al. (2014), always finds a 0.5-approximate solution. Can this approximation factor be improved? We answer this question affirmatively by designing a new algorithm Salsa for streaming submodular maximization. It is the first low-memory, singlepass algorithm that improves the factor 0.5, under the natural assumption that elements arrive in a random order. We also show that this assumption is necessary, i.e., that there is no such algorithm with better than 0.5-approximation when elements arrive in arbitrary order. Our experiments demonstrate that Salsa significantly outperforms the state of the art in applications related to exemplar-based clustering, social graph analysis, and recommender systems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/norouzi-fard18a/norouzi-fard18a.pdf",
        "supp": "",
        "pdf_size": 298996,
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1059100013993748033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Theory of Computation Laboratory, EPFL, Lausanne, Vaud, Switzerland; Theory of Computation Laboratory, EPFL, Lausanne, Vaud, Switzerland; Theory of Computation Laboratory, EPFL, Lausanne, Vaud, Switzerland; Theory of Computation Laboratory, EPFL, Lausanne, Vaud, Switzerland; Theory of Computation Laboratory, EPFL, Lausanne, Vaud, Switzerland; Theory of Computation Laboratory, EPFL, Lausanne, Vaud, Switzerland",
        "aff_domain": "gmail.com; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/norouzi-fard18a.html",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne (EPFL)",
        "aff_unique_dep": "Theory of Computation Laboratory",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1935",
        "id": "1935",
        "author_site": "Yiping Lu, Aoxiao Zhong, Quanzheng Li, Bin Dong",
        "author": "Yiping Lu; Aoxiao Zhong; Quanzheng Li; Bin Dong",
        "abstract": "Deep neural networks have become the state-of-the-art models in numerous machine learning tasks. However, general guidance to network architecture design is still missing. In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multi-step method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress (>50%) the original networks while maintaining a similar performance. This can be explained mathematically using the concept of modified equation from numerical analysis. Last but not least, we also establish a connection between stochastic control and noise injection in the training process which helps to improve generalization of the networks. Furthermore, by relating stochastic training strategy with stochastic dynamic system, we can easily apply stochastic training to the networks with the LM-architecture. As an example, we introduced stochastic depth to LM-ResNet and achieve significant improvement over the original LM-ResNet on CIFAR10.",
        "bibtex": "@InProceedings{pmlr-v80-lu18d,\n  title = \t {Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations},\n  author =       {Lu, Yiping and Zhong, Aoxiao and Li, Quanzheng and Dong, Bin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3276--3285},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lu18d/lu18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lu18d.html},\n  abstract = \t {Deep neural networks have become the state-of-the-art models in numerous machine learning tasks. However, general guidance to network architecture design is still missing. In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multi-step method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress (>50%) the original networks while maintaining a similar performance. This can be explained mathematically using the concept of modified equation from numerical analysis. Last but not least, we also establish a connection between stochastic control and noise injection in the training process which helps to improve generalization of the networks. Furthermore, by relating stochastic training strategy with stochastic dynamic system, we can easily apply stochastic training to the networks with the LM-architecture. As an example, we introduced stochastic depth to LM-ResNet and achieve significant improvement over the original LM-ResNet on CIFAR10.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lu18d/lu18d.pdf",
        "supp": "",
        "pdf_size": 875703,
        "gs_citation": 677,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15552677819794260504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "School of Mathematical Sciences, Peking University, Beijing, China+Beijing International Center for Mathematical Research, Peking University+Center for Data Science, Peking University; MGH/BWH Center for Clinical Data Science, Massachusetts General Hospital, Harvard Medical School+Center for Data Science in Health and Medicine, Peking University+Laboratory for Biomedical Image Analysis, Beijing Institute of Big Data Research; MGH/BWH Center for Clinical Data Science, Massachusetts General Hospital, Harvard Medical School+Center for Data Science in Health and Medicine, Peking University+Laboratory for Biomedical Image Analysis, Beijing Institute of Big Data Research; School of Mathematical Sciences, Peking University, Beijing, China+Beijing International Center for Mathematical Research, Peking University+Center for Data Science, Peking University",
        "aff_domain": "math.pku.edu.cn;mgh.harvard.edu; ; ",
        "email": "math.pku.edu.cn;mgh.harvard.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/lu18d.html",
        "aff_unique_index": "0+0+0;1+0+2;1+0+2;0+0+0",
        "aff_unique_norm": "Peking University;Massachusetts General Hospital;Beijing Institute of Big Data Research",
        "aff_unique_dep": "School of Mathematical Sciences;Center for Clinical Data Science;Laboratory for Biomedical Image Analysis",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.massgeneral.org;",
        "aff_unique_abbr": "PKU;MGH;",
        "aff_campus_unique_index": "0+0+0;;;0+0+0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0+0+0;1+0+0;1+0+0;0+0+0",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Beyond the One-Step Greedy Approach in Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2126",
        "id": "2126",
        "author_site": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor",
        "author": "Yonathan Efroni; Gal Dalal; Bruno Scherrer; Shie Mannor",
        "abstract": "The famous Policy Iteration algorithm alternates between policy improvement and policy evaluation. Implementations of this algorithm with several variants of the latter evaluation stage, e.g, n-step and trace-based returns, have been analyzed in previous works. However, the case of multiple-step lookahead policy improvement, despite the recent increase in empirical evidence of its strength, has to our knowledge not been carefully analyzed yet. In this work, we introduce the first such analysis. Namely, we formulate variants of multiple-step policy improvement, derive new algorithms using these definitions and prove their convergence. Moreover, we show that recent prominent Reinforcement Learning algorithms are, in fact, instances of our framework. We thus shed light on their empirical success and give a recipe for deriving new algorithms for future study.",
        "bibtex": "@InProceedings{pmlr-v80-efroni18a,\n  title = \t {Beyond the One-Step Greedy Approach in Reinforcement Learning},\n  author =       {Efroni, Yonathan and Dalal, Gal and Scherrer, Bruno and Mannor, Shie},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1387--1396},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/efroni18a/efroni18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/efroni18a.html},\n  abstract = \t {The famous Policy Iteration algorithm alternates between policy improvement and policy evaluation. Implementations of this algorithm with several variants of the latter evaluation stage, e.g, n-step and trace-based returns, have been analyzed in previous works. However, the case of multiple-step lookahead policy improvement, despite the recent increase in empirical evidence of its strength, has to our knowledge not been carefully analyzed yet. In this work, we introduce the first such analysis. Namely, we formulate variants of multiple-step policy improvement, derive new algorithms using these definitions and prove their convergence. Moreover, we show that recent prominent Reinforcement Learning algorithms are, in fact, instances of our framework. We thus shed light on their empirical success and give a recipe for deriving new algorithms for future study.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/efroni18a/efroni18a.pdf",
        "supp": "",
        "pdf_size": 2514572,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5555844098652005613&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Technion, Israel Institute of Technology; Technion, Israel Institute of Technology; INRIA, Villers-l\u00e8s-Nancy, F-54600, France; Technion, Israel Institute of Technology",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/efroni18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Israel Institute of Technology;INRIA",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.inria.fr",
        "aff_unique_abbr": "Technion;INRIA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Villers-l\u00e8s-Nancy",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Israel;France"
    },
    {
        "title": "Bilevel Programming for Hyperparameter Optimization and Meta-Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2248",
        "id": "2248",
        "author_site": "Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, Massimiliano Pontil",
        "author": "Luca Franceschi; Paolo Frasconi; Saverio Salzo; Riccardo Grazzi; Massimiliano Pontil",
        "abstract": "We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",
        "bibtex": "@InProceedings{pmlr-v80-franceschi18a,\n  title = \t {Bilevel Programming for Hyperparameter Optimization and Meta-Learning},\n  author =       {Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimiliano},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1568--1577},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/franceschi18a/franceschi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/franceschi18a.html},\n  abstract = \t {We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/franceschi18a/franceschi18a.pdf",
        "supp": "",
        "pdf_size": 1821704,
        "gs_citation": 932,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15127061716021225902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy+Department of Computer Science, University College London, London, UK; Department of Information Engineering, Universit `a degli Studi di Firenze, Florence, Italy; Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy; Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy; Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, Italy+Department of Computer Science, University College London, London, UK",
        "aff_domain": "iit.it; ; ; ; ",
        "email": "iit.it; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/franceschi18a.html",
        "aff_unique_index": "0+1;2;0;0;0+1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;University College London;Universit\u00e0 degli Studi di Firenze",
        "aff_unique_dep": "Computational Statistics and Machine Learning;Department of Computer Science;Department of Information Engineering",
        "aff_unique_url": "https://www.iit.it;https://www.ucl.ac.uk;https://www.unifi.it",
        "aff_unique_abbr": "IIT;UCL;",
        "aff_campus_unique_index": "0+1;2;0;0;0+1",
        "aff_campus_unique": "Genoa;London;Florence",
        "aff_country_unique_index": "0+1;0;0;0;0+1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "title": "Binary Classification with Karmic, Threshold-Quasi-Concave Metrics",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2232",
        "id": "2232",
        "author_site": "Bowei Yan, Sanmi Koyejo, Kai Zhong, Pradeep Ravikumar",
        "author": "Bowei Yan; Sanmi Koyejo; Kai Zhong; Pradeep Ravikumar",
        "abstract": "Complex performance measures, beyond the popular measure of accuracy, are increasingly being used in the context of binary classification. These complex performance measures are typically not even decomposable, that is, the loss evaluated on a batch of samples cannot typically be expressed as a sum or average of losses evaluated at individual samples, which in turn requires new theoretical and methodological developments beyond standard treatments of supervised learning. In this paper, we advance this understanding of binary classification for complex performance measures by identifying two key properties: a so-called Karmic property, and a more technical threshold-quasi-concavity property, which we show is milder than existing structural assumptions imposed on performance measures. Under these properties, we show that the Bayes optimal classifier is a threshold function of the conditional probability of positive class. We then leverage this result to come up with a computationally practical plug-in classifier, via a novel threshold estimator, and further, provide a novel statistical analysis of classification error with respect to complex performance measures.",
        "bibtex": "@InProceedings{pmlr-v80-yan18b,\n  title = \t {Binary Classification with Karmic, Threshold-Quasi-Concave Metrics},\n  author =       {Yan, Bowei and Koyejo, Sanmi and Zhong, Kai and Ravikumar, Pradeep},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5531--5540},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yan18b/yan18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yan18b.html},\n  abstract = \t {Complex performance measures, beyond the popular measure of accuracy, are increasingly being used in the context of binary classification. These complex performance measures are typically not even decomposable, that is, the loss evaluated on a batch of samples cannot typically be expressed as a sum or average of losses evaluated at individual samples, which in turn requires new theoretical and methodological developments beyond standard treatments of supervised learning. In this paper, we advance this understanding of binary classification for complex performance measures by identifying two key properties: a so-called Karmic property, and a more technical threshold-quasi-concavity property, which we show is milder than existing structural assumptions imposed on performance measures. Under these properties, we show that the Bayes optimal classifier is a threshold function of the conditional probability of positive class. We then leverage this result to come up with a computationally practical plug-in classifier, via a novel threshold estimator, and further, provide a novel statistical analysis of classification error with respect to complex performance measures.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yan18b/yan18b.pdf",
        "supp": "",
        "pdf_size": 347183,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2998449770537228393&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Texas at Austin; University of Illinois at Urbana-Champaign; University of Texas at Austin; Carnegie Mellon University",
        "aff_domain": "utexas.edu; ; ; ",
        "email": "utexas.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/yan18b.html",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Texas at Austin;University of Illinois Urbana-Champaign;Carnegie Mellon University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.utexas.edu;https://illinois.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UT Austin;UIUC;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Austin;Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Binary Partitions with Approximate Minimum Impurity",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1929",
        "id": "1929",
        "author_site": "Eduardo Laber, Marco Molinaro, Felipe de A. Mello Pereira",
        "author": "Eduardo Laber; Marco Molinaro; Felipe Mello Pereira",
        "abstract": "The problem of splitting attributes is one of the main steps in the construction of decision trees. In order to decide the best split, impurity measures such as Entropy and Gini are widely used. In practice, decision-tree inducers use heuristics for finding splits with small impurity when they consider nominal attributes with a large number of distinct values. However, there are no known guarantees for the quality of the splits obtained by these heuristics. To fill this gap, we propose two new splitting procedures that provably achieve near-optimal impurity. We also report experiments that provide evidence that the proposed methods are interesting candidates to be employed in splitting nominal attributes with many values during decision tree/random forest induction.",
        "bibtex": "@InProceedings{pmlr-v80-laber18a,\n  title = \t {Binary Partitions with Approximate Minimum Impurity},\n  author =       {Laber, Eduardo and Molinaro, Marco and Pereira, Felipe Mello},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2854--2862},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/laber18a/laber18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/laber18a.html},\n  abstract = \t {The problem of splitting attributes is one of the main steps in the construction of decision trees. In order to decide the best split, impurity measures such as Entropy and Gini are widely used. In practice, decision-tree inducers use heuristics for finding splits with small impurity when they consider nominal attributes with a large number of distinct values. However, there are no known guarantees for the quality of the splits obtained by these heuristics. To fill this gap, we propose two new splitting procedures that provably achieve near-optimal impurity. We also report experiments that provide evidence that the proposed methods are interesting candidates to be employed in splitting nominal attributes with many values during decision tree/random forest induction.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/laber18a/laber18a.pdf",
        "supp": "",
        "pdf_size": 351381,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3365862633694024958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Departamento de Inform\u00e1tica, PUC-RIO, Brazil; Departamento de Inform\u00e1tica, PUC-RIO, Brazil; Departamento de Inform\u00e1tica, PUC-RIO, Brazil",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/laber18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Pontif\u00edcia Universidade Cat\u00f3lica do Rio de Janeiro",
        "aff_unique_dep": "Departamento de Inform\u00e1tica",
        "aff_unique_url": "https://www.puc-rio.br",
        "aff_unique_abbr": "PUC-RIO",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rio de Janeiro",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "title": "Black Box FDR",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1954",
        "id": "1954",
        "author_site": "Wesley Tansey, Yixin Wang, David Blei, Raul Rabadan",
        "author": "Wesley Tansey; Yixin Wang; David Blei; Raul Rabadan",
        "abstract": "Analyzing large-scale, multi-experiment studies requires scientists to test each experimental outcome for statistical significance and then assess the results as a whole. We present Black Box FDR (BB-FDR), an empirical-Bayes method for analyzing multi-experiment studies when many covariates are gathered per experiment. BB-FDR learns a series of black box predictive models to boost power and control the false discovery rate (FDR) at two stages of study analysis. In Stage 1, it uses a deep neural network prior to report which experiments yielded significant outcomes. In Stage 2, a separate black box model of each covariate is used to select features that have significant predictive power across all experiments. In benchmarks, BB-FDR outperforms competing state-of-the-art methods in both stages of analysis. We apply BB-FDR to two real studies on cancer drug efficacy. For both studies, BB-FDR increases the proportion of significant outcomes discovered and selects variables that reveal key genomic drivers of drug sensitivity and resistance in cancer.",
        "bibtex": "@InProceedings{pmlr-v80-tansey18a,\n  title = \t {Black Box {FDR}},\n  author =       {Tansey, Wesley and Wang, Yixin and Blei, David and Rabadan, Raul},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4867--4876},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tansey18a/tansey18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tansey18a.html},\n  abstract = \t {Analyzing large-scale, multi-experiment studies requires scientists to test each experimental outcome for statistical significance and then assess the results as a whole. We present Black Box FDR (BB-FDR), an empirical-Bayes method for analyzing multi-experiment studies when many covariates are gathered per experiment. BB-FDR learns a series of black box predictive models to boost power and control the false discovery rate (FDR) at two stages of study analysis. In Stage 1, it uses a deep neural network prior to report which experiments yielded significant outcomes. In Stage 2, a separate black box model of each covariate is used to select features that have significant predictive power across all experiments. In benchmarks, BB-FDR outperforms competing state-of-the-art methods in both stages of analysis. We apply BB-FDR to two real studies on cancer drug efficacy. For both studies, BB-FDR increases the proportion of significant outcomes discovered and selects variables that reveal key genomic drivers of drug sensitivity and resistance in cancer.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tansey18a/tansey18a.pdf",
        "supp": "",
        "pdf_size": 5873494,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13943942726932532738&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Data Science Institute, Columbia University, New York, NY, USA+Department of Systems Biology, Columbia University Medical Center, New York, NY, USA+Department of Statistics, Columbia University, New York, NY, USA+Department of Computer Science, Columbia University, New York, NY, USA; Data Science Institute, Columbia University, New York, NY, USA+Department of Statistics, Columbia University, New York, NY, USA+Department of Computer Science, Columbia University, New York, NY, USA; Data Science Institute, Columbia University, New York, NY, USA+Department of Statistics, Columbia University, New York, NY, USA+Department of Computer Science, Columbia University, New York, NY, USA; Department of Systems Biology, Columbia University Medical Center, New York, NY, USA",
        "aff_domain": "columbia.edu; ; ; ",
        "email": "columbia.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/tansey18a.html",
        "aff_unique_index": "0+1+0+0;0+0+0;0+0+0;1",
        "aff_unique_norm": "Columbia University;Columbia University Medical Center",
        "aff_unique_dep": "Data Science Institute;Department of Systems Biology",
        "aff_unique_url": "https://www.columbia.edu;https://cumc.columbia.edu",
        "aff_unique_abbr": "Columbia;CUMC",
        "aff_campus_unique_index": "0+0+0+0;0+0+0;0+0+0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0+0+0+0;0+0+0;0+0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Black-Box Variational Inference for Stochastic Differential Equations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2034",
        "id": "2034",
        "author_site": "Tom Ryder, Andrew Golightly, Stephen McGough, Dennis Prangle",
        "author": "Tom Ryder; Andrew Golightly; A. Stephen McGough; Dennis Prangle",
        "abstract": "Parameter inference for stochastic differential equations is challenging due to the presence of a latent diffusion process. Working with an Euler-Maruyama discretisation for the diffusion, we use variational inference to jointly learn the parameters and the diffusion paths. We use a standard mean-field variational approximation of the parameter posterior, and introduce a recurrent neural network to approximate the posterior for the diffusion paths conditional on the parameters. This neural network learns how to provide Gaussian state transitions which bridge between observations in a very similar way to the conditioned diffusion process. The resulting black-box inference method can be applied to any SDE system with light tuning requirements. We illustrate the method on a Lotka-Volterra system and an epidemic model, producing accurate parameter estimates in a few hours.",
        "bibtex": "@InProceedings{pmlr-v80-ryder18a,\n  title = \t {Black-Box Variational Inference for Stochastic Differential Equations},\n  author =       {Ryder, Tom and Golightly, Andrew and McGough, A. Stephen and Prangle, Dennis},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4423--4432},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ryder18a/ryder18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ryder18a.html},\n  abstract = \t {Parameter inference for stochastic differential equations is challenging due to the presence of a latent diffusion process. Working with an Euler-Maruyama discretisation for the diffusion, we use variational inference to jointly learn the parameters and the diffusion paths. We use a standard mean-field variational approximation of the parameter posterior, and introduce a recurrent neural network to approximate the posterior for the diffusion paths conditional on the parameters. This neural network learns how to provide Gaussian state transitions which bridge between observations in a very similar way to the conditioned diffusion process. The resulting black-box inference method can be applied to any SDE system with light tuning requirements. We illustrate the method on a Lotka-Volterra system and an epidemic model, producing accurate parameter estimates in a few hours.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ryder18a/ryder18a.pdf",
        "supp": "",
        "pdf_size": 1870726,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=771102464723698631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "School of Mathematics, Statistics and Physics, Newcastle University, Newcastle, UK+School of Computing, Newcastle University, Newcastle, UK; School of Mathematics, Statistics and Physics, Newcastle University, Newcastle, UK; School of Computing, Newcastle University, Newcastle, UK; School of Mathematics, Statistics and Physics, Newcastle University, Newcastle, UK+School of Computing, Newcastle University, Newcastle, UK",
        "aff_domain": "newcastle.ac.uk; ; ;newcastle.ac.uk",
        "email": "newcastle.ac.uk; ; ;newcastle.ac.uk",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ryder18a.html",
        "aff_unique_index": "0+0;0;0;0+0",
        "aff_unique_norm": "Newcastle University",
        "aff_unique_dep": "School of Mathematics, Statistics and Physics",
        "aff_unique_url": "https://www.ncl.ac.uk",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0+0;0;0;0+0",
        "aff_campus_unique": "Newcastle",
        "aff_country_unique_index": "0+0;0;0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Black-box Adversarial Attacks with Limited Queries and Information",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2426",
        "id": "2426",
        "author_site": "Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin",
        "author": "Andrew Ilyas; Logan Engstrom; Anish Athalye; Jessy Lin",
        "abstract": "Current neural network-based classifiers are susceptible to adversarial examples even in the black-box setting, where the attacker only has query access to the model. In practice, the threat model for real-world systems is often more restrictive than the typical black-box model where the adversary can observe the full output of the network on arbitrarily many chosen inputs. We define three realistic threat models that more accurately characterize many real-world classifiers: the query-limited setting, the partial-information setting, and the label-only setting. We develop new attacks that fool classifiers under these more restrictive threat models, where previous methods would be impractical or ineffective. We demonstrate that our methods are effective against an ImageNet classifier under our proposed threat models. We also demonstrate a targeted black-box attack against a commercial classifier, overcoming the challenges of limited query access, partial information, and other practical issues to break the Google Cloud Vision API.",
        "bibtex": "@InProceedings{pmlr-v80-ilyas18a,\n  title = \t {Black-box Adversarial Attacks with Limited Queries and Information},\n  author =       {Ilyas, Andrew and Engstrom, Logan and Athalye, Anish and Lin, Jessy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2137--2146},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ilyas18a/ilyas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ilyas18a.html},\n  abstract = \t {Current neural network-based classifiers are susceptible to adversarial examples even in the black-box setting, where the attacker only has query access to the model. In practice, the threat model for real-world systems is often more restrictive than the typical black-box model where the adversary can observe the full output of the network on arbitrarily many chosen inputs. We define three realistic threat models that more accurately characterize many real-world classifiers: the query-limited setting, the partial-information setting, and the label-only setting. We develop new attacks that fool classifiers under these more restrictive threat models, where previous methods would be impractical or ineffective. We demonstrate that our methods are effective against an ImageNet classifier under our proposed threat models. We also demonstrate a targeted black-box attack against a commercial classifier, overcoming the challenges of limited query access, partial information, and other practical issues to break the Google Cloud Vision API.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ilyas18a/ilyas18a.pdf",
        "supp": "",
        "pdf_size": 3962720,
        "gs_citation": 1523,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15556405409493863238&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Massachusetts Institute of Technology+LabSix; Massachusetts Institute of Technology+LabSix; Massachusetts Institute of Technology+LabSix; Massachusetts Institute of Technology+LabSix",
        "aff_domain": "labsix.org;labsix.org;labsix.org;labsix.org",
        "email": "labsix.org;labsix.org;labsix.org;labsix.org",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ilyas18a.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "Massachusetts Institute of Technology;LabSix",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;",
        "aff_unique_abbr": "MIT;",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "title": "Blind Justice: Fairness with Encrypted Sensitive Attributes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1906",
        "id": "1906",
        "author_site": "Niki Kilbertus, Adria Gascon, Matt Kusner, Michael Veale, Krishna Gummadi, Adrian Weller",
        "author": "Niki Kilbertus; Adria Gascon; Matt Kusner; Michael Veale; Krishna Gummadi; Adrian Weller",
        "abstract": "Recent work has explored how to train machine learning models which do not discriminate against any subgroup of the population as determined by sensitive attributes such as gender or race. To avoid disparate treatment, sensitive attributes should not be considered. On the other hand, in order to avoid disparate impact, sensitive attributes must be examined, e.g., in order to learn a fair model, or to check if a given model is fair. We introduce methods from secure multi-party computation which allow us to avoid both. By encrypting sensitive attributes, we show how an outcome-based fair model may be learned, checked, or have its outputs verified and held to account, without users revealing their sensitive attributes.",
        "bibtex": "@InProceedings{pmlr-v80-kilbertus18a,\n  title = \t {Blind Justice: Fairness with Encrypted Sensitive Attributes},\n  author =       {Kilbertus, Niki and Gascon, Adria and Kusner, Matt and Veale, Michael and Gummadi, Krishna and Weller, Adrian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2630--2639},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kilbertus18a/kilbertus18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kilbertus18a.html},\n  abstract = \t {Recent work has explored how to train machine learning models which do not discriminate against any subgroup of the population as determined by sensitive attributes such as gender or race. To avoid disparate treatment, sensitive attributes should not be considered. On the other hand, in order to avoid disparate impact, sensitive attributes must be examined, e.g., in order to learn a fair model, or to check if a given model is fair. We introduce methods from secure multi-party computation which allow us to avoid both. By encrypting sensitive attributes, we show how an outcome-based fair model may be learned, checked, or have its outputs verified and held to account, without users revealing their sensitive attributes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kilbertus18a/kilbertus18a.pdf",
        "supp": "",
        "pdf_size": 785865,
        "gs_citation": 189,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7640712824806028167&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "aff": "Max Planck Institute for Intelligent Systems+University of Cambridge+The Alan Turing Institute+University of Warwick; The Alan Turing Institute+University of Warwick; The Alan Turing Institute+University of Warwick; University College London; Max Planck Institute for Software Systems; University of Cambridge+The Alan Turing Institute",
        "aff_domain": "tuebingen.mpg.de; ; ; ; ; ",
        "email": "tuebingen.mpg.de; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/kilbertus18a.html",
        "aff_unique_index": "0+1+2+3;2+3;2+3;4;5;1+2",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;University of Cambridge;Alan Turing Institute;University of Warwick;University College London;Max Planck Institute for Software Systems",
        "aff_unique_dep": "Intelligent Systems;;;;;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.cam.ac.uk;https://www.turing.ac.uk;https://www.warwick.ac.uk;https://www.ucl.ac.uk;https://www.mpi-sws.org",
        "aff_unique_abbr": "MPI-IS;Cambridge;ATI;Warwick;UCL;MPI-SWS",
        "aff_campus_unique_index": "1;;;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0+1+1+1;1+1;1+1;1;0;1+1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "title": "Born Again Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2404",
        "id": "2404",
        "author_site": "Tommaso Furlanello, Zachary Lipton, Michael Tschannen, Laurent Itti, Anima Anandkumar",
        "author": "Tommaso Furlanello; Zachary Lipton; Michael Tschannen; Laurent Itti; Anima Anandkumar",
        "abstract": "Knowledge Distillation (KD) consists of transferring \u201cknowledge\u201d from one machine learning model (the teacher) to another (the student). Commonly, the teacher is a high-capacity model with formidable performance, while the student is more compact. By transferring knowledge, one hopes to benefit from the student\u2019s compactness, without sacrificing too much performance. We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these Born-Again Networks (BANs), outperform their teachers significantly, both on computer vision and language modeling tasks. Our experiments with BANs based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate the essential components of KD, demonstrating the effect of the teacher outputs on both predicted and non-predicted classes.",
        "bibtex": "@InProceedings{pmlr-v80-furlanello18a,\n  title = \t {Born Again Neural Networks},\n  author =       {Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1607--1616},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/furlanello18a/furlanello18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/furlanello18a.html},\n  abstract = \t {Knowledge Distillation (KD) consists of transferring \u201cknowledge\u201d from one machine learning model (the teacher) to another (the student). Commonly, the teacher is a high-capacity model with formidable performance, while the student is more compact. By transferring knowledge, one hopes to benefit from the student\u2019s compactness, without sacrificing too much performance. We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these Born-Again Networks (BANs), outperform their teachers significantly, both on computer vision and language modeling tasks. Our experiments with BANs based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate the essential components of KD, demonstrating the effect of the teacher outputs on both predicted and non-predicted classes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/furlanello18a/furlanello18a.pdf",
        "supp": "",
        "pdf_size": 495806,
        "gs_citation": 1313,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7598194009838654531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/furlanello18a.html"
    },
    {
        "title": "Bounding and Counting Linear Regions of Deep Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2449",
        "id": "2449",
        "author_site": "Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam",
        "author": "Thiago Serra; Christian Tjandraatmadja; Srikumar Ramalingam",
        "abstract": "We investigate the complexity of deep neural networks (DNN) that represent piecewise linear (PWL) functions. In particular, we study the number of linear regions, i.e. pieces, that a PWL function represented by a DNN can attain, both theoretically and empirically. We present (i) tighter upper and lower bounds for the maximum number of linear regions on rectifier networks, which are exact for inputs of dimension one; (ii) a first upper bound for multi-layer maxout networks; and (iii) a first method to perform exact enumeration or counting of the number of regions by modeling the DNN with a mixed-integer linear formulation. These bounds come from leveraging the dimension of the space defining each linear region. The results also indicate that a deep rectifier network can only have more linear regions than every shallow counterpart with same number of neurons if that number exceeds the dimension of the input.",
        "bibtex": "@InProceedings{pmlr-v80-serra18b,\n  title = \t {Bounding and Counting Linear Regions of Deep Neural Networks},\n  author =       {Serra, Thiago and Tjandraatmadja, Christian and Ramalingam, Srikumar},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4558--4566},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/serra18b/serra18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/serra18b.html},\n  abstract = \t {We investigate the complexity of deep neural networks (DNN) that represent piecewise linear (PWL) functions. In particular, we study the number of linear regions, i.e. pieces, that a PWL function represented by a DNN can attain, both theoretically and empirically. We present (i) tighter upper and lower bounds for the maximum number of linear regions on rectifier networks, which are exact for inputs of dimension one; (ii) a first upper bound for multi-layer maxout networks; and (iii) a first method to perform exact enumeration or counting of the number of regions by modeling the DNN with a mixed-integer linear formulation. These bounds come from leveraging the dimension of the space defining each linear region. The results also indicate that a deep rectifier network can only have more linear regions than every shallow counterpart with same number of neurons if that number exceeds the dimension of the input.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/serra18b/serra18b.pdf",
        "supp": "",
        "pdf_size": 633380,
        "gs_citation": 347,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13037973585758872519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Carnegie Mellon University, Pittsburgh, USA; Carnegie Mellon University, Pittsburgh, USA; The University of Utah, Salt Lake City, USA",
        "aff_domain": "alumni.cmu.edu;alumni.cmu.edu;cs.utah.edu",
        "email": "alumni.cmu.edu;alumni.cmu.edu;cs.utah.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/serra18b.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Carnegie Mellon University;University of Utah",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.utah.edu",
        "aff_unique_abbr": "CMU;Utah",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Pittsburgh;Salt Lake City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Bounds on the Approximation Power of Feedforward Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2210",
        "id": "2210",
        "author_site": "Mohammad Mehrabi, Aslan Tchamkerten, MANSOOR I YOUSEFI",
        "author": "Mohammad Mehrabi; Aslan Tchamkerten; MANSOOR YOUSEFI",
        "abstract": "The approximation power of general feedforward neural networks with piecewise linear activation functions is investigated. First, lower bounds on the size of a network are established in terms of the approximation error and network depth and width. These bounds improve upon state-of-the-art bounds for certain classes of functions, such as strongly convex functions. Second, an upper bound is established on the difference of two neural networks with identical weights but different activation functions.",
        "bibtex": "@InProceedings{pmlr-v80-mehrabi18a,\n  title = \t {Bounds on the Approximation Power of Feedforward Neural Networks},\n  author =       {Mehrabi, Mohammad and Tchamkerten, Aslan and YOUSEFI, MANSOOR},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3453--3461},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mehrabi18a/mehrabi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mehrabi18a.html},\n  abstract = \t {The approximation power of general feedforward neural networks with piecewise linear activation functions is investigated. First, lower bounds on the size of a network are established in terms of the approximation error and network depth and width. These bounds improve upon state-of-the-art bounds for certain classes of functions, such as strongly convex functions. Second, an upper bound is established on the difference of two neural networks with identical weights but different activation functions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mehrabi18a/mehrabi18a.pdf",
        "supp": "",
        "pdf_size": 365092,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6683655503588789952&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical Engineering, Sharif University of Technology, Iran; Department of Communications and Electronics, Telecom ParisTech, France; Department of Communications and Electronics, Telecom ParisTech, France",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mehrabi18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Sharif University of Technology;Telecom ParisTech",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Communications and Electronics",
        "aff_unique_url": "https://www.sharif.edu;https://www.telecom-paristech.fr",
        "aff_unique_abbr": "SUT;Telecom ParisTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Iran;France"
    },
    {
        "title": "Bucket Renormalization for Approximate Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2157",
        "id": "2157",
        "author_site": "Sungsoo Ahn, Michael Chertkov, Adrian Weller, Jinwoo Shin",
        "author": "Sungsoo Ahn; Michael Chertkov; Adrian Weller; Jinwoo Shin",
        "abstract": "Probabilistic graphical models are a key tool in machine learning applications. Computing the partition function, i.e., normalizing constant, is a fundamental task of statistical inference but is generally computationally intractable, leading to extensive study of approximation methods. Iterative variational methods are a popular and successful family of approaches. However, even state of the art variational methods can return poor results or fail to converge on difficult instances. In this paper, we instead consider computing the partition function via sequential summation over variables. We develop robust approximate algorithms by combining ideas from mini-bucket elimination with tensor network and renormalization group methods from statistical physics. The resulting \u201cconvergence-free\u201d methods show good empirical performance on both synthetic and real-world benchmark models, even for difficult instances.",
        "bibtex": "@InProceedings{pmlr-v80-ahn18a,\n  title = \t {Bucket Renormalization for Approximate Inference},\n  author =       {Ahn, Sungsoo and Chertkov, Michael and Weller, Adrian and Shin, Jinwoo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {109--118},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ahn18a/ahn18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ahn18a.html},\n  abstract = \t {Probabilistic graphical models are a key tool in machine learning applications. Computing the partition function, i.e., normalizing constant, is a fundamental task of statistical inference but is generally computationally intractable, leading to extensive study of approximation methods. Iterative variational methods are a popular and successful family of approaches. However, even state of the art variational methods can return poor results or fail to converge on difficult instances. In this paper, we instead consider computing the partition function via sequential summation over variables. We develop robust approximate algorithms by combining ideas from mini-bucket elimination with tensor network and renormalization group methods from statistical physics. The resulting \u201cconvergence-free\u201d methods show good empirical performance on both synthetic and real-world benchmark models, even for difficult instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ahn18a/ahn18a.pdf",
        "supp": "",
        "pdf_size": 1827337,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11966357482221042193&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "School of Electrical Engineering, KAIST, Daejeon, South Korea; Theoretical Division, T-4 & Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, NM 87545, USA+Skolkovo Institute of Science and Technology, 143026 Moscow, Russia; University of Cambridge, UK+The Alan Turing Institute, UK; AITrics, Seoul, South Korea",
        "aff_domain": "kaist.ac.kr;lanl.gov;turing.ac.uk;kaist.ac.kr",
        "email": "kaist.ac.kr;lanl.gov;turing.ac.uk;kaist.ac.kr",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ahn18a.html",
        "aff_unique_index": "0;1+2;3+4;5",
        "aff_unique_norm": "KAIST;Los Alamos National Laboratory;Skolkovo Institute of Science and Technology;University of Cambridge;Alan Turing Institute;AITRICS",
        "aff_unique_dep": "School of Electrical Engineering;Theoretical Division, T-4 & Center for Nonlinear Studies;;;;",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.lanl.gov;https://www.skoltech.ru;https://www.cam.ac.uk;https://www.turing.ac.uk;",
        "aff_unique_abbr": "KAIST;LANL;Skoltech;Cambridge;ATI;",
        "aff_campus_unique_index": "0;1;3;4",
        "aff_campus_unique": "Daejeon;Los Alamos;;Cambridge;Seoul",
        "aff_country_unique_index": "0;1+2;3+3;0",
        "aff_country_unique": "South Korea;United States;Russian Federation;United Kingdom"
    },
    {
        "title": "Budgeted Experiment Design for Causal Structure Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2085",
        "id": "2085",
        "author_site": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Elias Bareinboim",
        "author": "AmirEmad Ghassami; Saber Salehkaleybar; Negar Kiyavash; Elias Bareinboim",
        "abstract": "We study the problem of causal structure learning when the experimenter is limited to perform at most $k$ non-adaptive experiments of size $1$. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the corresponding objective function is submodular and a greedy algorithm suffices to achieve $(1-\\frac{1}{e})$-approximation of the optimal value. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients the majority of the edges through a considerably small number of interventions.",
        "bibtex": "@InProceedings{pmlr-v80-ghassami18a,\n  title = \t {Budgeted Experiment Design for Causal Structure Learning},\n  author =       {Ghassami, AmirEmad and Salehkaleybar, Saber and Kiyavash, Negar and Bareinboim, Elias},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1724--1733},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ghassami18a/ghassami18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ghassami18a.html},\n  abstract = \t {We study the problem of causal structure learning when the experimenter is limited to perform at most $k$ non-adaptive experiments of size $1$. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the corresponding objective function is submodular and a greedy algorithm suffices to achieve $(1-\\frac{1}{e})$-approximation of the optimal value. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients the majority of the edges through a considerably small number of interventions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ghassami18a/ghassami18a.pdf",
        "supp": "",
        "pdf_size": 516799,
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15070197567351459266&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of ECE, and Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran; Department of ECE, and Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA",
        "aff_domain": "illinois.edu; ;illinois.edu; ",
        "email": "illinois.edu; ;illinois.edu; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ghassami18a.html",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Sharif University of Technology;Purdue University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Electrical Engineering;Department of Computer Science",
        "aff_unique_url": "https://illinois.edu;https://www.sharif.edu;https://www.purdue.edu",
        "aff_unique_abbr": "UIUC;SUT;Purdue",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Urbana;Tehran;West Lafayette",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Iran"
    },
    {
        "title": "Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2405",
        "id": "2405",
        "author_site": "Dong Yin, Yudong Chen, Kannan Ramchandran, Peter Bartlett",
        "author": "Dong Yin; Yudong Chen; Ramchandran Kannan; Peter Bartlett",
        "abstract": "In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures\u2014arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-yin18a,\n  title = \t {{B}yzantine-Robust Distributed Learning: Towards Optimal Statistical Rates},\n  author =       {Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5650--5659},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yin18a/yin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yin18a.html},\n  abstract = \t {In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures\u2014arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yin18a/yin18a.pdf",
        "supp": "",
        "pdf_size": 548220,
        "gs_citation": 1979,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15563848507518957094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of EECS, UC Berkeley; School of ORIE, Cornell University; Department of EECS, UC Berkeley; Department of Statistics, UC Berkeley",
        "aff_domain": "berkeley.edu; ; ; ",
        "email": "berkeley.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/yin18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Cornell University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;School of ORIE",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UC Berkeley;Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "CRAFTML, an Efficient Clustering-based Random Forest for Extreme Multi-label Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2216",
        "id": "2216",
        "author_site": "Wissam Siblini, Frank Meyer, Pascale Kuntz",
        "author": "Wissam Siblini; Pascale Kuntz; Frank Meyer",
        "abstract": "Extreme Multi-label Learning (XML) considers large sets of items described by a number of labels that can exceed one million. Tree-based methods, which hierarchically partition the problem into small scale sub-problems, are particularly promising in this context to reduce the learning/prediction complexity and to open the way to parallelization. However, the current best approaches do not exploit tree randomization which has shown its efficiency in random forests and they resort to complex partitioning strategies. To overcome these limits, we here introduce a new random forest based algorithm with a very fast partitioning approach called CRAFTML. Experimental comparisons on nine datasets from the XML literature show that it outperforms the other tree-based approaches. Moreover with a parallelized implementation reduced to five cores, it is competitive with the best state-of-the-art methods which run on one hundred-core machines.",
        "bibtex": "@InProceedings{pmlr-v80-siblini18a,\n  title = \t {{CRAFTML}, an Efficient Clustering-based Random Forest for Extreme Multi-label Learning},\n  author =       {Siblini, Wissam and Kuntz, Pascale and Meyer, Frank},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4664--4673},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/siblini18a/siblini18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/siblini18a.html},\n  abstract = \t {Extreme Multi-label Learning (XML) considers large sets of items described by a number of labels that can exceed one million. Tree-based methods, which hierarchically partition the problem into small scale sub-problems, are particularly promising in this context to reduce the learning/prediction complexity and to open the way to parallelization. However, the current best approaches do not exploit tree randomization which has shown its efficiency in random forests and they resort to complex partitioning strategies. To overcome these limits, we here introduce a new random forest based algorithm with a very fast partitioning approach called CRAFTML. Experimental comparisons on nine datasets from the XML literature show that it outperforms the other tree-based approaches. Moreover with a parallelized implementation reduced to five cores, it is competitive with the best state-of-the-art methods which run on one hundred-core machines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/siblini18a/siblini18a.pdf",
        "supp": "",
        "pdf_size": 725051,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13955512594417526835&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Computer Science Laboratory of Nantes (LS2N), France+Orange Labs Lannion, France; Computer Science Laboratory of Nantes (LS2N), France; Orange Labs Lannion, France",
        "aff_domain": "univ-nantes.fr; ; ",
        "email": "univ-nantes.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/siblini18a.html",
        "aff_unique_index": "0+1;0;1",
        "aff_unique_norm": "Computer Science Laboratory of Nantes;Orange Labs",
        "aff_unique_dep": "Computer Science;",
        "aff_unique_url": ";https://www.orangelabs.fr",
        "aff_unique_abbr": "LS2N;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Lannion",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "CRVI: Convex Relaxation for Variational Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2175",
        "id": "2175",
        "author_site": "Ghazal Fazelnia, John Paisley",
        "author": "Ghazal Fazelnia; John Paisley",
        "abstract": "We present a new technique for solving non-convex variational inference optimization problems. Variational inference is a widely used method for posterior approximation in which the inference problem is transformed into an optimization problem. For most models, this optimization is highly non-convex and so hard to solve. In this paper, we introduce a new approach to solving the variational inference optimization based on convex relaxation and semidefinite programming. Our theoretical results guarantee very tight relaxation bounds that get nearer to the global optimal solution than traditional coordinate ascent. We evaluate the performance of our approach on regression and sparse coding.",
        "bibtex": "@InProceedings{pmlr-v80-fazelnia18a,\n  title = \t {{CRVI}: Convex Relaxation for Variational Inference},\n  author =       {Fazelnia, Ghazal and Paisley, John},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1477--1485},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fazelnia18a/fazelnia18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fazelnia18a.html},\n  abstract = \t {We present a new technique for solving non-convex variational inference optimization problems. Variational inference is a widely used method for posterior approximation in which the inference problem is transformed into an optimization problem. For most models, this optimization is highly non-convex and so hard to solve. In this paper, we introduce a new approach to solving the variational inference optimization based on convex relaxation and semidefinite programming. Our theoretical results guarantee very tight relaxation bounds that get nearer to the global optimal solution than traditional coordinate ascent. We evaluate the performance of our approach on regression and sparse coding.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fazelnia18a/fazelnia18a.pdf",
        "supp": "",
        "pdf_size": 439211,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5195214518506097710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering & Data Science Institute, Columbia University, New York, USA; Department of Electrical Engineering & Data Science Institute, Columbia University, New York, USA",
        "aff_domain": "ee.columbia.edu; ",
        "email": "ee.columbia.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/fazelnia18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Electrical Engineering & Data Science Institute",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2221",
        "id": "2221",
        "author_site": "Maithra Raghu, Alexander Irpan, Jacob Andreas, Bobby Kleinberg, Quoc Le, Jon Kleinberg",
        "author": "Maithra Raghu; Alex Irpan; Jacob Andreas; Bobby Kleinberg; Quoc Le; Jon Kleinberg",
        "abstract": "Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but test for generalization, make comparisons to supervised learning, analyse multiagent play, and even develop a self play algorithm.",
        "bibtex": "@InProceedings{pmlr-v80-raghu18a,\n  title = \t {Can Deep Reinforcement Learning Solve {E}rdos-{S}elfridge-{S}pencer Games?},\n  author =       {Raghu, Maithra and Irpan, Alex and Andreas, Jacob and Kleinberg, Bobby and Le, Quoc and Kleinberg, Jon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4238--4246},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/raghu18a/raghu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/raghu18a.html},\n  abstract = \t {Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but test for generalization, make comparisons to supervised learning, analyse multiagent play, and even develop a self play algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/raghu18a/raghu18a.pdf",
        "supp": "",
        "pdf_size": 3369698,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5045759722516886464&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Google Brain+Cornell University; Google Brain; University of California, Berkeley; Cornell University; Google Brain; Cornell University",
        "aff_domain": "gmail.com; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/raghu18a.html",
        "aff_unique_index": "0+1;0;2;1;0;1",
        "aff_unique_norm": "Google;Cornell University;University of California, Berkeley",
        "aff_unique_dep": "Google Brain;;",
        "aff_unique_url": "https://brain.google.com;https://www.cornell.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Google Brain;Cornell;UC Berkeley",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Mountain View;;Berkeley",
        "aff_country_unique_index": "0+0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Candidates vs. Noises Estimation for Large Multi-Class Classification Problem",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2130",
        "id": "2130",
        "author_site": "Lei Han, Yiheng Huang, Tong Zhang",
        "author": "Lei Han; Yiheng Huang; Tong Zhang",
        "abstract": "This paper proposes a method for multi-class classification problems, where the number of classes K is large. The method, referred to as Candidates vs. Noises Estimation (CANE), selects a small subset of candidate classes and samples the remaining classes. We show that CANE is always consistent and computationally efficient. Moreover, the resulting estimator has low statistical variance approaching that of the maximum likelihood estimator, when the observed label belongs to the selected candidates with high probability. In practice, we use a tree structure with leaves as classes to promote fast beam search for candidate selection. We further apply the CANE method to estimate word probabilities in learning large neural language models. Extensive experimental results show that CANE achieves better prediction accuracy over the Noise-Contrastive Estimation (NCE), its variants and a number of the state-of-the-art tree classifiers, while it gains significant speedup compared to standard O(K) methods.",
        "bibtex": "@InProceedings{pmlr-v80-han18a,\n  title = \t {Candidates vs. Noises Estimation for Large Multi-Class Classification Problem},\n  author =       {Han, Lei and Huang, Yiheng and Zhang, Tong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1890--1899},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/han18a/han18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/han18a.html},\n  abstract = \t {This paper proposes a method for multi-class classification problems, where the number of classes K is large. The method, referred to as Candidates vs. Noises Estimation (CANE), selects a small subset of candidate classes and samples the remaining classes. We show that CANE is always consistent and computationally efficient. Moreover, the resulting estimator has low statistical variance approaching that of the maximum likelihood estimator, when the observed label belongs to the selected candidates with high probability. In practice, we use a tree structure with leaves as classes to promote fast beam search for candidate selection. We further apply the CANE method to estimate word probabilities in learning large neural language models. Extensive experimental results show that CANE achieves better prediction accuracy over the Noise-Contrastive Estimation (NCE), its variants and a number of the state-of-the-art tree classifiers, while it gains significant speedup compared to standard O(K) methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/han18a/han18a.pdf",
        "supp": "",
        "pdf_size": 588524,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17380764832938920205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China",
        "aff_domain": "tencent.com;tencent.com;tongzhang-ml.org",
        "email": "tencent.com;tencent.com;tongzhang-ml.org",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/han18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "AI Lab",
        "aff_unique_url": "https://ai.tencent.com",
        "aff_unique_abbr": "Tencent AI Lab",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Canonical Tensor Decomposition for Knowledge Base Completion",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2246",
        "id": "2246",
        "author_site": "Timothee Lacroix, Nicolas Usunier, Guillaume Obozinski",
        "author": "Timothee Lacroix; Nicolas Usunier; Guillaume Obozinski",
        "abstract": "The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem. In this light, the Canonical Tensor Decomposition (CP) seems like a natural solution; however, current implementations of CP on standard Knowledge Base Completion benchmarks are lagging behind their competitors. In this work, we attempt to understand the limits of CP for knowledge base completion. First, we motivate and test a novel regularizer, based on tensor nuclear p-norms. Then, we present a reformulation of the problem that makes it invariant to arbitrary choices in the inclusion of predicates or their reciprocals in the dataset. These two methods combined allow us to beat the current state of the art on several datasets with a CP decomposition, and obtain even better results using the more advanced ComplEx model.",
        "bibtex": "@InProceedings{pmlr-v80-lacroix18a,\n  title = \t {Canonical Tensor Decomposition for Knowledge Base Completion},\n  author =       {Lacroix, Timothee and Usunier, Nicolas and Obozinski, Guillaume},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2863--2872},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lacroix18a/lacroix18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lacroix18a.html},\n  abstract = \t {The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem. In this light, the Canonical Tensor Decomposition (CP) seems like a natural solution; however, current implementations of CP on standard Knowledge Base Completion benchmarks are lagging behind their competitors. In this work, we attempt to understand the limits of CP for knowledge base completion. First, we motivate and test a novel regularizer, based on tensor nuclear p-norms. Then, we present a reformulation of the problem that makes it invariant to arbitrary choices in the inclusion of predicates or their reciprocals in the dataset. These two methods combined allow us to beat the current state of the art on several datasets with a CP decomposition, and obtain even better results using the more advanced ComplEx model.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lacroix18a/lacroix18a.pdf",
        "supp": "",
        "pdf_size": 205240,
        "gs_citation": 500,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9542404017825528876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Facebook AI Research, Paris, France+Universit\u00e9 Paris-Est, Equipe Imagine, LIGM (UMR8049) Ecole des Ponts ParisTech Marne-la-Vall\u00e9e, France; Facebook AI Research, Paris, France; Universit\u00e9 Paris-Est, Equipe Imagine, LIGM (UMR8049) Ecole des Ponts ParisTech Marne-la-Vall\u00e9e, France",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lacroix18a.html",
        "aff_unique_index": "0+1;0;1",
        "aff_unique_norm": "Meta;Universit\u00e9 Paris-Est",
        "aff_unique_dep": "Facebook AI Research;Equipe Imagine, LIGM (UMR8049)",
        "aff_unique_url": "https://research.facebook.com;https://www.univ-Paris12.fr",
        "aff_unique_abbr": "FAIR;UPE",
        "aff_campus_unique_index": "0+1;0;1",
        "aff_campus_unique": "Paris;Marne-la-Vall\u00e9e",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Causal Bandits with Propagating Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2074",
        "id": "2074",
        "author_site": "Akihiro Yabe, Daisuke Hatano, Hanna Sumita, Shinji Ito, Naonori Kakimura, Takuro Fukunaga, Ken-ichi Kawarabayashi",
        "author": "Akihiro Yabe; Daisuke Hatano; Hanna Sumita; Shinji Ito; Naonori Kakimura; Takuro Fukunaga; Ken-ichi Kawarabayashi",
        "abstract": "Bandit is a framework for designing sequential experiments, where a learner selects an arm $A \\in \\mathcal{A}$ and obtains an observation corresponding to $A$ in each experiment. Theoretically, the tight regret lower-bound for the general bandit is polynomial with respect to the number of arms $|\\mathcal{A}|$, and thus, to overcome this bound, the bandit problem with side-information is often considered. Recently, a bandit framework over a causal graph was introduced, where the structure of the causal graph is available as side-information and the arms are identified with interventions on the causal graph. Existing algorithms for causal bandit overcame the $\\Omega(\\sqrt{|\\mathcal{A}|/T})$ simple-regret lower-bound; however, their algorithms work only when the interventions $\\mathcal{A}$ are localized around a single node (i.e., an intervention propagates only to its neighbors). We then propose a novel causal bandit algorithm for an arbitrary set of interventions, which can propagate throughout the causal graph. We also show that it achieves $O(\\sqrt{ \\gamma^*\\log(|\\mathcal{A}|T) / T})$ regret bound, where $\\gamma^*$ is determined by using a causal graph structure. In particular, if the maximum in-degree of the causal graph is a constant, then $\\gamma^* = O(N^2)$, where $N$ is the number of nodes.",
        "bibtex": "@InProceedings{pmlr-v80-yabe18a,\n  title = \t {Causal Bandits with Propagating Inference},\n  author =       {Yabe, Akihiro and Hatano, Daisuke and Sumita, Hanna and Ito, Shinji and Kakimura, Naonori and Fukunaga, Takuro and Kawarabayashi, Ken-ichi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5512--5520},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yabe18a/yabe18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yabe18a.html},\n  abstract = \t {Bandit is a framework for designing sequential experiments, where a learner selects an arm $A \\in \\mathcal{A}$ and obtains an observation corresponding to $A$ in each experiment. Theoretically, the tight regret lower-bound for the general bandit is polynomial with respect to the number of arms $|\\mathcal{A}|$, and thus, to overcome this bound, the bandit problem with side-information is often considered. Recently, a bandit framework over a causal graph was introduced, where the structure of the causal graph is available as side-information and the arms are identified with interventions on the causal graph. Existing algorithms for causal bandit overcame the $\\Omega(\\sqrt{|\\mathcal{A}|/T})$ simple-regret lower-bound; however, their algorithms work only when the interventions $\\mathcal{A}$ are localized around a single node (i.e., an intervention propagates only to its neighbors). We then propose a novel causal bandit algorithm for an arbitrary set of interventions, which can propagate throughout the causal graph. We also show that it achieves $O(\\sqrt{ \\gamma^*\\log(|\\mathcal{A}|T) / T})$ regret bound, where $\\gamma^*$ is determined by using a causal graph structure. In particular, if the maximum in-degree of the causal graph is a constant, then $\\gamma^* = O(N^2)$, where $N$ is the number of nodes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yabe18a/yabe18a.pdf",
        "supp": "",
        "pdf_size": 361753,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16642540996429874044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "NEC Corporation, Japan; RIKEN AIP, Japan; Tokyo Metropolitan University, Japan; NEC Corporation, Japan; Keio University, Japan; RIKEN AIP, Japan; National Institute of Informatics, Japan",
        "aff_domain": "cq.jp.nec.com; ; ; ; ; ; ",
        "email": "cq.jp.nec.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/yabe18a.html",
        "aff_unique_index": "0;1;2;0;3;1;4",
        "aff_unique_norm": "NEC Corporation;RIKEN AIP;Tokyo Metropolitan University;Keio University;National Institute of Informatics",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.nec.com;https://aip.Riken.jp;https://www.tmuc.ac.jp;https://www.keio.ac.jp;https://www.nii.ac.jp",
        "aff_unique_abbr": "NEC;RIKEN AIP;TMU;Keio;NII",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Celer: a Fast Solver for the Lasso with Dual Extrapolation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2132",
        "id": "2132",
        "author_site": "Mathurin MASSIAS, Joseph Salmon, Alexandre Gramfort",
        "author": "Mathurin MASSIAS; Alexandre Gramfort; Joseph Salmon",
        "abstract": "Convex sparsity-inducing regularizations are ubiquitous in high-dimensional machine learning, but solving the resulting optimization problems can be slow. To accelerate solvers, state-of-the-art approaches consist in reducing the size of the optimization problem at hand. In the context of regression, this can be achieved either by discarding irrelevant features (screening techniques) or by prioritizing features likely to be included in the support of the solution (working set techniques). Duality comes into play at several steps in these techniques. Here, we propose an extrapolation technique starting from a sequence of iterates in the dual that leads to the construction of improved dual points. This enables a tighter control of optimality as used in stopping criterion, as well as better screening performance of Gap Safe rules. Finally, we propose a working set strategy based on an aggressive use of Gap Safe screening rules. Thanks to our new dual point construction, we show significant computational speedups on multiple real-world problems.",
        "bibtex": "@InProceedings{pmlr-v80-massias18a,\n  title = \t {Celer: a Fast Solver for the Lasso with Dual Extrapolation},\n  author =       {MASSIAS, Mathurin and Gramfort, Alexandre and Salmon, Joseph},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3315--3324},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/massias18a/massias18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/massias18a.html},\n  abstract = \t {Convex sparsity-inducing regularizations are ubiquitous in high-dimensional machine learning, but solving the resulting optimization problems can be slow. To accelerate solvers, state-of-the-art approaches consist in reducing the size of the optimization problem at hand. In the context of regression, this can be achieved either by discarding irrelevant features (screening techniques) or by prioritizing features likely to be included in the support of the solution (working set techniques). Duality comes into play at several steps in these techniques. Here, we propose an extrapolation technique starting from a sequence of iterates in the dual that leads to the construction of improved dual points. This enables a tighter control of optimality as used in stopping criterion, as well as better screening performance of Gap Safe rules. Finally, we propose a working set strategy based on an aggressive use of Gap Safe screening rules. Thanks to our new dual point construction, we show significant computational speedups on multiple real-world problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/massias18a/massias18a.pdf",
        "supp": "",
        "pdf_size": 1013632,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5377261088300700033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "INRIA, Universit \u00b4e Paris-Saclay; INRIA, Universit \u00b4e Paris-Saclay; LTCI, T \u00b4el\u00b4ecom ParisTech, Universit \u00b4e Paris-Saclay",
        "aff_domain": "inria.fr; ; ",
        "email": "inria.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/massias18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "INRIA;T\u00e9l\u00e9com ParisTech",
        "aff_unique_dep": ";LTCI",
        "aff_unique_url": "https://www.inria.fr;https://www.telecom-paris.fr",
        "aff_unique_abbr": "INRIA;T\u00e9l\u00e9com ParisTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Characterizing Implicit Bias in Terms of Optimization Geometry",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2406",
        "id": "2406",
        "author_site": "Suriya Gunasekar, Jason Lee, Daniel Soudry, Nati Srebro",
        "author": "Suriya Gunasekar; Jason Lee; Daniel Soudry; Nathan Srebro",
        "abstract": "We study the bias of generic optimization methods, including Mirror Descent, Natural Gradient Descent and Steepest Descent with respect to different potentials and norms, when optimizing underdetermined linear models or separable linear classification problems. We ask the question of whether the global minimum (among the many possible global minima) reached by optimization can be characterized in terms of the potential or norm, and indecently of hyper-parameter choices, such as stepsize and momentum.",
        "bibtex": "@InProceedings{pmlr-v80-gunasekar18a,\n  title = \t {Characterizing Implicit Bias in Terms of Optimization Geometry},\n  author =       {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1832--1841},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gunasekar18a/gunasekar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gunasekar18a.html},\n  abstract = \t {We study the bias of generic optimization methods, including Mirror Descent, Natural Gradient Descent and Steepest Descent with respect to different potentials and norms, when optimizing underdetermined linear models or separable linear classification problems. We ask the question of whether the global minimum (among the many possible global minima) reached by optimization can be characterized in terms of the potential or norm, and indecently of hyper-parameter choices, such as stepsize and momentum.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gunasekar18a/gunasekar18a.pdf",
        "supp": "",
        "pdf_size": 3744728,
        "gs_citation": 522,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6245482376059821927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "TTI Chicago, USA; USC Los Angeles, USA; Technion, Israel; TTI Chicago, USA",
        "aff_domain": "ttic.edu;marshall.usc.edu;gmail.com;ttic.edu",
        "email": "ttic.edu;marshall.usc.edu;gmail.com;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/gunasekar18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Toyota Technological Institute at Chicago;University of Southern California;Technion - Israel Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://tti-chicago.org;https://www.usc.edu;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "TTI Chicago;USC;Technion",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Chicago;Los Angeles;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2097",
        "id": "2097",
        "author_site": "Karren Yang, Abigail Katoff, Caroline Uhler",
        "author": "Karren Yang; Abigail Katcoff; Caroline Uhler",
        "abstract": "We consider the problem of learning causal DAGs in the setting where both observational and interventional data is available. This setting is common in biology, where gene regulatory networks can be intervened on using chemical reagents or gene deletions. Hauser & Buhlmann (2012) previously characterized the identifiability of causal DAGs under perfect interventions, which eliminate dependencies between targeted variables and their direct causes. In this paper, we extend these identifiability results to general interventions, which may modify the dependencies between targeted variables and their causes without eliminating them. We define and characterize the interventional Markov equivalence class that can be identified from general (not necessarily perfect) intervention experiments. We also propose the first provably consistent algorithm for learning DAGs in this setting and evaluate our algorithm on simulated and biological datasets.",
        "bibtex": "@InProceedings{pmlr-v80-yang18a,\n  title = \t {Characterizing and Learning Equivalence Classes of Causal {DAG}s under Interventions},\n  author =       {Yang, Karren and Katcoff, Abigail and Uhler, Caroline},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5541--5550},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yang18a/yang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yang18a.html},\n  abstract = \t {We consider the problem of learning causal DAGs in the setting where both observational and interventional data is available. This setting is common in biology, where gene regulatory networks can be intervened on using chemical reagents or gene deletions. Hauser & Buhlmann (2012) previously characterized the identifiability of causal DAGs under perfect interventions, which eliminate dependencies between targeted variables and their direct causes. In this paper, we extend these identifiability results to general interventions, which may modify the dependencies between targeted variables and their causes without eliminating them. We define and characterize the interventional Markov equivalence class that can be identified from general (not necessarily perfect) intervention experiments. We also propose the first provably consistent algorithm for learning DAGs in this setting and evaluate our algorithm on simulated and biological datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yang18a/yang18a.pdf",
        "supp": "",
        "pdf_size": 506969,
        "gs_citation": 134,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=255785803450560924&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;mit.edu;mit.edu",
        "email": "mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/yang18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Chi-square Generative Adversarial Network",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2369",
        "id": "2369",
        "author_site": "Chenyang Tao, Liqun Chen, Ricardo Henao, Jianfeng Feng, Lawrence Carin",
        "author": "Chenyang Tao; Liqun Chen; Ricardo Henao; Jianfeng Feng; Lawrence Carin Duke",
        "abstract": "To assess the difference between real and synthetic data, Generative Adversarial Networks (GANs) are trained using a distribution discrepancy measure. Three widely employed measures are information-theoretic divergences, integral probability metrics, and Hilbert space discrepancy metrics. We elucidate the theoretical connections between these three popular GAN training criteria and propose a novel procedure, called $\\chi^2$ (Chi-square) GAN, that is conceptually simple, stable at training and resistant to mode collapse. Our procedure naturally generalizes to address the problem of simultaneous matching of multiple distributions. Further, we propose a resampling strategy that significantly improves sample quality, by repurposing the trained critic function via an importance weighting mechanism. Experiments show that the proposed procedure improves stability and convergence, and yields state-of-art results on a wide range of generative modeling tasks.",
        "bibtex": "@InProceedings{pmlr-v80-tao18b,\n  title = \t {{C}hi-square Generative Adversarial Network},\n  author =       {Tao, Chenyang and Chen, Liqun and Henao, Ricardo and Feng, Jianfeng and Duke, Lawrence Carin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4887--4896},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tao18b/tao18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tao18b.html},\n  abstract = \t {To assess the difference between real and synthetic data, Generative Adversarial Networks (GANs) are trained using a distribution discrepancy measure. Three widely employed measures are information-theoretic divergences, integral probability metrics, and Hilbert space discrepancy metrics. We elucidate the theoretical connections between these three popular GAN training criteria and propose a novel procedure, called $\\chi^2$ (Chi-square) GAN, that is conceptually simple, stable at training and resistant to mode collapse. Our procedure naturally generalizes to address the problem of simultaneous matching of multiple distributions. Further, we propose a resampling strategy that significantly improves sample quality, by repurposing the trained critic function via an importance weighting mechanism. Experiments show that the proposed procedure improves stability and convergence, and yields state-of-art results on a wide range of generative modeling tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tao18b/tao18b.pdf",
        "supp": "",
        "pdf_size": 2523308,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3560140041128352974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Electrical & Computer Engineering, Duke University, Durham, NC 27708, USA; Electrical & Computer Engineering, Duke University, Durham, NC 27708, USA; Electrical & Computer Engineering, Duke University, Durham, NC 27708, USA; ISTBI, Fudan University, Shanghai, China; Electrical & Computer Engineering, Duke University, Durham, NC 27708, USA",
        "aff_domain": "duke.edu; ; ; ; ",
        "email": "duke.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/tao18b.html",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Duke University;Fudan University",
        "aff_unique_dep": "Electrical & Computer Engineering;ISTBI",
        "aff_unique_url": "https://www.duke.edu;https://www.fudan.edu.cn/en/",
        "aff_unique_abbr": "Duke;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Durham;Shanghai",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Classification from Pairwise Similarity and Unlabeled Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2134",
        "id": "2134",
        "author_site": "Han Bao, Gang Niu, Masashi Sugiyama",
        "author": "Han Bao; Gang Niu; Masashi Sugiyama",
        "abstract": "Supervised learning needs a huge amount of labeled data, which can be a big bottleneck under the situation where there is a privacy concern or labeling cost is high. To overcome this problem, we propose a new weakly-supervised learning setting where only similar (S) data pairs (two examples belong to the same class) and unlabeled (U) data points are needed instead of fully labeled data, which is called SU classification. We show that an unbiased estimator of the classification risk can be obtained only from SU data, and the estimation error of its empirical risk minimizer achieves the optimal parametric convergence rate. Finally, we demonstrate the effectiveness of the proposed method through experiments.",
        "bibtex": "@InProceedings{pmlr-v80-bao18a,\n  title = \t {Classification from Pairwise Similarity and Unlabeled Data},\n  author =       {Bao, Han and Niu, Gang and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {452--461},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bao18a/bao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bao18a.html},\n  abstract = \t {Supervised learning needs a huge amount of labeled data, which can be a big bottleneck under the situation where there is a privacy concern or labeling cost is high. To overcome this problem, we propose a new weakly-supervised learning setting where only similar (S) data pairs (two examples belong to the same class) and unlabeled (U) data points are needed instead of fully labeled data, which is called SU classification. We show that an unbiased estimator of the classification risk can be obtained only from SU data, and the estimation error of its empirical risk minimizer achieves the optimal parametric convergence rate. Finally, we demonstrate the effectiveness of the proposed method through experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bao18a/bao18a.pdf",
        "supp": "",
        "pdf_size": 1736168,
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8079423244693933514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "The University of Tokyo, Japan+RIKEN, Japan; RIKEN, Japan; The University of Tokyo, Japan+RIKEN, Japan",
        "aff_domain": "ms.k.u-tokyo.ac.jp; ; ",
        "email": "ms.k.u-tokyo.ac.jp; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/bao18a.html",
        "aff_unique_index": "0+1;1;0+1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Clipped Action Policy Gradient",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2018",
        "id": "2018",
        "author_site": "Yasuhiro Fujita, Shin-ichi Maeda",
        "author": "Yasuhiro Fujita; Shin-ichi Maeda",
        "abstract": "Many continuous control tasks have bounded action spaces. When policy gradient methods are applied to such tasks, out-of-bound actions need to be clipped before execution, while policies are usually optimized as if the actions are not clipped. We propose a policy gradient estimator that exploits the knowledge of actions being clipped to reduce the variance in estimation. We prove that our estimator, named clipped action policy gradient (CAPG), is unbiased and achieves lower variance than the conventional estimator that ignores action bounds. Experimental results demonstrate that CAPG generally outperforms the conventional estimator, indicating that it is a better policy gradient estimator for continuous control tasks. The source code is available at https://github.com/pfnet-research/capg.",
        "bibtex": "@InProceedings{pmlr-v80-fujita18a,\n  title = \t {Clipped Action Policy Gradient},\n  author =       {Fujita, Yasuhiro and Maeda, Shin-ichi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1597--1606},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fujita18a/fujita18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fujita18a.html},\n  abstract = \t {Many continuous control tasks have bounded action spaces. When policy gradient methods are applied to such tasks, out-of-bound actions need to be clipped before execution, while policies are usually optimized as if the actions are not clipped. We propose a policy gradient estimator that exploits the knowledge of actions being clipped to reduce the variance in estimation. We prove that our estimator, named clipped action policy gradient (CAPG), is unbiased and achieves lower variance than the conventional estimator that ignores action bounds. Experimental results demonstrate that CAPG generally outperforms the conventional estimator, indicating that it is a better policy gradient estimator for continuous control tasks. The source code is available at https://github.com/pfnet-research/capg.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fujita18a/fujita18a.pdf",
        "supp": "",
        "pdf_size": 1185560,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14045811367797105459&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Preferred Networks, Inc., Japan; Preferred Networks, Inc., Japan",
        "aff_domain": "preferred.jp;preferred.jp",
        "email": "preferred.jp;preferred.jp",
        "github": "https://github.com/pfnet-research/capg",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/fujita18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Preferred Networks, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.preferred-networks.com",
        "aff_unique_abbr": "PFN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2240",
        "id": "2240",
        "author_site": "Louis Filstroff, Alberto Lumbreras, Cedric Fevotte",
        "author": "Louis Filstroff; Alberto Lumbreras; C\u00e9dric F\u00e9votte",
        "abstract": "We present novel understandings of the Gamma-Poisson (GaP) model, a probabilistic matrix factorization model for count data. We show that GaP can be rewritten free of the score/activation matrix. This gives us new insights about the estimation of the topic/dictionary matrix by maximum marginal likelihood estimation. In particular, this explains the robustness of this estimator to over-specified values of the factorization rank, especially its ability to automatically prune irrelevant dictionary columns, as empirically observed in previous work. The marginalization of the activation matrix leads in turn to a new Monte Carlo Expectation-Maximization algorithm with favorable properties.",
        "bibtex": "@InProceedings{pmlr-v80-filstroff18a,\n  title = \t {Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization},\n  author =       {Filstroff, Louis and Lumbreras, Alberto and F{\\'e}votte, C{\\'e}dric},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1506--1514},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/filstroff18a/filstroff18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/filstroff18a.html},\n  abstract = \t {We present novel understandings of the Gamma-Poisson (GaP) model, a probabilistic matrix factorization model for count data. We show that GaP can be rewritten free of the score/activation matrix. This gives us new insights about the estimation of the topic/dictionary matrix by maximum marginal likelihood estimation. In particular, this explains the robustness of this estimator to over-specified values of the factorization rank, especially its ability to automatically prune irrelevant dictionary columns, as empirically observed in previous work. The marginalization of the activation matrix leads in turn to a new Monte Carlo Expectation-Maximization algorithm with favorable properties.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/filstroff18a/filstroff18a.pdf",
        "supp": "",
        "pdf_size": 469359,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13249005912407125969&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "IRIT, Universit\u00e9 de Toulouse, CNRS, France; IRIT, Universit\u00e9 de Toulouse, CNRS, France; IRIT, Universit\u00e9 de Toulouse, CNRS, France",
        "aff_domain": "irit.fr; ; ",
        "email": "irit.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/filstroff18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 de Toulouse",
        "aff_unique_dep": "IRIT",
        "aff_unique_url": "https://www.univ-toulouse.fr",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Clustering Semi-Random Mixtures of Gaussians",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2323",
        "id": "2323",
        "author_site": "Aravindan Vijayaraghavan, Pranjal Awasthi",
        "author": "Aravindan Vijayaraghavan; Pranjal Awasthi",
        "abstract": "Gaussian mixture models (GMM) are the most widely used statistical model for the k-means clustering problem and form a popular framework for clustering in machine learning and data analysis. In this paper, we propose a natural robust model for k-means clustering that generalizes the Gaussian mixture model, and that we believe will be useful in identifying robust algorithms. Our first contribution is a polynomial time algorithm that provably recovers the ground-truth up to small classification error w.h.p., assuming certain separation between the components. Perhaps surprisingly, the algorithm we analyze is the popular Lloyd\u2019s algorithm for k-means clustering that is the method-of-choice in practice. Our second result complements the upper bound by giving a nearly matching lower bound on the number of misclassified points incurred by any k-means clustering algorithm on the semi-random model.",
        "bibtex": "@InProceedings{pmlr-v80-vijayaraghavan18a,\n  title = \t {Clustering Semi-Random Mixtures of {G}aussians},\n  author =       {Vijayaraghavan, Aravindan and Awasthi, Pranjal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5055--5064},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/vijayaraghavan18a/vijayaraghavan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/vijayaraghavan18a.html},\n  abstract = \t {Gaussian mixture models (GMM) are the most widely used statistical model for the k-means clustering problem and form a popular framework for clustering in machine learning and data analysis. In this paper, we propose a natural robust model for k-means clustering that generalizes the Gaussian mixture model, and that we believe will be useful in identifying robust algorithms. Our first contribution is a polynomial time algorithm that provably recovers the ground-truth up to small classification error w.h.p., assuming certain separation between the components. Perhaps surprisingly, the algorithm we analyze is the popular Lloyd\u2019s algorithm for k-means clustering that is the method-of-choice in practice. Our second result complements the upper bound by giving a nearly matching lower bound on the number of misclassified points incurred by any k-means clustering algorithm on the semi-random model.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/vijayaraghavan18a/vijayaraghavan18a.pdf",
        "supp": "",
        "pdf_size": 314718,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7344202073967450704&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, Rutgers University, USA; EECS Department, Northwestern University, USA",
        "aff_domain": "rutgers.edu;northwestern.edu",
        "email": "rutgers.edu;northwestern.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/vijayaraghavan18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Rutgers University;Northwestern University",
        "aff_unique_dep": "Department of Computer Science;EECS Department",
        "aff_unique_url": "https://www.rutgers.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "Rutgers;NU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "CoVeR: Learning Covariate-Specific Vector Representations with Tensor Decompositions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2309",
        "id": "2309",
        "author_site": "Kevin Tian, Teng Zhang, James Zou",
        "author": "Kevin Tian; Teng Zhang; James Zou",
        "abstract": "Word embedding is a useful approach to capture co-occurrence structures in large text corpora. However, in addition to the text data itself, we often have additional covariates associated with individual corpus documents\u2014e.g. the demographic of the author, time and venue of publication\u2014and we would like the embedding to naturally capture this information. We propose CoVeR, a new tensor decomposition model for vector embeddings with covariates. CoVeR jointly learns a",
        "bibtex": "@InProceedings{pmlr-v80-tian18a,\n  title = \t {{C}o{V}e{R}: Learning Covariate-Specific Vector Representations with Tensor Decompositions},\n  author =       {Tian, Kevin and Zhang, Teng and Zou, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4926--4935},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tian18a/tian18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tian18a.html},\n  abstract = \t {Word embedding is a useful approach to capture co-occurrence structures in large text corpora. However, in addition to the text data itself, we often have additional covariates associated with individual corpus documents\u2014e.g. the demographic of the author, time and venue of publication\u2014and we would like the embedding to naturally capture this information. We propose CoVeR, a new tensor decomposition model for vector embeddings with covariates. CoVeR jointly learns a",
        "pdf": "http://proceedings.mlr.press/v80/tian18a/tian18a.pdf",
        "supp": "",
        "pdf_size": 534576,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12802399499869833489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Stanford University; Department of Management Science and Engineering, Stanford University; Department of Biomedical Data Science, Stanford University",
        "aff_domain": "stanford.edu; ; ",
        "email": "stanford.edu; ; ",
        "github": "http://github.com/kjtian/CoVeR",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/tian18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Coded Sparse Matrix Multiplication",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1924",
        "id": "1924",
        "author_site": "Sinong Wang, Jiashang Liu, Ness Shroff",
        "author": "Sinong Wang; Jiashang Liu; Ness Shroff",
        "abstract": "In a large-scale and distributed matrix multiplication problem $C=A^{\\intercal}B$, where $C\\in\\mathbb{R}^{r\\times t}$, the coded computation plays an important role to effectively deal with \u201cstragglers\u201d (distributed computations that may get delayed due to few slow or faulty processors). However, existing coded schemes could destroy the significant sparsity that exists in large-scale machine learning problems, and could result in much higher computation overhead, i.e., $O(rt)$ decoding time. In this paper, we develop a new coded computation strategy, we call",
        "bibtex": "@InProceedings{pmlr-v80-wang18e,\n  title = \t {Coded Sparse Matrix Multiplication},\n  author =       {Wang, Sinong and Liu, Jiashang and Shroff, Ness},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5152--5160},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18e/wang18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18e.html},\n  abstract = \t {In a large-scale and distributed matrix multiplication problem $C=A^{\\intercal}B$, where $C\\in\\mathbb{R}^{r\\times t}$, the coded computation plays an important role to effectively deal with \u201cstragglers\u201d (distributed computations that may get delayed due to few slow or faulty processors). However, existing coded schemes could destroy the significant sparsity that exists in large-scale machine learning problems, and could result in much higher computation overhead, i.e., $O(rt)$ decoding time. In this paper, we develop a new coded computation strategy, we call",
        "pdf": "http://proceedings.mlr.press/v80/wang18e/wang18e.pdf",
        "supp": "",
        "pdf_size": 544388,
        "gs_citation": 153,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4705581010131613456&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of ECE, The Ohio State University, Columbus, USA; Department of ECE, The Ohio State University, Columbus, USA; Departments of ECE and CSE, The Ohio State University, Columbus, USA",
        "aff_domain": "osu.edu; ; ",
        "email": "osu.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wang18e.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Communication-Computation Efficient Gradient Coding",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1994",
        "id": "1994",
        "author_site": "Min Ye, Emmanuel Abbe",
        "author": "Min Ye; Emmanuel Abbe",
        "abstract": "This paper develops coding techniques to reduce the running time of distributed learning tasks. It characterizes the fundamental tradeoff to compute gradients in terms of three parameters: computation load, straggler tolerance and communication cost. It further gives an explicit coding scheme that achieves the optimal tradeoff based on recursive polynomial constructions, coding both across data subsets and vector components. As a result, the proposed scheme allows to minimize the running time for gradient computations. Implementations are made on Amazon EC2 clusters using Python with mpi4py package. Results show that the proposed scheme maintains the same generalization error while reducing the running time by $32%$ compared to uncoded schemes and $23%$ compared to prior coded schemes focusing only on stragglers (Tandon et al., ICML 2017).",
        "bibtex": "@InProceedings{pmlr-v80-ye18a,\n  title = \t {Communication-Computation Efficient Gradient Coding},\n  author =       {Ye, Min and Abbe, Emmanuel},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5610--5619},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ye18a/ye18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ye18a.html},\n  abstract = \t {This paper develops coding techniques to reduce the running time of distributed learning tasks. It characterizes the fundamental tradeoff to compute gradients in terms of three parameters: computation load, straggler tolerance and communication cost. It further gives an explicit coding scheme that achieves the optimal tradeoff based on recursive polynomial constructions, coding both across data subsets and vector components. As a result, the proposed scheme allows to minimize the running time for gradient computations. Implementations are made on Amazon EC2 clusters using Python with mpi4py package. Results show that the proposed scheme maintains the same generalization error while reducing the running time by $32%$ compared to uncoded schemes and $23%$ compared to prior coded schemes focusing only on stragglers (Tandon et al., ICML 2017).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ye18a/ye18a.pdf",
        "supp": "",
        "pdf_size": 437258,
        "gs_citation": 203,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3163640418206702534&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical Engineering, Princeton University; Program in Applied and Computational Mathematics and Department of Electrical Engineering, Princeton University, and the School of Mathematics, Institute for Advanced Study",
        "aff_domain": "gmail.com;princeton.edu",
        "email": "gmail.com;princeton.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/ye18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Comparing Dynamics: Deep Neural Networks versus Glassy Systems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2190",
        "id": "2190",
        "author_site": "Marco Baity-Jesi, Levent Sagun, Mario Geiger, Stefano Spigler, Gerard Arous, Chiara Cammarota, Yann LeCun, Matthieu Wyart, Giulio Biroli",
        "author": "Marco Baity-Jesi; Levent Sagun; Mario Geiger; Stefano Spigler; Gerard Ben Arous; Chiara Cammarota; Yann LeCun; Matthieu Wyart; Giulio Biroli",
        "abstract": "We analyze numerically the training dynamics of deep neural networks (DNN) by using methods developed in statistical physics of glassy systems. The two main issues we address are the complexity of the loss-landscape and of the dynamics within it, and to what extent DNNs share similarities with glassy systems. Our findings, obtained for different architectures and data-sets, suggest that during the training process the dynamics slows down because of an increasingly large number of flat directions. At large times, when the loss is approaching zero, the system diffuses at the bottom of the landscape. Despite some similarities with the dynamics of mean-field glassy systems, in particular, the absence of barrier crossing, we find distinctive dynamical behaviors in the two cases, thus showing that the statistical properties of the corresponding loss and energy landscapes are different. In contrast, when the network is under-parametrized we observe a typical glassy behavior, thus suggesting the existence of different phases depending on whether the network is under-parametrized or over-parametrized.",
        "bibtex": "@InProceedings{pmlr-v80-baity-jesi18a,\n  title = \t {Comparing Dynamics: Deep Neural Networks versus Glassy Systems},\n  author =       {Baity-Jesi, Marco and Sagun, Levent and Geiger, Mario and Spigler, Stefano and Arous, Gerard Ben and Cammarota, Chiara and LeCun, Yann and Wyart, Matthieu and Biroli, Giulio},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {314--323},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/baity-jesi18a/baity-jesi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/baity-jesi18a.html},\n  abstract = \t {We analyze numerically the training dynamics of deep neural networks (DNN) by using methods developed in statistical physics of glassy systems. The two main issues we address are the complexity of the loss-landscape and of the dynamics within it, and to what extent DNNs share similarities with glassy systems. Our findings, obtained for different architectures and data-sets, suggest that during the training process the dynamics slows down because of an increasingly large number of flat directions. At large times, when the loss is approaching zero, the system diffuses at the bottom of the landscape. Despite some similarities with the dynamics of mean-field glassy systems, in particular, the absence of barrier crossing, we find distinctive dynamical behaviors in the two cases, thus showing that the statistical properties of the corresponding loss and energy landscapes are different. In contrast, when the network is under-parametrized we observe a typical glassy behavior, thus suggesting the existence of different phases depending on whether the network is under-parametrized or over-parametrized.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/baity-jesi18a/baity-jesi18a.pdf",
        "supp": "",
        "pdf_size": 1674423,
        "gs_citation": 138,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15495075584154845496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "aff": "Department of Chemistry, Columbia University, New York, NY 10027, USA; Institut de Physique Th\u00e9orique, Universit\u00e9 Paris Saclay, CEA, CNRS, F-91191 Gif-sur-Yvette, France+EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland+Institut de Physique Th\u00e9orique, Universit\u00e9 Paris Saclay, CEA, CNRS, F-91191 Gif-sur-Yvette, France; Courant Institute of Mathematical Sciences, New York University, New York, USA; Kings College London, Department of Mathematics, Strand, London WC2R 2LS, United Kingdom; Courant Institute of Mathematical Sciences, New York University, New York, USA+Center for Data Science, New York University, New York, USA+Facebook AI Research, Facebook Inc., New York, USA; EPFL, Lausanne, Switzerland; Institut de Physique Th\u00e9orique, Universit\u00e9 Paris Saclay, CEA, CNRS, F-91191 Gif-sur-Yvette, France+Laboratoire de Physique Statistique, \u00c9cole Normale Sup\u00e9rieure, CNRS, PSL Research University, Sorbonne Universit\u00e9s, 75005 Paris, France",
        "aff_domain": "columbia.edu; ; ; ; ; ; ; ;",
        "email": "columbia.edu; ; ; ; ; ; ; ;",
        "github": "",
        "project": "",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/baity-jesi18a.html",
        "aff_unique_index": "0;1+2;2;2+1;3;4;3+3+5;2;1+6",
        "aff_unique_norm": "Columbia University;Universit\u00e9 Paris Saclay;EPFL;New York University;King's College London;Meta;\u00c9cole Normale Sup\u00e9rieure",
        "aff_unique_dep": "Department of Chemistry;Institut de Physique Th\u00e9orique;;Courant Institute of Mathematical Sciences;Department of Mathematics;Facebook AI Research;Laboratoire de Physique Statistique",
        "aff_unique_url": "https://www.columbia.edu;https://www.universite-paris-saclay.fr;https://www.epfl.ch;https://www.nyu.edu;https://www.kcl.ac.uk;https://www.facebook.com;https://www.ens.fr",
        "aff_unique_abbr": "Columbia;;EPFL;NYU;KCL;Facebook;ENS",
        "aff_campus_unique_index": "0;2;2;2;0;3;0+0+0;2;4",
        "aff_campus_unique": "New York;;Lausanne;Strand;Paris",
        "aff_country_unique_index": "0;1+2;2;2+1;0;3;0+0+0;2;1+1",
        "aff_country_unique": "United States;France;Switzerland;United Kingdom"
    },
    {
        "title": "Comparison-Based Random Forests",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1979",
        "id": "1979",
        "author_site": "Siavash Haghiri, Damien Garreau, Ulrike von Luxburg",
        "author": "Siavash Haghiri; Damien Garreau; Ulrike Luxburg",
        "abstract": "Assume we are given a set of items from a general metric space, but we neither have access to the representation of the data nor to the distances between data points. Instead, suppose that we can actively choose a triplet of items (A, B, C) and ask an oracle whether item A is closer to item B or to item C. In this paper, we propose a novel random forest algorithm for regression and classification that relies only on such triplet comparisons. In the theory part of this paper, we establish sufficient conditions for the consistency of such a forest. In a set of comprehensive experiments, we then demonstrate that the proposed random forest is efficient both for classification and regression. In particular, it is even competitive with other methods that have direct access to the metric representation of the data.",
        "bibtex": "@InProceedings{pmlr-v80-haghiri18a,\n  title = \t {Comparison-Based Random Forests},\n  author =       {Haghiri, Siavash and Garreau, Damien and von Luxburg, Ulrike},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1871--1880},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/haghiri18a/haghiri18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/haghiri18a.html},\n  abstract = \t {Assume we are given a set of items from a general metric space, but we neither have access to the representation of the data nor to the distances between data points. Instead, suppose that we can actively choose a triplet of items (A, B, C) and ask an oracle whether item A is closer to item B or to item C. In this paper, we propose a novel random forest algorithm for regression and classification that relies only on such triplet comparisons. In the theory part of this paper, we establish sufficient conditions for the consistency of such a forest. In a set of comprehensive experiments, we then demonstrate that the proposed random forest is efficient both for classification and regression. In particular, it is even competitive with other methods that have direct access to the metric representation of the data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/haghiri18a/haghiri18a.pdf",
        "supp": "",
        "pdf_size": 386507,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5869506403639298995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, University of T\u00fcbingen, Germany+Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Department of Computer Science, University of T\u00fcbingen, Germany+Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": "informatik.uni-tuebingen.de; ;informatik.uni-tuebingen.de",
        "email": "informatik.uni-tuebingen.de; ;informatik.uni-tuebingen.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/haghiri18a.html",
        "aff_unique_index": "0+1;1;0+1",
        "aff_unique_norm": "University of T\u00fcbingen;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uni-tuebingen.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": ";MPI-IS",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Competitive Caching with Machine Learned Advice",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2367",
        "id": "2367",
        "author_site": "Thodoris Lykouris, Sergei Vassilvitskii",
        "author": "Thodoris Lykouris; Sergei Vassilvtiskii",
        "abstract": "We develop a framework for augmenting online algorithms with a machine learned oracle to achieve competitive ratios that provably improve upon unconditional worst case lower bounds when the oracle has low error. Our approach treats the oracle as a complete black box, and is not dependent on its inner workings, or the exact distribution of its errors. We apply this framework to the traditional caching problem {\u2014} creating an eviction strategy for a cache of size k. We demonstrate that naively following the oracle\u2019s recommendations may lead to very poor performance, even when the average error is quite low. Instead we show how to modify the Marker algorithm to take into account the oracle\u2019s predictions, and prove that this combined approach achieves a competitive ratio that both (i) decreases as the oracle\u2019s error decreases, and (ii) is always capped by O(log k), which can be achieved without any oracle input. We complement our results with an empirical evaluation of our algorithm on real world datasets, and show that it performs well empirically even using simple off the shelf predictions.",
        "bibtex": "@InProceedings{pmlr-v80-lykouris18a,\n  title = \t {Competitive Caching with Machine Learned Advice},\n  author =       {Lykouris, Thodoris and Vassilvtiskii, Sergei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3296--3305},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lykouris18a/lykouris18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lykouris18a.html},\n  abstract = \t {We develop a framework for augmenting online algorithms with a machine learned oracle to achieve competitive ratios that provably improve upon unconditional worst case lower bounds when the oracle has low error. Our approach treats the oracle as a complete black box, and is not dependent on its inner workings, or the exact distribution of its errors. We apply this framework to the traditional caching problem {\u2014} creating an eviction strategy for a cache of size k. We demonstrate that naively following the oracle\u2019s recommendations may lead to very poor performance, even when the average error is quite low. Instead we show how to modify the Marker algorithm to take into account the oracle\u2019s predictions, and prove that this combined approach achieves a competitive ratio that both (i) decreases as the oracle\u2019s error decreases, and (ii) is always capped by O(log k), which can be achieved without any oracle input. We complement our results with an empirical evaluation of our algorithm on real world datasets, and show that it performs well empirically even using simple off the shelf predictions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lykouris18a/lykouris18a.pdf",
        "supp": "",
        "pdf_size": 295617,
        "gs_citation": 489,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12874161093946675697&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Cornell University, Ithaca, NY, USA; Google Research, New York, NY, USA",
        "aff_domain": "cs.cornell.edu;google.com",
        "email": "cs.cornell.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/lykouris18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Cornell University;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.cornell.edu;https://research.google",
        "aff_unique_abbr": "Cornell;Google Research",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Ithaca;New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2082",
        "id": "2082",
        "author_site": "IEMS Xingyu Wang, Diego Klabjan",
        "author": "Xingyu Wang; Diego Klabjan",
        "abstract": "This paper considers the problem of inverse reinforcement learning in zero-sum stochastic games when expert demonstrations are known to be suboptimal. Compared to previous works that decouple agents in the game by assuming optimality in expert policies, we introduce a new objective function that directly pits experts against Nash Equilibrium policies, and we design an algorithm to solve for the reward function in the context of inverse reinforcement learning with deep neural networks as model approximations. To ?nd Nash Equilibrium in large-scale games, we also propose an adversarial training algorithm for zero-sum stochastic games, and show the theoretical appeal of non-existence of local optima in its objective function. In numerical experiments, we demonstrate that our Nash Equilibrium and inverse reinforcement learning algorithms address games that are not amenable to existing benchmark algorithms. Moreover, our algorithm successfully recovers reward and policy functions regardless of the quality of the sub-optimal expert demonstration set.",
        "bibtex": "@InProceedings{pmlr-v80-wang18d,\n  title = \t {Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations},\n  author =       {Wang, Xingyu and Klabjan, Diego},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5143--5151},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18d/wang18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18d.html},\n  abstract = \t {This paper considers the problem of inverse reinforcement learning in zero-sum stochastic games when expert demonstrations are known to be suboptimal. Compared to previous works that decouple agents in the game by assuming optimality in expert policies, we introduce a new objective function that directly pits experts against Nash Equilibrium policies, and we design an algorithm to solve for the reward function in the context of inverse reinforcement learning with deep neural networks as model approximations. To ?nd Nash Equilibrium in large-scale games, we also propose an adversarial training algorithm for zero-sum stochastic games, and show the theoretical appeal of non-existence of local optima in its objective function. In numerical experiments, we demonstrate that our Nash Equilibrium and inverse reinforcement learning algorithms address games that are not amenable to existing benchmark algorithms. Moreover, our algorithm successfully recovers reward and policy functions regardless of the quality of the sub-optimal expert demonstration set.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18d/wang18d.pdf",
        "supp": "",
        "pdf_size": 391423,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18442998339541998027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Industrial Engineering and Management Sciences, Northwestern University; Department of Industrial Engineering and Management Sciences, Northwestern University",
        "aff_domain": "northwestern.edu;northwestern.edu",
        "email": "northwestern.edu;northwestern.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/wang18d.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Industrial Engineering and Management Sciences",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Compiling Combinatorial Prediction Games",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2374",
        "id": "2374",
        "author": "Frederic Koriche",
        "abstract": "In online optimization, the goal is to iteratively choose solutions from a decision space, so as to minimize the average cost over time. As long as this decision space is described by combinatorial constraints, the problem is generally intractable. In this paper, we consider the paradigm of compiling the set of combinatorial constraints into a deterministic and Decomposable Negation Normal Form (dDNNF) circuit, for which the tasks of linear optimization and solution sampling take linear time. Based on this framework, we provide efficient characterizations of existing combinatorial prediction strategies, with a particular attention to mirror descent techniques. These strategies are compared on several real-world benchmarks for which the set of Boolean constraints is preliminarily compiled into a dDNNF circuit.",
        "bibtex": "@InProceedings{pmlr-v80-koriche18a,\n  title = \t {Compiling Combinatorial Prediction Games},\n  author =       {Koriche, Frederic},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2756--2765},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/koriche18a/koriche18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/koriche18a.html},\n  abstract = \t {In online optimization, the goal is to iteratively choose solutions from a decision space, so as to minimize the average cost over time. As long as this decision space is described by combinatorial constraints, the problem is generally intractable. In this paper, we consider the paradigm of compiling the set of combinatorial constraints into a deterministic and Decomposable Negation Normal Form (dDNNF) circuit, for which the tasks of linear optimization and solution sampling take linear time. Based on this framework, we provide efficient characterizations of existing combinatorial prediction strategies, with a particular attention to mirror descent techniques. These strategies are compared on several real-world benchmarks for which the set of Boolean constraints is preliminarily compiled into a dDNNF circuit.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/koriche18a/koriche18a.pdf",
        "supp": "",
        "pdf_size": 364566,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2751519109783437140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "CRIL, CNRS UMR 8188, Universit\u00e9 d\u2019Artois, France",
        "aff_domain": "cril.fr",
        "email": "cril.fr",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/koriche18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Universit\u00e9 d\u2019Artois",
        "aff_unique_dep": "CRIL, CNRS UMR 8188",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "title": "Composable Planning with Attributes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2348",
        "id": "2348",
        "author_site": "Amy Zhang, Sainbayar Sukhbaatar, Adam Lerer, Arthur Szlam, Facebook Rob Fergus",
        "author": "Amy Zhang; Sainbayar Sukhbaatar; Adam Lerer; Arthur Szlam; Rob Fergus",
        "abstract": "The tasks that an agent will need to solve often are not known during training. However, if the agent knows which properties of the environment are important then, after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without training specifically for them. Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest. We propose a method that learns a policy for transitioning between \u201cnearby\u201d sets of attributes, and maintains a graph of possible transitions. Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan. We show in 3D block stacking, grid-world games, and StarCraft that our model is able to generalize to longer, more complex tasks at test time by composing simpler learned policies.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18k,\n  title = \t {Composable Planning with Attributes},\n  author =       {Zhang, Amy and Sukhbaatar, Sainbayar and Lerer, Adam and Szlam, Arthur and Fergus, Rob},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5842--5851},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18k/zhang18k.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18k.html},\n  abstract = \t {The tasks that an agent will need to solve often are not known during training. However, if the agent knows which properties of the environment are important then, after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without training specifically for them. Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest. We propose a method that learns a policy for transitioning between \u201cnearby\u201d sets of attributes, and maintains a graph of possible transitions. Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan. We show in 3D block stacking, grid-world games, and StarCraft that our model is able to generalize to longer, more complex tasks at test time by composing simpler learned policies.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18k/zhang18k.pdf",
        "supp": "",
        "pdf_size": 778657,
        "gs_citation": 89,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14836553939348389093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Facebook AI Research, New York, NY, USA+New York University, New York, NY, USA; Facebook AI Research, New York, NY, USA+New York University, New York, NY, USA; New York University, New York, NY, USA; Facebook AI Research, New York, NY, USA+New York University, New York, NY, USA; Facebook AI Research, New York, NY, USA",
        "aff_domain": "fb.com;fb.com; ; ;fb.com",
        "email": "fb.com;fb.com; ; ;fb.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/zhang18k.html",
        "aff_unique_index": "0+1;0+1;1;0+1;0",
        "aff_unique_norm": "Meta;New York University",
        "aff_unique_dep": "Facebook AI Research;",
        "aff_unique_url": "https://research.facebook.com;https://www.nyu.edu",
        "aff_unique_abbr": "FAIR;NYU",
        "aff_campus_unique_index": "0+0;0+0;0;0+0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0+0;0+0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Composite Functional Gradient Learning of Generative Adversarial Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2012",
        "id": "2012",
        "author_site": "Rie Johnson, Tong Zhang",
        "author": "Rie Johnson; Tong Zhang",
        "abstract": "This paper first presents a theory for generative adversarial methods that does not rely on the traditional minimax formulation. It shows that with a strong discriminator, a good generator can be learned so that the KL divergence between the distributions of real data and generated data improves after each functional gradient step until it converges to zero. Based on the theory, we propose a new stable generative adversarial method. A theoretical insight into the original GAN from this new viewpoint is also provided. The experiments on image generation show the effectiveness of our new method.",
        "bibtex": "@InProceedings{pmlr-v80-johnson18a,\n  title = \t {Composite Functional Gradient Learning of Generative Adversarial Models},\n  author =       {Johnson, Rie and Zhang, Tong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2371--2379},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/johnson18a/johnson18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/johnson18a.html},\n  abstract = \t {This paper first presents a theory for generative adversarial methods that does not rely on the traditional minimax formulation. It shows that with a strong discriminator, a good generator can be learned so that the KL divergence between the distributions of real data and generated data improves after each functional gradient step until it converges to zero. Based on the theory, we propose a new stable generative adversarial method. A theoretical insight into the original GAN from this new viewpoint is also provided. The experiments on image generation show the effectiveness of our new method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/johnson18a/johnson18a.pdf",
        "supp": "",
        "pdf_size": 925483,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15889803737340204736&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "RJ Research Consulting, Tarrytown, NY, USA; Tencent AI Lab, Shenzhen, China",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/johnson18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "RJ Research Consulting;Tencent",
        "aff_unique_dep": ";AI Lab",
        "aff_unique_url": ";https://ai.tencent.com",
        "aff_unique_abbr": ";Tencent AI Lab",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Composite Marginal Likelihood Methods for Random Utility Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1997",
        "id": "1997",
        "author_site": "Zhibing Zhao, Lirong Xia",
        "author": "Zhibing Zhao; Lirong Xia",
        "abstract": "We propose a novel and flexible rank-breaking-then-composite-marginal-likelihood (RBCML) framework for learning random utility models (RUMs), which include the Plackett-Luce model. We characterize conditions for the objective function of RBCML to be strictly log-concave by proving that strict log-concavity is preserved under convolution and marginalization. We characterize necessary and sufficient conditions for RBCML to satisfy consistency and asymptotic normality. Experiments on synthetic data show that RBCML for Gaussian RUMs achieves better statistical efficiency and computation efficiency than the state-of-the-art algorithm and our RBCML for the Plackett-Luce model provides flexible tradeoffs between running time and statistical efficiency.",
        "bibtex": "@InProceedings{pmlr-v80-zhao18d,\n  title = \t {Composite Marginal Likelihood Methods for Random Utility Models},\n  author =       {Zhao, Zhibing and Xia, Lirong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5922--5931},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhao18d/zhao18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhao18d.html},\n  abstract = \t {We propose a novel and flexible rank-breaking-then-composite-marginal-likelihood (RBCML) framework for learning random utility models (RUMs), which include the Plackett-Luce model. We characterize conditions for the objective function of RBCML to be strictly log-concave by proving that strict log-concavity is preserved under convolution and marginalization. We characterize necessary and sufficient conditions for RBCML to satisfy consistency and asymptotic normality. Experiments on synthetic data show that RBCML for Gaussian RUMs achieves better statistical efficiency and computation efficiency than the state-of-the-art algorithm and our RBCML for the Plackett-Luce model provides flexible tradeoffs between running time and statistical efficiency.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhao18d/zhao18d.pdf",
        "supp": "",
        "pdf_size": 526643,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4478785770757442923&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY, USA; Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY, USA",
        "aff_domain": "rpi.edu;cs.rpi.edu",
        "email": "rpi.edu;cs.rpi.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/zhao18d.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.rpi.edu",
        "aff_unique_abbr": "RPI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Troy",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Compressing Neural Networks using the Variational Information Bottleneck",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2411",
        "id": "2411",
        "author_site": "Bin Dai, Chen Zhu, Baining Guo, David Wipf",
        "author": "Bin Dai; Chen Zhu; Baining Guo; David Wipf",
        "abstract": "Neural networks can be compressed to reduce memory and computational requirements, or to increase accuracy by facilitating the use of a larger base architecture. In this paper we focus on pruning individual neurons, which can simultaneously trim model size, FLOPs, and run-time memory. To improve upon the performance of existing compression algorithms we utilize the information bottleneck principle instantiated via a tractable variational bound. Minimization of this information theoretic bound reduces the redundancy between adjacent layers by aggregating useful information into a subset of neurons that can be preserved. In contrast, the activations of disposable neurons are shut off via an attractive form of sparse regularization that emerges naturally from this framework, providing tangible advantages over traditional sparsity penalties without contributing additional tuning parameters to the energy landscape. We demonstrate state-of-the-art compression rates across an array of datasets and network architectures.",
        "bibtex": "@InProceedings{pmlr-v80-dai18d,\n  title = \t {Compressing Neural Networks using the Variational Information Bottleneck},\n  author =       {Dai, Bin and Zhu, Chen and Guo, Baining and Wipf, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1135--1144},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dai18d/dai18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dai18d.html},\n  abstract = \t {Neural networks can be compressed to reduce memory and computational requirements, or to increase accuracy by facilitating the use of a larger base architecture. In this paper we focus on pruning individual neurons, which can simultaneously trim model size, FLOPs, and run-time memory. To improve upon the performance of existing compression algorithms we utilize the information bottleneck principle instantiated via a tractable variational bound. Minimization of this information theoretic bound reduces the redundancy between adjacent layers by aggregating useful information into a subset of neurons that can be preserved. In contrast, the activations of disposable neurons are shut off via an attractive form of sparse regularization that emerges naturally from this framework, providing tangible advantages over traditional sparsity penalties without contributing additional tuning parameters to the energy landscape. We demonstrate state-of-the-art compression rates across an array of datasets and network architectures.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dai18d/dai18d.pdf",
        "supp": "",
        "pdf_size": 555678,
        "gs_citation": 211,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9160999391601213517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/dai18d.html"
    },
    {
        "title": "Computational Optimal Transport: Complexity by Accelerated Gradient Descent Is Better Than by Sinkhorn\u2019s Algorithm",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2468",
        "id": "2468",
        "author_site": "Pavel Dvurechenskii, Alexander Gasnikov, Alexey Kroshnin",
        "author": "Pavel Dvurechensky; Alexander Gasnikov; Alexey Kroshnin",
        "abstract": "We analyze two algorithms for approximating the general optimal transport (OT) distance between two discrete distributions of size $n$, up to accuracy $\\varepsilon$. For the first algorithm, which is based on the celebrated Sinkhorn\u2019s algorithm, we prove the complexity bound $\\widetilde{O}\\left(\\frac{n^2}{\\varepsilon^2}\\right)$ arithmetic operations ($\\widetilde{O}$ hides polylogarithmic factors $(\\ln n)^c$, $c>0$). For the second one, which is based on our novel Adaptive Primal-Dual Accelerated Gradient Descent (APDAGD) algorithm, we prove the complexity bound $\\widetilde{O}\\left(\\min\\left\\{\\frac{n^{9/4}}{\\varepsilon}, \\frac{n^{2}}{\\varepsilon^2} \\right\\}\\right)$ arithmetic operations. Both bounds have better dependence on $\\varepsilon$ than the state-of-the-art result given by $\\widetilde{O}\\left(\\frac{n^2}{\\varepsilon^3}\\right)$. Our second algorithm not only has better dependence on $\\varepsilon$ in the complexity bound, but also is not specific to entropic regularization and can solve the OT problem with different regularizers.",
        "bibtex": "@InProceedings{pmlr-v80-dvurechensky18a,\n  title = \t {Computational Optimal Transport: Complexity by Accelerated Gradient Descent Is Better Than by Sinkhorn\u2019s Algorithm},\n  author =       {Dvurechensky, Pavel and Gasnikov, Alexander and Kroshnin, Alexey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1367--1376},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dvurechensky18a/dvurechensky18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dvurechensky18a.html},\n  abstract = \t {We analyze two algorithms for approximating the general optimal transport (OT) distance between two discrete distributions of size $n$, up to accuracy $\\varepsilon$. For the first algorithm, which is based on the celebrated Sinkhorn\u2019s algorithm, we prove the complexity bound $\\widetilde{O}\\left(\\frac{n^2}{\\varepsilon^2}\\right)$ arithmetic operations ($\\widetilde{O}$ hides polylogarithmic factors $(\\ln n)^c$, $c>0$). For the second one, which is based on our novel Adaptive Primal-Dual Accelerated Gradient Descent (APDAGD) algorithm, we prove the complexity bound $\\widetilde{O}\\left(\\min\\left\\{\\frac{n^{9/4}}{\\varepsilon}, \\frac{n^{2}}{\\varepsilon^2} \\right\\}\\right)$ arithmetic operations. Both bounds have better dependence on $\\varepsilon$ than the state-of-the-art result given by $\\widetilde{O}\\left(\\frac{n^2}{\\varepsilon^3}\\right)$. Our second algorithm not only has better dependence on $\\varepsilon$ in the complexity bound, but also is not specific to entropic regularization and can solve the OT problem with different regularizers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dvurechensky18a/dvurechensky18a.pdf",
        "supp": "",
        "pdf_size": 422364,
        "gs_citation": 362,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5479928774471511261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "https://github.com/chervud/AGD-vs-Sinkhorn",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/dvurechensky18a.html"
    },
    {
        "title": "Conditional Neural Processes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2253",
        "id": "2253",
        "author_site": "Marta Garnelo, Dan Rosenbaum, Chris Maddison, Tiago Ramalho, David Saxton, Murray Shanahan, Yee Teh, Danilo J. Rezende, S. M. Ali Eslami",
        "author": "Marta Garnelo; Dan Rosenbaum; Christopher Maddison; Tiago Ramalho; David Saxton; Murray Shanahan; Yee Whye Teh; Danilo Rezende; S. M. Ali Eslami",
        "abstract": "Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.",
        "bibtex": "@InProceedings{pmlr-v80-garnelo18a,\n  title = \t {Conditional Neural Processes},\n  author =       {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1704--1713},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/garnelo18a.html},\n  abstract = \t {Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf",
        "supp": "",
        "pdf_size": 1264558,
        "gs_citation": 906,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8385411747082083401&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK+Imperial College London, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/garnelo18a.html",
        "aff_unique_index": "0;0;0;0;0;0+1;0;0;0",
        "aff_unique_norm": "DeepMind;Imperial College London",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://deepmind.com;https://www.imperial.ac.uk",
        "aff_unique_abbr": "DeepMind;ICL",
        "aff_campus_unique_index": "0;0;0;0;0;0+0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0+0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Conditional Noise-Contrastive Estimation of Unnormalised Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2158",
        "id": "2158",
        "author_site": "Ciwan Ceylan, Michael Gutmann",
        "author": "Ciwan Ceylan; Michael U. Gutmann",
        "abstract": "Many parametric statistical models are not properly normalised and only specified up to an intractable partition function, which renders parameter estimation difficult. Examples of unnormalised models are Gibbs distributions, Markov random fields, and neural network models in unsupervised deep learning. In previous work, the estimation principle called noise-contrastive estimation (NCE) was introduced where unnormalised models are estimated by learning to distinguish between data and auxiliary noise. An open question is how to best choose the auxiliary noise distribution. We here propose a new method that addresses this issue. The proposed method shares with NCE the idea of formulating density estimation as a supervised learning problem but in contrast to NCE, the proposed method leverages the observed data when generating noise samples. The noise can thus be generated in a semi-automated manner. We first present the underlying theory of the new method, show that score matching emerges as a limiting case, validate the method on continuous and discrete valued synthetic data, and show that we can expect an improved performance compared to NCE when the data lie in a lower-dimensional manifold. Then we demonstrate its applicability in unsupervised deep learning by estimating a four-layer neural image model.",
        "bibtex": "@InProceedings{pmlr-v80-ceylan18a,\n  title = \t {Conditional Noise-Contrastive Estimation of Unnormalised Models},\n  author =       {Ceylan, Ciwan and Gutmann, Michael U.},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {726--734},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ceylan18a/ceylan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ceylan18a.html},\n  abstract = \t {Many parametric statistical models are not properly normalised and only specified up to an intractable partition function, which renders parameter estimation difficult. Examples of unnormalised models are Gibbs distributions, Markov random fields, and neural network models in unsupervised deep learning. In previous work, the estimation principle called noise-contrastive estimation (NCE) was introduced where unnormalised models are estimated by learning to distinguish between data and auxiliary noise. An open question is how to best choose the auxiliary noise distribution. We here propose a new method that addresses this issue. The proposed method shares with NCE the idea of formulating density estimation as a supervised learning problem but in contrast to NCE, the proposed method leverages the observed data when generating noise samples. The noise can thus be generated in a semi-automated manner. We first present the underlying theory of the new method, show that score matching emerges as a limiting case, validate the method on continuous and discrete valued synthetic data, and show that we can expect an improved performance compared to NCE when the data lie in a lower-dimensional manifold. Then we demonstrate its applicability in unsupervised deep learning by estimating a four-layer neural image model.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ceylan18a/ceylan18a.pdf",
        "supp": "",
        "pdf_size": 2638341,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17029520173982518200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "UMIC, RWTH Aachen University, Aachen, Germany (affiliated with KTH Royal Institute of Technology and University of Edinburgh during project timespan); School of Informatics, University of Edinburgh, Edinburgh, United Kingdom",
        "aff_domain": "vision.rwth-aachen.de;ed.ac.uk",
        "email": "vision.rwth-aachen.de;ed.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/ceylan18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "RWTH Aachen University;University of Edinburgh",
        "aff_unique_dep": "UMIC;School of Informatics",
        "aff_unique_url": "https://www.rwth-aachen.de;https://www.ed.ac.uk",
        "aff_unique_abbr": "RWTH;Edinburgh",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Aachen;Edinburgh",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "title": "Configurable Markov Decision Processes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2137",
        "id": "2137",
        "author_site": "Alberto Maria Metelli, Mirco Mutti, Marcello Restelli",
        "author": "Alberto Maria Metelli; Mirco Mutti; Marcello Restelli",
        "abstract": "In many real-world problems, there is the possibility to configure, to a limited extent, some environmental parameters to improve the performance of a learning agent. In this paper, we propose a novel framework, Configurable Markov Decision Processes (Conf-MDPs), to model this new type of interaction with the environment. Furthermore, we provide a new learning algorithm, Safe Policy-Model Iteration (SPMI), to jointly and adaptively optimize the policy and the environment configuration. After having introduced our approach and derived some theoretical results, we present the experimental evaluation in two explicative problems to show the benefits of the environment configurability on the performance of the learned policy.",
        "bibtex": "@InProceedings{pmlr-v80-metelli18a,\n  title = \t {Configurable {M}arkov Decision Processes},\n  author =       {Metelli, Alberto Maria and Mutti, Mirco and Restelli, Marcello},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3491--3500},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/metelli18a/metelli18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/metelli18a.html},\n  abstract = \t {In many real-world problems, there is the possibility to configure, to a limited extent, some environmental parameters to improve the performance of a learning agent. In this paper, we propose a novel framework, Configurable Markov Decision Processes (Conf-MDPs), to model this new type of interaction with the environment. Furthermore, we provide a new learning algorithm, Safe Policy-Model Iteration (SPMI), to jointly and adaptively optimize the policy and the environment configuration. After having introduced our approach and derived some theoretical results, we present the experimental evaluation in two explicative problems to show the benefits of the environment configurability on the performance of the learned policy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/metelli18a/metelli18a.pdf",
        "supp": "",
        "pdf_size": 511588,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8503820574616408825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Politecnico di Milano; Politecnico di Milano; Politecnico di Milano",
        "aff_domain": "polimi.it; ; ",
        "email": "polimi.it; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/metelli18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Polimi",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "title": "Constant-Time Predictive Distributions for Gaussian Processes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2067",
        "id": "2067",
        "author_site": "Geoff Pleiss, Jacob Gardner, Kilian Weinberger, Andrew Wilson",
        "author": "Geoff Pleiss; Jacob Gardner; Kilian Weinberger; Andrew Gordon Wilson",
        "abstract": "One of the most compelling features of Gaussian process (GP) regression is its ability to provide well-calibrated posterior distributions. Recent advances in inducing point methods have sped up GP marginal likelihood and posterior mean computations, leaving posterior covariance estimation and sampling as the remaining computational bottlenecks. In this paper we address these shortcomings by using the Lanczos algorithm to rapidly approximate the predictive covariance matrix. Our approach, which we refer to as LOVE (LanczOs Variance Estimates), substantially improves time and space complexity. In our experiments, LOVE computes covariances up to 2,000 times faster and draws samples 18,000 times faster than existing methods, all without sacrificing accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-pleiss18a,\n  title = \t {Constant-Time Predictive Distributions for {G}aussian Processes},\n  author =       {Pleiss, Geoff and Gardner, Jacob and Weinberger, Kilian and Wilson, Andrew Gordon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4114--4123},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pleiss18a/pleiss18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pleiss18a.html},\n  abstract = \t {One of the most compelling features of Gaussian process (GP) regression is its ability to provide well-calibrated posterior distributions. Recent advances in inducing point methods have sped up GP marginal likelihood and posterior mean computations, leaving posterior covariance estimation and sampling as the remaining computational bottlenecks. In this paper we address these shortcomings by using the Lanczos algorithm to rapidly approximate the predictive covariance matrix. Our approach, which we refer to as LOVE (LanczOs Variance Estimates), substantially improves time and space complexity. In our experiments, LOVE computes covariances up to 2,000 times faster and draws samples 18,000 times faster than existing methods, all without sacrificing accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pleiss18a/pleiss18a.pdf",
        "supp": "",
        "pdf_size": 805925,
        "gs_citation": 139,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3694360452348960880&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Cornell University; Cornell University; Cornell University; Cornell University",
        "aff_domain": "cs.cornell.edu;cornell.edu; ;cornell.edu",
        "email": "cs.cornell.edu;cornell.edu; ;cornell.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/pleiss18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Constrained Interacting Submodular Groupings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2129",
        "id": "2129",
        "author_site": "Andrew Cotter, Mahdi Milani Fard, Seungil You, Maya Gupta, Jeff Bilmes",
        "author": "Andrew Cotter; Mahdi Milani Fard; Seungil You; Maya Gupta; Jeff Bilmes",
        "abstract": "We introduce the problem of grouping a finite ground set into blocks where each block is a subset of the ground set and where: (i) the blocks are individually highly valued by a submodular function (both robustly and in the average case) while satisfying block-specific matroid constraints; and (ii) block scores interact where blocks are jointly scored highly, thus making the blocks mutually non-redundant. Submodular functions are good models of information and diversity; thus, the above can be seen as grouping the ground set into matroid constrained blocks that are both intra- and inter-diverse. Potential applications include forming ensembles of classification/regression models, partitioning data for parallel processing, and summarization. In the non-robust case, we reduce the problem to non-monotone submodular maximization subject to multiple matroid constraints. In the mixed robust/average case, we offer a bi-criterion guarantee for a polynomial time deterministic algorithm and a probabilistic guarantee for randomized algorithm, as long as the involved submodular functions (including the inter-block interaction terms) are monotone. We close with a case study in which we use these algorithms to find high quality diverse ensembles of classifiers, showing good results.",
        "bibtex": "@InProceedings{pmlr-v80-cotter18a,\n  title = \t {Constrained Interacting Submodular Groupings},\n  author =       {Cotter, Andrew and Fard, Mahdi Milani and You, Seungil and Gupta, Maya and Bilmes, Jeff},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1068--1077},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cotter18a/cotter18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cotter18a.html},\n  abstract = \t {We introduce the problem of grouping a finite ground set into blocks where each block is a subset of the ground set and where: (i) the blocks are individually highly valued by a submodular function (both robustly and in the average case) while satisfying block-specific matroid constraints; and (ii) block scores interact where blocks are jointly scored highly, thus making the blocks mutually non-redundant. Submodular functions are good models of information and diversity; thus, the above can be seen as grouping the ground set into matroid constrained blocks that are both intra- and inter-diverse. Potential applications include forming ensembles of classification/regression models, partitioning data for parallel processing, and summarization. In the non-robust case, we reduce the problem to non-monotone submodular maximization subject to multiple matroid constraints. In the mixed robust/average case, we offer a bi-criterion guarantee for a polynomial time deterministic algorithm and a probabilistic guarantee for randomized algorithm, as long as the involved submodular functions (including the inter-block interaction terms) are monotone. We close with a case study in which we use these algorithms to find high quality diverse ensembles of classifiers, showing good results.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cotter18a/cotter18a.pdf",
        "supp": "",
        "pdf_size": 438323,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1707265645270207000&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Google AI; Google AI; Kakao Mobility; Google AI; University of Washington, Seattle",
        "aff_domain": "google.com; ; ; ;uw.edu",
        "email": "google.com; ; ; ;uw.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/cotter18a.html",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Google;Kakao Mobility;University of Washington",
        "aff_unique_dep": "Google AI;;",
        "aff_unique_url": "https://ai.google;https://mobility.kakaocorp.com;https://www.washington.edu",
        "aff_unique_abbr": "Google AI;Kakao Mobility;UW",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Mountain View;;Seattle",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "title": "Constraining the Dynamics of Deep Probabilistic Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2209",
        "id": "2209",
        "author_site": "Marco Lorenzi, Maurizio Filippone",
        "author": "Marco Lorenzi; Maurizio Filippone",
        "abstract": "We introduce a novel generative formulation of deep probabilistic models implementing \"soft\" constraints on their function dynamics. In particular, we develop a flexible methodological framework where the modeled functions and derivatives of a given order are subject to inequality or equality constraints. We then characterize the posterior distribution over model and constraint parameters through stochastic variational inference. As a result, the proposed approach allows for accurate and scalable uncertainty quantification on the predictions and on all parameters. We demonstrate the application of equality constraints in the challenging problem of parameter inference in ordinary differential equation models, while we showcase the application of inequality constraints on the problem of monotonic regression of count data. The proposed approach is extensively tested in several experimental settings, leading to highly competitive results in challenging modeling applications, while offering high expressiveness, flexibility and scalability.",
        "bibtex": "@InProceedings{pmlr-v80-lorenzi18a,\n  title = \t {Constraining the Dynamics of Deep Probabilistic Models},\n  author =       {Lorenzi, Marco and Filippone, Maurizio},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3227--3236},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lorenzi18a/lorenzi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lorenzi18a.html},\n  abstract = \t {We introduce a novel generative formulation of deep probabilistic models implementing \"soft\" constraints on their function dynamics. In particular, we develop a flexible methodological framework where the modeled functions and derivatives of a given order are subject to inequality or equality constraints. We then characterize the posterior distribution over model and constraint parameters through stochastic variational inference. As a result, the proposed approach allows for accurate and scalable uncertainty quantification on the predictions and on all parameters. We demonstrate the application of equality constraints in the challenging problem of parameter inference in ordinary differential equation models, while we showcase the application of inequality constraints on the problem of monotonic regression of count data. The proposed approach is extensively tested in several experimental settings, leading to highly competitive results in challenging modeling applications, while offering high expressiveness, flexibility and scalability.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lorenzi18a/lorenzi18a.pdf",
        "supp": "",
        "pdf_size": 2435893,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16643488282668412066&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Cote d\u2019Azur, INRIA Sophia Antipolis, EPIONE research group, France+1; EURECOM, Department of Data Science, Sophia Antipolis, France+2",
        "aff_domain": "inria.fr;eurecom.fr",
        "email": "inria.fr;eurecom.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/lorenzi18a.html",
        "aff_unique_index": "0;2",
        "aff_unique_norm": "University of Cote d\u2019Azur;;EURECOM",
        "aff_unique_dep": "INRIA Sophia Antipolis;;Department of Data Science",
        "aff_unique_url": "https://www.univ-cotedazur.fr;;https://www.eurecom.fr",
        "aff_unique_abbr": "UCA;;",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Sophia Antipolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France;"
    },
    {
        "title": "ContextNet: Deep learning for Star Galaxy Classification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2195",
        "id": "2195",
        "author_site": "Noble Kennamer, University of California David Kirkby, Alexander Ihler, University of California Francisco Javier Sanchez-Lopez",
        "author": "Noble Kennamer; David Kirkby; Alexander Ihler; Francisco Javier Sanchez-Lopez",
        "abstract": "We present a framework to compose artificial neural networks in cases where the data cannot be treated as independent events. Our particular motivation is star galaxy classification for ground based optical surveys. Due to a turbulent atmosphere and imperfect instruments, a single image of an astronomical object is not enough to definitively classify it as a star or galaxy. Instead the context of the surrounding objects imaged at the same time need to be considered in order to make an optimal classification. The model we present is divided into three distinct ANNs: one designed to capture local features about each object, the second to compare these features across all objects in an image, and the third to make a final prediction for each object based on the local and compared features. By exploiting the ability to replicate the weights of an ANN, the model can handle an arbitrary and variable number of individual objects embedded in a larger exposure. We train and test our model on simulations of a large up and coming ground based survey, the Large Synoptic Survey Telescope (LSST). We compare to the state of the art approach, showing improved overall performance as well as better performance for a specific class of objects that is important for the LSST.",
        "bibtex": "@InProceedings{pmlr-v80-kennamer18a,\n  title = \t {{C}ontext{N}et: Deep learning for Star Galaxy Classification},\n  author =       {Kennamer, Noble and Kirkby, David and Ihler, Alexander and Sanchez-Lopez, Francisco Javier},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2582--2590},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kennamer18a/kennamer18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kennamer18a.html},\n  abstract = \t {We present a framework to compose artificial neural networks in cases where the data cannot be treated as independent events. Our particular motivation is star galaxy classification for ground based optical surveys. Due to a turbulent atmosphere and imperfect instruments, a single image of an astronomical object is not enough to definitively classify it as a star or galaxy. Instead the context of the surrounding objects imaged at the same time need to be considered in order to make an optimal classification. The model we present is divided into three distinct ANNs: one designed to capture local features about each object, the second to compare these features across all objects in an image, and the third to make a final prediction for each object based on the local and compared features. By exploiting the ability to replicate the weights of an ANN, the model can handle an arbitrary and variable number of individual objects embedded in a larger exposure. We train and test our model on simulations of a large up and coming ground based survey, the Large Synoptic Survey Telescope (LSST). We compare to the state of the art approach, showing improved overall performance as well as better performance for a specific class of objects that is important for the LSST.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kennamer18a/kennamer18a.pdf",
        "supp": "",
        "pdf_size": 637077,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=897117176592870879&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Sciences, University of California, Irvine; Department of Physics and Astronomy, University of California, Irvine; Department of Computer Sciences, University of California, Irvine; Department of Physics and Astronomy, University of California, Irvine",
        "aff_domain": "uci.edu; ; ; ",
        "email": "uci.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kennamer18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Irvine",
        "aff_unique_dep": "Department of Computer Sciences",
        "aff_unique_url": "https://www.uci.edu",
        "aff_unique_abbr": "UCI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Irvine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2084",
        "id": "2084",
        "author_site": "Davide Bacciu, Federico Errica, Alessio Micheli",
        "author": "Davide Bacciu; Federico Errica; Alessio Micheli",
        "abstract": "We introduce the Contextual Graph Markov Model, an approach combining ideas from generative models and neural networks for the processing of graph data. It founds on a constructive methodology to build a deep architecture comprising layers of probabilistic models that learn to encode the structured information in an incremental fashion. Context is diffused in an efficient and scalable way across the graph vertexes and edges. The resulting graph encoding is used in combination with discriminative models to address structure classification benchmarks.",
        "bibtex": "@InProceedings{pmlr-v80-bacciu18a,\n  title = \t {Contextual Graph {M}arkov Model: A Deep and Generative Approach to Graph Processing},\n  author =       {Bacciu, Davide and Errica, Federico and Micheli, Alessio},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {294--303},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bacciu18a/bacciu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bacciu18a.html},\n  abstract = \t {We introduce the Contextual Graph Markov Model, an approach combining ideas from generative models and neural networks for the processing of graph data. It founds on a constructive methodology to build a deep architecture comprising layers of probabilistic models that learn to encode the structured information in an incremental fashion. Context is diffused in an efficient and scalable way across the graph vertexes and edges. The resulting graph encoding is used in combination with discriminative models to address structure classification benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bacciu18a/bacciu18a.pdf",
        "supp": "",
        "pdf_size": 529229,
        "gs_citation": 102,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11762309887012905485&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Pisa; Department of Computer Science, University of Pisa; Department of Computer Science, University of Pisa",
        "aff_domain": "di.unipi.it;protonmail.com;di.unipi.it",
        "email": "di.unipi.it;protonmail.com;di.unipi.it",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/bacciu18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pisa",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unipi.it",
        "aff_unique_abbr": "UNIPi",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "title": "Continual Reinforcement Learning with Complex Synapses",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2165",
        "id": "2165",
        "author_site": "Christos Kaplanis, Murray Shanahan, Claudia Clopath",
        "author": "Christos Kaplanis; Murray Shanahan; Claudia Clopath",
        "abstract": "Unlike humans, who are capable of continual learning over their lifetimes, artificial neural networks have long been known to suffer from a phenomenon known as catastrophic forgetting, whereby new learning can lead to abrupt erasure of previously acquired knowledge. Whereas in a neural network the parameters are typically modelled as scalar values, an individual synapse in the brain comprises a complex network of interacting biochemical components that evolve at different timescales. In this paper, we show that by equipping tabular and deep reinforcement learning agents with a synaptic model that incorporates this biological complexity (Benna & Fusi, 2016), catastrophic forgetting can be mitigated at multiple timescales. In particular, we find that as well as enabling continual learning across sequential training of two simple tasks, it can also be used to overcome within-task forgetting by reducing the need for an experience replay database.",
        "bibtex": "@InProceedings{pmlr-v80-kaplanis18a,\n  title = \t {Continual Reinforcement Learning with Complex Synapses},\n  author =       {Kaplanis, Christos and Shanahan, Murray and Clopath, Claudia},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2497--2506},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kaplanis18a/kaplanis18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kaplanis18a.html},\n  abstract = \t {Unlike humans, who are capable of continual learning over their lifetimes, artificial neural networks have long been known to suffer from a phenomenon known as catastrophic forgetting, whereby new learning can lead to abrupt erasure of previously acquired knowledge. Whereas in a neural network the parameters are typically modelled as scalar values, an individual synapse in the brain comprises a complex network of interacting biochemical components that evolve at different timescales. In this paper, we show that by equipping tabular and deep reinforcement learning agents with a synaptic model that incorporates this biological complexity (Benna & Fusi, 2016), catastrophic forgetting can be mitigated at multiple timescales. In particular, we find that as well as enabling continual learning across sequential training of two simple tasks, it can also be used to overcome within-task forgetting by reducing the need for an experience replay database.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kaplanis18a/kaplanis18a.pdf",
        "supp": "",
        "pdf_size": 2935155,
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9116708688187603044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computing, Imperial College London + Google DeepMind, London; Department of Computing, Imperial College London; Department of Bioengineering, Imperial College London + Google DeepMind, London",
        "aff_domain": "imperial.ac.uk; ; ",
        "email": "imperial.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kaplanis18a.html",
        "aff_unique_index": "0+1;0;0+1",
        "aff_unique_norm": "Imperial College London;Google",
        "aff_unique_dep": "Department of Computing;Google DeepMind",
        "aff_unique_url": "https://www.imperial.ac.uk;https://deepmind.com",
        "aff_unique_abbr": "Imperial;DeepMind",
        "aff_campus_unique_index": "0+0;0;0+0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Continuous and Discrete-time Accelerated Stochastic Mirror Descent for Strongly Convex Functions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2166",
        "id": "2166",
        "author_site": "Pan Xu, Tianhao Wang, Quanquan Gu",
        "author": "Pan Xu; Tianhao Wang; Quanquan Gu",
        "abstract": "We provide a second-order stochastic differential equation (SDE), which characterizes the continuous-time dynamics of accelerated stochastic mirror descent (ASMD) for strongly convex functions. This SDE plays a central role in designing new discrete-time ASMD algorithms via numerical discretization, and providing neat analyses of their convergence rates based on Lyapunov functions. Our results suggest that the only existing ASMD algorithm, namely, AC-SA proposed in Ghadimi & Lan (2012) is one instance of its kind, and we can actually derive new instances of ASMD with fewer tuning parameters. This sheds light on revisiting accelerated stochastic optimization through the lens of SDEs, which can lead to a better understanding of acceleration in stochastic optimization, as well as new simpler algorithms. Numerical experiments on both synthetic and real data support our theory.",
        "bibtex": "@InProceedings{pmlr-v80-xu18g,\n  title = \t {Continuous and Discrete-time Accelerated Stochastic Mirror Descent for Strongly Convex Functions},\n  author =       {Xu, Pan and Wang, Tianhao and Gu, Quanquan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5492--5501},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18g/xu18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18g.html},\n  abstract = \t {We provide a second-order stochastic differential equation (SDE), which characterizes the continuous-time dynamics of accelerated stochastic mirror descent (ASMD) for strongly convex functions. This SDE plays a central role in designing new discrete-time ASMD algorithms via numerical discretization, and providing neat analyses of their convergence rates based on Lyapunov functions. Our results suggest that the only existing ASMD algorithm, namely, AC-SA proposed in Ghadimi & Lan (2012) is one instance of its kind, and we can actually derive new instances of ASMD with fewer tuning parameters. This sheds light on revisiting accelerated stochastic optimization through the lens of SDEs, which can lead to a better understanding of acceleration in stochastic optimization, as well as new simpler algorithms. Numerical experiments on both synthetic and real data support our theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18g/xu18g.pdf",
        "supp": "",
        "pdf_size": 891361,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7222293616693089258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of California, Los Angeles, CA 90095, USA; School of Mathematical Sciences, University of Science and technology of China, Hefei, Anhui, China; Department of Computer Science, University of California, Los Angeles, CA 90095, USA",
        "aff_domain": "cs.ucla.edu; ;cs.ucla.edu",
        "email": "cs.ucla.edu; ;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/xu18g.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;University of Science and Technology of China",
        "aff_unique_dep": "Department of Computer Science;School of Mathematical Sciences",
        "aff_unique_url": "https://www.ucla.edu;http://www.ustc.edu.cn",
        "aff_unique_abbr": "UCLA;USTC",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Los Angeles;Hefei",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Continuous-Time Flows for Efficient Inference and Density Estimation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2258",
        "id": "2258",
        "author_site": "Changyou Chen, Chunyuan Li, Liquan Chen, Wenlin Wang, Yunchen Pu, Lawrence Carin",
        "author": "Changyou Chen; Chunyuan Li; Liqun Chen; Wenlin Wang; Yunchen Pu; Lawrence Carin Duke",
        "abstract": "Two fundamental problems in unsupervised learning are efficient inference for latent-variable models and robust density estimation based on large amounts of unlabeled data. Algorithms for the two tasks, such as normalizing flows and generative adversarial networks (GANs), are often developed independently. In this paper, we propose the concept of",
        "bibtex": "@InProceedings{pmlr-v80-chen18d,\n  title = \t {Continuous-Time Flows for Efficient Inference and Density Estimation},\n  author =       {Chen, Changyou and Li, Chunyuan and Chen, Liqun and Wang, Wenlin and Pu, Yunchen and Duke, Lawrence Carin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {824--833},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18d/chen18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18d.html},\n  abstract = \t {Two fundamental problems in unsupervised learning are efficient inference for latent-variable models and robust density estimation based on large amounts of unlabeled data. Algorithms for the two tasks, such as normalizing flows and generative adversarial networks (GANs), are often developed independently. In this paper, we propose the concept of",
        "pdf": "http://proceedings.mlr.press/v80/chen18d/chen18d.pdf",
        "supp": "",
        "pdf_size": 5253837,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17786542528210483087&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "SUNY at Buffalo; Duke University; Duke University; Duke University; Duke University; Duke University",
        "aff_domain": "gmail.com; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/chen18d.html",
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "State University of New York at Buffalo;Duke University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.buffalo.edu;https://www.duke.edu",
        "aff_unique_abbr": "SUNY Buffalo;Duke",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Buffalo;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Convergence guarantees for a class of non-convex and non-smooth optimization problems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2283",
        "id": "2283",
        "author_site": "Koulik Khamaru, Martin Wainwright",
        "author": "Koulik Khamaru; Martin Wainwright",
        "abstract": "Non-convex optimization problems arise frequently in machine learning, including feature selection, structured matrix learning, mixture modeling, and neural network training. We consider the problem of finding critical points of a broad class of non-convex problems with non-smooth components. We analyze the behavior of two gradient-based methods\u2014namely a sub-gradient method, and a proximal method. Our main results are to establish rates of convergence for general problems, and also exhibit faster rates for sub-analytic functions. As an application of our theory, we obtain a simplification of the popular CCCP algorithm, which retains all the desirable convergence properties of the original method, along with a significantly lower cost per iteration. We illustrate our methods and theory via application to the problems of best subset selection, robust estimation, and shape from shading reconstruction.",
        "bibtex": "@InProceedings{pmlr-v80-khamaru18a,\n  title = \t {Convergence guarantees for a class of non-convex and non-smooth optimization problems},\n  author =       {Khamaru, Koulik and Wainwright, Martin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2601--2610},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/khamaru18a/khamaru18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/khamaru18a.html},\n  abstract = \t {Non-convex optimization problems arise frequently in machine learning, including feature selection, structured matrix learning, mixture modeling, and neural network training. We consider the problem of finding critical points of a broad class of non-convex problems with non-smooth components. We analyze the behavior of two gradient-based methods\u2014namely a sub-gradient method, and a proximal method. Our main results are to establish rates of convergence for general problems, and also exhibit faster rates for sub-analytic functions. As an application of our theory, we obtain a simplification of the popular CCCP algorithm, which retains all the desirable convergence properties of the original method, along with a significantly lower cost per iteration. We illustrate our methods and theory via application to the problems of best subset selection, robust estimation, and shape from shading reconstruction.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/khamaru18a/khamaru18a.pdf",
        "supp": "",
        "pdf_size": 415392,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8562541105138200871&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, UC Berkeley, Berkeley, USA + Department of EECS, UC Berkeley, Berkeley, USA; Department of Statistics, UC Berkeley, Berkeley, USA + Department of EECS, UC Berkeley, Berkeley, USA",
        "aff_domain": "berkeley.edu;eecs.berkeley.edu",
        "email": "berkeley.edu;eecs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/khamaru18a.html",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Convergent Tree Backup and Retrace with Function Approximation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2470",
        "id": "2470",
        "author_site": "Ahmed Touati, Pierre-Luc Bacon, Doina Precup, Pascal Vincent",
        "author": "Ahmed Touati; Pierre-Luc Bacon; Doina Precup; Pascal Vincent",
        "abstract": "Off-policy learning is key to scaling up reinforcement learning as it allows to learn about a target policy from the experience generated by a different behavior policy. Unfortunately, it has been challenging to combine off-policy learning with function approximation and multi-step bootstrapping in a way that leads to both stable and efficient algorithms. In this work, we show that the Tree Backup and Retrace algorithms are unstable with linear function approximation, both in theory and in practice with specific examples. Based on our analysis, we then derive stable and efficient gradient-based algorithms using a quadratic convex-concave saddle-point formulation. By exploiting the problem structure proper to these algorithms, we are able to provide convergence guarantees and finite-sample bounds. The applicability of our new analysis also goes beyond Tree Backup and Retrace and allows us to provide new convergence rates for the GTD and GTD2 algorithms without having recourse to projections or Polyak averaging.",
        "bibtex": "@InProceedings{pmlr-v80-touati18a,\n  title = \t {Convergent Tree Backup and Retrace with Function Approximation},\n  author =       {Touati, Ahmed and Bacon, Pierre-Luc and Precup, Doina and Vincent, Pascal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4955--4964},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/touati18a/touati18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/touati18a.html},\n  abstract = \t {Off-policy learning is key to scaling up reinforcement learning as it allows to learn about a target policy from the experience generated by a different behavior policy. Unfortunately, it has been challenging to combine off-policy learning with function approximation and multi-step bootstrapping in a way that leads to both stable and efficient algorithms. In this work, we show that the Tree Backup and Retrace algorithms are unstable with linear function approximation, both in theory and in practice with specific examples. Based on our analysis, we then derive stable and efficient gradient-based algorithms using a quadratic convex-concave saddle-point formulation. By exploiting the problem structure proper to these algorithms, we are able to provide convergence guarantees and finite-sample bounds. The applicability of our new analysis also goes beyond Tree Backup and Retrace and allows us to provide new convergence rates for the GTD and GTD2 algorithms without having recourse to projections or Polyak averaging.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/touati18a/touati18a.pdf",
        "supp": "",
        "pdf_size": 2717911,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10537981275590800964&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "MILA, Universit\u00e9 de Montr\u00e9al+Facebook AI Research; MILA, McGill University; MILA, McGill University+Canadian Institute for Advanced Research (CIFAR); MILA, Universit\u00e9 de Montr\u00e9al+Facebook AI Research+Canadian Institute for Advanced Research (CIFAR)",
        "aff_domain": "umontreal.ca; ; ; ",
        "email": "umontreal.ca; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/touati18a.html",
        "aff_unique_index": "0+1;2;2+3;0+1+3",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;Meta;McGill University;Canadian Institute for Advanced Research",
        "aff_unique_dep": "MILA;Facebook AI Research;MILA;",
        "aff_unique_url": "https://www.umontreal.ca;https://research.facebook.com;https://www.mcgill.ca;https://www.cifar.ca",
        "aff_unique_abbr": "UdeM;FAIR;McGill;CIFAR",
        "aff_campus_unique_index": "0;2;2;0",
        "aff_campus_unique": "Montr\u00e9al;;Montreal",
        "aff_country_unique_index": "0+1;0;0+0;0+1+0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "title": "Convolutional Imputation of Matrix Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2135",
        "id": "2135",
        "author_site": "Qingyun Sun, Mengyuan Yan, David Donoho, stephen boyd",
        "author": "Qingyun Sun; Mengyuan Yan; David Donoho;  boyd",
        "abstract": "A matrix network is a family of matrices, with their relations modeled as a weighted graph. We consider the task of completing a partially observed matrix network. The observation comes from a novel sampling scheme where a fraction of matrices might be completely unobserved. How can we recover the entire matrix network from incomplete observations? This mathematical problem arises in many applications including medical imaging and social networks. To recover the matrix network, we propose a structural assumption that the matrices are low-rank after the graph Fourier transform on the network. We formulate a convex optimization problem and prove an exact recovery guarantee for the optimization problem. Furthermore, we numerically characterize the exact recovery regime for varying rank and sampling rate and discover a new phase transition phenomenon. Then we give an iterative imputation algorithm to efficiently solve optimization problem and complete large scale matrix networks. We demonstrate the algorithm with a variety of applications such as MRI and Facebook user network.",
        "bibtex": "@InProceedings{pmlr-v80-sun18d,\n  title = \t {Convolutional Imputation of Matrix Networks},\n  author =       {Sun, Qingyun and Yan, Mengyuan and Donoho, David and stephen boyd},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4818--4827},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sun18d/sun18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sun18d.html},\n  abstract = \t {A matrix network is a family of matrices, with their relations modeled as a weighted graph. We consider the task of completing a partially observed matrix network. The observation comes from a novel sampling scheme where a fraction of matrices might be completely unobserved. How can we recover the entire matrix network from incomplete observations? This mathematical problem arises in many applications including medical imaging and social networks. To recover the matrix network, we propose a structural assumption that the matrices are low-rank after the graph Fourier transform on the network. We formulate a convex optimization problem and prove an exact recovery guarantee for the optimization problem. Furthermore, we numerically characterize the exact recovery regime for varying rank and sampling rate and discover a new phase transition phenomenon. Then we give an iterative imputation algorithm to efficiently solve optimization problem and complete large scale matrix networks. We demonstrate the algorithm with a variety of applications such as MRI and Facebook user network.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sun18d/sun18d.pdf",
        "supp": "",
        "pdf_size": 4862203,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4050136046619038234&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Mathematics, Stanford University, California, USA+Department of Electrical Engineering, Stanford University, California, USA; Department of Electrical Engineering, Stanford University, California, USA; Department of Statistics, Stanford University, California, USA; Department of Electrical Engineering, Stanford University, California, USA",
        "aff_domain": "stanford.edu; ; ; ",
        "email": "stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sun18d.html",
        "aff_unique_index": "0+0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0+0;0;0;0",
        "aff_campus_unique": "California",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Coordinated Exploration in Concurrent Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1943",
        "id": "1943",
        "author_site": "Maria Dimakopoulou, Benjamin Van Roy",
        "author": "Maria Dimakopoulou; Benjamin Van Roy",
        "abstract": "We consider a team of reinforcement learning agents that concurrently learn to operate in a common environment. We identify three properties - adaptivity, commitment, and diversity - which are necessary for efficient coordinated exploration and demonstrate that straightforward extensions to single-agent optimistic and posterior sampling approaches fail to satisfy them. As an alternative, we propose seed sampling, which extends posterior sampling in a manner that meets these requirements. Simulation results investigate how per-agent regret decreases as the number of agents grows, establishing substantial advantages of seed sampling over alternative exploration schemes.",
        "bibtex": "@InProceedings{pmlr-v80-dimakopoulou18a,\n  title = \t {Coordinated Exploration in Concurrent Reinforcement Learning},\n  author =       {Dimakopoulou, Maria and Van Roy, Benjamin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1271--1279},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dimakopoulou18a/dimakopoulou18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dimakopoulou18a.html},\n  abstract = \t {We consider a team of reinforcement learning agents that concurrently learn to operate in a common environment. We identify three properties - adaptivity, commitment, and diversity - which are necessary for efficient coordinated exploration and demonstrate that straightforward extensions to single-agent optimistic and posterior sampling approaches fail to satisfy them. As an alternative, we propose seed sampling, which extends posterior sampling in a manner that meets these requirements. Simulation results investigate how per-agent regret decreases as the number of agents grows, establishing substantial advantages of seed sampling over alternative exploration schemes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dimakopoulou18a/dimakopoulou18a.pdf",
        "supp": "",
        "pdf_size": 871160,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5319871067417609300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "stanford.edu;stanford.edu",
        "email": "stanford.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/dimakopoulou18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2478",
        "id": "2478",
        "author_site": "Jinghui Chen, Pan Xu, Lingxiao Wang, Jian Ma, Quanquan Gu",
        "author": "Jinghui Chen; Pan Xu; Lingxiao Wang; Jian Ma; Quanquan Gu",
        "abstract": "We propose a nonconvex estimator for the covariate adjusted precision matrix estimation problem in the high dimensional regime, under sparsity constraints. To solve this estimator, we propose an alternating gradient descent algorithm with hard thresholding. Compared with existing methods along this line of research, which lack theoretical guarantees in optimization error and/or statistical error, the proposed algorithm not only is computationally much more efficient with a linear rate of convergence, but also attains the optimal statistical rate up to a logarithmic factor. Thorough experiments on both synthetic and real data support our theory.",
        "bibtex": "@InProceedings{pmlr-v80-chen18n,\n  title = \t {Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization},\n  author =       {Chen, Jinghui and Xu, Pan and Wang, Lingxiao and Ma, Jian and Gu, Quanquan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {922--931},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18n/chen18n.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18n.html},\n  abstract = \t {We propose a nonconvex estimator for the covariate adjusted precision matrix estimation problem in the high dimensional regime, under sparsity constraints. To solve this estimator, we propose an alternating gradient descent algorithm with hard thresholding. Compared with existing methods along this line of research, which lack theoretical guarantees in optimization error and/or statistical error, the proposed algorithm not only is computationally much more efficient with a linear rate of convergence, but also attains the optimal statistical rate up to a logarithmic factor. Thorough experiments on both synthetic and real data support our theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18n/chen18n.pdf",
        "supp": "",
        "pdf_size": 863661,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12839134285264142370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA",
        "aff_domain": "cs.ucla.edu; ; ; ;cs.ucla.edu",
        "email": "cs.ucla.edu; ; ; ;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/chen18n.html",
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "University of Virginia;University of California, Los Angeles;Carnegie Mellon University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;School of Computer Science",
        "aff_unique_url": "https://www.virginia.edu;https://www.ucla.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UVA;UCLA;CMU",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Charlottesville;Los Angeles;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Crowdsourcing with Arbitrary Adversaries",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2054",
        "id": "2054",
        "author_site": "Matth\u00e4us Kleindessner, Pranjal Awasthi",
        "author": "Matthaeus Kleindessner; Pranjal Awasthi",
        "abstract": "Most existing works on crowdsourcing assume that the workers follow the Dawid-Skene model, or the one-coin model as its special case, where every worker makes mistakes independently of other workers and with the same error probability for every task. We study a significant extension of this restricted model. We allow almost half of the workers to deviate from the one-coin model and for those workers, their probabilities of making an error to be task-dependent and to be arbitrarily correlated. In other words, we allow for arbitrary adversaries, for which not only error probabilities can be high, but which can also perfectly collude. In this adversarial scenario, we design an efficient algorithm to consistently estimate the workers\u2019 error probabilities.",
        "bibtex": "@InProceedings{pmlr-v80-kleindessner18a,\n  title = \t {Crowdsourcing with Arbitrary Adversaries},\n  author =       {Kleindessner, Matthaeus and Awasthi, Pranjal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2708--2717},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kleindessner18a/kleindessner18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kleindessner18a.html},\n  abstract = \t {Most existing works on crowdsourcing assume that the workers follow the Dawid-Skene model, or the one-coin model as its special case, where every worker makes mistakes independently of other workers and with the same error probability for every task. We study a significant extension of this restricted model. We allow almost half of the workers to deviate from the one-coin model and for those workers, their probabilities of making an error to be task-dependent and to be arbitrarily correlated. In other words, we allow for arbitrary adversaries, for which not only error probabilities can be high, but which can also perfectly collude. In this adversarial scenario, we design an efficient algorithm to consistently estimate the workers\u2019 error probabilities.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kleindessner18a/kleindessner18a.pdf",
        "supp": "",
        "pdf_size": 460537,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17754689490852106653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Rutgers University, Piscataway Township, New Jersey, USA; Department of Computer Science, Rutgers University, Piscataway Township, New Jersey, USA",
        "aff_domain": "rutgers.edu;rutgers.edu",
        "email": "rutgers.edu;rutgers.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kleindessner18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway Township",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2021",
        "id": "2021",
        "author_site": "Daphna Weinshall, Gad A Cohen, Dan Amir",
        "author": "Daphna Weinshall; Gad Cohen; Dan Amir",
        "abstract": "We provide theoretical investigation of curriculum learning in the context of stochastic gradient descent when optimizing the convex linear regression loss. We prove that the rate of convergence of an ideal curriculum learning method is monotonically increasing with the difficulty of the examples. Moreover, among all equally difficult points, convergence is faster when using points which incur higher loss with respect to the current hypothesis. We then analyze curriculum learning in the context of training a CNN. We describe a method which infers the curriculum by way of transfer learning from another network, pre-trained on a different task. While this approach can only approximate the ideal curriculum, we observe empirically similar behavior to the one predicted by the theory, namely, a significant boost in convergence speed at the beginning of training. When the task is made more difficult, improvement in generalization performance is also observed. Finally, curriculum learning exhibits robustness against unfavorable conditions such as excessive regularization.",
        "bibtex": "@InProceedings{pmlr-v80-weinshall18a,\n  title = \t {Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks},\n  author =       {Weinshall, Daphna and Cohen, Gad and Amir, Dan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5238--5246},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/weinshall18a/weinshall18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/weinshall18a.html},\n  abstract = \t {We provide theoretical investigation of curriculum learning in the context of stochastic gradient descent when optimizing the convex linear regression loss. We prove that the rate of convergence of an ideal curriculum learning method is monotonically increasing with the difficulty of the examples. Moreover, among all equally difficult points, convergence is faster when using points which incur higher loss with respect to the current hypothesis. We then analyze curriculum learning in the context of training a CNN. We describe a method which infers the curriculum by way of transfer learning from another network, pre-trained on a different task. While this approach can only approximate the ideal curriculum, we observe empirically similar behavior to the one predicted by the theory, namely, a significant boost in convergence speed at the beginning of training. When the task is made more difficult, improvement in generalization performance is also observed. Finally, curriculum learning exhibits robustness against unfavorable conditions such as excessive regularization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/weinshall18a/weinshall18a.pdf",
        "supp": "",
        "pdf_size": 525849,
        "gs_citation": 293,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1166174630510905307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israel; School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israel; School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israel",
        "aff_domain": "mail.huji.ac.il; ; ",
        "email": "mail.huji.ac.il; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/weinshall18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hebrew University of Jerusalem",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.huji.ac.il",
        "aff_unique_abbr": "HUJI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Jerusalem",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Cut-Pursuit Algorithm for Regularizing Nonsmooth Functionals with Graph Total Variation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2392",
        "id": "2392",
        "author_site": "Hugo Raguet, loic landrieu",
        "author": "Hugo Raguet; Loic Landrieu",
        "abstract": "We present an extension of the cut-pursuit algorithm, introduced by Landrieu and Obozinski (2017), to the graph total-variation regularization of functions with a separable nondifferentiable part. We propose a modified algorithmic scheme as well as adapted proofs of convergence. We also present a heuristic approach for handling the cases in which the values associated to each vertex of the graph are multidimensional. The performance of our algorithm, which we demonstrate on difficult, ill-conditioned large-scale inverse and learning problems, is such that it may in practice extend the scope of application of the total-variation regularization.",
        "bibtex": "@InProceedings{pmlr-v80-raguet18a,\n  title = \t {Cut-Pursuit Algorithm for Regularizing Nonsmooth Functionals with Graph Total Variation},\n  author =       {Raguet, Hugo and Landrieu, Loic},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4247--4256},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/raguet18a/raguet18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/raguet18a.html},\n  abstract = \t {We present an extension of the cut-pursuit algorithm, introduced by Landrieu and Obozinski (2017), to the graph total-variation regularization of functions with a separable nondifferentiable part. We propose a modified algorithmic scheme as well as adapted proofs of convergence. We also present a heuristic approach for handling the cases in which the values associated to each vertex of the graph are multidimensional. The performance of our algorithm, which we demonstrate on difficult, ill-conditioned large-scale inverse and learning problems, is such that it may in practice extend the scope of application of the total-variation regularization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/raguet18a/raguet18a.pdf",
        "supp": "",
        "pdf_size": 340977,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1642340457851755634&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "LIVE, CNRS, Univ. Strasbourg, France; Univ. Paris-Est, LaSTIG MATIS, IGN, ENSG, F-94160 Saint-Mand\u00e9, France",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/raguet18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Strasbourg;Universit\u00e9 Paris-Est",
        "aff_unique_dep": "LIVE;LaSTIG MATIS",
        "aff_unique_url": "https://www.unistra.fr;https://www.univ-Paris-est.fr",
        "aff_unique_abbr": "Unistra;UPE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "CyCADA: Cycle-Consistent Adversarial Domain Adaptation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2286",
        "id": "2286",
        "author_site": "Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Philip Isola, Kate Saenko, Alexei Efros, Trevor Darrell",
        "author": "Judy Hoffman; Eric Tzeng; Taesung Park; Jun-Yan Zhu; Phillip Isola; Kate Saenko; Alexei Efros; Trevor Darrell",
        "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",
        "bibtex": "@InProceedings{pmlr-v80-hoffman18a,\n  title = \t {{C}y{CADA}: Cycle-Consistent Adversarial Domain Adaptation},\n  author =       {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1989--1998},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hoffman18a/hoffman18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hoffman18a.html},\n  abstract = \t {Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hoffman18a/hoffman18a.pdf",
        "supp": "",
        "pdf_size": 5284270,
        "gs_citation": 3795,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13169730024102659375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "EECS and BAIR, UC Berkeley; EECS and BAIR, UC Berkeley; EECS and BAIR, UC Berkeley; EECS and BAIR, UC Berkeley; EECS and BAIR, UC Berkeley + OpenAI (work done while at UC Berkeley); CS Department, Boston University; EECS and BAIR, UC Berkeley; EECS and BAIR, UC Berkeley",
        "aff_domain": "eecs.berkeley.edu; ; ; ; ; ; ; ",
        "email": "eecs.berkeley.edu; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/hoffman18a.html",
        "aff_unique_index": "0;0;0;0;0+0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Boston University",
        "aff_unique_dep": "Electrical Engineering and Computer Sciences;Computer Science Department",
        "aff_unique_url": "https://www.berkeley.edu;https://www.bu.edu",
        "aff_unique_abbr": "UC Berkeley;BU",
        "aff_campus_unique_index": "0;0;0;0;0+0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "DCFNet: Deep Neural Network with Decomposed Convolutional Filters",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2056",
        "id": "2056",
        "author_site": "Qiang Qiu, Xiuyuan Cheng, robert Calderbank, Guillermo Sapiro",
        "author": "Qiang Qiu; Xiuyuan Cheng;  Calderbank; Guillermo Sapiro",
        "abstract": "Filters in a Convolutional Neural Network (CNN) contain model parameters learned from enormous amounts of data. In this paper, we suggest to decompose convolutional filters in CNN as a truncated expansion with pre-fixed bases, namely the Decomposed Convolutional Filters network (DCFNet), where the expansion coefficients remain learned from data. Such a structure not only reduces the number of trainable parameters and computation, but also imposes filter regularity by bases truncation. Through extensive experiments, we consistently observe that DCFNet maintains accuracy for image classification tasks with a significant reduction of model parameters, particularly with Fourier-Bessel (FB) bases, and even with random bases. Theoretically, we analyze the representation stability of DCFNet with respect to input variations, and prove representation stability under generic assumptions on the expansion coefficients. The analysis is consistent with the empirical observations.",
        "bibtex": "@InProceedings{pmlr-v80-qiu18a,\n  title = \t {{DCFN}et: Deep Neural Network with Decomposed Convolutional Filters},\n  author =       {Qiu, Qiang and Cheng, Xiuyuan and robert Calderbank and Sapiro, Guillermo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4198--4207},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/qiu18a/qiu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/qiu18a.html},\n  abstract = \t {Filters in a Convolutional Neural Network (CNN) contain model parameters learned from enormous amounts of data. In this paper, we suggest to decompose convolutional filters in CNN as a truncated expansion with pre-fixed bases, namely the Decomposed Convolutional Filters network (DCFNet), where the expansion coefficients remain learned from data. Such a structure not only reduces the number of trainable parameters and computation, but also imposes filter regularity by bases truncation. Through extensive experiments, we consistently observe that DCFNet maintains accuracy for image classification tasks with a significant reduction of model parameters, particularly with Fourier-Bessel (FB) bases, and even with random bases. Theoretically, we analyze the representation stability of DCFNet with respect to input variations, and prove representation stability under generic assumptions on the expansion coefficients. The analysis is consistent with the empirical observations.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/qiu18a/qiu18a.pdf",
        "supp": "",
        "pdf_size": 984675,
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6785841352849465563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Duke University; Duke University; Duke University; Duke University",
        "aff_domain": "duke.edu;duke.edu;duke.edu;duke.edu",
        "email": "duke.edu;duke.edu;duke.edu;duke.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/qiu18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "DICOD: Distributed Convolutional Coordinate Descent for Convolutional Sparse Coding",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1904",
        "id": "1904",
        "author_site": "Thomas Moreau, Laurent Oudre, Nicolas Vayatis",
        "author": "Thomas Moreau; Laurent Oudre; Nicolas Vayatis",
        "abstract": "In this paper, we introduce DICOD, a convolutional sparse coding algorithm which builds shift invariant representations for long signals. This algorithm is designed to run in a distributed setting, with local message passing, making it communication efficient. It is based on coordinate descent and uses locally greedy updates which accelerate the resolution compared to greedy coordinate selection. We prove the convergence of this algorithm and highlight its computational speed-up which is super-linear in the number of cores used. We also provide empirical evidence for the acceleration properties of our algorithm compared to state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v80-moreau18a,\n  title = \t {{DICOD}: Distributed Convolutional Coordinate Descent for Convolutional Sparse Coding},\n  author =       {Moreau, Thomas and Oudre, Laurent and Vayatis, Nicolas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3626--3634},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/moreau18a/moreau18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/moreau18a.html},\n  abstract = \t {In this paper, we introduce DICOD, a convolutional sparse coding algorithm which builds shift invariant representations for long signals. This algorithm is designed to run in a distributed setting, with local message passing, making it communication efficient. It is based on coordinate descent and uses locally greedy updates which accelerate the resolution compared to greedy coordinate selection. We prove the convergence of this algorithm and highlight its computational speed-up which is super-linear in the number of cores used. We also provide empirical evidence for the acceleration properties of our algorithm compared to state-of-the-art methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/moreau18a/moreau18a.pdf",
        "supp": "",
        "pdf_size": 2451579,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6841370809688839469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "CMLA, ENS Cachan, CNRS, Universit\u00e9 Paris-Saclay, 94235 Cachan, France; L2TI, Universit\u00e9 Paris 13, 93430 Villetaneuse, France; CMLA, ENS Cachan, CNRS, Universit\u00e9 Paris-Saclay, 94235 Cachan, France",
        "aff_domain": "cmla.ens-cachan.fr; ;cmla.ens-cachan.fr",
        "email": "cmla.ens-cachan.fr; ;cmla.ens-cachan.fr",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/moreau18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "\u00c9cole Normale Sup\u00e9rieure de Cachan;Universit\u00e9 Paris 13",
        "aff_unique_dep": "CMLA;L2TI",
        "aff_unique_url": "https://www.ens-cachan.fr;https://www.univ-paris13.fr",
        "aff_unique_abbr": "ENS Cachan;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cachan;Villetaneuse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "DRACO: Byzantine-resilient Distributed Training via Redundant Gradients",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2474",
        "id": "2474",
        "author_site": "Lingjiao Chen, Hongyi Wang, Zachary Charles, Dimitris Papailiopoulos",
        "author": "Lingjiao Chen; Hongyi Wang; Zachary Charles; Dimitris Papailiopoulos",
        "abstract": "Distributed model training is vulnerable to byzantine system failures and adversarial compute nodes, i.e., nodes that use malicious updates to corrupt the global model stored at a parameter server (PS). To guarantee some form of robustness, recent work suggests using variants of the geometric median as an aggregation rule, in place of gradient averaging. Unfortunately, median-based rules can incur a prohibitive computational overhead in large-scale settings, and their convergence guarantees often require strong assumptions. In this work, we present DRACO, a scalable framework for robust distributed training that uses ideas from coding theory. In DRACO, each compute node evaluates redundant gradients that are used by the parameter server to eliminate the effects of adversarial updates. DRACO comes with problem-independent robustness guarantees, and the model that it trains is identical to the one trained in the adversary-free setup. We provide extensive experiments on real datasets and distributed setups across a variety of large-scale models, where we show that DRACO is several times, to orders of magnitude faster than median-based approaches.",
        "bibtex": "@InProceedings{pmlr-v80-chen18l,\n  title = \t {{DRACO}: {B}yzantine-resilient Distributed Training via Redundant Gradients},\n  author =       {Chen, Lingjiao and Wang, Hongyi and Charles, Zachary and Papailiopoulos, Dimitris},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {903--912},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18l/chen18l.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18l.html},\n  abstract = \t {Distributed model training is vulnerable to byzantine system failures and adversarial compute nodes, i.e., nodes that use malicious updates to corrupt the global model stored at a parameter server (PS). To guarantee some form of robustness, recent work suggests using variants of the geometric median as an aggregation rule, in place of gradient averaging. Unfortunately, median-based rules can incur a prohibitive computational overhead in large-scale settings, and their convergence guarantees often require strong assumptions. In this work, we present DRACO, a scalable framework for robust distributed training that uses ideas from coding theory. In DRACO, each compute node evaluates redundant gradients that are used by the parameter server to eliminate the effects of adversarial updates. DRACO comes with problem-independent robustness guarantees, and the model that it trains is identical to the one trained in the adversary-free setup. We provide extensive experiments on real datasets and distributed setups across a variety of large-scale models, where we show that DRACO is several times, to orders of magnitude faster than median-based approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18l/chen18l.pdf",
        "supp": "",
        "pdf_size": 4935397,
        "gs_citation": 287,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7533143184939579191&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": "cs.wisc.edu; ; ; ",
        "email": "cs.wisc.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/chen18l.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "DVAE++: Discrete Variational Autoencoders with Overlapping Transformations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2273",
        "id": "2273",
        "author_site": "Arash Vahdat, William Macready, Zhengbing Bian, Amir Khoshaman, Evgeny Andriyash",
        "author": "Arash Vahdat; William Macready; Zhengbing Bian; Amir Khoshaman; Evgeny Andriyash",
        "abstract": "Training of discrete latent variable models remains challenging because passing gradient information through discrete units is difficult. We propose a new class of smoothing transformations based on a mixture of two overlapping distributions, and show that the proposed transformation can be used for training binary latent models with either directed or undirected priors. We derive a new variational bound to efficiently train with Boltzmann machine priors. Using this bound, we develop DVAE++, a generative model with a global discrete prior and a hierarchy of convolutional continuous variables. Experiments on several benchmarks show that overlapping transformations outperform other recent continuous relaxations of discrete latent variables including Gumbel-Softmax (Maddison et al., 2016; Jang et al., 2016), and discrete variational autoencoders (Rolfe 2016).",
        "bibtex": "@InProceedings{pmlr-v80-vahdat18a,\n  title = \t {{DVAE}++: Discrete Variational Autoencoders with Overlapping Transformations},\n  author =       {Vahdat, Arash and Macready, William and Bian, Zhengbing and Khoshaman, Amir and Andriyash, Evgeny},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5035--5044},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/vahdat18a/vahdat18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/vahdat18a.html},\n  abstract = \t {Training of discrete latent variable models remains challenging because passing gradient information through discrete units is difficult. We propose a new class of smoothing transformations based on a mixture of two overlapping distributions, and show that the proposed transformation can be used for training binary latent models with either directed or undirected priors. We derive a new variational bound to efficiently train with Boltzmann machine priors. Using this bound, we develop DVAE++, a generative model with a global discrete prior and a hierarchy of convolutional continuous variables. Experiments on several benchmarks show that overlapping transformations outperform other recent continuous relaxations of discrete latent variables including Gumbel-Softmax (Maddison et al., 2016; Jang et al., 2016), and discrete variational autoencoders (Rolfe 2016).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/vahdat18a/vahdat18a.pdf",
        "supp": "",
        "pdf_size": 858940,
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8532899816919123190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Quadrant.ai, D-Wave Systems Inc., Burnaby, BC, Canada; Quadrant.ai, D-Wave Systems Inc., Burnaby, BC, Canada; Quadrant.ai, D-Wave Systems Inc., Burnaby, BC, Canada; Quadrant.ai, D-Wave Systems Inc., Burnaby, BC, Canada; Quadrant.ai, D-Wave Systems Inc., Burnaby, BC, Canada",
        "aff_domain": "quadrant.ai; ; ; ; ",
        "email": "quadrant.ai; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/vahdat18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "D-Wave Systems Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Data Summarization at Scale: A Two-Stage Submodular Approach",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2144",
        "id": "2144",
        "author_site": "Marko Mitrovic, Ehsan Kazemi, Morteza Zadimoghaddam, Amin Karbasi",
        "author": "Marko Mitrovic; Ehsan Kazemi; Morteza Zadimoghaddam; Amin Karbasi",
        "abstract": "The sheer scale of modern datasets has resulted in a dire need for summarization techniques that can identify representative elements in a dataset. Fortunately, the vast majority of data summarization tasks satisfy an intuitive diminishing returns condition known as submodularity, which allows us to find nearly-optimal solutions in linear time. We focus on a two-stage submodular framework where the goal is to use some given training functions to reduce the ground set so that optimizing new functions (drawn from the same distribution) over the reduced set provides almost as much value as optimizing them over the entire ground set. In this paper, we develop the first streaming and distributed solutions to this problem. In addition to providing strong theoretical guarantees, we demonstrate both the utility and efficiency of our algorithms on real-world tasks including image summarization and ride-share optimization.",
        "bibtex": "@InProceedings{pmlr-v80-mitrovic18a,\n  title = \t {Data Summarization at Scale: A Two-Stage Submodular Approach},\n  author =       {Mitrovic, Marko and Kazemi, Ehsan and Zadimoghaddam, Morteza and Karbasi, Amin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3596--3605},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mitrovic18a/mitrovic18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mitrovic18a.html},\n  abstract = \t {The sheer scale of modern datasets has resulted in a dire need for summarization techniques that can identify representative elements in a dataset. Fortunately, the vast majority of data summarization tasks satisfy an intuitive diminishing returns condition known as submodularity, which allows us to find nearly-optimal solutions in linear time. We focus on a two-stage submodular framework where the goal is to use some given training functions to reduce the ground set so that optimizing new functions (drawn from the same distribution) over the reduced set provides almost as much value as optimizing them over the entire ground set. In this paper, we develop the first streaming and distributed solutions to this problem. In addition to providing strong theoretical guarantees, we demonstrate both the utility and efficiency of our algorithms on real-world tasks including image summarization and ride-share optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mitrovic18a/mitrovic18a.pdf",
        "supp": "",
        "pdf_size": 2985857,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16731220901415326768&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, Yale University, New Haven, Connecticut, USA+Google Research, Zurich, Switzerland; Department of Computer Science, Yale University, New Haven, Connecticut, USA+Google Research, Zurich, Switzerland; Google Research, Zurich, Switzerland; Department of Computer Science, Yale University, New Haven, Connecticut, USA",
        "aff_domain": "yale.edu;yale.edu;google.com;yale.edu",
        "email": "yale.edu;yale.edu;google.com;yale.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/mitrovic18a.html",
        "aff_unique_index": "0+1;0+1;1;0",
        "aff_unique_norm": "Yale University;Google",
        "aff_unique_dep": "Department of Computer Science;Google Research",
        "aff_unique_url": "https://www.yale.edu;https://research.google",
        "aff_unique_abbr": "Yale;Google",
        "aff_campus_unique_index": "0+1;0+1;1;0",
        "aff_campus_unique": "New Haven;Zurich",
        "aff_country_unique_index": "0+1;0+1;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "title": "Data-Dependent Stability of Stochastic Gradient Descent",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1984",
        "id": "1984",
        "author_site": "Ilja Kuzborskij, Christoph H. Lampert",
        "author": "Ilja Kuzborskij; Christoph Lampert",
        "abstract": "We establish a data-dependent notion of algorithmic stability for Stochastic Gradient Descent (SGD), and employ it to develop novel generalization bounds. This is in contrast to previous distribution-free algorithmic stability results for SGD which depend on the worst-case constants. By virtue of the data-dependent argument, our bounds provide new insights into learning with SGD on convex and non-convex problems. In the convex case, we show that the bound on the generalization error depends on the risk at the initialization point. In the non-convex case, we prove that the expected curvature of the objective function around the initialization point has crucial influence on the generalization error. In both cases, our results suggest a simple data-driven strategy to stabilize SGD by pre-screening its initialization. As a corollary, our results allow us to show optimistic generalization bounds that exhibit fast convergence rates for SGD subject to a vanishing empirical risk and low noise of stochastic gradient.",
        "bibtex": "@InProceedings{pmlr-v80-kuzborskij18a,\n  title = \t {Data-Dependent Stability of Stochastic Gradient Descent},\n  author =       {Kuzborskij, Ilja and Lampert, Christoph},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2815--2824},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kuzborskij18a/kuzborskij18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kuzborskij18a.html},\n  abstract = \t {We establish a data-dependent notion of algorithmic stability for Stochastic Gradient Descent (SGD), and employ it to develop novel generalization bounds. This is in contrast to previous distribution-free algorithmic stability results for SGD which depend on the worst-case constants. By virtue of the data-dependent argument, our bounds provide new insights into learning with SGD on convex and non-convex problems. In the convex case, we show that the bound on the generalization error depends on the risk at the initialization point. In the non-convex case, we prove that the expected curvature of the objective function around the initialization point has crucial influence on the generalization error. In both cases, our results suggest a simple data-driven strategy to stabilize SGD by pre-screening its initialization. As a corollary, our results allow us to show optimistic generalization bounds that exhibit fast convergence rates for SGD subject to a vanishing empirical risk and low noise of stochastic gradient.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kuzborskij18a/kuzborskij18a.pdf",
        "supp": "",
        "pdf_size": 457009,
        "gs_citation": 182,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18149484406737206768&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Milan, Italy; IST Austria",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kuzborskij18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Milan;Institute of Science and Technology Austria",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unimi.it;https://www.ist.ac.at",
        "aff_unique_abbr": "UniMi;IST Austria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Italy;Austria"
    },
    {
        "title": "Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2358",
        "id": "2358",
        "author_site": "Aryan Mokhtari, Hamed Hassani, Amin Karbasi",
        "author": "Aryan Mokhtari; Hamed Hassani; Amin Karbasi",
        "abstract": "In this paper, we showcase the interplay between discrete and continuous optimization in network-structured settings. We propose the first fully decentralized optimization method for a wide class of non-convex objective functions that possess a diminishing returns property. More specifically, given an arbitrary connected network and a global continuous submodular function, formed by a sum of local functions, we develop Decentralized Continuous Greedy (DCG), a message passing algorithm that converges to the tight $(1-1/e)$ approximation factor of the optimum global solution using only local computation and communication. We also provide strong convergence bounds as a function of network size and spectral characteristics of the underlying topology. Interestingly, DCG readily provides a simple recipe for decentralized discrete submodular maximization through the means of continuous relaxations. Formally, we demonstrate that by lifting the local discrete functions to continuous domains and using DCG as an interface we can develop a consensus algorithm that also achieves the tight $(1-1/e)$ approximation guarantee of the global discrete solution once a proper rounding scheme is applied.",
        "bibtex": "@InProceedings{pmlr-v80-mokhtari18a,\n  title = \t {Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings},\n  author =       {Mokhtari, Aryan and Hassani, Hamed and Karbasi, Amin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3616--3625},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mokhtari18a/mokhtari18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mokhtari18a.html},\n  abstract = \t {In this paper, we showcase the interplay between discrete and continuous optimization in network-structured settings. We propose the first fully decentralized optimization method for a wide class of non-convex objective functions that possess a diminishing returns property. More specifically, given an arbitrary connected network and a global continuous submodular function, formed by a sum of local functions, we develop Decentralized Continuous Greedy (DCG), a message passing algorithm that converges to the tight $(1-1/e)$ approximation factor of the optimum global solution using only local computation and communication. We also provide strong convergence bounds as a function of network size and spectral characteristics of the underlying topology. Interestingly, DCG readily provides a simple recipe for decentralized discrete submodular maximization through the means of continuous relaxations. Formally, we demonstrate that by lifting the local discrete functions to continuous domains and using DCG as an interface we can develop a consensus algorithm that also achieves the tight $(1-1/e)$ approximation guarantee of the global discrete solution once a proper rounding scheme is applied.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mokhtari18a/mokhtari18a.pdf",
        "supp": "",
        "pdf_size": 674098,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=895449346685155990&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Laboratory for Information and Decision Systems, Massachusetts Institute of Technology; Department of Electrical and Systems Engineering, University of Pennsylvania; Department of Electrical Engineering and Computer Science, Yale University",
        "aff_domain": "mit.edu; ; ",
        "email": "mit.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mokhtari18a.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Pennsylvania;Yale University",
        "aff_unique_dep": "Laboratory for Information and Decision Systems;Department of Electrical and Systems Engineering;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://web.mit.edu;https://www.upenn.edu;https://www.yale.edu",
        "aff_unique_abbr": "MIT;UPenn;Yale",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2262",
        "id": "2262",
        "author_site": "Stefan Depeweg, Jose Miguel Hernandez-Lobato, Finale Doshi-Velez, Steffen Udluft",
        "author": "Stefan Depeweg; Jose-Miguel Hernandez-Lobato; Finale Doshi-Velez; Steffen Udluft",
        "abstract": "Bayesian neural networks with latent variables are scalable and flexible probabilistic models: they account for uncertainty in the estimation of the network weights and, by making use of latent variables, can capture complex noise patterns in the data. Using these models we show how to perform and utilize a decomposition of uncertainty in aleatoric and epistemic components for decision making purposes. This allows us to successfully identify informative points for active learning of functions with heteroscedastic and bimodal noise. Using the decomposition we further define a novel risk-sensitive criterion for reinforcement learningto identify policies that balance expected cost, model-bias and noise aversion.",
        "bibtex": "@InProceedings{pmlr-v80-depeweg18a,\n  title = \t {Decomposition of Uncertainty in {B}ayesian Deep Learning for Efficient and Risk-sensitive Learning},\n  author =       {Depeweg, Stefan and Hernandez-Lobato, Jose-Miguel and Doshi-Velez, Finale and Udluft, Steffen},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1184--1193},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/depeweg18a/depeweg18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/depeweg18a.html},\n  abstract = \t {Bayesian neural networks with latent variables are scalable and flexible probabilistic models: they account for uncertainty in the estimation of the network weights and, by making use of latent variables, can capture complex noise patterns in the data. Using these models we show how to perform and utilize a decomposition of uncertainty in aleatoric and epistemic components for decision making purposes. This allows us to successfully identify informative points for active learning of functions with heteroscedastic and bimodal noise. Using the decomposition we further define a novel risk-sensitive criterion for reinforcement learningto identify policies that balance expected cost, model-bias and noise aversion.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/depeweg18a/depeweg18a.pdf",
        "supp": "",
        "pdf_size": 1963570,
        "gs_citation": 541,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13563599882871713230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Siemens AG + TU Munich; University of Cambridge; Harvard University; Siemens AG",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/depeweg18a.html",
        "aff_unique_index": "0+1;2;3;0",
        "aff_unique_norm": "Siemens AG;Technical University of Munich;University of Cambridge;Harvard University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.siemens.com;https://www.tum.de;https://www.cam.ac.uk;https://www.harvard.edu",
        "aff_unique_abbr": "Siemens;TUM;Cambridge;Harvard",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0+0;1;2;0",
        "aff_country_unique": "Germany;United Kingdom;United States"
    },
    {
        "title": "Decoupled Parallel Backpropagation with Convergence Guarantee",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2106",
        "id": "2106",
        "author_site": "Zhouyuan Huo, Bin Gu, Qian Yang, Heng Huang",
        "author": "Zhouyuan Huo; Bin Gu;  Yang; Heng Huang",
        "abstract": "Backpropagation algorithm is indispensable for the training of feedforward neural networks. It requires propagating error gradients sequentially from the output layer all the way back to the input layer. The backward locking in backpropagation algorithm constrains us from updating network layers in parallel and fully leveraging the computing resources. Recently, several algorithms have been proposed for breaking the backward locking. However, their performances degrade seriously when networks are deep. In this paper, we propose decoupled parallel backpropagation algorithm for deep learning optimization with convergence guarantee. Firstly, we decouple the backpropagation algorithm using delayed gradients, and show that the backward locking is removed when we split the networks into multiple modules. Then, we utilize decoupled parallel backpropagation in two stochastic methods and prove that our method guarantees convergence to critical points for the non-convex problem. Finally, we perform experiments for training deep convolutional neural networks on benchmark datasets. The experimental results not only confirm our theoretical analysis, but also demonstrate that the proposed method can achieve significant speedup without loss of accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-huo18a,\n  title = \t {Decoupled Parallel Backpropagation with Convergence Guarantee},\n  author =       {Huo, Zhouyuan and Gu, Bin and qian Yang and Huang, Heng},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2098--2106},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/huo18a/huo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/huo18a.html},\n  abstract = \t {Backpropagation algorithm is indispensable for the training of feedforward neural networks. It requires propagating error gradients sequentially from the output layer all the way back to the input layer. The backward locking in backpropagation algorithm constrains us from updating network layers in parallel and fully leveraging the computing resources. Recently, several algorithms have been proposed for breaking the backward locking. However, their performances degrade seriously when networks are deep. In this paper, we propose decoupled parallel backpropagation algorithm for deep learning optimization with convergence guarantee. Firstly, we decouple the backpropagation algorithm using delayed gradients, and show that the backward locking is removed when we split the networks into multiple modules. Then, we utilize decoupled parallel backpropagation in two stochastic methods and prove that our method guarantees convergence to critical points for the non-convex problem. Finally, we perform experiments for training deep convolutional neural networks on benchmark datasets. The experimental results not only confirm our theoretical analysis, but also demonstrate that the proposed method can achieve significant speedup without loss of accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/huo18a/huo18a.pdf",
        "supp": "",
        "pdf_size": 1173826,
        "gs_citation": 109,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9542708515407168556&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA, United States; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA, United States; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA, United States; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA, United States",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/huo18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pittsburgh",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.pitt.edu",
        "aff_unique_abbr": "Pitt",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Decoupling Gradient-Like Learning Rules from Representations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2343",
        "id": "2343",
        "author_site": "Philip Thomas, Christoph Dann, Emma Brunskill",
        "author": "Philip Thomas; Christoph Dann; Emma Brunskill",
        "abstract": "In machine learning, learning often corresponds to changing the parameters of a parameterized function. A learning rule is an algorithm or mathematical expression that specifies precisely how the parameters should be changed. When creating a machine learning system, we must make two decisions: what representation should be used (i.e., what parameterized function should be used) and what learning rule should be used to search through the resulting set of representable functions. In this paper we focus on gradient-like learning rules, wherein these two decisions are coupled in a subtle (and often unintentional) way. Using most learning rules, these two decisions are coupled in a subtle (and often unintentional) way. That is, using the same learning rule with two different representations that can represent the same sets of functions can result in two different outcomes. After arguing that this coupling is undesirable, particularly when using neural networks, we present a method for partially decoupling these two decisions for a broad class of gradient-like learning rules that span unsupervised learning, reinforcement learning, and supervised learning.",
        "bibtex": "@InProceedings{pmlr-v80-thomas18a,\n  title = \t {Decoupling Gradient-Like Learning Rules from Representations},\n  author =       {Thomas, Philip and Dann, Christoph and Brunskill, Emma},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4917--4925},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/thomas18a/thomas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/thomas18a.html},\n  abstract = \t {In machine learning, learning often corresponds to changing the parameters of a parameterized function. A learning rule is an algorithm or mathematical expression that specifies precisely how the parameters should be changed. When creating a machine learning system, we must make two decisions: what representation should be used (i.e., what parameterized function should be used) and what learning rule should be used to search through the resulting set of representable functions. In this paper we focus on gradient-like learning rules, wherein these two decisions are coupled in a subtle (and often unintentional) way. Using most learning rules, these two decisions are coupled in a subtle (and often unintentional) way. That is, using the same learning rule with two different representations that can represent the same sets of functions can result in two different outcomes. After arguing that this coupling is undesirable, particularly when using neural networks, we present a method for partially decoupling these two decisions for a broad class of gradient-like learning rules that span unsupervised learning, reinforcement learning, and supervised learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/thomas18a/thomas18a.pdf",
        "supp": "",
        "pdf_size": 969898,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9925039723167156656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Massachusetts Amherst; Carnegie Mellon University; Stanford University",
        "aff_domain": "cs.umass.edu; ; ",
        "email": "cs.umass.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/thomas18a.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Massachusetts Amherst;Carnegie Mellon University;Stanford University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.umass.edu;https://www.cmu.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UMass Amherst;CMU;Stanford",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Amherst;;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Deep Asymmetric Multi-task Feature Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1960",
        "id": "1960",
        "author_site": "Hae Beom Lee, Eunho Yang, Sung Ju Hwang",
        "author": "Hae Beom Lee; Eunho Yang; Sung Ju Hwang",
        "abstract": "We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can learn deep representations shared across multiple tasks while effectively preventing negative transfer that may happen in the feature sharing process. Specifically, we introduce an asymmetric autoencoder term that allows reliable predictors for the easy tasks to have high contribution to the feature learning while suppressing the influences of unreliable predictors for more difficult tasks. This allows the learning of less noisy representations, and enables unreliable predictors to exploit knowledge from the reliable predictors via the shared latent features. Such asymmetric knowledge transfer through shared features is also more scalable and efficient than inter-task asymmetric transfer. We validate our Deep-AMTFL model on multiple benchmark datasets for multitask learning and image classification, on which it significantly outperforms existing symmetric and asymmetric multitask learning models, by effectively preventing negative transfer in deep feature learning.",
        "bibtex": "@InProceedings{pmlr-v80-lee18d,\n  title = \t {Deep Asymmetric Multi-task Feature Learning},\n  author =       {Lee, Hae Beom and Yang, Eunho and Hwang, Sung Ju},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2956--2964},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lee18d/lee18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lee18d.html},\n  abstract = \t {We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can learn deep representations shared across multiple tasks while effectively preventing negative transfer that may happen in the feature sharing process. Specifically, we introduce an asymmetric autoencoder term that allows reliable predictors for the easy tasks to have high contribution to the feature learning while suppressing the influences of unreliable predictors for more difficult tasks. This allows the learning of less noisy representations, and enables unreliable predictors to exploit knowledge from the reliable predictors via the shared latent features. Such asymmetric knowledge transfer through shared features is also more scalable and efficient than inter-task asymmetric transfer. We validate our Deep-AMTFL model on multiple benchmark datasets for multitask learning and image classification, on which it significantly outperforms existing symmetric and asymmetric multitask learning models, by effectively preventing negative transfer in deep feature learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lee18d/lee18d.pdf",
        "supp": "",
        "pdf_size": 2990734,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7786406609741351183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "UNIST, Ulsan, South Korea+AItrics, Seoul, South Korea; KAIST, Daejeon, South Korea+AItrics, Seoul, South Korea; KAIST, Daejeon, South Korea+AItrics, Seoul, South Korea",
        "aff_domain": "unist.ac.kr;kaist.ac.kr;kaist.ac.kr",
        "email": "unist.ac.kr;kaist.ac.kr;kaist.ac.kr",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lee18d.html",
        "aff_unique_index": "0+1;2+1;2+1",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;AITRICS;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.unist.ac.kr;;https://www.kaist.ac.kr",
        "aff_unique_abbr": "UNIST;;KAIST",
        "aff_campus_unique_index": "0+1;2+1;2+1",
        "aff_campus_unique": "Ulsan;Seoul;Daejeon",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Deep Bayesian Nonparametric Tracking",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2090",
        "id": "2090",
        "author_site": "Aonan Zhang, John Paisley",
        "author": "Aonan Zhang; John Paisley",
        "abstract": "Time-series data often exhibit irregular behavior, making them hard to analyze and explain with a simple dynamic model. For example, information in social networks may show change-point-like bursts that then diffuse with smooth dynamics. Powerful models such as deep neural networks learn smooth functions from data, but are not as well-suited (in off-the-shelf form) for discovering and explaining sparse, discrete and bursty dynamic patterns. Bayesian models can do this well by encoding the appropriate probabilistic assumptions in the model prior. We propose an integration of Bayesian nonparametric methods within deep neural networks for modeling irregular patterns in time-series data. We use a Bayesian nonparametrics to model change-point behavior in time, and a deep neural network to model nonlinear latent space dynamics. We compare with a non-deep linear version of the model also proposed here. Empirical evaluations demonstrates improved performance and interpretable results when tracking stock prices and Twitter trends.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18j,\n  title = \t {Deep {B}ayesian Nonparametric Tracking},\n  author =       {Zhang, Aonan and Paisley, John},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5833--5841},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18j/zhang18j.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18j.html},\n  abstract = \t {Time-series data often exhibit irregular behavior, making them hard to analyze and explain with a simple dynamic model. For example, information in social networks may show change-point-like bursts that then diffuse with smooth dynamics. Powerful models such as deep neural networks learn smooth functions from data, but are not as well-suited (in off-the-shelf form) for discovering and explaining sparse, discrete and bursty dynamic patterns. Bayesian models can do this well by encoding the appropriate probabilistic assumptions in the model prior. We propose an integration of Bayesian nonparametric methods within deep neural networks for modeling irregular patterns in time-series data. We use a Bayesian nonparametrics to model change-point behavior in time, and a deep neural network to model nonlinear latent space dynamics. We compare with a non-deep linear version of the model also proposed here. Empirical evaluations demonstrates improved performance and interpretable results when tracking stock prices and Twitter trends.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18j/zhang18j.pdf",
        "supp": "",
        "pdf_size": 692874,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10004227329858556301&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Electrical Engineering & Data Science Institute, Columbia University, New York, USA; Department of Electrical Engineering & Data Science Institute, Columbia University, New York, USA",
        "aff_domain": "columbia.edu; ",
        "email": "columbia.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/zhang18j.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Electrical Engineering & Data Science Institute",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Deep Density Destructors",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2437",
        "id": "2437",
        "author_site": "David Inouye, Pradeep Ravikumar",
        "author": "David Inouye; Pradeep Ravikumar",
        "abstract": "We propose a unified framework for deep density models by formally defining density destructors. A density destructor is an invertible function that transforms a given density to the uniform density\u2014essentially destroying any structure in the original density. This destructive transformation generalizes Gaussianization via ICA and more recent autoregressive models such as MAF and Real NVP. Informally, this transformation can be seen as a generalized whitening procedure or a multivariate generalization of the univariate CDF function. Unlike Gaussianization, our destructive transformation has the elegant property that the density function is equal to the absolute value of the Jacobian determinant. Thus, each layer of a deep density can be seen as a shallow density\u2014uncovering a fundamental connection between shallow and deep densities. In addition, our framework provides a common interface for all previous methods enabling them to be systematically combined, evaluated and improved. Leveraging the connection to shallow densities, we also propose a novel tree destructor based on tree densities and an image-specific destructor based on pixel locality. We illustrate our framework on a 2D dataset, MNIST, and CIFAR-10. Code is available on first author\u2019s website.",
        "bibtex": "@InProceedings{pmlr-v80-inouye18a,\n  title = \t {Deep Density Destructors},\n  author =       {Inouye, David and Ravikumar, Pradeep},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2167--2175},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/inouye18a/inouye18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/inouye18a.html},\n  abstract = \t {We propose a unified framework for deep density models by formally defining density destructors. A density destructor is an invertible function that transforms a given density to the uniform density\u2014essentially destroying any structure in the original density. This destructive transformation generalizes Gaussianization via ICA and more recent autoregressive models such as MAF and Real NVP. Informally, this transformation can be seen as a generalized whitening procedure or a multivariate generalization of the univariate CDF function. Unlike Gaussianization, our destructive transformation has the elegant property that the density function is equal to the absolute value of the Jacobian determinant. Thus, each layer of a deep density can be seen as a shallow density\u2014uncovering a fundamental connection between shallow and deep densities. In addition, our framework provides a common interface for all previous methods enabling them to be systematically combined, evaluated and improved. Leveraging the connection to shallow densities, we also propose a novel tree destructor based on tree densities and an image-specific destructor based on pixel locality. We illustrate our framework on a 2D dataset, MNIST, and CIFAR-10. Code is available on first author\u2019s website.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/inouye18a/inouye18a.pdf",
        "supp": "",
        "pdf_size": 784177,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=355716786498221655&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA",
        "aff_domain": "cs.cmu.edu; ",
        "email": "cs.cmu.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/inouye18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1993",
        "id": "1993",
        "author_site": "Thomas Laurent, James von Brecht",
        "author": "Thomas Laurent; James Brecht",
        "abstract": "We consider deep linear networks with arbitrary convex differentiable loss. We provide a short and elementary proof of the fact that all local minima are global minima if the hidden layers are either 1) at least as wide as the input layer, or 2) at least as wide as the output layer. This result is the strongest possible in the following sense: If the loss is convex and Lipschitz but not differentiable then deep linear networks can have sub-optimal local minima.",
        "bibtex": "@InProceedings{pmlr-v80-laurent18a,\n  title = \t {Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global},\n  author =       {Laurent, Thomas and von Brecht, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2902--2907},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/laurent18a/laurent18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/laurent18a.html},\n  abstract = \t {We consider deep linear networks with arbitrary convex differentiable loss. We provide a short and elementary proof of the fact that all local minima are global minima if the hidden layers are either 1) at least as wide as the input layer, or 2) at least as wide as the output layer. This result is the strongest possible in the following sense: If the loss is convex and Lipschitz but not differentiable then deep linear networks can have sub-optimal local minima.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/laurent18a/laurent18a.pdf",
        "supp": "",
        "pdf_size": 274024,
        "gs_citation": 176,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11689987386391083608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Mathematics, Loyola Marymount University, Los Angeles, CA 90045, USA; Department of Mathematics and Statistics, California State University, Long Beach, Long Beach, CA 90840, USA",
        "aff_domain": "lmu.edu;csulb.edu",
        "email": "lmu.edu;csulb.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/laurent18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Loyola Marymount University;California State University, Long Beach",
        "aff_unique_dep": "Department of Mathematics;Department of Mathematics and Statistics",
        "aff_unique_url": "https://www.lmu.edu;https://www.csulb.edu",
        "aff_unique_abbr": "LMU;CSULB",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Los Angeles;Long Beach",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Deep Models of Interactions Across Sets",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2428",
        "id": "2428",
        "author_site": "Jason Hartford, Devon Graham, Kevin Leyton-Brown, Siamak Ravanbakhsh",
        "author": "Jason Hartford; Devon Graham; Kevin Leyton-Brown; Siamak Ravanbakhsh",
        "abstract": "We use deep learning to model interactions across two or more sets of objects, such as user{\u2013}movie ratings or protein{\u2013}drug bindings. The canonical representation of such interactions is a matrix (or tensor) with an exchangeability property: the encoding\u2019s meaning is not changed by permuting rows or columns. We argue that models should hence be Permutation Equivariant (PE): constrained to make the same predictions across such permutations. We present a parameter-sharing scheme and prove that it is maximally expressive under the PE constraint. This scheme yields three benefits. First, we demonstrate performance competitive with the state of the art on multiple matrix completion benchmarks. Second, our models require a number of parameters independent of the numbers of objects and thus scale well to large datasets. Third, models can be queried about new objects that were not available at training time, but for which interactions have since been observed. We observed surprisingly good generalization performance on this matrix extrapolation task, both within domains (e.g., new users and new movies drawn from the same distribution used for training) and even across domains (e.g., predicting music ratings after training on movie ratings).",
        "bibtex": "@InProceedings{pmlr-v80-hartford18a,\n  title = \t {Deep Models of Interactions Across Sets},\n  author =       {Hartford, Jason and Graham, Devon and Leyton-Brown, Kevin and Ravanbakhsh, Siamak},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1909--1918},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hartford18a/hartford18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hartford18a.html},\n  abstract = \t {We use deep learning to model interactions across two or more sets of objects, such as user{\u2013}movie ratings or protein{\u2013}drug bindings. The canonical representation of such interactions is a matrix (or tensor) with an exchangeability property: the encoding\u2019s meaning is not changed by permuting rows or columns. We argue that models should hence be Permutation Equivariant (PE): constrained to make the same predictions across such permutations. We present a parameter-sharing scheme and prove that it is maximally expressive under the PE constraint. This scheme yields three benefits. First, we demonstrate performance competitive with the state of the art on multiple matrix completion benchmarks. Second, our models require a number of parameters independent of the numbers of objects and thus scale well to large datasets. Third, models can be queried about new objects that were not available at training time, but for which interactions have since been observed. We observed surprisingly good generalization performance on this matrix extrapolation task, both within domains (e.g., new users and new movies drawn from the same distribution used for training) and even across domains (e.g., predicting music ratings after training on movie ratings).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hartford18a/hartford18a.pdf",
        "supp": "",
        "pdf_size": 1749893,
        "gs_citation": 189,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9552429858443331211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, University of British Columbia, Canada; Department of Computer Science, University of British Columbia, Canada; Department of Computer Science, University of British Columbia, Canada; Department of Computer Science, University of British Columbia, Canada",
        "aff_domain": "cs.ubc.ca;cs.ubc.ca; ; ",
        "email": "cs.ubc.ca;cs.ubc.ca; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/hartford18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Deep One-Class Classification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2483",
        "id": "2483",
        "author_site": "Lukas Ruff, Nico G\u00f6rnitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Robert Vandermeulen, Alexander Binder, Emmanuel M\u00fcller, Marius Kloft",
        "author": "Lukas Ruff; Robert Vandermeulen; Nico Goernitz; Lucas Deecke; Shoaib Ahmed Siddiqui; Alexander Binder; Emmanuel M\u00fcller; Marius Kloft",
        "abstract": "Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective. In this paper we introduce a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs.",
        "bibtex": "@InProceedings{pmlr-v80-ruff18a,\n  title = \t {Deep One-Class Classification},\n  author =       {Ruff, Lukas and Vandermeulen, Robert and Goernitz, Nico and Deecke, Lucas and Siddiqui, Shoaib Ahmed and Binder, Alexander and M{\\\"u}ller, Emmanuel and Kloft, Marius},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4393--4402},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ruff18a/ruff18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ruff18a.html},\n  abstract = \t {Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective. In this paper we introduce a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ruff18a/ruff18a.pdf",
        "supp": "",
        "pdf_size": 673298,
        "gs_citation": 2927,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12023251308407380383&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/ruff18a.html"
    },
    {
        "title": "Deep Predictive Coding Network for Object Recognition",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2447",
        "id": "2447",
        "author_site": "Haiguang Wen, Kuan Han, Junxing Shi, Yizhen Zhang, Eugenio Culurciello, Zhongming Liu",
        "author": "Haiguang Wen; Kuan Han; Junxing Shi; Yizhen Zhang; Eugenio Culurciello; Zhongming Liu",
        "abstract": "Based on the predictive coding theory in neuro- science, we designed a bi-directional and recur- rent neural net, namely deep predictive coding networks (PCN), that has feedforward, feedback, and recurrent connections. Feedback connections from a higher layer carry the prediction of its lower-layer representation; feedforward connec- tions carry the prediction errors to its higher-layer. Given image input, PCN runs recursive cycles of bottom-up and top-down computation to update its internal representations and reduce the differ- ence between bottom-up input and top-down pre- diction at every layer. After multiple cycles of recursive updating, the representation is used for image classification. With benchmark datasets (CIFAR-10/100, SVHN, and MNIST), PCN was found to always outperform its feedforward-only counterpart: a model without any mechanism for recurrent dynamics, and its performance tended to improve given more cycles of computation over time. In short, PCN reuses a single architecture to recursively run bottom-up and top-down pro- cesses to refine its representation towards more accurate and definitive object recognition.",
        "bibtex": "@InProceedings{pmlr-v80-wen18a,\n  title = \t {Deep Predictive Coding Network for Object Recognition},\n  author =       {Wen, Haiguang and Han, Kuan and Shi, Junxing and Zhang, Yizhen and Culurciello, Eugenio and Liu, Zhongming},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5266--5275},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wen18a/wen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wen18a.html},\n  abstract = \t {Based on the predictive coding theory in neuro- science, we designed a bi-directional and recur- rent neural net, namely deep predictive coding networks (PCN), that has feedforward, feedback, and recurrent connections. Feedback connections from a higher layer carry the prediction of its lower-layer representation; feedforward connec- tions carry the prediction errors to its higher-layer. Given image input, PCN runs recursive cycles of bottom-up and top-down computation to update its internal representations and reduce the differ- ence between bottom-up input and top-down pre- diction at every layer. After multiple cycles of recursive updating, the representation is used for image classification. With benchmark datasets (CIFAR-10/100, SVHN, and MNIST), PCN was found to always outperform its feedforward-only counterpart: a model without any mechanism for recurrent dynamics, and its performance tended to improve given more cycles of computation over time. In short, PCN reuses a single architecture to recursively run bottom-up and top-down pro- cesses to refine its representation towards more accurate and definitive object recognition.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wen18a/wen18a.pdf",
        "supp": "",
        "pdf_size": 1309887,
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13277226928501941625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of Electrical and Computer Engineering, Purdue University+Weldon School of Biomedical Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University+Weldon School of Biomedical Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University+Weldon School of Biomedical Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University+Weldon School of Biomedical Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University+Weldon School of Biomedical Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University+Weldon School of Biomedical Engineering, Purdue University",
        "aff_domain": "purdue.edu;purdue.edu;purdue.edu;purdue.edu;purdue.edu;purdue.edu",
        "email": "purdue.edu;purdue.edu;purdue.edu;purdue.edu;purdue.edu;purdue.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/wen18a.html",
        "aff_unique_index": "0+0;0+0;0+0;0+0;0+0;0+0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": ";;;;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Deep Reinforcement Learning in Continuous Action Spaces: a Case Study in the Game of Simulated Curling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2461",
        "id": "2461",
        "author_site": "kyowoon Lee, Sol-A Kim, Jaesik Choi, Seong-Whan Lee",
        "author": "Kyowoon Lee; Sol-A Kim; Jaesik Choi; Seong-Whan Lee",
        "abstract": "Many real-world applications of reinforcement learning require an agent to select optimal actions from continuous spaces. Recently, deep neural networks have successfully been applied to games with discrete actions spaces. However, deep neural networks for discrete actions are not suitable for devising strategies for games where a very small change in an action can dramatically affect the outcome. In this paper, we present a new self-play reinforcement learning framework which equips a continuous search algorithm which enables to search in continuous action spaces with a kernel regression method. Without any hand-crafted features, our network is trained by supervised learning followed by self-play reinforcement learning with a high-fidelity simulator for the Olympic sport of curling. The program trained under our framework outperforms existing programs equipped with several hand-crafted features and won an international digital curling competition.",
        "bibtex": "@InProceedings{pmlr-v80-lee18b,\n  title = \t {Deep Reinforcement Learning in Continuous Action Spaces: a Case Study in the Game of Simulated Curling},\n  author =       {Lee, Kyowoon and Kim, Sol-A and Choi, Jaesik and Lee, Seong-Whan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2937--2946},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lee18b/lee18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lee18b.html},\n  abstract = \t {Many real-world applications of reinforcement learning require an agent to select optimal actions from continuous spaces. Recently, deep neural networks have successfully been applied to games with discrete actions spaces. However, deep neural networks for discrete actions are not suitable for devising strategies for games where a very small change in an action can dramatically affect the outcome. In this paper, we present a new self-play reinforcement learning framework which equips a continuous search algorithm which enables to search in continuous action spaces with a kernel regression method. Without any hand-crafted features, our network is trained by supervised learning followed by self-play reinforcement learning with a high-fidelity simulator for the Olympic sport of curling. The program trained under our framework outperforms existing programs equipped with several hand-crafted features and won an international digital curling competition.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lee18b/lee18b.pdf",
        "supp": "",
        "pdf_size": 1315522,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6730862284084733221&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea; Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea; Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, Republic of Korea",
        "aff_domain": "unist.ac.kr; ; ; ",
        "email": "unist.ac.kr; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/lee18b.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;Korea University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Brain and Cognitive Engineering",
        "aff_unique_url": "https://www.unist.ac.kr;http://www.korea.ac.kr",
        "aff_unique_abbr": "UNIST;KU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Ulsan;Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Deep Variational Reinforcement Learning for POMDPs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2456",
        "id": "2456",
        "author_site": "Maximilian Igl, Luisa Zintgraf, Tuan Anh Le, Frank Wood, Shimon Whiteson",
        "author": "Maximilian Igl; Luisa Zintgraf; Tuan Anh Le; Frank Wood; Shimon Whiteson",
        "abstract": "Many real-world sequential decision making problems are partially observable by nature, and the environment model is typically unknown. Consequently, there is great need for reinforcement learning methods that can tackle such problems given only a stream of rewards and incomplete and noisy observations. In this paper, we propose deep variational reinforcement learning (DVRL), which introduces an inductive bias that allows an agent to learn a generative model of the environment and perform inference in that model to effectively aggregate the available information. We develop an n-step approximation to the evidence lower bound (ELBO), allowing the model to be trained jointly with the policy. This ensures that the latent state representation is suitable for the control task. In experiments on Mountain Hike and flickering Atari we show that our method outperforms previous approaches relying on recurrent neural networks to encode the past.",
        "bibtex": "@InProceedings{pmlr-v80-igl18a,\n  title = \t {Deep Variational Reinforcement Learning for {POMDP}s},\n  author =       {Igl, Maximilian and Zintgraf, Luisa and Le, Tuan Anh and Wood, Frank and Whiteson, Shimon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2117--2126},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/igl18a/igl18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/igl18a.html},\n  abstract = \t {Many real-world sequential decision making problems are partially observable by nature, and the environment model is typically unknown. Consequently, there is great need for reinforcement learning methods that can tackle such problems given only a stream of rewards and incomplete and noisy observations. In this paper, we propose deep variational reinforcement learning (DVRL), which introduces an inductive bias that allows an agent to learn a generative model of the environment and perform inference in that model to effectively aggregate the available information. We develop an n-step approximation to the evidence lower bound (ELBO), allowing the model to be trained jointly with the policy. This ensures that the latent state representation is suitable for the control task. In experiments on Mountain Hike and flickering Atari we show that our method outperforms previous approaches relying on recurrent neural networks to encode the past.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/igl18a/igl18a.pdf",
        "supp": "",
        "pdf_size": 2094791,
        "gs_citation": 350,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12007406566032573768&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of Oxford; University of Oxford; University of Oxford; University of British Columbia; University of Oxford",
        "aff_domain": "eng.ox.ac.uk; ; ; ; ",
        "email": "eng.ox.ac.uk; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/igl18a.html",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Oxford;University of British Columbia",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.ubc.ca",
        "aff_unique_abbr": "Oxford;UBC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "title": "Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2219",
        "id": "2219",
        "author_site": "Junru Wu, Yue Wang, Zhenyu Wu, Zhangyang Wang, Ashok Veeraraghavan, Yingyan Lin",
        "author": "Junru Wu; Yue Wang; Zhenyu Wu; Zhangyang Wang; Ashok Veeraraghavan; Yingyan Lin",
        "abstract": "The current trend of pushing CNNs deeper with convolutions has created a pressing demand to achieve higher compression gains on CNNs where convolutions dominate the computation and parameter amount (e.g., GoogLeNet, ResNet and Wide ResNet). Further, the high energy consumption of convolutions limits its deployment on mobile devices. To this end, we proposed a simple yet effective scheme for compressing convolutions though applying k-means clustering on the weights, compression is achieved through weight-sharing, by only recording $K$ cluster centers and weight assignment indexes. We then introduced a novel spectrally relaxed $k$-means regularization, which tends to make hard assignments of convolutional layer weights to $K$ learned cluster centers during re-training. We additionally propose an improved set of metrics to estimate energy consumption of CNN hardware implementations, whose estimation results are verified to be consistent with previously proposed energy estimation tool extrapolated from actual hardware measurements. We finally evaluated Deep $k$-Means across several CNN models in terms of both compression ratio and energy consumption reduction, observing promising results without incurring accuracy loss. The code is available at https://github.com/Sandbox3aster/Deep-K-Means",
        "bibtex": "@InProceedings{pmlr-v80-wu18h,\n  title = \t {Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions},\n  author =       {Wu, Junru and Wang, Yue and Wu, Zhenyu and Wang, Zhangyang and Veeraraghavan, Ashok and Lin, Yingyan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5363--5372},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18h/wu18h.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18h.html},\n  abstract = \t {The current trend of pushing CNNs deeper with convolutions has created a pressing demand to achieve higher compression gains on CNNs where convolutions dominate the computation and parameter amount (e.g., GoogLeNet, ResNet and Wide ResNet). Further, the high energy consumption of convolutions limits its deployment on mobile devices. To this end, we proposed a simple yet effective scheme for compressing convolutions though applying k-means clustering on the weights, compression is achieved through weight-sharing, by only recording $K$ cluster centers and weight assignment indexes. We then introduced a novel spectrally relaxed $k$-means regularization, which tends to make hard assignments of convolutional layer weights to $K$ learned cluster centers during re-training. We additionally propose an improved set of metrics to estimate energy consumption of CNN hardware implementations, whose estimation results are verified to be consistent with previously proposed energy estimation tool extrapolated from actual hardware measurements. We finally evaluated Deep $k$-Means across several CNN models in terms of both compression ratio and energy consumption reduction, observing promising results without incurring accuracy loss. The code is available at https://github.com/Sandbox3aster/Deep-K-Means}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18h/wu18h.pdf",
        "supp": "",
        "pdf_size": 423276,
        "gs_citation": 157,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5421215697510972919&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Department of Electrical and Computer Engineering, Rice University, Houston, TX, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Department of Electrical and Computer Engineering, Rice University, Houston, TX, USA; Department of Electrical and Computer Engineering, Rice University, Houston, TX, USA",
        "aff_domain": "tamu.edu;rice.edu; ; ; ; ",
        "email": "tamu.edu;rice.edu; ; ; ; ",
        "github": "https://github.com/Sandbox3aster/Deep-K-Means",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/wu18h.html",
        "aff_unique_index": "0;1;0;0;1;1",
        "aff_unique_norm": "Texas A&M University;Rice University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tamu.edu;https://www.rice.edu",
        "aff_unique_abbr": "TAMU;Rice",
        "aff_campus_unique_index": "0;1;0;0;1;1",
        "aff_campus_unique": "College Station;Houston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Delayed Impact of Fair Machine Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2403",
        "id": "2403",
        "author_site": "Lydia T. Liu, Sarah Dean, Esther Rolf, Max Simchowitz, Moritz Hardt",
        "author": "Lydia T. Liu; Sarah Dean; Esther Rolf; Max Simchowitz; Moritz Hardt",
        "abstract": "Fairness in machine learning has predominantly been studied in static classification settings without concern for how decisions change the underlying population over time. Conventional wisdom suggests that fairness criteria promote the long-term well-being of those groups they aim to protect. We study how static fairness criteria interact with temporal indicators of well-being, such as long-term improvement, stagnation, and decline in a variable of interest. We demonstrate that even in a one-step feedback model, common fairness criteria in general do not promote improvement over time, and may in fact cause harm in cases where an unconstrained objective would not. We completely characterize the delayed impact of three standard criteria, contrasting the regimes in which these exhibit qualitatively different behavior. In addition, we find that a natural form of measurement error broadens the regime in which fairness criteria perform favorably. Our results highlight the importance of measurement and temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.",
        "bibtex": "@InProceedings{pmlr-v80-liu18c,\n  title = \t {Delayed Impact of Fair Machine Learning},\n  author =       {Liu, Lydia T. and Dean, Sarah and Rolf, Esther and Simchowitz, Max and Hardt, Moritz},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3150--3158},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18c/liu18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18c.html},\n  abstract = \t {Fairness in machine learning has predominantly been studied in static classification settings without concern for how decisions change the underlying population over time. Conventional wisdom suggests that fairness criteria promote the long-term well-being of those groups they aim to protect. We study how static fairness criteria interact with temporal indicators of well-being, such as long-term improvement, stagnation, and decline in a variable of interest. We demonstrate that even in a one-step feedback model, common fairness criteria in general do not promote improvement over time, and may in fact cause harm in cases where an unconstrained objective would not. We completely characterize the delayed impact of three standard criteria, contrasting the regimes in which these exhibit qualitatively different behavior. In addition, we find that a natural form of measurement error broadens the regime in which fairness criteria perform favorably. Our results highlight the importance of measurement and temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18c/liu18c.pdf",
        "supp": "",
        "pdf_size": 1811243,
        "gs_citation": 626,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5181623229195224544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California at Berkeley; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley",
        "aff_domain": "berkeley.edu; ; ; ; ",
        "email": "berkeley.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/liu18c.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Dependent Relational Gamma Process Models for Longitudinal Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1942",
        "id": "1942",
        "author_site": "Sikun Yang, Heinz Koeppl",
        "author": "Sikun Yang; Heinz Koeppl",
        "abstract": "A probabilistic framework based on the covariate-dependent relational gamma process is developed to analyze relational data arising from longitudinal networks. The proposed framework characterizes networked nodes by nonnegative node-group memberships, which allow each node to belong to multiple latent groups simultaneously, and encodes edge probabilities between each pair of nodes using a Bernoulli Poisson link to the embedded latent space. Within the latent space, our framework models the birth and death dynamics of individual groups via a thinning function. Our framework also captures the evolution of individual node-group memberships over time using gamma Markov processes. Exploiting the recent advances in data augmentation and marginalization techniques, a simple and efficient Gibbs sampler is proposed for posterior computation. Experimental results on a simulation study and three real-world temporal network data sets demonstrate the model\u2019s capability, competitive performance and scalability compared to state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v80-yang18b,\n  title = \t {Dependent Relational Gamma Process Models for Longitudinal Networks},\n  author =       {Yang, Sikun and Koeppl, Heinz},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5551--5560},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yang18b/yang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yang18b.html},\n  abstract = \t {A probabilistic framework based on the covariate-dependent relational gamma process is developed to analyze relational data arising from longitudinal networks. The proposed framework characterizes networked nodes by nonnegative node-group memberships, which allow each node to belong to multiple latent groups simultaneously, and encodes edge probabilities between each pair of nodes using a Bernoulli Poisson link to the embedded latent space. Within the latent space, our framework models the birth and death dynamics of individual groups via a thinning function. Our framework also captures the evolution of individual node-group memberships over time using gamma Markov processes. Exploiting the recent advances in data augmentation and marginalization techniques, a simple and efficient Gibbs sampler is proposed for posterior computation. Experimental results on a simulation study and three real-world temporal network data sets demonstrate the model\u2019s capability, competitive performance and scalability compared to state-of-the-art methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yang18b/yang18b.pdf",
        "supp": "",
        "pdf_size": 909649,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2367780675939446917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt, Germany; Department of Electrical Engineering and Information Technology, Technische Universit\u00e4t Darmstadt, Germany",
        "aff_domain": "bcs.tu-darmstadt.de;bcs.tu-darmstadt.de",
        "email": "bcs.tu-darmstadt.de;bcs.tu-darmstadt.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/yang18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2236",
        "id": "2236",
        "author_site": "Simon Olofsson, Marc P Deisenroth, Ruth Misener",
        "author": "Simon Olofsson; Marc Deisenroth; Ruth Misener",
        "abstract": "Healthcare companies must submit pharmaceutical drugs or medical device to regulatory bodies before marketing new technology. Regulatory bodies frequently require transparent and interpretable computational modelling to justify a new healthcare technology, but researchers may have several competing models for a biological system and too little data to discriminate between the models. In design of experiments for model discrimination, where the goal is to design maximally informative physical experiments in order to discriminate between rival predictive models, research has focused either on analytical approaches, which cannot manage all functions, or on data-driven approaches, which may have computational difficulties or lack interpretable marginal predictive distributions. We develop a methodology for introducing Gaussian process surrogates in lieu of the original mechanistic models. This allows us to extend existing design and model discrimination methods developed for analytical models to cases of non-analytical models.",
        "bibtex": "@InProceedings{pmlr-v80-olofsson18a,\n  title = \t {Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches},\n  author =       {Olofsson, Simon and Deisenroth, Marc and Misener, Ruth},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3908--3917},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/olofsson18a/olofsson18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/olofsson18a.html},\n  abstract = \t {Healthcare companies must submit pharmaceutical drugs or medical device to regulatory bodies before marketing new technology. Regulatory bodies frequently require transparent and interpretable computational modelling to justify a new healthcare technology, but researchers may have several competing models for a biological system and too little data to discriminate between the models. In design of experiments for model discrimination, where the goal is to design maximally informative physical experiments in order to discriminate between rival predictive models, research has focused either on analytical approaches, which cannot manage all functions, or on data-driven approaches, which may have computational difficulties or lack interpretable marginal predictive distributions. We develop a methodology for introducing Gaussian process surrogates in lieu of the original mechanistic models. This allows us to extend existing design and model discrimination methods developed for analytical models to cases of non-analytical models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/olofsson18a/olofsson18a.pdf",
        "supp": "",
        "pdf_size": 2585677,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9325502538406369296&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Dept. of Computing, Imperial College London, United Kingdom + PROWLER.io, United Kingdom; Dept. of Computing, Imperial College London, United Kingdom + PROWLER.io, United Kingdom; Dept. of Computing, Imperial College London, United Kingdom",
        "aff_domain": "imperial.ac.uk;imperial.ac.uk;imperial.ac.uk",
        "email": "imperial.ac.uk;imperial.ac.uk;imperial.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/olofsson18a.html",
        "aff_unique_index": "0+1;0+1;0",
        "aff_unique_norm": "Imperial College London;PROWLER.io",
        "aff_unique_dep": "Dept. of Computing;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://prowler.io",
        "aff_unique_abbr": "Imperial;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0+0;0+0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Detecting and Correcting for Label Shift with Black Box Predictors",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2117",
        "id": "2117",
        "author_site": "Zachary Lipton, Yu-Xiang Wang, Alexander Smola",
        "author": "Zachary Lipton; Yu-Xiang Wang; Alexander Smola",
        "abstract": "Faced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets), cause symptoms (observations), we focus on label shift, where the label marginal p(y) changes but the conditional p(x| y) does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution p(y). BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE\u2019s consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.",
        "bibtex": "@InProceedings{pmlr-v80-lipton18a,\n  title = \t {Detecting and Correcting for Label Shift with Black Box Predictors},\n  author =       {Lipton, Zachary and Wang, Yu-Xiang and Smola, Alexander},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3122--3130},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lipton18a/lipton18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lipton18a.html},\n  abstract = \t {Faced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets), cause symptoms (observations), we focus on label shift, where the label marginal p(y) changes but the conditional p(x| y) does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution p(y). BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE\u2019s consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lipton18a/lipton18a.pdf",
        "supp": "",
        "pdf_size": 1026797,
        "gs_citation": 684,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11186647129267032175&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Carnegie Mellon University; Amazon AI + UC Santa Barbara; Amazon AI",
        "aff_domain": "cmu.edu;amazon.com;amazon.com",
        "email": "cmu.edu;amazon.com;amazon.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lipton18a.html",
        "aff_unique_index": "0;1+2;1",
        "aff_unique_norm": "Carnegie Mellon University;Amazon;University of California, Santa Barbara",
        "aff_unique_dep": ";Amazon AI;",
        "aff_unique_url": "https://www.cmu.edu;https://www.amazon.com;https://www.ucsb.edu",
        "aff_unique_abbr": "CMU;Amazon;UCSB",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Santa Barbara",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Detecting non-causal artifacts in multivariate linear regression models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2007",
        "id": "2007",
        "author_site": "Dominik Janzing, Bernhard Sch\u00f6lkopf",
        "author": "Dominik Janzing; Bernhard Sch\u00f6lkopf",
        "abstract": "We consider linear models where d potential causes X_1,...,X_d are correlated with one target quantity Y and propose a method to infer whether the association is causal or whether it is an artifact caused by overfitting or hidden common causes. We employ the idea that in the former case the vector of regression coefficients has \u2018generic\u2019 orientation relative to the covariance matrix Sigma_{XX} of X. Using an ICA based model for confounding, we show that both confounding and overfitting yield regression vectors that concentrate mainly in the space of low eigenvalues of Sigma_{XX}.",
        "bibtex": "@InProceedings{pmlr-v80-janzing18a,\n  title = \t {Detecting non-causal artifacts in multivariate linear regression models},\n  author =       {Janzing, Dominik and Sch{\\\"o}lkopf, Bernhard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2245--2253},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/janzing18a/janzing18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/janzing18a.html},\n  abstract = \t {We consider linear models where d potential causes X_1,...,X_d are correlated with one target quantity Y and propose a method to infer whether the association is causal or whether it is an artifact caused by overfitting or hidden common causes. We employ the idea that in the former case the vector of regression coefficients has \u2018generic\u2019 orientation relative to the covariance matrix Sigma_{XX} of X. Using an ICA based model for confounding, we show that both confounding and overfitting yield regression vectors that concentrate mainly in the space of low eigenvalues of Sigma_{XX}.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/janzing18a/janzing18a.pdf",
        "supp": "",
        "pdf_size": 377737,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6321142934893531881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Amazon Development Center, T\u00fcbingen, Germany+Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": "amazon.com; ",
        "email": "amazon.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/janzing18a.html",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "Amazon;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Amazon Development Center;",
        "aff_unique_url": "https://www.amazon.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": ";MPI-IS",
        "aff_campus_unique_index": "0+0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "DiCE: The Infinitely Differentiable Monte Carlo Estimator",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2266",
        "id": "2266",
        "author_site": "Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim Rockt\u00e4schel, Eric Xing, Shimon Whiteson",
        "author": "Jakob Foerster; Gregory Farquhar; Maruan Al-Shedivat; Tim Rockt\u00e4schel; Eric Xing; Shimon Whiteson",
        "abstract": "The score function estimator is widely used for estimating gradients of stochastic objectives in stochastic computation graphs (SCG), eg., in reinforcement learning and meta-learning. While deriving the first-order gradient estimators by differentiating a surrogate loss (SL) objective is computationally and conceptually simple, using the same approach for higher-order derivatives is more challenging. Firstly, analytically deriving and implementing such estimators is laborious and not compliant with automatic differentiation. Secondly, repeatedly applying SL to construct new objectives for each order derivative involves increasingly cumbersome graph manipulations. Lastly, to match the first-order gradient under differentiation, SL treats part of the cost as a fixed sample, which we show leads to missing and wrong terms for estimators of higher-order derivatives. To address all these shortcomings in a unified way, we introduce DiCE, which provides a single objective that can be differentiated repeatedly, generating correct estimators of derivatives of any order in SCGs. Unlike SL, DiCE relies on automatic differentiation for performing the requisite graph manipulations. We verify the correctness of DiCE both through a proof and numerical evaluation of the DiCE derivative estimates. We also use DiCE to propose and evaluate a novel approach for multi-agent learning. Our code is available at https://github.com/alshedivat/lola.",
        "bibtex": "@InProceedings{pmlr-v80-foerster18a,\n  title = \t {{D}i{CE}: The Infinitely Differentiable {M}onte {C}arlo Estimator},\n  author =       {Foerster, Jakob and Farquhar, Gregory and Al-Shedivat, Maruan and Rockt{\\\"a}schel, Tim and Xing, Eric and Whiteson, Shimon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1529--1538},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/foerster18a/foerster18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/foerster18a.html},\n  abstract = \t {The score function estimator is widely used for estimating gradients of stochastic objectives in stochastic computation graphs (SCG), eg., in reinforcement learning and meta-learning. While deriving the first-order gradient estimators by differentiating a surrogate loss (SL) objective is computationally and conceptually simple, using the same approach for higher-order derivatives is more challenging. Firstly, analytically deriving and implementing such estimators is laborious and not compliant with automatic differentiation. Secondly, repeatedly applying SL to construct new objectives for each order derivative involves increasingly cumbersome graph manipulations. Lastly, to match the first-order gradient under differentiation, SL treats part of the cost as a fixed sample, which we show leads to missing and wrong terms for estimators of higher-order derivatives. To address all these shortcomings in a unified way, we introduce DiCE, which provides a single objective that can be differentiated repeatedly, generating correct estimators of derivatives of any order in SCGs. Unlike SL, DiCE relies on automatic differentiation for performing the requisite graph manipulations. We verify the correctness of DiCE both through a proof and numerical evaluation of the DiCE derivative estimates. We also use DiCE to propose and evaluate a novel approach for multi-agent learning. Our code is available at https://github.com/alshedivat/lola.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/foerster18a/foerster18a.pdf",
        "supp": "",
        "pdf_size": 1393950,
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9790220931943601676&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "University of Oxford1; University of Oxford1; Carnegie Mellon University2; University of Oxford1; Carnegie Mellon University2; University of Oxford1",
        "aff_domain": "cs.ox.ac.uk; ; ; ; ; ",
        "email": "cs.ox.ac.uk; ; ; ; ; ",
        "github": "github.com/alshedivat/lola",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/foerster18a.html",
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "University of Oxford;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.cmu.edu",
        "aff_unique_abbr": "Oxford;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Differentiable Abstract Interpretation for Provably Robust Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2477",
        "id": "2477",
        "author_site": "Matthew Mirman, Timon Gehr, Martin Vechev",
        "author": "Matthew Mirman; Timon Gehr; Martin Vechev",
        "abstract": "We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.",
        "bibtex": "@InProceedings{pmlr-v80-mirman18b,\n  title = \t {Differentiable Abstract Interpretation for Provably Robust Neural Networks},\n  author =       {Mirman, Matthew and Gehr, Timon and Vechev, Martin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3578--3586},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mirman18b/mirman18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mirman18b.html},\n  abstract = \t {We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mirman18b/mirman18b.pdf",
        "supp": "",
        "pdf_size": 388132,
        "gs_citation": 648,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15605098958178065362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland",
        "aff_domain": "inf.ethz.ch; ;inf.ethz.ch",
        "email": "inf.ethz.ch; ;inf.ethz.ch",
        "github": "",
        "project": "http://diffai.ethz.ch",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mirman18b.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Differentiable Compositional Kernel Learning for Gaussian Processes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2378",
        "id": "2378",
        "author_site": "Shengyang Sun, Guodong Zhang, Chaoqi Wang, Wenyuan Zeng, Jiaman Li, Roger Grosse",
        "author": "Shengyang Sun; Guodong Zhang; Chaoqi Wang; Wenyuan Zeng; Jiaman Li; Roger Grosse",
        "abstract": "The generalization properties of Gaussian processes depend heavily on the choice of kernel, and this choice remains a dark art. We present the Neural Kernel Network (NKN), a flexible family of kernels represented by a neural network. The NKN\u2019s architecture is based on the composition rules for kernels, so that each unit of the network corresponds to a valid kernel. It can compactly approximate compositional kernel structures such as those used by the Automatic Statistician (Lloyd et al., 2014), but because the architecture is differentiable, it is end-to-end trainable with gradient- based optimization. We show that the NKN is universal for the class of stationary kernels. Empirically we demonstrate NKN\u2019s pattern discovery and extrapolation abilities on several tasks that depend crucially on identifying the underlying structure, including time series and texture extrapolation, as well as Bayesian optimization.",
        "bibtex": "@InProceedings{pmlr-v80-sun18e,\n  title = \t {Differentiable Compositional Kernel Learning for {G}aussian Processes},\n  author =       {Sun, Shengyang and Zhang, Guodong and Wang, Chaoqi and Zeng, Wenyuan and Li, Jiaman and Grosse, Roger},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4828--4837},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sun18e/sun18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sun18e.html},\n  abstract = \t {The generalization properties of Gaussian processes depend heavily on the choice of kernel, and this choice remains a dark art. We present the Neural Kernel Network (NKN), a flexible family of kernels represented by a neural network. The NKN\u2019s architecture is based on the composition rules for kernels, so that each unit of the network corresponds to a valid kernel. It can compactly approximate compositional kernel structures such as those used by the Automatic Statistician (Lloyd et al., 2014), but because the architecture is differentiable, it is end-to-end trainable with gradient- based optimization. We show that the NKN is universal for the class of stationary kernels. Empirically we demonstrate NKN\u2019s pattern discovery and extrapolation abilities on several tasks that depend crucially on identifying the underlying structure, including time series and texture extrapolation, as well as Bayesian optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sun18e/sun18e.pdf",
        "supp": "",
        "pdf_size": 2746042,
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9136343757471146046&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of Toronto, Toronto, ON, CA + Vector Institute; Department of Computer Science, University of Toronto, Toronto, ON, CA + Vector Institute; Department of Computer Science, University of Toronto, Toronto, ON, CA + Vector Institute; Department of Computer Science, University of Toronto, Toronto, ON, CA + Vector Institute + Uber Advanced Technologies Group, Toronto, ON, CA; Department of Computer Science, University of Toronto, Toronto, ON, CA + Vector Institute; Department of Computer Science, University of Toronto, Toronto, ON, CA + Vector Institute",
        "aff_domain": "cs.toronto.edu; ; ; ; ; ",
        "email": "cs.toronto.edu; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/sun18e.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1+2;0+1;0+1",
        "aff_unique_norm": "University of Toronto;Vector Institute;Uber Advanced Technologies Group",
        "aff_unique_dep": "Department of Computer Science;;Advanced Technologies Group",
        "aff_unique_url": "https://www.utoronto.ca;https://vectorinstitute.ai/;https://www.uber.com/ca/en/",
        "aff_unique_abbr": "U of T;Vector Institute;Uber ATG",
        "aff_campus_unique_index": "0;0;0;0+0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0+0;0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Differentiable Dynamic Programming for Structured Prediction and Attention",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2114",
        "id": "2114",
        "author_site": "Arthur Mensch, Mathieu Blondel",
        "author": "Arthur Mensch; Mathieu Blondel",
        "abstract": "Dynamic programming (DP) solves a variety of structured combinatorial problems by iteratively breaking them down into smaller subproblems. In spite of their versatility, many DP algorithms are non-differentiable, which hampers their use as a layer in neural networks trained by backpropagation. To address this issue, we propose to smooth the max operator in the dynamic programming recursion, using a strongly convex regularizer. This allows to relax both the optimal value and solution of the original combinatorial problem, and turns a broad class of DP algorithms into differentiable operators. Theoretically, we provide a new probabilistic perspective on backpropagating through these DP operators, and relate them to inference in graphical models. We derive two particular instantiations of our framework, a smoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm for time-series alignment. We showcase these instantiations on structured prediction (audio-to-score alignment, NER) and on structured and sparse attention for translation.",
        "bibtex": "@InProceedings{pmlr-v80-mensch18a,\n  title = \t {Differentiable Dynamic Programming for Structured Prediction and Attention},\n  author =       {Mensch, Arthur and Blondel, Mathieu},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3462--3471},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mensch18a/mensch18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mensch18a.html},\n  abstract = \t {Dynamic programming (DP) solves a variety of structured combinatorial problems by iteratively breaking them down into smaller subproblems. In spite of their versatility, many DP algorithms are non-differentiable, which hampers their use as a layer in neural networks trained by backpropagation. To address this issue, we propose to smooth the max operator in the dynamic programming recursion, using a strongly convex regularizer. This allows to relax both the optimal value and solution of the original combinatorial problem, and turns a broad class of DP algorithms into differentiable operators. Theoretically, we provide a new probabilistic perspective on backpropagating through these DP operators, and relate them to inference in graphical models. We derive two particular instantiations of our framework, a smoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm for time-series alignment. We showcase these instantiations on structured prediction (audio-to-score alignment, NER) and on structured and sparse attention for translation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mensch18a/mensch18a.pdf",
        "supp": "",
        "pdf_size": 375094,
        "gs_citation": 170,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13448789584202552560&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Inria, CEA, Universit \u00b4e Paris-Saclay, Gif-sur-Yvette, France; NTT Communication Science Laboratories, Kyoto, Japan",
        "aff_domain": "m4x.org;mblondel.org",
        "email": "m4x.org;mblondel.org",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/mensch18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "INRIA;NTT Communication Science Laboratories",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.inria.fr;https://www.ntt-csl.com",
        "aff_unique_abbr": "Inria;",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Gif-sur-Yvette;Kyoto",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;Japan"
    },
    {
        "title": "Differentiable plasticity: training plastic neural networks with backpropagation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2078",
        "id": "2078",
        "author_site": "Thomas Miconi, Kenneth Stanley, Jeff Clune",
        "author": "Thomas Miconi; Kenneth Stanley; Jeff Clune",
        "abstract": "How can we build agents that keep learning from experience, quickly and efficiently, after their initial training? Here we take inspiration from the main mechanism of learning in biological brains: synaptic plasticity, carefully tuned by evolution to produce efficient lifelong learning. We show that plasticity, just like connection weights, can be optimized by gradient descent in large (millions of parameters) recurrent networks with Hebbian plastic connections. First, recurrent plastic networks with more than two million parameters can be trained to memorize and reconstruct sets of novel, high-dimensional (1000+ pixels) natural images not seen during training. Crucially, traditional non-plastic recurrent networks fail to solve this task. Furthermore, trained plastic networks can also solve generic meta-learning tasks such as the Omniglot task, with competitive results and little parameter overhead. Finally, in reinforcement learning settings, plastic networks outperform non-plastic equivalent in a maze exploration task. We conclude that differentiable plasticity may provide a powerful novel approach to the learning-to-learn problem.",
        "bibtex": "@InProceedings{pmlr-v80-miconi18a,\n  title = \t {Differentiable plasticity: training plastic neural networks with backpropagation},\n  author =       {Miconi, Thomas and Stanley, Kenneth and Clune, Jeff},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3559--3568},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/miconi18a/miconi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/miconi18a.html},\n  abstract = \t {How can we build agents that keep learning from experience, quickly and efficiently, after their initial training? Here we take inspiration from the main mechanism of learning in biological brains: synaptic plasticity, carefully tuned by evolution to produce efficient lifelong learning. We show that plasticity, just like connection weights, can be optimized by gradient descent in large (millions of parameters) recurrent networks with Hebbian plastic connections. First, recurrent plastic networks with more than two million parameters can be trained to memorize and reconstruct sets of novel, high-dimensional (1000+ pixels) natural images not seen during training. Crucially, traditional non-plastic recurrent networks fail to solve this task. Furthermore, trained plastic networks can also solve generic meta-learning tasks such as the Omniglot task, with competitive results and little parameter overhead. Finally, in reinforcement learning settings, plastic networks outperform non-plastic equivalent in a maze exploration task. We conclude that differentiable plasticity may provide a powerful novel approach to the learning-to-learn problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/miconi18a/miconi18a.pdf",
        "supp": "",
        "pdf_size": 831695,
        "gs_citation": 195,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16849084099727983459&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Uber AI Labs; Uber AI Labs; Uber AI Labs",
        "aff_domain": "uber.com; ; ",
        "email": "uber.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/miconi18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Uber",
        "aff_unique_dep": "Uber AI Labs",
        "aff_unique_url": "https://www.uber.com",
        "aff_unique_abbr": "Uber AI Labs",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Differentially Private Database Release via Kernel Mean Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1964",
        "id": "1964",
        "author_site": "Matej Balog, Ilya Tolstikhin, Bernhard Sch\u00f6lkopf",
        "author": "Matej Balog; Ilya Tolstikhin; Bernhard Sch\u00f6lkopf",
        "abstract": "We lay theoretical foundations for new database release mechanisms that allow third-parties to construct consistent estimators of population statistics, while ensuring that the privacy of each individual contributing to the database is protected. The proposed framework rests on two main ideas. First, releasing (an estimate of) the kernel mean embedding of the data generating random variable instead of the database itself still allows third-parties to construct consistent estimators of a wide class of population statistics. Second, the algorithm can satisfy the definition of differential privacy by basing the released kernel mean embedding on entirely synthetic data points, while controlling accuracy through the metric available in a Reproducing Kernel Hilbert Space. We describe two instantiations of the proposed framework, suitable under different scenarios, and prove theoretical results guaranteeing differential privacy of the resulting algorithms and the consistency of estimators constructed from their outputs.",
        "bibtex": "@InProceedings{pmlr-v80-balog18a,\n  title = \t {Differentially Private Database Release via Kernel Mean Embeddings},\n  author =       {Balog, Matej and Tolstikhin, Ilya and Sch{\\\"o}lkopf, Bernhard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {414--422},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balog18a/balog18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balog18a.html},\n  abstract = \t {We lay theoretical foundations for new database release mechanisms that allow third-parties to construct consistent estimators of population statistics, while ensuring that the privacy of each individual contributing to the database is protected. The proposed framework rests on two main ideas. First, releasing (an estimate of) the kernel mean embedding of the data generating random variable instead of the database itself still allows third-parties to construct consistent estimators of a wide class of population statistics. Second, the algorithm can satisfy the definition of differential privacy by basing the released kernel mean embedding on entirely synthetic data points, while controlling accuracy through the metric available in a Reproducing Kernel Hilbert Space. We describe two instantiations of the proposed framework, suitable under different scenarios, and prove theoretical results guaranteeing differential privacy of the resulting algorithms and the consistency of estimators constructed from their outputs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balog18a/balog18a.pdf",
        "supp": "",
        "pdf_size": 3309468,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3884748492191157354&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "MPI-IS, T\u00fcbingen, Germany+University of Cambridge, UK; MPI-IS, T\u00fcbingen, Germany; MPI-IS, T\u00fcbingen, Germany",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "https://github.com/matejbalog/RKHS-private-database/",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/balog18a.html",
        "aff_unique_index": "0+1;0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;University of Cambridge",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.mpituebingen.mpg.de;https://www.cam.ac.uk",
        "aff_unique_abbr": "MPI-IS;Cambridge",
        "aff_campus_unique_index": "0+1;0;0",
        "aff_campus_unique": "T\u00fcbingen;Cambridge",
        "aff_country_unique_index": "0+1;0;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "title": "Differentially Private Identity and Equivalence Testing of Discrete Distributions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2415",
        "id": "2415",
        "author_site": "Maryam Aliakbarpour, Ilias Diakonikolas, MIT Ronitt Rubinfeld",
        "author": "Maryam Aliakbarpour; Ilias Diakonikolas; Ronitt Rubinfeld",
        "abstract": "We study the fundamental problems of identity and equivalence testing over a discrete population from random samples. Our goal is to develop efficient testers while guaranteeing differential privacy to the individuals of the population. We provide sample-efficient differentially private testers for these problems. Our theoretical results significantly improve over the best known algorithms for identity testing, and are the first results for private equivalence testing. The conceptual message of our work is that there exist private hypothesis testers that are nearly as sample-efficient as their non-private counterparts. We perform an experimental evaluation of our algorithms on synthetic data. Our experiments illustrate that our private testers achieve small type I and type II errors with sample size",
        "bibtex": "@InProceedings{pmlr-v80-aliakbarpour18a,\n  title = \t {Differentially Private Identity and Equivalence Testing of Discrete Distributions},\n  author =       {Aliakbarpour, Maryam and Diakonikolas, Ilias and Rubinfeld, Ronitt},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {169--178},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/aliakbarpour18a/aliakbarpour18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/aliakbarpour18a.html},\n  abstract = \t {We study the fundamental problems of identity and equivalence testing over a discrete population from random samples. Our goal is to develop efficient testers while guaranteeing differential privacy to the individuals of the population. We provide sample-efficient differentially private testers for these problems. Our theoretical results significantly improve over the best known algorithms for identity testing, and are the first results for private equivalence testing. The conceptual message of our work is that there exist private hypothesis testers that are nearly as sample-efficient as their non-private counterparts. We perform an experimental evaluation of our algorithms on synthetic data. Our experiments illustrate that our private testers achieve small type I and type II errors with sample size",
        "pdf": "http://proceedings.mlr.press/v80/aliakbarpour18a/aliakbarpour18a.pdf",
        "supp": "",
        "pdf_size": 630018,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=804099797784198114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "CSAIL, MIT, Cambridge, MA 02139, USA+TAU, Tel Aviv-Yafo, Israel; Department of Computer Science, USC, Los Angeles, CA 90089, USA+TAU, Tel Aviv-Yafo, Israel; CSAIL, MIT, Cambridge, MA 02139, USA",
        "aff_domain": "mit.edu;usc.edu;csail.mit.edu",
        "email": "mit.edu;usc.edu;csail.mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/aliakbarpour18a.html",
        "aff_unique_index": "0+1;2+1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Tel Aviv University;University of Southern California",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;;Department of Computer Science",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.tau.ac.il;https://www.usc.edu",
        "aff_unique_abbr": "MIT;TAU;USC",
        "aff_campus_unique_index": "0+1;2+1;0",
        "aff_campus_unique": "Cambridge;Tel Aviv-Yafo;Los Angeles",
        "aff_country_unique_index": "0+1;0+1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Differentially Private Matrix Completion Revisited",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2400",
        "id": "2400",
        "author_site": "Prateek Jain, Om Dipakbhai Thakkar, Abhradeep Thakurta",
        "author": "Prateek Jain; Om Dipakbhai Thakkar; Abhradeep Thakurta",
        "abstract": "We provide the first provably joint differentially private algorithm with formal utility guarantees for the problem of user-level privacy-preserving collaborative filtering. Our algorithm is based on the Frank-Wolfe method, and it consistently estimates the underlying preference matrix as long as the number of users $m$ is $\\omega(n^{5/4})$, where $n$ is the number of items, and each user provides her preference for at least $\\sqrt{n}$ randomly selected items. Along the way, we provide an optimal differentially private algorithm for singular vector computation, based on the celebrated Oja\u2019s method, that provides significant savings in terms of space and time while operating on sparse matrices. We also empirically evaluate our algorithm on a suite of datasets, and show that it consistently outperforms the state-of-the-art private algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-jain18b,\n  title = \t {Differentially Private Matrix Completion Revisited},\n  author =       {Jain, Prateek and Thakkar, Om Dipakbhai and Thakurta, Abhradeep},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2215--2224},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jain18b/jain18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jain18b.html},\n  abstract = \t {We provide the first provably joint differentially private algorithm with formal utility guarantees for the problem of user-level privacy-preserving collaborative filtering. Our algorithm is based on the Frank-Wolfe method, and it consistently estimates the underlying preference matrix as long as the number of users $m$ is $\\omega(n^{5/4})$, where $n$ is the number of items, and each user provides her preference for at least $\\sqrt{n}$ randomly selected items. Along the way, we provide an optimal differentially private algorithm for singular vector computation, based on the celebrated Oja\u2019s method, that provides significant savings in terms of space and time while operating on sparse matrices. We also empirically evaluate our algorithm on a suite of datasets, and show that it consistently outperforms the state-of-the-art private algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jain18b/jain18b.pdf",
        "supp": "",
        "pdf_size": 700416,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7598527399935632849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Microsoft Research; Department of Computer Science, Boston University; Computer Science Department, University of California Santa Cruz",
        "aff_domain": "microsoft.com;bu.edu;ucsc.edu",
        "email": "microsoft.com;bu.edu;ucsc.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jain18b.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Microsoft;Boston University;University of California, Santa Cruz",
        "aff_unique_dep": "Microsoft Research;Department of Computer Science;Computer Science Department",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.bu.edu;https://www.ucsc.edu",
        "aff_unique_abbr": "MSR;BU;UCSC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Santa Cruz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Dimensionality-Driven Learning with Noisy Labels",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1970",
        "id": "1970",
        "author_site": "Xingjun Ma, Yisen Wang, Michael E. Houle, Shuo Zhou, Sarah Erfani, Shutao Xia, Sudanthi Wijewickrema, James Bailey",
        "author": "Xingjun Ma; Yisen Wang; Michael E. Houle; Shuo Zhou; Sarah Erfani; Shutao Xia; Sudanthi Wijewickrema; James Bailey",
        "abstract": "Datasets with significant proportions of noisy (incorrect) class labels present challenges for training accurate Deep Neural Networks (DNNs). We propose a new perspective for understanding DNN generalization for such datasets, by investigating the dimensionality of the deep representation subspace of training samples. We show that from a dimensionality perspective, DNNs exhibit quite distinctive learning styles when trained with clean labels versus when trained with a proportion of noisy labels. Based on this finding, we develop a new dimensionality-driven learning strategy, which monitors the dimensionality of subspaces during training and adapts the loss function accordingly. We empirically demonstrate that our approach is highly tolerant to significant proportions of noisy labels, and can effectively learn low-dimensional local subspaces that capture the data distribution.",
        "bibtex": "@InProceedings{pmlr-v80-ma18d,\n  title = \t {Dimensionality-Driven Learning with Noisy Labels},\n  author =       {Ma, Xingjun and Wang, Yisen and Houle, Michael E. and Zhou, Shuo and Erfani, Sarah and Xia, Shutao and Wijewickrema, Sudanthi and Bailey, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3355--3364},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ma18d/ma18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ma18d.html},\n  abstract = \t {Datasets with significant proportions of noisy (incorrect) class labels present challenges for training accurate Deep Neural Networks (DNNs). We propose a new perspective for understanding DNN generalization for such datasets, by investigating the dimensionality of the deep representation subspace of training samples. We show that from a dimensionality perspective, DNNs exhibit quite distinctive learning styles when trained with clean labels versus when trained with a proportion of noisy labels. Based on this finding, we develop a new dimensionality-driven learning strategy, which monitors the dimensionality of subspaces during training and adapts the loss function accordingly. We empirically demonstrate that our approach is highly tolerant to significant proportions of noisy labels, and can effectively learn low-dimensional local subspaces that capture the data distribution.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ma18d/ma18d.pdf",
        "supp": "",
        "pdf_size": 2312082,
        "gs_citation": 494,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13671594748199391279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "The University of Melbourne; Tsinghua University; National Institute of Informatics; The University of Melbourne; The University of Melbourne; Tsinghua University; The University of Melbourne; The University of Melbourne",
        "aff_domain": "unimelb.edu.au;mails.tsinghua.edu.cn; ; ; ; ; ; ",
        "email": "unimelb.edu.au;mails.tsinghua.edu.cn; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/ma18d.html",
        "aff_unique_index": "0;1;2;0;0;1;0;0",
        "aff_unique_norm": "University of Melbourne;Tsinghua University;National Institute of Informatics",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.unimelb.edu.au;https://www.tsinghua.edu.cn;https://www.nii.ac.jp/",
        "aff_unique_abbr": "UniMelb;THU;NII",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0;0;1;0;0",
        "aff_country_unique": "Australia;China;Japan"
    },
    {
        "title": "Discovering Interpretable Representations for Both Deep Generative and Discriminative Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1908",
        "id": "1908",
        "author_site": "Tameem Adel, Zoubin Ghahramani, Adrian Weller",
        "author": "Tameem Adel; Zoubin Ghahramani; Adrian Weller",
        "abstract": "Interpretability of representations in both deep generative and discriminative models is highly desirable. Current methods jointly optimize an objective combining accuracy and interpretability. However, this may reduce accuracy, and is not applicable to already trained models. We propose two interpretability frameworks. First, we provide an interpretable lens for an existing model. We use a generative model which takes as input the representation in an existing (generative or discriminative) model, weakly supervised by limited side information. Applying a flexible and invertible transformation to the input leads to an interpretable representation with no loss in accuracy. We extend the approach using an active learning strategy to choose the most useful side information to obtain, allowing a human to guide what \"interpretable\" means. Our second framework relies on joint optimization for a representation which is both maximally informative about the side information and maximally compressive about the non-interpretable data factors. This leads to a novel perspective on the relationship between compression and regularization. We also propose a new interpretability evaluation metric based on our framework. Empirically, we achieve state-of-the-art results on three datasets using the two proposed algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-adel18a,\n  title = \t {Discovering Interpretable Representations for Both Deep Generative and Discriminative Models},\n  author =       {Adel, Tameem and Ghahramani, Zoubin and Weller, Adrian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {50--59},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/adel18a/adel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/adel18a.html},\n  abstract = \t {Interpretability of representations in both deep generative and discriminative models is highly desirable. Current methods jointly optimize an objective combining accuracy and interpretability. However, this may reduce accuracy, and is not applicable to already trained models. We propose two interpretability frameworks. First, we provide an interpretable lens for an existing model. We use a generative model which takes as input the representation in an existing (generative or discriminative) model, weakly supervised by limited side information. Applying a flexible and invertible transformation to the input leads to an interpretable representation with no loss in accuracy. We extend the approach using an active learning strategy to choose the most useful side information to obtain, allowing a human to guide what \"interpretable\" means. Our second framework relies on joint optimization for a representation which is both maximally informative about the side information and maximally compressive about the non-interpretable data factors. This leads to a novel perspective on the relationship between compression and regularization. We also propose a new interpretability evaluation metric based on our framework. Empirically, we achieve state-of-the-art results on three datasets using the two proposed algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/adel18a/adel18a.pdf",
        "supp": "",
        "pdf_size": 704862,
        "gs_citation": 119,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12951823537813234709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Cambridge, UK+Leverhulme CFI, Cambridge, UK+Uber AI Labs, USA; University of Cambridge, UK+Leverhulme CFI, Cambridge, UK+The Alan Turing Institute, UK; University of Cambridge, UK+Leverhulme CFI, Cambridge, UK+The Alan Turing Institute, UK",
        "aff_domain": "cam.ac.uk; ; ",
        "email": "cam.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/adel18a.html",
        "aff_unique_index": "0+1+2;0+1+3;0+1+3",
        "aff_unique_norm": "University of Cambridge;Leverhulme Centre for Future Intelligence;Uber;Alan Turing Institute",
        "aff_unique_dep": ";;Uber AI Labs;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.lcfi.ac.uk;https://www.uber.com;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;LCFI;Uber;ATI",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0+0+1;0+0+0;0+0+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2093",
        "id": "2093",
        "author_site": "Thomas Dietterich, George Trimponias, Zhitang Chen",
        "author": "Thomas Dietterich; George Trimponias; Zhitang Chen",
        "abstract": "Exogenous state variables and rewards can slow down reinforcement learning by injecting uncontrolled variation into the reward signal. We formalize exogenous state variables and rewards and identify conditions under which an MDP with exogenous state can be decomposed into an exogenous Markov Reward Process involving only the exogenous state+reward and an endogenous Markov Decision Process defined with respect to only the endogenous rewards. We also derive a variance-covariance condition under which Monte Carlo policy evaluation on the endogenous MDP is accelerated compared to using the full MDP. Similar speedups are likely to carry over to all RL algorithms. We develop two algorithms for discovering the exogenous variables and test them on several MDPs. Results show that the algorithms are practical and can significantly speed up reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v80-dietterich18a,\n  title = \t {Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning},\n  author =       {Dietterich, Thomas and Trimponias, George and Chen, Zhitang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1262--1270},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dietterich18a/dietterich18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dietterich18a.html},\n  abstract = \t {Exogenous state variables and rewards can slow down reinforcement learning by injecting uncontrolled variation into the reward signal. We formalize exogenous state variables and rewards and identify conditions under which an MDP with exogenous state can be decomposed into an exogenous Markov Reward Process involving only the exogenous state+reward and an endogenous Markov Decision Process defined with respect to only the endogenous rewards. We also derive a variance-covariance condition under which Monte Carlo policy evaluation on the endogenous MDP is accelerated compared to using the full MDP. Similar speedups are likely to carry over to all RL algorithms. We develop two algorithms for discovering the exogenous variables and test them on several MDPs. Results show that the algorithms are practical and can significantly speed up reinforcement learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dietterich18a/dietterich18a.pdf",
        "supp": "",
        "pdf_size": 347709,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1207165937270371121&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of EECS, Oregon State University, Corvallis, OR, USA; Huawei Noah\u2019s Ark Lab, Hong Kong; Huawei Noah\u2019s Ark Lab, Hong Kong",
        "aff_domain": "cs.orst.edu; ; ",
        "email": "cs.orst.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/dietterich18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Oregon State University;Huawei",
        "aff_unique_dep": "School of EECS;Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "https://osu.edu;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "OSU;Huawei Noah\u2019s Ark Lab",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Corvallis;Hong Kong SAR",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2009",
        "id": "2009",
        "author_site": "Yi Wu, Siddharth Srivastava, Nicholas Hay, Simon Du, Stuart Russell",
        "author": "Yi Wu; Siddharth Srivastava; Nicholas Hay; Simon Du; Stuart Russell",
        "abstract": "Despite the recent successes of probabilistic programming languages (PPLs) in AI applications, PPLs offer only limited support for random variables whose distributions combine discrete and continuous elements. We develop the notion of measure-theoretic Bayesian networks (MTBNs) and use it to provide more general semantics for PPLs with arbitrarily many random variables defined over arbitrary measure spaces. We develop two new general sampling algorithms that are provably correct under the MTBN framework: the lexicographic likelihood weighting (LLW) for general MTBNs and the lexicographic particle filter (LPF), a specialized algorithm for state-space models. We further integrate MTBNs into a widely used PPL system, BLOG, and verify the effectiveness of the new inference algorithms through representative examples.",
        "bibtex": "@InProceedings{pmlr-v80-wu18f,\n  title = \t {Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms},\n  author =       {Wu, Yi and Srivastava, Siddharth and Hay, Nicholas and Du, Simon and Russell, Stuart},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5343--5352},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18f/wu18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18f.html},\n  abstract = \t {Despite the recent successes of probabilistic programming languages (PPLs) in AI applications, PPLs offer only limited support for random variables whose distributions combine discrete and continuous elements. We develop the notion of measure-theoretic Bayesian networks (MTBNs) and use it to provide more general semantics for PPLs with arbitrarily many random variables defined over arbitrary measure spaces. We develop two new general sampling algorithms that are provably correct under the MTBN framework: the lexicographic likelihood weighting (LLW) for general MTBNs and the lexicographic particle filter (LPF), a specialized algorithm for state-space models. We further integrate MTBNs into a widely used PPL system, BLOG, and verify the effectiveness of the new inference algorithms through representative examples.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18f/wu18f.pdf",
        "supp": "",
        "pdf_size": 524229,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10429532106958390341&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "University of California, Berkeley; Arizona State University; Vicarious Inc.; Carnegie Mellon University; University of California, Berkeley",
        "aff_domain": "gmail.com; ; ; ; ",
        "email": "gmail.com; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/wu18f.html",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of California, Berkeley;Arizona State University;Vicarious Inc.;Carnegie Mellon University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.asu.edu;https://www.vicarious.com;https://www.cmu.edu",
        "aff_unique_abbr": "UC Berkeley;ASU;Vicarious;CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Disentangled Sequential Autoencoder",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2147",
        "id": "2147",
        "author_site": "Yingzhen Li, Stephan Mandt",
        "author": "Li Yingzhen; Stephan Mandt",
        "abstract": "We present a VAE architecture for encoding and generating high dimensional sequential data, such as video or audio. Our deep generative model learns a latent representation of the data which is split into a static and dynamic part, allowing us to approximately disentangle latent time-dependent features (dynamics) from features which are preserved over time (content). This architecture gives us partial control over generating content and dynamics by conditioning on either one of these sets of features. In our experiments on artificially generated cartoon video clips and voice recordings, we show that we can convert the content of a given sequence into another one by such content swapping. For audio, this allows us to convert a male speaker into a female speaker and vice versa, while for video we can separately manipulate shapes and dynamics. Furthermore, we give empirical evidence for the hypothesis that stochastic RNNs as latent state models are more efficient at compressing and generating long sequences than deterministic ones, which may be relevant for applications in video compression.",
        "bibtex": "@InProceedings{pmlr-v80-yingzhen18a,\n  title = \t {Disentangled Sequential Autoencoder},\n  author =       {Yingzhen, Li and Mandt, Stephan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5670--5679},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yingzhen18a/yingzhen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yingzhen18a.html},\n  abstract = \t {We present a VAE architecture for encoding and generating high dimensional sequential data, such as video or audio. Our deep generative model learns a latent representation of the data which is split into a static and dynamic part, allowing us to approximately disentangle latent time-dependent features (dynamics) from features which are preserved over time (content). This architecture gives us partial control over generating content and dynamics by conditioning on either one of these sets of features. In our experiments on artificially generated cartoon video clips and voice recordings, we show that we can convert the content of a given sequence into another one by such content swapping. For audio, this allows us to convert a male speaker into a female speaker and vice versa, while for video we can separately manipulate shapes and dynamics. Furthermore, we give empirical evidence for the hypothesis that stochastic RNNs as latent state models are more efficient at compressing and generating long sequences than deterministic ones, which may be relevant for applications in video compression.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yingzhen18a/yingzhen18a.pdf",
        "supp": "",
        "pdf_size": 1942181,
        "gs_citation": 199,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16072911229244600776&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Cambridge, UK; Disney Research, Los Angeles, CA, USA",
        "aff_domain": "cam.ac.uk;disneyresearch.com",
        "email": "cam.ac.uk;disneyresearch.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/yingzhen18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Cambridge;Disney Research",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cam.ac.uk;https://research.disney.com",
        "aff_unique_abbr": "Cambridge;Disney Research",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Cambridge;Los Angeles",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Disentangling by Factorising",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2146",
        "id": "2146",
        "author_site": "Hyunjik Kim, Andriy Mnih",
        "author": "Hyunjik Kim; Andriy Mnih",
        "abstract": "We define and address the problem of unsupervised learning of disentangled representations on data generated from independent factors of variation. We propose FactorVAE, a method that disentangles by encouraging the distribution of representations to be factorial and hence independent across the dimensions. We show that it improves upon beta-VAE by providing a better trade-off between disentanglement and reconstruction quality and being more robust to the number of training iterations. Moreover, we highlight the problems of a commonly used disentanglement metric and introduce a new metric that does not suffer from them.",
        "bibtex": "@InProceedings{pmlr-v80-kim18b,\n  title = \t {Disentangling by Factorising},\n  author =       {Kim, Hyunjik and Mnih, Andriy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2649--2658},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kim18b/kim18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kim18b.html},\n  abstract = \t {We define and address the problem of unsupervised learning of disentangled representations on data generated from independent factors of variation. We propose FactorVAE, a method that disentangles by encouraging the distribution of representations to be factorial and hence independent across the dimensions. We show that it improves upon beta-VAE by providing a better trade-off between disentanglement and reconstruction quality and being more robust to the number of training iterations. Moreover, we highlight the problems of a commonly used disentanglement metric and introduce a new metric that does not suffer from them.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kim18b/kim18b.pdf",
        "supp": "",
        "pdf_size": 3635240,
        "gs_citation": 1869,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4010663500903508201&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "DeepMind, UK+Department of Statistics, University of Oxford; DeepMind, UK",
        "aff_domain": "google.com; ",
        "email": "google.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kim18b.html",
        "aff_unique_index": "0+1;0",
        "aff_unique_norm": "DeepMind;University of Oxford",
        "aff_unique_dep": ";Department of Statistics",
        "aff_unique_url": "https://deepmind.com;https://www.ox.ac.uk",
        "aff_unique_abbr": "DeepMind;Oxford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Oxford",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2002",
        "id": "2002",
        "author_site": "Lukas Balles, Philipp Hennig",
        "author": "Lukas Balles; Philipp Hennig",
        "abstract": "The ADAM optimizer is exceedingly popular in the deep learning community. Often it works very well, sometimes it doesn\u2019t. Why? We interpret ADAM as a combination of two aspects: for each weight, the update direction is determined by the sign of stochastic gradients, whereas the update magnitude is determined by an estimate of their relative variance. We disentangle these two aspects and analyze them in isolation, gaining insight into the mechanisms underlying ADAM. This analysis also extends recent results on adverse effects of ADAM on generalization, isolating the sign aspect as the problematic one. Transferring the variance adaptation to SGD gives rise to a novel method, completing the practitioner\u2019s toolbox for problems where ADAM fails.",
        "bibtex": "@InProceedings{pmlr-v80-balles18a,\n  title = \t {Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients},\n  author =       {Balles, Lukas and Hennig, Philipp},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {404--413},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balles18a/balles18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balles18a.html},\n  abstract = \t {The ADAM optimizer is exceedingly popular in the deep learning community. Often it works very well, sometimes it doesn\u2019t. Why? We interpret ADAM as a combination of two aspects: for each weight, the update direction is determined by the sign of stochastic gradients, whereas the update magnitude is determined by an estimate of their relative variance. We disentangle these two aspects and analyze them in isolation, gaining insight into the mechanisms underlying ADAM. This analysis also extends recent results on adverse effects of ADAM on generalization, isolating the sign aspect as the problematic one. Transferring the variance adaptation to SGD gives rise to a novel method, completing the practitioner\u2019s toolbox for problems where ADAM fails.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balles18a/balles18a.pdf",
        "supp": "",
        "pdf_size": 555490,
        "gs_citation": 205,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7051163857828136426&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": "tue.mpg.de; ",
        "email": "tue.mpg.de; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/balles18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Dissipativity Theory for Accelerating Stochastic Variance Reduction: A Unified Analysis of SVRG and Katyusha Using Semidefinite Programs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2471",
        "id": "2471",
        "author_site": "Bin Hu, Stephen Wright, Laurent Lessard",
        "author": "Bin Hu; Stephen Wright; Laurent Lessard",
        "abstract": "Techniques for reducing the variance of gradient estimates used in stochastic programming algorithms for convex finite-sum problems have received a great deal of attention in recent years. By leveraging dissipativity theory from control, we provide a new perspective on two important variance-reduction algorithms: SVRG and its direct accelerated variant Katyusha. Our perspective provides a physically intuitive understanding of the behavior of SVRG-like methods via a principle of energy conservation. The tools discussed here allow us to automate the convergence analysis of SVRG-like methods by capturing their essential properties in small semidefinite programs amenable to standard analysis and computational techniques. Our approach recovers existing convergence results for SVRG and Katyusha and generalizes the theory to alternative parameter choices. We also discuss how our approach complements the linear coupling technique. Our combination of perspectives leads to a better understanding of accelerated variance-reduced stochastic methods for finite-sum problems.",
        "bibtex": "@InProceedings{pmlr-v80-hu18b,\n  title = \t {Dissipativity Theory for Accelerating Stochastic Variance Reduction: A Unified Analysis of {SVRG} and {K}atyusha Using Semidefinite Programs},\n  author =       {Hu, Bin and Wright, Stephen and Lessard, Laurent},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2038--2047},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hu18b/hu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hu18b.html},\n  abstract = \t {Techniques for reducing the variance of gradient estimates used in stochastic programming algorithms for convex finite-sum problems have received a great deal of attention in recent years. By leveraging dissipativity theory from control, we provide a new perspective on two important variance-reduction algorithms: SVRG and its direct accelerated variant Katyusha. Our perspective provides a physically intuitive understanding of the behavior of SVRG-like methods via a principle of energy conservation. The tools discussed here allow us to automate the convergence analysis of SVRG-like methods by capturing their essential properties in small semidefinite programs amenable to standard analysis and computational techniques. Our approach recovers existing convergence results for SVRG and Katyusha and generalizes the theory to alternative parameter choices. We also discuss how our approach complements the linear coupling technique. Our combination of perspectives leads to a better understanding of accelerated variance-reduced stochastic methods for finite-sum problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hu18b/hu18b.pdf",
        "supp": "",
        "pdf_size": 272441,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5999687270081825909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Wisconsin\u2013Madison; University of Wisconsin\u2013Madison; University of Wisconsin\u2013Madison",
        "aff_domain": "wisc.edu; ; ",
        "email": "wisc.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/hu18b.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Distilling the Posterior in Bayesian Neural Networks",
        "author": "Kuan-Chieh Wang, Paul Vicol, James Lucas, Li Gu, Roger Grosse, Richard Zemel",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2362",
        "id": "2362"
    },
    {
        "title": "Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2293",
        "id": "2293",
        "author_site": "Zhengyuan Zhou, Panayotis Mertikopoulos, Nicholas Bambos, Peter Glynn, Yinyu Ye, Li-Jia Li, Li Fei-Fei",
        "author": "Zhengyuan Zhou; Panayotis Mertikopoulos; Nicholas Bambos; Peter Glynn; Yinyu Ye; Li-Jia Li; Li Fei-Fei",
        "abstract": "One of the most widely used optimization methods for large-scale machine learning problems is distributed asynchronous stochastic gradient descent (DASGD). However, a key issue that arises here is that of delayed gradients: when a \u201cworker\u201d node asynchronously contributes a gradient update to the \u201cmaster\u201d, the global model parameter may have changed, rendering this information stale. In massively parallel computing grids, these delays can quickly add up if the computational throughput of a node is saturated, so the convergence of DASGD is uncertain under these conditions. Nevertheless, by using a judiciously chosen quasilinear step-size sequence, we show that it is possible to amortize these delays and achieve global convergence with probability 1, even when the delays grow at a polynomial rate. In this way, our results help reaffirm the successful application of DASGD to large-scale optimization problems.",
        "bibtex": "@InProceedings{pmlr-v80-zhou18b,\n  title = \t {Distributed Asynchronous Optimization with Unbounded Delays: How Slow Can You Go?},\n  author =       {Zhou, Zhengyuan and Mertikopoulos, Panayotis and Bambos, Nicholas and Glynn, Peter and Ye, Yinyu and Li, Li-Jia and Fei-Fei, Li},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5970--5979},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhou18b/zhou18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhou18b.html},\n  abstract = \t {One of the most widely used optimization methods for large-scale machine learning problems is distributed asynchronous stochastic gradient descent (DASGD). However, a key issue that arises here is that of delayed gradients: when a \u201cworker\u201d node asynchronously contributes a gradient update to the \u201cmaster\u201d, the global model parameter may have changed, rendering this information stale. In massively parallel computing grids, these delays can quickly add up if the computational throughput of a node is saturated, so the convergence of DASGD is uncertain under these conditions. Nevertheless, by using a judiciously chosen quasilinear step-size sequence, we show that it is possible to amortize these delays and achieve global convergence with probability 1, even when the delays grow at a polynomial rate. In this way, our results help reaffirm the successful application of DASGD to large-scale optimization problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhou18b/zhou18b.pdf",
        "supp": "",
        "pdf_size": 723930,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4463969164006342737&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Stanford University; Univ. Grenoble Alpes, CNRS, Inria, LIG; Stanford University; Stanford University; Stanford University; Google; Stanford University + Google",
        "aff_domain": "stanford.edu; ; ; ; ; ; ",
        "email": "stanford.edu; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/zhou18b.html",
        "aff_unique_index": "0;1;0;0;0;2;0+2",
        "aff_unique_norm": "Stanford University;Universit\u00e9 Grenoble Alpes;Google",
        "aff_unique_dep": ";;Google",
        "aff_unique_url": "https://www.stanford.edu;https://www.univ-grenoble-alpes.fr;https://www.google.com",
        "aff_unique_abbr": "Stanford;UGA;Google",
        "aff_campus_unique_index": "0;0;0;0;2;0+2",
        "aff_campus_unique": "Stanford;;Mountain View",
        "aff_country_unique_index": "0;1;0;0;0;0;0+0",
        "aff_country_unique": "United States;France"
    },
    {
        "title": "Distributed Clustering via LSH Based Data Partitioning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2443",
        "id": "2443",
        "author_site": "Aditya Bhaskara, Pruthuvi Maheshakya Wijewardena",
        "author": "Aditya Bhaskara; Maheshakya Wijewardena",
        "abstract": "Given the importance of clustering in the analysisof large scale data, distributed algorithms for formulations such as k-means, k-median, etc. have been extensively studied. A successful approach here has been the \u201creduce and merge\u201d paradigm, in which each machine reduces its input size to {\u00d5}(k), and this data reduction continues (possibly iteratively) until all the data fits on one machine, at which point the problem is solved locally. This approach has the intrinsic bottleneck that each machine must solve a problem of size $\\geq$ k, and needs to communicate at least $\\Omega$(k) points to the other machines. We propose a novel data partitioning idea to overcome this bottleneck, and in effect, have different machines focus on \u201cfinding different clusters\u201d. Under the assumption that we know the optimum value of the objective up to a poly(n) factor (arbitrary polynomial), we establish worst-case approximation guarantees for our method. We see that our algorithm results in lower communication as well as a near-optimal number of \u2018rounds\u2019 of computation (in the popular MapReduce framework).",
        "bibtex": "@InProceedings{pmlr-v80-bhaskara18a,\n  title = \t {Distributed Clustering via {LSH} Based Data Partitioning},\n  author =       {Bhaskara, Aditya and Wijewardena, Maheshakya},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {570--579},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bhaskara18a/bhaskara18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bhaskara18a.html},\n  abstract = \t {Given the importance of clustering in the analysisof large scale data, distributed algorithms for formulations such as k-means, k-median, etc. have been extensively studied. A successful approach here has been the \u201creduce and merge\u201d paradigm, in which each machine reduces its input size to {\u00d5}(k), and this data reduction continues (possibly iteratively) until all the data fits on one machine, at which point the problem is solved locally. This approach has the intrinsic bottleneck that each machine must solve a problem of size $\\geq$ k, and needs to communicate at least $\\Omega$(k) points to the other machines. We propose a novel data partitioning idea to overcome this bottleneck, and in effect, have different machines focus on \u201cfinding different clusters\u201d. Under the assumption that we know the optimum value of the objective up to a poly(n) factor (arbitrary polynomial), we establish worst-case approximation guarantees for our method. We see that our algorithm results in lower communication as well as a near-optimal number of \u2018rounds\u2019 of computation (in the popular MapReduce framework).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bhaskara18a/bhaskara18a.pdf",
        "supp": "",
        "pdf_size": 1881235,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13651262988209576847&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Computing, University of Utah; School of Computing, University of Utah",
        "aff_domain": "gmail.com;gmail.com",
        "email": "gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/bhaskara18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Utah",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Distributed Nonparametric Regression under Communication Constraints",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2046",
        "id": "2046",
        "author_site": "Yuancheng Zhu, John Lafferty",
        "author": "Yuancheng Zhu; John Lafferty",
        "abstract": "This paper studies the problem of nonparametric estimation of a smooth function with data distributed across multiple machines. We assume an independent sample from a white noise model is collected at each machine, and an estimator of the underlying true function needs to be constructed at a central machine. We place limits on the number of bits that each machine can use to transmit information to the central machine. Our results give both asymptotic lower bounds and matching upper bounds on the statistical risk under various settings. We identify three regimes, depending on the relationship among the number of machines, the size of data available at each machine, and the communication budget. When the communication budget is small, the statistical risk depends solely on this communication bottleneck, regardless of the sample size. In the regime where the communication budget is large, the classic minimax risk in the non-distributed estimation setting is recovered. In an intermediate regime, the statistical risk depends on both the sample size and the communication budget.",
        "bibtex": "@InProceedings{pmlr-v80-zhu18a,\n  title = \t {Distributed Nonparametric Regression under Communication Constraints},\n  author =       {Zhu, Yuancheng and Lafferty, John},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {6009--6017},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhu18a/zhu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhu18a.html},\n  abstract = \t {This paper studies the problem of nonparametric estimation of a smooth function with data distributed across multiple machines. We assume an independent sample from a white noise model is collected at each machine, and an estimator of the underlying true function needs to be constructed at a central machine. We place limits on the number of bits that each machine can use to transmit information to the central machine. Our results give both asymptotic lower bounds and matching upper bounds on the statistical risk under various settings. We identify three regimes, depending on the relationship among the number of machines, the size of data available at each machine, and the communication budget. When the communication budget is small, the statistical risk depends solely on this communication bottleneck, regardless of the sample size. In the regime where the communication budget is large, the classic minimax risk in the non-distributed estimation setting is recovered. In an intermediate regime, the statistical risk depends on both the sample size and the communication budget.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhu18a/zhu18a.pdf",
        "supp": "",
        "pdf_size": 364346,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9932248850923767674&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistics, Wharton School, University of Pennsylvania; Department of Statistics and Data Science, Yale University",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/zhu18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Pennsylvania;Yale University",
        "aff_unique_dep": "Department of Statistics;Department of Statistics and Data Science",
        "aff_unique_url": "https://www.upenn.edu;https://www.yale.edu",
        "aff_unique_abbr": "UPenn;Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Do Outliers Ruin Collaboration?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1876",
        "id": "1876",
        "author": "Mingda Qiao",
        "abstract": "We consider the problem of learning a binary classifier from $n$ different data sources, among which at most an $\\eta$ fraction are adversarial. The overhead is defined as the ratio between the sample complexity of learning in this setting and that of learning the same hypothesis class on a single data distribution. We present an algorithm that achieves an $O(\\eta n + \\ln n)$ overhead, which is proved to be worst-case optimal. We also discuss the potential challenges to the design of a computationally efficient learning algorithm with a small overhead.",
        "bibtex": "@InProceedings{pmlr-v80-qiao18a,\n  title = \t {Do Outliers Ruin Collaboration?},\n  author =       {Qiao, Mingda},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4180--4187},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/qiao18a/qiao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/qiao18a.html},\n  abstract = \t {We consider the problem of learning a binary classifier from $n$ different data sources, among which at most an $\\eta$ fraction are adversarial. The overhead is defined as the ratio between the sample complexity of learning in this setting and that of learning the same hypothesis class on a single data distribution. We present an algorithm that achieves an $O(\\eta n + \\ln n)$ overhead, which is proved to be worst-case optimal. We also discuss the potential challenges to the design of a computationally efficient learning algorithm with a small overhead.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/qiao18a/qiao18a.pdf",
        "supp": "",
        "pdf_size": 261593,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16229513289959373542&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University, Beijing, China",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/qiao18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences (IIIS)",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "title": "Does Distributionally Robust Supervised Learning Give Robust Classifiers?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2181",
        "id": "2181",
        "author_site": "Weihua Hu, Gang Niu, Issei Sato, Masashi Sugiyama",
        "author": "Weihua Hu; Gang Niu; Issei Sato; Masashi Sugiyama",
        "abstract": "Distributionally Robust Supervised Learning (DRSL) is necessary for building reliable machine learning systems. When machine learning is deployed in the real world, its performance can be significantly degraded because test data may follow a different distribution from training data. DRSL with f-divergences explicitly considers the worst-case distribution shift by minimizing the adversarially reweighted training loss. In this paper, we analyze this DRSL, focusing on the classification scenario. Since the DRSL is explicitly formulated for a distribution shift scenario, we naturally expect it to give a robust classifier that can aggressively handle shifted distributions. However, surprisingly, we prove that the DRSL just ends up giving a classifier that exactly fits the given training distribution, which is too pessimistic. This pessimism comes from two sources: the particular losses used in classification and the fact that the variety of distributions to which the DRSL tries to be robust is too wide. Motivated by our analysis, we propose simple DRSL that overcomes this pessimism and empirically demonstrate its effectiveness.",
        "bibtex": "@InProceedings{pmlr-v80-hu18a,\n  title = \t {Does Distributionally Robust Supervised Learning Give Robust Classifiers?},\n  author =       {Hu, Weihua and Niu, Gang and Sato, Issei and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2029--2037},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hu18a/hu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hu18a.html},\n  abstract = \t {Distributionally Robust Supervised Learning (DRSL) is necessary for building reliable machine learning systems. When machine learning is deployed in the real world, its performance can be significantly degraded because test data may follow a different distribution from training data. DRSL with f-divergences explicitly considers the worst-case distribution shift by minimizing the adversarially reweighted training loss. In this paper, we analyze this DRSL, focusing on the classification scenario. Since the DRSL is explicitly formulated for a distribution shift scenario, we naturally expect it to give a robust classifier that can aggressively handle shifted distributions. However, surprisingly, we prove that the DRSL just ends up giving a classifier that exactly fits the given training distribution, which is too pessimistic. This pessimism comes from two sources: the particular losses used in classification and the fact that the variety of distributions to which the DRSL tries to be robust is too wide. Motivated by our analysis, we propose simple DRSL that overcomes this pessimism and empirically demonstrate its effectiveness.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hu18a/hu18a.pdf",
        "supp": "",
        "pdf_size": 255343,
        "gs_citation": 347,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15968638258650495531&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Tokyo, Japan+RIKEN, Tokyo, Japan; RIKEN, Tokyo, Japan; University of Tokyo, Japan+RIKEN, Tokyo, Japan; RIKEN, Tokyo, Japan",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/hu18a.html",
        "aff_unique_index": "0+1;1;0+1;1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0+0;0;0+0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Dropout Training, Data-dependent Regularization, and Generalization Bounds",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2000",
        "id": "2000",
        "author_site": "Wenlong Mou, Yuchen Zhou, Jun Gao, Liwei Wang",
        "author": "Wenlong Mou; Yuchen Zhou; Jun Gao; Liwei Wang",
        "abstract": "We study the problem of generalization guarantees for dropout training. A general framework is first proposed for learning procedures with random perturbation on model parameters. The generalization error is bounded by sum of two offset Rademacher complexities: the main term is Rademacher complexity of the hypothesis class with minus offset induced by the perturbation variance, which characterizes data-dependent regularization by the random perturbation; the auxiliary term is offset Rademacher complexity for the variance class, controlling the degree to which this regularization effect can be weakened. For neural networks, we estimate upper and lower bounds for the variance induced by truthful dropout, a variant of dropout that we propose to ensure unbiased output and fit into our framework, and the variance bounds exhibits connection to adaptive regularization methods. By applying our framework to ReLU networks with one hidden layer, a generalization upper bound is derived with no assumptions on the parameter norms or data distribution, with $O(1/n)$ fast rate and adaptivity to geometry of data points being achieved at the same time.",
        "bibtex": "@InProceedings{pmlr-v80-mou18a,\n  title = \t {Dropout Training, Data-dependent Regularization, and Generalization Bounds},\n  author =       {Mou, Wenlong and Zhou, Yuchen and Gao, Jun and Wang, Liwei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3645--3653},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mou18a/mou18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mou18a.html},\n  abstract = \t {We study the problem of generalization guarantees for dropout training. A general framework is first proposed for learning procedures with random perturbation on model parameters. The generalization error is bounded by sum of two offset Rademacher complexities: the main term is Rademacher complexity of the hypothesis class with minus offset induced by the perturbation variance, which characterizes data-dependent regularization by the random perturbation; the auxiliary term is offset Rademacher complexity for the variance class, controlling the degree to which this regularization effect can be weakened. For neural networks, we estimate upper and lower bounds for the variance induced by truthful dropout, a variant of dropout that we propose to ensure unbiased output and fit into our framework, and the variance bounds exhibits connection to adaptive regularization methods. By applying our framework to ReLU networks with one hidden layer, a generalization upper bound is derived with no assumptions on the parameter norms or data distribution, with $O(1/n)$ fast rate and adaptivity to geometry of data points being achieved at the same time.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mou18a/mou18a.pdf",
        "supp": "",
        "pdf_size": 342316,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14571253940742994857&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/mou18a.html"
    },
    {
        "title": "Dynamic Evaluation of Neural Sequence Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2197",
        "id": "2197",
        "author_site": "Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals",
        "author": "Ben Krause; Emmanuel Kahembwe; Iain Murray; Steve Renals",
        "abstract": "We explore dynamic evaluation, where sequence models are adapted to the recent sequence history using gradient descent, assigning higher probabilities to re-occurring sequential patterns. We develop a dynamic evaluation approach that outperforms existing adaptation approaches in our comparisons. We apply dynamic evaluation to outperform all previous word-level perplexities on the Penn Treebank and WikiText-2 datasets (achieving 51.1 and 44.3 respectively) and all previous character-level cross-entropies on the text8 and Hutter Prize datasets (achieving 1.19 bits/char and 1.08 bits/char respectively).",
        "bibtex": "@InProceedings{pmlr-v80-krause18a,\n  title = \t {Dynamic Evaluation of Neural Sequence Models},\n  author =       {Krause, Ben and Kahembwe, Emmanuel and Murray, Iain and Renals, Steve},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2766--2775},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/krause18a/krause18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/krause18a.html},\n  abstract = \t {We explore dynamic evaluation, where sequence models are adapted to the recent sequence history using gradient descent, assigning higher probabilities to re-occurring sequential patterns. We develop a dynamic evaluation approach that outperforms existing adaptation approaches in our comparisons. We apply dynamic evaluation to outperform all previous word-level perplexities on the Penn Treebank and WikiText-2 datasets (achieving 51.1 and 44.3 respectively) and all previous character-level cross-entropies on the text8 and Hutter Prize datasets (achieving 1.19 bits/char and 1.08 bits/char respectively).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/krause18a/krause18a.pdf",
        "supp": "",
        "pdf_size": 334877,
        "gs_citation": 152,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7171182301432620931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh",
        "aff_domain": "ed.ac.uk; ; ; ",
        "email": "ed.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/krause18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Dynamic Regret of Strongly Adaptive Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1989",
        "id": "1989",
        "author_site": "Lijun Zhang, Tianbao Yang, rong jin, Zhi-Hua Zhou",
        "author": "Lijun Zhang; Tianbao Yang;  jin; Zhi-Hua Zhou",
        "abstract": "To cope with changing environments, recent developments in online learning have introduced the concepts of adaptive regret and dynamic regret independently. In this paper, we illustrate an intrinsic connection between these two concepts by showing that the dynamic regret can be expressed in terms of the adaptive regret and the functional variation. This observation implies that strongly adaptive algorithms can be directly leveraged to minimize the dynamic regret. As a result, we present a series of strongly adaptive algorithms that have small dynamic regrets for convex functions, exponentially concave functions, and strongly convex functions, respectively. To the best of our knowledge, this is the first time that exponential concavity is utilized to upper bound the dynamic regret. Moreover, all of those adaptive algorithms do not need any prior knowledge of the functional variation, which is a significant advantage over previous specialized methods for minimizing dynamic regret.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18o,\n  title = \t {Dynamic Regret of Strongly Adaptive Methods},\n  author =       {Zhang, Lijun and Yang, Tianbao and rong jin and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5882--5891},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18o/zhang18o.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18o.html},\n  abstract = \t {To cope with changing environments, recent developments in online learning have introduced the concepts of adaptive regret and dynamic regret independently. In this paper, we illustrate an intrinsic connection between these two concepts by showing that the dynamic regret can be expressed in terms of the adaptive regret and the functional variation. This observation implies that strongly adaptive algorithms can be directly leveraged to minimize the dynamic regret. As a result, we present a series of strongly adaptive algorithms that have small dynamic regrets for convex functions, exponentially concave functions, and strongly convex functions, respectively. To the best of our knowledge, this is the first time that exponential concavity is utilized to upper bound the dynamic regret. Moreover, all of those adaptive algorithms do not need any prior knowledge of the functional variation, which is a significant advantage over previous specialized methods for minimizing dynamic regret.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18o/zhang18o.pdf",
        "supp": "",
        "pdf_size": 370867,
        "gs_citation": 122,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4539585531686903822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science, The University of Iowa, Iowa City, USA; Alibaba Group, Seattle, USA; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
        "aff_domain": "lamda.nju.edu.cn; ; ; ",
        "email": "lamda.nju.edu.cn; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/zhang18o.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Nanjing University;University of Iowa;Alibaba Group",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology;Department of Computer Science;",
        "aff_unique_url": "http://www.nju.edu.cn;https://www.uiowa.edu;https://www.alibaba.com",
        "aff_unique_abbr": "Nanjing U;UIowa;Alibaba",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Nanjing;Iowa City;Seattle",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2421",
        "id": "2421",
        "author_site": "Lechao Xiao, Yasaman Bahri, Jascha Sohl-Dickstein, Samuel Schoenholz, Jeffrey Pennington",
        "author": "Lechao Xiao; Yasaman Bahri; Jascha Sohl-Dickstein; Samuel Schoenholz; Jeffrey Pennington",
        "abstract": "In recent years, state-of-the-art methods in computer vision have utilized increasingly deep convolutional neural network architectures (CNNs), with some of the most successful models employing hundreds or even thousands of layers. A variety of pathologies such as vanishing/exploding gradients make training such deep networks challenging. While residual connections and batch normalization do enable training at these depths, it has remained unclear whether such specialized architecture designs are truly necessary to train deep CNNs. In this work, we demonstrate that it is possible to train vanilla CNNs with ten thousand layers or more simply by using an appropriate initialization scheme. We derive this initialization scheme theoretically by developing a mean field theory for signal propagation and by characterizing the conditions for dynamical isometry, the equilibration of singular values of the input-output Jacobian matrix. These conditions require that the convolution operator be an orthogonal transformation in the sense that it is norm-preserving. We present an algorithm for generating such random initial orthogonal convolution kernels and demonstrate empirically that they enable efficient training of extremely deep architectures.",
        "bibtex": "@InProceedings{pmlr-v80-xiao18a,\n  title = \t {Dynamical Isometry and a Mean Field Theory of {CNN}s: How to Train 10,000-Layer Vanilla Convolutional Neural Networks},\n  author =       {Xiao, Lechao and Bahri, Yasaman and Sohl-Dickstein, Jascha and Schoenholz, Samuel and Pennington, Jeffrey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5393--5402},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xiao18a/xiao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xiao18a.html},\n  abstract = \t {In recent years, state-of-the-art methods in computer vision have utilized increasingly deep convolutional neural network architectures (CNNs), with some of the most successful models employing hundreds or even thousands of layers. A variety of pathologies such as vanishing/exploding gradients make training such deep networks challenging. While residual connections and batch normalization do enable training at these depths, it has remained unclear whether such specialized architecture designs are truly necessary to train deep CNNs. In this work, we demonstrate that it is possible to train vanilla CNNs with ten thousand layers or more simply by using an appropriate initialization scheme. We derive this initialization scheme theoretically by developing a mean field theory for signal propagation and by characterizing the conditions for dynamical isometry, the equilibration of singular values of the input-output Jacobian matrix. These conditions require that the convolution operator be an orthogonal transformation in the sense that it is norm-preserving. We present an algorithm for generating such random initial orthogonal convolution kernels and demonstrate empirically that they enable efficient training of extremely deep architectures.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xiao18a/xiao18a.pdf",
        "supp": "",
        "pdf_size": 1228012,
        "gs_citation": 412,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4327553153293253435&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Google Brain; Google Brain; Google Brain; Google Brain; Google Brain",
        "aff_domain": "google.com; ; ; ; ",
        "email": "google.com; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/xiao18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Brain",
        "aff_unique_url": "https://brain.google.com",
        "aff_unique_abbr": "Google Brain",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2464",
        "id": "2464",
        "author_site": "Minmin Chen, Jeffrey Pennington, Samuel Schoenholz",
        "author": "Minmin Chen; Jeffrey Pennington; Samuel Schoenholz",
        "abstract": "Recurrent neural networks have gained widespread use in modeling sequence data across various domains. While many successful recurrent architectures employ a notion of gating, the exact mechanism that enables such remarkable performance is not well understood. We develop a theory for signal propagation in recurrent networks after random initialization using a combination of mean field theory and random matrix theory. To simplify our discussion, we introduce a new RNN cell with a simple gating mechanism that we call the minimalRNN and compare it with vanilla RNNs. Our theory allows us to define a maximum timescale over which RNNs can remember an input. We show that this theory predicts trainability for both recurrent architectures. We show that gated recurrent networks feature a much broader, more robust, trainable region than vanilla RNNs, which corroborates recent experimental findings. Finally, we develop a closed-form critical initialization scheme that achieves dynamical isometry in both vanilla RNNs and minimalRNNs. We show that this results in significantly improved training dynamics. Finally, we demonstrate that the minimalRNN achieves comparable performance to its more complex counterparts, such as LSTMs or GRUs, on a language modeling task.",
        "bibtex": "@InProceedings{pmlr-v80-chen18i,\n  title = \t {Dynamical Isometry and a Mean Field Theory of {RNN}s: Gating Enables Signal Propagation in Recurrent Neural Networks},\n  author =       {Chen, Minmin and Pennington, Jeffrey and Schoenholz, Samuel},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {873--882},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18i/chen18i.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18i.html},\n  abstract = \t {Recurrent neural networks have gained widespread use in modeling sequence data across various domains. While many successful recurrent architectures employ a notion of gating, the exact mechanism that enables such remarkable performance is not well understood. We develop a theory for signal propagation in recurrent networks after random initialization using a combination of mean field theory and random matrix theory. To simplify our discussion, we introduce a new RNN cell with a simple gating mechanism that we call the minimalRNN and compare it with vanilla RNNs. Our theory allows us to define a maximum timescale over which RNNs can remember an input. We show that this theory predicts trainability for both recurrent architectures. We show that gated recurrent networks feature a much broader, more robust, trainable region than vanilla RNNs, which corroborates recent experimental findings. Finally, we develop a closed-form critical initialization scheme that achieves dynamical isometry in both vanilla RNNs and minimalRNNs. We show that this results in significantly improved training dynamics. Finally, we demonstrate that the minimalRNN achieves comparable performance to its more complex counterparts, such as LSTMs or GRUs, on a language modeling task.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18i/chen18i.pdf",
        "supp": "",
        "pdf_size": 1609867,
        "gs_citation": 133,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5677047534407738645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Google; Google Brain; Google Brain",
        "aff_domain": "google.com; ; ",
        "email": "google.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chen18i.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2036",
        "id": "2036",
        "author_site": "Ronan Fruit, Matteo Pirotta, Alessandro Lazaric, Ronald Ortner",
        "author": "Ronan Fruit; Matteo Pirotta; Alessandro Lazaric; Ronald Ortner",
        "abstract": "We introduce SCAL, an algorithm designed to perform efficient exploration-exploration in any unknown weakly-communicating Markov Decision Process (MDP) for which an upper bound c on the span of the optimal bias function is known. For an MDP with $S$ states, $A$ actions and $\\Gamma \\leq S$ possible next states, we prove a regret bound of $O(c\\sqrt{\\Gamma SAT})$, which significantly improves over existing algorithms (e.g., UCRL and PSRL), whose regret scales linearly with the MDP diameter $D$. In fact, the optimal bias span is finite and often much smaller than $D$ (e.g., $D=+\\infty$ in non-communicating MDPs). A similar result was originally derived by Bartlett and Tewari (2009) for REGAL.C, for which no tractable algorithm is available. In this paper, we relax the optimization problem at the core of REGAL.C, we carefully analyze its properties, and we provide the first computationally efficient algorithm to solve it. Finally, we report numerical simulations supporting our theoretical findings and showing how SCAL significantly outperforms UCRL in MDPs with large diameter and small span.",
        "bibtex": "@InProceedings{pmlr-v80-fruit18a,\n  title = \t {Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning},\n  author =       {Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Ortner, Ronald},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1578--1586},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fruit18a/fruit18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fruit18a.html},\n  abstract = \t {We introduce SCAL, an algorithm designed to perform efficient exploration-exploration in any unknown weakly-communicating Markov Decision Process (MDP) for which an upper bound c on the span of the optimal bias function is known. For an MDP with $S$ states, $A$ actions and $\\Gamma \\leq S$ possible next states, we prove a regret bound of $O(c\\sqrt{\\Gamma SAT})$, which significantly improves over existing algorithms (e.g., UCRL and PSRL), whose regret scales linearly with the MDP diameter $D$. In fact, the optimal bias span is finite and often much smaller than $D$ (e.g., $D=+\\infty$ in non-communicating MDPs). A similar result was originally derived by Bartlett and Tewari (2009) for REGAL.C, for which no tractable algorithm is available. In this paper, we relax the optimization problem at the core of REGAL.C, we carefully analyze its properties, and we provide the first computationally efficient algorithm to solve it. Finally, we report numerical simulations supporting our theoretical findings and showing how SCAL significantly outperforms UCRL in MDPs with large diameter and small span.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fruit18a/fruit18a.pdf",
        "supp": "",
        "pdf_size": 529727,
        "gs_citation": 132,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10255005828513027230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "SequeL Team, INRIA Lille, France; SequeL Team, INRIA Lille, France; Facebook AI Research, Paris, France; Montanuniversit \u00a8at Leoben, Austria",
        "aff_domain": "inria.fr; ; ;",
        "email": "inria.fr; ; ;",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/fruit18a.html",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "INRIA Lille;Meta;Montanuniversit\u00e4t Leoben",
        "aff_unique_dep": "SequeL Team;Facebook AI Research;",
        "aff_unique_url": "https://www.inria.fr/en;https://research.facebook.com;https://www.montanuni-leoben.at",
        "aff_unique_abbr": "INRIA;FAIR;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Lille;Paris;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "France;Austria"
    },
    {
        "title": "Efficient First-Order Algorithms for Adaptive Signal Denoising",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2359",
        "id": "2359",
        "author_site": "Dmitrii Ostrovskii, Zaid Harchaoui",
        "author": "Dmitrii Ostrovskii; Zaid Harchaoui",
        "abstract": "We consider the problem of discrete-time signal denoising, focusing on a specific family of non-linear convolution-type estimators. Each such estimator is associated with a time-invariant filter which is obtained adaptively, by solving a certain convex optimization problem. Adaptive convolution-type estimators were demonstrated to have favorable statistical properties, see (Juditsky & Nemirovski, 2009; 2010; Harchaoui et al., 2015b; Ostrovsky et al., 2016). Our first contribution is an efficient implementation of these estimators via the known first-order proximal algorithms. Our second contribution is a computational complexity analysis of the proposed procedures, which takes into account their statistical nature and the related notion of statistical accuracy. The proposed procedures and their analysis are illustrated on a simulated data benchmark.",
        "bibtex": "@InProceedings{pmlr-v80-ostrovskii18a,\n  title = \t {Efficient First-Order Algorithms for Adaptive Signal Denoising},\n  author =       {Ostrovskii, Dmitrii and Harchaoui, Zaid},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3946--3955},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ostrovskii18a/ostrovskii18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ostrovskii18a.html},\n  abstract = \t {We consider the problem of discrete-time signal denoising, focusing on a specific family of non-linear convolution-type estimators. Each such estimator is associated with a time-invariant filter which is obtained adaptively, by solving a certain convex optimization problem. Adaptive convolution-type estimators were demonstrated to have favorable statistical properties, see (Juditsky & Nemirovski, 2009; 2010; Harchaoui et al., 2015b; Ostrovsky et al., 2016). Our first contribution is an efficient implementation of these estimators via the known first-order proximal algorithms. Our second contribution is a computational complexity analysis of the proposed procedures, which takes into account their statistical nature and the related notion of statistical accuracy. The proposed procedures and their analysis are illustrated on a simulated data benchmark.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ostrovskii18a/ostrovskii18a.pdf",
        "supp": "",
        "pdf_size": 1497162,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16164313069281185033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "SIERRA Project-Team, INRIA Paris, Paris, France; Department of Statistics, University of Washington, Seattle, USA",
        "aff_domain": "inria.fr; ",
        "email": "inria.fr; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/ostrovskii18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "INRIA Paris;University of Washington",
        "aff_unique_dep": "SIERRA Project-Team;Department of Statistics",
        "aff_unique_url": "https://www.inria.fr;https://www.washington.edu",
        "aff_unique_abbr": "INRIA;UW",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Paris;Seattle",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;United States"
    },
    {
        "title": "Efficient Gradient-Free Variational Inference using Policy Search",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2482",
        "id": "2482",
        "author_site": "Oleg Arenz, Gerhard Neumann, Mingjun Zhong",
        "author": "Oleg Arenz; Gerhard Neumann; Mingjun Zhong",
        "abstract": "Inference from complex distributions is a common problem in machine learning needed for many Bayesian methods. We propose an efficient, gradient-free method for learning general GMM approximations of multimodal distributions based on recent insights from stochastic search methods. Our method establishes information-geometric trust regions to ensure efficient exploration of the sampling space and stability of the GMM updates, allowing for efficient estimation of multi-variate Gaussian variational distributions. For GMMs, we apply a variational lower bound to decompose the learning objective into sub-problems given by learning the individual mixture components and the coefficients. The number of mixture components is adapted online in order to allow for arbitrary exact approximations. We demonstrate on several domains that we can learn significantly better approximations than competing variational inference methods and that the quality of samples drawn from our approximations is on par with samples created by state-of-the-art MCMC samplers that require significantly more computational resources.",
        "bibtex": "@InProceedings{pmlr-v80-arenz18a,\n  title = \t {Efficient Gradient-Free Variational Inference using Policy Search},\n  author =       {Arenz, Oleg and Neumann, Gerhard and Zhong, Mingjun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {234--243},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/arenz18a/arenz18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/arenz18a.html},\n  abstract = \t {Inference from complex distributions is a common problem in machine learning needed for many Bayesian methods. We propose an efficient, gradient-free method for learning general GMM approximations of multimodal distributions based on recent insights from stochastic search methods. Our method establishes information-geometric trust regions to ensure efficient exploration of the sampling space and stability of the GMM updates, allowing for efficient estimation of multi-variate Gaussian variational distributions. For GMMs, we apply a variational lower bound to decompose the learning objective into sub-problems given by learning the individual mixture components and the coefficients. The number of mixture components is adapted online in order to allow for arbitrary exact approximations. We demonstrate on several domains that we can learn significantly better approximations than competing variational inference methods and that the quality of samples drawn from our approximations is on par with samples created by state-of-the-art MCMC samplers that require significantly more computational resources.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/arenz18a/arenz18a.pdf",
        "supp": "",
        "pdf_size": 3383222,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15860909759042559191&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Computational Learning for Autonomous Systems, TU Darmstadt, Darmstadt, Germany+Lincoln Center for Autonomous Systems, University of Lincoln, Lincoln, UK; Machine Learning Lab, University of Lincoln, Lincoln, UK; Computational Learning for Autonomous Systems, TU Darmstadt, Darmstadt, Germany+Lincoln Center for Autonomous Systems, University of Lincoln, Lincoln, UK",
        "aff_domain": "robot-learning.de; ; ",
        "email": "robot-learning.de; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/arenz18a.html",
        "aff_unique_index": "0+1;1;0+1",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;University of Lincoln",
        "aff_unique_dep": "Computational Learning for Autonomous Systems;Lincoln Center for Autonomous Systems",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "TU Darmstadt;UoL",
        "aff_campus_unique_index": "0+1;1;0+1",
        "aff_campus_unique": "Darmstadt;Lincoln",
        "aff_country_unique_index": "0+1;1;0+1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "title": "Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2242",
        "id": "2242",
        "author_site": "Dane Corneil, Wulfram Gerstner, Johanni Brea",
        "author": "Dane Corneil; Wulfram Gerstner; Johanni Brea",
        "abstract": "Modern reinforcement learning algorithms reach super-human performance on many board and video games, but they are sample inefficient, i.e. they typically require significantly more playing experience than humans to reach an equal performance level. To improve sample efficiency, an agent may build a model of the environment and use planning methods to update its policy. In this article we introduce Variational State Tabulation (VaST), which maps an environment with a high-dimensional state space (e.g. the space of visual inputs) to an abstract tabular model. Prioritized sweeping with small backups, a highly efficient planning method, can then be used to update state-action values. We show how VaST can rapidly learn to maximize reward in tasks like 3D navigation and efficiently adapt to sudden changes in rewards or transition probabilities.",
        "bibtex": "@InProceedings{pmlr-v80-corneil18a,\n  title = \t {Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation},\n  author =       {Corneil, Dane and Gerstner, Wulfram and Brea, Johanni},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1049--1058},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/corneil18a/corneil18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/corneil18a.html},\n  abstract = \t {Modern reinforcement learning algorithms reach super-human performance on many board and video games, but they are sample inefficient, i.e. they typically require significantly more playing experience than humans to reach an equal performance level. To improve sample efficiency, an agent may build a model of the environment and use planning methods to update its policy. In this article we introduce Variational State Tabulation (VaST), which maps an environment with a high-dimensional state space (e.g. the space of visual inputs) to an abstract tabular model. Prioritized sweeping with small backups, a highly efficient planning method, can then be used to update state-action values. We show how VaST can rapidly learn to maximize reward in tasks like 3D navigation and efficiently adapt to sudden changes in rewards or transition probabilities.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/corneil18a/corneil18a.pdf",
        "supp": "",
        "pdf_size": 3261734,
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1130683550787496400&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/corneil18a.html"
    },
    {
        "title": "Efficient Neural Architecture Search via Parameters Sharing",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2247",
        "id": "2247",
        "author_site": "Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, Jeff Dean",
        "author": "Hieu Pham; Melody Guan; Barret Zoph; Quoc Le; Jeff Dean",
        "abstract": "We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. ENAS constructs a large computational graph, where each subgraph represents a neural network architecture, hence forcing all architectures to share their parameters. A controller is trained with policy gradient to search for a subgraph that maximizes the expected reward on a validation set. Meanwhile a model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Sharing parameters among child models allows ENAS to deliver strong empirical performances, whilst using much fewer GPU-hours than existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On Penn Treebank, ENAS discovers a novel architecture that achieves a test perplexity of 56.3, on par with the existing state-of-the-art among all methods without post-training processing. On CIFAR-10, ENAS finds a novel architecture that achieves 2.89% test error, which is on par with the 2.65% test error of NASNet (Zoph et al., 2018).",
        "bibtex": "@InProceedings{pmlr-v80-pham18a,\n  title = \t {Efficient Neural Architecture Search via Parameters Sharing},\n  author =       {Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4095--4104},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pham18a/pham18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pham18a.html},\n  abstract = \t {We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. ENAS constructs a large computational graph, where each subgraph represents a neural network architecture, hence forcing all architectures to share their parameters. A controller is trained with policy gradient to search for a subgraph that maximizes the expected reward on a validation set. Meanwhile a model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Sharing parameters among child models allows ENAS to deliver strong empirical performances, whilst using much fewer GPU-hours than existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On Penn Treebank, ENAS discovers a novel architecture that achieves a test perplexity of 56.3, on par with the existing state-of-the-art among all methods without post-training processing. On CIFAR-10, ENAS finds a novel architecture that achieves 2.89% test error, which is on par with the 2.65% test error of NASNet (Zoph et al., 2018).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pham18a/pham18a.pdf",
        "supp": "",
        "pdf_size": 625853,
        "gs_citation": 3645,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4835934105722100680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "Google Brain; Language Technology Institute, Carnegie Mellon University + Google Brain; Department of Computer Science, Stanford University + Google Brain; Google Brain; Google Brain",
        "aff_domain": "cmu.edu;stanford.edu; ; ; ",
        "email": "cmu.edu;stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/pham18a.html",
        "aff_unique_index": "0;1+0;2+0;0;0",
        "aff_unique_norm": "Google;Carnegie Mellon University;Stanford University",
        "aff_unique_dep": "Google Brain;Language Technology Institute;Department of Computer Science",
        "aff_unique_url": "https://brain.google.com;https://www.cmu.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Google Brain;CMU;Stanford",
        "aff_campus_unique_index": "0;1+0;2+0;0;0",
        "aff_campus_unique": "Mountain View;Pittsburgh;Stanford",
        "aff_country_unique_index": "0;0+0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Efficient Neural Audio Synthesis",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2333",
        "id": "2333",
        "author_site": "Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, A\u00e4ron van den Oord, Sander Dieleman, Koray Kavukcuoglu",
        "author": "Nal Kalchbrenner; Erich Elsen; Karen Simonyan; Seb Noury; Norman Casagrande; Edward Lockhart; Florian Stimberg; Aaron Oord; Sander Dieleman; Koray Kavukcuoglu",
        "abstract": "Sequential models achieve state-of-the-art results in audio, visual and textual domains with respect to both estimating the data distribution and generating desired samples. Efficient sampling for this class of models at the cost of little to no loss in quality has however remained an elusive problem. With a focus on text-to-speech synthesis, we describe a set of general techniques for reducing sampling time while maintaining high output quality. We first describe a single-layer recurrent neural network, the WaveRNN, with a dual softmax layer that matches the quality of the state-of-the-art WaveNet model. The compact form of the network makes it possible to generate 24 kHz 16-bit audio 4 times faster than real time on a GPU. Secondly, we apply a weight pruning technique to reduce the number of weights in the WaveRNN. We find that, for a constant number of parameters, large sparse networks perform better than small dense networks and this relationship holds past sparsity levels of more than 96%. The small number of weights in a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile phone CPU in real time. Finally, we describe a new dependency scheme for sampling that lets us trade a constant number of non-local, distant dependencies for the ability to generate samples in batches. The Batch WaveRNN produces 8 samples per step without loss of quality and offers orthogonal ways of further increasing sampling efficiency.",
        "bibtex": "@InProceedings{pmlr-v80-kalchbrenner18a,\n  title = \t {Efficient Neural Audio Synthesis},\n  author =       {Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and van den Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2410--2419},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kalchbrenner18a/kalchbrenner18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kalchbrenner18a.html},\n  abstract = \t {Sequential models achieve state-of-the-art results in audio, visual and textual domains with respect to both estimating the data distribution and generating desired samples. Efficient sampling for this class of models at the cost of little to no loss in quality has however remained an elusive problem. With a focus on text-to-speech synthesis, we describe a set of general techniques for reducing sampling time while maintaining high output quality. We first describe a single-layer recurrent neural network, the WaveRNN, with a dual softmax layer that matches the quality of the state-of-the-art WaveNet model. The compact form of the network makes it possible to generate 24 kHz 16-bit audio 4 times faster than real time on a GPU. Secondly, we apply a weight pruning technique to reduce the number of weights in the WaveRNN. We find that, for a constant number of parameters, large sparse networks perform better than small dense networks and this relationship holds past sparsity levels of more than 96%. The small number of weights in a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile phone CPU in real time. Finally, we describe a new dependency scheme for sampling that lets us trade a constant number of non-local, distant dependencies for the ability to generate samples in batches. The Batch WaveRNN produces 8 samples per step without loss of quality and offers orthogonal ways of further increasing sampling efficiency.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kalchbrenner18a/kalchbrenner18a.pdf",
        "supp": "",
        "pdf_size": 734783,
        "gs_citation": 1097,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14599728628710698803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "DeepMind; Google Brain; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 10,
        "oa": "https://proceedings.mlr.press/v80/kalchbrenner18a.html",
        "aff_unique_index": "0;1;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind;Google",
        "aff_unique_dep": ";Google Brain",
        "aff_unique_url": "https://deepmind.com;https://brain.google.com",
        "aff_unique_abbr": "DeepMind;Google Brain",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Efficient and Consistent Adversarial Bipartite Matching",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2162",
        "id": "2162",
        "author_site": "Rizal Fathony, Sima Behpour, Xinhua Zhang, Brian Ziebart",
        "author": "Rizal Fathony; Sima Behpour; Xinhua Zhang; Brian Ziebart",
        "abstract": "Many important structured prediction problems, including learning to rank items, correspondence-based natural language processing, and multi-object tracking, can be formulated as weighted bipartite matching optimizations. Existing structured prediction approaches have significant drawbacks when applied under the constraints of perfect bipartite matchings. Exponential family probabilistic models, such as the conditional random field (CRF), provide statistical consistency guarantees, but suffer computationally from the need to compute the normalization term of its distribution over matchings, which is a #P-hard matrix permanent computation. In contrast, the structured support vector machine (SSVM) provides computational efficiency, but lacks Fisher consistency, meaning that there are distributions of data for which it cannot learn the optimal matching even under ideal learning conditions (i.e., given the true distribution and selecting from all measurable potential functions). We propose adversarial bipartite matching to avoid both of these limitations. We develop this approach algorithmically, establish its computational efficiency and Fisher consistency properties, and apply it to matching problems that demonstrate its empirical benefits.",
        "bibtex": "@InProceedings{pmlr-v80-fathony18a,\n  title = \t {Efficient and Consistent Adversarial Bipartite Matching},\n  author =       {Fathony, Rizal and Behpour, Sima and Zhang, Xinhua and Ziebart, Brian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1457--1466},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fathony18a/fathony18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fathony18a.html},\n  abstract = \t {Many important structured prediction problems, including learning to rank items, correspondence-based natural language processing, and multi-object tracking, can be formulated as weighted bipartite matching optimizations. Existing structured prediction approaches have significant drawbacks when applied under the constraints of perfect bipartite matchings. Exponential family probabilistic models, such as the conditional random field (CRF), provide statistical consistency guarantees, but suffer computationally from the need to compute the normalization term of its distribution over matchings, which is a #P-hard matrix permanent computation. In contrast, the structured support vector machine (SSVM) provides computational efficiency, but lacks Fisher consistency, meaning that there are distributions of data for which it cannot learn the optimal matching even under ideal learning conditions (i.e., given the true distribution and selecting from all measurable potential functions). We propose adversarial bipartite matching to avoid both of these limitations. We develop this approach algorithmically, establish its computational efficiency and Fisher consistency properties, and apply it to matching problems that demonstrate its empirical benefits.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fathony18a/fathony18a.pdf",
        "supp": "",
        "pdf_size": 980225,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11840033213692362046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Illinois at Chicago; Department of Computer Science, University of Illinois at Chicago; Department of Computer Science, University of Illinois at Chicago; Department of Computer Science, University of Illinois at Chicago",
        "aff_domain": "uic.edu;uic.edu; ; ",
        "email": "uic.edu;uic.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/fathony18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Illinois at Chicago",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uic.edu",
        "aff_unique_abbr": "UIC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Efficient end-to-end learning for quantizable representations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2123",
        "id": "2123",
        "author_site": "Yeonwoo Jeong, Hyun Oh Song",
        "author": "Yeonwoo Jeong; Hyun Oh Song",
        "abstract": "Embedding representation learning via neural networks is at the core foundation of modern similarity based search. While much effort has been put in developing algorithms for learning binary hamming code representations for search efficiency, this still requires a linear scan of the entire dataset per each query and trades off the search accuracy through binarization. To this end, we consider the problem of directly learning a quantizable embedding representation and the sparse binary hash code end-to-end which can be used to construct an efficient hash table not only providing significant search reduction in the number of data but also achieving the state of the art search accuracy outperforming previous state of the art deep metric learning methods. We also show that finding the optimal sparse binary hash code in a mini-batch can be computed exactly in polynomial time by solving a minimum cost flow problem. Our results on Cifar-100 and on ImageNet datasets show the state of the art search accuracy in precision@k and NMI metrics while providing up to 98X and 478X search speedup respectively over exhaustive linear search. The source code is available at https://github.com/maestrojeong/Deep-Hash-Table-ICML18.",
        "bibtex": "@InProceedings{pmlr-v80-jeong18a,\n  title = \t {Efficient end-to-end learning for quantizable representations},\n  author =       {Jeong, Yeonwoo and Song, Hyun Oh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2264--2273},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jeong18a/jeong18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jeong18a.html},\n  abstract = \t {Embedding representation learning via neural networks is at the core foundation of modern similarity based search. While much effort has been put in developing algorithms for learning binary hamming code representations for search efficiency, this still requires a linear scan of the entire dataset per each query and trades off the search accuracy through binarization. To this end, we consider the problem of directly learning a quantizable embedding representation and the sparse binary hash code end-to-end which can be used to construct an efficient hash table not only providing significant search reduction in the number of data but also achieving the state of the art search accuracy outperforming previous state of the art deep metric learning methods. We also show that finding the optimal sparse binary hash code in a mini-batch can be computed exactly in polynomial time by solving a minimum cost flow problem. Our results on Cifar-100 and on ImageNet datasets show the state of the art search accuracy in precision@k and NMI metrics while providing up to 98X and 478X search speedup respectively over exhaustive linear search. The source code is available at https://github.com/maestrojeong/Deep-Hash-Table-ICML18.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jeong18a/jeong18a.pdf",
        "supp": "",
        "pdf_size": 410066,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14118214895723382983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea",
        "aff_domain": "snu.ac.kr;snu.ac.kr",
        "email": "snu.ac.kr;snu.ac.kr",
        "github": "https://github.com/maestrojeong/Deep-Hash-Table-ICML18",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/jeong18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "End-to-End Learning for the Deep Multivariate Probit Model",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2259",
        "id": "2259",
        "author_site": "Di Chen, Yexiang Xue, Carla Gomes",
        "author": "Di Chen; Yexiang Xue; Carla Gomes",
        "abstract": "The multivariate probit model (MVP) is a popular classic model for studying binary responses of multiple entities. Nevertheless, the computational challenge of learning the MVP model, given that its likelihood involves integrating over a multidimensional constrained space of latent variables, significantly limits its application in practice. We propose a flexible deep generalization of the classic MVP, the Deep Multivariate Probit Model (DMVP), which is an end-to-end learning scheme that uses an efficient parallel sampling process of the multivariate probit model to exploit GPU-boosted deep neural networks. We present both theoretical and empirical analysis of the convergence behavior of DMVP\u2019s sampling process with respect to the resolution of the correlation structure. We provide convergence guarantees for DMVP and our empirical analysis demonstrates the advantages of DMVP\u2019s sampling compared with standard MCMC-based methods. We also show that when applied to multi-entity modelling problems, which are natural DMVP applications, DMVP trains faster than classical MVP, by at least an order of magnitude, captures rich correlations among entities, and further improves the joint likelihood of entities compared with several competitive models.",
        "bibtex": "@InProceedings{pmlr-v80-chen18o,\n  title = \t {End-to-End Learning for the Deep Multivariate Probit Model},\n  author =       {Chen, Di and Xue, Yexiang and Gomes, Carla},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {932--941},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18o/chen18o.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18o.html},\n  abstract = \t {The multivariate probit model (MVP) is a popular classic model for studying binary responses of multiple entities. Nevertheless, the computational challenge of learning the MVP model, given that its likelihood involves integrating over a multidimensional constrained space of latent variables, significantly limits its application in practice. We propose a flexible deep generalization of the classic MVP, the Deep Multivariate Probit Model (DMVP), which is an end-to-end learning scheme that uses an efficient parallel sampling process of the multivariate probit model to exploit GPU-boosted deep neural networks. We present both theoretical and empirical analysis of the convergence behavior of DMVP\u2019s sampling process with respect to the resolution of the correlation structure. We provide convergence guarantees for DMVP and our empirical analysis demonstrates the advantages of DMVP\u2019s sampling compared with standard MCMC-based methods. We also show that when applied to multi-entity modelling problems, which are natural DMVP applications, DMVP trains faster than classical MVP, by at least an order of magnitude, captures rich correlations among entities, and further improves the joint likelihood of entities compared with several competitive models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18o/chen18o.pdf",
        "supp": "",
        "pdf_size": 850253,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16506601685601121180&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Department, Cornell University, Ithaca, NY, US 14850; Computer Science Department, Cornell University, Ithaca, NY, US 14850; Computer Science Department, Cornell University, Ithaca, NY, US 14850",
        "aff_domain": "cs.cornell.edu; ; ",
        "email": "cs.cornell.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chen18o.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "End-to-end Active Object Tracking via Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1889",
        "id": "1889",
        "author_site": "Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, Yizhou Wang",
        "author": "Wenhan Luo; Peng Sun; Fangwei Zhong; Wei Liu; Tong Zhang; Yizhou Wang",
        "abstract": "We study active object tracking, where a tracker takes as input the visual observation (i.e. frame sequence) and produces the camera control signal (e.g., move forward, turn left, etc). Conventional methods tackle the tracking and the camera control separately, which is challenging to tune jointly. It also incurs many human efforts for labeling and many expensive trial-and-errors in real-world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning, where a ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for a successful training. The tracker trained in simulators (ViZDoom, Unreal Engine) shows good generalization in the case of unseen object moving path, unseen object appearance, unseen background, and distracting object. It can restore tracking when occasionally losing the target. With the experiments over the VOT dataset, we also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios.",
        "bibtex": "@InProceedings{pmlr-v80-luo18a,\n  title = \t {End-to-end Active Object Tracking via Reinforcement Learning},\n  author =       {Luo, Wenhan and Sun, Peng and Zhong, Fangwei and Liu, Wei and Zhang, Tong and Wang, Yizhou},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3286--3295},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/luo18a/luo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/luo18a.html},\n  abstract = \t {We study active object tracking, where a tracker takes as input the visual observation (i.e. frame sequence) and produces the camera control signal (e.g., move forward, turn left, etc). Conventional methods tackle the tracking and the camera control separately, which is challenging to tune jointly. It also incurs many human efforts for labeling and many expensive trial-and-errors in real-world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning, where a ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for a successful training. The tracker trained in simulators (ViZDoom, Unreal Engine) shows good generalization in the case of unseen object moving path, unseen object appearance, unseen background, and distracting object. It can restore tracking when occasionally losing the target. With the experiments over the VOT dataset, we also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/luo18a/luo18a.pdf",
        "supp": "",
        "pdf_size": 1983495,
        "gs_citation": 113,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12521883354777891417&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Tencent AI Lab; Tencent AI Lab; Peking University; Tencent AI Lab; Tencent AI Lab; Peking University",
        "aff_domain": "gmail.com;gmail.com;pku.edu.cn;columbia.edu;tongzhang-ml.org;pku.edu.cn",
        "email": "gmail.com;gmail.com;pku.edu.cn;columbia.edu;tongzhang-ml.org;pku.edu.cn",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/luo18a.html",
        "aff_unique_index": "0;0;1;0;0;1",
        "aff_unique_norm": "Tencent;Peking University",
        "aff_unique_dep": "Tencent AI Lab;",
        "aff_unique_url": "https://ai.tencent.com;http://www.pku.edu.cn",
        "aff_unique_abbr": "Tencent AI Lab;Peking U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Entropy-SGD optimizes the prior of a PAC-Bayes bound: Generalization properties of Entropy-SGD and data-dependent priors",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2274",
        "id": "2274",
        "author_site": "Gintare Karolina Dziugaite, Daniel Roy",
        "author": "Gintare Karolina Dziugaite; Daniel Roy",
        "abstract": "We show that Entropy-SGD (Chaudhari et al., 2017), when viewed as a learning algorithm, optimizes a PAC-Bayes bound on the risk of a Gibbs (posterior) classifier, i.e., a randomized classifier obtained by a risk-sensitive perturbation of the weights of a learned classifier. Entropy-SGD works by optimizing the bound\u2019s prior, violating the hypothesis of the PAC-Bayes theorem that the prior is chosen independently of the data. Indeed, available implementations of Entropy-SGD rapidly obtain zero training error on random labels and the same holds of the Gibbs posterior. In order to obtain a valid generalization bound, we rely on a result showing that data-dependent priors obtained by stochastic gradient Langevin dynamics (SGLD) yield valid PAC-Bayes bounds provided the target distribution of SGLD is eps-differentially private. We observe that test error on MNIST and CIFAR10 falls within the (empirically nonvacuous) risk bounds computed under the assumption that SGLD reaches stationarity. In particular, Entropy-SGLD can be configured to yield relatively tight generalization bounds and still fit real labels, although these same settings do not obtain state-of-the-art performance.",
        "bibtex": "@InProceedings{pmlr-v80-dziugaite18a,\n  title = \t {Entropy-{SGD} optimizes the prior of a {PAC}-{B}ayes bound: Generalization properties of Entropy-{SGD} and data-dependent priors},\n  author =       {Dziugaite, Gintare Karolina and Roy, Daniel},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1377--1386},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dziugaite18a/dziugaite18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dziugaite18a.html},\n  abstract = \t {We show that Entropy-SGD (Chaudhari et al., 2017), when viewed as a learning algorithm, optimizes a PAC-Bayes bound on the risk of a Gibbs (posterior) classifier, i.e., a randomized classifier obtained by a risk-sensitive perturbation of the weights of a learned classifier. Entropy-SGD works by optimizing the bound\u2019s prior, violating the hypothesis of the PAC-Bayes theorem that the prior is chosen independently of the data. Indeed, available implementations of Entropy-SGD rapidly obtain zero training error on random labels and the same holds of the Gibbs posterior. In order to obtain a valid generalization bound, we rely on a result showing that data-dependent priors obtained by stochastic gradient Langevin dynamics (SGLD) yield valid PAC-Bayes bounds provided the target distribution of SGLD is eps-differentially private. We observe that test error on MNIST and CIFAR10 falls within the (empirically nonvacuous) risk bounds computed under the assumption that SGLD reaches stationarity. In particular, Entropy-SGLD can be configured to yield relatively tight generalization bounds and still fit real labels, although these same settings do not obtain state-of-the-art performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dziugaite18a/dziugaite18a.pdf",
        "supp": "",
        "pdf_size": 594954,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6549161260882885895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Dept. of Engineering, Univ. of Cambridge, Cambridge, UK+Vector Institute, Toronto, Canada; Dept. of Statistical Sciences, Univ. of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada",
        "aff_domain": "cam.ac.uk;utstat.toronto.edu",
        "email": "cam.ac.uk;utstat.toronto.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/dziugaite18a.html",
        "aff_unique_index": "0+1;2+1",
        "aff_unique_norm": "University of Cambridge;Vector Institute;University of Toronto",
        "aff_unique_dep": "Department of Engineering;;Department of Statistical Sciences",
        "aff_unique_url": "https://www.cam.ac.uk;https://vectorinstitute.ai;https://www.utoronto.ca",
        "aff_unique_abbr": "Cambridge;Vector Institute;U of T",
        "aff_campus_unique_index": "0+1;1+1",
        "aff_campus_unique": "Cambridge;Toronto",
        "aff_country_unique_index": "0+1;1+1",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "title": "Equivalence of Multicategory SVM and Simplex Cone SVM: Fast Computations and Statistical Theory",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2427",
        "id": "2427",
        "author": "Guillaume Pouliot",
        "abstract": "The multicategory SVM (MSVM) of Lee et al. (2004) is a natural generalization of the classical, binary support vector machines (SVM). However, its use has been limited by computational difficulties. The simplex-cone SVM (SCSVM) of Mroueh et al. (2012) is a computationally efficient multicategory classifier, but its use has been limited by a seemingly opaque interpretation. We show that MSVM and SCSVM are in fact exactly equivalent, and provide a bijection between their tuning parameters. MSVM may then be entertained as both a natural and computationally efficient multicategory extension of SVM. We further provide a Donsker theorem for finite-dimensional kernel MSVM and partially answer the open question pertaining to the very competitive performance of One-vs-Rest methods against MSVM. Furthermore, we use the derived asymptotic covariance formula to develop an inverse-variance weighted classification rule which improves on the One-vs-Rest approach.",
        "bibtex": "@InProceedings{pmlr-v80-pouliot18a,\n  title = \t {Equivalence of Multicategory {SVM} and Simplex Cone {SVM}: Fast Computations and Statistical Theory},\n  author =       {Pouliot, Guillaume},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4133--4140},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pouliot18a/pouliot18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pouliot18a.html},\n  abstract = \t {The multicategory SVM (MSVM) of Lee et al. (2004) is a natural generalization of the classical, binary support vector machines (SVM). However, its use has been limited by computational difficulties. The simplex-cone SVM (SCSVM) of Mroueh et al. (2012) is a computationally efficient multicategory classifier, but its use has been limited by a seemingly opaque interpretation. We show that MSVM and SCSVM are in fact exactly equivalent, and provide a bijection between their tuning parameters. MSVM may then be entertained as both a natural and computationally efficient multicategory extension of SVM. We further provide a Donsker theorem for finite-dimensional kernel MSVM and partially answer the open question pertaining to the very competitive performance of One-vs-Rest methods against MSVM. Furthermore, we use the derived asymptotic covariance formula to develop an inverse-variance weighted classification rule which improves on the One-vs-Rest approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pouliot18a/pouliot18a.pdf",
        "supp": "",
        "pdf_size": 459903,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14560493240216361659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Harris School of Public Policy, University of Chicago, Chicago, IL, USA",
        "aff_domain": "uchicago.edu",
        "email": "uchicago.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/pouliot18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "Harris School of Public Policy",
        "aff_unique_url": "https://www.chicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2148",
        "id": "2148",
        "author_site": "Jiaxiang Wu, Weidong Huang, Junzhou Huang, Tong Zhang",
        "author": "Jiaxiang Wu; Weidong Huang; Junzhou Huang; Tong Zhang",
        "abstract": "Large-scale distributed optimization is of great importance in various applications. For data-parallel based distributed learning, the inter-node gradient communication often becomes the performance bottleneck. In this paper, we propose the error compensated quantized stochastic gradient descent algorithm to improve the training efficiency. Local gradients are quantized to reduce the communication overhead, and accumulated quantization error is utilized to speed up the convergence. Furthermore, we present theoretical analysis on the convergence behaviour, and demonstrate its advantage over competitors. Extensive experiments indicate that our algorithm can compress gradients by a factor of up to two magnitudes without performance degradation.",
        "bibtex": "@InProceedings{pmlr-v80-wu18d,\n  title = \t {Error Compensated Quantized {SGD} and its Applications to Large-scale Distributed Optimization},\n  author =       {Wu, Jiaxiang and Huang, Weidong and Huang, Junzhou and Zhang, Tong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5325--5333},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18d/wu18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18d.html},\n  abstract = \t {Large-scale distributed optimization is of great importance in various applications. For data-parallel based distributed learning, the inter-node gradient communication often becomes the performance bottleneck. In this paper, we propose the error compensated quantized stochastic gradient descent algorithm to improve the training efficiency. Local gradients are quantized to reduce the communication overhead, and accumulated quantization error is utilized to speed up the convergence. Furthermore, we present theoretical analysis on the convergence behaviour, and demonstrate its advantage over competitors. Extensive experiments indicate that our algorithm can compress gradients by a factor of up to two magnitudes without performance degradation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18d/wu18d.pdf",
        "supp": "",
        "pdf_size": 457607,
        "gs_citation": 286,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3944409673992063020&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China",
        "aff_domain": "tencent.com; ; ; ",
        "email": "tencent.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/wu18d.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "AI Lab",
        "aff_unique_url": "https://ai.tencent.com",
        "aff_unique_abbr": "Tencent AI Lab",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2345",
        "id": "2345",
        "author_site": "Miles Lopes, Shusen Wang, Michael Mahoney",
        "author": "Miles Lopes; Shusen Wang; Michael Mahoney",
        "abstract": "Over the course of the past decade, a variety of randomized algorithms have been proposed for computing approximate least-squares (LS) solutions in large-scale settings. A longstanding practical issue is that, for any given input, the user rarely knows the actual error of an approximate solution (relative to the exact solution). Likewise, it is difficult for the user to know precisely how much computation is needed to achieve the desired error tolerance. Consequently, the user often appeals to worst-case error bounds that tend to offer only qualitative guidance. As a more practical alternative, we propose a bootstrap method to compute a posteriori error estimates for randomized LS algorithms. These estimates permit the user to numerically assess the error of a given solution, and to predict how much work is needed to improve a \"preliminary\" solution. In addition, we provide theoretical consistency results for the method, which are the first such results in this context (to the best of our knowledge). From a practical standpoint, the method also has considerable flexibility, insofar as it can be applied to several popular sketching algorithms, as well as a variety of error metrics. Moreover, the extra step of error estimation does not add much cost to an underlying sketching algorithm. Finally, we demonstrate the effectiveness of the method with empirical results.",
        "bibtex": "@InProceedings{pmlr-v80-lopes18a,\n  title = \t {Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap},\n  author =       {Lopes, Miles and Wang, Shusen and Mahoney, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3217--3226},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lopes18a/lopes18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lopes18a.html},\n  abstract = \t {Over the course of the past decade, a variety of randomized algorithms have been proposed for computing approximate least-squares (LS) solutions in large-scale settings. A longstanding practical issue is that, for any given input, the user rarely knows the actual error of an approximate solution (relative to the exact solution). Likewise, it is difficult for the user to know precisely how much computation is needed to achieve the desired error tolerance. Consequently, the user often appeals to worst-case error bounds that tend to offer only qualitative guidance. As a more practical alternative, we propose a bootstrap method to compute a posteriori error estimates for randomized LS algorithms. These estimates permit the user to numerically assess the error of a given solution, and to predict how much work is needed to improve a \"preliminary\" solution. In addition, we provide theoretical consistency results for the method, which are the first such results in this context (to the best of our knowledge). From a practical standpoint, the method also has considerable flexibility, insofar as it can be applied to several popular sketching algorithms, as well as a variety of error metrics. Moreover, the extra step of error estimation does not add much cost to an underlying sketching algorithm. Finally, we demonstrate the effectiveness of the method with empirical results.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lopes18a/lopes18a.pdf",
        "supp": "",
        "pdf_size": 755596,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10584517909331964249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistics, UC Davis; ICSI and Department of Statistics, UC Berkeley; ICSI and Department of Statistics, UC Berkeley",
        "aff_domain": "ucdavis.edu; ; ",
        "email": "ucdavis.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lopes18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Davis;University of California, Berkeley",
        "aff_unique_dep": "Department of Statistics;Department of Statistics",
        "aff_unique_url": "https://www.ucdavis.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UC Davis;UC Berkeley",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Davis;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Escaping Saddles with Stochastic Gradients",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2265",
        "id": "2265",
        "author_site": "Hadi Daneshmand, Jonas Kohler, Aurelien Lucchi, Thomas Hofmann",
        "author": "Hadi Daneshmand; Jonas Kohler; Aurelien Lucchi; Thomas Hofmann",
        "abstract": "We analyze the variance of stochastic gradients along negative curvature directions in certain non-convex machine learning models and show that stochastic gradients indeed exhibit a strong component along these directions. Furthermore, we show that - contrary to the case of isotropic noise - this variance is proportional to the magnitude of the corresponding eigenvalues and not decreasing in the dimensionality. Based upon this bservation we propose a new assumption under which we show that the injection of explicit, isotropic noise usually applied to make gradient descent escape saddle points can successfully be replaced by a simple SGD step. Additionally - and under the same condition - we derive the first convergence rate for plain SGD to a second-order stationary point in a number of iterations that is independent of the problem dimension.",
        "bibtex": "@InProceedings{pmlr-v80-daneshmand18a,\n  title = \t {Escaping Saddles with Stochastic Gradients},\n  author =       {Daneshmand, Hadi and Kohler, Jonas and Lucchi, Aurelien and Hofmann, Thomas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1155--1164},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/daneshmand18a/daneshmand18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/daneshmand18a.html},\n  abstract = \t {We analyze the variance of stochastic gradients along negative curvature directions in certain non-convex machine learning models and show that stochastic gradients indeed exhibit a strong component along these directions. Furthermore, we show that - contrary to the case of isotropic noise - this variance is proportional to the magnitude of the corresponding eigenvalues and not decreasing in the dimensionality. Based upon this bservation we propose a new assumption under which we show that the injection of explicit, isotropic noise usually applied to make gradient descent escape saddle points can successfully be replaced by a simple SGD step. Additionally - and under the same condition - we derive the first convergence rate for plain SGD to a second-order stationary point in a number of iterations that is independent of the problem dimension.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/daneshmand18a/daneshmand18a.pdf",
        "supp": "",
        "pdf_size": 756917,
        "gs_citation": 186,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2555473880748905386&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "ETH, Zurich, Switzerland; ETH, Zurich, Switzerland; ETH, Zurich, Switzerland; ETH, Zurich, Switzerland",
        "aff_domain": "inf.ethz.ch; ; ; ",
        "email": "inf.ethz.ch; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/daneshmand18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Essentially No Barriers in Neural Network Energy Landscape",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2349",
        "id": "2349",
        "author_site": "Felix Draxler, Kambis Veschgini, Manfred Salmhofer, Fred Hamprecht",
        "author": "Felix Draxler; Kambis Veschgini; Manfred Salmhofer; Fred Hamprecht",
        "abstract": "Training neural networks involves finding minima of a high-dimensional non-convex loss function. Relaxing from linear interpolations, we construct continuous paths between minima of recent neural network architectures on CIFAR10 and CIFAR100. Surprisingly, the paths are essentially flat in both the training and test landscapes. This implies that minima are perhaps best seen as points on a single connected manifold of low loss, rather than as the bottoms of distinct valleys.",
        "bibtex": "@InProceedings{pmlr-v80-draxler18a,\n  title = \t {Essentially No Barriers in Neural Network Energy Landscape},\n  author =       {Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1309--1318},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/draxler18a/draxler18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/draxler18a.html},\n  abstract = \t {Training neural networks involves finding minima of a high-dimensional non-convex loss function. Relaxing from linear interpolations, we construct continuous paths between minima of recent neural network architectures on CIFAR10 and CIFAR100. Surprisingly, the paths are essentially flat in both the training and test landscapes. This implies that minima are perhaps best seen as points on a single connected manifold of low loss, rather than as the bottoms of distinct valleys.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/draxler18a/draxler18a.pdf",
        "supp": "",
        "pdf_size": 3567037,
        "gs_citation": 509,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15426527759025848933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Heidelberg Collaboratory for Image Processing (HCI), IWR, Heidelberg University, D-69120 Heidelberg, Germany+Institut f\u00fcr Theoretische Physik, Heidelberg University, D-69120 Heidelberg, Germany; Institut f\u00fcr Theoretische Physik, Heidelberg University, D-69120 Heidelberg, Germany; Institut f\u00fcr Theoretische Physik, Heidelberg University, D-69120 Heidelberg, Germany; Heidelberg Collaboratory for Image Processing (HCI), IWR, Heidelberg University, D-69120 Heidelberg, Germany+Institut f\u00fcr Theoretische Physik, Heidelberg University, D-69120 Heidelberg, Germany",
        "aff_domain": "iwr.uni-heidelberg.de; ; ;iwr.uni-heidelberg.de",
        "email": "iwr.uni-heidelberg.de; ; ;iwr.uni-heidelberg.de",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/draxler18a.html",
        "aff_unique_index": "0+0;0;0;0+0",
        "aff_unique_norm": "Heidelberg University",
        "aff_unique_dep": "Heidelberg Collaboratory for Image Processing (HCI)",
        "aff_unique_url": "https://www.uni-heidelberg.de",
        "aff_unique_abbr": "Uni Heidelberg",
        "aff_campus_unique_index": "0+0;0;0;0+0",
        "aff_campus_unique": "Heidelberg",
        "aff_country_unique_index": "0+0;0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Estimation of Markov Chain via Rank-Constrained Likelihood",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2304",
        "id": "2304",
        "author_site": "XUDONG LI, Mengdi Wang, Anru Zhang",
        "author": "Xudong Li; Mengdi Wang; Anru Zhang",
        "abstract": "This paper studies the estimation of low-rank Markov chains from empirical trajectories. We propose a non-convex estimator based on rank-constrained likelihood maximization. Statistical upper bounds are provided for the Kullback-Leiber divergence and the $\\ell_2$ risk between the estimator and the true transition matrix. The estimator reveals a compressed state space of the Markov chain. We also develop a novel DC (difference of convex function) programming algorithm to tackle the rank-constrained non-smooth optimization problem. Convergence results are established. Experiments show that the proposed estimator achieves better empirical performance than other popular approaches.",
        "bibtex": "@InProceedings{pmlr-v80-li18g,\n  title = \t {Estimation of {M}arkov Chain via Rank-Constrained Likelihood},\n  author =       {Li, Xudong and Wang, Mengdi and Zhang, Anru},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3033--3042},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18g/li18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18g.html},\n  abstract = \t {This paper studies the estimation of low-rank Markov chains from empirical trajectories. We propose a non-convex estimator based on rank-constrained likelihood maximization. Statistical upper bounds are provided for the Kullback-Leiber divergence and the $\\ell_2$ risk between the estimator and the true transition matrix. The estimator reveals a compressed state space of the Markov chain. We also develop a novel DC (difference of convex function) programming algorithm to tackle the rank-constrained non-smooth optimization problem. Convergence results are established. Experiments show that the proposed estimator achieves better empirical performance than other popular approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18g/li18g.pdf",
        "supp": "",
        "pdf_size": 364142,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6437778880145149151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Operations Research and Financial Engineering, Princeton University; Department of Operations Research and Financial Engineering, Princeton University; Department of Statistics, University of Wisconsin-Madison",
        "aff_domain": "princeton.edu;princeton.edu;stat.wisc.edu",
        "email": "princeton.edu;princeton.edu;stat.wisc.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/li18g.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Princeton University;University of Wisconsin-Madison",
        "aff_unique_dep": "Department of Operations Research and Financial Engineering;Department of Statistics",
        "aff_unique_url": "https://www.princeton.edu;https://www.wisc.edu",
        "aff_unique_abbr": "Princeton;UW-Madison",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Explicit Inductive Bias for Transfer Learning with Convolutional Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2225",
        "id": "2225",
        "author_site": "Xuhong LI, Yves Grandvalet, Franck Davoine",
        "author": "Xuhong LI; Yves Grandvalet; Franck Davoine",
        "abstract": "In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch. When using fine-tuning, the underlying assumption is that the pre-trained model extracts generic features, which are at least partially relevant for solving the target task, but would be difficult to extract from the limited amount of data available on the target task. However, besides the initialization with the pre-trained model and the early stopping, there is no mechanism in fine-tuning for retaining the features learned on the source task. In this paper, we investigate several regularization schemes that explicitly promote the similarity of the final solution with the initial model. We show the benefit of having an explicit inductive bias towards the initial model, and we eventually recommend a simple $L^2$ penalty with the pre-trained model being a reference as the baseline of penalty for transfer learning tasks.",
        "bibtex": "@InProceedings{pmlr-v80-li18a,\n  title = \t {Explicit Inductive Bias for Transfer Learning with Convolutional Networks},\n  author =       {LI, Xuhong and Grandvalet, Yves and Davoine, Franck},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2825--2834},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18a/li18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18a.html},\n  abstract = \t {In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch. When using fine-tuning, the underlying assumption is that the pre-trained model extracts generic features, which are at least partially relevant for solving the target task, but would be difficult to extract from the limited amount of data available on the target task. However, besides the initialization with the pre-trained model and the early stopping, there is no mechanism in fine-tuning for retaining the features learned on the source task. In this paper, we investigate several regularization schemes that explicitly promote the similarity of the final solution with the initial model. We show the benefit of having an explicit inductive bias towards the initial model, and we eventually recommend a simple $L^2$ penalty with the pre-trained model being a reference as the baseline of penalty for transfer learning tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18a/li18a.pdf",
        "supp": "",
        "pdf_size": 310633,
        "gs_citation": 415,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8930504204220703046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Sorbonne universit \u00b4es, Universit \u00b4e de technologie de Compi `egne, CNRS, Heudiasyc, UMR 7253, Compi `egne, France; Sorbonne universit \u00b4es, Universit \u00b4e de technologie de Compi `egne, CNRS, Heudiasyc, UMR 7253, Compi `egne, France; Sorbonne universit \u00b4es, Universit \u00b4e de technologie de Compi `egne, CNRS, Heudiasyc, UMR 7253, Compi `egne, France",
        "aff_domain": "hds.utc.fr; ; ",
        "email": "hds.utc.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/li18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9s",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2329",
        "id": "2329",
        "author_site": "Masanori SUGANUMA, Mete Ozay, Takayuki Okatani",
        "author": "Masanori Suganuma; Mete Ozay; Takayuki Okatani",
        "abstract": "Researchers have applied deep neural networks to image restoration tasks, in which they proposed various network architectures, loss functions, and training methods. In particular, adversarial training, which is employed in recent studies, seems to be a key ingredient to success. In this paper, we show that simple convolutional autoencoders (CAEs) built upon only standard network components, i.e., convolutional layers and skip connections, can outperform the state-of-the-art methods which employ adversarial training and sophisticated loss functions. The secret is to search for good architectures using an evolutionary algorithm. All we did was to train the optimized CAEs by minimizing the l2 loss between reconstructed images and their ground truths using the ADAM optimizer. Our experimental results show that this approach achieves 27.8 dB peak signal to noise ratio (PSNR) on the CelebA dataset and 33.3 dB on the SVHN dataset, compared to 22.8 dB and 19.0 dB provided by the former state-of-the-art methods, respectively.",
        "bibtex": "@InProceedings{pmlr-v80-suganuma18a,\n  title = \t {Exploiting the Potential of Standard Convolutional Autoencoders for Image Restoration by Evolutionary Search},\n  author =       {Suganuma, Masanori and Ozay, Mete and Okatani, Takayuki},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4771--4780},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/suganuma18a/suganuma18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/suganuma18a.html},\n  abstract = \t {Researchers have applied deep neural networks to image restoration tasks, in which they proposed various network architectures, loss functions, and training methods. In particular, adversarial training, which is employed in recent studies, seems to be a key ingredient to success. In this paper, we show that simple convolutional autoencoders (CAEs) built upon only standard network components, i.e., convolutional layers and skip connections, can outperform the state-of-the-art methods which employ adversarial training and sophisticated loss functions. The secret is to search for good architectures using an evolutionary algorithm. All we did was to train the optimized CAEs by minimizing the l2 loss between reconstructed images and their ground truths using the ADAM optimizer. Our experimental results show that this approach achieves 27.8 dB peak signal to noise ratio (PSNR) on the CelebA dataset and 33.3 dB on the SVHN dataset, compared to 22.8 dB and 19.0 dB provided by the former state-of-the-art methods, respectively.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/suganuma18a/suganuma18a.pdf",
        "supp": "",
        "pdf_size": 1052209,
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4118394325034454915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "RIKEN, Tokyo, Japan+Tohoku University, Sendai, Japan; Tohoku University, Sendai, Japan; Tohoku University, Sendai, Japan",
        "aff_domain": "vision.is.tohoku.ac.jp; ; ",
        "email": "vision.is.tohoku.ac.jp; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/suganuma18a.html",
        "aff_unique_index": "0+1;1;1",
        "aff_unique_norm": "RIKEN;Tohoku University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.riken.jp;https://www.tohoku.ac.jp",
        "aff_unique_abbr": "RIKEN;Tohoku U",
        "aff_campus_unique_index": "0+1;1;1",
        "aff_campus_unique": "Tokyo;Sendai",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1891",
        "id": "1891",
        "author_site": "Zhihao Jia, Sina Lin, Charles Qi, Alex Aiken",
        "author": "Zhihao Jia; Sina Lin; Charles R. Qi; Alex Aiken",
        "abstract": "The past few years have witnessed growth in the computational requirements for training deep convolutional neural networks. Current approaches parallelize training onto multiple devices by applying a single parallelization strategy (e.g., data or model parallelism) to all layers in a network. Although easy to reason about, these approaches result in suboptimal runtime performance in large-scale distributed training, since different layers in a network may prefer different parallelization strategies. In this paper, we propose layer-wise parallelism that allows each layer in a network to use an individual parallelization strategy. We jointly optimize how each layer is parallelized by solving a graph search problem. Our evaluation shows that layer-wise parallelism outperforms state-of-the-art approaches by increasing training throughput, reducing communication costs, achieving better scalability to multiple GPUs, while maintaining original network accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-jia18a,\n  title = \t {Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks},\n  author =       {Jia, Zhihao and Lin, Sina and Qi, Charles R. and Aiken, Alex},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2274--2283},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jia18a/jia18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jia18a.html},\n  abstract = \t {The past few years have witnessed growth in the computational requirements for training deep convolutional neural networks. Current approaches parallelize training onto multiple devices by applying a single parallelization strategy (e.g., data or model parallelism) to all layers in a network. Although easy to reason about, these approaches result in suboptimal runtime performance in large-scale distributed training, since different layers in a network may prefer different parallelization strategies. In this paper, we propose layer-wise parallelism that allows each layer in a network to use an individual parallelization strategy. We jointly optimize how each layer is parallelized by solving a graph search problem. Our evaluation shows that layer-wise parallelism outperforms state-of-the-art approaches by increasing training throughput, reducing communication costs, achieving better scalability to multiple GPUs, while maintaining original network accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jia18a/jia18a.pdf",
        "supp": "",
        "pdf_size": 563170,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3576848664502386850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Stanford University; Microsoft; Stanford University; Stanford University",
        "aff_domain": "cs.stanford.edu; ; ; ",
        "email": "cs.stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/jia18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Stanford University;Microsoft",
        "aff_unique_dep": ";Microsoft Corporation",
        "aff_unique_url": "https://www.stanford.edu;https://www.microsoft.com",
        "aff_unique_abbr": "Stanford;Microsoft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2276",
        "id": "2276",
        "author_site": "Gail Weiss, Yoav Goldberg, Eran Yahav",
        "author": "Gail Weiss; Yoav Goldberg; Eran Yahav",
        "abstract": "We present a novel algorithm that uses exact learning and abstraction to extract a deterministic finite automaton describing the state dynamics of a given trained RNN. We do this using Angluin\u2019s \\lstar algorithm as a learner and the trained RNN as an oracle. Our technique efficiently extracts accurate automata from trained RNNs, even when the state vectors are large and require fine differentiation.",
        "bibtex": "@InProceedings{pmlr-v80-weiss18a,\n  title = \t {Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples},\n  author =       {Weiss, Gail and Goldberg, Yoav and Yahav, Eran},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5247--5256},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/weiss18a/weiss18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/weiss18a.html},\n  abstract = \t {We present a novel algorithm that uses exact learning and abstraction to extract a deterministic finite automaton describing the state dynamics of a given trained RNN. We do this using Angluin\u2019s \\lstar algorithm as a learner and the trained RNN as an oracle. Our technique efficiently extracts accurate automata from trained RNNs, even when the state vectors are large and require fine differentiation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/weiss18a/weiss18a.pdf",
        "supp": "",
        "pdf_size": 290705,
        "gs_citation": 255,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3812692831904479239&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Technion, Haifa, Israel; Bar Ilan University, Ramat Gan, Israel; Technion, Haifa, Israel",
        "aff_domain": "cs.technion.ac.il; ; ",
        "email": "cs.technion.ac.il; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/weiss18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology;Bar-Ilan University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.technion.ac.il/en/;https://www.biu.ac.il",
        "aff_unique_abbr": "Technion;BIU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Haifa;Ramat Gan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Extreme Learning to Rank via Low Rank Assumption",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2102",
        "id": "2102",
        "author_site": "Minhao Cheng, Ian Davidson, Cho-Jui Hsieh",
        "author": "Minhao Cheng; Ian Davidson; Cho-Jui Hsieh",
        "abstract": "We consider the setting where we wish to perform ranking for hundreds of thousands of users which is common in recommender systems and web search ranking. Learning a single ranking function is unlikely to capture the variability across all users while learning a ranking function for each person is time-consuming and requires large amounts of data from each user. To address this situation, we propose a Factorization RankSVM algorithm which learns a series of k basic ranking functions and then constructs for each user a local ranking function that is a combination of them. We develop a fast algorithm to reduce the time complexity of gradient descent solver by exploiting the low-rank structure, and the resulting algorithm is much faster than existing methods. Furthermore, we prove that the generalization error of the proposed method can be significantly better than training individual RankSVMs. Finally, we present some interesting patterns in the principal ranking functions learned by our algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-cheng18a,\n  title = \t {Extreme Learning to Rank via Low Rank Assumption},\n  author =       {Cheng, Minhao and Davidson, Ian and Hsieh, Cho-Jui},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {951--960},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cheng18a/cheng18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cheng18a.html},\n  abstract = \t {We consider the setting where we wish to perform ranking for hundreds of thousands of users which is common in recommender systems and web search ranking. Learning a single ranking function is unlikely to capture the variability across all users while learning a ranking function for each person is time-consuming and requires large amounts of data from each user. To address this situation, we propose a Factorization RankSVM algorithm which learns a series of k basic ranking functions and then constructs for each user a local ranking function that is a combination of them. We develop a fast algorithm to reduce the time complexity of gradient descent solver by exploiting the low-rank structure, and the resulting algorithm is much faster than existing methods. Furthermore, we prove that the generalization error of the proposed method can be significantly better than training individual RankSVMs. Finally, we present some interesting patterns in the principal ranking functions learned by our algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cheng18a/cheng18a.pdf",
        "supp": "",
        "pdf_size": 1065865,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9182893810623925979&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, University of California Davis, USA + Department of Statistics, University of California Davis, USA; Department of Computer Science, University of California Davis, USA; Department of Computer Science, University of California Davis, USA + Department of Statistics, University of California Davis, USA",
        "aff_domain": "ucdavis.edu; ; ",
        "email": "ucdavis.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/cheng18a.html",
        "aff_unique_index": "0+0;0;0+0",
        "aff_unique_norm": "University of California, Davis",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Davis",
        "aff_campus_unique_index": "0+0;0;0+0",
        "aff_campus_unique": "Davis",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Fair and Diverse DPP-Based Data Summarization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2176",
        "id": "2176",
        "author_site": "L. Elisa Celis, Vijay Keswani, Damian Straszak, Amit Jayant Deshpande, Tarun Kathuria, Nisheeth Vishnoi",
        "author": "Elisa Celis; Vijay Keswani; Damian Straszak; Amit Deshpande; Tarun Kathuria; Nisheeth Vishnoi",
        "abstract": "Sampling methods that choose a subset of the data proportional to its diversity in the feature space are popular for data summarization. However, recent studies have noted the occurrence of bias {\u2013} e.g., under or over representation of a particular gender or ethnicity {\u2013} in such data summarization methods. In this paper we initiate a study of the problem of outputting a diverse and fair summary of a given dataset. We work with a well-studied determinantal measure of diversity and corresponding distributions (DPPs) and present a framework that allows us to incorporate a general class of fairness constraints into such distributions. Designing efficient algorithms to sample from these constrained determinantal distributions, however, suffers from a complexity barrier; we present a fast sampler that is provably good when the input vectors satisfy a natural property. Our empirical results on both real-world and synthetic datasets show that the diversity of the samples produced by adding fairness constraints is not too far from the unconstrained case.",
        "bibtex": "@InProceedings{pmlr-v80-celis18a,\n  title = \t {Fair and Diverse {DPP}-Based Data Summarization},\n  author =       {Celis, Elisa and Keswani, Vijay and Straszak, Damian and Deshpande, Amit and Kathuria, Tarun and Vishnoi, Nisheeth},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {716--725},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/celis18a/celis18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/celis18a.html},\n  abstract = \t {Sampling methods that choose a subset of the data proportional to its diversity in the feature space are popular for data summarization. However, recent studies have noted the occurrence of bias {\u2013} e.g., under or over representation of a particular gender or ethnicity {\u2013} in such data summarization methods. In this paper we initiate a study of the problem of outputting a diverse and fair summary of a given dataset. We work with a well-studied determinantal measure of diversity and corresponding distributions (DPPs) and present a framework that allows us to incorporate a general class of fairness constraints into such distributions. Designing efficient algorithms to sample from these constrained determinantal distributions, however, suffers from a complexity barrier; we present a fast sampler that is provably good when the input vectors satisfy a natural property. Our empirical results on both real-world and synthetic datasets show that the diversity of the samples produced by adding fairness constraints is not too far from the unconstrained case.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/celis18a/celis18a.pdf",
        "supp": "",
        "pdf_size": 331551,
        "gs_citation": 149,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8274834659671095665&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Microsoft Research, India; UC Berkeley; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "aff_domain": "epfl.ch; ; ; ; ;epfl.ch",
        "email": "epfl.ch; ; ; ; ;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/celis18a.html",
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "EPFL;Microsoft;University of California, Berkeley",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://www.epfl.ch;https://www.microsoft.com/en-us/research/group/india.aspx;https://www.berkeley.edu",
        "aff_unique_abbr": "EPFL;MSR India;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0;1;2;0",
        "aff_country_unique": "Switzerland;India;United States"
    },
    {
        "title": "Fairness Without Demographics in Repeated Loss Minimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2434",
        "id": "2434",
        "author_site": "Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, Percy Liang",
        "author": "Tatsunori Hashimoto; Megha Srivastava; Hongseok Namkoong; Percy Liang",
        "abstract": "Machine learning models (e.g., speech recognizers) trained on average loss suffer from representation disparity\u2014minority groups (e.g., non-native speakers) carry less weight in the training objective, and thus tend to suffer higher loss. Worse, as model accuracy affects user retention, a minority group can shrink over time. In this paper, we first show that the status quo of empirical risk minimization (ERM) amplifies representation disparity over time, which can even turn initially fair models unfair. To mitigate this, we develop an approach based on distributionally robust optimization (DRO), which minimizes the worst case risk over all distributions close to the empirical distribution. We prove that this approach controls the risk of the minority group at each time step, in the spirit of Rawlsian distributive justice, while remaining oblivious to the identity of the groups. We demonstrate that DRO prevents disparity amplification on examples where ERM fails, and show improvements in minority group user satisfaction in a real-world text autocomplete task.",
        "bibtex": "@InProceedings{pmlr-v80-hashimoto18a,\n  title = \t {Fairness Without Demographics in Repeated Loss Minimization},\n  author =       {Hashimoto, Tatsunori and Srivastava, Megha and Namkoong, Hongseok and Liang, Percy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1929--1938},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hashimoto18a/hashimoto18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hashimoto18a.html},\n  abstract = \t {Machine learning models (e.g., speech recognizers) trained on average loss suffer from representation disparity\u2014minority groups (e.g., non-native speakers) carry less weight in the training objective, and thus tend to suffer higher loss. Worse, as model accuracy affects user retention, a minority group can shrink over time. In this paper, we first show that the status quo of empirical risk minimization (ERM) amplifies representation disparity over time, which can even turn initially fair models unfair. To mitigate this, we develop an approach based on distributionally robust optimization (DRO), which minimizes the worst case risk over all distributions close to the empirical distribution. We prove that this approach controls the risk of the minority group at each time step, in the spirit of Rawlsian distributive justice, while remaining oblivious to the identity of the groups. We demonstrate that DRO prevents disparity amplification on examples where ERM fails, and show improvements in minority group user satisfaction in a real-world text autocomplete task.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hashimoto18a/hashimoto18a.pdf",
        "supp": "",
        "pdf_size": 718052,
        "gs_citation": 757,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15368907455793303464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Stanford, USA+Department of Statistics, Stanford, USA; Department of Computer Science, Stanford, USA; Management Science & Engineering, Stanford, USA; Department of Computer Science, Stanford, USA",
        "aff_domain": "stanford.edu; ; ; ",
        "email": "stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/hashimoto18a.html",
        "aff_unique_index": "0+0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0+0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Fast Approximate Spectral Clustering for Dynamic Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2028",
        "id": "2028",
        "author_site": "Lionel Martin, Andreas Loukas, Pierre Vandergheynst",
        "author": "Lionel Martin; Andreas Loukas; Pierre Vandergheynst",
        "abstract": "Spectral clustering is a widely studied problem, yet its complexity is prohibitive for dynamic graphs of even modest size. We claim that it is possible to reuse information of past cluster assignments to expedite computation. Our approach builds on a recent idea of sidestepping the main bottleneck of spectral clustering, i.e., computing the graph eigenvectors, by a polynomial-based randomized sketching technique. We show that the proposed algorithm achieves clustering assignments with quality approximating that of spectral clustering and that it can yield significant complexity benefits when the graph dynamics are appropriately bounded. In our experiments, our method clusters 30k node graphs 3.9$\\times$ faster in average and deviates from the correct assignment by less than 0.1%.",
        "bibtex": "@InProceedings{pmlr-v80-martin18a,\n  title = \t {Fast Approximate Spectral Clustering for Dynamic Networks},\n  author =       {Martin, Lionel and Loukas, Andreas and Vandergheynst, Pierre},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3423--3432},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/martin18a/martin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/martin18a.html},\n  abstract = \t {Spectral clustering is a widely studied problem, yet its complexity is prohibitive for dynamic graphs of even modest size. We claim that it is possible to reuse information of past cluster assignments to expedite computation. Our approach builds on a recent idea of sidestepping the main bottleneck of spectral clustering, i.e., computing the graph eigenvectors, by a polynomial-based randomized sketching technique. We show that the proposed algorithm achieves clustering assignments with quality approximating that of spectral clustering and that it can yield significant complexity benefits when the graph dynamics are appropriately bounded. In our experiments, our method clusters 30k node graphs 3.9$\\times$ faster in average and deviates from the correct assignment by less than 0.1%.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/martin18a/martin18a.pdf",
        "supp": "",
        "pdf_size": 445211,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11235356289969169957&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "\u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne, Switzerland; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne, Switzerland; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne, Switzerland",
        "aff_domain": "epfl.ch;epfl.ch; ",
        "email": "epfl.ch;epfl.ch; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/martin18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Fast Bellman Updates for Robust MDPs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2318",
        "id": "2318",
        "author_site": "Chin Pang Ho, Marek Petrik, Wolfram Wiesemann",
        "author": "Chin Pang Ho; Marek Petrik; Wolfram Wiesemann",
        "abstract": "We describe two efficient, and exact, algorithms for computing Bellman updates in robust Markov decision processes (MDPs). The first algorithm uses a homotopy continuation method to compute updates for L1-constrained s,a-rectangular ambiguity sets. It runs in quasi-linear time for plain L1-norms and also generalizes to weighted L1-norms. The second algorithm uses bisection to compute updates for robust MDPs with s-rectangular ambiguity sets. This algorithm, when combined with the homotopy method, also has a quasi-linear runtime. Unlike previous methods, our algorithms compute the primal solution in addition to the optimal objective value, which makes them useful in policy iteration methods. Our experimental results indicate that the proposed methods are over 1,000 times faster than Gurobi, a state-of-the-art commercial optimization package, for small instances, and the performance gap grows considerably with problem size.",
        "bibtex": "@InProceedings{pmlr-v80-ho18a,\n  title = \t {Fast {B}ellman Updates for Robust {MDP}s},\n  author =       {Ho, Chin Pang and Petrik, Marek and Wiesemann, Wolfram},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1979--1988},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ho18a/ho18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ho18a.html},\n  abstract = \t {We describe two efficient, and exact, algorithms for computing Bellman updates in robust Markov decision processes (MDPs). The first algorithm uses a homotopy continuation method to compute updates for L1-constrained s,a-rectangular ambiguity sets. It runs in quasi-linear time for plain L1-norms and also generalizes to weighted L1-norms. The second algorithm uses bisection to compute updates for robust MDPs with s-rectangular ambiguity sets. This algorithm, when combined with the homotopy method, also has a quasi-linear runtime. Unlike previous methods, our algorithms compute the primal solution in addition to the optimal objective value, which makes them useful in policy iteration methods. Our experimental results indicate that the proposed methods are over 1,000 times faster than Gurobi, a state-of-the-art commercial optimization package, for small instances, and the performance gap grows considerably with problem size.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ho18a/ho18a.pdf",
        "supp": "",
        "pdf_size": 438617,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12071945544730669372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Imperial College London; Department of Computer Science, University of New Hampshire; Imperial College London",
        "aff_domain": "imperial.ac.uk;cs.unh.edu;imperial.ac.uk",
        "email": "imperial.ac.uk;cs.unh.edu;imperial.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ho18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Imperial College London;University of New Hampshire",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.unh.edu",
        "aff_unique_abbr": "ICL;UNH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Fast Decoding in Sequence Models Using Discrete Latent Variables",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2438",
        "id": "2438",
        "author_site": "Lukasz Kaiser, Samy Bengio, Aurko Roy, Ashish Vaswani, Niki Parmar, Jakob Uszkoreit, Noam Shazeer",
        "author": "Lukasz Kaiser; Samy Bengio; Aurko Roy; Ashish Vaswani; Niki Parmar; Jakob Uszkoreit; Noam Shazeer",
        "abstract": "Autoregressive sequence models based on deep neural networks, such as RNNs, Wavenet and Transformer are the state-of-the-art on many tasks. However, they lack parallelism and are thus slow for long sequences. RNNs lack parallelism both during training and decoding, while architectures like WaveNet and Transformer are much more parallel during training, but still lack parallelism during decoding. We present a method to extend sequence models using discrete latent variables that makes decoding much more parallel. The main idea behind this approach is to first autoencode the target sequence into a shorter discrete latent sequence, which is generated autoregressively, and finally decode the full sequence from this shorter latent sequence in a parallel manner. To this end, we introduce a new method for constructing discrete latent variables and compare it with previously introduced methods. Finally, we verify that our model works on the task of neural machine translation, where our models are an order of magnitude faster than comparable autoregressive models and, while lower in BLEU than purely autoregressive models, better than previously proposed non-autogregressive translation.",
        "bibtex": "@InProceedings{pmlr-v80-kaiser18a,\n  title = \t {Fast Decoding in Sequence Models Using Discrete Latent Variables},\n  author =       {Kaiser, Lukasz and Bengio, Samy and Roy, Aurko and Vaswani, Ashish and Parmar, Niki and Uszkoreit, Jakob and Shazeer, Noam},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2390--2399},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kaiser18a/kaiser18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kaiser18a.html},\n  abstract = \t {Autoregressive sequence models based on deep neural networks, such as RNNs, Wavenet and Transformer are the state-of-the-art on many tasks. However, they lack parallelism and are thus slow for long sequences. RNNs lack parallelism both during training and decoding, while architectures like WaveNet and Transformer are much more parallel during training, but still lack parallelism during decoding. We present a method to extend sequence models using discrete latent variables that makes decoding much more parallel. The main idea behind this approach is to first autoencode the target sequence into a shorter discrete latent sequence, which is generated autoregressively, and finally decode the full sequence from this shorter latent sequence in a parallel manner. To this end, we introduce a new method for constructing discrete latent variables and compare it with previously introduced methods. Finally, we verify that our model works on the task of neural machine translation, where our models are an order of magnitude faster than comparable autoregressive models and, while lower in BLEU than purely autoregressive models, better than previously proposed non-autogregressive translation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kaiser18a/kaiser18a.pdf",
        "supp": "",
        "pdf_size": 442081,
        "gs_citation": 149,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4042994175439965815&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA; Google Brain, Mountain View, California, USA",
        "aff_domain": "google.com;google.com; ; ; ; ; ",
        "email": "google.com;google.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/kaiser18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Brain",
        "aff_unique_url": "https://brain.google.com",
        "aff_unique_abbr": "Google Brain",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Fast Gradient-Based Methods with Exponential Rate: A Hybrid Control Framework",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2320",
        "id": "2320",
        "author_site": "Arman Sharifi Kolarijani, Peyman Mohajerin Esfahani, Tamas Keviczky",
        "author": "Arman Sharifi Kolarijani; Peyman Mohajerin Esfahani; Tamas Keviczky",
        "abstract": "Ordinary differential equations, and in general a dynamical system viewpoint, have seen a resurgence of interest in developing fast optimization methods, mainly thanks to the availability of well-established analysis tools. In this study, we pursue a similar objective and propose a class of hybrid control systems that adopts a 2nd-order differential equation as its continuous flow. A distinctive feature of the proposed differential equation in comparison with the existing literature is a state-dependent, time-invariant damping term that acts as a feedback control input. Given a user-defined scalar $\\alpha$, it is shown that the proposed control input steers the state trajectories to the global optimizer of a desired objective function with a guaranteed rate of convergence $\\mathcal{O}(e^{-\\alpha t})$. Our framework requires that the objective function satisfies the so called Polyak\u2013{\u0141}ojasiewicz inequality. Furthermore, a discretization method is introduced such that the resulting discrete dynamical system possesses an exponential rate of convergence.",
        "bibtex": "@InProceedings{pmlr-v80-kolarijani18a,\n  title = \t {Fast Gradient-Based Methods with Exponential Rate: A Hybrid Control Framework},\n  author =       {Kolarijani, Arman Sharifi and Esfahani, Peyman Mohajerin and Keviczky, Tamas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2728--2736},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kolarijani18a/kolarijani18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kolarijani18a.html},\n  abstract = \t {Ordinary differential equations, and in general a dynamical system viewpoint, have seen a resurgence of interest in developing fast optimization methods, mainly thanks to the availability of well-established analysis tools. In this study, we pursue a similar objective and propose a class of hybrid control systems that adopts a 2nd-order differential equation as its continuous flow. A distinctive feature of the proposed differential equation in comparison with the existing literature is a state-dependent, time-invariant damping term that acts as a feedback control input. Given a user-defined scalar $\\alpha$, it is shown that the proposed control input steers the state trajectories to the global optimizer of a desired objective function with a guaranteed rate of convergence $\\mathcal{O}(e^{-\\alpha t})$. Our framework requires that the objective function satisfies the so called Polyak\u2013{\u0141}ojasiewicz inequality. Furthermore, a discretization method is introduced such that the resulting discrete dynamical system possesses an exponential rate of convergence.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kolarijani18a/kolarijani18a.pdf",
        "supp": "",
        "pdf_size": 384142,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4345335815974312003&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Delft Center for Systems and Control, Delft University of Technology, The Netherlands; Delft Center for Systems and Control, Delft University of Technology, The Netherlands; Delft Center for Systems and Control, Delft University of Technology, The Netherlands",
        "aff_domain": "tudelft.nl; ; ",
        "email": "tudelft.nl; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kolarijani18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Delft Center for Systems and Control",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "title": "Fast Information-theoretic Bayesian Optimisation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1973",
        "id": "1973",
        "author_site": "Binxin Ru, Michael A Osborne, Mark Mcleod, Diego Granziol",
        "author": "Binxin Ru; Michael A. Osborne; Mark Mcleod; Diego Granziol",
        "abstract": "Information-theoretic Bayesian optimisation techniques have demonstrated state-of-the-art performance in tackling important global optimisation problems. However, current information-theoretic approaches require many approximations in implementation, introduce often-prohibitive computational overhead and limit the choice of kernels available to model the objective. We develop a fast information-theoretic Bayesian Optimisation method, FITBO, that avoids the need for sampling the global minimiser, thus significantly reducing computational overhead. Moreover, in comparison with existing approaches, our method faces fewer constraints on kernel choice and enjoys the merits of dealing with the output space. We demonstrate empirically that FITBO inherits the performance associated with information-theoretic Bayesian optimisation, while being even faster than simpler Bayesian optimisation approaches, such as Expected Improvement.",
        "bibtex": "@InProceedings{pmlr-v80-ru18a,\n  title = \t {Fast Information-theoretic {B}ayesian Optimisation},\n  author =       {Ru, Binxin and Osborne, Michael A. and Mcleod, Mark and Granziol, Diego},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4384--4392},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ru18a/ru18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ru18a.html},\n  abstract = \t {Information-theoretic Bayesian optimisation techniques have demonstrated state-of-the-art performance in tackling important global optimisation problems. However, current information-theoretic approaches require many approximations in implementation, introduce often-prohibitive computational overhead and limit the choice of kernels available to model the objective. We develop a fast information-theoretic Bayesian Optimisation method, FITBO, that avoids the need for sampling the global minimiser, thus significantly reducing computational overhead. Moreover, in comparison with existing approaches, our method faces fewer constraints on kernel choice and enjoys the merits of dealing with the output space. We demonstrate empirically that FITBO inherits the performance associated with information-theoretic Bayesian optimisation, while being even faster than simpler Bayesian optimisation approaches, such as Expected Improvement.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ru18a/ru18a.pdf",
        "supp": "",
        "pdf_size": 941847,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12232335065092117172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Engineering Science, University of Oxford, Oxford, UK+Mind Foundry Ltd., Oxford; Department of Engineering Science, University of Oxford, Oxford, UK+Mind Foundry Ltd., Oxford; Department of Engineering Science, University of Oxford, Oxford, UK+Mind Foundry Ltd., Oxford; Department of Engineering Science, University of Oxford, Oxford, UK+Mind Foundry Ltd., Oxford",
        "aff_domain": "robots.ox.ac.uk;magd.ox.ac.uk;robots.ox.ac.uk;robots.ox.ac.uk",
        "email": "robots.ox.ac.uk;magd.ox.ac.uk;robots.ox.ac.uk;robots.ox.ac.uk",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ru18a.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "University of Oxford;Mind Foundry Ltd.",
        "aff_unique_dep": "Department of Engineering Science;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.mindfoundry.co.uk",
        "aff_unique_abbr": "Oxford;",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1912",
        "id": "1912",
        "author_site": "Alan Kuhnle, J. Smith, Victoria Crawford, My T. Thai",
        "author": "Alan Kuhnle; J. David Smith; Victoria Crawford; My Thai",
        "abstract": "The optimization of submodular functions on the integer lattice has received much attention recently, but the objective functions of many applications are non-submodular. We provide two approximation algorithms for maximizing a non-submodular function on the integer lattice subject to a cardinality constraint; these are the first algorithms for this purpose that have polynomial query complexity. We propose a general framework for influence maximization on the integer lattice that generalizes prior works on this topic, and we demonstrate the efficiency of our algorithms in this context.",
        "bibtex": "@InProceedings{pmlr-v80-kuhnle18a,\n  title = \t {Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice},\n  author =       {Kuhnle, Alan and Smith, J. David and Crawford, Victoria and Thai, My},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2786--2795},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kuhnle18a/kuhnle18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kuhnle18a.html},\n  abstract = \t {The optimization of submodular functions on the integer lattice has received much attention recently, but the objective functions of many applications are non-submodular. We provide two approximation algorithms for maximizing a non-submodular function on the integer lattice subject to a cardinality constraint; these are the first algorithms for this purpose that have polynomial query complexity. We propose a general framework for influence maximization on the integer lattice that generalizes prior works on this topic, and we demonstrate the efficiency of our algorithms in this context.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kuhnle18a/kuhnle18a.pdf",
        "supp": "",
        "pdf_size": 633187,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=468867736927651405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Florida; University of Florida; University of Florida; University of Florida",
        "aff_domain": "ufl.edu; ; ;ufl.edu",
        "email": "ufl.edu; ; ;ufl.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kuhnle18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Florida",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ufl.edu",
        "aff_unique_abbr": "UF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Fast Parametric Learning with Activation Memorization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2299",
        "id": "2299",
        "author_site": "Jack Rae, Chris Dyer, Peter Dayan, Timothy Lillicrap",
        "author": "Jack Rae; Chris Dyer; Peter Dayan; Timothy Lillicrap",
        "abstract": "Neural networks trained with backpropagation often struggle to identify classes that have been observed a small number of times. In applications where most class labels are rare, such as language modelling, this can become a performance bottleneck. One potential remedy is to augment the network with a fast-learning non-parametric model which stores recent activations and class labels into an external memory. We explore a simplified architecture where we treat a subset of the model parameters as fast memory stores. This can help retain information over longer time intervals than a traditional memory, and does not require additional space or compute. In the case of image classification, we display faster binding of novel classes on an Omniglot image curriculum task. We also show improved performance for word-based language models on news reports (GigaWord), books (Project Gutenberg) and Wikipedia articles (WikiText-103) - the latter achieving a state-of-the-art perplexity of 29.2.",
        "bibtex": "@InProceedings{pmlr-v80-rae18a,\n  title = \t {Fast Parametric Learning with Activation Memorization},\n  author =       {Rae, Jack and Dyer, Chris and Dayan, Peter and Lillicrap, Timothy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4228--4237},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rae18a/rae18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rae18a.html},\n  abstract = \t {Neural networks trained with backpropagation often struggle to identify classes that have been observed a small number of times. In applications where most class labels are rare, such as language modelling, this can become a performance bottleneck. One potential remedy is to augment the network with a fast-learning non-parametric model which stores recent activations and class labels into an external memory. We explore a simplified architecture where we treat a subset of the model parameters as fast memory stores. This can help retain information over longer time intervals than a traditional memory, and does not require additional space or compute. In the case of image classification, we display faster binding of novel classes on an Omniglot image curriculum task. We also show improved performance for word-based language models on news reports (GigaWord), books (Project Gutenberg) and Wikipedia articles (WikiText-103) - the latter achieving a state-of-the-art perplexity of 29.2.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rae18a/rae18a.pdf",
        "supp": "",
        "pdf_size": 715417,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3568206229599826410&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "DeepMind, London, UK+CoMPLEX, Computer Science, University College London, London, UK; DeepMind, London, UK; Gatsby Computational Neuroscience Unit, University College London, UK; DeepMind, London, UK+CoMPLEX, Computer Science, University College London, London, UK",
        "aff_domain": "google.com; ; ;google.com",
        "email": "google.com; ; ;google.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/rae18a.html",
        "aff_unique_index": "0+1;0;1;0+1",
        "aff_unique_norm": "DeepMind;University College London",
        "aff_unique_dep": ";Computer Science",
        "aff_unique_url": "https://deepmind.com;https://www.ucl.ac.uk",
        "aff_unique_abbr": "DeepMind;UCL",
        "aff_campus_unique_index": "0+0;0;0;0+0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0+0;0;0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Fast Stochastic AUC Maximization with $O(1/n)$-Convergence Rate",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1940",
        "id": "1940",
        "author_site": "Mingrui Liu, Xiaoxuan Zhang, Zaiyi Chen, Xiaoyu Wang, Tianbao Yang",
        "author": "Mingrui Liu; Xiaoxuan Zhang; Zaiyi Chen; Xiaoyu Wang; Tianbao Yang",
        "abstract": "In this paper, we consider statistical learning with AUC (area under ROC curve) maximization in the classical stochastic setting where one random data drawn from an unknown distribution is revealed at each iteration for updating the model. Although consistent convex surrogate losses for AUC maximization have been proposed to make the problem tractable, it remains an challenging problem to design fast optimization algorithms in the classical stochastic setting due to that the convex surrogate loss depends on random pairs of examples from positive and negative classes. Building on a saddle point formulation for a consistent square loss, this paper proposes a novel stochastic algorithm to improve the standard $O(1/\\sqrt{n})$ convergence rate to $\\widetilde O(1/n)$ convergence rate without strong convexity assumption or any favorable statistical assumptions (e.g., low noise), where $n$ is the number of random samples. To the best of our knowledge, this is the first stochastic algorithm for AUC maximization with a statistical convergence rate as fast as $O(1/n)$ up to a logarithmic factor. Extensive experiments on eight large-scale benchmark data sets demonstrate the superior performance of the proposed algorithm comparing with existing stochastic or online algorithms for AUC maximization.",
        "bibtex": "@InProceedings{pmlr-v80-liu18g,\n  title = \t {Fast Stochastic {AUC} Maximization with $O(1/n)$-Convergence Rate},\n  author =       {Liu, Mingrui and Zhang, Xiaoxuan and Chen, Zaiyi and Wang, Xiaoyu and Yang, Tianbao},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3189--3197},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18g/liu18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18g.html},\n  abstract = \t {In this paper, we consider statistical learning with AUC (area under ROC curve) maximization in the classical stochastic setting where one random data drawn from an unknown distribution is revealed at each iteration for updating the model. Although consistent convex surrogate losses for AUC maximization have been proposed to make the problem tractable, it remains an challenging problem to design fast optimization algorithms in the classical stochastic setting due to that the convex surrogate loss depends on random pairs of examples from positive and negative classes. Building on a saddle point formulation for a consistent square loss, this paper proposes a novel stochastic algorithm to improve the standard $O(1/\\sqrt{n})$ convergence rate to $\\widetilde O(1/n)$ convergence rate without strong convexity assumption or any favorable statistical assumptions (e.g., low noise), where $n$ is the number of random samples. To the best of our knowledge, this is the first stochastic algorithm for AUC maximization with a statistical convergence rate as fast as $O(1/n)$ up to a logarithmic factor. Extensive experiments on eight large-scale benchmark data sets demonstrate the superior performance of the proposed algorithm comparing with existing stochastic or online algorithms for AUC maximization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18g/liu18g.pdf",
        "supp": "",
        "pdf_size": 472057,
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9537058118416371403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Computer Science, The University of Iowa, IA 52242, USA; Department of Computer Science, The University of Iowa, IA 52242, USA; University of Science and Technology of China; Intellifusion; Department of Computer Science, The University of Iowa, IA 52242, USA",
        "aff_domain": "uiowa.edu; ; ; ;uiowa.edu",
        "email": "uiowa.edu; ; ; ;uiowa.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/liu18g.html",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Iowa;University of Science and Technology of China;Intellifusion",
        "aff_unique_dep": "Department of Computer Science;;",
        "aff_unique_url": "https://www.uiowa.edu;http://www.ustc.edu.cn;https://www.intellifusion.com/",
        "aff_unique_abbr": "UIowa;USTC;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Fast Variance Reduction Method with Stochastic Batch Size",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2295",
        "id": "2295",
        "author_site": "University of California Xuanqing Liu, Cho-Jui Hsieh",
        "author": "Xuanqing Liu; Cho-Jui Hsieh",
        "abstract": "In this paper we study a family of variance reduction methods with randomized batch size\u2014at each step, the algorithm first randomly chooses the batch size and then selects a batch of samples to conduct a variance-reduced stochastic update. We give the linear converge rate for this framework for composite functions, and show that the optimal strategy to achieve the best converge rate per data access is to always choose batch size equalling to 1, which is equivalent to the SAGA algorithm. However, due to the presence of cache/disk IO effect in computer architecture, number of data access cannot reflect the running time because of 1) random memory access is much slower than sequential access, 2) when data is too big to fit into memory, disk seeking takes even longer time. After taking these into account, choosing batch size equals to 1 is no longer optimal, so we propose a new algorithm called SAGA++ and theoretically show how to calculate the optimal average batch size. Our algorithm outperforms SAGA and other existing batch and stochastic solvers on real datasets. In addition, we also conduct a precise analysis to compare different update rules for variance reduction methods, showing that SAGA++ converges faster than SVRG in theory.",
        "bibtex": "@InProceedings{pmlr-v80-liu18f,\n  title = \t {Fast Variance Reduction Method with Stochastic Batch Size},\n  author =       {Liu, Xuanqing and Hsieh, Cho-Jui},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3179--3188},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18f/liu18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18f.html},\n  abstract = \t {In this paper we study a family of variance reduction methods with randomized batch size\u2014at each step, the algorithm first randomly chooses the batch size and then selects a batch of samples to conduct a variance-reduced stochastic update. We give the linear converge rate for this framework for composite functions, and show that the optimal strategy to achieve the best converge rate per data access is to always choose batch size equalling to 1, which is equivalent to the SAGA algorithm. However, due to the presence of cache/disk IO effect in computer architecture, number of data access cannot reflect the running time because of 1) random memory access is much slower than sequential access, 2) when data is too big to fit into memory, disk seeking takes even longer time. After taking these into account, choosing batch size equals to 1 is no longer optimal, so we propose a new algorithm called SAGA++ and theoretically show how to calculate the optimal average batch size. Our algorithm outperforms SAGA and other existing batch and stochastic solvers on real datasets. In addition, we also conduct a precise analysis to compare different update rules for variance reduction methods, showing that SAGA++ converges faster than SVRG in theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18f/liu18f.pdf",
        "supp": "",
        "pdf_size": 551515,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10778333779146071070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of California, Davis, California, USA+Department of Statistic, University of California, Davis, California, USA; Department of Computer Science, University of California, Davis, California, USA+Department of Statistic, University of California, Davis, California, USA",
        "aff_domain": "ucdavis.edu;ucdavis.edu",
        "email": "ucdavis.edu;ucdavis.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/liu18f.html",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "University of California, Davis",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Davis",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Davis",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase Procrustes Flow",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1951",
        "id": "1951",
        "author_site": "Xiao Zhang, Simon Du, Quanquan Gu",
        "author": "Xiao Zhang; Simon Du; Quanquan Gu",
        "abstract": "We revisit the inductive matrix completion problem that aims to recover a rank-$r$ matrix with ambient dimension $d$ given $n$ features as the side prior information. The goal is to make use of the known $n$ features to reduce sample and computational complexities. We present and analyze a new gradient-based non-convex optimization algorithm that converges to the true underlying matrix at a linear rate with sample complexity only linearly depending on $n$ and logarithmically depending on $d$. To the best of our knowledge, all previous algorithms either have a quadratic dependency on the number of features in sample complexity or a sub-linear computational convergence rate. In addition, we provide experiments on both synthetic and real world data to demonstrate the effectiveness of our proposed algorithm.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18b,\n  title = \t {Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase Procrustes Flow},\n  author =       {Zhang, Xiao and Du, Simon and Gu, Quanquan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5756--5765},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18b/zhang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18b.html},\n  abstract = \t {We revisit the inductive matrix completion problem that aims to recover a rank-$r$ matrix with ambient dimension $d$ given $n$ features as the side prior information. The goal is to make use of the known $n$ features to reduce sample and computational complexities. We present and analyze a new gradient-based non-convex optimization algorithm that converges to the true underlying matrix at a linear rate with sample complexity only linearly depending on $n$ and logarithmically depending on $d$. To the best of our knowledge, all previous algorithms either have a quadratic dependency on the number of features in sample complexity or a sub-linear computational convergence rate. In addition, we provide experiments on both synthetic and real world data to demonstrate the effectiveness of our proposed algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18b/zhang18b.pdf",
        "supp": "",
        "pdf_size": 377281,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16663516703684803968&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Virginia, Charlottesville, Virginia, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA",
        "aff_domain": "cs.ucla.edu; ; ",
        "email": "cs.ucla.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhang18b.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Virginia;Carnegie Mellon University;University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science;Machine Learning Department;Department of Computer Science",
        "aff_unique_url": "https://www.virginia.edu;https://www.cmu.edu;https://www.ucla.edu",
        "aff_unique_abbr": "UVA;CMU;UCLA",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Charlottesville;Pittsburgh;Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2261",
        "id": "2261",
        "author_site": "Mohammad Emtiyaz Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin Gal, Akash Srivastava",
        "author": "Mohammad Khan; Didrik Nielsen; Voot Tangkaratt; Wu Lin; Yarin Gal; Akash Srivastava",
        "abstract": "Uncertainty computation in deep learning is essential to design robust and reliable systems. Variational inference (VI) is a promising approach for such computation, but requires more effort to implement and execute compared to maximum-likelihood methods. In this paper, we propose new natural-gradient algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms can be implemented within the Adam optimizer by perturbing the network weights during gradient evaluations, and uncertainty estimates can be cheaply obtained by using the vector that adapts the learning rate. This requires lower memory, computation, and implementation effort than existing VI methods, while obtaining uncertainty estimates of comparable quality. Our empirical results confirm this and further suggest that the weight-perturbation in our algorithm could be useful for exploration in reinforcement learning and stochastic optimization.",
        "bibtex": "@InProceedings{pmlr-v80-khan18a,\n  title = \t {Fast and Scalable {B}ayesian Deep Learning by Weight-Perturbation in {A}dam},\n  author =       {Khan, Mohammad and Nielsen, Didrik and Tangkaratt, Voot and Lin, Wu and Gal, Yarin and Srivastava, Akash},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2611--2620},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/khan18a/khan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/khan18a.html},\n  abstract = \t {Uncertainty computation in deep learning is essential to design robust and reliable systems. Variational inference (VI) is a promising approach for such computation, but requires more effort to implement and execute compared to maximum-likelihood methods. In this paper, we propose new natural-gradient algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms can be implemented within the Adam optimizer by perturbing the network weights during gradient evaluations, and uncertainty estimates can be cheaply obtained by using the vector that adapts the learning rate. This requires lower memory, computation, and implementation effort than existing VI methods, while obtaining uncertainty estimates of comparable quality. Our empirical results confirm this and further suggest that the weight-perturbation in our algorithm could be useful for exploration in reinforcement learning and stochastic optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/khan18a/khan18a.pdf",
        "supp": "",
        "pdf_size": 973045,
        "gs_citation": 339,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11374390410783252644&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "RIKEN Center for Advanced Intelligence project, Tokyo, Japan; RIKEN Center for Advanced Intelligence project, Tokyo, Japan; RIKEN Center for Advanced Intelligence project, Tokyo, Japan; University of British Columbia, Vancouver, Canada; University of Oxford, Oxford, UK; University of Edinburgh, Edinburgh, UK",
        "aff_domain": "riken.jp; ; ; ; ; ",
        "email": "riken.jp; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/khan18a.html",
        "aff_unique_index": "0;0;0;1;2;3",
        "aff_unique_norm": "RIKEN Center for Advanced Intelligence Project;University of British Columbia;University of Oxford;University of Edinburgh",
        "aff_unique_dep": "Center for Advanced Intelligence;;;",
        "aff_unique_url": "https://www.riken.jp/en/crai/;https://www.ubc.ca;https://www.ox.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "RIKEN CRAI;UBC;Oxford;Edinburgh",
        "aff_campus_unique_index": "0;0;0;1;2;3",
        "aff_campus_unique": "Tokyo;Vancouver;Oxford;Edinburgh",
        "aff_country_unique_index": "0;0;0;1;2;2",
        "aff_country_unique": "Japan;Canada;United Kingdom"
    },
    {
        "title": "Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2022",
        "id": "2022",
        "author_site": "Bin Gu, Zhouyuan Huo, Cheng Deng, Heng Huang",
        "author": "Bin Gu; Zhouyuan Huo; Cheng Deng; Heng Huang",
        "abstract": "Asynchronous parallel stochastic gradient optimization has been playing a pivotal role to solve large-scale machine learning problems in big data applications. Zeroth-order (derivative-free) methods estimate the gradient only by two function evaluations, thus have been applied to solve the problems where the explicit gradient calculations are computationally expensive or infeasible. Recently, the first asynchronous parallel stochastic zeroth-order algorithm (AsySZO) was proposed. However, its convergence rate is O(1/SQRT{T}) for the smooth, possibly non-convex learning problems, which is significantly slower than O(1/T) the best convergence rate of (asynchronous) stochastic gradient algorithm. To fill this gap, in this paper, we first point out the fundamental reason leading to the slow convergence rate of AsySZO, and then propose a new asynchronous stochastic zerothorder algorithm (AsySZO+). We provide a faster convergence rate O(1/bT) (b is the mini-batch size) for AsySZO+ by the rigorous theoretical analysis, which is a significant improvement over O(1/SQRT{T}). The experimental results on the application of ensemble learning confirm that our AsySZO+ has a faster convergence rate than the existing (asynchronous) stochastic zeroth-order algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-gu18a,\n  title = \t {Faster Derivative-Free Stochastic Algorithm for Shared Memory Machines},\n  author =       {Gu, Bin and Huo, Zhouyuan and Deng, Cheng and Huang, Heng},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1812--1821},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gu18a/gu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gu18a.html},\n  abstract = \t {Asynchronous parallel stochastic gradient optimization has been playing a pivotal role to solve large-scale machine learning problems in big data applications. Zeroth-order (derivative-free) methods estimate the gradient only by two function evaluations, thus have been applied to solve the problems where the explicit gradient calculations are computationally expensive or infeasible. Recently, the first asynchronous parallel stochastic zeroth-order algorithm (AsySZO) was proposed. However, its convergence rate is O(1/SQRT{T}) for the smooth, possibly non-convex learning problems, which is significantly slower than O(1/T) the best convergence rate of (asynchronous) stochastic gradient algorithm. To fill this gap, in this paper, we first point out the fundamental reason leading to the slow convergence rate of AsySZO, and then propose a new asynchronous stochastic zerothorder algorithm (AsySZO+). We provide a faster convergence rate O(1/bT) (b is the mini-batch size) for AsySZO+ by the rigorous theoretical analysis, which is a significant improvement over O(1/SQRT{T}). The experimental results on the application of ensemble learning confirm that our AsySZO+ has a faster convergence rate than the existing (asynchronous) stochastic zeroth-order algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gu18a/gu18a.pdf",
        "supp": "",
        "pdf_size": 865231,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4501785268093834280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical and Computer Engineering, University of Pittsburgh, PA, USA+School of Electronic Engineering, Xidian University, Xi\u2019an, Shaanxi, China; Department of Electrical and Computer Engineering, University of Pittsburgh, PA, USA+School of Electronic Engineering, Xidian University, Xi\u2019an, Shaanxi, China; School of Electronic Engineering, Xidian University, Xi\u2019an, Shaanxi, China; Department of Electrical and Computer Engineering, University of Pittsburgh, PA, USA+School of Electronic Engineering, Xidian University, Xi\u2019an, Shaanxi, China",
        "aff_domain": "gmail.com; ; ;gmail.com",
        "email": "gmail.com; ; ;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/gu18a.html",
        "aff_unique_index": "0+1;0+1;1;0+1",
        "aff_unique_norm": "University of Pittsburgh;Xidian University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;School of Electronic Engineering",
        "aff_unique_url": "https://www.pitt.edu;http://www.xidian.edu.cn",
        "aff_unique_abbr": "Pitt;Xidian",
        "aff_campus_unique_index": "0+1;0+1;1;0+1",
        "aff_campus_unique": "Pittsburgh;Xi'an",
        "aff_country_unique_index": "0+1;0+1;1;0+1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Feasible Arm Identification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2064",
        "id": "2064",
        "author_site": "Julian Katz-Samuels, Clay Scott",
        "author": "Julian Katz-Samuels; Clay Scott",
        "abstract": "We introduce the feasible arm identification problem, a pure exploration multi-armed bandit problem where the agent is given a set of $D$-dimensional arms and a polyhedron $P = \\{x : A x \\leq b \\} \\subset R^D$. Pulling an arm gives a random vector and the goal is to determine, using a fixed budget of $T$ pulls, which of the arms have means belonging to $P$. We propose three algorithms MD-UCBE, MD-SAR, and MD-APT and provide a unified analysis establishing upper bounds for each of them. We also establish a lower bound that matches up to constants the upper bounds of MD-UCBE and MD-APT. Finally, we demonstrate the effectiveness of our algorithms on synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v80-katz-samuels18a,\n  title = \t {Feasible Arm Identification},\n  author =       {Katz-Samuels, Julian and Scott, Clay},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2535--2543},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/katz-samuels18a/katz-samuels18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/katz-samuels18a.html},\n  abstract = \t {We introduce the feasible arm identification problem, a pure exploration multi-armed bandit problem where the agent is given a set of $D$-dimensional arms and a polyhedron $P = \\{x : A x \\leq b \\} \\subset R^D$. Pulling an arm gives a random vector and the goal is to determine, using a fixed budget of $T$ pulls, which of the arms have means belonging to $P$. We propose three algorithms MD-UCBE, MD-SAR, and MD-APT and provide a unified analysis establishing upper bounds for each of them. We also establish a lower bound that matches up to constants the upper bounds of MD-UCBE and MD-APT. Finally, we demonstrate the effectiveness of our algorithms on synthetic and real-world datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/katz-samuels18a/katz-samuels18a.pdf",
        "supp": "",
        "pdf_size": 2984105,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4670258338017243429&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Department of Computer Science and Electrical Engineering, University of Michigan; Department of Computer Science and Electrical Engineering, University of Michigan",
        "aff_domain": "umich.edu; ",
        "email": "umich.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/katz-samuels18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Computer Science and Electrical Engineering",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Feedback-Based Tree Search for Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2429",
        "id": "2429",
        "author_site": "Daniel Jiang, Emmanuel Ekwedike, Han Liu",
        "author": "Daniel Jiang; Emmanuel Ekwedike; Han Liu",
        "abstract": "Inspired by recent successes of Monte-Carlo tree search (MCTS) in a number of artificial intelligence (AI) application domains, we propose a reinforcement learning (RL) technique that iteratively applies MCTS on batches of small, finite-horizon versions of the original infinite-horizon Markov decision process. The terminal condition of the finite-horizon problems, or the leaf-node evaluator of the decision tree generated by MCTS, is specified using a combination of an estimated value function and an estimated policy function. The recommendations generated by the MCTS procedure are then provided as feedback in order to refine, through classification and regression, the leaf-node evaluator for the next iteration. We provide the first sample complexity bounds for a tree search-based RL algorithm. In addition, we show that a deep neural network implementation of the technique can create a competitive AI agent for the popular multi-player online battle arena (MOBA) game King of Glory.",
        "bibtex": "@InProceedings{pmlr-v80-jiang18a,\n  title = \t {Feedback-Based Tree Search for Reinforcement Learning},\n  author =       {Jiang, Daniel and Ekwedike, Emmanuel and Liu, Han},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2284--2293},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jiang18a/jiang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jiang18a.html},\n  abstract = \t {Inspired by recent successes of Monte-Carlo tree search (MCTS) in a number of artificial intelligence (AI) application domains, we propose a reinforcement learning (RL) technique that iteratively applies MCTS on batches of small, finite-horizon versions of the original infinite-horizon Markov decision process. The terminal condition of the finite-horizon problems, or the leaf-node evaluator of the decision tree generated by MCTS, is specified using a combination of an estimated value function and an estimated policy function. The recommendations generated by the MCTS procedure are then provided as feedback in order to refine, through classification and regression, the leaf-node evaluator for the next iteration. We provide the first sample complexity bounds for a tree search-based RL algorithm. In addition, we show that a deep neural network implementation of the technique can create a competitive AI agent for the popular multi-player online battle arena (MOBA) game King of Glory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jiang18a/jiang18a.pdf",
        "supp": "",
        "pdf_size": 2757108,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2576590834471620908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Pittsburgh; Tencent AI Lab + Princeton University; Tencent AI Lab + Northwestern University",
        "aff_domain": "pitt.edu; ; ",
        "email": "pitt.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jiang18a.html",
        "aff_unique_index": "0;1+2;1+3",
        "aff_unique_norm": "University of Pittsburgh;Tencent;Princeton University;Northwestern University",
        "aff_unique_dep": ";Tencent AI Lab;;",
        "aff_unique_url": "https://www.pitt.edu;https://ai.tencent.com;https://www.princeton.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "Pitt;Tencent AI Lab;Princeton;NU",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;1+0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Finding Influential Training Samples for Gradient Boosted Decision Trees",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2395",
        "id": "2395",
        "author_site": "Boris Sharchilev, Yury Ustinovskiy, Pavel Serdyukov, Maarten de Rijke",
        "author": "Boris Sharchilev; Yury Ustinovskiy; Pavel Serdyukov; Maarten Rijke",
        "abstract": "We address the problem of finding influential training samples for a particular case of tree ensemble-based models, e.g., Random Forest (RF) or Gradient Boosted Decision Trees (GBDT). A natural way of formalizing this problem is studying how the model\u2019s predictions change upon leave-one-out retraining, leaving out each individual training sample. Recent work has shown that, for parametric models, this analysis can be conducted in a computationally efficient way. We propose several ways of extending this framework to non-parametric GBDT ensembles under the assumption that tree structures remain fixed. Furthermore, we introduce a general scheme of obtaining further approximations to our method that balance the trade-off between performance and computational complexity. We evaluate our approaches on various experimental setups and use-case scenarios and demonstrate both the quality of our approach to finding influential training samples in comparison to the baselines and its computational efficiency.",
        "bibtex": "@InProceedings{pmlr-v80-sharchilev18a,\n  title = \t {Finding Influential Training Samples for Gradient Boosted Decision Trees},\n  author =       {Sharchilev, Boris and Ustinovskiy, Yury and Serdyukov, Pavel and de Rijke, Maarten},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4577--4585},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sharchilev18a/sharchilev18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sharchilev18a.html},\n  abstract = \t {We address the problem of finding influential training samples for a particular case of tree ensemble-based models, e.g., Random Forest (RF) or Gradient Boosted Decision Trees (GBDT). A natural way of formalizing this problem is studying how the model\u2019s predictions change upon leave-one-out retraining, leaving out each individual training sample. Recent work has shown that, for parametric models, this analysis can be conducted in a computationally efficient way. We propose several ways of extending this framework to non-parametric GBDT ensembles under the assumption that tree structures remain fixed. Furthermore, we introduce a general scheme of obtaining further approximations to our method that balance the trade-off between performance and computational complexity. We evaluate our approaches on various experimental setups and use-case scenarios and demonstrate both the quality of our approach to finding influential training samples in comparison to the baselines and its computational efficiency.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sharchilev18a/sharchilev18a.pdf",
        "supp": "",
        "pdf_size": 427185,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16436473119957517587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands+Yandex, Moscow, Russia; Department of Mathematics, Princeton University, Princeton, NJ, USA; Yandex, Moscow, Russia; Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands",
        "aff_domain": "yandex-team.ru; ;yandex-team.ru;uva.nl",
        "email": "yandex-team.ru; ;yandex-team.ru;uva.nl",
        "github": "https://github.com/bsharchilev/influence_boosting",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sharchilev18a.html",
        "aff_unique_index": "0+1;2;1;0",
        "aff_unique_norm": "University of Amsterdam;Yandex;Princeton University",
        "aff_unique_dep": "Informatics Institute;;Department of Mathematics",
        "aff_unique_url": "https://www.uva.nl;https://yandex.com;https://www.princeton.edu",
        "aff_unique_abbr": "UvA;Yandex;Princeton",
        "aff_campus_unique_index": "0+1;2;1;0",
        "aff_campus_unique": "Amsterdam;Moscow;Princeton",
        "aff_country_unique_index": "0+1;2;1;0",
        "aff_country_unique": "Netherlands;Russian Federation;United States"
    },
    {
        "title": "Firing Bandits: Optimizing Crowdfunding",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2462",
        "id": "2462",
        "author_site": "Lalit Jain, Kevin Jamieson",
        "author": "Lalit Jain; Kevin Jamieson",
        "abstract": "In this paper, we model the problem of optimizing crowdfunding platforms, such as the non-profit Kiva or for-profit KickStarter, as a variant of the multi-armed bandit problem. In our setting, Bernoulli arms emit no rewards until their cumulative number of successes over any number of trials exceeds a fixed threshold and then provides no additional reward for any additional trials - a process reminiscent to that of a neuron firing once it reaches the action potential and then saturates. In the spirit of an infinite armed bandit problem, the player can add new arms whose expected probability of success is drawn iid from an unknown distribution \u2013 this endless supply of projects models the harsh reality that the number of projects seeking funding greatly exceeds the total capital available by lenders. Crowdfunding platforms naturally fall under this setting where the arms are potential projects, and their probability of success is the probability that a potential funder decides to fund it after reviewing it. The goal is to play arms (prioritize the display of projects on a webpage) to maximize the number of arms that reach the firing threshold (meet their goal amount) using as few total trials (number of impressions) as possible over all the played arms. We provide an algorithm for this setting and prove sublinear regret bounds.",
        "bibtex": "@InProceedings{pmlr-v80-jain18a,\n  title = \t {Firing Bandits: Optimizing Crowdfunding},\n  author =       {Jain, Lalit and Jamieson, Kevin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2206--2214},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jain18a/jain18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jain18a.html},\n  abstract = \t {In this paper, we model the problem of optimizing crowdfunding platforms, such as the non-profit Kiva or for-profit KickStarter, as a variant of the multi-armed bandit problem. In our setting, Bernoulli arms emit no rewards until their cumulative number of successes over any number of trials exceeds a fixed threshold and then provides no additional reward for any additional trials - a process reminiscent to that of a neuron firing once it reaches the action potential and then saturates. In the spirit of an infinite armed bandit problem, the player can add new arms whose expected probability of success is drawn iid from an unknown distribution \u2013 this endless supply of projects models the harsh reality that the number of projects seeking funding greatly exceeds the total capital available by lenders. Crowdfunding platforms naturally fall under this setting where the arms are potential projects, and their probability of success is the probability that a potential funder decides to fund it after reviewing it. The goal is to play arms (prioritize the display of projects on a webpage) to maximize the number of arms that reach the firing threshold (meet their goal amount) using as few total trials (number of impressions) as possible over all the played arms. We provide an algorithm for this setting and prove sublinear regret bounds.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jain18a/jain18a.pdf",
        "supp": "",
        "pdf_size": 1036012,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7868152296766936865&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Computer Science and Engineering, University of Washington, Seattle, USA; Computer Science and Engineering, University of Washington, Seattle, USA",
        "aff_domain": "cs.washington.edu;cs.washington.edu",
        "email": "cs.washington.edu;cs.washington.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/jain18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "First Order Generative Adversarial Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2073",
        "id": "2073",
        "author_site": "Calvin Seward, Thomas Unterthiner, Urs M Bergmann, Nikolay Jetchev, Sepp Hochreiter",
        "author": "Calvin Seward; Thomas Unterthiner; Urs Bergmann; Nikolay Jetchev; Sepp Hochreiter",
        "abstract": "GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow\u2019s original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic\u2019s first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task.",
        "bibtex": "@InProceedings{pmlr-v80-seward18a,\n  title = \t {First Order Generative Adversarial Networks},\n  author =       {Seward, Calvin and Unterthiner, Thomas and Bergmann, Urs and Jetchev, Nikolay and Hochreiter, Sepp},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4567--4576},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/seward18a/seward18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/seward18a.html},\n  abstract = \t {GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow\u2019s original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic\u2019s first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/seward18a/seward18a.pdf",
        "supp": "",
        "pdf_size": 1974740,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4229294235141796493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Zalando Research, M\u00fchlenstra\u00dfe 25, 10243 Berlin, Germany+LIT AI Lab & Institute of Bioinformatics, Johannes Kepler University Linz, Austria; LIT AI Lab & Institute of Bioinformatics, Johannes Kepler University Linz, Austria; Zalando Research, M\u00fchlenstra\u00dfe 25, 10243 Berlin, Germany; Zalando Research, M\u00fchlenstra\u00dfe 25, 10243 Berlin, Germany; LIT AI Lab & Institute of Bioinformatics, Johannes Kepler University Linz, Austria",
        "aff_domain": "zalando.de; ; ; ; ",
        "email": "zalando.de; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/seward18a.html",
        "aff_unique_index": "0+1;1;0;0;1",
        "aff_unique_norm": "Zalando Research;Johannes Kepler University Linz",
        "aff_unique_dep": ";Institute of Bioinformatics",
        "aff_unique_url": "https://research.zalando.com;https://www.jku.at",
        "aff_unique_abbr": ";JKU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Linz",
        "aff_country_unique_index": "0+1;1;0;0;1",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "title": "Fitting New Speakers Based on a Short Untranscribed Sample",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2149",
        "id": "2149",
        "author_site": "Eliya Nachmani, Adam Polyak, Yaniv Taigman, Lior Wolf",
        "author": "Eliya Nachmani; Adam Polyak; Yaniv Taigman; Lior Wolf",
        "abstract": "Learning-based Text To Speech systems have the potential to generalize from one speaker to the next and thus require a relatively short sample of any new voice. However, this promise is currently largely unrealized. We present a method that is designed to capture a new speaker from a short untranscribed audio sample. This is done by employing an additional network that given an audio sample, places the speaker in the embedding space. This network is trained as part of the speech synthesis system using various consistency losses. Our results demonstrate a greatly improved performance on both the dataset speakers, and, more importantly, when fitting new voices, even from very short samples.",
        "bibtex": "@InProceedings{pmlr-v80-nachmani18a,\n  title = \t {Fitting New Speakers Based on a Short Untranscribed Sample},\n  author =       {Nachmani, Eliya and Polyak, Adam and Taigman, Yaniv and Wolf, Lior},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3683--3691},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nachmani18a/nachmani18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nachmani18a.html},\n  abstract = \t {Learning-based Text To Speech systems have the potential to generalize from one speaker to the next and thus require a relatively short sample of any new voice. However, this promise is currently largely unrealized. We present a method that is designed to capture a new speaker from a short untranscribed audio sample. This is done by employing an additional network that given an audio sample, places the speaker in the embedding space. This network is trained as part of the speech synthesis system using various consistency losses. Our results demonstrate a greatly improved performance on both the dataset speakers, and, more importantly, when fitting new voices, even from very short samples.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nachmani18a/nachmani18a.pdf",
        "supp": "",
        "pdf_size": 858863,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13916155346200428391&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Facebook AI Research + Tel Aviv University; Facebook AI Research; Facebook AI Research; Facebook AI Research + Tel Aviv University",
        "aff_domain": "fb.com; ; ; ",
        "email": "fb.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/nachmani18a.html",
        "aff_unique_index": "0+1;0;0;0+1",
        "aff_unique_norm": "Meta;Tel Aviv University",
        "aff_unique_dep": "Facebook AI Research;",
        "aff_unique_url": "https://research.facebook.com;https://www.tau.ac.il",
        "aff_unique_abbr": "FAIR;TAU",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;0;0;0+1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Fixing a Broken ELBO",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2442",
        "id": "2442",
        "author_site": "Alexander Alemi, Ben Poole, Ian Fischer, Joshua V Dillon, Rif Saurous, Kevin Murphy",
        "author": "Alexander Alemi; Ben Poole; Ian Fischer; Joshua Dillon; Rif A. Saurous; Kevin Murphy",
        "abstract": "Recent work in unsupervised representation learning has focused on learning deep directed latentvariable models. Fitting these models by maximizing the marginal likelihood or evidence is typically intractable, thus a common approximation is to maximize the evidence lower bound (ELBO) instead. However, maximum likelihood training (whether exact or approximate) does not necessarily result in a good latent representation, as we demonstrate both theoretically and empirically. In particular, we derive variational lower and upper bounds on the mutual information between the input and the latent variable, and use these bounds to derive a rate-distortion curve that characterizes the tradeoff between compression and reconstruction accuracy. Using this framework, we demonstrate that there is a family of models with identical ELBO, but different quantitative and qualitative characteristics. Our framework also suggests a simple new method to ensure that latent variable models with powerful stochastic decoders do not ignore their latent code.",
        "bibtex": "@InProceedings{pmlr-v80-alemi18a,\n  title = \t {Fixing a Broken {ELBO}},\n  author =       {Alemi, Alexander and Poole, Ben and Fischer, Ian and Dillon, Joshua and Saurous, Rif A. and Murphy, Kevin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {159--168},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/alemi18a/alemi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/alemi18a.html},\n  abstract = \t {Recent work in unsupervised representation learning has focused on learning deep directed latentvariable models. Fitting these models by maximizing the marginal likelihood or evidence is typically intractable, thus a common approximation is to maximize the evidence lower bound (ELBO) instead. However, maximum likelihood training (whether exact or approximate) does not necessarily result in a good latent representation, as we demonstrate both theoretically and empirically. In particular, we derive variational lower and upper bounds on the mutual information between the input and the latent variable, and use these bounds to derive a rate-distortion curve that characterizes the tradeoff between compression and reconstruction accuracy. Using this framework, we demonstrate that there is a family of models with identical ELBO, but different quantitative and qualitative characteristics. Our framework also suggests a simple new method to ensure that latent variable models with powerful stochastic decoders do not ignore their latent code.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/alemi18a/alemi18a.pdf",
        "supp": "",
        "pdf_size": 1467946,
        "gs_citation": 634,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9023267707881241240&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Google AI; Stanford University; Google AI; Google AI; Google AI; Google AI",
        "aff_domain": "google.com; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/alemi18a.html",
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Google;Stanford University",
        "aff_unique_dep": "Google AI;",
        "aff_unique_url": "https://ai.google;https://www.stanford.edu",
        "aff_unique_abbr": "Google AI;Stanford",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Mountain View;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Focused Hierarchical RNNs for Conditional Sequence Processing",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2312",
        "id": "2312",
        "author_site": "Rosemary Nan Ke, Konrad Zolna, Alessandro Sordoni, Zhouhan Lin, Adam Trischler, Yoshua Bengio, Joelle Pineau, Laurent Charlin, Christopher Pal",
        "author": "Nan Rosemary Ke; Konrad \u017bo\u0142na; Alessandro Sordoni; Zhouhan Lin; Adam Trischler; Yoshua Bengio; Joelle Pineau; Laurent Charlin; Christopher Pal",
        "abstract": "Recurrent Neural Networks (RNNs) with attention mechanisms have obtained state-of-the-art results for many sequence processing tasks. Most of these models use a simple form of encoder with attention that looks over the entire sequence and assigns a weight to each token independently. We present a mechanism for focusing RNN encoders for sequence modelling tasks which allows them to attend to key parts of the input as needed. We formulate this using a multi-layer conditional hierarchical sequence encoder that reads in one token at a time and makes a discrete decision on whether the token is relevant to the context or question being asked. The discrete gating mechanism takes in the context embedding and the current hidden state as inputs and controls information flow into the layer above. We train it using policy gradient methods. We evaluate this method on several types of tasks with different attributes. First, we evaluate the method on synthetic tasks which allow us to evaluate the model for its generalization ability and probe the behavior of the gates in more controlled settings. We then evaluate this approach on large scale Question Answering tasks including the challenging MS MARCO and SearchQA tasks. Our models shows consistent improvements for both tasks over prior work and our baselines. It has also shown to generalize significantly better on synthetic tasks as compared to the baselines.",
        "bibtex": "@InProceedings{pmlr-v80-ke18a,\n  title = \t {Focused Hierarchical {RNN}s for Conditional Sequence Processing},\n  author =       {Ke, Nan Rosemary and {\\.Z}o{\\l}na, Konrad and Sordoni, Alessandro and Lin, Zhouhan and Trischler, Adam and Bengio, Yoshua and Pineau, Joelle and Charlin, Laurent and Pal, Christopher},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2554--2563},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ke18a/ke18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ke18a.html},\n  abstract = \t {Recurrent Neural Networks (RNNs) with attention mechanisms have obtained state-of-the-art results for many sequence processing tasks. Most of these models use a simple form of encoder with attention that looks over the entire sequence and assigns a weight to each token independently. We present a mechanism for focusing RNN encoders for sequence modelling tasks which allows them to attend to key parts of the input as needed. We formulate this using a multi-layer conditional hierarchical sequence encoder that reads in one token at a time and makes a discrete decision on whether the token is relevant to the context or question being asked. The discrete gating mechanism takes in the context embedding and the current hidden state as inputs and controls information flow into the layer above. We train it using policy gradient methods. We evaluate this method on several types of tasks with different attributes. First, we evaluate the method on synthetic tasks which allow us to evaluate the model for its generalization ability and probe the behavior of the gates in more controlled settings. We then evaluate this approach on large scale Question Answering tasks including the challenging MS MARCO and SearchQA tasks. Our models shows consistent improvements for both tasks over prior work and our baselines. It has also shown to generalize significantly better on synthetic tasks as compared to the baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ke18a/ke18a.pdf",
        "supp": "",
        "pdf_size": 803867,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16306476485097119650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;;;;",
        "aff_domain": ";;;;;;;;",
        "email": ";;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/ke18a.html"
    },
    {
        "title": "Fourier Policy Gradients",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2414",
        "id": "2414",
        "author_site": "Matthew Fellows, Kamil Ciosek, Shimon Whiteson",
        "author": "Matthew Fellows; Kamil Ciosek; Shimon Whiteson",
        "abstract": "We propose a new way of deriving policy gradient updates for reinforcement learning. Our technique, based on Fourier analysis, recasts integrals that arise with expected policy gradients as convolutions and turns them into multiplications. The obtained analytical solutions allow us to capture the low variance benefits of EPG in a broad range of settings. For the critic, we treat trigonometric and radial basis functions, two function families with the universal approximation property. The choice of policy can be almost arbitrary, including mixtures or hybrid continuous-discrete probability distributions. Moreover, we derive a general family of sample-based estimators for stochastic policy gradients, which unifies existing results on sample-based approximation. We believe that this technique has the potential to shape the next generation of policy gradient approaches, powered by analytical results.",
        "bibtex": "@InProceedings{pmlr-v80-fellows18a,\n  title = \t {{F}ourier Policy Gradients},\n  author =       {Fellows, Matthew and Ciosek, Kamil and Whiteson, Shimon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1486--1495},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fellows18a/fellows18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fellows18a.html},\n  abstract = \t {We propose a new way of deriving policy gradient updates for reinforcement learning. Our technique, based on Fourier analysis, recasts integrals that arise with expected policy gradients as convolutions and turns them into multiplications. The obtained analytical solutions allow us to capture the low variance benefits of EPG in a broad range of settings. For the critic, we treat trigonometric and radial basis functions, two function families with the universal approximation property. The choice of policy can be almost arbitrary, including mixtures or hybrid continuous-discrete probability distributions. Moreover, we derive a general family of sample-based estimators for stochastic policy gradients, which unifies existing results on sample-based approximation. We believe that this technique has the potential to shape the next generation of policy gradient approaches, powered by analytical results.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fellows18a/fellows18a.pdf",
        "supp": "",
        "pdf_size": 695753,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9547477991847185694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, University of Oxford; Department of Computer Science, University of Oxford; Department of Computer Science, University of Oxford",
        "aff_domain": "cs.ox.ac.uk; ; ",
        "email": "cs.ox.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/fellows18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Frank-Wolfe with Subsampling Oracle",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2057",
        "id": "2057",
        "author_site": "Thomas Kerdreux, Fabian Pedregosa, Alexandre d'Aspremont",
        "author": "Thomas Kerdreux; Fabian Pedregosa; Alexandre d\u2019Aspremont",
        "abstract": "We analyze two novel randomized variants of the Frank-Wolfe (FW) or conditional gradient algorithm. While classical FW algorithms require solving a linear minimization problem over the domain at each iteration, the proposed method only requires to solve a linear minimization problem over a small",
        "bibtex": "@InProceedings{pmlr-v80-kerdreux18a,\n  title = \t {Frank-{W}olfe with Subsampling Oracle},\n  author =       {Kerdreux, Thomas and Pedregosa, Fabian and d'Aspremont, Alexandre},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2591--2600},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kerdreux18a/kerdreux18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kerdreux18a.html},\n  abstract = \t {We analyze two novel randomized variants of the Frank-Wolfe (FW) or conditional gradient algorithm. While classical FW algorithms require solving a linear minimization problem over the domain at each iteration, the proposed method only requires to solve a linear minimization problem over a small",
        "pdf": "http://proceedings.mlr.press/v80/kerdreux18a/kerdreux18a.pdf",
        "supp": "",
        "pdf_size": 790863,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1632698363139933589&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "D.I., UMR 8548, \u00c9cole Normale Sup\u00e9rieure, Paris, France; UC Berkeley, USA + ETH Zurich, Switzerland; CNRS, France",
        "aff_domain": "inria.fr;bianp.net; ",
        "email": "inria.fr;bianp.net; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kerdreux18a.html",
        "aff_unique_index": "0;1+2;3",
        "aff_unique_norm": "\u00c9cole Normale Sup\u00e9rieure;University of California, Berkeley;ETH Zurich;CNRS",
        "aff_unique_dep": "UMR 8548;;;",
        "aff_unique_url": "https://www.ens.fr;https://www.berkeley.edu;https://www.ethz.ch;https://www.cnrs.fr",
        "aff_unique_abbr": "ENS;UC Berkeley;ETHZ;CNRS",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Paris;Berkeley;",
        "aff_country_unique_index": "0;1+2;0",
        "aff_country_unique": "France;United States;Switzerland"
    },
    {
        "title": "Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2269",
        "id": "2269",
        "author_site": "Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, Tamer Basar",
        "author": "Kaiqing Zhang; Zhuoran Yang; Han Liu; Tong Zhang; Tamer Basar",
        "abstract": "We consider the fully decentralized multi-agent reinforcement learning (MARL) problem, where the agents are connected via a time-varying and possibly sparse communication network. Specifically, we assume that the reward functions of the agents might correspond to different tasks, and are only known to the corresponding agent. Moreover, each agent makes individual decisions based on both the information observed locally and the messages received from its neighbors over the network. To maximize the globally averaged return over the network, we propose two fully decentralized actor-critic algorithms, which are applicable to large-scale MARL problems in an online fashion. Convergence guarantees are provided when the value functions are approximated within the class of linear functions. Our work appears to be the first theoretical study of fully decentralized MARL algorithms for networked agents that use function approximation.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18n,\n  title = \t {Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents},\n  author =       {Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5872--5881},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18n/zhang18n.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18n.html},\n  abstract = \t {We consider the fully decentralized multi-agent reinforcement learning (MARL) problem, where the agents are connected via a time-varying and possibly sparse communication network. Specifically, we assume that the reward functions of the agents might correspond to different tasks, and are only known to the corresponding agent. Moreover, each agent makes individual decisions based on both the information observed locally and the messages received from its neighbors over the network. To maximize the globally averaged return over the network, we propose two fully decentralized actor-critic algorithms, which are applicable to large-scale MARL problems in an online fashion. Convergence guarantees are provided when the value functions are approximated within the class of linear functions. Our work appears to be the first theoretical study of fully decentralized MARL algorithms for networked agents that use function approximation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18n/zhang18n.pdf",
        "supp": "",
        "pdf_size": 570146,
        "gs_citation": 786,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3690955484955332697&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Electrical and Computer Engineering & Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, USA+Tencent AI Lab, China; Department of Operations Research and Financial Engineering, Princeton University, USA; Department of Electrical Engineering and Computer Science and Statistics, Northwestern University, USA; Tencent AI Lab, China; Department of Electrical and Computer Engineering & Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, USA",
        "aff_domain": "illinois.edu; ; ; ; ",
        "email": "illinois.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/zhang18n.html",
        "aff_unique_index": "0+1;2;3;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Tencent;Princeton University;Northwestern University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Tencent AI Lab;Department of Operations Research and Financial Engineering;Department of Electrical Engineering and Computer Science and Statistics",
        "aff_unique_url": "https://illinois.edu;https://ai.tencent.com;https://www.princeton.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "UIUC;Tencent AI Lab;Princeton;NU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0+1;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Functional Gradient Boosting based on Residual Network Perception",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2184",
        "id": "2184",
        "author_site": "Atsushi Nitanda, Taiji Suzuki",
        "author": "Atsushi Nitanda; Taiji Suzuki",
        "abstract": "Residual Networks (ResNets) have become state-of-the-art models in deep learning and several theoretical studies have been devoted to understanding why ResNet works so well. One attractive viewpoint on ResNet is that it is optimizing the risk in a functional space by consisting of an ensemble of effective features. In this paper, we adopt this viewpoint to construct a new gradient boosting method, which is known to be very powerful in data analysis. To do so, we formalize the boosting perspective of ResNet mathematically using the notion of functional gradients and propose a new method called ResFGB for classification tasks by leveraging ResNet perception. Two types of generalization guarantees are provided from the optimization perspective: one is the margin bound and the other is the expected risk bound by the sample-splitting technique. Experimental results show superior performance of the proposed method over state-of-the-art methods such as LightGBM.",
        "bibtex": "@InProceedings{pmlr-v80-nitanda18a,\n  title = \t {Functional Gradient Boosting based on Residual Network Perception},\n  author =       {Nitanda, Atsushi and Suzuki, Taiji},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3819--3828},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nitanda18a/nitanda18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nitanda18a.html},\n  abstract = \t {Residual Networks (ResNets) have become state-of-the-art models in deep learning and several theoretical studies have been devoted to understanding why ResNet works so well. One attractive viewpoint on ResNet is that it is optimizing the risk in a functional space by consisting of an ensemble of effective features. In this paper, we adopt this viewpoint to construct a new gradient boosting method, which is known to be very powerful in data analysis. To do so, we formalize the boosting perspective of ResNet mathematically using the notion of functional gradients and propose a new method called ResFGB for classification tasks by leveraging ResNet perception. Two types of generalization guarantees are provided from the optimization perspective: one is the margin bound and the other is the expected risk bound by the sample-splitting technique. Experimental results show superior performance of the proposed method over state-of-the-art methods such as LightGBM.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nitanda18a/nitanda18a.pdf",
        "supp": "",
        "pdf_size": 304907,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3070437700785003463&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo+Center for Advanced Intelligence Project, RIKEN; Graduate School of Information Science and Technology, The University of Tokyo+Center for Advanced Intelligence Project, RIKEN",
        "aff_domain": "mist.i.u-tokyo.ac.jp;mist.i.u-tokyo.ac.jp",
        "email": "mist.i.u-tokyo.ac.jp;mist.i.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/nitanda18a.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": "Graduate School of Information Science and Technology;Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "GAIN: Missing Data Imputation using Generative Adversarial Nets",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2025",
        "id": "2025",
        "author_site": "Jinsung Yoon, James Jordon, Mihaela van der Schaar",
        "author": "Jinsung Yoon; James Jordon; Mihaela Schaar",
        "abstract": "We propose a novel method for imputing missing data by adapting the well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call our method Generative Adversarial Imputation Nets (GAIN). The generator (G) observes some components of a real data vector, imputes the missing components conditioned on what is actually observed, and outputs a completed vector. The discriminator (D) then takes a completed vector and attempts to determine which components were actually observed and which were imputed. To ensure that D forces G to learn the desired distribution, we provide D with some additional information in the form of a hint vector. The hint reveals to D partial information about the missingness of the original sample, which is used by D to focus its attention on the imputation quality of particular components. This hint ensures that G does in fact learn to generate according to the true data distribution. We tested our method on various datasets and found that GAIN significantly outperforms state-of-the-art imputation methods.",
        "bibtex": "@InProceedings{pmlr-v80-yoon18a,\n  title = \t {{GAIN}: Missing Data Imputation using Generative Adversarial Nets},\n  author =       {Yoon, Jinsung and Jordon, James and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5689--5698},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yoon18a/yoon18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yoon18a.html},\n  abstract = \t {We propose a novel method for imputing missing data by adapting the well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call our method Generative Adversarial Imputation Nets (GAIN). The generator (G) observes some components of a real data vector, imputes the missing components conditioned on what is actually observed, and outputs a completed vector. The discriminator (D) then takes a completed vector and attempts to determine which components were actually observed and which were imputed. To ensure that D forces G to learn the desired distribution, we provide D with some additional information in the form of a hint vector. The hint reveals to D partial information about the missingness of the original sample, which is used by D to focus its attention on the imputation quality of particular components. This hint ensures that G does in fact learn to generate according to the true data distribution. We tested our method on various datasets and found that GAIN significantly outperforms state-of-the-art imputation methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yoon18a/yoon18a.pdf",
        "supp": "",
        "pdf_size": 654494,
        "gs_citation": 1573,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6024113526841994005&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of California, Los Angeles, CA, USA+Alan Turing Institute, UK; University of Oxford, UK+Alan Turing Institute, UK; University of California, Los Angeles, CA, USA+University of Oxford, UK+Alan Turing Institute, UK",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/yoon18a.html",
        "aff_unique_index": "0+1;2+1;0+2+1",
        "aff_unique_norm": "University of California, Los Angeles;Alan Turing Institute;University of Oxford",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucla.edu;https://www.turing.ac.uk;https://www.ox.ac.uk",
        "aff_unique_abbr": "UCLA;ATI;Oxford",
        "aff_campus_unique_index": "0;;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0+1;1+1;0+1+1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2151",
        "id": "2151",
        "author_site": "C\u00e9dric Colas, Olivier Sigaud, Pierre-Yves Oudeyer",
        "author": "C\u00e9dric Colas; Olivier Sigaud; Pierre-Yves Oudeyer",
        "abstract": "In continuous action domains, standard deep reinforcement learning algorithms like DDPG suffer from inefficient exploration when facing sparse or deceptive reward problems. Conversely, evolutionary and developmental methods focusing on exploration like Novelty Search, Quality-Diversity or Goal Exploration Processes explore more robustly but are less efficient at fine-tuning policies using gradient-descent. In this paper, we present the GEP-PG approach, taking the best of both worlds by sequentially combining a Goal Exploration Process and two variants of DDPG . We study the learning performance of these components and their combination on a low dimensional deceptive reward problem and on the larger Half-Cheetah benchmark. We show that DDPG fails on the former and that GEP-PG improves over the best DDPG variant in both environments.",
        "bibtex": "@InProceedings{pmlr-v80-colas18a,\n  title = \t {{GEP}-{PG}: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms},\n  author =       {Colas, C{\\'e}dric and Sigaud, Olivier and Oudeyer, Pierre-Yves},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1039--1048},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/colas18a/colas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/colas18a.html},\n  abstract = \t {In continuous action domains, standard deep reinforcement learning algorithms like DDPG suffer from inefficient exploration when facing sparse or deceptive reward problems. Conversely, evolutionary and developmental methods focusing on exploration like Novelty Search, Quality-Diversity or Goal Exploration Processes explore more robustly but are less efficient at fine-tuning policies using gradient-descent. In this paper, we present the GEP-PG approach, taking the best of both worlds by sequentially combining a Goal Exploration Process and two variants of DDPG . We study the learning performance of these components and their combination on a low dimensional deceptive reward problem and on the larger Half-Cheetah benchmark. We show that DDPG fails on the former and that GEP-PG improves over the best DDPG variant in both environments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/colas18a/colas18a.pdf",
        "supp": "",
        "pdf_size": 3174817,
        "gs_citation": 194,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13798285446369315971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "INRIA, Flowers Team, Bordeaux, France+ Sorbonne University, ISIR, Paris, France; INRIA, Flowers Team, Bordeaux, France+ Sorbonne University, ISIR, Paris, France; INRIA, Flowers Team, Bordeaux, France",
        "aff_domain": "inria.fr; ; ",
        "email": "inria.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/colas18a.html",
        "aff_unique_index": "0+1;0+1;0",
        "aff_unique_norm": "INRIA;Sorbonne University",
        "aff_unique_dep": "Flowers Team;Institut des Sciences de l'Ing\u00e9nierie de la Robotique (ISIR)",
        "aff_unique_url": "https://www.inria.fr;https://www.sorbonne-university.fr",
        "aff_unique_abbr": "INRIA;Sorbonne",
        "aff_campus_unique_index": "0+1;0+1;0",
        "aff_campus_unique": "Bordeaux;Paris",
        "aff_country_unique_index": "0+0;0+0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Gated Path Planning Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2488",
        "id": "2488",
        "author_site": "Lisa Lee, Emilio Parisotto, Devendra Singh Chaplot, Eric Xing, Ruslan Salakhutdinov",
        "author": "Lisa Lee; Emilio Parisotto; Devendra Singh Chaplot; Eric Xing; Ruslan Salakhutdinov",
        "abstract": "Value Iteration Networks (VINs) are effective differentiable path planning modules that can be used by agents to perform navigation while still maintaining end-to-end differentiability of the entire architecture. Despite their effectiveness, they suffer from several disadvantages including training instability, random seed sensitivity, and other optimization problems. In this work, we reframe VINs as recurrent-convolutional networks which demonstrates that VINs couple recurrent convolutions with an unconventional max-pooling activation. From this perspective, we argue that standard gated recurrent update equations could potentially alleviate the optimization issues plaguing VIN. The resulting architecture, which we call the Gated Path Planning Network, is shown to empirically outperform VIN on a variety of metrics such as learning speed, hyperparameter sensitivity, iteration count, and even generalization. Furthermore, we show that this performance gap is consistent across different maze transition types, maze sizes and even show success on a challenging 3D environment, where the planner is only provided with first-person RGB images.",
        "bibtex": "@InProceedings{pmlr-v80-lee18c,\n  title = \t {Gated Path Planning Networks},\n  author =       {Lee, Lisa and Parisotto, Emilio and Chaplot, Devendra Singh and Xing, Eric and Salakhutdinov, Ruslan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2947--2955},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lee18c/lee18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lee18c.html},\n  abstract = \t {Value Iteration Networks (VINs) are effective differentiable path planning modules that can be used by agents to perform navigation while still maintaining end-to-end differentiability of the entire architecture. Despite their effectiveness, they suffer from several disadvantages including training instability, random seed sensitivity, and other optimization problems. In this work, we reframe VINs as recurrent-convolutional networks which demonstrates that VINs couple recurrent convolutions with an unconventional max-pooling activation. From this perspective, we argue that standard gated recurrent update equations could potentially alleviate the optimization issues plaguing VIN. The resulting architecture, which we call the Gated Path Planning Network, is shown to empirically outperform VIN on a variety of metrics such as learning speed, hyperparameter sensitivity, iteration count, and even generalization. Furthermore, we show that this performance gap is consistent across different maze transition types, maze sizes and even show success on a challenging 3D environment, where the planner is only provided with first-person RGB images.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lee18c/lee18c.pdf",
        "supp": "",
        "pdf_size": 1108541,
        "gs_citation": 105,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13413362645977057245&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Carnegie Mellon University, Machine Learning Department; Carnegie Mellon University, Machine Learning Department; Carnegie Mellon University, Machine Learning Department; Carnegie Mellon University, Machine Learning Department; Carnegie Mellon University, Machine Learning Department",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu; ; ; ",
        "email": "cs.cmu.edu;cs.cmu.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/lee18c.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1938",
        "id": "1938",
        "author_site": "Brenden Lake, Marco Baroni",
        "author": "Brenden Lake; Marco Baroni",
        "abstract": "Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb \"dax,\" he or she can immediately understand the meaning of \"dax twice\" or \"sing and dax.\" In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can make successful zero-shot generalizations when the differences between training and test commands are small, so that they can apply \"mix-and-match\" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the \"dax\" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, suggesting that lack of systematicity might be partially responsible for neural networks\u2019 notorious training data thirst.",
        "bibtex": "@InProceedings{pmlr-v80-lake18a,\n  title = \t {Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks},\n  author =       {Lake, Brenden and Baroni, Marco},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2873--2882},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lake18a/lake18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lake18a.html},\n  abstract = \t {Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb \"dax,\" he or she can immediately understand the meaning of \"dax twice\" or \"sing and dax.\" In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can make successful zero-shot generalizations when the differences between training and test commands are small, so that they can apply \"mix-and-match\" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the \"dax\" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, suggesting that lack of systematicity might be partially responsible for neural networks\u2019 notorious training data thirst.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lake18a/lake18a.pdf",
        "supp": "",
        "pdf_size": 1057858,
        "gs_citation": 930,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11276348225798571948&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Dept. of Psychology and Center for Data Science, New York University+Facebook Artificial Intelligence Research; Facebook Artificial Intelligence Research",
        "aff_domain": "nyu.edu;fb.com",
        "email": "nyu.edu;fb.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/lake18a.html",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "New York University;Meta",
        "aff_unique_dep": "Dept. of Psychology;Artificial Intelligence Research",
        "aff_unique_url": "https://www.nyu.edu;https://research.facebook.com",
        "aff_unique_abbr": "NYU;FAIR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New York;",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1920",
        "id": "1920",
        "author_site": "Siyuan Qi, Baoxiong Jia, Song-Chun Zhu",
        "author": "Siyuan Qi; Baoxiong Jia; Song-Chun Zhu",
        "abstract": "Future predictions on sequence data (e.g., videos or audios) require the algorithms to capture non-Markovian and compositional properties of high-level semantics. Context-free grammars are natural choices to capture such properties, but traditional grammar parsers (e.g., Earley parser) only take symbolic sentences as inputs. In this paper, we generalize the Earley parser to parse sequence data which is neither segmented nor labeled. This generalized Earley parser integrates a grammar parser with a classifier to find the optimal segmentation and labels, and makes top-down future predictions. Experiments show that our method significantly outperforms other approaches for future human activity prediction.",
        "bibtex": "@InProceedings{pmlr-v80-qi18a,\n  title = \t {Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction},\n  author =       {Qi, Siyuan and Jia, Baoxiong and Zhu, Song-Chun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4171--4179},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/qi18a/qi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/qi18a.html},\n  abstract = \t {Future predictions on sequence data (e.g., videos or audios) require the algorithms to capture non-Markovian and compositional properties of high-level semantics. Context-free grammars are natural choices to capture such properties, but traditional grammar parsers (e.g., Earley parser) only take symbolic sentences as inputs. In this paper, we generalize the Earley parser to parse sequence data which is neither segmented nor labeled. This generalized Earley parser integrates a grammar parser with a classifier to find the optimal segmentation and labels, and makes top-down future predictions. Experiments show that our method significantly outperforms other approaches for future human activity prediction.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/qi18a/qi18a.pdf",
        "supp": "",
        "pdf_size": 3390728,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4541282162255418053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Los Angeles, USA; University of California, Los Angeles, USA + Peking University, Beijing, China; University of California, Los Angeles, USA",
        "aff_domain": "cs.ucla.edu; ; ",
        "email": "cs.ucla.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/qi18a.html",
        "aff_unique_index": "0;0+1;0",
        "aff_unique_norm": "University of California, Los Angeles;Peking University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucla.edu;http://www.pku.edu.cn",
        "aff_unique_abbr": "UCLA;Peking U",
        "aff_campus_unique_index": "0;0+1;0",
        "aff_campus_unique": "Los Angeles;Beijing",
        "aff_country_unique_index": "0;0+1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1958",
        "id": "1958",
        "author_site": "Haitao Liu, Jianfei Cai, Yi Wang, Yew Soon ONG",
        "author": "Haitao Liu; Jianfei Cai; Yi Wang; Yew Soon Ong",
        "abstract": "In order to scale standard Gaussian process (GP) regression to large-scale datasets, aggregation models employ factorized training process and then combine predictions from distributed experts. The state-of-the-art aggregation models, however, either provide inconsistent predictions or require time-consuming aggregation process. We first prove the inconsistency of typical aggregations using disjoint or random data partition, and then present a consistent yet efficient aggregation model for large-scale GP. The proposed model inherits the advantages of aggregations, e.g., closed-form inference and aggregation, parallelization and distributed computing. Furthermore, theoretical and empirical analyses reveal that the new aggregation model performs better due to the consistent predictions that converge to the true underlying function when the training size approaches infinity.",
        "bibtex": "@InProceedings{pmlr-v80-liu18a,\n  title = \t {Generalized Robust {B}ayesian Committee Machine for Large-scale {G}aussian Process Regression},\n  author =       {Liu, Haitao and Cai, Jianfei and Wang, Yi and Ong, Yew Soon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3131--3140},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18a/liu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18a.html},\n  abstract = \t {In order to scale standard Gaussian process (GP) regression to large-scale datasets, aggregation models employ factorized training process and then combine predictions from distributed experts. The state-of-the-art aggregation models, however, either provide inconsistent predictions or require time-consuming aggregation process. We first prove the inconsistency of typical aggregations using disjoint or random data partition, and then present a consistent yet efficient aggregation model for large-scale GP. The proposed model inherits the advantages of aggregations, e.g., closed-form inference and aggregation, parallelization and distributed computing. Furthermore, theoretical and empirical analyses reveal that the new aggregation model performs better due to the consistent predictions that converge to the true underlying function when the training size approaches infinity.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18a/liu18a.pdf",
        "supp": "",
        "pdf_size": 1464074,
        "gs_citation": 120,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8338496144713791124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Rolls-Royce@NTU Corporate Lab, Nanyang Technological University, Singapore 637460; School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798; Applied Technology Group, Rolls-Royce Singapore, 6 Seletar Aerospace Rise, Singapore 797575; Data Science and Artificial Intelligence Research Center, Nanyang Technological University, Singapore 639798",
        "aff_domain": "ntu.edu.sg; ; ; ",
        "email": "ntu.edu.sg; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/liu18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Rolls-Royce Singapore",
        "aff_unique_dep": "Rolls-Royce@NTU Corporate Lab;Applied Technology Group",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.rolls-royce.com",
        "aff_unique_abbr": "NTU;RRS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "title": "Generative Temporal Models with Spatial Memory for Partially Observed Environments",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2128",
        "id": "2128",
        "author_site": "Marco Fraccaro, Danilo J. Rezende, Yori Zwols, Alexander Pritzel, S. M. Ali Eslami, Fabio Viola",
        "author": "Marco Fraccaro; Danilo Rezende; Yori Zwols; Alexander Pritzel; S. M. Ali Eslami; Fabio Viola",
        "abstract": "In model-based reinforcement learning, generative and temporal models of environments can be leveraged to boost agent performance, either by tuning the agent\u2019s representations during training or via use as part of an explicit planning mechanism. However, their application in practice has been limited to simplistic environments, due to the difficulty of training such models in larger, potentially partially-observed and 3D environments. In this work we introduce a novel action-conditioned generative model of such challenging environments. The model features a non-parametric spatial memory system in which we store learned, disentangled representations of the environment. Low-dimensional spatial updates are computed using a state-space model that makes use of knowledge on the prior dynamics of the moving agent, and high-dimensional visual observations are modelled with a Variational Auto-Encoder. The result is a scalable architecture capable of performing coherent predictions over hundreds of time steps across a range of partially observed 2D and 3D environments.",
        "bibtex": "@InProceedings{pmlr-v80-fraccaro18a,\n  title = \t {Generative Temporal Models with Spatial Memory for Partially Observed Environments},\n  author =       {Fraccaro, Marco and Rezende, Danilo and Zwols, Yori and Pritzel, Alexander and Eslami, S. M. Ali and Viola, Fabio},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1549--1558},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fraccaro18a/fraccaro18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fraccaro18a.html},\n  abstract = \t {In model-based reinforcement learning, generative and temporal models of environments can be leveraged to boost agent performance, either by tuning the agent\u2019s representations during training or via use as part of an explicit planning mechanism. However, their application in practice has been limited to simplistic environments, due to the difficulty of training such models in larger, potentially partially-observed and 3D environments. In this work we introduce a novel action-conditioned generative model of such challenging environments. The model features a non-parametric spatial memory system in which we store learned, disentangled representations of the environment. Low-dimensional spatial updates are computed using a state-space model that makes use of knowledge on the prior dynamics of the moving agent, and high-dimensional visual observations are modelled with a Variational Auto-Encoder. The result is a scalable architecture capable of performing coherent predictions over hundreds of time steps across a range of partially observed 2D and 3D environments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fraccaro18a/fraccaro18a.pdf",
        "supp": "",
        "pdf_size": 4847897,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15477881930463999364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Technical University of Denmark; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "gmail.com; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/fraccaro18a.html",
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Technical University of Denmark;DeepMind",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tek.dk;https://deepmind.com",
        "aff_unique_abbr": "DTU;DeepMind",
        "aff_campus_unique_index": "1;1;1;1;1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "Denmark;United Kingdom"
    },
    {
        "title": "Geodesic Convolutional Shape Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1944",
        "id": "1944",
        "author_site": "Pierre Baque, Edoardo Remelli, Francois Fleuret, EPFL Pascal Fua",
        "author": "Pierre Baque; Edoardo Remelli; Francois Fleuret; Pascal Fua",
        "abstract": "Aerodynamic shape optimization has many industrial applications. Existing methods, however, are so computationally demanding that typical engineering practices are to either simply try a limited number of hand-designed shapes or restrict oneself to shapes that can be parameterized using only few degrees of freedom. In this work, we introduce a new way to optimize complex shapes fast and accurately. To this end, we train Geodesic Convolutional Neural Networks to emulate a fluidynamics simulator. The key to making this approach practical is remeshing the original shape using a poly-cube map, which makes it possible to perform the computations on GPUs instead of CPUs. The neural net is then used to formulate an objective function that is differentiable with respect to the shape parameters, which can then be optimized using a gradient-based technique. This outperforms state-of-the-art methods by 5 to 20% for standard problems and, even more importantly, our approach applies to cases that previous methods cannot handle.",
        "bibtex": "@InProceedings{pmlr-v80-baque18a,\n  title = \t {Geodesic Convolutional Shape Optimization},\n  author =       {Baque, Pierre and Remelli, Edoardo and Fleuret, Francois and Fua, Pascal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {472--481},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/baque18a/baque18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/baque18a.html},\n  abstract = \t {Aerodynamic shape optimization has many industrial applications. Existing methods, however, are so computationally demanding that typical engineering practices are to either simply try a limited number of hand-designed shapes or restrict oneself to shapes that can be parameterized using only few degrees of freedom. In this work, we introduce a new way to optimize complex shapes fast and accurately. To this end, we train Geodesic Convolutional Neural Networks to emulate a fluidynamics simulator. The key to making this approach practical is remeshing the original shape using a poly-cube map, which makes it possible to perform the computations on GPUs instead of CPUs. The neural net is then used to formulate an objective function that is differentiable with respect to the shape parameters, which can then be optimized using a gradient-based technique. This outperforms state-of-the-art methods by 5 to 20% for standard problems and, even more importantly, our approach applies to cases that previous methods cannot handle.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/baque18a/baque18a.pdf",
        "supp": "",
        "pdf_size": 4051494,
        "gs_citation": 99,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8938881766919584384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "CVLab, EPFL, Lausanne, Switzerland; CVLab, EPFL, Lausanne, Switzerland; Machine Learning Group, Idiap, Martigny, Switzerland; CVLab, EPFL, Lausanne, Switzerland",
        "aff_domain": "epfl.ch; ; ; ",
        "email": "epfl.ch; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/baque18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "EPFL;Idiap Research Institute",
        "aff_unique_dep": "CVLab;Machine Learning Group",
        "aff_unique_url": "https://www.epfl.ch;https://www.idiap.ch",
        "aff_unique_abbr": "EPFL;Idiap",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Lausanne;Martigny",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Geometry Score: A Method For Comparing Generative Adversarial Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2153",
        "id": "2153",
        "author_site": "Valentin Khrulkov, Ivan Oseledets",
        "author": "Valentin Khrulkov; Ivan Oseledets",
        "abstract": "One of the biggest challenges in the research of generative adversarial networks (GANs) is assessing the quality of generated samples and detecting various levels of mode collapse. In this work, we construct a novel measure of performance of a GAN by comparing geometrical properties of the underlying data manifold and the generated one, which provides both qualitative and quantitative means for evaluation. Our algorithm can be applied to datasets of an arbitrary nature and is not limited to visual data. We test the obtained metric on various real-life models and datasets and demonstrate that our method provides new insights into properties of GANs.",
        "bibtex": "@InProceedings{pmlr-v80-khrulkov18a,\n  title = \t {Geometry Score: A Method For Comparing Generative Adversarial Networks},\n  author =       {Khrulkov, Valentin and Oseledets, Ivan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2621--2629},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/khrulkov18a/khrulkov18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/khrulkov18a.html},\n  abstract = \t {One of the biggest challenges in the research of generative adversarial networks (GANs) is assessing the quality of generated samples and detecting various levels of mode collapse. In this work, we construct a novel measure of performance of a GAN by comparing geometrical properties of the underlying data manifold and the generated one, which provides both qualitative and quantitative means for evaluation. Our algorithm can be applied to datasets of an arbitrary nature and is not limited to visual data. We test the obtained metric on various real-life models and datasets and demonstrate that our method provides new insights into properties of GANs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/khrulkov18a/khrulkov18a.pdf",
        "supp": "",
        "pdf_size": 2125781,
        "gs_citation": 151,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3414107301309460899&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Skolkovo Institute of Science and Technology+Institute of Numerical Mathematics RAS; Skolkovo Institute of Science and Technology+Institute of Numerical Mathematics RAS",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/khrulkov18a.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;Institute of Numerical Mathematics",
        "aff_unique_dep": ";RAS (Russian Academy of Sciences)",
        "aff_unique_url": "https://www.skoltech.ru;http://www.inm.ras.ru",
        "aff_unique_abbr": "Skoltech;INM RAS",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "title": "Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2091",
        "id": "2091",
        "author_site": "Maryam Fazel, Rong Ge, Sham Kakade, Mehran Mesbahi",
        "author": "Maryam Fazel; Rong Ge; Sham Kakade; Mehran Mesbahi",
        "abstract": "Direct policy gradient methods for reinforcement learning and continuous control problems are a popular approach for a variety of reasons: 1) they are easy to implement without explicit knowledge of the underlying model, 2) they are an \u201cend-to-end\u201d approach, directly optimizing the performance metric of interest, 3) they inherently allow for richly parameterized policies. A notable drawback is that even in the most basic continuous control problem (that of linear quadratic regulators), these methods must solve a non-convex optimization problem, where little is understood about their efficiency from both computational and statistical perspectives. In contrast, system identification and model based planning in optimal control theory have a much more solid theoretical footing, where much is known with regards to their computational and statistical properties. This work bridges this gap showing that (model free) policy gradient methods globally converge to the optimal solution and are efficient (polynomially so in relevant problem dependent quantities) with regards to their sample and computational complexities.",
        "bibtex": "@InProceedings{pmlr-v80-fazel18a,\n  title = \t {Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator},\n  author =       {Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1467--1476},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/fazel18a/fazel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/fazel18a.html},\n  abstract = \t {Direct policy gradient methods for reinforcement learning and continuous control problems are a popular approach for a variety of reasons: 1) they are easy to implement without explicit knowledge of the underlying model, 2) they are an \u201cend-to-end\u201d approach, directly optimizing the performance metric of interest, 3) they inherently allow for richly parameterized policies. A notable drawback is that even in the most basic continuous control problem (that of linear quadratic regulators), these methods must solve a non-convex optimization problem, where little is understood about their efficiency from both computational and statistical perspectives. In contrast, system identification and model based planning in optimal control theory have a much more solid theoretical footing, where much is known with regards to their computational and statistical properties. This work bridges this gap showing that (model free) policy gradient methods globally converge to the optimal solution and are efficient (polynomially so in relevant problem dependent quantities) with regards to their sample and computational complexities.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/fazel18a/fazel18a.pdf",
        "supp": "",
        "pdf_size": 428743,
        "gs_citation": 765,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3945861776854318811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "University of Washington, Seattle, WA, USA+Duke University, Durham, NC, USA; Duke University, Durham, NC, USA; University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA",
        "aff_domain": "cs.duke.edu; ; ; ",
        "email": "cs.duke.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/fazel18a.html",
        "aff_unique_index": "0+1;1;0;0",
        "aff_unique_norm": "University of Washington;Duke University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.washington.edu;https://www.duke.edu",
        "aff_unique_abbr": "UW;Duke",
        "aff_campus_unique_index": "0+1;1;0;0",
        "aff_campus_unique": "Seattle;Durham",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Goodness-of-Fit Testing for Discrete Distributions via Stein Discrepancy",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1894",
        "id": "1894",
        "author_site": "Jiasen Yang, Qiang Liu, Vinayak A Rao, Jennifer Neville",
        "author": "Jiasen Yang; Qiang Liu; Vinayak Rao; Jennifer Neville",
        "abstract": "Recent work has combined Stein\u2019s method with reproducing kernel Hilbert space theory to develop nonparametric goodness-of-fit tests for un-normalized probability distributions. However, the currently available tests apply exclusively to distributions with smooth density functions. In this work, we introduce a kernelized Stein discrepancy measure for discrete spaces, and develop a nonparametric goodness-of-fit test for discrete distributions with intractable normalization constants. Furthermore, we propose a general characterization of Stein operators that encompasses both discrete and continuous distributions, providing a recipe for constructing new Stein operators. We apply the proposed goodness-of-fit test to three statistical models involving discrete distributions, and our experiments show that the proposed test typically outperforms a two-sample test based on the maximum mean discrepancy.",
        "bibtex": "@InProceedings{pmlr-v80-yang18c,\n  title = \t {Goodness-of-Fit Testing for Discrete Distributions via Stein Discrepancy},\n  author =       {Yang, Jiasen and Liu, Qiang and Rao, Vinayak and Neville, Jennifer},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5561--5570},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yang18c/yang18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yang18c.html},\n  abstract = \t {Recent work has combined Stein\u2019s method with reproducing kernel Hilbert space theory to develop nonparametric goodness-of-fit tests for un-normalized probability distributions. However, the currently available tests apply exclusively to distributions with smooth density functions. In this work, we introduce a kernelized Stein discrepancy measure for discrete spaces, and develop a nonparametric goodness-of-fit test for discrete distributions with intractable normalization constants. Furthermore, we propose a general characterization of Stein operators that encompasses both discrete and continuous distributions, providing a recipe for constructing new Stein operators. We apply the proposed goodness-of-fit test to three statistical models involving discrete distributions, and our experiments show that the proposed test typically outperforms a two-sample test based on the maximum mean discrepancy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yang18c/yang18c.pdf",
        "supp": "",
        "pdf_size": 4407308,
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3574872646175524163&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistics, Purdue University, West Lafayette, IN; Department of Computer Science, The University of Texas at Austin, Austin, TX; Department of Statistics, Purdue University, West Lafayette, IN; Department of Computer Science, Purdue University, West Lafayette, IN",
        "aff_domain": "purdue.edu; ; ; ",
        "email": "purdue.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/yang18c.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Purdue University;University of Texas at Austin",
        "aff_unique_dep": "Department of Statistics;Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Purdue;UT Austin",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "West Lafayette;Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2419",
        "id": "2419",
        "author_site": "Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich",
        "author": "Zhao Chen; Vijay Badrinarayanan; Chen-Yu Lee; Andrew Rabinovich",
        "abstract": "Deep multitask networks, in which one neural network produces multiple predictive outputs, can offer better speed and performance than their single-task counterparts but are challenging to train properly. We present a gradient normalization (GradNorm) algorithm that automatically balances training in deep multitask models by dynamically tuning gradient magnitudes. We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting across multiple tasks when compared to single-task networks, static baselines, and other adaptive multitask loss balancing techniques. GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter $\\alpha$. Thus, what was once a tedious search process that incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks. Ultimately, we will demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.",
        "bibtex": "@InProceedings{pmlr-v80-chen18a,\n  title = \t {{G}rad{N}orm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks},\n  author =       {Chen, Zhao and Badrinarayanan, Vijay and Lee, Chen-Yu and Rabinovich, Andrew},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {794--803},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18a/chen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18a.html},\n  abstract = \t {Deep multitask networks, in which one neural network produces multiple predictive outputs, can offer better speed and performance than their single-task counterparts but are challenging to train properly. We present a gradient normalization (GradNorm) algorithm that automatically balances training in deep multitask models by dynamically tuning gradient magnitudes. We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting across multiple tasks when compared to single-task networks, static baselines, and other adaptive multitask loss balancing techniques. GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter $\\alpha$. Thus, what was once a tedious search process that incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks. Ultimately, we will demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18a/chen18a.pdf",
        "supp": "",
        "pdf_size": 2472328,
        "gs_citation": 1623,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13835759043891121290&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Magic Leap, Inc.; Magic Leap, Inc.; Magic Leap, Inc.; Magic Leap, Inc.",
        "aff_domain": "magicleap.com; ; ; ",
        "email": "magicleap.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/chen18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Magic Leap",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.magicleap.com",
        "aff_unique_abbr": "Magic Leap",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Gradient Coding from Cyclic MDS Codes and Expander Graphs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2063",
        "id": "2063",
        "author_site": "Netanel Raviv, Rashish Tandon, Alexandros Dimakis, Itzhak Tamo",
        "author": "Netanel Raviv; Rashish Tandon; Alex Dimakis; Itzhak Tamo",
        "abstract": "Gradient coding is a technique for straggler mitigation in distributed learning. In this paper we design novel gradient codes using tools from classical coding theory, namely, cyclic MDS codes, which compare favourably with existing solutions, both in the applicable range of parameters and in the complexity of the involved algorithms. Second, we introduce an approximate variant of the gradient coding problem, in which we settle for approximate gradient computation instead of the exact one. This approach enables graceful degradation, i.e., the $\\ell_2$ error of the approximate gradient is a decreasing function of the number of stragglers. Our main result is that the normalized adjacency matrix of an expander graph can yield excellent approximate gradient codes, and that this approach allows us to perform significantly less computation compared to exact gradient coding. We experimentally test our approach on Amazon EC2, and show that the generalization error of approximate gradient coding is very close to the full gradient while requiring significantly less computation from the workers.",
        "bibtex": "@InProceedings{pmlr-v80-raviv18a,\n  title = \t {Gradient Coding from Cyclic {MDS} Codes and Expander Graphs},\n  author =       {Raviv, Netanel and Tandon, Rashish and Dimakis, Alex and Tamo, Itzhak},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4305--4313},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/raviv18a/raviv18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/raviv18a.html},\n  abstract = \t {Gradient coding is a technique for straggler mitigation in distributed learning. In this paper we design novel gradient codes using tools from classical coding theory, namely, cyclic MDS codes, which compare favourably with existing solutions, both in the applicable range of parameters and in the complexity of the involved algorithms. Second, we introduce an approximate variant of the gradient coding problem, in which we settle for approximate gradient computation instead of the exact one. This approach enables graceful degradation, i.e., the $\\ell_2$ error of the approximate gradient is a decreasing function of the number of stragglers. Our main result is that the normalized adjacency matrix of an expander graph can yield excellent approximate gradient codes, and that this approach allows us to perform significantly less computation compared to exact gradient coding. We experimentally test our approach on Amazon EC2, and show that the generalization error of approximate gradient coding is very close to the full gradient while requiring significantly less computation from the workers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/raviv18a/raviv18a.pdf",
        "supp": "",
        "pdf_size": 932588,
        "gs_citation": 223,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11291963769704251546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 17,
        "aff": "Department of Electrical Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Electrical Engineering\u2013Systems, Tel-Aviv University, Israel; Apple, Seattle, WA, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/raviv18a.html",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "California Institute of Technology;Tel-Aviv University;Apple;University of Texas at Austin",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Electrical Engineering\u2013Systems;Apple Inc.;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.caltech.edu;https://www.tau.ac.il;https://www.apple.com;https://www.utexas.edu",
        "aff_unique_abbr": "Caltech;TAU;Apple;UT Austin",
        "aff_campus_unique_index": "0;2;3",
        "aff_campus_unique": "Pasadena;;Seattle;Austin",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Gradient Descent Learns One-hidden-layer CNN: Don\u2019t be Afraid of Spurious Local Minima",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1922",
        "id": "1922",
        "author_site": "Simon Du, Jason Lee, Yuandong Tian, Aarti Singh, Barnab\u00e1s P\u00f3czos",
        "author": "Simon Du; Jason Lee; Yuandong Tian; Aarti Singh; Barnabas Poczos",
        "abstract": "We consider the problem of learning an one-hidden-layer neural network with non-overlapping convolutional layer and ReLU activation function, i.e., $f(Z; w, a) = \\sum_j a_j\\sigma(w^\\top Z_j)$, in which both the convolutional weights $w$ and the output weights $a$ are parameters to be learned. We prove that with Gaussian input $\\mathbf{Z}$ there is a spurious local minimizer. Surprisingly, in the presence of the spurious local minimizer, starting from randomly initialized weights, gradient descent with weight normalization can still be proven to recover the true parameters with constant probability (which can be boosted to probability $1$ with multiple restarts). We also show that with constant probability, the same procedure could also converge to the spurious local minimum, showing that the local minimum plays a non-trivial role in the dynamics of gradient descent. Furthermore, a quantitative analysis shows that the gradient descent dynamics has two phases: it starts off slow, but converges much faster after several iterations.",
        "bibtex": "@InProceedings{pmlr-v80-du18b,\n  title = \t {Gradient Descent Learns One-hidden-layer {CNN}: Don\u2019t be Afraid of Spurious Local Minima},\n  author =       {Du, Simon and Lee, Jason and Tian, Yuandong and Singh, Aarti and Poczos, Barnabas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1339--1348},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/du18b/du18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/du18b.html},\n  abstract = \t {We consider the problem of learning an one-hidden-layer neural network with non-overlapping convolutional layer and ReLU activation function, i.e., $f(Z; w, a) = \\sum_j a_j\\sigma(w^\\top Z_j)$, in which both the convolutional weights $w$ and the output weights $a$ are parameters to be learned. We prove that with Gaussian input $\\mathbf{Z}$ there is a spurious local minimizer. Surprisingly, in the presence of the spurious local minimizer, starting from randomly initialized weights, gradient descent with weight normalization can still be proven to recover the true parameters with constant probability (which can be boosted to probability $1$ with multiple restarts). We also show that with constant probability, the same procedure could also converge to the spurious local minimum, showing that the local minimum plays a non-trivial role in the dynamics of gradient descent. Furthermore, a quantitative analysis shows that the gradient descent dynamics has two phases: it starts off slow, but converges much faster after several iterations.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/du18b/du18b.pdf",
        "supp": "",
        "pdf_size": 557744,
        "gs_citation": 258,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2621548559743490986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Machine Learning Department, Carnegie Mellon University; Department of Data Sciences and Operations, University of Southern California; Facebook Artificial Intelligence Research; Machine Learning Department, Carnegie Mellon University; Machine Learning Department, Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu; ; ; ; ",
        "email": "cs.cmu.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/du18b.html",
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Southern California;Meta",
        "aff_unique_dep": "Machine Learning Department;Department of Data Sciences and Operations;Artificial Intelligence Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.usc.edu;https://research.facebook.com",
        "aff_unique_abbr": "CMU;USC;FAIR",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2196",
        "id": "2196",
        "author_site": "Yao Ma, Alex Olshevsky, Csaba Szepesvari, Venkatesh Saligrama",
        "author": "Yao Ma; Alexander Olshevsky; Csaba Szepesvari; Venkatesh Saligrama",
        "abstract": "We consider worker skill estimation for the single coin Dawid-Skene crowdsourcing model. In practice skill-estimation is challenging because worker assignments are sparse and irregular due to the arbitrary, and uncontrolled availability of workers. We formulate skill estimation as a rank-one correlation-matrix completion problem, where the observed components correspond to observed label correlation between workers. We show that the correlation matrix can be successfully recovered and skills identifiable if and only if the sampling matrix (observed components) is irreducible and aperiodic. We then propose an efficient gradient descent scheme and show that skill estimates converges to the desired global optima for such sampling matrices. Our proof is original and the results are surprising in light of the fact that even the weighted rank-one matrix factorization problem is NP hard in general. Next we derive sample complexity bounds for the noisy case in terms of spectral properties of the signless Laplacian of the sampling matrix. Our proposed scheme achieves state-of-art performance on a number of real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v80-ma18b,\n  title = \t {Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers},\n  author =       {Ma, Yao and Olshevsky, Alexander and Szepesvari, Csaba and Saligrama, Venkatesh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3335--3344},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ma18b/ma18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ma18b.html},\n  abstract = \t {We consider worker skill estimation for the single coin Dawid-Skene crowdsourcing model. In practice skill-estimation is challenging because worker assignments are sparse and irregular due to the arbitrary, and uncontrolled availability of workers. We formulate skill estimation as a rank-one correlation-matrix completion problem, where the observed components correspond to observed label correlation between workers. We show that the correlation matrix can be successfully recovered and skills identifiable if and only if the sampling matrix (observed components) is irreducible and aperiodic. We then propose an efficient gradient descent scheme and show that skill estimates converges to the desired global optima for such sampling matrices. Our proof is original and the results are surprising in light of the fact that even the weighted rank-one matrix factorization problem is NP hard in general. Next we derive sample complexity bounds for the noisy case in terms of spectral properties of the signless Laplacian of the sampling matrix. Our proposed scheme achieves state-of-art performance on a number of real-world datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ma18b/ma18b.pdf",
        "supp": "",
        "pdf_size": 439352,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10222563810621001488&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Division of Systems Engineering, Boston University, USA; Department of Electrical and Computer Engineering, Boston University, USA; Department of Electrical and Computer Engineering, Boston University, USA; Department of Computing Science, University of Alberta, Canada",
        "aff_domain": "bu.edu;bu.edu;bu.edu;ualberta.ca",
        "email": "bu.edu;bu.edu;bu.edu;ualberta.ca",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ma18b.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Boston University;University of Alberta",
        "aff_unique_dep": "Division of Systems Engineering;Department of Computing Science",
        "aff_unique_url": "https://www.bu.edu;https://www.ualberta.ca",
        "aff_unique_abbr": "BU;UAlberta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "title": "Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solution for Nonconvex Distributed Optimization Over Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2156",
        "id": "2156",
        "author_site": "Mingyi Hong, Meisam Razaviyayn, Jason Lee",
        "author": "Mingyi Hong; Meisam Razaviyayn; Jason Lee",
        "abstract": "In this work, we study two first-order primal-dual based algorithms, the Gradient Primal-Dual Algorithm (GPDA) and the Gradient Alternating Direction Method of Multipliers (GADMM), for solving a class of linearly constrained non-convex optimization problems. We show that with random initialization of the primal and dual variables, both algorithms are able to compute second-order stationary solutions (ss2) with probability one. This is the first result showing that primal-dual algorithm is capable of finding ss2 when only using first-order information; it also extends the existing results for first-order, but {primal-only} algorithms. An important implication of our result is that it also gives rise to the first global convergence result to the ss2, for two classes of unconstrained distributed non-convex learning problems over multi-agent networks.",
        "bibtex": "@InProceedings{pmlr-v80-hong18a,\n  title = \t {Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solution for Nonconvex Distributed Optimization Over Networks},\n  author =       {Hong, Mingyi and Razaviyayn, Meisam and Lee, Jason},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2009--2018},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hong18a/hong18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hong18a.html},\n  abstract = \t {In this work, we study two first-order primal-dual based algorithms, the Gradient Primal-Dual Algorithm (GPDA) and the Gradient Alternating Direction Method of Multipliers (GADMM), for solving a class of linearly constrained non-convex optimization problems. We show that with random initialization of the primal and dual variables, both algorithms are able to compute second-order stationary solutions (ss2) with probability one. This is the first result showing that primal-dual algorithm is capable of finding ss2 when only using first-order information; it also extends the existing results for first-order, but {primal-only} algorithms. An important implication of our result is that it also gives rise to the first global convergence result to the ss2, for two classes of unconstrained distributed non-convex learning problems over multi-agent networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hong18a/hong18a.pdf",
        "supp": "",
        "pdf_size": 323936,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9022928579062107689&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55414, USA; Department of Data Sciences and Operations, the University of Southern California, Los Angeles, CA 90089; Department of Industrial and Systems Engineering, the University of Southern California",
        "aff_domain": "umn.edu; ; ",
        "email": "umn.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/hong18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Minnesota;University of Southern California",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Data Sciences and Operations",
        "aff_unique_url": "https://www.umn.edu;https://www.usc.edu",
        "aff_unique_abbr": "UMN;USC",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Minneapolis;Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1980",
        "id": "1980",
        "author_site": "Peter Bartlett, Dave Helmbold, Phil Long",
        "author": "Peter Bartlett; Dave Helmbold; Philip Long",
        "abstract": "We analyze algorithms for approximating a function $f(x) = \\Phi x$ mapping $\\Re^d$ to $\\Re^d$ using deep linear neural networks, i.e. that learn a function $h$ parameterized by matrices $\\Theta_1,...,\\Theta_L$ and defined by $h(x) = \\Theta_L \\Theta_{L-1} ... \\Theta_1 x$. We focus on algorithms that learn through gradient descent on the population quadratic loss in the case that the distribution over the inputs is isotropic. We provide polynomial bounds on the number of iterations for gradient descent to approximate the least squares matrix $\\Phi$, in the case where the initial hypothesis $\\Theta_1 = ... = \\Theta_L = I$ has excess loss bounded by a small enough constant. On the other hand, we show that gradient descent fails to converge for $\\Phi$ whose distance from the identity is a larger constant, and we show that some forms of regularization toward the identity in each layer do not help. If $\\Phi$ is symmetric positive definite, we show that an algorithm that initializes $\\Theta_i = I$ learns an $\\epsilon$-approximation of $f$ using a number of updates polynomial in $L$, the condition number of $\\Phi$, and $\\log(d/\\epsilon)$. In contrast, we show that if the least squares matrix $\\Phi$ is symmetric and has a negative eigenvalue, then all members of a class of algorithms that perform gradient descent with identity initialization, and optionally regularize toward the identity in each layer, fail to converge. We analyze an algorithm for the case that $\\Phi$ satisfies $u^{\\top} \\Phi u > 0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers: one that maintains the invariant $u^{\\top} \\Theta_L \\Theta_{L-1} ... \\Theta_1 u > 0$ for all $u$, and another that \"balances\" $\\Theta_1, ..., \\Theta_L$ so that they have the same singular values.",
        "bibtex": "@InProceedings{pmlr-v80-bartlett18a,\n  title = \t {Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks},\n  author =       {Bartlett, Peter and Helmbold, Dave and Long, Philip},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {521--530},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bartlett18a/bartlett18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bartlett18a.html},\n  abstract = \t {We analyze algorithms for approximating a function $f(x) = \\Phi x$ mapping $\\Re^d$ to $\\Re^d$ using deep linear neural networks, i.e. that learn a function $h$ parameterized by matrices $\\Theta_1,...,\\Theta_L$ and defined by $h(x) = \\Theta_L \\Theta_{L-1} ... \\Theta_1 x$. We focus on algorithms that learn through gradient descent on the population quadratic loss in the case that the distribution over the inputs is isotropic. We provide polynomial bounds on the number of iterations for gradient descent to approximate the least squares matrix $\\Phi$, in the case where the initial hypothesis $\\Theta_1 = ... = \\Theta_L = I$ has excess loss bounded by a small enough constant. On the other hand, we show that gradient descent fails to converge for $\\Phi$ whose distance from the identity is a larger constant, and we show that some forms of regularization toward the identity in each layer do not help. If $\\Phi$ is symmetric positive definite, we show that an algorithm that initializes $\\Theta_i = I$ learns an $\\epsilon$-approximation of $f$ using a number of updates polynomial in $L$, the condition number of $\\Phi$, and $\\log(d/\\epsilon)$. In contrast, we show that if the least squares matrix $\\Phi$ is symmetric and has a negative eigenvalue, then all members of a class of algorithms that perform gradient descent with identity initialization, and optionally regularize toward the identity in each layer, fail to converge. We analyze an algorithm for the case that $\\Phi$ satisfies $u^{\\top} \\Phi u > 0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers: one that maintains the invariant $u^{\\top} \\Theta_L \\Theta_{L-1} ... \\Theta_1 u > 0$ for all $u$, and another that \"balances\" $\\Theta_1, ..., \\Theta_L$ so that they have the same singular values.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bartlett18a/bartlett18a.pdf",
        "supp": "",
        "pdf_size": 287556,
        "gs_citation": 158,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17098957846749998434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "UC Berkeley; UC Santa Cruz; Google",
        "aff_domain": "berkeley.edu;soe.ucsc.edu;google.com",
        "email": "berkeley.edu;soe.ucsc.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/bartlett18a.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of California, Berkeley;University of California, Santa Cruz;Google",
        "aff_unique_dep": ";;Google",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ucsc.edu;https://www.google.com",
        "aff_unique_abbr": "UC Berkeley;UCSC;Google",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Berkeley;Santa Cruz;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2202",
        "id": "2202",
        "author_site": "Yoonho Lee, Seungjin Choi",
        "author": "Yoonho Lee; Seungjin Choi",
        "abstract": "Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during meta-testing. Our primary contribution is the",
        "bibtex": "@InProceedings{pmlr-v80-lee18a,\n  title = \t {Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace},\n  author =       {Lee, Yoonho and Choi, Seungjin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2927--2936},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lee18a/lee18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lee18a.html},\n  abstract = \t {Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during meta-testing. Our primary contribution is the",
        "pdf": "http://proceedings.mlr.press/v80/lee18a/lee18a.pdf",
        "supp": "",
        "pdf_size": 730677,
        "gs_citation": 455,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16589702021969633682&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Engineering, Pohang University of Science and Technology, Korea; Department of Computer Science and Engineering, Pohang University of Science and Technology, Korea",
        "aff_domain": "postech.ac.kr;postech.ac.kr",
        "email": "postech.ac.kr;postech.ac.kr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/lee18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Gradually Updated Neural Networks for Large-Scale Image Recognition",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1905",
        "id": "1905",
        "author_site": "Siyuan Qiao, Zhishuai Zhang, Wei Shen, Bo Wang, Alan Yuille",
        "author": "Siyuan Qiao; Zhishuai Zhang; Wei Shen; Bo Wang; Alan Yuille",
        "abstract": "Depth is one of the keys that make neural networks succeed in the task of large-scale image recognition. The state-of-the-art network architectures usually increase the depths by cascading convolutional layers or building blocks. In this paper, we present an alternative method to increase the depth. Our method is by introducing computation orderings to the channels within convolutional layers or blocks, based on which we gradually compute the outputs in a channel-wise manner. The added orderings not only increase the depths and the learning capacities of the networks without any additional computation costs, but also eliminate the overlap singularities so that the networks are able to converge faster and perform better. Experiments show that the networks based on our method achieve the state-of-the-art performances on CIFAR and ImageNet datasets.",
        "bibtex": "@InProceedings{pmlr-v80-qiao18b,\n  title = \t {Gradually Updated Neural Networks for Large-Scale Image Recognition},\n  author =       {Qiao, Siyuan and Zhang, Zhishuai and Shen, Wei and Wang, Bo and Yuille, Alan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4188--4197},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/qiao18b/qiao18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/qiao18b.html},\n  abstract = \t {Depth is one of the keys that make neural networks succeed in the task of large-scale image recognition. The state-of-the-art network architectures usually increase the depths by cascading convolutional layers or building blocks. In this paper, we present an alternative method to increase the depth. Our method is by introducing computation orderings to the channels within convolutional layers or blocks, based on which we gradually compute the outputs in a channel-wise manner. The added orderings not only increase the depths and the learning capacities of the networks without any additional computation costs, but also eliminate the overlap singularities so that the networks are able to converge faster and perform better. Experiments show that the networks based on our method achieve the state-of-the-art performances on CIFAR and ImageNet datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/qiao18b/qiao18b.pdf",
        "supp": "",
        "pdf_size": 952438,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2192054677051521986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Johns Hopkins University; Johns Hopkins University; Johns Hopkins University + Shanghai University; Hikvision Research; Johns Hopkins University",
        "aff_domain": "jhu.edu; ; ; ; ",
        "email": "jhu.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/qiao18b.html",
        "aff_unique_index": "0;0;0+1;2;0",
        "aff_unique_norm": "Johns Hopkins University;Shanghai University;Hikvision",
        "aff_unique_dep": ";;Research",
        "aff_unique_url": "https://www.jhu.edu;https://www.shu.edu.cn;https://www.hikvision.com/cn/",
        "aff_unique_abbr": "JHU;SHU;Hikvision",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Graph Networks as Learnable Physics Engines for Inference and Control",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2220",
        "id": "2220",
        "author_site": "Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, Peter Battaglia",
        "author": "Alvaro Sanchez-Gonzalez; Nicolas Heess; Jost Tobias Springenberg; Josh Merel; Martin Riedmiller; Raia Hadsell; Peter Battaglia",
        "abstract": "Understanding and interacting with everyday physical scenes requires rich knowledge about the structure of the world, represented either implicitly in a value or policy function, or explicitly in a transition model. Here we introduce a new class of learnable models\u2013based on graph networks\u2013which implement an inductive bias for object- and relation-centric representations of complex, dynamical systems. Our results show that as a forward model, our approach supports accurate predictions from real and simulated data, and surprisingly strong and efficient generalization, across eight distinct physical systems which we varied parametrically and structurally. We also found that our inference model can perform system identification. Our models are also differentiable, and support online planning via gradient-based trajectory optimization, as well as offline policy optimization. Our framework offers new opportunities for harnessing and exploiting rich knowledge about the world, and takes a key step toward building machines with more human-like representations of the world.",
        "bibtex": "@InProceedings{pmlr-v80-sanchez-gonzalez18a,\n  title = \t {Graph Networks as Learnable Physics Engines for Inference and Control},\n  author =       {Sanchez-Gonzalez, Alvaro and Heess, Nicolas and Springenberg, Jost Tobias and Merel, Josh and Riedmiller, Martin and Hadsell, Raia and Battaglia, Peter},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4470--4479},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sanchez-gonzalez18a/sanchez-gonzalez18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sanchez-gonzalez18a.html},\n  abstract = \t {Understanding and interacting with everyday physical scenes requires rich knowledge about the structure of the world, represented either implicitly in a value or policy function, or explicitly in a transition model. Here we introduce a new class of learnable models\u2013based on graph networks\u2013which implement an inductive bias for object- and relation-centric representations of complex, dynamical systems. Our results show that as a forward model, our approach supports accurate predictions from real and simulated data, and surprisingly strong and efficient generalization, across eight distinct physical systems which we varied parametrically and structurally. We also found that our inference model can perform system identification. Our models are also differentiable, and support online planning via gradient-based trajectory optimization, as well as offline policy optimization. Our framework offers new opportunities for harnessing and exploiting rich knowledge about the world, and takes a key step toward building machines with more human-like representations of the world.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sanchez-gonzalez18a/sanchez-gonzalez18a.pdf",
        "supp": "",
        "pdf_size": 2137081,
        "gs_citation": 794,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17683095654624011771&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ; ; ;google.com",
        "email": "google.com; ; ; ; ; ;google.com",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/sanchez-gonzalez18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2373",
        "id": "2373",
        "author_site": "Jiaxuan You, Rex (Zhitao) Ying, Xiang Ren, Will Hamilton, Jure Leskovec",
        "author": "Jiaxuan You; Rex Ying; Xiang Ren; William Hamilton; Jure Leskovec",
        "abstract": "Modeling and generating graphs is fundamental for studying networks in biology, engineering, and social sciences. However, modeling complex distributions over graphs and then efficiently sampling from these distributions is challenging due to the non-unique, high-dimensional nature of graphs and the complex, non-local dependencies that exist between edges in a given graph. Here we propose GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure. GraphRNN learns to generate graphs by training on a representative set of graphs and decomposes the graph generation process into a sequence of node and edge formations, conditioned on the graph structure generated so far. In order to quantitatively evaluate the performance of GraphRNN, we introduce a benchmark suite of datasets, baselines and novel evaluation metrics based on Maximum Mean Discrepancy, which measure distances between sets of graphs. Our experiments show that GraphRNN significantly outperforms all baselines, learning to generate diverse graphs that match the structural characteristics of a target set, while also scaling to graphs 50 times larger than previous deep models.",
        "bibtex": "@InProceedings{pmlr-v80-you18a,\n  title = \t {{G}raph{RNN}: Generating Realistic Graphs with Deep Auto-regressive Models},\n  author =       {You, Jiaxuan and Ying, Rex and Ren, Xiang and Hamilton, William and Leskovec, Jure},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5708--5717},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/you18a/you18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/you18a.html},\n  abstract = \t {Modeling and generating graphs is fundamental for studying networks in biology, engineering, and social sciences. However, modeling complex distributions over graphs and then efficiently sampling from these distributions is challenging due to the non-unique, high-dimensional nature of graphs and the complex, non-local dependencies that exist between edges in a given graph. Here we propose GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure. GraphRNN learns to generate graphs by training on a representative set of graphs and decomposes the graph generation process into a sequence of node and edge formations, conditioned on the graph structure generated so far. In order to quantitatively evaluate the performance of GraphRNN, we introduce a benchmark suite of datasets, baselines and novel evaluation metrics based on Maximum Mean Discrepancy, which measure distances between sets of graphs. Our experiments show that GraphRNN significantly outperforms all baselines, learning to generate diverse graphs that match the structural characteristics of a target set, while also scaling to graphs 50 times larger than previous deep models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/you18a/you18a.pdf",
        "supp": "",
        "pdf_size": 2006543,
        "gs_citation": 1213,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18334516615969196433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, University of Southern California; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University",
        "aff_domain": "stanford.edu; ; ; ; ",
        "email": "stanford.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/you18a.html",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Stanford University;University of Southern California",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu;https://www.usc.edu",
        "aff_unique_abbr": "Stanford;USC",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Stanford;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Graphical Nonconvex Optimization via an Adaptive Convex Relaxation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1955",
        "id": "1955",
        "author_site": "Qiang Sun, Kean Ming Tan, Han Liu, Tong Zhang",
        "author": "Qiang Sun; Kean Ming Tan; Han Liu; Tong Zhang",
        "abstract": "We consider the problem of learning high-dimensional Gaussian graphical models. The graphical lasso is one of the most popular methods for estimating Gaussian graphical models. However, it does not achieve the oracle rate of convergence. In this paper, we propose the graphical nonconvex optimization for optimal estimation in Gaussian graphical models, which is then approximated by a sequence of convex programs. Our proposal is computationally tractable and produces an estimator that achieves the oracle rate of convergence. The statistical error introduced by the sequential approximation using a sequence of convex programs is clearly demonstrated via a contraction property. The proposed methodology is then extended to modeling semiparametric graphical models. We show via numerical studies that the proposed estimator outperforms other popular methods for estimating Gaussian graphical models.",
        "bibtex": "@InProceedings{pmlr-v80-sun18c,\n  title = \t {Graphical Nonconvex Optimization via an Adaptive Convex Relaxation},\n  author =       {Sun, Qiang and Tan, Kean Ming and Liu, Han and Zhang, Tong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4810--4817},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sun18c/sun18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sun18c.html},\n  abstract = \t {We consider the problem of learning high-dimensional Gaussian graphical models. The graphical lasso is one of the most popular methods for estimating Gaussian graphical models. However, it does not achieve the oracle rate of convergence. In this paper, we propose the graphical nonconvex optimization for optimal estimation in Gaussian graphical models, which is then approximated by a sequence of convex programs. Our proposal is computationally tractable and produces an estimator that achieves the oracle rate of convergence. The statistical error introduced by the sequential approximation using a sequence of convex programs is clearly demonstrated via a contraction property. The proposed methodology is then extended to modeling semiparametric graphical models. We show via numerical studies that the proposed estimator outperforms other popular methods for estimating Gaussian graphical models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sun18c/sun18c.pdf",
        "supp": "",
        "pdf_size": 612342,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17515804471924047962&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Statistical Sciences, University of Toronto, Toronto, Ontario, Canada; School of Statistics, University of Minnesota, Minneapolis, MN, USA; Tencent AI Lab, Tencent Technology, Shenzhen, China; Tencent AI Lab, Tencent Technology, Shenzhen, China",
        "aff_domain": "utstat.toronto.edu; ; ; ",
        "email": "utstat.toronto.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sun18c.html",
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Toronto;University of Minnesota;Tencent",
        "aff_unique_dep": "Department of Statistical Sciences;School of Statistics;Tencent AI Lab",
        "aff_unique_url": "https://www.utoronto.ca;https://www.minnesota.edu;https://www.tencent.com",
        "aff_unique_abbr": "U of T;UMN;Tencent",
        "aff_campus_unique_index": "0;1;2;2",
        "aff_campus_unique": "Toronto;Minneapolis;Shenzhen",
        "aff_country_unique_index": "0;1;2;2",
        "aff_country_unique": "Canada;United States;China"
    },
    {
        "title": "Greed is Still Good: Maximizing Monotone Submodular+Supermodular (BP) Functions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2350",
        "id": "2350",
        "author_site": "Wenruo Bai, Jeff Bilmes",
        "author": "Wenruo Bai; Jeff Bilmes",
        "abstract": "We analyze the performance of the greedy algorithm, and also a discrete semi-gradient based algorithm, for maximizing the sum of a suBmodular and suPermodular (BP) function (both of which are non-negative monotone non-decreasing) under two types of constraints, either a cardinality constraint or $p\\geq 1$ matroid independence constraints. These problems occur naturally in several real-world applications in data science, machine learning, and artificial intelligence. The problems are ordinarily inapproximable to any factor. Using the curvature $\\curv_f$ of the submodular term, and introducing $\\curv^g$ for the supermodular term (a natural dual curvature for supermodular functions), however, both of which are computable in linear time, we show that BP maximization can be efficiently approximated by both the greedy and the semi-gradient based algorithm. The algorithms yield multiplicative guarantees of $\\frac{1}{\\curv_f}\\left[1-e^{-(1-\\curv^g)\\curv_f}\\right]$ and $\\frac{1-\\curv^g}{(1-\\curv^g)\\curv_f + p}$ for the two types of constraints respectively. For pure monotone supermodular constrained maximization, these yield $1-\\curvg$ and $(1-\\curvg)/p$ for the two types of constraints respectively. We also analyze the hardness of BP maximization and show that our guarantees match hardness by a constant factor and by $O(\\ln(p))$ respectively. Computational experiments are also provided supporting our analysis.",
        "bibtex": "@InProceedings{pmlr-v80-bai18a,\n  title = \t {Greed is Still Good: Maximizing Monotone {S}ubmodular+{S}upermodular ({BP}) Functions},\n  author =       {Bai, Wenruo and Bilmes, Jeff},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {304--313},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bai18a/bai18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bai18a.html},\n  abstract = \t {We analyze the performance of the greedy algorithm, and also a discrete semi-gradient based algorithm, for maximizing the sum of a suBmodular and suPermodular (BP) function (both of which are non-negative monotone non-decreasing) under two types of constraints, either a cardinality constraint or $p\\geq 1$ matroid independence constraints. These problems occur naturally in several real-world applications in data science, machine learning, and artificial intelligence. The problems are ordinarily inapproximable to any factor. Using the curvature $\\curv_f$ of the submodular term, and introducing $\\curv^g$ for the supermodular term (a natural dual curvature for supermodular functions), however, both of which are computable in linear time, we show that BP maximization can be efficiently approximated by both the greedy and the semi-gradient based algorithm. The algorithms yield multiplicative guarantees of $\\frac{1}{\\curv_f}\\left[1-e^{-(1-\\curv^g)\\curv_f}\\right]$ and $\\frac{1-\\curv^g}{(1-\\curv^g)\\curv_f + p}$ for the two types of constraints respectively. For pure monotone supermodular constrained maximization, these yield $1-\\curvg$ and $(1-\\curvg)/p$ for the two types of constraints respectively. We also analyze the hardness of BP maximization and show that our guarantees match hardness by a constant factor and by $O(\\ln(p))$ respectively. Computational experiments are also provided supporting our analysis.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bai18a/bai18a.pdf",
        "supp": "",
        "pdf_size": 741960,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9766513621965037368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering, University of Washington, Seattle, USA+Department of Computer Science and Engineering, University of Washington, Seattle, USA; Department of Electrical Engineering, University of Washington, Seattle, USA+Department of Computer Science and Engineering, University of Washington, Seattle, USA",
        "aff_domain": "uw.edu;uw.edu",
        "email": "uw.edu;uw.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/bai18a.html",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Hierarchical Clustering with Structural Constraints",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2058",
        "id": "2058",
        "author_site": "Evangelos Chatziafratis, Rad Niazadeh, Moses Charikar",
        "author": "Vaggos Chatziafratis; Rad Niazadeh; Moses Charikar",
        "abstract": "Hierarchical clustering is a popular unsupervised data analysis method. For many real-world applications, we would like to exploit prior information about the data that imposes constraints on the clustering hierarchy, and is not captured by the set of features available to the algorithm. This gives rise to the problem of hierarchical clustering with structural constraints. Structural constraints pose major challenges for bottom-up approaches like average/single linkage and even though they can be naturally incorporated into top-down divisive algorithms, no formal guarantees exist on the quality of their output. In this paper, we provide provable approximation guarantees for two simple top-down algorithms, using a recently introduced optimization viewpoint of hierarchical clustering with pairwise similarity information (Dasgupta, 2016). We show how to find good solutions even in the presence of conflicting prior information, by formulating a constraint-based regularization of the objective. Furthemore, we explore a variation of this objective for dissimilarity information (Cohen-Addad et al., 2018) and improve upon current techniques. Finally, we demonstrate our approach on a real dataset for the taxonomy application.",
        "bibtex": "@InProceedings{pmlr-v80-chatziafratis18a,\n  title = \t {Hierarchical Clustering with Structural Constraints},\n  author =       {Chatziafratis, Vaggos and Niazadeh, Rad and Charikar, Moses},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {774--783},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chatziafratis18a/chatziafratis18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chatziafratis18a.html},\n  abstract = \t {Hierarchical clustering is a popular unsupervised data analysis method. For many real-world applications, we would like to exploit prior information about the data that imposes constraints on the clustering hierarchy, and is not captured by the set of features available to the algorithm. This gives rise to the problem of hierarchical clustering with structural constraints. Structural constraints pose major challenges for bottom-up approaches like average/single linkage and even though they can be naturally incorporated into top-down divisive algorithms, no formal guarantees exist on the quality of their output. In this paper, we provide provable approximation guarantees for two simple top-down algorithms, using a recently introduced optimization viewpoint of hierarchical clustering with pairwise similarity information (Dasgupta, 2016). We show how to find good solutions even in the presence of conflicting prior information, by formulating a constraint-based regularization of the objective. Furthemore, we explore a variation of this objective for dissimilarity information (Cohen-Addad et al., 2018) and improve upon current techniques. Finally, we demonstrate our approach on a real dataset for the taxonomy application.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chatziafratis18a/chatziafratis18a.pdf",
        "supp": "",
        "pdf_size": 629826,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5299367795574527129&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "aff_domain": "stanford.edu;cs.stanford.edu;cs.stanford.edu",
        "email": "stanford.edu;cs.stanford.edu;cs.stanford.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chatziafratis18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2108",
        "id": "2108",
        "author_site": "Zhengping Che, Sanjay Purushotham, Max Guangyu Li, Bo Jiang, Yan Liu",
        "author": "Zhengping Che; Sanjay Purushotham; Guangyu Li; Bo Jiang; Yan Liu",
        "abstract": "Multi-Rate Multivariate Time Series (MR-MTS) are the multivariate time series observations which come with various sampling rates and encode multiple temporal dependencies. State-space models such as Kalman filters and deep learning models such as deep Markov models are mainly designed for time series data with the same sampling rate and cannot capture all the dependencies present in the MR-MTS data. To address this challenge, we propose the Multi-Rate Hierarchical Deep Markov Model (MR-HDMM), a novel deep generative model which uses the latent hierarchical structure with a learnable switch mechanism to capture the temporal dependencies of MR-MTS. Experimental results on two real-world datasets demonstrate that our MR-HDMM model outperforms the existing state-of-the-art deep learning and state-space models on forecasting and interpolation tasks. In addition, the latent hierarchies in our model provide a way to show and interpret the multiple temporal dependencies.",
        "bibtex": "@InProceedings{pmlr-v80-che18a,\n  title = \t {Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series},\n  author =       {Che, Zhengping and Purushotham, Sanjay and Li, Guangyu and Jiang, Bo and Liu, Yan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {784--793},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/che18a/che18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/che18a.html},\n  abstract = \t {Multi-Rate Multivariate Time Series (MR-MTS) are the multivariate time series observations which come with various sampling rates and encode multiple temporal dependencies. State-space models such as Kalman filters and deep learning models such as deep Markov models are mainly designed for time series data with the same sampling rate and cannot capture all the dependencies present in the MR-MTS data. To address this challenge, we propose the Multi-Rate Hierarchical Deep Markov Model (MR-HDMM), a novel deep generative model which uses the latent hierarchical structure with a learnable switch mechanism to capture the temporal dependencies of MR-MTS. Experimental results on two real-world datasets demonstrate that our MR-HDMM model outperforms the existing state-of-the-art deep learning and state-space models on forecasting and interpolation tasks. In addition, the latent hierarchies in our model provide a way to show and interpret the multiple temporal dependencies.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/che18a/che18a.pdf",
        "supp": "",
        "pdf_size": 2564817,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14649876345386777550&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, California, United States; Department of Computer Science, University of Southern California, Los Angeles, California, United States; Department of Computer Science, University of Southern California, Los Angeles, California, United States; Department of Computer Science, University of Southern California, Los Angeles, California, United States; Department of Computer Science, University of Southern California, Los Angeles, California, United States",
        "aff_domain": "usc.edu;usc.edu;usc.edu;usc.edu;usc.edu",
        "email": "usc.edu;usc.edu;usc.edu;usc.edu;usc.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/che18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Hierarchical Imitation and Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2290",
        "id": "2290",
        "author_site": "Hoang Le, Nan Jiang, Alekh Agarwal, Miroslav Dudik, Yisong Yue, Hal Daum\u00e9 III",
        "author": "Hoang Le; Nan Jiang; Alekh Agarwal; Miroslav Dudik; Yisong Yue; Hal Daum\u00e9 III",
        "abstract": "We study how to effectively leverage expert feedback to learn sequential decision-making policies. We focus on problems with sparse rewards and long time horizons, which typically pose significant challenges in reinforcement learning. We propose an algorithmic framework, called hierarchical guidance, that leverages the hierarchical structure of the underlying problem to integrate different modes of expert interaction. Our framework can incorporate different combinations of imitation learning (IL) and reinforcement learning (RL) at different levels, leading to dramatic reductions in both expert effort and cost of exploration. Using long-horizon benchmarks, including Montezuma\u2019s Revenge, we demonstrate that our approach can learn significantly faster than hierarchical RL, and be significantly more label-efficient than standard IL. We also theoretically analyze labeling cost for certain instantiations of our framework.",
        "bibtex": "@InProceedings{pmlr-v80-le18a,\n  title = \t {Hierarchical Imitation and Reinforcement Learning},\n  author =       {Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Yue, Yisong and Daum{\\'e}, III, Hal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2917--2926},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/le18a/le18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/le18a.html},\n  abstract = \t {We study how to effectively leverage expert feedback to learn sequential decision-making policies. We focus on problems with sparse rewards and long time horizons, which typically pose significant challenges in reinforcement learning. We propose an algorithmic framework, called hierarchical guidance, that leverages the hierarchical structure of the underlying problem to integrate different modes of expert interaction. Our framework can incorporate different combinations of imitation learning (IL) and reinforcement learning (RL) at different levels, leading to dramatic reductions in both expert effort and cost of exploration. Using long-horizon benchmarks, including Montezuma\u2019s Revenge, we demonstrate that our approach can learn significantly faster than hierarchical RL, and be significantly more label-efficient than standard IL. We also theoretically analyze labeling cost for certain instantiations of our framework.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/le18a/le18a.pdf",
        "supp": "",
        "pdf_size": 637853,
        "gs_citation": 251,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17866154816448753073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "California Institute of Technology; Microsoft Research; Microsoft Research; Microsoft Research; California Institute of Technology; University of Maryland",
        "aff_domain": "caltech.edu; ; ; ; ; ",
        "email": "caltech.edu; ; ; ; ; ",
        "github": "",
        "project": "https://sites.google.com/view/hierarchical-il-rl",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/le18a.html",
        "aff_unique_index": "0;1;1;1;0;2",
        "aff_unique_norm": "California Institute of Technology;Microsoft;University of Maryland",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://www.caltech.edu;https://www.microsoft.com/en-us/research;https://www/umd.edu",
        "aff_unique_abbr": "Caltech;MSR;UMD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Hierarchical Long-term Video Prediction without Supervision",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2381",
        "id": "2381",
        "author_site": "Nevan Wichers, Ruben Villegas, Dumitru Erhan, Honglak Lee",
        "author": "Nevan wichers; Ruben Villegas; Dumitru Erhan; Honglak Lee",
        "abstract": "Much of recent research has been devoted to video prediction and generation, yet most of the previous works have demonstrated only limited success in generating videos on short-term horizons. The hierarchical video prediction method by Villegas et al. (2017) is an example of a state-of-the-art method for long-term video prediction, but their method is limited because it requires ground truth annotation of high-level structures (e.g., human joint landmarks) at training time. Our network encodes the input frame, predicts a high-level encoding into the future, and then a decoder with access to the first frame produces the predicted image from the predicted encoding. The decoder also produces a mask that outlines the predicted foreground object (e.g., person) as a by-product. Unlike Villegas et al. (2017), we develop a novel training method that jointly trains the encoder, the predictor, and the decoder together without highlevel supervision; we further improve upon this by using an adversarial loss in the feature space to train the predictor. Our method can predict about 20 seconds into the future and provides better results compared to Denton and Fergus (2018) and Finn et al. (2016) on the Human 3.6M dataset.",
        "bibtex": "@InProceedings{pmlr-v80-wichers18a,\n  title = \t {Hierarchical Long-term Video Prediction without Supervision},\n  author =       {wichers, Nevan and Villegas, Ruben and Erhan, Dumitru and Lee, Honglak},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {6038--6046},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wichers18a/wichers18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wichers18a.html},\n  abstract = \t {Much of recent research has been devoted to video prediction and generation, yet most of the previous works have demonstrated only limited success in generating videos on short-term horizons. The hierarchical video prediction method by Villegas et al. (2017) is an example of a state-of-the-art method for long-term video prediction, but their method is limited because it requires ground truth annotation of high-level structures (e.g., human joint landmarks) at training time. Our network encodes the input frame, predicts a high-level encoding into the future, and then a decoder with access to the first frame produces the predicted image from the predicted encoding. The decoder also produces a mask that outlines the predicted foreground object (e.g., person) as a by-product. Unlike Villegas et al. (2017), we develop a novel training method that jointly trains the encoder, the predictor, and the decoder together without highlevel supervision; we further improve upon this by using an adversarial loss in the feature space to train the predictor. Our method can predict about 20 seconds into the future and provides better results compared to Denton and Fergus (2018) and Finn et al. (2016) on the Human 3.6M dataset.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wichers18a/wichers18a.pdf",
        "supp": "",
        "pdf_size": 1053318,
        "gs_citation": 164,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14642775681724463574&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Google Brain, Mountain View, CA, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Google Brain, Mountain View, CA, USA; Google Brain, Mountain View, CA, USA",
        "aff_domain": "google.com; ; ; ",
        "email": "google.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/wichers18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Google;University of Michigan",
        "aff_unique_dep": "Google Brain;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://brain.google.com;https://www.umich.edu",
        "aff_unique_abbr": "Google Brain;UM",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Mountain View;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Hierarchical Multi-Label Classification Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2306",
        "id": "2306",
        "author_site": "Jonatas Wehrmann, Ricardo Cerri, Rodrigo Barros",
        "author": "Jonatas Wehrmann; Ricardo Cerri; Rodrigo Barros",
        "abstract": "One of the most challenging machine learning problems is a particular case of data classification in which classes are hierarchically structured and objects can be assigned to multiple paths of the class hierarchy at the same time. This task is known as hierarchical multi-label classification (HMC), with applications in text classification, image annotation, and in bioinformatics problems such as protein function prediction. In this paper, we propose novel neural network architectures for HMC called HMCN, capable of simultaneously optimizing local and global loss functions for discovering local hierarchical class-relationships and global information from the entire class hierarchy while penalizing hierarchical violations. We evaluate its performance in 21 datasets from four distinct domains, and we compare it against the current HMC state-of-the-art approaches. Results show that HMCN substantially outperforms all baselines with statistical significance, arising as the novel state-of-the-art for HMC.",
        "bibtex": "@InProceedings{pmlr-v80-wehrmann18a,\n  title = \t {Hierarchical Multi-Label Classification Networks},\n  author =       {Wehrmann, Jonatas and Cerri, Ricardo and Barros, Rodrigo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5075--5084},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wehrmann18a/wehrmann18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wehrmann18a.html},\n  abstract = \t {One of the most challenging machine learning problems is a particular case of data classification in which classes are hierarchically structured and objects can be assigned to multiple paths of the class hierarchy at the same time. This task is known as hierarchical multi-label classification (HMC), with applications in text classification, image annotation, and in bioinformatics problems such as protein function prediction. In this paper, we propose novel neural network architectures for HMC called HMCN, capable of simultaneously optimizing local and global loss functions for discovering local hierarchical class-relationships and global information from the entire class hierarchy while penalizing hierarchical violations. We evaluate its performance in 21 datasets from four distinct domains, and we compare it against the current HMC state-of-the-art approaches. Results show that HMCN substantially outperforms all baselines with statistical significance, arising as the novel state-of-the-art for HMC.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wehrmann18a/wehrmann18a.pdf",
        "supp": "",
        "pdf_size": 395892,
        "gs_citation": 411,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9666568380808090584&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "School of Technology, Pontif\u00edcia Universidade Cat\u00f3lica do Rio Grande do Sul; Universidade Federal de S\u00e3o Carlos; School of Technology, Pontif\u00edcia Universidade Cat\u00f3lica do Rio Grande do Sul",
        "aff_domain": "pucrs.br; ;pucrs.br",
        "email": "pucrs.br; ;pucrs.br",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wehrmann18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Pontif\u00edcia Universidade Cat\u00f3lica do Rio Grande do Sul;Universidade Federal de S\u00e3o Carlos",
        "aff_unique_dep": "School of Technology;",
        "aff_unique_url": "https://www.pucrs.br;http://www.ufscar.br",
        "aff_unique_abbr": "PUCRS;UFSCar",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "title": "Hierarchical Text Generation and Planning for Strategic Dialogue",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2257",
        "id": "2257",
        "author_site": "Denis Yarats, Mike Lewis",
        "author": "Denis Yarats; Mike Lewis",
        "abstract": "End-to-end models for goal-orientated dialogue are challenging to train, because linguistic and strategic aspects are entangled in latent state vectors. We introduce an approach to learning representations of messages in dialogues by maximizing the likelihood of subsequent sentences and actions, which decouples the semantics of the dialogue utterance from its linguistic realization. We then use these latent sentence representations for hierarchical language generation, planning and reinforcement learning. Experiments show that our approach increases the end-task reward achieved by the model, improves the effectiveness of long-term planning using rollouts, and allows self-play reinforcement learning to improve decision making without diverging from human language. Our hierarchical latent-variable model outperforms previous work both linguistically and strategically.",
        "bibtex": "@InProceedings{pmlr-v80-yarats18a,\n  title = \t {Hierarchical Text Generation and Planning for Strategic Dialogue},\n  author =       {Yarats, Denis and Lewis, Mike},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5591--5599},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yarats18a/yarats18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yarats18a.html},\n  abstract = \t {End-to-end models for goal-orientated dialogue are challenging to train, because linguistic and strategic aspects are entangled in latent state vectors. We introduce an approach to learning representations of messages in dialogues by maximizing the likelihood of subsequent sentences and actions, which decouples the semantics of the dialogue utterance from its linguistic realization. We then use these latent sentence representations for hierarchical language generation, planning and reinforcement learning. Experiments show that our approach increases the end-task reward achieved by the model, improves the effectiveness of long-term planning using rollouts, and allows self-play reinforcement learning to improve decision making without diverging from human language. Our hierarchical latent-variable model outperforms previous work both linguistically and strategically.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yarats18a/yarats18a.pdf",
        "supp": "",
        "pdf_size": 574288,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9420783538301927247&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Facebook AI Research; Facebook AI Research",
        "aff_domain": "fb.com; ",
        "email": "fb.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/yarats18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "High Performance Zero-Memory Overhead Direct Convolutions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2341",
        "id": "2341",
        "author_site": "Jiyuan Zhang, Franz Franchetti, Tze Meng Low",
        "author": "Jiyuan Zhang; Franz Franchetti; Tze Meng Low",
        "abstract": "The computation of convolution layers in deep neural networks typically rely on high performance routines that trade space for time by using additional memory (either for packing purposes or required as part of the algorithm) to improve performance. The problems with such an approach are two-fold. First, these routines incur additional memory overhead which reduces the overall size of the network that can fit on embedded devices with limited memory capacity. Second, these high performance routines were not optimized for performing convolution, which means that the performance obtained is usually less than conventionally expected. In this paper, we demonstrate that direct convolution, when implemented correctly, eliminates all memory overhead, and yields performance that is between 10% to 400% times better than existing high performance implementations of convolution layers on conventional and embedded CPU architectures. We also show that a high performance direct convolution exhibits better scaling performance, i.e. suffers less performance drop, when increasing the number of threads.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18d,\n  title = \t {High Performance Zero-Memory Overhead Direct Convolutions},\n  author =       {Zhang, Jiyuan and Franchetti, Franz and Low, Tze Meng},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5776--5785},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18d/zhang18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18d.html},\n  abstract = \t {The computation of convolution layers in deep neural networks typically rely on high performance routines that trade space for time by using additional memory (either for packing purposes or required as part of the algorithm) to improve performance. The problems with such an approach are two-fold. First, these routines incur additional memory overhead which reduces the overall size of the network that can fit on embedded devices with limited memory capacity. Second, these high performance routines were not optimized for performing convolution, which means that the performance obtained is usually less than conventionally expected. In this paper, we demonstrate that direct convolution, when implemented correctly, eliminates all memory overhead, and yields performance that is between 10% to 400% times better than existing high performance implementations of convolution layers on conventional and embedded CPU architectures. We also show that a high performance direct convolution exhibits better scaling performance, i.e. suffers less performance drop, when increasing the number of threads.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18d/zhang18d.pdf",
        "supp": "",
        "pdf_size": 1892035,
        "gs_citation": 107,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9830641149530846622&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, USA",
        "aff_domain": "andrew.cmu.edu; ; ",
        "email": "andrew.cmu.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhang18d.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2188",
        "id": "2188",
        "author_site": "Tim Pearce, Alexandra Brintrup, Mohamed Zaki, Andy Neely",
        "author": "Tim Pearce; Alexandra Brintrup; Mohamed Zaki; Andy Neely",
        "abstract": "This paper considers the generation of prediction intervals (PIs) by neural networks for quantifying uncertainty in regression tasks. It is axiomatic that high-quality PIs should be as narrow as possible, whilst capturing a specified portion of data. We derive a loss function directly from this axiom that requires no distributional assumption. We show how its form derives from a likelihood principle, that it can be used with gradient descent, and that model uncertainty is accounted for in ensembled form. Benchmark experiments show the method outperforms current state-of-the-art uncertainty quantification methods, reducing average PI width by over 10%.",
        "bibtex": "@InProceedings{pmlr-v80-pearce18a,\n  title = \t {High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach},\n  author =       {Pearce, Tim and Brintrup, Alexandra and Zaki, Mohamed and Neely, Andy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4075--4084},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pearce18a/pearce18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pearce18a.html},\n  abstract = \t {This paper considers the generation of prediction intervals (PIs) by neural networks for quantifying uncertainty in regression tasks. It is axiomatic that high-quality PIs should be as narrow as possible, whilst capturing a specified portion of data. We derive a loss function directly from this axiom that requires no distributional assumption. We show how its form derives from a likelihood principle, that it can be used with gradient descent, and that model uncertainty is accounted for in ensembled form. Benchmark experiments show the method outperforms current state-of-the-art uncertainty quantification methods, reducing average PI width by over 10%.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pearce18a/pearce18a.pdf",
        "supp": "",
        "pdf_size": 645584,
        "gs_citation": 374,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7300123517160820508&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Engineering, University of Cambridge, UK+Alan Turing Institute, UK; Department of Engineering, University of Cambridge, UK; Department of Engineering, University of Cambridge, UK; Department of Engineering, University of Cambridge, UK",
        "aff_domain": "cam.ac.uk; ; ; ",
        "email": "cam.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/pearce18a.html",
        "aff_unique_index": "0+1;0;0;0",
        "aff_unique_norm": "University of Cambridge;Alan Turing Institute",
        "aff_unique_dep": "Department of Engineering;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;ATI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Hyperbolic Entailment Cones for Learning Hierarchical Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2487",
        "id": "2487",
        "author_site": "Octavian-Eugen Ganea, Gary Becigneul, Thomas Hofmann",
        "author": "Octavian Ganea; Gary Becigneul; Thomas Hofmann",
        "abstract": "Learning graph representations via low-dimensional embeddings that preserve relevant network properties is an important class of problems in machine learning. We here present a novel method to embed directed acyclic graphs. Following prior work, we first advocate for using hyperbolic spaces which provably model tree-like structures better than Euclidean geometry. Second, we view hierarchical relations as partial orders defined using a family of nested geodesically convex cones. We prove that these entailment cones admit an optimal shape with a closed form expression both in the Euclidean and hyperbolic spaces, and they canonically define the embedding learning process. Experiments show significant improvements of our method over strong recent baselines both in terms of representational capacity and generalization.",
        "bibtex": "@InProceedings{pmlr-v80-ganea18a,\n  title = \t {Hyperbolic Entailment Cones for Learning Hierarchical Embeddings},\n  author =       {Ganea, Octavian and Becigneul, Gary and Hofmann, Thomas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1646--1655},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ganea18a/ganea18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ganea18a.html},\n  abstract = \t {Learning graph representations via low-dimensional embeddings that preserve relevant network properties is an important class of problems in machine learning. We here present a novel method to embed directed acyclic graphs. Following prior work, we first advocate for using hyperbolic spaces which provably model tree-like structures better than Euclidean geometry. Second, we view hierarchical relations as partial orders defined using a family of nested geodesically convex cones. We prove that these entailment cones admit an optimal shape with a closed form expression both in the Euclidean and hyperbolic spaces, and they canonically define the embedding learning process. Experiments show significant improvements of our method over strong recent baselines both in terms of representational capacity and generalization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ganea18a/ganea18a.pdf",
        "supp": "",
        "pdf_size": 1625071,
        "gs_citation": 332,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18219062814600908733&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland",
        "aff_domain": "inf.ethz.ch;inf.ethz.ch;inf.ethz.ch",
        "email": "inf.ethz.ch;inf.ethz.ch;inf.ethz.ch",
        "github": "",
        "project": "http://geometricdeeplearning.com/",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ganea18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2174",
        "id": "2174",
        "author_site": "Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Vlad Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane Legg, Koray Kavukcuoglu",
        "author": "Lasse Espeholt; Hubert Soyer; Remi Munos; Karen Simonyan; Vlad Mnih; Tom Ward; Yotam Doron; Vlad Firoiu; Tim Harley; Iain Dunning; Shane Legg; Koray Kavukcuoglu",
        "abstract": "In this work we aim to solve a large collection of tasks using a single reinforcement learning agent with a single set of parameters. A key challenge is to handle the increased amount of data and extended training time. We have developed a new distributed agent IMPALA (Importance Weighted Actor-Learner Architecture) that not only uses resources more efficiently in single-machine training but also scales to thousands of machines without sacrificing data efficiency or resource utilisation. We achieve stable learning at high throughput by combining decoupled acting and learning with a novel off-policy correction method called V-trace. We demonstrate the effectiveness of IMPALA for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the DeepMind Lab environment (Beattie et al., 2016)) and Atari57 (all available Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our results show that IMPALA is able to achieve better performance than previous agents with less data, and crucially exhibits positive transfer between tasks as a result of its multi-task approach.",
        "bibtex": "@InProceedings{pmlr-v80-espeholt18a,\n  title = \t {{IMPALA}: Scalable Distributed Deep-{RL} with Importance Weighted Actor-Learner Architectures},\n  author =       {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and Legg, Shane and Kavukcuoglu, Koray},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1407--1416},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/espeholt18a/espeholt18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/espeholt18a.html},\n  abstract = \t {In this work we aim to solve a large collection of tasks using a single reinforcement learning agent with a single set of parameters. A key challenge is to handle the increased amount of data and extended training time. We have developed a new distributed agent IMPALA (Importance Weighted Actor-Learner Architecture) that not only uses resources more efficiently in single-machine training but also scales to thousands of machines without sacrificing data efficiency or resource utilisation. We achieve stable learning at high throughput by combining decoupled acting and learning with a novel off-policy correction method called V-trace. We demonstrate the effectiveness of IMPALA for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the DeepMind Lab environment (Beattie et al., 2016)) and Atari57 (all available Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our results show that IMPALA is able to achieve better performance than previous agents with less data, and crucially exhibits positive transfer between tasks as a result of its multi-task approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/espeholt18a/espeholt18a.pdf",
        "supp": "",
        "pdf_size": 2690435,
        "gs_citation": 1853,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14673826846490570917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 12,
        "oa": "https://proceedings.mlr.press/v80/espeholt18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind Technologies",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "INSPECTRE: Privately Estimating the Unseen",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1872",
        "id": "1872",
        "author_site": "Jayadev Acharya, Gautam Kamath, Ziteng Sun, Huanyu Zhang",
        "author": "Jayadev Acharya; Gautam Kamath; Ziteng Sun; Huanyu Zhang",
        "abstract": "We develop differentially private methods for estimating various distributional properties. Given a sample from a discrete distribution p, some functional f, and accuracy and privacy parameters alpha and epsilon, the goal is to estimate f(p) up to accuracy alpha, while maintaining epsilon-differential privacy of the sample. We prove almost-tight bounds on the sample size required for this problem for several functionals of interest, including support size, support coverage, and entropy. We show that the cost of privacy is negligible in a variety of settings, both theoretically and experimentally. Our methods are based on a sensitivity analysis of several state-of-the-art methods for estimating these properties with sublinear sample complexities",
        "bibtex": "@InProceedings{pmlr-v80-acharya18a,\n  title = \t {{INSPECTRE}: Privately Estimating the Unseen},\n  author =       {Acharya, Jayadev and Kamath, Gautam and Sun, Ziteng and Zhang, Huanyu},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {30--39},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/acharya18a/acharya18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/acharya18a.html},\n  abstract = \t {We develop differentially private methods for estimating various distributional properties. Given a sample from a discrete distribution p, some functional f, and accuracy and privacy parameters alpha and epsilon, the goal is to estimate f(p) up to accuracy alpha, while maintaining epsilon-differential privacy of the sample. We prove almost-tight bounds on the sample size required for this problem for several functionals of interest, including support size, support coverage, and entropy. We show that the cost of privacy is negligible in a variety of settings, both theoretically and experimentally. Our methods are based on a sensitivity analysis of several state-of-the-art methods for estimating these properties with sublinear sample complexities}\n}",
        "pdf": "http://proceedings.mlr.press/v80/acharya18a/acharya18a.pdf",
        "supp": "",
        "pdf_size": 4548860,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17397677821917989513&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "ECE, Cornell University; EECS & CSAIL, Massachusetts Institute of Technology; ECE, Cornell University; ECE, Cornell University",
        "aff_domain": "cornell.edu;csail.mit.edu;cornell.edu;cornell.edu",
        "email": "cornell.edu;csail.mit.edu;cornell.edu;cornell.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/acharya18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Cornell University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Electrical and Computer Engineering;EECS & CSAIL",
        "aff_unique_url": "https://www.cornell.edu;https://web.mit.edu",
        "aff_unique_abbr": "Cornell;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Image Transformer",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2430",
        "id": "2430",
        "author_site": "Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, Dustin Tran",
        "author": "Niki Parmar; Ashish Vaswani; Jakob Uszkoreit; Lukasz Kaiser; Noam Shazeer; Alexander Ku; Dustin Tran",
        "abstract": "Image generation has been successfully cast as an autoregressive sequence generation or transformation problem. Recent work has shown that self-attention is an effective way of modeling textual sequences. In this work, we generalize a recently proposed model architecture based on self-attention, the Transformer, to a sequence modeling formulation of image generation with a tractable likelihood. By restricting the self-attention mechanism to attend to local neighborhoods we significantly increase the size of images the model can process in practice, despite maintaining significantly larger receptive fields per layer than typical convolutional neural networks. While conceptually simple, our generative models significantly outperform the current state of the art in image generation on ImageNet, improving the best published negative log-likelihood on ImageNet from 3.83 to 3.77. We also present results on image super-resolution with a large magnification ratio, applying an encoder-decoder configuration of our architecture. In a human evaluation study, we find that images generated by our super-resolution model fool human observers three times more often than the previous state of the art.",
        "bibtex": "@InProceedings{pmlr-v80-parmar18a,\n  title = \t {Image Transformer},\n  author =       {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4055--4064},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/parmar18a/parmar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/parmar18a.html},\n  abstract = \t {Image generation has been successfully cast as an autoregressive sequence generation or transformation problem. Recent work has shown that self-attention is an effective way of modeling textual sequences. In this work, we generalize a recently proposed model architecture based on self-attention, the Transformer, to a sequence modeling formulation of image generation with a tractable likelihood. By restricting the self-attention mechanism to attend to local neighborhoods we significantly increase the size of images the model can process in practice, despite maintaining significantly larger receptive fields per layer than typical convolutional neural networks. While conceptually simple, our generative models significantly outperform the current state of the art in image generation on ImageNet, improving the best published negative log-likelihood on ImageNet from 3.83 to 3.77. We also present results on image super-resolution with a large magnification ratio, applying an encoder-decoder configuration of our architecture. In a human evaluation study, we find that images generated by our super-resolution model fool human observers three times more often than the previous state of the art.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/parmar18a/parmar18a.pdf",
        "supp": "",
        "pdf_size": 1040904,
        "gs_citation": 2292,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7958557148623619738&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Google Brain, Mountain View, USA; Google Brain, Mountain View, USA; Google Brain, Mountain View, USA; Google Brain, Mountain View, USA; Google Brain, Mountain View, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley + Google Brain, Mountain View, USA; Google AI, Mountain View, USA",
        "aff_domain": "google.com;google.com;google.com; ; ; ;google.com",
        "email": "google.com;google.com;google.com; ; ; ;google.com",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/parmar18a.html",
        "aff_unique_index": "0;0;0;0;0;1+0;0",
        "aff_unique_norm": "Google;University of California, Berkeley",
        "aff_unique_dep": "Google Brain;Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://brain.google.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Google Brain;UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;1+0;0",
        "aff_campus_unique": "Mountain View;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Implicit Quantile Networks for Distributional Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2450",
        "id": "2450",
        "author_site": "Will Dabney, Georg Ostrovski, David Silver, Remi Munos",
        "author": "Will Dabney; Georg Ostrovski; David Silver; Remi Munos",
        "abstract": "In this work, we build on recent advances in distributional reinforcement learning to give a generally applicable, flexible, and state-of-the-art distributional variant of DQN. We achieve this by using quantile regression to approximate the full quantile function for the state-action return distribution. By reparameterizing a distribution over the sample space, this yields an implicitly defined return distribution and gives rise to a large class of risk-sensitive policies. We demonstrate improved performance on the 57 Atari 2600 games in the ALE, and use our algorithm\u2019s implicitly defined distributions to study the effects of risk-sensitive policies in Atari games.",
        "bibtex": "@InProceedings{pmlr-v80-dabney18a,\n  title = \t {Implicit Quantile Networks for Distributional Reinforcement Learning},\n  author =       {Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Remi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1096--1105},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dabney18a/dabney18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dabney18a.html},\n  abstract = \t {In this work, we build on recent advances in distributional reinforcement learning to give a generally applicable, flexible, and state-of-the-art distributional variant of DQN. We achieve this by using quantile regression to approximate the full quantile function for the state-action return distribution. By reparameterizing a distribution over the sample space, this yields an implicitly defined return distribution and gives rise to a large class of risk-sensitive policies. We demonstrate improved performance on the 57 Atari 2600 games in the ALE, and use our algorithm\u2019s implicitly defined distributions to study the effects of risk-sensitive policies in Atari games.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dabney18a/dabney18a.pdf",
        "supp": "",
        "pdf_size": 1368555,
        "gs_citation": 713,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18024292778151689886&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "google.com;google.com; ; ",
        "email": "google.com;google.com; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/dabney18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1893",
        "id": "1893",
        "author_site": "Cong Ma, Kaizheng Wang, Yuejie Chi, Yuxin Chen",
        "author": "Cong Ma; Kaizheng Wang; Yuejie Chi; Yuxin Chen",
        "abstract": "Recent years have seen a flurry of activities in designing provably efficient nonconvex optimization procedures for solving statistical estimation problems. For various problems like phase retrieval or low-rank matrix completion, state-of-the-art nonconvex procedures require proper regularization (e.g.\u00a0trimming, regularized cost, projection) in order to guarantee fast convergence. When it comes to vanilla procedures such as gradient descent, however, prior theory either recommends highly conservative learning rates to avoid overshooting, or completely lacks performance guarantees. This paper uncovers a striking phenomenon in several nonconvex problems: even in the absence of explicit regularization, gradient descent follows a trajectory staying within a basin that enjoys nice geometry, consisting of points incoherent with the sampling mechanism. This \u201cimplicit regularization\u201d feature allows gradient descent to proceed in a far more aggressive fashion without overshooting, which in turn results in substantial computational savings. Focusing on two statistical estimation problems, i.e.\u00a0solving random quadratic systems of equations and low-rank matrix completion, we establish that gradient descent achieves near-optimal statistical and computational guarantees without explicit regularization. As a byproduct, for noisy matrix completion, we demonstrate that gradient descent enables optimal control of both entrywise and spectral-norm errors.",
        "bibtex": "@InProceedings{pmlr-v80-ma18c,\n  title = \t {Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion},\n  author =       {Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3345--3354},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ma18c/ma18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ma18c.html},\n  abstract = \t {Recent years have seen a flurry of activities in designing provably efficient nonconvex optimization procedures for solving statistical estimation problems. For various problems like phase retrieval or low-rank matrix completion, state-of-the-art nonconvex procedures require proper regularization (e.g.\u00a0trimming, regularized cost, projection) in order to guarantee fast convergence. When it comes to vanilla procedures such as gradient descent, however, prior theory either recommends highly conservative learning rates to avoid overshooting, or completely lacks performance guarantees. This paper uncovers a striking phenomenon in several nonconvex problems: even in the absence of explicit regularization, gradient descent follows a trajectory staying within a basin that enjoys nice geometry, consisting of points incoherent with the sampling mechanism. This \u201cimplicit regularization\u201d feature allows gradient descent to proceed in a far more aggressive fashion without overshooting, which in turn results in substantial computational savings. Focusing on two statistical estimation problems, i.e.\u00a0solving random quadratic systems of equations and low-rank matrix completion, we establish that gradient descent achieves near-optimal statistical and computational guarantees without explicit regularization. As a byproduct, for noisy matrix completion, we demonstrate that gradient descent enables optimal control of both entrywise and spectral-norm errors.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ma18c/ma18c.pdf",
        "supp": "",
        "pdf_size": 1082136,
        "gs_citation": 334,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2925935119512359218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 22,
        "aff": "Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ 08544, USA; Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ 08544, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA; Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA",
        "aff_domain": "princeton.edu; ; ; ",
        "email": "princeton.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ma18c.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Princeton University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Operations Research and Financial Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.princeton.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Princeton;CMU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Princeton;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Importance Weighted Transfer of Samples in Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2008",
        "id": "2008",
        "author_site": "Andrea Tirinzoni, Andrea Sessa, Matteo Pirotta, Marcello Restelli",
        "author": "Andrea Tirinzoni; Andrea Sessa; Matteo Pirotta; Marcello Restelli",
        "abstract": "We consider the transfer of experience samples (i.e., tuples < s, a, s\u2019, r >) in reinforcement learning (RL), collected from a set of source tasks to improve the learning process in a given target task. Most of the related approaches focus on selecting the most relevant source samples for solving the target task, but then all the transferred samples are used without considering anymore the discrepancies between the task models. In this paper, we propose a model-based technique that automatically estimates the relevance (importance weight) of each source sample for solving the target task. In the proposed approach, all the samples are transferred and used by a batch RL algorithm to solve the target task, but their contribution to the learning process is proportional to their importance weight. By extending the results for importance weighting provided in supervised learning literature, we develop a finite-sample analysis of the proposed batch RL algorithm. Furthermore, we empirically compare the proposed algorithm to state-of-the-art approaches, showing that it achieves better learning performance and is very robust to negative transfer, even when some source tasks are significantly different from the target task.",
        "bibtex": "@InProceedings{pmlr-v80-tirinzoni18a,\n  title = \t {Importance Weighted Transfer of Samples in Reinforcement Learning},\n  author =       {Tirinzoni, Andrea and Sessa, Andrea and Pirotta, Matteo and Restelli, Marcello},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4936--4945},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tirinzoni18a/tirinzoni18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tirinzoni18a.html},\n  abstract = \t {We consider the transfer of experience samples (i.e., tuples < s, a, s\u2019, r >) in reinforcement learning (RL), collected from a set of source tasks to improve the learning process in a given target task. Most of the related approaches focus on selecting the most relevant source samples for solving the target task, but then all the transferred samples are used without considering anymore the discrepancies between the task models. In this paper, we propose a model-based technique that automatically estimates the relevance (importance weight) of each source sample for solving the target task. In the proposed approach, all the samples are transferred and used by a batch RL algorithm to solve the target task, but their contribution to the learning process is proportional to their importance weight. By extending the results for importance weighting provided in supervised learning literature, we develop a finite-sample analysis of the proposed batch RL algorithm. Furthermore, we empirically compare the proposed algorithm to state-of-the-art approaches, showing that it achieves better learning performance and is very robust to negative transfer, even when some source tasks are significantly different from the target task.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tirinzoni18a/tirinzoni18a.pdf",
        "supp": "",
        "pdf_size": 436709,
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14197953519153719258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy; SequeL Team, INRIA Lille, France; Politecnico di Milano, Milan, Italy",
        "aff_domain": "polimi.it; ; ; ",
        "email": "polimi.it; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/tirinzoni18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Politecnico di Milano;INRIA Lille",
        "aff_unique_dep": ";SequeL Team",
        "aff_unique_url": "https://www.polimi.it;https://www.inria.fr/en",
        "aff_unique_abbr": "Polimi;INRIA",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Milan;Lille",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Italy;France"
    },
    {
        "title": "Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2353",
        "id": "2353",
        "author_site": "Marc Abeille, Alessandro Lazaric",
        "author": "Marc Abeille; Alessandro Lazaric",
        "abstract": "Thompson sampling (TS) is an effective approach to trade off exploration and exploration in reinforcement learning. Despite its empirical success and recent advances, its theoretical analysis is often limited to the Bayesian setting, finite state-action spaces, or finite-horizon problems. In this paper, we study an instance of TS in the challenging setting of the infinite-horizon linear quadratic (LQ) control, which models problems with continuous state-action variables, linear dynamics, and quadratic cost. In particular, we analyze the regret in the frequentist sense (i.e., for a fixed unknown environment) in one-dimensional systems. We derive the first $O(\\sqrt{T})$ frequentist regret bound for this problem, thus significantly improving the $O(T^{2/3})$ bound of Abeille & Lazaric (2017) and matching the frequentist performance derived by Abbasi-Yadkori & Szepesv\u00e1ri (2011) for an optimistic approach and the Bayesian result Ouyang et al. (2017) We obtain this result by developing a novel bound on the regret due to policy switches, which holds for LQ systems of any dimensionality and it allows updating the parameters and the policy at each step, thus overcoming previous limitations due to lazy updates. Finally, we report numerical simulations supporting the conjecture that our result extends to multi-dimensional systems.",
        "bibtex": "@InProceedings{pmlr-v80-abeille18a,\n  title = \t {Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems},\n  author =       {Abeille, Marc and Lazaric, Alessandro},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1--9},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/abeille18a/abeille18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/abeille18a.html},\n  abstract = \t {Thompson sampling (TS) is an effective approach to trade off exploration and exploration in reinforcement learning. Despite its empirical success and recent advances, its theoretical analysis is often limited to the Bayesian setting, finite state-action spaces, or finite-horizon problems. In this paper, we study an instance of TS in the challenging setting of the infinite-horizon linear quadratic (LQ) control, which models problems with continuous state-action variables, linear dynamics, and quadratic cost. In particular, we analyze the regret in the frequentist sense (i.e., for a fixed unknown environment) in one-dimensional systems. We derive the first $O(\\sqrt{T})$ frequentist regret bound for this problem, thus significantly improving the $O(T^{2/3})$ bound of Abeille & Lazaric (2017) and matching the frequentist performance derived by Abbasi-Yadkori & Szepesv\u00e1ri (2011) for an optimistic approach and the Bayesian result Ouyang et al. (2017) We obtain this result by developing a novel bound on the regret due to policy switches, which holds for LQ systems of any dimensionality and it allows updating the parameters and the policy at each step, thus overcoming previous limitations due to lazy updates. Finally, we report numerical simulations supporting the conjecture that our result extends to multi-dimensional systems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/abeille18a/abeille18a.pdf",
        "supp": "",
        "pdf_size": 355481,
        "gs_citation": 115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8926925568231499579&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Criteo, Paris, France; Facebook AI Research, Paris, France",
        "aff_domain": "criteo.com; ",
        "email": "criteo.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/abeille18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Criteo;Meta",
        "aff_unique_dep": ";Facebook AI Research",
        "aff_unique_url": "https://www.criteo.com;https://research.facebook.com",
        "aff_unique_abbr": "Criteo;FAIR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Improved Training of Generative Adversarial Networks Using Representative Features",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1888",
        "id": "1888",
        "author_site": "Duhyeon Bang, Hyunjung Shim",
        "author": "Duhyeon Bang; Hyunjung Shim",
        "abstract": "Despite the success of generative adversarial networks (GANs) for image generation, the trade-off between visual quality and image diversity remains a significant issue. This paper achieves both aims simultaneously by improving the stability of training GANs. The key idea of the proposed approach is to implicitly regularize the discriminator using representative features. Focusing on the fact that standard GAN minimizes reverse Kullback-Leibler (KL) divergence, we transfer the representative feature, which is extracted from the data distribution using a pre-trained autoencoder (AE), to the discriminator of standard GANs. Because the AE learns to minimize forward KL divergence, our GAN training with representative features is influenced by both reverse and forward KL divergence. Consequently, the proposed approach is verified to improve visual quality and diversity of state of the art GANs using extensive evaluations.",
        "bibtex": "@InProceedings{pmlr-v80-bang18a,\n  title = \t {Improved Training of Generative Adversarial Networks Using Representative Features},\n  author =       {Bang, Duhyeon and Shim, Hyunjung},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {433--442},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bang18a/bang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bang18a.html},\n  abstract = \t {Despite the success of generative adversarial networks (GANs) for image generation, the trade-off between visual quality and image diversity remains a significant issue. This paper achieves both aims simultaneously by improving the stability of training GANs. The key idea of the proposed approach is to implicitly regularize the discriminator using representative features. Focusing on the fact that standard GAN minimizes reverse Kullback-Leibler (KL) divergence, we transfer the representative feature, which is extracted from the data distribution using a pre-trained autoencoder (AE), to the discriminator of standard GANs. Because the AE learns to minimize forward KL divergence, our GAN training with representative features is influenced by both reverse and forward KL divergence. Consequently, the proposed approach is verified to improve visual quality and diversity of state of the art GANs using extensive evaluations.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bang18a/bang18a.pdf",
        "supp": "",
        "pdf_size": 3745150,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4071144111043455824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "School of Integrated Technology, Yonsei University, South Korea; School of Integrated Technology, Yonsei University, South Korea",
        "aff_domain": "yonsei.ac.kr;yonsei.ac.kr",
        "email": "yonsei.ac.kr;yonsei.ac.kr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/bang18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Yonsei University",
        "aff_unique_dep": "School of Integrated Technology",
        "aff_unique_url": "https://www.yonsei.ac.kr",
        "aff_unique_abbr": "Yonsei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Improved large-scale graph learning through ridge spectral sparsification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2371",
        "id": "2371",
        "author_site": "Daniele Calandriello, Alessandro Lazaric, Ioannis Koutis, Michal Valko",
        "author": "Daniele Calandriello; Alessandro Lazaric; Ioannis Koutis; Michal Valko",
        "abstract": "The representation and learning benefits of methods based on graph Laplacians, such as Laplacian smoothing or harmonic function solution for semi-supervised learning (SSL), are empirically and theoretically well supported. Nonetheless, the exact versions of these methods scale poorly with the number of nodes $n$ of the graph. In this paper, we combine a spectral sparsification routine with Laplacian learning. Given a graph $G$ as input, our algorithm computes a sparsifier in a distributed way in $O(n\\log^3(n))$ time, $O(m\\log^3(n))$ work and $O(n\\log(n))$ memory, using only $\\log(n)$ rounds of communication. Furthermore, motivated by the regularization often employed in learning algorithms, we show that constructing sparsifiers that preserve the spectrum of the Laplacian only up to the regularization level may drastically reduce the size of the final graph. By constructing a spectrally-similar graph, we are able to bound the error induced by the sparsification for a variety of downstream tasks (e.g., SSL). We empirically validate the theoretical guarantees on Amazon co-purchase graph and compare to the state-of-the-art heuristics.",
        "bibtex": "@InProceedings{pmlr-v80-calandriello18a,\n  title = \t {Improved large-scale graph learning through ridge spectral sparsification},\n  author =       {Calandriello, Daniele and Lazaric, Alessandro and Koutis, Ioannis and Valko, Michal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {688--697},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/calandriello18a/calandriello18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/calandriello18a.html},\n  abstract = \t {The representation and learning benefits of methods based on graph Laplacians, such as Laplacian smoothing or harmonic function solution for semi-supervised learning (SSL), are empirically and theoretically well supported. Nonetheless, the exact versions of these methods scale poorly with the number of nodes $n$ of the graph. In this paper, we combine a spectral sparsification routine with Laplacian learning. Given a graph $G$ as input, our algorithm computes a sparsifier in a distributed way in $O(n\\log^3(n))$ time, $O(m\\log^3(n))$ work and $O(n\\log(n))$ memory, using only $\\log(n)$ rounds of communication. Furthermore, motivated by the regularization often employed in learning algorithms, we show that constructing sparsifiers that preserve the spectrum of the Laplacian only up to the regularization level may drastically reduce the size of the final graph. By constructing a spectrally-similar graph, we are able to bound the error induced by the sparsification for a variety of downstream tasks (e.g., SSL). We empirically validate the theoretical guarantees on Amazon co-purchase graph and compare to the state-of-the-art heuristics.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/calandriello18a/calandriello18a.pdf",
        "supp": "",
        "pdf_size": 544233,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13857197621113219797&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "SequeL team, INRIA Lille - Nord Europe, France+LCSL, IIT, Italy, and MIT, USA; New Jersey Institute of Technology, USA; Facebook AI Research, Paris, France; SequeL team, INRIA Lille - Nord Europe, France",
        "aff_domain": "iit.it; ; ; ",
        "email": "iit.it; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/calandriello18a.html",
        "aff_unique_index": "0+1;2;3;0",
        "aff_unique_norm": "INRIA Lille - Nord Europe;Istituto Italiano di Tecnologia (IIT);New Jersey Institute of Technology;Meta",
        "aff_unique_dep": "SequeL team;LCSL;;Facebook AI Research",
        "aff_unique_url": "https://www.inria.fr/en/centre/lille-nord-europe;https://www.iit.it;https://www.njit.edu;https://research.facebook.com",
        "aff_unique_abbr": "INRIA;IIT;NJIT;FAIR",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Lille;;Paris",
        "aff_country_unique_index": "0+1;2;0;0",
        "aff_country_unique": "France;Italy;United States"
    },
    {
        "title": "Improved nearest neighbor search using auxiliary information and priority functions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2041",
        "id": "2041",
        "author_site": "Omid Keivani, Kaushik Sinha",
        "author": "Omid Keivani; Kaushik Sinha",
        "abstract": "Nearest neighbor search using random projection trees has recently been shown to achieve superior performance, in terms of better accuracy while retrieving less number of data points, compared to locality sensitive hashing based methods. However, to achieve acceptable nearest neighbor search accuracy for large scale applications, where number of data points and/or number of features can be very large, it requires users to maintain, store and search through large number of such independent random projection trees, which may be undesirable for many practical applications. To address this issue, in this paper we present different search strategies to improve nearest neighbor search performance of a single random projection tree. Our approach exploits properties of single and multiple random projections, which allows us to store meaningful auxiliary information at internal nodes of a random projection tree as well as to design priority functions to guide the search process that results in improved nearest neighbor search performance. Empirical results on multiple real world datasets show that our proposed method improves the search accuracy of a single tree compared to baseline methods.",
        "bibtex": "@InProceedings{pmlr-v80-keivani18a,\n  title = \t {Improved nearest neighbor search using auxiliary information and priority functions},\n  author =       {Keivani, Omid and Sinha, Kaushik},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2573--2581},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/keivani18a/keivani18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/keivani18a.html},\n  abstract = \t {Nearest neighbor search using random projection trees has recently been shown to achieve superior performance, in terms of better accuracy while retrieving less number of data points, compared to locality sensitive hashing based methods. However, to achieve acceptable nearest neighbor search accuracy for large scale applications, where number of data points and/or number of features can be very large, it requires users to maintain, store and search through large number of such independent random projection trees, which may be undesirable for many practical applications. To address this issue, in this paper we present different search strategies to improve nearest neighbor search performance of a single random projection tree. Our approach exploits properties of single and multiple random projections, which allows us to store meaningful auxiliary information at internal nodes of a random projection tree as well as to design priority functions to guide the search process that results in improved nearest neighbor search performance. Empirical results on multiple real world datasets show that our proposed method improves the search accuracy of a single tree compared to baseline methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/keivani18a/keivani18a.pdf",
        "supp": "",
        "pdf_size": 962719,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9630318934770005338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Electrical Engineering & Computer Science, Wichita State University, KS, USA; Department of Electrical Engineering & Computer Science, Wichita State University, KS, USA",
        "aff_domain": "wichita.edu;wichita.edu",
        "email": "wichita.edu;wichita.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/keivani18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Wichita State University",
        "aff_unique_dep": "Department of Electrical Engineering & Computer Science",
        "aff_unique_url": "https://www.wichita.edu",
        "aff_unique_abbr": "WSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wichita",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Improving Optimization for Models With Continuous Symmetry Breaking",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2360",
        "id": "2360",
        "author_site": "Robert Bamler, Stephan Mandt",
        "author": "Robert Bamler; Stephan Mandt",
        "abstract": "Many loss functions in representation learning are invariant under a continuous symmetry transformation. For example, the loss function of word embeddings (Mikolov et al., 2013) remains unchanged if we simultaneously rotate all word and context embedding vectors. We show that representation learning models for time series possess an approximate continuous symmetry that leads to slow convergence of gradient descent. We propose a new optimization algorithm that speeds up convergence using ideas from gauge theory in physics. Our algorithm leads to orders of magnitude faster convergence and to more interpretable representations, as we show for dynamic extensions of matrix factorization and word embedding models. We further present an example application of our proposed algorithm that translates modern words into their historic equivalents.",
        "bibtex": "@InProceedings{pmlr-v80-bamler18a,\n  title = \t {Improving Optimization for Models With Continuous Symmetry Breaking},\n  author =       {Bamler, Robert and Mandt, Stephan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {423--432},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bamler18a/bamler18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bamler18a.html},\n  abstract = \t {Many loss functions in representation learning are invariant under a continuous symmetry transformation. For example, the loss function of word embeddings (Mikolov et al., 2013) remains unchanged if we simultaneously rotate all word and context embedding vectors. We show that representation learning models for time series possess an approximate continuous symmetry that leads to slow convergence of gradient descent. We propose a new optimization algorithm that speeds up convergence using ideas from gauge theory in physics. Our algorithm leads to orders of magnitude faster convergence and to more interpretable representations, as we show for dynamic extensions of matrix factorization and word embedding models. We further present an example application of our proposed algorithm that translates modern words into their historic equivalents.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bamler18a/bamler18a.pdf",
        "supp": "",
        "pdf_size": 1326290,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16886812030798350071&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "aff": "1Disney Research, Glendale, CA, USA; 1Disney Research, Glendale, CA, USA",
        "aff_domain": "gmail.com;gmail.com",
        "email": "gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/bamler18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Disney Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://research.disney.com",
        "aff_unique_abbr": "Disney Research",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Glendale",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Improving Regression Performance with Distributional Losses",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2092",
        "id": "2092",
        "author_site": "Ehsan Imani, Martha White",
        "author": "Ehsan Imani; Martha White",
        "abstract": "There is growing evidence that converting targets to soft targets in supervised learning can provide considerable gains in performance. Much of this work has considered classification, converting hard zero-one values to soft labels\u2014such as by adding label noise, incorporating label ambiguity or using distillation. In parallel, there is some evidence from a regression setting in reinforcement learning that learning distributions can improve performance. In this work, we investigate the reasons for this improvement, in a regression setting. We introduce a novel distributional regression loss, and similarly find it significantly improves prediction accuracy. We investigate several common hypotheses, around reducing overfitting and improved representations. We instead find evidence for an alternative hypothesis: this loss is easier to optimize, with better behaved gradients, resulting in improved generalization. We provide theoretical support for this alternative hypothesis, by characterizing the norm of the gradients of this loss.",
        "bibtex": "@InProceedings{pmlr-v80-imani18a,\n  title = \t {Improving Regression Performance with Distributional Losses},\n  author =       {Imani, Ehsan and White, Martha},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2157--2166},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/imani18a/imani18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/imani18a.html},\n  abstract = \t {There is growing evidence that converting targets to soft targets in supervised learning can provide considerable gains in performance. Much of this work has considered classification, converting hard zero-one values to soft labels\u2014such as by adding label noise, incorporating label ambiguity or using distillation. In parallel, there is some evidence from a regression setting in reinforcement learning that learning distributions can improve performance. In this work, we investigate the reasons for this improvement, in a regression setting. We introduce a novel distributional regression loss, and similarly find it significantly improves prediction accuracy. We investigate several common hypotheses, around reducing overfitting and improved representations. We instead find evidence for an alternative hypothesis: this loss is easier to optimize, with better behaved gradients, resulting in improved generalization. We provide theoretical support for this alternative hypothesis, by characterizing the norm of the gradients of this loss.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/imani18a/imani18a.pdf",
        "supp": "",
        "pdf_size": 1338034,
        "gs_citation": 84,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14428870985087756452&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computing Science, University of Alberta, Edmonton; Department of Computing Science, University of Alberta, Edmonton",
        "aff_domain": "ualberta.ca;ualberta.ca",
        "email": "ualberta.ca;ualberta.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/imani18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Improving Sign Random Projections With Additional Information",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1896",
        "id": "1896",
        "author_site": "Keegan Kang, Wei Pin Wong",
        "author": "Keegan Kang; Weipin Wong",
        "abstract": "Sign random projections (SRP) is a technique which allows the user to quickly estimate the angular similarity and inner products between data. We propose using additional information to improve these estimates which is easy to implement and cost efficient. We prove that the variance of our estimator is lower than the variance of SRP. Our proposed method can also be used together with other modifications of SRP, such as Super-Bit LSH (SBLSH). We demonstrate the effectiveness of our method on the MNIST test dataset and the Gisette dataset. We discuss how our proposed method can be extended to random projections or even other hashing algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-kang18b,\n  title = \t {Improving Sign Random Projections With Additional Information},\n  author =       {Kang, Keegan and Wong, Weipin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2479--2487},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kang18b/kang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kang18b.html},\n  abstract = \t {Sign random projections (SRP) is a technique which allows the user to quickly estimate the angular similarity and inner products between data. We propose using additional information to improve these estimates which is easy to implement and cost efficient. We prove that the variance of our estimator is lower than the variance of SRP. Our proposed method can also be used together with other modifications of SRP, such as Super-Bit LSH (SBLSH). We demonstrate the effectiveness of our method on the MNIST test dataset and the Gisette dataset. We discuss how our proposed method can be extended to random projections or even other hashing algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kang18b/kang18b.pdf",
        "supp": "",
        "pdf_size": 4118545,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4936448943625835431&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Singapore University Of Technology And Design; Singapore University Of Technology And Design",
        "aff_domain": "sutd.edu.sg; ",
        "email": "sutd.edu.sg; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kang18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "title": "Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2245",
        "id": "2245",
        "author_site": "Borja de Balle Pigem, Yu-Xiang Wang",
        "author": "Borja Balle; Yu-Xiang Wang",
        "abstract": "The Gaussian mechanism is an essential building block used in multitude of differentially private data analysis algorithms. In this paper we revisit the Gaussian mechanism and show that the original analysis has several important limitations. Our analysis reveals that the variance formula for the original mechanism is far from tight in the high privacy regime ($\\varepsilon \\to 0$) and it cannot be extended to the low privacy regime ($\\varepsilon \\to \\infty$). We address these limitations by developing an optimal Gaussian mechanism whose variance is calibrated directly using the Gaussian cumulative density function instead of a tail bound approximation. We also propose to equip the Gaussian mechanism with a post-processing step based on adaptive estimation techniques by leveraging that the distribution of the perturbation is known. Our experiments show that analytical calibration removes at least a third of the variance of the noise compared to the classical Gaussian mechanism, and that denoising dramatically improves the accuracy of the Gaussian mechanism in the high-dimensional regime.",
        "bibtex": "@InProceedings{pmlr-v80-balle18a,\n  title = \t {Improving the {G}aussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising},\n  author =       {Balle, Borja and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {394--403},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balle18a/balle18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balle18a.html},\n  abstract = \t {The Gaussian mechanism is an essential building block used in multitude of differentially private data analysis algorithms. In this paper we revisit the Gaussian mechanism and show that the original analysis has several important limitations. Our analysis reveals that the variance formula for the original mechanism is far from tight in the high privacy regime ($\\varepsilon \\to 0$) and it cannot be extended to the low privacy regime ($\\varepsilon \\to \\infty$). We address these limitations by developing an optimal Gaussian mechanism whose variance is calibrated directly using the Gaussian cumulative density function instead of a tail bound approximation. We also propose to equip the Gaussian mechanism with a post-processing step based on adaptive estimation techniques by leveraging that the distribution of the perturbation is known. Our experiments show that analytical calibration removes at least a third of the variance of the noise compared to the classical Gaussian mechanism, and that denoising dramatically improves the accuracy of the Gaussian mechanism in the high-dimensional regime.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balle18a/balle18a.pdf",
        "supp": "",
        "pdf_size": 2509114,
        "gs_citation": 545,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6616371088385060239&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Amazon Research, Cambridge, UK+University of California, Santa Barbara, USA; Amazon Web Services, Palo Alto, USA+University of California, Santa Barbara, USA",
        "aff_domain": "amazon.co.uk;amazon.com",
        "email": "amazon.co.uk;amazon.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/balle18a.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Amazon;University of California, Santa Barbara",
        "aff_unique_dep": "Amazon Research;",
        "aff_unique_url": "https://www.amazon.science;https://www.ucsb.edu",
        "aff_unique_abbr": "Amazon Research;UCSB",
        "aff_campus_unique_index": "0+1;2+1",
        "aff_campus_unique": "Cambridge;Santa Barbara;Palo Alto",
        "aff_country_unique_index": "0+1;1+1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2075",
        "id": "2075",
        "author_site": "Xueru Zhang, Mohammad Mahdi Khalili, Mingyan Liu",
        "author": "Xueru Zhang; Mohammad Mahdi Khalili; Mingyan Liu",
        "abstract": "Alternating direction method of multiplier (ADMM) is a popular method used to design distributed versions of a machine learning algorithm, whereby local computations are performed on local data with the output exchanged among neighbors in an iterative fashion. During this iterative process the leakage of data privacy arises. A differentially private ADMM was proposed in prior work (Zhang & Zhu, 2017) where only the privacy loss of a single node during one iteration was bounded, a method that makes it difficult to balance the tradeoff between the utility attained through distributed computation and privacy guarantees when considering the total privacy loss of all nodes over the entire iterative process. We propose a perturbation method for ADMM where the perturbed term is correlated with the penalty parameters; this is shown to improve the utility and privacy simultaneously. The method is based on a modified ADMM where each node independently determines its own penalty parameter in every iteration and decouples it from the dual updating step size. The condition for convergence of the modified ADMM and the lower bound on the convergence rate are also derived.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18f,\n  title = \t {Improving the Privacy and Accuracy of {ADMM}-Based Distributed Algorithms},\n  author =       {Zhang, Xueru and Khalili, Mohammad Mahdi and Liu, Mingyan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5796--5805},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18f/zhang18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18f.html},\n  abstract = \t {Alternating direction method of multiplier (ADMM) is a popular method used to design distributed versions of a machine learning algorithm, whereby local computations are performed on local data with the output exchanged among neighbors in an iterative fashion. During this iterative process the leakage of data privacy arises. A differentially private ADMM was proposed in prior work (Zhang & Zhu, 2017) where only the privacy loss of a single node during one iteration was bounded, a method that makes it difficult to balance the tradeoff between the utility attained through distributed computation and privacy guarantees when considering the total privacy loss of all nodes over the entire iterative process. We propose a perturbation method for ADMM where the perturbed term is correlated with the penalty parameters; this is shown to improve the utility and privacy simultaneously. The method is based on a modified ADMM where each node independently determines its own penalty parameter in every iteration and decouples it from the dual updating step size. The condition for convergence of the modified ADMM and the lower bound on the convergence rate are also derived.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18f/zhang18f.pdf",
        "supp": "",
        "pdf_size": 690152,
        "gs_citation": 119,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18029795818176779929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA",
        "aff_domain": "umich.edu;umich.edu;umich.edu",
        "email": "umich.edu;umich.edu;umich.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhang18f.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Inductive Two-Layer Modeling with Parametric Bregman Transfer",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2104",
        "id": "2104",
        "author_site": "Vignesh Ganapathiraman, Zhan Shi, Xinhua Zhang, Yaoliang Yu",
        "author": "Vignesh Ganapathiraman; Zhan Shi; Xinhua Zhang; Yaoliang Yu",
        "abstract": "Latent prediction models, exemplified by multi-layer networks, employ hidden variables that automate abstract feature discovery. They typically pose nonconvex optimization problems and effective semi-definite programming (SDP) relaxations have been developed to enable global solutions (Aslan et al., 2014).However, these models rely on nonparametric training of layer-wise kernel representations, and are therefore restricted to transductive learning which slows down test prediction. In this paper, we develop a new inductive learning framework for parametric transfer functions using matching losses. The result for ReLU utilizes completely positive matrices, and the inductive learner not only delivers superior accuracy but also offers an order of magnitude speedup over SDP with constant approximation guarantees.",
        "bibtex": "@InProceedings{pmlr-v80-ganapathiraman18a,\n  title = \t {Inductive Two-Layer Modeling with Parametric {B}regman Transfer},\n  author =       {Ganapathiraman, Vignesh and Shi, Zhan and Zhang, Xinhua and Yu, Yaoliang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1636--1645},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ganapathiraman18a/ganapathiraman18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ganapathiraman18a.html},\n  abstract = \t {Latent prediction models, exemplified by multi-layer networks, employ hidden variables that automate abstract feature discovery. They typically pose nonconvex optimization problems and effective semi-definite programming (SDP) relaxations have been developed to enable global solutions (Aslan et al., 2014).However, these models rely on nonparametric training of layer-wise kernel representations, and are therefore restricted to transductive learning which slows down test prediction. In this paper, we develop a new inductive learning framework for parametric transfer functions using matching losses. The result for ReLU utilizes completely positive matrices, and the inductive learner not only delivers superior accuracy but also offers an order of magnitude speedup over SDP with constant approximation guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ganapathiraman18a/ganapathiraman18a.pdf",
        "supp": "",
        "pdf_size": 686483,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15190057844167601456&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Illinois at Chicago, USA; Department of Computer Science, University of Illinois at Chicago, USA; Department of Computer Science, University of Illinois at Chicago, USA; School of Computer Science, University of Waterloo, Canada",
        "aff_domain": "uic.edu; ; ; ",
        "email": "uic.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ganapathiraman18a.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Illinois at Chicago;University of Waterloo",
        "aff_unique_dep": "Department of Computer Science;School of Computer Science",
        "aff_unique_url": "https://www.uic.edu;https://uwaterloo.ca",
        "aff_unique_abbr": "UIC;UW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chicago;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "title": "Inference Suboptimality in Variational Autoencoders",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2425",
        "id": "2425",
        "author_site": "Chris Cremer, Xuechen Li, David Duvenaud",
        "author": "Chris Cremer; Xuechen Li; David Duvenaud",
        "abstract": "Amortized inference allows latent-variable models trained via variational learning to scale to large datasets. The quality of approximate inference is determined by two factors: a) the capacity of the variational distribution to match the true posterior and b) the ability of the recognition network to produce good variational parameters for each datapoint. We examine approximate inference in variational autoencoders in terms of these factors. We find that divergence from the true posterior is often due to imperfect recognition networks, rather than the limited complexity of the approximating distribution. We show that this is due partly to the generator learning to accommodate the choice of approximation. Furthermore, we show that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.",
        "bibtex": "@InProceedings{pmlr-v80-cremer18a,\n  title = \t {Inference Suboptimality in Variational Autoencoders},\n  author =       {Cremer, Chris and Li, Xuechen and Duvenaud, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1078--1086},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cremer18a/cremer18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cremer18a.html},\n  abstract = \t {Amortized inference allows latent-variable models trained via variational learning to scale to large datasets. The quality of approximate inference is determined by two factors: a) the capacity of the variational distribution to match the true posterior and b) the ability of the recognition network to produce good variational parameters for each datapoint. We examine approximate inference in variational autoencoders in terms of these factors. We find that divergence from the true posterior is often due to imperfect recognition networks, rather than the limited complexity of the approximating distribution. We show that this is due partly to the generator learning to accommodate the choice of approximation. Furthermore, we show that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cremer18a/cremer18a.pdf",
        "supp": "",
        "pdf_size": 697522,
        "gs_citation": 350,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16046280884129751666&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Toronto; Department of Computer Science, University of Toronto; Department of Computer Science, University of Toronto",
        "aff_domain": "cs.toronto.edu; ; ",
        "email": "cs.toronto.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/cremer18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Information Theoretic Guarantees for Empirical Risk Minimization with Applications to Model Selection and Large-Scale Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1914",
        "id": "1914",
        "author": "Ibrahim Alabdulmohsin",
        "abstract": "In this paper, we derive bounds on the mutual information of the empirical risk minimization (ERM) procedure for both 0-1 and strongly-convex loss classes. We prove that under the Axiom of Choice, the existence of an ERM learning rule with a vanishing mutual information is equivalent to the assertion that the loss class has a finite VC dimension, thus bridging information theory with statistical learning theory. Similarly, an asymptotic bound on the mutual information is established for strongly-convex loss classes in terms of the number of model parameters. The latter result rests on a central limit theorem (CLT) that we derive in this paper. In addition, we use our results to analyze the excess risk in stochastic convex optimization and unify previous works. Finally, we present two important applications. First, we show that the ERM of strongly-convex loss classes can be trivially scaled to big data using a naive parallelization algorithm with provable guarantees. Second, we propose a simple information criterion for model selection and demonstrate experimentally that it outperforms the popular Akaike\u2019s information criterion (AIC) and Schwarz\u2019s Bayesian information criterion (BIC).",
        "bibtex": "@InProceedings{pmlr-v80-alabdulmohsin18a,\n  title = \t {Information Theoretic Guarantees for Empirical Risk Minimization with Applications to Model Selection and Large-Scale Optimization},\n  author =       {Alabdulmohsin, Ibrahim},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {149--158},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/alabdulmohsin18a/alabdulmohsin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/alabdulmohsin18a.html},\n  abstract = \t {In this paper, we derive bounds on the mutual information of the empirical risk minimization (ERM) procedure for both 0-1 and strongly-convex loss classes. We prove that under the Axiom of Choice, the existence of an ERM learning rule with a vanishing mutual information is equivalent to the assertion that the loss class has a finite VC dimension, thus bridging information theory with statistical learning theory. Similarly, an asymptotic bound on the mutual information is established for strongly-convex loss classes in terms of the number of model parameters. The latter result rests on a central limit theorem (CLT) that we derive in this paper. In addition, we use our results to analyze the excess risk in stochastic convex optimization and unify previous works. Finally, we present two important applications. First, we show that the ERM of strongly-convex loss classes can be trivially scaled to big data using a naive parallelization algorithm with provable guarantees. Second, we propose a simple information criterion for model selection and demonstrate experimentally that it outperforms the popular Akaike\u2019s information criterion (AIC) and Schwarz\u2019s Bayesian information criterion (BIC).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/alabdulmohsin18a/alabdulmohsin18a.pdf",
        "supp": "",
        "pdf_size": 605913,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8344449382276558730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Saudi Aramco, Dhahran 31311, Saudi Arabia",
        "aff_domain": "kaust.edu.sa",
        "email": "kaust.edu.sa",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/alabdulmohsin18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Saudi Aramco",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.saudiaramco.com",
        "aff_unique_abbr": "Saudi Aramco",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Dhahran",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Saudi Arabia"
    },
    {
        "title": "Inter and Intra Topic Structure Learning with Word Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2183",
        "id": "2183",
        "author_site": "He Zhao, Lan Du, Wray Buntine, Mingyuan Zhou",
        "author": "He Zhao; Lan Du; Wray Buntine; Mingyuan Zhou",
        "abstract": "One important task of topic modeling for text analysis is interpretability. By discovering structured topics one is able to yield improved interpretability as well as modeling accuracy. In this paper, we propose a novel topic model with a deep structure that explores both inter-topic and intra-topic structures informed by word embeddings. Specifically, our model discovers inter topic structures in the form of topic hierarchies and discovers intra topic structures in the form of sub-topics, each of which is informed by word embeddings and captures a fine-grained thematic aspect of a normal topic. Extensive experiments demonstrate that our model achieves the state-of-the-art performance in terms of perplexity, document classification, and topic quality. Moreover, with topic hierarchies and sub-topics, the topics discovered in our model are more interpretable, providing an illuminating means to understand text data.",
        "bibtex": "@InProceedings{pmlr-v80-zhao18a,\n  title = \t {Inter and Intra Topic Structure Learning with Word Embeddings},\n  author =       {Zhao, He and Du, Lan and Buntine, Wray and Zhou, Mingyuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5892--5901},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhao18a/zhao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhao18a.html},\n  abstract = \t {One important task of topic modeling for text analysis is interpretability. By discovering structured topics one is able to yield improved interpretability as well as modeling accuracy. In this paper, we propose a novel topic model with a deep structure that explores both inter-topic and intra-topic structures informed by word embeddings. Specifically, our model discovers inter topic structures in the form of topic hierarchies and discovers intra topic structures in the form of sub-topics, each of which is informed by word embeddings and captures a fine-grained thematic aspect of a normal topic. Extensive experiments demonstrate that our model achieves the state-of-the-art performance in terms of perplexity, document classification, and topic quality. Moreover, with topic hierarchies and sub-topics, the topics discovered in our model are more interpretable, providing an illuminating means to understand text data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhao18a/zhao18a.pdf",
        "supp": "",
        "pdf_size": 468065,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11048244315815532986&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Faculty of Information Technology, Monash University, Australia; Faculty of Information Technology, Monash University, Australia; Faculty of Information Technology, Monash University, Australia; McCombs School of Business, University of Texas at Austin",
        "aff_domain": "monash.edu;mccombs.utexas.edu; ; ",
        "email": "monash.edu;mccombs.utexas.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/zhao18a.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Monash University;University of Texas at Austin",
        "aff_unique_dep": "Faculty of Information Technology;McCombs School of Business",
        "aff_unique_url": "https://www.monash.edu;https://www.mccombs.utexas.edu",
        "aff_unique_abbr": "Monash;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2089",
        "id": "2089",
        "author_site": "Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Vi\u00e9gas, Rory sayres",
        "author": "Been Kim; Martin Wattenberg; Justin Gilmer; Carrie Cai; James Wexler; Fernanda Viegas; Rory sayres",
        "abstract": "The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net\u2019s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result\u2013for example, how sensitive a prediction of \u201czebra\u201d is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.",
        "bibtex": "@InProceedings{pmlr-v80-kim18d,\n  title = \t {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ({TCAV})},\n  author =       {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and sayres, Rory},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2668--2677},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kim18d/kim18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kim18d.html},\n  abstract = \t {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net\u2019s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result\u2013for example, how sensitive a prediction of \u201czebra\u201d is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kim18d/kim18d.pdf",
        "supp": "",
        "pdf_size": 2082566,
        "gs_citation": 2433,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3851819948477187965&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Google; Google; Google; Google; Google; Google; Google",
        "aff_domain": "google.com; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/kim18d.html",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Invariance of Weight Distributions in Rectified MLPs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1925",
        "id": "1925",
        "author_site": "Susumu Tsuchida, Fred Roosta, Marcus Gallagher",
        "author": "Russell Tsuchida; Fred Roosta; Marcus Gallagher",
        "abstract": "An interesting approach to analyzing neural networks that has received renewed attention is to examine the equivalent kernel of the neural network. This is based on the fact that a fully connected feedforward network with one hidden layer, a certain weight distribution, an activation function, and an infinite number of neurons can be viewed as a mapping into a Hilbert space. We derive the equivalent kernels of MLPs with ReLU or Leaky ReLU activations for all rotationally-invariant weight distributions, generalizing a previous result that required Gaussian weight distributions. Additionally, the Central Limit Theorem is used to show that for certain activation functions, kernels corresponding to layers with weight distributions having $0$ mean and finite absolute third moment are asymptotically universal, and are well approximated by the kernel corresponding to layers with spherical Gaussian weights. In deep networks, as depth increases the equivalent kernel approaches a pathological fixed point, which can be used to argue why training randomly initialized networks can be difficult. Our results also have implications for weight initialization.",
        "bibtex": "@InProceedings{pmlr-v80-tsuchida18a,\n  title = \t {Invariance of Weight Distributions in Rectified {MLP}s},\n  author =       {Tsuchida, Russell and Roosta, Fred and Gallagher, Marcus},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4995--5004},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tsuchida18a/tsuchida18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tsuchida18a.html},\n  abstract = \t {An interesting approach to analyzing neural networks that has received renewed attention is to examine the equivalent kernel of the neural network. This is based on the fact that a fully connected feedforward network with one hidden layer, a certain weight distribution, an activation function, and an infinite number of neurons can be viewed as a mapping into a Hilbert space. We derive the equivalent kernels of MLPs with ReLU or Leaky ReLU activations for all rotationally-invariant weight distributions, generalizing a previous result that required Gaussian weight distributions. Additionally, the Central Limit Theorem is used to show that for certain activation functions, kernels corresponding to layers with weight distributions having $0$ mean and finite absolute third moment are asymptotically universal, and are well approximated by the kernel corresponding to layers with spherical Gaussian weights. In deep networks, as depth increases the equivalent kernel approaches a pathological fixed point, which can be used to argue why training randomly initialized networks can be difficult. Our results also have implications for weight initialization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tsuchida18a/tsuchida18a.pdf",
        "supp": "",
        "pdf_size": 2015887,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7233084810577286871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of ITEE, University of Queensland, Brisbane, Queensland, Australia+International Computer Science Institute, Berkeley, California, USA; School of Mathematics and Physics, University of Queensland, Brisbane, Queensland, Australia+International Computer Science Institute, Berkeley, California, USA; School of ITEE, University of Queensland, Brisbane, Queensland, Australia",
        "aff_domain": "uq.edu.au;uq.edu.au;uq.edu.au",
        "email": "uq.edu.au;uq.edu.au;uq.edu.au",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/tsuchida18a.html",
        "aff_unique_index": "0+1;0+1;0",
        "aff_unique_norm": "University of Queensland;International Computer Science Institute",
        "aff_unique_dep": "School of ITEE;",
        "aff_unique_url": "https://www.uq.edu.au;https://www.icsi.berkeley.edu",
        "aff_unique_abbr": "UQ;ICSI",
        "aff_campus_unique_index": "0+1;0+1;0",
        "aff_campus_unique": "Brisbane;Berkeley",
        "aff_country_unique_index": "0+1;0+1;0",
        "aff_country_unique": "Australia;United States"
    },
    {
        "title": "Investigating Human Priors for Playing Video Games",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2133",
        "id": "2133",
        "author_site": "Rachit Dubey, Pulkit Agrawal, Deepak Pathak, Tom Griffiths, Alexei Efros",
        "author": "Rachit Dubey; Pulkit Agrawal; Deepak Pathak; Tom Griffiths; Alexei Efros",
        "abstract": "What makes humans so good at solving seemingly complex video games? Unlike computers, humans bring in a great deal of prior knowledge about the world, enabling efficient decision making. This paper investigates the role of human priors for solving video games. Given a sample game, we conduct a series of ablation studies to quantify the importance of various priors on human performance. We do this by modifying the video game environment to systematically mask different types of visual information that could be used by humans as priors. We find that removal of some prior knowledge causes a drastic degradation in the speed with which human players solve the game, e.g. from 2 minutes to over 20 minutes. Furthermore, our results indicate that general priors, such as the importance of objects and visual consistency, are critical for efficient game-play. Videos and the game manipulations are available at https://rach0012.github.io/humanRL_website/",
        "bibtex": "@InProceedings{pmlr-v80-dubey18a,\n  title = \t {Investigating Human Priors for Playing Video Games},\n  author =       {Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Tom and Efros, Alexei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1349--1357},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dubey18a/dubey18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dubey18a.html},\n  abstract = \t {What makes humans so good at solving seemingly complex video games? Unlike computers, humans bring in a great deal of prior knowledge about the world, enabling efficient decision making. This paper investigates the role of human priors for solving video games. Given a sample game, we conduct a series of ablation studies to quantify the importance of various priors on human performance. We do this by modifying the video game environment to systematically mask different types of visual information that could be used by humans as priors. We find that removal of some prior knowledge causes a drastic degradation in the speed with which human players solve the game, e.g. from 2 minutes to over 20 minutes. Furthermore, our results indicate that general priors, such as the importance of objects and visual consistency, are critical for efficient game-play. Videos and the game manipulations are available at https://rach0012.github.io/humanRL_website/}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dubey18a/dubey18a.pdf",
        "supp": "",
        "pdf_size": 8108987,
        "gs_citation": 210,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2202192690517876762&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "berkeley.edu; ; ; ; ",
        "email": "berkeley.edu; ; ; ; ",
        "github": "",
        "project": "https://rach0012.github.io/humanRL_website/",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/dubey18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Is Generator Conditioning Causally Related to GAN Performance?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2439",
        "id": "2439",
        "author_site": "Augustus Odena, Jacob Buckman, Catherine Olsson, Tom B Brown, Christopher Olah, Colin Raffel, Ian Goodfellow",
        "author": "Augustus Odena; Jacob Buckman; Catherine Olsson; Tom Brown; Christopher Olah; Colin Raffel; Ian Goodfellow",
        "abstract": "Recent work suggests that controlling the entire distribution of Jacobian singular values is an important design consideration in deep learning. Motivated by this, we study the distribution of singular values of the Jacobian of the generator in Generative Adversarial Networks. We find that this Jacobian generally becomes ill-conditioned at the beginning of training. Moreover, we find that the average (across the latent space) conditioning of the generator is highly predictive of two other ad-hoc metrics for measuring the \u201cquality\u201d of trained GANs: the Inception Score and the Frechet Inception Distance. We then test the hypothesis that this relationship is causal by proposing a \u201cregularization\u201d technique (called Jacobian Clamping) that softly penalizes the condition number of the generator Jacobian. Jacobian Clamping improves the mean score for nearly all datasets on which we tested it. It also greatly reduces inter-run variance of the aforementioned scores, addressing (at least partially) one of the main criticisms of GANs.",
        "bibtex": "@InProceedings{pmlr-v80-odena18a,\n  title = \t {Is Generator Conditioning Causally Related to {GAN} Performance?},\n  author =       {Odena, Augustus and Buckman, Jacob and Olsson, Catherine and Brown, Tom and Olah, Christopher and Raffel, Colin and Goodfellow, Ian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3849--3858},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/odena18a/odena18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/odena18a.html},\n  abstract = \t {Recent work suggests that controlling the entire distribution of Jacobian singular values is an important design consideration in deep learning. Motivated by this, we study the distribution of singular values of the Jacobian of the generator in Generative Adversarial Networks. We find that this Jacobian generally becomes ill-conditioned at the beginning of training. Moreover, we find that the average (across the latent space) conditioning of the generator is highly predictive of two other ad-hoc metrics for measuring the \u201cquality\u201d of trained GANs: the Inception Score and the Frechet Inception Distance. We then test the hypothesis that this relationship is causal by proposing a \u201cregularization\u201d technique (called Jacobian Clamping) that softly penalizes the condition number of the generator Jacobian. Jacobian Clamping improves the mean score for nearly all datasets on which we tested it. It also greatly reduces inter-run variance of the aforementioned scores, addressing (at least partially) one of the main criticisms of GANs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/odena18a/odena18a.pdf",
        "supp": "",
        "pdf_size": 1499010,
        "gs_citation": 149,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2494855030902961623&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Google Brain; Google Brain; Google Brain; Google Brain; Google Brain; Google Brain; Google Brain",
        "aff_domain": "google.com; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/odena18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Brain",
        "aff_unique_url": "https://brain.google.com",
        "aff_unique_abbr": "Google Brain",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Iterative Amortized Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2110",
        "id": "2110",
        "author_site": "Joe Marino, Yisong Yue, Stephan Mandt",
        "author": "Joe Marino; Yisong Yue; Stephan Mandt",
        "abstract": "Inference models are a key component in scaling variational inference to deep latent variable models, most notably as encoder networks in variational auto-encoders (VAEs). By replacing conventional optimization-based inference with a learned model, inference is amortized over data examples and therefore more computationally efficient. However, standard inference models are restricted to direct mappings from data to approximate posterior estimates. The failure of these models to reach fully optimized approximate posterior estimates results in an amortization gap. We aim toward closing this gap by proposing iterative inference models, which learn to perform inference optimization through repeatedly encoding gradients. Our approach generalizes standard inference models in VAEs and provides insight into several empirical findings, including top-down inference techniques. We demonstrate the inference optimization capabilities of iterative inference models and show that they outperform standard inference models on several benchmark data sets of images and text.",
        "bibtex": "@InProceedings{pmlr-v80-marino18a,\n  title = \t {Iterative Amortized Inference},\n  author =       {Marino, Joe and Yue, Yisong and Mandt, Stephan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3403--3412},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/marino18a/marino18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/marino18a.html},\n  abstract = \t {Inference models are a key component in scaling variational inference to deep latent variable models, most notably as encoder networks in variational auto-encoders (VAEs). By replacing conventional optimization-based inference with a learned model, inference is amortized over data examples and therefore more computationally efficient. However, standard inference models are restricted to direct mappings from data to approximate posterior estimates. The failure of these models to reach fully optimized approximate posterior estimates results in an amortization gap. We aim toward closing this gap by proposing iterative inference models, which learn to perform inference optimization through repeatedly encoding gradients. Our approach generalizes standard inference models in VAEs and provides insight into several empirical findings, including top-down inference techniques. We demonstrate the inference optimization capabilities of iterative inference models and show that they outperform standard inference models on several benchmark data sets of images and text.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/marino18a/marino18a.pdf",
        "supp": "",
        "pdf_size": 2788970,
        "gs_citation": 211,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11655024897433506011&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "California Institute of Technology (Caltech), Pasadena, CA, USA; California Institute of Technology (Caltech), Pasadena, CA, USA; Disney Research, Los Angeles, CA, USA",
        "aff_domain": "caltech.edu; ; ",
        "email": "caltech.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/marino18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "California Institute of Technology;Disney Research",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.caltech.edu;https://research.disney.com",
        "aff_unique_abbr": "Caltech;Disney Research",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Pasadena;Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2161",
        "id": "2161",
        "author_site": "Yunchen Pu, Shuyang Dai, Zhe Gan, Weiyao Wang, Guoyin Wang, Yizhe Zhang, Ricardo Henao, Lawrence Carin",
        "author": "Yunchen Pu; Shuyang Dai; Zhe Gan; Weiyao Wang; Guoyin Wang; Yizhe Zhang; Ricardo Henao; Lawrence Carin Duke",
        "abstract": "A new generative adversarial network is developed for joint distribution matching.Distinct from most existing approaches, that only learn conditional distributions, the proposed model aims to learn a joint distribution of multiple random variables (domains). This is achieved by learning to sample from conditional distributions between the domains, while simultaneously learning to sample from the marginals of each individual domain.The proposed framework consists of multiple generators and a single softmax-based critic, all jointly trained via adversarial learning.From a simple noise source, the proposed framework allows synthesis of draws from the marginals, conditional draws given observations from a subset of random variables, or complete draws from the full joint distribution. Most examples considered are for joint analysis of two domains, with examples for three domains also presented.",
        "bibtex": "@InProceedings{pmlr-v80-pu18a,\n  title = \t {{J}oint{GAN}: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets},\n  author =       {Pu, Yunchen and Dai, Shuyang and Gan, Zhe and Wang, Weiyao and Wang, Guoyin and Zhang, Yizhe and Henao, Ricardo and Duke, Lawrence Carin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4151--4160},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pu18a/pu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pu18a.html},\n  abstract = \t {A new generative adversarial network is developed for joint distribution matching.Distinct from most existing approaches, that only learn conditional distributions, the proposed model aims to learn a joint distribution of multiple random variables (domains). This is achieved by learning to sample from conditional distributions between the domains, while simultaneously learning to sample from the marginals of each individual domain.The proposed framework consists of multiple generators and a single softmax-based critic, all jointly trained via adversarial learning.From a simple noise source, the proposed framework allows synthesis of draws from the marginals, conditional draws given observations from a subset of random variables, or complete draws from the full joint distribution. Most examples considered are for joint analysis of two domains, with examples for three domains also presented.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pu18a/pu18a.pdf",
        "supp": "",
        "pdf_size": 4337730,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17442133177721066359&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/pu18a.html"
    },
    {
        "title": "Junction Tree Variational Autoencoder for Molecular Graph Generation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1903",
        "id": "1903",
        "author_site": "Wengong Jin, Regina Barzilay, Tommi Jaakkola",
        "author": "Wengong Jin; Regina Barzilay; Tommi Jaakkola",
        "abstract": "We seek to automate the design of molecules based on specific chemical properties. In computational terms, this task involves continuous embedding and generation of molecular graphs. Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs. Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network. This approach allows us to incrementally expand molecules while maintaining chemical validity at every step. We evaluate our model on multiple tasks ranging from molecular generation to optimization. Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.",
        "bibtex": "@InProceedings{pmlr-v80-jin18a,\n  title = \t {Junction Tree Variational Autoencoder for Molecular Graph Generation},\n  author =       {Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2323--2332},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jin18a/jin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jin18a.html},\n  abstract = \t {We seek to automate the design of molecules based on specific chemical properties. In computational terms, this task involves continuous embedding and generation of molecular graphs. Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs. Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network. This approach allows us to incrementally expand molecules while maintaining chemical validity at every step. We evaluate our model on multiple tasks ranging from molecular generation to optimization. Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jin18a/jin18a.pdf",
        "supp": "",
        "pdf_size": 1671814,
        "gs_citation": 1850,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14713480171095443338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 23,
        "aff": "MIT Computer Science & Artificial Intelligence Lab; MIT Computer Science & Artificial Intelligence Lab; MIT Computer Science & Artificial Intelligence Lab",
        "aff_domain": "csail.mit.edu; ; ",
        "email": "csail.mit.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jin18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science & Artificial Intelligence Lab",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT CSAIL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1962",
        "id": "1962",
        "author_site": "Jihun Hamm, Yung-Kyun Noh",
        "author": "Jihun Hamm; Yung-Kyun Noh",
        "abstract": "Minimax optimization plays a key role in adversarial training of machine learning algorithms, such as learning generative models, domain adaptation, privacy preservation, and robust learning. In this paper, we demonstrate the failure of alternating gradient descent in minimax optimization problems due to the discontinuity of solutions of the inner maximization. To address this, we propose a new $\\epsilon$-subgradient descent algorithm that addresses this problem by simultaneously tracking $K$ candidate solutions. Practically, the algorithm can find solutions that previous saddle-point algorithms cannot find, with only a sublinear increase of complexity in $K$. We analyze the conditions under which the algorithm converges to the true solution in detail. A significant improvement in stability and convergence speed of the algorithm is observed in simple representative problems, GAN training, and domain-adaptation problems.",
        "bibtex": "@InProceedings{pmlr-v80-hamm18a,\n  title = \t {K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning},\n  author =       {Hamm, Jihun and Noh, Yung-Kyun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1881--1889},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hamm18a/hamm18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hamm18a.html},\n  abstract = \t {Minimax optimization plays a key role in adversarial training of machine learning algorithms, such as learning generative models, domain adaptation, privacy preservation, and robust learning. In this paper, we demonstrate the failure of alternating gradient descent in minimax optimization problems due to the discontinuity of solutions of the inner maximization. To address this, we propose a new $\\epsilon$-subgradient descent algorithm that addresses this problem by simultaneously tracking $K$ candidate solutions. Practically, the algorithm can find solutions that previous saddle-point algorithms cannot find, with only a sublinear increase of complexity in $K$. We analyze the conditions under which the algorithm converges to the true solution in detail. A significant improvement in stability and convergence speed of the algorithm is observed in simple representative problems, GAN training, and domain-adaptation problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hamm18a/hamm18a.pdf",
        "supp": "",
        "pdf_size": 7392624,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17252205883133016426&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "The Ohio State University, Columbus, OH, USA; Seoul National University, Seoul, Korea",
        "aff_domain": "cse.ohio-state.edu; ",
        "email": "cse.ohio-state.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/hamm18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Ohio State University;Seoul National University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.osu.edu;https://www.snu.ac.kr",
        "aff_unique_abbr": "OSU;SNU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Columbus;Seoul",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "title": "K-means clustering using random matrix sparsification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2072",
        "id": "2072",
        "author": "Kaushik Sinha",
        "abstract": "K-means clustering algorithm using Lloyd\u2019s heuristic is one of the most commonly used tools in data mining and machine learning that shows promising performance. However, it suffers from a high computational cost resulting from pairwise Euclidean distance computations between data points and cluster centers in each iteration of Lloyd\u2019s heuristic. Main contributing factor of this computational bottle neck is a matrix-vector multiplication step, where the matrix contains all the data points and the vector is a cluster center. In this paper we show that we can randomly sparsify the original data matrix resulting in a sparse data matrix which can significantly speed up the above mentioned matrix vector multiplication step without significantly affecting cluster quality. In particular, we show that optimal k-means clustering solution of the sparse data matrix, obtained by applying random matrix sparsification, results in an approximately optimal k-means clustering objective of the original data matrix. Our empirical studies on three real world datasets corroborate our theoretical findings and demonstrate that our proposed sparsification method can indeed achieve satisfactory clustering performance.",
        "bibtex": "@InProceedings{pmlr-v80-sinha18a,\n  title = \t {K-means clustering using random matrix sparsification},\n  author =       {Sinha, Kaushik},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4684--4692},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sinha18a/sinha18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sinha18a.html},\n  abstract = \t {K-means clustering algorithm using Lloyd\u2019s heuristic is one of the most commonly used tools in data mining and machine learning that shows promising performance. However, it suffers from a high computational cost resulting from pairwise Euclidean distance computations between data points and cluster centers in each iteration of Lloyd\u2019s heuristic. Main contributing factor of this computational bottle neck is a matrix-vector multiplication step, where the matrix contains all the data points and the vector is a cluster center. In this paper we show that we can randomly sparsify the original data matrix resulting in a sparse data matrix which can significantly speed up the above mentioned matrix vector multiplication step without significantly affecting cluster quality. In particular, we show that optimal k-means clustering solution of the sparse data matrix, obtained by applying random matrix sparsification, results in an approximately optimal k-means clustering objective of the original data matrix. Our empirical studies on three real world datasets corroborate our theoretical findings and demonstrate that our proposed sparsification method can indeed achieve satisfactory clustering performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sinha18a/sinha18a.pdf",
        "supp": "",
        "pdf_size": 587868,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6095583881052539938&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Electrical Engineering & Computer Science, Wichita State University, KS, USA",
        "aff_domain": "wichita.edu",
        "email": "wichita.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/sinha18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Wichita State University",
        "aff_unique_dep": "Department of Electrical Engineering & Computer Science",
        "aff_unique_url": "https://www.wichita.edu",
        "aff_unique_abbr": "WSU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Wichita",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Katyusha X: Simple Momentum Method for Stochastic Sum-of-Nonconvex Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2017",
        "id": "2017",
        "author": "Zeyuan Allen-Zhu",
        "abstract": "The problem of minimizing sum-of-nonconvex functions (i.e., convex functions that are average of non-convex ones) is becoming increasing important in machine learning, and is the core machinery for PCA, SVD, regularized Newton\u2019s method, accelerated non-convex optimization, and more. We show how to provably obtain an accelerated stochastic algorithm for minimizing sum-of-nonconvex functions, by adding one additional line to the well-known SVRG method. This line corresponds to momentum, and shows how to directly apply momentum to the finite-sum stochastic minimization of sum-of-nonconvex functions. As a side result, our method enjoys linear parallel speed-up using mini-batch.",
        "bibtex": "@InProceedings{pmlr-v80-allen-zhu18a,\n  title = \t {{K}atyusha X: Simple Momentum Method for Stochastic Sum-of-Nonconvex Optimization},\n  author =       {Allen-Zhu, Zeyuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {179--185},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/allen-zhu18a/allen-zhu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/allen-zhu18a.html},\n  abstract = \t {The problem of minimizing sum-of-nonconvex functions (i.e., convex functions that are average of non-convex ones) is becoming increasing important in machine learning, and is the core machinery for PCA, SVD, regularized Newton\u2019s method, accelerated non-convex optimization, and more. We show how to provably obtain an accelerated stochastic algorithm for minimizing sum-of-nonconvex functions, by adding one additional line to the well-known SVRG method. This line corresponds to momentum, and shows how to directly apply momentum to the finite-sum stochastic minimization of sum-of-nonconvex functions. As a side result, our method enjoys linear parallel speed-up using mini-batch.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/allen-zhu18a/allen-zhu18a.pdf",
        "supp": "",
        "pdf_size": 1199566,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7251387672843348646&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Microsoft Research AI",
        "aff_domain": "csail.mit.edu",
        "email": "csail.mit.edu",
        "github": "",
        "project": "https://arxiv.org/abs/1802.03866",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/allen-zhu18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "AI",
        "aff_unique_url": "https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "MSR",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Kernel Recursive ABC: Point Estimation with Intractable Likelihood",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2239",
        "id": "2239",
        "author_site": "Takafumi Kajihara, Motonobu Kanagawa, Keisuke Yamazaki, Kenji Fukumizu",
        "author": "Takafumi Kajihara; Motonobu Kanagawa; Keisuke Yamazaki; Kenji Fukumizu",
        "abstract": "We propose a novel approach to parameter estimation for simulator-based statistical models with intractable likelihood. Our proposed method involves recursive application of kernel ABC and kernel herding to the same observed data. We provide a theoretical explanation regarding why the approach works, showing (for the population setting) that, under a certain assumption, point estimates obtained with this method converge to the true parameter, as recursion proceeds. We have conducted a variety of numerical experiments, including parameter estimation for a real-world pedestrian flow simulator, and show that in most cases our method outperforms existing approaches.",
        "bibtex": "@InProceedings{pmlr-v80-kajihara18a,\n  title = \t {Kernel Recursive {ABC}: Point Estimation with Intractable Likelihood},\n  author =       {Kajihara, Takafumi and Kanagawa, Motonobu and Yamazaki, Keisuke and Fukumizu, Kenji},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2400--2409},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kajihara18a/kajihara18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kajihara18a.html},\n  abstract = \t {We propose a novel approach to parameter estimation for simulator-based statistical models with intractable likelihood. Our proposed method involves recursive application of kernel ABC and kernel herding to the same observed data. We provide a theoretical explanation regarding why the approach works, showing (for the population setting) that, under a certain assumption, point estimates obtained with this method converge to the true parameter, as recursion proceeds. We have conducted a variety of numerical experiments, including parameter estimation for a real-world pedestrian flow simulator, and show that in most cases our method outperforms existing approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kajihara18a/kajihara18a.pdf",
        "supp": "",
        "pdf_size": 623189,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12068705844158699696&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "NEC Corporation; National Institute of Advanced Industrial Science and Technology; Max Planck Institute for Intelligent Systems; The Institute of Statistical Mathematics",
        "aff_domain": "ct.jp.nec.com; ; ; ",
        "email": "ct.jp.nec.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kajihara18a.html",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "NEC Corporation;National Institute of Advanced Industrial Science and Technology;Max Planck Institute for Intelligent Systems;Institute of Statistical Mathematics",
        "aff_unique_dep": ";;Intelligent Systems;",
        "aff_unique_url": "https://www.nec.com;https://www.aist.go.jp;https://www.mpi-is.mpg.de;https://www.ism.ac.jp",
        "aff_unique_abbr": "NEC;AIST;MPI-IS;ISM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Japan;Germany"
    },
    {
        "title": "Kernelized Synaptic Weight Matrices",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2141",
        "id": "2141",
        "author_site": "Lorenz M\u00fcller, Julien Martel, Giacomo Indiveri",
        "author": "Lorenz Muller; Julien Martel; Giacomo Indiveri",
        "abstract": "In this paper we introduce a novel neural network architecture, in which weight matrices are re-parametrized in terms of low-dimensional vectors, interacting through kernel functions. A layer of our network can be interpreted as introducing a (potentially infinitely wide) linear layer between input and output. We describe the theory underpinning this model and validate it with concrete examples, exploring how it can be used to impose structure on neural networks in diverse applications ranging from data visualization to recommender systems. We achieve state-of-the-art performance in a collaborative filtering task (MovieLens).",
        "bibtex": "@InProceedings{pmlr-v80-muller18a,\n  title = \t {Kernelized Synaptic Weight Matrices},\n  author =       {Muller, Lorenz and Martel, Julien and Indiveri, Giacomo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3654--3663},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/muller18a/muller18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/muller18a.html},\n  abstract = \t {In this paper we introduce a novel neural network architecture, in which weight matrices are re-parametrized in terms of low-dimensional vectors, interacting through kernel functions. A layer of our network can be interpreted as introducing a (potentially infinitely wide) linear layer between input and output. We describe the theory underpinning this model and validate it with concrete examples, exploring how it can be used to impose structure on neural networks in diverse applications ranging from data visualization to recommender systems. We achieve state-of-the-art performance in a collaborative filtering task (MovieLens).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/muller18a/muller18a.pdf",
        "supp": "",
        "pdf_size": 2711458,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2910064100768308881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "aff_domain": "ini.ethz.ch; ; ",
        "email": "ini.ethz.ch; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/muller18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Institute of Neuroinformatics",
        "aff_unique_url": "https://www.neuro.ethz.ch/",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Knowledge Transfer with Jacobian Matching",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2171",
        "id": "2171",
        "author_site": "Suraj Srinivas, Francois Fleuret",
        "author": "Suraj Srinivas; Francois Fleuret",
        "abstract": "Classical distillation methods transfer representations from a \u201cteacher\u201d neural network to a \u201cstudent\u201d network by matching their output activations. Recent methods also match the Jacobians, or the gradient of output activations with the input. However, this involves making some ad hoc decisions, in particular, the choice of the loss function. In this paper, we first establish an equivalence between Jacobian matching and distillation with input noise, from which we derive appropriate loss functions for Jacobian matching. We then rely on this analysis to apply Jacobian matching to transfer learning by establishing equivalence of a recent transfer learning procedure to distillation. We then show experimentally on standard image datasets that Jacobian-based penalties improve distillation, robustness to noisy inputs, and transfer learning.",
        "bibtex": "@InProceedings{pmlr-v80-srinivas18a,\n  title = \t {Knowledge Transfer with {J}acobian Matching},\n  author =       {Srinivas, Suraj and Fleuret, Francois},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4723--4731},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/srinivas18a/srinivas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/srinivas18a.html},\n  abstract = \t {Classical distillation methods transfer representations from a \u201cteacher\u201d neural network to a \u201cstudent\u201d network by matching their output activations. Recent methods also match the Jacobians, or the gradient of output activations with the input. However, this involves making some ad hoc decisions, in particular, the choice of the loss function. In this paper, we first establish an equivalence between Jacobian matching and distillation with input noise, from which we derive appropriate loss functions for Jacobian matching. We then rely on this analysis to apply Jacobian matching to transfer learning by establishing equivalence of a recent transfer learning procedure to distillation. We then show experimentally on standard image datasets that Jacobian-based penalties improve distillation, robustness to noisy inputs, and transfer learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/srinivas18a/srinivas18a.pdf",
        "supp": "",
        "pdf_size": 887053,
        "gs_citation": 207,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5794422302233522659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Idiap Research Institute & EPFL, Switzerland; Idiap Research Institute & EPFL, Switzerland",
        "aff_domain": "idiap.ch; ",
        "email": "idiap.ch; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/srinivas18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Idiap Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.idiap.ch",
        "aff_unique_abbr": "Idiap",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Kronecker Recurrent Units",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2150",
        "id": "2150",
        "author_site": "Cijo Jose, Mouhamadou Moustapha Cisse, Francois Fleuret",
        "author": "Cijo Jose; Moustapha Cisse; Francois Fleuret",
        "abstract": "Our work addresses two important issues with recurrent neural networks: (1) they are over-parametrized, and (2) the recurrent weight matrix is ill-conditioned. The former increases the sample complexity of learning and the training time. The latter causes the vanishing and exploding gradient problem. We present a flexible recurrent neural network model called Kronecker Recurrent Units (KRU). KRU achieves parameter efficiency in RNNs through a Kronecker factored recurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by enforcing soft unitary constraints on the factors. Thanks to the small dimensionality of the factors, maintaining these constraints is computationally efficient. Our experimental results on seven standard data-sets reveal that KRU can reduce the number of parameters by three orders of magnitude in the recurrent weight matrix compared to the existing recurrent models, without trading the statistical performance. These results in particular show that while there are advantages in having a high dimensional recurrent space, the capacity of the recurrent part of the model can be dramatically reduced.",
        "bibtex": "@InProceedings{pmlr-v80-jose18a,\n  title = \t {{K}ronecker Recurrent Units},\n  author =       {Jose, Cijo and Cisse, Moustapha and Fleuret, Francois},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2380--2389},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jose18a/jose18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jose18a.html},\n  abstract = \t {Our work addresses two important issues with recurrent neural networks: (1) they are over-parametrized, and (2) the recurrent weight matrix is ill-conditioned. The former increases the sample complexity of learning and the training time. The latter causes the vanishing and exploding gradient problem. We present a flexible recurrent neural network model called Kronecker Recurrent Units (KRU). KRU achieves parameter efficiency in RNNs through a Kronecker factored recurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by enforcing soft unitary constraints on the factors. Thanks to the small dimensionality of the factors, maintaining these constraints is computationally efficient. Our experimental results on seven standard data-sets reveal that KRU can reduce the number of parameters by three orders of magnitude in the recurrent weight matrix compared to the existing recurrent models, without trading the statistical performance. These results in particular show that while there are advantages in having a high dimensional recurrent space, the capacity of the recurrent part of the model can be dramatically reduced.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jose18a/jose18a.pdf",
        "supp": "",
        "pdf_size": 565828,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14809178725284478631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Idiap Research Institute + \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); Facebook AI Research; Idiap Research Institute + \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)",
        "aff_domain": "idiap.ch;fb.com;idiap.ch",
        "email": "idiap.ch;fb.com;idiap.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jose18a.html",
        "aff_unique_index": "0+1;2;0+1",
        "aff_unique_norm": "Idiap Research Institute;EPFL;Meta",
        "aff_unique_dep": ";;Facebook AI Research",
        "aff_unique_url": "https://www.idiap.ch;https://www.epfl.ch;https://research.facebook.com",
        "aff_unique_abbr": "Idiap;EPFL;FAIR",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;1;0+0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "title": "LaVAN: Localized and Visible Adversarial Noise",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2154",
        "id": "2154",
        "author_site": "Danny Karmon, Daniel Zoran, Yoav Goldberg",
        "author": "Danny Karmon; Daniel Zoran; Yoav Goldberg",
        "abstract": "Most works on adversarial examples for deep-learning based image classifiers use noise that, while small, covers the entire image. We explore the case where the noise is allowed to be visible but confined to a small, localized patch of the image, without covering any of the main object(s) in the image. We show that it is possible to generate localized adversarial noises that cover only 2% of the pixels in the image, none of them over the main object, and that are transferable across images and locations, and successfully fool a state-of-the-art Inception v3 model with very high success rates.",
        "bibtex": "@InProceedings{pmlr-v80-karmon18a,\n  title = \t {{L}a{VAN}: Localized and Visible Adversarial Noise},\n  author =       {Karmon, Danny and Zoran, Daniel and Goldberg, Yoav},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2507--2515},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/karmon18a/karmon18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/karmon18a.html},\n  abstract = \t {Most works on adversarial examples for deep-learning based image classifiers use noise that, while small, covers the entire image. We explore the case where the noise is allowed to be visible but confined to a small, localized patch of the image, without covering any of the main object(s) in the image. We show that it is possible to generate localized adversarial noises that cover only 2% of the pixels in the image, none of them over the main object, and that are transferable across images and locations, and successfully fool a state-of-the-art Inception v3 model with very high success rates.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/karmon18a/karmon18a.pdf",
        "supp": "",
        "pdf_size": 6733320,
        "gs_citation": 300,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5856799243179870731&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Microsoft, Herzliya, Israel; DeepMind, London, UK; Department of Computer Science, Bar-Ilan University, Ramat Gan, Israel",
        "aff_domain": "microsoft.com;google.com;cs.biu.ac.il",
        "email": "microsoft.com;google.com;cs.biu.ac.il",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/karmon18a.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Microsoft;DeepMind;Bar-Ilan University",
        "aff_unique_dep": "Microsoft;;Department of Computer Science",
        "aff_unique_url": "https://www.microsoft.com;https://deepmind.com;https://www.biu.ac.il",
        "aff_unique_abbr": "MSFT;DeepMind;BIU",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Herzliya;London;Ramat Gan",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Israel;United Kingdom"
    },
    {
        "title": "Large-Scale Cox Process Inference using Variational Fourier Features",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1982",
        "id": "1982",
        "author_site": "ST John, James Hensman",
        "author": "ST John; James Hensman",
        "abstract": "Gaussian process modulated Poisson processes provide a flexible framework for modeling spatiotemporal point patterns. So far this had been restricted to one dimension, binning to a pre-determined grid, or small data sets of up to a few thousand data points. Here we introduce Cox process inference based on Fourier features. This sparse representation induces global rather than local constraints on the function space and is computationally efficient. This allows us to formulate a grid-free approximation that scales well with the number of data points and the size of the domain. We demonstrate that this allows MCMC approximations to the non-Gaussian posterior. In practice, we find that Fourier features have more consistent optimization behavior than previous approaches. Our approximate Bayesian method can fit over 100 000 events with complex spatiotemporal patterns in three dimensions on a single GPU.",
        "bibtex": "@InProceedings{pmlr-v80-john18a,\n  title = \t {Large-Scale {C}ox Process Inference using Variational {F}ourier Features},\n  author =       {John, ST and Hensman, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2362--2370},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/john18a/john18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/john18a.html},\n  abstract = \t {Gaussian process modulated Poisson processes provide a flexible framework for modeling spatiotemporal point patterns. So far this had been restricted to one dimension, binning to a pre-determined grid, or small data sets of up to a few thousand data points. Here we introduce Cox process inference based on Fourier features. This sparse representation induces global rather than local constraints on the function space and is computationally efficient. This allows us to formulate a grid-free approximation that scales well with the number of data points and the size of the domain. We demonstrate that this allows MCMC approximations to the non-Gaussian posterior. In practice, we find that Fourier features have more consistent optimization behavior than previous approaches. Our approximate Bayesian method can fit over 100 000 events with complex spatiotemporal patterns in three dimensions on a single GPU.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/john18a/john18a.pdf",
        "supp": "",
        "pdf_size": 3756084,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15505657896191044845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "PROWLER.io, 66-68 Hills Road, Cambridge CB2 1LA, United Kingdom; PROWLER.io, 66-68 Hills Road, Cambridge CB2 1LA, United Kingdom",
        "aff_domain": "prowler.io;prowler.io",
        "email": "prowler.io;prowler.io",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/john18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "PROWLER.io",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2189",
        "id": "2189",
        "author_site": "Richard Zhang, Salar Fattahi, Somayeh Sojoudi",
        "author": "Richard Zhang; Salar Fattahi; Somayeh Sojoudi",
        "abstract": "The sparse inverse covariance estimation problem is commonly solved using an $\\ell_{1}$-regularized Gaussian maximum likelihood estimator known as \u201cgraphical lasso\u201d, but its computational cost becomes prohibitive for large data sets. A recently line of results showed{\u2013}under mild assumptions{\u2013}that the graphical lasso estimator can be retrieved by soft-thresholding the sample covariance matrix and solving a maximum determinant matrix completion (MDMC) problem. This paper proves an extension of this result, and describes a Newton-CG algorithm to efficiently solve the MDMC problem. Assuming that the thresholded sample covariance matrix is sparse with a sparse Cholesky factorization, we prove that the algorithm converges to an $\\epsilon$-accurate solution in $O(n\\log(1/\\epsilon))$ time and $O(n)$ memory. The algorithm is highly efficient in practice: we solve the associated MDMC problems with as many as 200,000 variables to 7-9 digits of accuracy in less than an hour on a standard laptop computer running MATLAB.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18c,\n  title = \t {Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion},\n  author =       {Zhang, Richard and Fattahi, Salar and Sojoudi, Somayeh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5766--5775},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18c/zhang18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18c.html},\n  abstract = \t {The sparse inverse covariance estimation problem is commonly solved using an $\\ell_{1}$-regularized Gaussian maximum likelihood estimator known as \u201cgraphical lasso\u201d, but its computational cost becomes prohibitive for large data sets. A recently line of results showed{\u2013}under mild assumptions{\u2013}that the graphical lasso estimator can be retrieved by soft-thresholding the sample covariance matrix and solving a maximum determinant matrix completion (MDMC) problem. This paper proves an extension of this result, and describes a Newton-CG algorithm to efficiently solve the MDMC problem. Assuming that the thresholded sample covariance matrix is sparse with a sparse Cholesky factorization, we prove that the algorithm converges to an $\\epsilon$-accurate solution in $O(n\\log(1/\\epsilon))$ time and $O(n)$ memory. The algorithm is highly efficient in practice: we solve the associated MDMC problems with as many as 200,000 variables to 7-9 digits of accuracy in less than an hour on a standard laptop computer running MATLAB.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18c/zhang18c.pdf",
        "supp": "",
        "pdf_size": 378574,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12982808978728350880&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Industrial Engineering and Operations Research, University of California, Berkeley, USA; Department of Industrial Engineering and Operations Research, University of California, Berkeley, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, USA",
        "aff_domain": "berkeley.edu; ; ",
        "email": "berkeley.edu; ; ",
        "github": "",
        "project": "http://alum.mit.edu/www/ryz",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhang18c.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Industrial Engineering and Operations Research",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Latent Space Policies for Hierarchical Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2334",
        "id": "2334",
        "author_site": "Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, Sergey Levine",
        "author": "Tuomas Haarnoja; Kristian Hartikainen; Pieter Abbeel; Sergey Levine",
        "abstract": "We address the problem of learning hierarchical deep neural network policies for reinforcement learning. In contrast to methods that explicitly restrict or cripple lower layers of a hierarchy to force them to use higher-level modulating signals, each layer in our framework is trained to directly solve the task, but acquires a range of diverse strategies via a maximum entropy reinforcement learning objective. Each layer is also augmented with latent random variables, which are sampled from a prior distribution during the training of that layer. The maximum entropy objective causes these latent variables to be incorporated into the layer\u2019s policy, and the higher level layer can directly control the behavior of the lower layer through this latent space. Furthermore, by constraining the mapping from latent variables to actions to be invertible, higher layers retain full expressivity: neither the higher layers nor the lower layers are constrained in their behavior. Our experimental evaluation demonstrates that we can improve on the performance of single-layer policies on standard benchmark tasks simply by adding additional layers, and that our method can solve more complex sparse-reward tasks by learning higher-level policies on top of high-entropy skills optimized for simple low-level objectives.",
        "bibtex": "@InProceedings{pmlr-v80-haarnoja18a,\n  title = \t {Latent Space Policies for Hierarchical Reinforcement Learning},\n  author =       {Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1851--1860},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/haarnoja18a/haarnoja18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/haarnoja18a.html},\n  abstract = \t {We address the problem of learning hierarchical deep neural network policies for reinforcement learning. In contrast to methods that explicitly restrict or cripple lower layers of a hierarchy to force them to use higher-level modulating signals, each layer in our framework is trained to directly solve the task, but acquires a range of diverse strategies via a maximum entropy reinforcement learning objective. Each layer is also augmented with latent random variables, which are sampled from a prior distribution during the training of that layer. The maximum entropy objective causes these latent variables to be incorporated into the layer\u2019s policy, and the higher level layer can directly control the behavior of the lower layer through this latent space. Furthermore, by constraining the mapping from latent variables to actions to be invertible, higher layers retain full expressivity: neither the higher layers nor the lower layers are constrained in their behavior. Our experimental evaluation demonstrates that we can improve on the performance of single-layer policies on standard benchmark tasks simply by adding additional layers, and that our method can solve more complex sparse-reward tasks by learning higher-level policies on top of high-entropy skills optimized for simple low-level objectives.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/haarnoja18a/haarnoja18a.pdf",
        "supp": "",
        "pdf_size": 2517823,
        "gs_citation": 235,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16469506517224271150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Berkeley Artificial Intelligence Research, University of California, Berkeley, USA+Independent researcher, Seattle, WA, USA; Independent researcher, Seattle, WA, USA; Berkeley Artificial Intelligence Research, University of California, Berkeley, USA; Berkeley Artificial Intelligence Research, University of California, Berkeley, USA",
        "aff_domain": "berkeley.edu;gmail.com; ; ",
        "email": "berkeley.edu;gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/haarnoja18a.html",
        "aff_unique_index": "0+1;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Independent Researcher",
        "aff_unique_dep": "Berkeley Artificial Intelligence Research;",
        "aff_unique_url": "https://www.berkeley.edu;",
        "aff_unique_abbr": "UC Berkeley;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "LeapsAndBounds: A Method for Approximately Optimal Algorithm Configuration",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2263",
        "id": "2263",
        "author_site": "Gell\u00e9rt Weisz, Andr\u00e1s Gy\u00f6rgy, Csaba Szepesvari",
        "author": "Gellert Weisz; Andras Gyorgy; Csaba Szepesvari",
        "abstract": "We consider the problem of configuring general-purpose solvers to run efficiently on problem instances drawn from an unknown distribution. The goal of the configurator is to find a configuration that runs fast on average on most instances, and do so with the least amount of total work. It can run a chosen solver on a random instance until the solver finishes or a timeout is reached. We propose LeapsAndBounds, an algorithm that tests configurations on randomly selected problem instances for longer and longer time. We prove that the capped expected runtime of the configuration returned by LeapsAndBounds is close to the optimal expected runtime, while our algorithm\u2019s running time is near-optimal. Our results show that LeapsAndBounds is more efficient than the recent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the only other algorithm configuration method with non-trivial theoretical guarantees. Experimental results on configuring a public SAT solver on a new benchmark dataset also stand witness to the superiority of our method.",
        "bibtex": "@InProceedings{pmlr-v80-weisz18a,\n  title = \t {{L}eaps{A}nd{B}ounds: A Method for Approximately Optimal Algorithm Configuration},\n  author =       {Weisz, Gellert and Gyorgy, Andras and Szepesvari, Csaba},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5257--5265},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/weisz18a/weisz18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/weisz18a.html},\n  abstract = \t {We consider the problem of configuring general-purpose solvers to run efficiently on problem instances drawn from an unknown distribution. The goal of the configurator is to find a configuration that runs fast on average on most instances, and do so with the least amount of total work. It can run a chosen solver on a random instance until the solver finishes or a timeout is reached. We propose LeapsAndBounds, an algorithm that tests configurations on randomly selected problem instances for longer and longer time. We prove that the capped expected runtime of the configuration returned by LeapsAndBounds is close to the optimal expected runtime, while our algorithm\u2019s running time is near-optimal. Our results show that LeapsAndBounds is more efficient than the recent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the only other algorithm configuration method with non-trivial theoretical guarantees. Experimental results on configuring a public SAT solver on a new benchmark dataset also stand witness to the superiority of our method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/weisz18a/weisz18a.pdf",
        "supp": "",
        "pdf_size": 469753,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15095680868222377688&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "DeepMind, London, UK + Imperial College London, London, UK; DeepMind, London, UK + University of Alberta, Edmonton, AB, Canada; DeepMind, London, UK + University of Alberta, Edmonton, AB, Canada",
        "aff_domain": "google.com;google.com;google.com",
        "email": "google.com;google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/weisz18a.html",
        "aff_unique_index": "0+1;0+2;0+2",
        "aff_unique_norm": "DeepMind;Imperial College London;University of Alberta",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://deepmind.com;https://www.imperial.ac.uk;https://www.ualberta.ca",
        "aff_unique_abbr": "DeepMind;ICL;UAlberta",
        "aff_campus_unique_index": "0+0;0+1;0+1",
        "aff_campus_unique": "London;Edmonton",
        "aff_country_unique_index": "0+0;0+1;0+1",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "title": "Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2325",
        "id": "2325",
        "author_site": "Ashwin Kalyan, Stefan Lee, Anitha Kannan, Dhruv Batra",
        "author": "Ashwin Kalyan; Stefan Lee; Anitha Kannan; Dhruv Batra",
        "abstract": "Many structured prediction problems (particularly in vision and language domains) are ambiguous, with multiple outputs being \u2018correct\u2019 for an input {\u2013} e.g. there are many ways of describing an image, multiple ways of translating a sentence; however, exhaustively annotating the applicability of all possible outputs is intractable due to exponentially large output spaces (e.g. all English sentences). In practice, these problems are cast as multi-class prediction, with the likelihood of only a sparse set of annotations being maximized {\u2013} unfortunately penalizing for placing beliefs on plausible but unannotated outputs. We make and test the following hypothesis {\u2013} for a given input, the annotations of its neighbors may serve as an additional supervisory signal. Specifically, we propose an objective that transfers supervision from neighboring examples. We first study the properties of our developed method in a controlled toy setup before reporting results on multi-label classification and two image-grounded sequence modeling tasks {\u2013} captioning and question generation. We evaluate using standard task-specific metrics and measures of output diversity, finding consistent improvements over standard maximum likelihood training and other baselines.",
        "bibtex": "@InProceedings{pmlr-v80-kalyan18a,\n  title = \t {Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations},\n  author =       {Kalyan, Ashwin and Lee, Stefan and Kannan, Anitha and Batra, Dhruv},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2449--2458},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kalyan18a/kalyan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kalyan18a.html},\n  abstract = \t {Many structured prediction problems (particularly in vision and language domains) are ambiguous, with multiple outputs being \u2018correct\u2019 for an input {\u2013} e.g. there are many ways of describing an image, multiple ways of translating a sentence; however, exhaustively annotating the applicability of all possible outputs is intractable due to exponentially large output spaces (e.g. all English sentences). In practice, these problems are cast as multi-class prediction, with the likelihood of only a sparse set of annotations being maximized {\u2013} unfortunately penalizing for placing beliefs on plausible but unannotated outputs. We make and test the following hypothesis {\u2013} for a given input, the annotations of its neighbors may serve as an additional supervisory signal. Specifically, we propose an objective that transfers supervision from neighboring examples. We first study the properties of our developed method in a controlled toy setup before reporting results on multi-label classification and two image-grounded sequence modeling tasks {\u2013} captioning and question generation. We evaluate using standard task-specific metrics and measures of output diversity, finding consistent improvements over standard maximum likelihood training and other baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kalyan18a/kalyan18a.pdf",
        "supp": "",
        "pdf_size": 709841,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8208148588536981454&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Georgia Tech; Georgia Tech; Curai; Facebook AI Research",
        "aff_domain": "gatech.edu; ; ; ",
        "email": "gatech.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kalyan18a.html",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Georgia Institute of Technology;Curai;Meta",
        "aff_unique_dep": ";;Facebook AI Research",
        "aff_unique_url": "https://www.gatech.edu;https://www.curai.com;https://research.facebook.com",
        "aff_unique_abbr": "Georgia Tech;Curai;FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Adversarially Fair and Transferable Representations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2393",
        "id": "2393",
        "author_site": "David Madras, Elliot Creager, Toniann Pitassi, Richard Zemel",
        "author": "David Madras; Elliot Creager; Toniann Pitassi; Richard Zemel",
        "abstract": "In this paper, we advocate for representation learning as the key to mitigating unfair prediction outcomes downstream. Motivated by a scenario where learned representations are used by third parties with unknown objectives, we propose and explore adversarial representation learning as a natural method of ensuring those parties act fairly. We connect group fairness (demographic parity, equalized odds, and equal opportunity) to different adversarial objectives. Through worst-case theoretical guarantees and experimental validation, we show that the choice of this objective is crucial to fair prediction. Furthermore, we present the first in-depth experimental demonstration of fair transfer learning and demonstrate empirically that our learned representations admit fair predictions on new tasks while maintaining utility, an essential goal of fair representation learning.",
        "bibtex": "@InProceedings{pmlr-v80-madras18a,\n  title = \t {Learning Adversarially Fair and Transferable Representations},\n  author =       {Madras, David and Creager, Elliot and Pitassi, Toniann and Zemel, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3384--3393},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/madras18a/madras18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/madras18a.html},\n  abstract = \t {In this paper, we advocate for representation learning as the key to mitigating unfair prediction outcomes downstream. Motivated by a scenario where learned representations are used by third parties with unknown objectives, we propose and explore adversarial representation learning as a natural method of ensuring those parties act fairly. We connect group fairness (demographic parity, equalized odds, and equal opportunity) to different adversarial objectives. Through worst-case theoretical guarantees and experimental validation, we show that the choice of this objective is crucial to fair prediction. Furthermore, we present the first in-depth experimental demonstration of fair transfer learning and demonstrate empirically that our learned representations admit fair predictions on new tasks while maintaining utility, an essential goal of fair representation learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/madras18a/madras18a.pdf",
        "supp": "",
        "pdf_size": 548702,
        "gs_citation": 851,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6932272369084023440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada; Department of Computer Science, University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada; Department of Computer Science, University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada; Department of Computer Science, University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada",
        "aff_domain": "cs.toronto.edu; ; ; ",
        "email": "cs.toronto.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/madras18a.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "University of Toronto;Vector Institute",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.utoronto.ca;https://vectorinstitute.ai",
        "aff_unique_abbr": "U of T;Vector Institute",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Learning Binary Latent Variable Models: A Tensor Eigenpair Approach",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2053",
        "id": "2053",
        "author_site": "Ariel Jaffe, Roi Weiss, Boaz Nadler, Shai Carmi, Yuval Kluger",
        "author": "Ariel Jaffe; Roi Weiss; Boaz Nadler; Shai Carmi; Yuval Kluger",
        "abstract": "Latent variable models with hidden binary units appear in various applications. Learning such models, in particular in the presence of noise, is a challenging computational problem. In this paper we propose a novel spectral approach to this problem, based on the eigenvectors of both the second order moment matrix and third order moment tensor of the observed data. We prove that under mild non-degeneracy conditions, our method consistently estimates the model parameters at the optimal parametric rate. Our tensor-based method generalizes previous orthogonal tensor decomposition approaches, where the hidden units were assumed to be either statistically independent or mutually exclusive. We illustrate the consistency of our method on simulated data and demonstrate its usefulness in learning a common model for population mixtures in genetics.",
        "bibtex": "@InProceedings{pmlr-v80-jaffe18a,\n  title = \t {Learning Binary Latent Variable Models: A Tensor Eigenpair Approach},\n  author =       {Jaffe, Ariel and Weiss, Roi and Nadler, Boaz and Carmi, Shai and Kluger, Yuval},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2196--2205},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jaffe18a/jaffe18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jaffe18a.html},\n  abstract = \t {Latent variable models with hidden binary units appear in various applications. Learning such models, in particular in the presence of noise, is a challenging computational problem. In this paper we propose a novel spectral approach to this problem, based on the eigenvectors of both the second order moment matrix and third order moment tensor of the observed data. We prove that under mild non-degeneracy conditions, our method consistently estimates the model parameters at the optimal parametric rate. Our tensor-based method generalizes previous orthogonal tensor decomposition approaches, where the hidden units were assumed to be either statistically independent or mutually exclusive. We illustrate the consistency of our method on simulated data and demonstrate its usefulness in learning a common model for population mixtures in genetics.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jaffe18a/jaffe18a.pdf",
        "supp": "",
        "pdf_size": 540901,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2293549350827967377&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Dept. of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot 7610001, Israel; Dept. of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot 7610001, Israel; Braun School of Public Health and Community Medicine, The Hebrew University of Jerusalem, Jerusalem 9112102, Israel; Program of Applied Mathematics, Yale University, New Haven, CT 06511, USA; Dept. of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot 7610001, Israel",
        "aff_domain": "weizmann.ac.il;weizmann.ac.il; ; ; ",
        "email": "weizmann.ac.il;weizmann.ac.il; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/jaffe18a.html",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Weizmann Institute of Science;Hebrew University of Jerusalem;Yale University",
        "aff_unique_dep": "Dept. of Computer Science and Applied Mathematics;Braun School of Public Health and Community Medicine;Program of Applied Mathematics",
        "aff_unique_url": "https://www.weizmann.ac.il;https://www.huji.ac.il;https://www.yale.edu",
        "aff_unique_abbr": "Weizmann;HUJI;Yale",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Rehovot;Jerusalem;New Haven",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Israel;United States"
    },
    {
        "title": "Learning Compact Neural Networks with Regularization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1933",
        "id": "1933",
        "author": "Samet Oymak",
        "abstract": "Proper regularization is critical for speeding up training, improving generalization performance, and learning compact models that are cost efficient. We propose and analyze regularized gradient descent algorithms for learning shallow neural networks. Our framework is general and covers weight-sharing (convolutional networks), sparsity (network pruning), and low-rank constraints among others. We first introduce covering dimension to quantify the complexity of the constraint set and provide insights on the generalization properties. Then, we show that proposed algorithms become well-behaved and local linear convergence occurs once the amount of data exceeds the covering dimension. Overall, our results demonstrate that near-optimal sample complexity is sufficient for efficient learning and illustrate how regularization can be beneficial to learn over-parameterized networks.",
        "bibtex": "@InProceedings{pmlr-v80-oymak18a,\n  title = \t {Learning Compact Neural Networks with Regularization},\n  author =       {Oymak, Samet},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3966--3975},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/oymak18a/oymak18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/oymak18a.html},\n  abstract = \t {Proper regularization is critical for speeding up training, improving generalization performance, and learning compact models that are cost efficient. We propose and analyze regularized gradient descent algorithms for learning shallow neural networks. Our framework is general and covers weight-sharing (convolutional networks), sparsity (network pruning), and low-rank constraints among others. We first introduce covering dimension to quantify the complexity of the constraint set and provide insights on the generalization properties. Then, we show that proposed algorithms become well-behaved and local linear convergence occurs once the amount of data exceeds the covering dimension. Overall, our results demonstrate that near-optimal sample complexity is sufficient for efficient learning and illustrate how regularization can be beneficial to learn over-parameterized networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/oymak18a/oymak18a.pdf",
        "supp": "",
        "pdf_size": 915896,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2486847204383435662&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, Riverside, CA, USA + The Voleon Group, Berkeley, CA, USA",
        "aff_domain": "ece.ucr.edu",
        "email": "ece.ucr.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/oymak18a.html",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "University of California, Riverside;University of California, Berkeley",
        "aff_unique_dep": ";The Voleon Group",
        "aff_unique_url": "https://www.ucr.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UCR;UC Berkeley",
        "aff_campus_unique_index": "0+1",
        "aff_campus_unique": "Riverside;Berkeley",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2370",
        "id": "2370",
        "author_site": "Maximilian Nickel, Douwe Kiela",
        "author": "Maximillian Nickel; Douwe Kiela",
        "abstract": "We are concerned with the discovery of hierarchical relationships from large-scale unstructured similarity scores. For this purpose, we study different models of hyperbolic space and find that learning embeddings in the Lorentz model is substantially more efficient than in the Poincar{\u00e9}-ball model. We show that the proposed approach allows us to learn high-quality embeddings of large taxonomies which yield improvements over Poincar{\u00e9} embeddings, especially in low dimensions. Lastly, we apply our model to discover hierarchies in two real-world datasets: we show that an embedding in hyperbolic space can reveal important aspects of a company\u2019s organizational structure as well as reveal historical relationships between language families.",
        "bibtex": "@InProceedings{pmlr-v80-nickel18a,\n  title = \t {Learning Continuous Hierarchies in the {L}orentz Model of Hyperbolic Geometry},\n  author =       {Nickel, Maximillian and Kiela, Douwe},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3779--3788},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nickel18a/nickel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nickel18a.html},\n  abstract = \t {We are concerned with the discovery of hierarchical relationships from large-scale unstructured similarity scores. For this purpose, we study different models of hyperbolic space and find that learning embeddings in the Lorentz model is substantially more efficient than in the Poincar{\u00e9}-ball model. We show that the proposed approach allows us to learn high-quality embeddings of large taxonomies which yield improvements over Poincar{\u00e9} embeddings, especially in low dimensions. Lastly, we apply our model to discover hierarchies in two real-world datasets: we show that an embedding in hyperbolic space can reveal important aspects of a company\u2019s organizational structure as well as reveal historical relationships between language families.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nickel18a/nickel18a.pdf",
        "supp": "",
        "pdf_size": 1321493,
        "gs_citation": 568,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5235601311596588081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Facebook AI Research, New York, NY, USA; Facebook AI Research, New York, NY, USA",
        "aff_domain": "fb.com; ",
        "email": "fb.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/nickel18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Deep ResNet Blocks Sequentially using Boosting Theory",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2107",
        "id": "2107",
        "author_site": "Furong Huang, Jordan Ash, John Langford, Robert Schapire",
        "author": "Furong Huang; Jordan Ash; John Langford; Robert Schapire",
        "abstract": "We prove a",
        "bibtex": "@InProceedings{pmlr-v80-huang18b,\n  title = \t {Learning Deep {R}es{N}et Blocks Sequentially using Boosting Theory},\n  author =       {Huang, Furong and Ash, Jordan and Langford, John and Schapire, Robert},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2058--2067},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/huang18b/huang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/huang18b.html},\n  abstract = \t {We prove a",
        "pdf": "http://proceedings.mlr.press/v80/huang18b/huang18b.pdf",
        "supp": "",
        "pdf_size": 728103,
        "gs_citation": 136,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10501544880463084863&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, University of Maryland; Department of Computer Science, Princeton University; Microsoft Research; Microsoft Research",
        "aff_domain": "cs.umd.edu; ; ; ",
        "email": "cs.umd.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/huang18b.html",
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Maryland;Princeton University;Microsoft",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Microsoft Research",
        "aff_unique_url": "https://www/umd.edu;https://www.princeton.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "UMD;Princeton;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Diffusion using Hyperparameters",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1880",
        "id": "1880",
        "author_site": "Dimitrios Kalimeris, Yaron Singer, Karthik Subbian, Udi Weinsberg",
        "author": "Dimitris Kalimeris; Yaron Singer; Karthik Subbian; Udi Weinsberg",
        "abstract": "In this paper we advocate for a hyperparametric approach to learn diffusion in the independent cascade (IC) model. The sample complexity of this model is a function of the number of edges in the network and consequently learning becomes infeasible when the network is large. We study a natural restriction of the hypothesis class using additional information available in order to dramatically reduce the sample complexity of the learning process. In particular we assume that diffusion probabilities can be described as a function of a global hyperparameter and features of the individuals in the network. One of the main challenges with this approach is that training a model reduces to optimizing a non-convex objective. Despite this obstacle, we can shrink the best-known sample complexity bound for learning IC by a factor of |E|/d where |E| is the number of edges in the graph and d is the dimension of the hyperparameter. We show that under mild assumptions about the distribution generating the samples one can provably train a model with low generalization error. Finally, we use large-scale diffusion data from Facebook to show that a hyperparametric model using approximately 20 features per node achieves remarkably high accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-kalimeris18a,\n  title = \t {Learning Diffusion using Hyperparameters},\n  author =       {Kalimeris, Dimitris and Singer, Yaron and Subbian, Karthik and Weinsberg, Udi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2420--2428},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kalimeris18a/kalimeris18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kalimeris18a.html},\n  abstract = \t {In this paper we advocate for a hyperparametric approach to learn diffusion in the independent cascade (IC) model. The sample complexity of this model is a function of the number of edges in the network and consequently learning becomes infeasible when the network is large. We study a natural restriction of the hypothesis class using additional information available in order to dramatically reduce the sample complexity of the learning process. In particular we assume that diffusion probabilities can be described as a function of a global hyperparameter and features of the individuals in the network. One of the main challenges with this approach is that training a model reduces to optimizing a non-convex objective. Despite this obstacle, we can shrink the best-known sample complexity bound for learning IC by a factor of |E|/d where |E| is the number of edges in the graph and d is the dimension of the hyperparameter. We show that under mild assumptions about the distribution generating the samples one can provably train a model with low generalization error. Finally, we use large-scale diffusion data from Facebook to show that a hyperparametric model using approximately 20 features per node achieves remarkably high accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kalimeris18a/kalimeris18a.pdf",
        "supp": "",
        "pdf_size": 520954,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5088518944626589309&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Harvard University; Department of Computer Science, Harvard University; Facebook, Menlo Park; Facebook, Menlo Park",
        "aff_domain": "g.harvard.edu; ; ; ",
        "email": "g.harvard.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kalimeris18a.html",
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Harvard University;Meta",
        "aff_unique_dep": "Department of Computer Science;Facebook",
        "aff_unique_url": "https://www.harvard.edu;https://www.facebook.com",
        "aff_unique_abbr": "Harvard;FB",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Cambridge;Menlo Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Dynamics of Linear Denoising Autoencoders",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2013",
        "id": "2013",
        "author_site": "Arnu Pretorius, Steve Kroon, Herman Kamper",
        "author": "Arnu Pretorius; Steve Kroon; Herman Kamper",
        "abstract": "Denoising autoencoders (DAEs) have proven useful for unsupervised representation learning, but a thorough theoretical understanding is still lacking of how the input noise influences learning. Here we develop theory for how noise influences learning in DAEs. By focusing on linear DAEs, we are able to derive analytic expressions that exactly describe their learning dynamics. We verify our theoretical predictions with simulations as well as experiments on MNIST and CIFAR-10. The theory illustrates how, when tuned correctly, noise allows DAEs to ignore low variance directions in the inputs while learning to reconstruct them. Furthermore, in a comparison of the learning dynamics of DAEs to standard regularised autoencoders, we show that noise has a similar regularisation effect to weight decay, but with faster training dynamics. We also show that our theoretical predictions approximate learning dynamics on real-world data and qualitatively match observed dynamics in nonlinear DAEs.",
        "bibtex": "@InProceedings{pmlr-v80-pretorius18a,\n  title = \t {Learning Dynamics of Linear Denoising Autoencoders},\n  author =       {Pretorius, Arnu and Kroon, Steve and Kamper, Herman},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4141--4150},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pretorius18a/pretorius18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pretorius18a.html},\n  abstract = \t {Denoising autoencoders (DAEs) have proven useful for unsupervised representation learning, but a thorough theoretical understanding is still lacking of how the input noise influences learning. Here we develop theory for how noise influences learning in DAEs. By focusing on linear DAEs, we are able to derive analytic expressions that exactly describe their learning dynamics. We verify our theoretical predictions with simulations as well as experiments on MNIST and CIFAR-10. The theory illustrates how, when tuned correctly, noise allows DAEs to ignore low variance directions in the inputs while learning to reconstruct them. Furthermore, in a comparison of the learning dynamics of DAEs to standard regularised autoencoders, we show that noise has a similar regularisation effect to weight decay, but with faster training dynamics. We also show that our theoretical predictions approximate learning dynamics on real-world data and qualitatively match observed dynamics in nonlinear DAEs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pretorius18a/pretorius18a.pdf",
        "supp": "",
        "pdf_size": 1838985,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11573052296697932394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Computer Science Division, Stellenbosch University, South Africa+CSIR/SU Centre for Arti\ufb01cial Intelligence Research; Computer Science Division, Stellenbosch University, South Africa+CSIR/SU Centre for Arti\ufb01cial Intelligence Research; Department of Electrical and Electronic Engineering, Stellenbosch University, South Africa",
        "aff_domain": "sun.ac.za;sun.ac.za;sun.ac.za",
        "email": "sun.ac.za;sun.ac.za;sun.ac.za",
        "github": "https://github.com/arnupretorius/lindaedynamics_icml2018",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/pretorius18a.html",
        "aff_unique_index": "0+1;0+1;0",
        "aff_unique_norm": "Stellenbosch University;CSIR/SU Centre for Artificial Intelligence Research",
        "aff_unique_dep": "Computer Science Division;Centre for Artificial Intelligence Research",
        "aff_unique_url": "https://www.sun.ac.za;https://www.csir.co.za",
        "aff_unique_abbr": "SU;CSIR AI",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "title": "Learning Equations for Extrapolation and Control",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2364",
        "id": "2364",
        "author_site": "Subham S Sahoo, Christoph H. Lampert, Georg Martius",
        "author": "Subham Sahoo; Christoph Lampert; Georg Martius",
        "abstract": "We present an approach to identify concise equations from data using a shallow neural network approach. In contrast to ordinary black-box regression, this approach allows understanding functional relations and generalizing them from observed data to unseen parts of the parameter space. We show how to extend the class of learnable equations for a recently proposed equation learning network to include divisions, and we improve the learning and model selection strategy to be useful for challenging real-world data. For systems governed by analytical expressions, our method can in many cases identify the true underlying equation and extrapolate to unseen domains. We demonstrate its effectiveness by experiments on a cart-pendulum system, where only 2 random rollouts are required to learn the forward dynamics and successfully achieve the swing-up task.",
        "bibtex": "@InProceedings{pmlr-v80-sahoo18a,\n  title = \t {Learning Equations for Extrapolation and Control},\n  author =       {Sahoo, Subham and Lampert, Christoph and Martius, Georg},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4442--4450},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sahoo18a/sahoo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sahoo18a.html},\n  abstract = \t {We present an approach to identify concise equations from data using a shallow neural network approach. In contrast to ordinary black-box regression, this approach allows understanding functional relations and generalizing them from observed data to unseen parts of the parameter space. We show how to extend the class of learnable equations for a recently proposed equation learning network to include divisions, and we improve the learning and model selection strategy to be useful for challenging real-world data. For systems governed by analytical expressions, our method can in many cases identify the true underlying equation and extrapolate to unseen domains. We demonstrate its effectiveness by experiments on a cart-pendulum system, where only 2 random rollouts are required to learn the forward dynamics and successfully achieve the swing-up task.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sahoo18a/sahoo18a.pdf",
        "supp": "",
        "pdf_size": 2059806,
        "gs_citation": 331,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17858101000872488447&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/sahoo18a.html"
    },
    {
        "title": "Learning Hidden Markov Models from Pairwise Co-occurrences with Application to Topic Modeling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2231",
        "id": "2231",
        "author_site": "Kejun Huang, Xiao Fu, Nicholas Sidiropoulos",
        "author": "Kejun Huang; Xiao Fu; Nicholas Sidiropoulos",
        "abstract": "We present a new algorithm for identifying the transition and emission probabilities of a hidden Markov model (HMM) from the emitted data. Expectation-maximization becomes computationally prohibitive for long observation records, which are often required for identification. The new algorithm is particularly suitable for cases where the available sample size is large enough to accurately estimate second-order output probabilities, but not higher-order ones. We show that if one is only able to obtain a reliable estimate of the pairwise co-occurrence probabilities of the emissions, it is still possible to uniquely identify the HMM if the emission probability is",
        "bibtex": "@InProceedings{pmlr-v80-huang18c,\n  title = \t {Learning Hidden {M}arkov Models from Pairwise Co-occurrences with Application to Topic Modeling},\n  author =       {Huang, Kejun and Fu, Xiao and Sidiropoulos, Nicholas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2068--2077},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/huang18c/huang18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/huang18c.html},\n  abstract = \t {We present a new algorithm for identifying the transition and emission probabilities of a hidden Markov model (HMM) from the emitted data. Expectation-maximization becomes computationally prohibitive for long observation records, which are often required for identification. The new algorithm is particularly suitable for cases where the available sample size is large enough to accurately estimate second-order output probabilities, but not higher-order ones. We show that if one is only able to obtain a reliable estimate of the pairwise co-occurrence probabilities of the emissions, it is still possible to uniquely identify the HMM if the emission probability is",
        "pdf": "http://proceedings.mlr.press/v80/huang18c/huang18c.pdf",
        "supp": "",
        "pdf_size": 320660,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3680544553506414247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Minnesota, Minneapolis, MN 55455; Oregon State University, Corvallis, OR 97331; University of Virginia, Charlottesville, VA 22904",
        "aff_domain": "umn.edu;oregonstate.edu;virginia.edu",
        "email": "umn.edu;oregonstate.edu;virginia.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/huang18c.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Minnesota;Oregon State University;University of Virginia",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.minnesota.edu;https://oregonstate.edu;https://www.virginia.edu",
        "aff_unique_abbr": "UMN;OSU;UVA",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Minneapolis;Corvallis;Charlottesville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Implicit Generative Models with the Method of Learned Moments",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2251",
        "id": "2251",
        "author_site": "Suman Ravuri, Shakir Mohamed, Mihaela Rosca, Oriol Vinyals",
        "author": "Suman Ravuri; Shakir Mohamed; Mihaela Rosca; Oriol Vinyals",
        "abstract": "We propose a method of moments (MoM) algorithm for training large-scale implicit generative models. Moment estimation in this setting encounters two problems: it is often difficult to define the millions of moments needed to learn the model parameters, and it is hard to determine which properties are useful when specifying moments. To address the first issue, we introduce a moment network, and define the moments as the network\u2019s hidden units and the gradient of the network\u2019s output with respect to its parameters. To tackle the second problem, we use asymptotic theory to highlight desiderata for moments \u2013 namely they should minimize the asymptotic variance of estimated model parameters \u2013 and introduce an objective to learn better moments. The sequence of objectives created by this Method of Learned Moments (MoLM) can train high-quality neural image samplers. On CIFAR-10, we demonstrate that MoLM-trained generators achieve significantly higher Inception Scores and lower Frechet Inception Distances than those trained with gradient penalty-regularized and spectrally-normalized adversarial objectives. These generators also achieve nearly perfect Multi-Scale Structural Similarity Scores on CelebA, and can create high-quality samples of 128x128 images.",
        "bibtex": "@InProceedings{pmlr-v80-ravuri18a,\n  title = \t {Learning Implicit Generative Models with the Method of Learned Moments},\n  author =       {Ravuri, Suman and Mohamed, Shakir and Rosca, Mihaela and Vinyals, Oriol},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4314--4323},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ravuri18a/ravuri18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ravuri18a.html},\n  abstract = \t {We propose a method of moments (MoM) algorithm for training large-scale implicit generative models. Moment estimation in this setting encounters two problems: it is often difficult to define the millions of moments needed to learn the model parameters, and it is hard to determine which properties are useful when specifying moments. To address the first issue, we introduce a moment network, and define the moments as the network\u2019s hidden units and the gradient of the network\u2019s output with respect to its parameters. To tackle the second problem, we use asymptotic theory to highlight desiderata for moments \u2013 namely they should minimize the asymptotic variance of estimated model parameters \u2013 and introduce an objective to learn better moments. The sequence of objectives created by this Method of Learned Moments (MoLM) can train high-quality neural image samplers. On CIFAR-10, we demonstrate that MoLM-trained generators achieve significantly higher Inception Scores and lower Frechet Inception Distances than those trained with gradient penalty-regularized and spectrally-normalized adversarial objectives. These generators also achieve nearly perfect Multi-Scale Structural Similarity Scores on CelebA, and can create high-quality samples of 128x128 images.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ravuri18a/ravuri18a.pdf",
        "supp": "",
        "pdf_size": 2277252,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15268389797011125418&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "DeepMind London, N1C 4AG, UK; DeepMind London, N1C 4AG, UK; DeepMind London, N1C 4AG, UK; DeepMind London, N1C 4AG, UK",
        "aff_domain": "google.com; ; ; ",
        "email": "google.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ravuri18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Learning Independent Causal Mechanisms",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2049",
        "id": "2049",
        "author_site": "Giambattista Parascandolo, Niki Kilbertus, Mateo Rojas-Carulla, Bernhard Sch\u00f6lkopf",
        "author": "Giambattista Parascandolo; Niki Kilbertus; Mateo Rojas-Carulla; Bernhard Sch\u00f6lkopf",
        "abstract": "Statistical learning relies upon data sampled from a distribution, and we usually do not care what actually generated it in the first place. From the point of view of causal modeling, the structure of each distribution is induced by physical mechanisms that give rise to dependences between observables. Mechanisms, however, can be meaningful autonomous modules of generative models that make sense beyond a particular entailed data distribution, lending themselves to transfer between problems. We develop an algorithm to recover a set of independent (inverse) mechanisms from a set of transformed data points. The approach is unsupervised and based on a set of experts that compete for data generated by the mechanisms, driving specialization. We analyze the proposed method in a series of experiments on image data. Each expert learns to map a subset of the transformed data back to a reference distribution. The learned mechanisms generalize to novel domains. We discuss implications for transfer learning and links to recent trends in generative modeling.",
        "bibtex": "@InProceedings{pmlr-v80-parascandolo18a,\n  title = \t {Learning Independent Causal Mechanisms},\n  author =       {Parascandolo, Giambattista and Kilbertus, Niki and Rojas-Carulla, Mateo and Sch{\\\"o}lkopf, Bernhard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4036--4044},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/parascandolo18a/parascandolo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/parascandolo18a.html},\n  abstract = \t {Statistical learning relies upon data sampled from a distribution, and we usually do not care what actually generated it in the first place. From the point of view of causal modeling, the structure of each distribution is induced by physical mechanisms that give rise to dependences between observables. Mechanisms, however, can be meaningful autonomous modules of generative models that make sense beyond a particular entailed data distribution, lending themselves to transfer between problems. We develop an algorithm to recover a set of independent (inverse) mechanisms from a set of transformed data points. The approach is unsupervised and based on a set of experts that compete for data generated by the mechanisms, driving specialization. We analyze the proposed method in a series of experiments on image data. Each expert learns to map a subset of the transformed data back to a reference distribution. The learned mechanisms generalize to novel domains. We discuss implications for transfer learning and links to recent trends in generative modeling.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/parascandolo18a/parascandolo18a.pdf",
        "supp": "",
        "pdf_size": 1512250,
        "gs_citation": 206,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1033682372481921023&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Max Planck Institute for Intelligent Systems; Max Planck ETH Center for Learning Systems; University of Cambridge; Max Planck Institute for Intelligent Systems",
        "aff_domain": "tue.mpg.de; ; ; ",
        "email": "tue.mpg.de; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/parascandolo18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Max Planck ETH Center for Learning Systems;University of Cambridge",
        "aff_unique_dep": "Intelligent Systems;Center for Learning Systems;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://learning-systems.org;https://www.cam.ac.uk",
        "aff_unique_abbr": "MPI-IS;;Cambridge",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Germany;Switzerland;United Kingdom"
    },
    {
        "title": "Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2284",
        "id": "2284",
        "author_site": "Ting Chen, Martin Min, Yizhou Sun",
        "author": "Ting Chen; Martin Renqiang Min; Yizhou Sun",
        "abstract": "Conventional embedding methods directly associate each symbol with a continuous embedding vector, which is equivalent to applying a linear transformation based on a \u201cone-hot\u201d encoding of the discrete symbols. Despite its simplicity, such approach yields the number of parameters that grows linearly with the vocabulary size and can lead to overfitting. In this work, we propose a much more compact K-way D-dimensional discrete encoding scheme to replace the \u201cone-hot\" encoding. In the proposed \u201cKD encoding\u201d, each symbol is represented by a $D$-dimensional code with a cardinality of $K$, and the final symbol embedding vector is generated by composing the code embedding vectors. To end-to-end learn semantically meaningful codes, we derive a relaxed discrete optimization approach based on stochastic gradient descent, which can be generally applied to any differentiable computational graph with an embedding layer. In our experiments with various applications from natural language processing to graph convolutional networks, the total size of the embedding layer can be reduced up to 98% while achieving similar or better performance.",
        "bibtex": "@InProceedings{pmlr-v80-chen18g,\n  title = \t {Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations},\n  author =       {Chen, Ting and Min, Martin Renqiang and Sun, Yizhou},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {854--863},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18g/chen18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18g.html},\n  abstract = \t {Conventional embedding methods directly associate each symbol with a continuous embedding vector, which is equivalent to applying a linear transformation based on a \u201cone-hot\u201d encoding of the discrete symbols. Despite its simplicity, such approach yields the number of parameters that grows linearly with the vocabulary size and can lead to overfitting. In this work, we propose a much more compact K-way D-dimensional discrete encoding scheme to replace the \u201cone-hot\" encoding. In the proposed \u201cKD encoding\u201d, each symbol is represented by a $D$-dimensional code with a cardinality of $K$, and the final symbol embedding vector is generated by composing the code embedding vectors. To end-to-end learn semantically meaningful codes, we derive a relaxed discrete optimization approach based on stochastic gradient descent, which can be generally applied to any differentiable computational graph with an embedding layer. In our experiments with various applications from natural language processing to graph convolutional networks, the total size of the embedding layer can be reduced up to 98% while achieving similar or better performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18g/chen18g.pdf",
        "supp": "",
        "pdf_size": 1371608,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5885997397535824827&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, University of California, Los Angeles; NEC Laboratories America; Department of Computer Science, University of California, Los Angeles",
        "aff_domain": "cs.ucla.edu; ; ",
        "email": "cs.ucla.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chen18g.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;NEC Laboratories America",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.ucla.edu;https://www.nec-labs.com",
        "aff_unique_abbr": "UCLA;NEC Labs America",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Localized Spatio-Temporal Models From Streaming Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2015",
        "id": "2015",
        "author_site": "Muhammad Osama, Dave Zachariah, Thomas Sch\u00f6n",
        "author": "Muhammad Osama; Dave Zachariah; Thomas Sch\u00f6n",
        "abstract": "We address the problem of predicting spatio-temporal processes with temporal patterns that vary across spatial regions, when data is obtained as a stream. That is, when the training dataset is augmented sequentially. Specifically, we develop a localized spatio-temporal covariance model of the process that can capture spatially varying temporal periodicities in the data. We then apply a covariance-fitting methodology to learn the model parameters which yields a predictor that can be updated sequentially with each new data point. The proposed method is evaluated using both synthetic and real climate data which demonstrate its ability to accurately predict data missing in spatial regions over time.",
        "bibtex": "@InProceedings{pmlr-v80-osama18a,\n  title = \t {Learning Localized Spatio-Temporal Models From Streaming Data},\n  author =       {Osama, Muhammad and Zachariah, Dave and Sch{\\\"o}n, Thomas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3927--3935},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/osama18a/osama18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/osama18a.html},\n  abstract = \t {We address the problem of predicting spatio-temporal processes with temporal patterns that vary across spatial regions, when data is obtained as a stream. That is, when the training dataset is augmented sequentially. Specifically, we develop a localized spatio-temporal covariance model of the process that can capture spatially varying temporal periodicities in the data. We then apply a covariance-fitting methodology to learn the model parameters which yields a predictor that can be updated sequentially with each new data point. The proposed method is evaluated using both synthetic and real climate data which demonstrate its ability to accurately predict data missing in spatial regions over time.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/osama18a/osama18a.pdf",
        "supp": "",
        "pdf_size": 995701,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6273621603567429406&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Uppsala University; Uppsala University; Uppsala University",
        "aff_domain": "it.uu.se;it.uu.se; ",
        "email": "it.uu.se;it.uu.se; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/osama18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Uppsala University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uu.se",
        "aff_unique_abbr": "UU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "title": "Learning Long Term Dependencies via Fourier Recurrent Units",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2006",
        "id": "2006",
        "author_site": "Jiong Zhang, Yibo Lin, Zhao Song, Inderjit Dhillon",
        "author": "Jiong Zhang; Yibo Lin; Zhao Song; Inderjit Dhillon",
        "abstract": "It is a known fact that training recurrent neural networks for tasks that have long term dependencies is challenging. One of the main reasons is the vanishing or exploding gradient problem, which prevents gradient information from propagating to early layers. In this paper we propose a simple recurrent architecture, the Fourier Recurrent Unit (FRU), that stabilizes the gradients that arise in its training while giving us stronger expressive power. Specifically, FRU summarizes the hidden states $h^{(t)}$ along the temporal dimension with Fourier basis functions. This allows gradients to easily reach any layer due to FRU\u2019s residual learning structure and the global support of trigonometric functions. We show that FRU has gradient lower and upper bounds independent of temporal dimension. We also show the strong expressivity of sparse Fourier basis, from which FRU obtains its strong expressive power. Our experimental study also demonstrates that with fewer parameters the proposed architecture outperforms other recurrent architectures on many tasks.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18h,\n  title = \t {Learning Long Term Dependencies via {F}ourier Recurrent Units},\n  author =       {Zhang, Jiong and Lin, Yibo and Song, Zhao and Dhillon, Inderjit},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5815--5823},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18h/zhang18h.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18h.html},\n  abstract = \t {It is a known fact that training recurrent neural networks for tasks that have long term dependencies is challenging. One of the main reasons is the vanishing or exploding gradient problem, which prevents gradient information from propagating to early layers. In this paper we propose a simple recurrent architecture, the Fourier Recurrent Unit (FRU), that stabilizes the gradients that arise in its training while giving us stronger expressive power. Specifically, FRU summarizes the hidden states $h^{(t)}$ along the temporal dimension with Fourier basis functions. This allows gradients to easily reach any layer due to FRU\u2019s residual learning structure and the global support of trigonometric functions. We show that FRU has gradient lower and upper bounds independent of temporal dimension. We also show the strong expressivity of sparse Fourier basis, from which FRU obtains its strong expressive power. Our experimental study also demonstrates that with fewer parameters the proposed architecture outperforms other recurrent architectures on many tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18h/zhang18h.pdf",
        "supp": "",
        "pdf_size": 674241,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16150244378271641439&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "UT-Austin; UT-Austin; Harvard & UT-Austin; UT-Austin & Amazon",
        "aff_domain": "utexas.edu;utexas.edu;seas.harvard.edu;cs.utexas.edu",
        "email": "utexas.edu;utexas.edu;seas.harvard.edu;cs.utexas.edu",
        "github": "",
        "project": "https://arxiv.org/pdf/1803.06585",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/zhang18h.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Texas at Austin;Harvard University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.harvard.edu",
        "aff_unique_abbr": "UT Austin;Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2127",
        "id": "2127",
        "author_site": "Trieu H Trinh, Andrew Dai, Thang Luong, Quoc Le",
        "author": "Trieu Trinh; Andrew Dai; Thang Luong; Quoc Le",
        "abstract": "Despite recent advances in training recurrent neural networks (RNNs), capturing long-term dependencies in sequences remains a fundamental challenge. Most approaches use backpropagation through time (BPTT), which is difficult to scale to very long sequences. This paper proposes a simple method that improves the ability to capture long term dependencies in RNNs by adding an unsupervised auxiliary loss to the original objective. This auxiliary loss forces RNNs to either reconstruct previous events or predict next events in a sequence, making truncated backpropagation feasible for long sequences and also improving full BPTT. We evaluate our method on a variety of settings, including pixel-by-pixel image classification with sequence lengths up to 16000, and a real document classification benchmark. Our results highlight good performance and resource efficiency of this approach over competitive baselines, including other recurrent models and a comparable sized Transformer. Further analyses reveal beneficial effects of the auxiliary loss on optimization and regularization, as well as extreme cases where there is little to no backpropagation.",
        "bibtex": "@InProceedings{pmlr-v80-trinh18a,\n  title = \t {Learning Longer-term Dependencies in {RNN}s with Auxiliary Losses},\n  author =       {Trinh, Trieu and Dai, Andrew and Luong, Thang and Le, Quoc},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4965--4974},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/trinh18a/trinh18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/trinh18a.html},\n  abstract = \t {Despite recent advances in training recurrent neural networks (RNNs), capturing long-term dependencies in sequences remains a fundamental challenge. Most approaches use backpropagation through time (BPTT), which is difficult to scale to very long sequences. This paper proposes a simple method that improves the ability to capture long term dependencies in RNNs by adding an unsupervised auxiliary loss to the original objective. This auxiliary loss forces RNNs to either reconstruct previous events or predict next events in a sequence, making truncated backpropagation feasible for long sequences and also improving full BPTT. We evaluate our method on a variety of settings, including pixel-by-pixel image classification with sequence lengths up to 16000, and a real document classification benchmark. Our results highlight good performance and resource efficiency of this approach over competitive baselines, including other recurrent models and a comparable sized Transformer. Further analyses reveal beneficial effects of the auxiliary loss on optimization and regularization, as well as extreme cases where there is little to no backpropagation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/trinh18a/trinh18a.pdf",
        "supp": "",
        "pdf_size": 350545,
        "gs_citation": 246,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17665995543548139955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Google; Google; Google; Google",
        "aff_domain": "google.com;google.com;google.com;google.com",
        "email": "google.com;google.com;google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/trinh18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Low-Dimensional Temporal Representations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1910",
        "id": "1910",
        "author_site": "Bing Su, Ying Wu",
        "author": "Bing Su; Ying Wu",
        "abstract": "Low-dimensional discriminative representations enhance machine learning methods in both performance and complexity, motivating supervised dimensionality reduction (DR) that transforms high-dimensional data to a discriminative subspace. Most DR methods require data to be i.i.d., however, in some domains, data naturally come in sequences, where the observations are temporally correlated. We propose a DR method called LT-LDA to learn low-dimensional temporal representations. We construct the separability among sequence classes by lifting the holistic temporal structures, which are established based on temporal alignments and may change in different subspaces. We jointly learn the subspace and the associated alignments by optimizing an objective which favors easily-separable temporal structures, and show that this objective is connected to the inference of alignments, thus allows an iterative solution. We provide both theoretical insight and empirical evaluation on real-world sequence datasets to show the interest of our method.",
        "bibtex": "@InProceedings{pmlr-v80-su18a,\n  title = \t {Learning Low-Dimensional Temporal Representations},\n  author =       {Su, Bing and Wu, Ying},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4761--4770},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/su18a/su18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/su18a.html},\n  abstract = \t {Low-dimensional discriminative representations enhance machine learning methods in both performance and complexity, motivating supervised dimensionality reduction (DR) that transforms high-dimensional data to a discriminative subspace. Most DR methods require data to be i.i.d., however, in some domains, data naturally come in sequences, where the observations are temporally correlated. We propose a DR method called LT-LDA to learn low-dimensional temporal representations. We construct the separability among sequence classes by lifting the holistic temporal structures, which are established based on temporal alignments and may change in different subspaces. We jointly learn the subspace and the associated alignments by optimizing an objective which favors easily-separable temporal structures, and show that this objective is connected to the inference of alignments, thus allows an iterative solution. We provide both theoretical insight and empirical evaluation on real-world sequence datasets to show the interest of our method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/su18a/su18a.pdf",
        "supp": "",
        "pdf_size": 143318,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2979027931297576278&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Science & Technology on Integrated Information System Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/su18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Chinese Academy of Sciences;Northwestern University",
        "aff_unique_dep": "Institute of Software;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "http://www.ios.ac.cn;https://www.northwestern.edu",
        "aff_unique_abbr": "CAS;NU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Beijing;Evanston",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2436",
        "id": "2436",
        "author_site": "Asish Ghoshal, Jean Honorio",
        "author": "Asish Ghoshal; Jean Honorio",
        "abstract": "MAP perturbation models have emerged as a powerful framework for inference in structured prediction. Such models provide a way to efficiently sample from the Gibbs distribution and facilitate predictions that are robust to random noise. In this paper, we propose a provably polynomial time randomized algorithm for learning the parameters of perturbed MAP predictors. Our approach is based on minimizing a novel Rademacher-based generalization bound on the expected loss of a perturbed MAP predictor, which can be computed in polynomial time. We obtain conditions under which our randomized learning algorithm can guarantee generalization to unseen examples.",
        "bibtex": "@InProceedings{pmlr-v80-ghoshal18a,\n  title = \t {Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time},\n  author =       {Ghoshal, Asish and Honorio, Jean},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1754--1762},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ghoshal18a/ghoshal18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ghoshal18a.html},\n  abstract = \t {MAP perturbation models have emerged as a powerful framework for inference in structured prediction. Such models provide a way to efficiently sample from the Gibbs distribution and facilitate predictions that are robust to random noise. In this paper, we propose a provably polynomial time randomized algorithm for learning the parameters of perturbed MAP predictors. Our approach is based on minimizing a novel Rademacher-based generalization bound on the expected loss of a perturbed MAP predictor, which can be computed in polynomial time. We obtain conditions under which our randomized learning algorithm can guarantee generalization to unseen examples.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ghoshal18a/ghoshal18a.pdf",
        "supp": "",
        "pdf_size": 610819,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3948007554459683289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Purdue University, West Lafayette, IN - 47906; Department of Computer Science, Purdue University, West Lafayette, IN - 47906",
        "aff_domain": "purdue.edu;purdue.edu",
        "email": "purdue.edu;purdue.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/ghoshal18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Memory Access Patterns",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2243",
        "id": "2243",
        "author_site": "Milad Hashemi, Kevin Swersky, Jamie Smith, Grant Ayers, Heiner Litz, Jichuan Chang, Christos Kozyrakis, Parthasarathy Ranganathan",
        "author": "Milad Hashemi; Kevin Swersky; Jamie Smith; Grant Ayers; Heiner Litz; Jichuan Chang; Christos Kozyrakis; Parthasarathy Ranganathan",
        "abstract": "The explosion in workload complexity and the recent slow-down in Moore\u2019s law scaling call for new approaches towards efficient computing. Researchers are now beginning to use recent advances in machine learning in software optimizations; augmenting or replacing traditional heuristics and data structures. However, the space of machine learning for computer hardware architecture is only lightly explored. In this paper, we demonstrate the potential of deep learning to address the von Neumann bottleneck of memory performance. We focus on the critical problem of learning memory access patterns, with the goal of constructing accurate and efficient memory prefetchers. We relate contemporary prefetching strategies to n-gram models in natural language processing, and show how recurrent neural networks can serve as a drop-in replacement. On a suite of challenging benchmark datasets, we find that neural networks consistently demonstrate superior performance in terms of precision and recall. This work represents the first step towards practical neural-network based prefetching, and opens a wide range of exciting directions for machine learning in computer architecture research.",
        "bibtex": "@InProceedings{pmlr-v80-hashemi18a,\n  title = \t {Learning Memory Access Patterns},\n  author =       {Hashemi, Milad and Swersky, Kevin and Smith, Jamie and Ayers, Grant and Litz, Heiner and Chang, Jichuan and Kozyrakis, Christos and Ranganathan, Parthasarathy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1919--1928},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hashemi18a/hashemi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hashemi18a.html},\n  abstract = \t {The explosion in workload complexity and the recent slow-down in Moore\u2019s law scaling call for new approaches towards efficient computing. Researchers are now beginning to use recent advances in machine learning in software optimizations; augmenting or replacing traditional heuristics and data structures. However, the space of machine learning for computer hardware architecture is only lightly explored. In this paper, we demonstrate the potential of deep learning to address the von Neumann bottleneck of memory performance. We focus on the critical problem of learning memory access patterns, with the goal of constructing accurate and efficient memory prefetchers. We relate contemporary prefetching strategies to n-gram models in natural language processing, and show how recurrent neural networks can serve as a drop-in replacement. On a suite of challenging benchmark datasets, we find that neural networks consistently demonstrate superior performance in terms of precision and recall. This work represents the first step towards practical neural-network based prefetching, and opens a wide range of exciting directions for machine learning in computer architecture research.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hashemi18a/hashemi18a.pdf",
        "supp": "",
        "pdf_size": 3917528,
        "gs_citation": 278,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12510877250319122516&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Google; Google; Google; Stanford University; University of California, Santa Cruz; Google; Stanford University; Google",
        "aff_domain": "google.com;google.com; ; ; ; ; ;google.com",
        "email": "google.com;google.com; ; ; ; ; ;google.com",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/hashemi18a.html",
        "aff_unique_index": "0;0;0;1;2;0;1;0",
        "aff_unique_norm": "Google;Stanford University;University of California, Santa Cruz",
        "aff_unique_dep": "Google;;",
        "aff_unique_url": "https://www.google.com;https://www.stanford.edu;https://www.ucsc.edu",
        "aff_unique_abbr": "Google;Stanford;UCSC",
        "aff_campus_unique_index": "0;0;0;1;2;0;1;0",
        "aff_campus_unique": "Mountain View;Stanford;Santa Cruz",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning One Convolutional Layer with Overlapping Patches",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1985",
        "id": "1985",
        "author_site": "Surbhi Goel, Adam Klivans, Raghu Meka",
        "author": "Surbhi Goel; Adam Klivans; Raghu Meka",
        "abstract": "We give the first provably efficient algorithm for learning a one hidden layer convolutional network with respect to a general class of (potentially overlapping) patches under mild conditions on the underlying distribution. We prove that our framework captures commonly used schemes from computer vision, including one-dimensional and two-dimensional \u201cpatch and stride\u201d convolutions. Our algorithm\u2013",
        "bibtex": "@InProceedings{pmlr-v80-goel18a,\n  title = \t {Learning One Convolutional Layer with Overlapping Patches},\n  author =       {Goel, Surbhi and Klivans, Adam and Meka, Raghu},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1783--1791},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/goel18a/goel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/goel18a.html},\n  abstract = \t {We give the first provably efficient algorithm for learning a one hidden layer convolutional network with respect to a general class of (potentially overlapping) patches under mild conditions on the underlying distribution. We prove that our framework captures commonly used schemes from computer vision, including one-dimensional and two-dimensional \u201cpatch and stride\u201d convolutions. Our algorithm\u2013",
        "pdf": "http://proceedings.mlr.press/v80/goel18a/goel18a.pdf",
        "supp": "",
        "pdf_size": 388375,
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9638967642251022663&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of Texas at Austin; Department of Computer Science, University of Texas at Austin; Department of Computer Science, UCLA",
        "aff_domain": "cs.utexas.edu; ; ",
        "email": "cs.utexas.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/goel18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Texas at Austin;University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://www.ucla.edu",
        "aff_unique_abbr": "UT Austin;UCLA",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Austin;Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Policy Representations in Multiagent Systems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2435",
        "id": "2435",
        "author_site": "Aditya Grover, Maruan Al-Shedivat, Jayesh K. Gupta, Yura Burda, Harrison Edwards",
        "author": "Aditya Grover; Maruan Al-Shedivat; Jayesh Gupta; Yuri Burda; Harrison Edwards",
        "abstract": "Modeling agent behavior is central to understanding the emergence of complex phenomena in multiagent systems. Prior work in agent modeling has largely been task-specific and driven by hand-engineering domain-specific prior knowledge. We propose a general learning framework for modeling agent behavior in any multiagent system using only a handful of interaction data. Our framework casts agent modeling as a representation learning problem. Consequently, we construct a novel objective inspired by imitation learning and agent identification and design an algorithm for unsupervised learning of representations of agent policies. We demonstrate empirically the utility of the proposed framework in (i) a challenging high-dimensional competitive environment for continuous control and (ii) a cooperative environment for communication, on supervised predictive tasks, unsupervised clustering, and policy optimization using deep reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v80-grover18a,\n  title = \t {Learning Policy Representations in Multiagent Systems},\n  author =       {Grover, Aditya and Al-Shedivat, Maruan and Gupta, Jayesh and Burda, Yuri and Edwards, Harrison},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1802--1811},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/grover18a/grover18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/grover18a.html},\n  abstract = \t {Modeling agent behavior is central to understanding the emergence of complex phenomena in multiagent systems. Prior work in agent modeling has largely been task-specific and driven by hand-engineering domain-specific prior knowledge. We propose a general learning framework for modeling agent behavior in any multiagent system using only a handful of interaction data. Our framework casts agent modeling as a representation learning problem. Consequently, we construct a novel objective inspired by imitation learning and agent identification and design an algorithm for unsupervised learning of representations of agent policies. We demonstrate empirically the utility of the proposed framework in (i) a challenging high-dimensional competitive environment for continuous control and (ii) a cooperative environment for communication, on supervised predictive tasks, unsupervised clustering, and policy optimization using deep reinforcement learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/grover18a/grover18a.pdf",
        "supp": "",
        "pdf_size": 1786442,
        "gs_citation": 153,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4083006576944796074&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Stanford University; Carnegie Mellon University; Stanford University; OpenAI; OpenAI",
        "aff_domain": "cs.stanford.edu; ; ; ; ",
        "email": "cs.stanford.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/grover18a.html",
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Stanford University;Carnegie Mellon University;OpenAI",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.cmu.edu;https://openai.com",
        "aff_unique_abbr": "Stanford;CMU;OpenAI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Registered Point Processes from Idiosyncratic Observations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2045",
        "id": "2045",
        "author_site": "Hongteng Xu, Lawrence Carin, Hongyuan Zha",
        "author": "Hongteng Xu; Lawrence Carin; Hongyuan Zha",
        "abstract": "A parametric point process model is developed, with modeling based on the assumption that sequential observations often share latent phenomena, while also possessing idiosyncratic effects. An alternating optimization method is proposed to learn a \u201cregistered\u201d point process that accounts for shared structure, as well as \u201cwarping\u201d functions that characterize idiosyncratic aspects of each observed sequence. Under reasonable constraints, in each iteration we update the sample-specific warping functions by solving a set of constrained nonlinear programming problems in parallel, and update the model by maximum likelihood estimation. The justifiability, complexity and robustness of the proposed method are investigated in detail, and the influence of sequence stitching on the learning results is examined empirically. Experiments on both synthetic and real-world data demonstrate that the method yields explainable point process models, achieving encouraging results compared to state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v80-xu18b,\n  title = \t {Learning Registered Point Processes from Idiosyncratic Observations},\n  author =       {Xu, Hongteng and Carin, Lawrence and Zha, Hongyuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5443--5452},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18b/xu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18b.html},\n  abstract = \t {A parametric point process model is developed, with modeling based on the assumption that sequential observations often share latent phenomena, while also possessing idiosyncratic effects. An alternating optimization method is proposed to learn a \u201cregistered\u201d point process that accounts for shared structure, as well as \u201cwarping\u201d functions that characterize idiosyncratic aspects of each observed sequence. Under reasonable constraints, in each iteration we update the sample-specific warping functions by solving a set of constrained nonlinear programming problems in parallel, and update the model by maximum likelihood estimation. The justifiability, complexity and robustness of the proposed method are investigated in detail, and the influence of sequence stitching on the learning results is examined empirically. Experiments on both synthetic and real-world data demonstrate that the method yields explainable point process models, achieving encouraging results compared to state-of-the-art methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18b/xu18b.pdf",
        "supp": "",
        "pdf_size": 2655547,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15217194924693158997&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of ECE, Duke University, Durham, NC, USA+In\ufb01niaML Inc., Durham, NC, USA; Department of ECE, Duke University, Durham, NC, USA; College of Computing, Georgia Institute of Technology, Atlanta, GA, USA",
        "aff_domain": "duke.edu; ; ",
        "email": "duke.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/xu18b.html",
        "aff_unique_index": "0+1;0;2",
        "aff_unique_norm": "Duke University;In\ufb01niaML Inc.;Georgia Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;;College of Computing",
        "aff_unique_url": "https://www.duke.edu;;https://www.gatech.edu",
        "aff_unique_abbr": "Duke;;Georgia Tech",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Durham;;Atlanta",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning Representations and Generative Models for 3D Point Clouds",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1917",
        "id": "1917",
        "author_site": "Panagiotis Achlioptas, Olga Diamanti, Ioannis Mitliagkas, Leonidas Guibas",
        "author": "Panos Achlioptas; Olga Diamanti; Ioannis Mitliagkas; Leonidas Guibas",
        "abstract": "Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.",
        "bibtex": "@InProceedings{pmlr-v80-achlioptas18a,\n  title = \t {Learning Representations and Generative Models for 3{D} Point Clouds},\n  author =       {Achlioptas, Panos and Diamanti, Olga and Mitliagkas, Ioannis and Guibas, Leonidas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {40--49},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/achlioptas18a/achlioptas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/achlioptas18a.html},\n  abstract = \t {Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/achlioptas18a/achlioptas18a.pdf",
        "supp": "",
        "pdf_size": 4269028,
        "gs_citation": 1771,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9902857073066842718&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Stanford University, USA; Department of Computer Science, Stanford University, USA; MILA, Department of Computer Science and Operations Research, University of Montr \u00b4eal, Canada; Department of Computer Science, Stanford University, USA",
        "aff_domain": "cs.stanford.edu; ; ; ",
        "email": "cs.stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/achlioptas18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;University of Montr\u00e9al",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science and Operations Research",
        "aff_unique_url": "https://www.stanford.edu;https://www.mila.quebec",
        "aff_unique_abbr": "Stanford;UdeM",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stanford;Montr\u00e9al",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "title": "Learning Semantic Representations for Unsupervised Domain Adaptation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1961",
        "id": "1961",
        "author_site": "Shaoan Xie, Zibin Zheng, Liang Chen, Chuan Chen",
        "author": "Shaoan Xie; Zibin Zheng; Liang Chen; Chuan Chen",
        "abstract": "It is important to transfer the knowledge from label-rich source domain to unlabeled target domain due to the expensive cost of manual labeling efforts. Prior domain adaptation methods address this problem through aligning the global distribution statistics between source domain and target domain, but a drawback of prior methods is that they ignore the semantic information contained in samples, e.g., features of backpacks in target domain might be mapped near features of cars in source domain. In this paper, we present moving semantic transfer network, which learn semantic representations for unlabeled target samples by aligning labeled source centroid and pseudo-labeled target centroid. Features in same class but different domains are expected to be mapped nearby, resulting in an improved target classification accuracy. Moving average centroid alignment is cautiously designed to compensate the insufficient categorical information within each mini batch. Experiments testify that our model yields state of the art results on standard datasets.",
        "bibtex": "@InProceedings{pmlr-v80-xie18c,\n  title = \t {Learning Semantic Representations for Unsupervised Domain Adaptation},\n  author =       {Xie, Shaoan and Zheng, Zibin and Chen, Liang and Chen, Chuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5423--5432},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xie18c/xie18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xie18c.html},\n  abstract = \t {It is important to transfer the knowledge from label-rich source domain to unlabeled target domain due to the expensive cost of manual labeling efforts. Prior domain adaptation methods address this problem through aligning the global distribution statistics between source domain and target domain, but a drawback of prior methods is that they ignore the semantic information contained in samples, e.g., features of backpacks in target domain might be mapped near features of cars in source domain. In this paper, we present moving semantic transfer network, which learn semantic representations for unlabeled target samples by aligning labeled source centroid and pseudo-labeled target centroid. Features in same class but different domains are expected to be mapped nearby, resulting in an improved target classification accuracy. Moving average centroid alignment is cautiously designed to compensate the insufficient categorical information within each mini batch. Experiments testify that our model yields state of the art results on standard datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xie18c/xie18c.pdf",
        "supp": "",
        "pdf_size": 2912579,
        "gs_citation": 644,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3795243851386744123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China+National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China+National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China+National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China+National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangzhou, China",
        "aff_domain": "mail.sysu.edu.cn;mail.sysu.edu.cn; ; ",
        "email": "mail.sysu.edu.cn;mail.sysu.edu.cn; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/xie18c.html",
        "aff_unique_index": "0+0;0+0;0+0;0+0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Data and Computer Science",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Learning Steady-States of Iterative Algorithms over Graphs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2424",
        "id": "2424",
        "author_site": "Hanjun Dai, Zornitsa Kozareva, Bo Dai, Alex Smola, Le Song",
        "author": "Hanjun Dai; Zornitsa Kozareva; Bo Dai; Alex Smola; Le Song",
        "abstract": "Many graph analytics problems can be solved via iterative algorithms where the solutions are often characterized by a set of steady-state conditions. Different algorithms respect to different set of fixed point constraints, so instead of using these traditional algorithms, can we learn an algorithm which can obtain the same steady-state solutions automatically from examples, in an effective and scalable way? How to represent the meta learner for such algorithm and how to carry out the learning? In this paper, we propose an embedding representation for iterative algorithms over graphs, and design a learning method which alternates between updating the embeddings and projecting them onto the steady-state constraints. We demonstrate the effectiveness of our framework using a few commonly used graph algorithms, and show that in some cases, the learned algorithm can handle graphs with more than 100,000,000 nodes in a single machine.",
        "bibtex": "@InProceedings{pmlr-v80-dai18a,\n  title = \t {Learning Steady-States of Iterative Algorithms over Graphs},\n  author =       {Dai, Hanjun and Kozareva, Zornitsa and Dai, Bo and Smola, Alex and Song, Le},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1106--1114},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dai18a/dai18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dai18a.html},\n  abstract = \t {Many graph analytics problems can be solved via iterative algorithms where the solutions are often characterized by a set of steady-state conditions. Different algorithms respect to different set of fixed point constraints, so instead of using these traditional algorithms, can we learn an algorithm which can obtain the same steady-state solutions automatically from examples, in an effective and scalable way? How to represent the meta learner for such algorithm and how to carry out the learning? In this paper, we propose an embedding representation for iterative algorithms over graphs, and design a learning method which alternates between updating the embeddings and projecting them onto the steady-state constraints. We demonstrate the effectiveness of our framework using a few commonly used graph algorithms, and show that in some cases, the learned algorithm can handle graphs with more than 100,000,000 nodes in a single machine.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dai18a/dai18a.pdf",
        "supp": "",
        "pdf_size": 3241295,
        "gs_citation": 293,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3975723799997082368&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Georgia Institute of Technology; Amazon; Georgia Institute of Technology + Ant Financial; Amazon; Georgia Institute of Technology + Ant Financial",
        "aff_domain": "gatech.edu; ; ; ; ",
        "email": "gatech.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/dai18a.html",
        "aff_unique_index": "0;1;0+2;1;0+2",
        "aff_unique_norm": "Georgia Institute of Technology;Amazon;Ant Financial",
        "aff_unique_dep": ";Amazon.com, Inc.;",
        "aff_unique_url": "https://www.gatech.edu;https://www.amazon.com;https://www.antgroup.com",
        "aff_unique_abbr": "Georgia Tech;Amazon;Ant Financial",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1;0;0+1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Learning a Mixture of Two Multinomial Logits",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2238",
        "id": "2238",
        "author_site": "Flavio Chierichetti, Ravi Kumar, Andrew Tomkins",
        "author": "Flavio Chierichetti; Ravi Kumar; Andrew Tomkins",
        "abstract": "The classical Multinomial Logit (MNL) is a behavioral model for user choice. In this model, a user is offered a slate of choices (a subset of a finite universe of $n$ items), and selects exactly one item from the slate, each with probability proportional to its (positive) weight. Given a set of observed slates and choices, the likelihood-maximizing item weights are easy to learn at scale, and easy to interpret. However, the model fails to represent common real-world behavior. As a result, researchers in user choice often turn to mixtures of MNLs, which are known to approximate a large class of models of rational user behavior. Unfortunately, the only known algorithms for this problem have been heuristic in nature. In this paper we give the first polynomial-time algorithms for exact learning of uniform mixtures of two MNLs. Interestingly, the parameters of the model can be learned for any $n$ by sampling the behavior of random users only on slates of sizes 2 and 3; in contrast, we show that slates of size 2 are insufficient by themselves.",
        "bibtex": "@InProceedings{pmlr-v80-chierichetti18a,\n  title = \t {Learning a Mixture of Two Multinomial Logits},\n  author =       {Chierichetti, Flavio and Kumar, Ravi and Tomkins, Andrew},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {961--969},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chierichetti18a/chierichetti18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chierichetti18a.html},\n  abstract = \t {The classical Multinomial Logit (MNL) is a behavioral model for user choice. In this model, a user is offered a slate of choices (a subset of a finite universe of $n$ items), and selects exactly one item from the slate, each with probability proportional to its (positive) weight. Given a set of observed slates and choices, the likelihood-maximizing item weights are easy to learn at scale, and easy to interpret. However, the model fails to represent common real-world behavior. As a result, researchers in user choice often turn to mixtures of MNLs, which are known to approximate a large class of models of rational user behavior. Unfortunately, the only known algorithms for this problem have been heuristic in nature. In this paper we give the first polynomial-time algorithms for exact learning of uniform mixtures of two MNLs. Interestingly, the parameters of the model can be learned for any $n$ by sampling the behavior of random users only on slates of sizes 2 and 3; in contrast, we show that slates of size 2 are insufficient by themselves.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chierichetti18a/chierichetti18a.pdf",
        "supp": "",
        "pdf_size": 290257,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16705842961303124731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Sapienza University, Rome, Italy; Google, Mountain View, CA; Google, Mountain View, CA",
        "aff_domain": "di.uniroma1.it; ; ",
        "email": "di.uniroma1.it; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chierichetti18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Sapienza University;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.uniroma1.it;https://www.google.com",
        "aff_unique_abbr": "Sapienza;Google",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Rome;Mountain View",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "title": "Learning and Memorization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2080",
        "id": "2080",
        "author_site": "Sat Chatterjee",
        "author": "Satrajit Chatterjee",
        "abstract": "In the machine learning research community, it is generally believed that there is a tension between memorization and generalization. In this work we examine to what extent this tension exists by exploring if it is possible to generalize by memorizing alone. Although direct memorization with a lookup table obviously does not generalize, we find that introducing depth in the form of a network of support-limited lookup tables leads to generalization that is significantly above chance and closer to those obtained by standard learning algorithms on several tasks derived from MNIST and CIFAR-10. Furthermore, we demonstrate through a series of empirical results that our approach allows for a smooth tradeoff between memorization and generalization and exhibits some of the most salient characteristics of neural networks: depth improves performance; random data can be memorized and yet there is generalization on real data; and memorizing random data is harder in a certain sense than memorizing real data. The extreme simplicity of the algorithm and potential connections with generalization theory point to several interesting directions for future research.",
        "bibtex": "@InProceedings{pmlr-v80-chatterjee18a,\n  title = \t {Learning and Memorization},\n  author =       {Chatterjee, Satrajit},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {755--763},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chatterjee18a/chatterjee18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chatterjee18a.html},\n  abstract = \t {In the machine learning research community, it is generally believed that there is a tension between memorization and generalization. In this work we examine to what extent this tension exists by exploring if it is possible to generalize by memorizing alone. Although direct memorization with a lookup table obviously does not generalize, we find that introducing depth in the form of a network of support-limited lookup tables leads to generalization that is significantly above chance and closer to those obtained by standard learning algorithms on several tasks derived from MNIST and CIFAR-10. Furthermore, we demonstrate through a series of empirical results that our approach allows for a smooth tradeoff between memorization and generalization and exhibits some of the most salient characteristics of neural networks: depth improves performance; random data can be memorized and yet there is generalization on real data; and memorizing random data is harder in a certain sense than memorizing real data. The extreme simplicity of the algorithm and potential connections with generalization theory point to several interesting directions for future research.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chatterjee18a/chatterjee18a.pdf",
        "supp": "",
        "pdf_size": 5019224,
        "gs_citation": 77,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5392443071037588751&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Two Sigma, New York, NY, USA",
        "aff_domain": "twosigma.com",
        "email": "twosigma.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/chatterjee18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Two Sigma",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.twosigma.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning by Playing Solving Sparse Reward Tasks from Scratch",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2179",
        "id": "2179",
        "author_site": "Martin Riedmiller, Roland Hafner, Thomas Lampe, Michael Neunert, Jonas Degrave, Tom Van de Wiele, Vlad Mnih, Nicolas Heess, Jost Springenberg",
        "author": "Martin Riedmiller; Roland Hafner; Thomas Lampe; Michael Neunert; Jonas Degrave; Tom Wiele; Vlad Mnih; Nicolas Heess; Jost Tobias Springenberg",
        "abstract": "We propose Scheduled Auxiliary Control (SAC-X), a new learning paradigm in the context of Reinforcement Learning (RL). SAC-X enables learning of complex behaviors - from scratch - in the presence of multiple sparse reward signals. To this end, the agent is equipped with a set of general auxiliary tasks, that it attempts to learn simultaneously via off-policy RL. The key idea behind our method is that active (learned) scheduling and execution of auxiliary policies allows the agent to efficiently explore its environment - enabling it to excel at sparse reward RL. Our experiments in several challenging robotic manipulation settings demonstrate the power of our approach.",
        "bibtex": "@InProceedings{pmlr-v80-riedmiller18a,\n  title = \t {Learning by Playing Solving Sparse Reward Tasks from Scratch},\n  author =       {Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and van de Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4344--4353},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/riedmiller18a/riedmiller18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/riedmiller18a.html},\n  abstract = \t {We propose Scheduled Auxiliary Control (SAC-X), a new learning paradigm in the context of Reinforcement Learning (RL). SAC-X enables learning of complex behaviors - from scratch - in the presence of multiple sparse reward signals. To this end, the agent is equipped with a set of general auxiliary tasks, that it attempts to learn simultaneously via off-policy RL. The key idea behind our method is that active (learned) scheduling and execution of auxiliary policies allows the agent to efficiently explore its environment - enabling it to excel at sparse reward RL. Our experiments in several challenging robotic manipulation settings demonstrate the power of our approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/riedmiller18a/riedmiller18a.pdf",
        "supp": "",
        "pdf_size": 6761974,
        "gs_citation": 549,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15917464885618538553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB; Google DeepMind, London, GB",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "https://youtu.be/mPKyvocNeM",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/riedmiller18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google DeepMind",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Learning in Integer Latent Variable Models with Nested Automatic Differentiation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2357",
        "id": "2357",
        "author_site": "Daniel Sheldon, Kevin Winner, Debora Sujono",
        "author": "Daniel Sheldon; Kevin Winner; Debora Sujono",
        "abstract": "We develop nested automatic differentiation (AD) algorithms for exact inference and learning in integer latent variable models. Recently, Winner, Sujono, and Sheldon showed how to reduce marginalization in a class of integer latent variable models to evaluating a probability generating function which contains many levels of nested high-order derivatives. We contribute faster and more stable AD algorithms for this challenging problem and a novel algorithm to compute exact gradients for learning. These contributions lead to significantly faster and more accurate learning algorithms, and are the first AD algorithms whose running time is polynomial in the number of levels of nesting.",
        "bibtex": "@InProceedings{pmlr-v80-sheldon18a,\n  title = \t {Learning in Integer Latent Variable Models with Nested Automatic Differentiation},\n  author =       {Sheldon, Daniel and Winner, Kevin and Sujono, Debora},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4615--4623},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sheldon18a/sheldon18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sheldon18a.html},\n  abstract = \t {We develop nested automatic differentiation (AD) algorithms for exact inference and learning in integer latent variable models. Recently, Winner, Sujono, and Sheldon showed how to reduce marginalization in a class of integer latent variable models to evaluating a probability generating function which contains many levels of nested high-order derivatives. We contribute faster and more stable AD algorithms for this challenging problem and a novel algorithm to compute exact gradients for learning. These contributions lead to significantly faster and more accurate learning algorithms, and are the first AD algorithms whose running time is polynomial in the number of levels of nesting.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sheldon18a/sheldon18a.pdf",
        "supp": "",
        "pdf_size": 1934467,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4834090260282787814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "College of Information and Computer Sciences, University of Massachusetts Amherst+Department of Computer Science, Mount Holyoke College; College of Information and Computer Sciences, University of Massachusetts Amherst; College of Information and Computer Sciences, University of Massachusetts Amherst",
        "aff_domain": "cs.umass.edu; ; ",
        "email": "cs.umass.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/sheldon18a.html",
        "aff_unique_index": "0+1;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst;Mount Holyoke College",
        "aff_unique_dep": "College of Information and Computer Sciences;Department of Computer Science",
        "aff_unique_url": "https://www.umass.edu;https://www.mtholyoke.edu",
        "aff_unique_abbr": "UMass Amherst;MHC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Amherst;",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning in Reproducing Kernel Kre\u0131\u0306n Spaces",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2200",
        "id": "2200",
        "author_site": "Dino Oglic, Thomas Gaertner",
        "author": "Dino Oglic; Thomas Gaertner",
        "abstract": "We formulate a novel regularized risk minimization problem for learning in reproducing kernel Kre{\u0131\u0306}n spaces and show that the strong representer theorem applies to it. As a result of the latter, the learning problem can be expressed as the minimization of a quadratic form over a hypersphere of constant radius. We present an algorithm that can find a globally optimal solution to this non-convex optimization problem in time cubic in the number of instances. Moreover, we derive the gradient of the solution with respect to its hyperparameters and, in this way, provide means for efficient hyperparameter tuning. The approach comes with a generalization bound expressed in terms of the Rademacher complexity of the corresponding hypothesis space. The major advantage over standard kernel methods is the ability to learn with various domain specific similarity measures for which positive definiteness does not hold or is difficult to establish. The approach is evaluated empirically using indefinite kernels defined on structured as well as vectorial data. The empirical results demonstrate a superior performance of our approach over the state-of-the-art baselines.",
        "bibtex": "@InProceedings{pmlr-v80-oglic18a,\n  title = \t {Learning in Reproducing Kernel {K}re{\u0131\u0306}n Spaces},\n  author =       {Oglic, Dino and Gaertner, Thomas},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3859--3867},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/oglic18a/oglic18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/oglic18a.html},\n  abstract = \t {We formulate a novel regularized risk minimization problem for learning in reproducing kernel Kre{\u0131\u0306}n spaces and show that the strong representer theorem applies to it. As a result of the latter, the learning problem can be expressed as the minimization of a quadratic form over a hypersphere of constant radius. We present an algorithm that can find a globally optimal solution to this non-convex optimization problem in time cubic in the number of instances. Moreover, we derive the gradient of the solution with respect to its hyperparameters and, in this way, provide means for efficient hyperparameter tuning. The approach comes with a generalization bound expressed in terms of the Rademacher complexity of the corresponding hypothesis space. The major advantage over standard kernel methods is the ability to learn with various domain specific similarity measures for which positive definiteness does not hold or is difficult to establish. The approach is evaluated empirically using indefinite kernels defined on structured as well as vectorial data. The empirical results demonstrate a superior performance of our approach over the state-of-the-art baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/oglic18a/oglic18a.pdf",
        "supp": "",
        "pdf_size": 386048,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "School of Computer Science, University of Nottingham, UK + Institut f \u00a8ur Informatik III, Universit \u00a8at Bonn, Germany; Institut f \u00a8ur Informatik III, Universit \u00a8at Bonn, Germany",
        "aff_domain": "uni-bonn.de; ",
        "email": "uni-bonn.de; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/oglic18a.html",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "University of Nottingham;Universit\u00e4t Bonn",
        "aff_unique_dep": "School of Computer Science;Institut f\u00fcr Informatik III",
        "aff_unique_url": "https://www.nottingham.ac.uk;https://www.uni-bonn.de",
        "aff_unique_abbr": "UoN;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;1",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "title": "Learning the Reward Function for a Misspecified Model",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1913",
        "id": "1913",
        "author": "Erik Talvitie",
        "abstract": "In model-based reinforcement learning it is typical to decouple the problems of learning the dynamics model and learning the reward function. However, when the dynamics model is flawed, it may generate erroneous states that would never occur in the true environment. It is not clear a priori what value the reward function should assign to such states. This paper presents a novel error bound that accounts for the reward model\u2019s behavior in states sampled from the model. This bound is used to extend the existing Hallucinated DAgger-MC algorithm, which offers theoretical performance guarantees in deterministic MDPs that do not assume a perfect model can be learned. Empirically, this approach to reward learning can yield dramatic improvements in control performance when the dynamics model is flawed.",
        "bibtex": "@InProceedings{pmlr-v80-talvitie18a,\n  title = \t {Learning the Reward Function for a Misspecified Model},\n  author =       {Talvitie, Erik},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4838--4847},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/talvitie18a/talvitie18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/talvitie18a.html},\n  abstract = \t {In model-based reinforcement learning it is typical to decouple the problems of learning the dynamics model and learning the reward function. However, when the dynamics model is flawed, it may generate erroneous states that would never occur in the true environment. It is not clear a priori what value the reward function should assign to such states. This paper presents a novel error bound that accounts for the reward model\u2019s behavior in states sampled from the model. This bound is used to extend the existing Hallucinated DAgger-MC algorithm, which offers theoretical performance guarantees in deterministic MDPs that do not assume a perfect model can be learned. Empirically, this approach to reward learning can yield dramatic improvements in control performance when the dynamics model is flawed.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/talvitie18a/talvitie18a.pdf",
        "supp": "",
        "pdf_size": 531648,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16036091820545871049&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Franklin & Marshall College, Lancaster, Pennsylvania, USA",
        "aff_domain": "fandm.edu",
        "email": "fandm.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/talvitie18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Franklin & Marshall College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.fandm.edu",
        "aff_unique_abbr": "F&M",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Lancaster",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning to Act in Decentralized Partially Observable MDPs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2278",
        "id": "2278",
        "author_site": "Jilles Dibangoye, Olivier Buffet",
        "author": "Jilles Dibangoye; Olivier Buffet",
        "abstract": "We address a long-standing open problem of reinforcement learning in decentralized partially observable Markov decision processes. Previous attempts focussed on different forms of generalized policy iteration, which at best led to local optima. In this paper, we restrict attention to plans, which are simpler to store and update than policies. We derive, under certain conditions, the first near-optimal cooperative multi-agent reinforcement learning algorithm. To achieve significant scalability gains, we replace the greedy maximization by mixed-integer linear programming. Experiments show our approach can learn to act near-optimally in many finite domains from the literature.",
        "bibtex": "@InProceedings{pmlr-v80-dibangoye18a,\n  title = \t {Learning to Act in Decentralized Partially Observable {MDP}s},\n  author =       {Dibangoye, Jilles and Buffet, Olivier},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1233--1242},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dibangoye18a/dibangoye18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dibangoye18a.html},\n  abstract = \t {We address a long-standing open problem of reinforcement learning in decentralized partially observable Markov decision processes. Previous attempts focussed on different forms of generalized policy iteration, which at best led to local optima. In this paper, we restrict attention to plans, which are simpler to store and update than policies. We derive, under certain conditions, the first near-optimal cooperative multi-agent reinforcement learning algorithm. To achieve significant scalability gains, we replace the greedy maximization by mixed-integer linear programming. Experiments show our approach can learn to act near-optimally in many finite domains from the literature.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dibangoye18a/dibangoye18a.pdf",
        "supp": "",
        "pdf_size": 373681,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3091036164641771669&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 19,
        "aff": "Univ Lyon, INSA Lyon, INRIA, CITI, F-69621 Villeurbanne, France; INRIA / Universit \u00b4e de Lorraine, Nancy, France",
        "aff_domain": "inria.fr;loria.fr",
        "email": "inria.fr;loria.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/dibangoye18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "INSA Lyon;INRIA",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.insa-lyon.fr;https://www.inria.fr",
        "aff_unique_abbr": "INSA Lyon;INRIA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Nancy",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Learning to Branch",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2244",
        "id": "2244",
        "author_site": "Nina Balcan, Travis Dick, Tuomas Sandholm, Ellen Vitercik",
        "author": "Maria-Florina Balcan; Travis Dick; Tuomas Sandholm; Ellen Vitercik",
        "abstract": "Tree search algorithms, such as branch-and-bound, are the most widely used tools for solving combinatorial problems. These algorithms recursively partition the search space to find an optimal solution. To keep the tree small, it is crucial to carefully decide, when expanding a tree node, which variable to branch on at that node to partition the remaining space. Many partitioning techniques have been proposed, but no theory describes which is optimal. We show how to use machine learning to determine an optimal weighting of any set of partitioning procedures for the instance distribution at hand using samples. Via theory and experiments, we show that learning to branch is both practical and hugely beneficial.",
        "bibtex": "@InProceedings{pmlr-v80-balcan18a,\n  title = \t {Learning to Branch},\n  author =       {Balcan, Maria-Florina and Dick, Travis and Sandholm, Tuomas and Vitercik, Ellen},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {344--353},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balcan18a/balcan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balcan18a.html},\n  abstract = \t {Tree search algorithms, such as branch-and-bound, are the most widely used tools for solving combinatorial problems. These algorithms recursively partition the search space to find an optimal solution. To keep the tree small, it is crucial to carefully decide, when expanding a tree node, which variable to branch on at that node to partition the remaining space. Many partitioning techniques have been proposed, but no theory describes which is optimal. We show how to use machine learning to determine an optimal weighting of any set of partitioning procedures for the instance distribution at hand using samples. Via theory and experiments, we show that learning to branch is both practical and hugely beneficial.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balcan18a/balcan18a.pdf",
        "supp": "",
        "pdf_size": 547707,
        "gs_citation": 261,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9281231443210645853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Computer Science Department, Carnegie Mellon University; Computer Science Department, Carnegie Mellon University; Computer Science Department, Carnegie Mellon University; Computer Science Department, Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu; ; ;cs.cmu.edu",
        "email": "cs.cmu.edu; ; ;cs.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/balcan18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2177",
        "id": "2177",
        "author_site": "Eugenio Bargiacchi, Timothy Verstraeten, Diederik Roijers, Ann Now\u00e9, Hado van Hasselt",
        "author": "Eugenio Bargiacchi; Timothy Verstraeten; Diederik Roijers; Ann Now\u00e9; Hado Hasselt",
        "abstract": "Learning to coordinate between multiple agents is an important problem in many reinforcement learning problems. Key to learning to coordinate is exploiting loose couplings, i.e., conditional independences between agents. In this paper we study learning in repeated fully cooperative games, multi-agent multi-armed bandits (MAMABs), in which the expected rewards can be expressed as a coordination graph. We propose multi-agent upper confidence exploration (MAUCE), a new algorithm for MAMABs that exploits loose couplings, which enables us to prove a regret bound that is logarithmic in the number of arm pulls and only linear in the number of agents. We empirically compare MAUCE to sparse cooperative Q-learning, and a state-of-the-art combinatorial bandit approach, and show that it performs much better on a variety of settings, including learning control policies for wind farms.",
        "bibtex": "@InProceedings{pmlr-v80-bargiacchi18a,\n  title = \t {Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Problems},\n  author =       {Bargiacchi, Eugenio and Verstraeten, Timothy and Roijers, Diederik and Now{\\'e}, Ann and van Hasselt, Hado},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {482--490},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bargiacchi18a/bargiacchi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bargiacchi18a.html},\n  abstract = \t {Learning to coordinate between multiple agents is an important problem in many reinforcement learning problems. Key to learning to coordinate is exploiting loose couplings, i.e., conditional independences between agents. In this paper we study learning in repeated fully cooperative games, multi-agent multi-armed bandits (MAMABs), in which the expected rewards can be expressed as a coordination graph. We propose multi-agent upper confidence exploration (MAUCE), a new algorithm for MAMABs that exploits loose couplings, which enables us to prove a regret bound that is logarithmic in the number of arm pulls and only linear in the number of agents. We empirically compare MAUCE to sparse cooperative Q-learning, and a state-of-the-art combinatorial bandit approach, and show that it performs much better on a variety of settings, including learning control policies for wind farms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bargiacchi18a/bargiacchi18a.pdf",
        "supp": "",
        "pdf_size": 628344,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17323072677194095818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Dept. of Computer Science, Vrije Universiteit Brussel, Brussels, Belgium+Fac. of Science, Vrije Universiteit Amsterdam, The Netherlands; Dept. of Computer Science, Vrije Universiteit Brussel, Brussels, Belgium+Fac. of Science, Vrije Universiteit Amsterdam, The Netherlands; Dept. of Computer Science, Vrije Universiteit Brussel, Brussels, Belgium+Fac. of Science, Vrije Universiteit Amsterdam, The Netherlands; Dept. of Computer Science, Vrije Universiteit Brussel, Brussels, Belgium; DeepMind, London, UK",
        "aff_domain": "gmail.com; ; ; ; ",
        "email": "gmail.com; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/bargiacchi18a.html",
        "aff_unique_index": "0+1;0+1;0+1;0;2",
        "aff_unique_norm": "Vrije Universiteit Brussel;Vrije Universiteit Amsterdam;DeepMind",
        "aff_unique_dep": "Dept. of Computer Science;Faculty of Science;",
        "aff_unique_url": "https://www.vub.be;https://www.vu.nl;https://deepmind.com",
        "aff_unique_abbr": "VUB;VU Amsterdam;DeepMind",
        "aff_campus_unique_index": "0+1;0+1;0+1;0;2",
        "aff_campus_unique": "Brussels;Amsterdam;London",
        "aff_country_unique_index": "0+1;0+1;0+1;0;2",
        "aff_country_unique": "Belgium;Netherlands;United Kingdom"
    },
    {
        "title": "Learning to Explain: An Information-Theoretic Perspective on Model Interpretation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1957",
        "id": "1957",
        "author_site": "Jianbo Chen, Le Song, Martin Wainwright, Michael Jordan",
        "author": "Jianbo Chen; Le Song; Martin Wainwright; Michael Jordan",
        "abstract": "We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show the effectiveness of our method on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.",
        "bibtex": "@InProceedings{pmlr-v80-chen18j,\n  title = \t {Learning to Explain: An Information-Theoretic Perspective on Model Interpretation},\n  author =       {Chen, Jianbo and Song, Le and Wainwright, Martin and Jordan, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {883--892},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18j/chen18j.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18j.html},\n  abstract = \t {We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show the effectiveness of our method on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18j/chen18j.pdf",
        "supp": "",
        "pdf_size": 2213914,
        "gs_citation": 808,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8716068966978529202&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, Berkeley + Ant Financial; Georgia Institute of Technology + Ant Financial; University of California, Berkeley + The Voleon Group; University of California, Berkeley",
        "aff_domain": "berkeley.edu; ; ; ",
        "email": "berkeley.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/chen18j.html",
        "aff_unique_index": "0+1;2+1;0+3;0",
        "aff_unique_norm": "University of California, Berkeley;Ant Financial;Georgia Institute of Technology;Voleon Group",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.antgroup.com;https://www.gatech.edu;",
        "aff_unique_abbr": "UC Berkeley;Ant Financial;Georgia Tech;",
        "aff_campus_unique_index": "0;;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0+1;0+1;0+0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Learning to Explore via Meta-Policy Gradient",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1939",
        "id": "1939",
        "author_site": "Tianbing Xu, Qiang Liu, Liang Zhao, Jian Peng",
        "author": "Tianbing Xu; Qiang Liu; Liang Zhao; Jian Peng",
        "abstract": "The performance of off-policy learning, including deep Q-learning and deep deterministic policy gradient (DDPG), critically depends on the choice of the exploration policy. Existing exploration methods are mostly based on adding noise to the on-going actor policy and can only explore",
        "bibtex": "@InProceedings{pmlr-v80-xu18d,\n  title = \t {Learning to Explore via Meta-Policy Gradient},\n  author =       {Xu, Tianbing and Liu, Qiang and Zhao, Liang and Peng, Jian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5463--5472},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18d/xu18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18d.html},\n  abstract = \t {The performance of off-policy learning, including deep Q-learning and deep deterministic policy gradient (DDPG), critically depends on the choice of the exploration policy. Existing exploration methods are mostly based on adding noise to the on-going actor policy and can only explore",
        "pdf": "http://proceedings.mlr.press/v80/xu18d/xu18d.pdf",
        "supp": "",
        "pdf_size": 787508,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9093519485857110369&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Baidu Research, Sunnyvale, CA; University of Texas at Austin, TX; Baidu Research, Sunnyvale, CA; University of Illinois at Urbana Champaign, IL",
        "aff_domain": "baidu.com; ; ; ",
        "email": "baidu.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/xu18d.html",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Baidu;University of Texas at Austin;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Baidu Research;;",
        "aff_unique_url": "https://research.baidu.com;https://www.utexas.edu;https://illinois.edu",
        "aff_unique_abbr": "Baidu;UT Austin;UIUC",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Sunnyvale;Austin;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning to Optimize Combinatorial Functions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1881",
        "id": "1881",
        "author_site": "Nir Rosenfeld, Eric Balkanski, Amir Globerson, Yaron Singer",
        "author": "Nir Rosenfeld; Eric Balkanski; Amir Globerson; Yaron Singer",
        "abstract": "Submodular functions have become a ubiquitous tool in machine learning. They are learnable from data, and can be optimized efficiently and with guarantees. Nonetheless, recent negative results show that optimizing learned surrogates of submodular functions can result in arbitrarily bad approximations of the true optimum. Our goal in this paper is to highlight the source of this hardness, and propose an alternative criterion for optimizing general combinatorial functions from sampled data. We prove a tight equivalence showing that a class of functions is optimizable if and only if it can be learned. We provide efficient and scalable optimization algorithms for several function classes of interest, and demonstrate their utility on the task of optimally choosing trending social media items.",
        "bibtex": "@InProceedings{pmlr-v80-rosenfeld18a,\n  title = \t {Learning to Optimize Combinatorial Functions},\n  author =       {Rosenfeld, Nir and Balkanski, Eric and Globerson, Amir and Singer, Yaron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4374--4383},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rosenfeld18a/rosenfeld18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rosenfeld18a.html},\n  abstract = \t {Submodular functions have become a ubiquitous tool in machine learning. They are learnable from data, and can be optimized efficiently and with guarantees. Nonetheless, recent negative results show that optimizing learned surrogates of submodular functions can result in arbitrarily bad approximations of the true optimum. Our goal in this paper is to highlight the source of this hardness, and propose an alternative criterion for optimizing general combinatorial functions from sampled data. We prove a tight equivalence showing that a class of functions is optimizable if and only if it can be learned. We provide efficient and scalable optimization algorithms for several function classes of interest, and demonstrate their utility on the task of optimally choosing trending social media items.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rosenfeld18a/rosenfeld18a.pdf",
        "supp": "",
        "pdf_size": 469734,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1721420402213414751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Harvard University; Harvard University; Tel Aviv University; Harvard University",
        "aff_domain": "g.harvard.edu; ; ; ",
        "email": "g.harvard.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/rosenfeld18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Harvard University;Tel Aviv University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.harvard.edu;https://www.tau.ac.il",
        "aff_unique_abbr": "Harvard;TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Learning to Reweight Examples for Robust Deep Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1991",
        "id": "1991",
        "author_site": "Mengye Ren, Wenyuan Zeng, Bin Yang, Raquel Urtasun",
        "author": "Mengye Ren; Wenyuan Zeng; Bin Yang; Raquel Urtasun",
        "abstract": "Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns. However, they can also easily overfit to training set biases and label noises. In addition to various regularizers, example reweighting algorithms are popular solutions to these problems, but they require careful tuning of additional hyperparameters, such as example mining schedules and regularization hyperparameters. In contrast to past reweighting methods, which typically consist of functions of the cost value of each example, in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions. To determine the example weights, our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set. Our proposed method can be easily implemented on any type of deep network, does not require any additional hyperparameter tuning, and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.",
        "bibtex": "@InProceedings{pmlr-v80-ren18a,\n  title = \t {Learning to Reweight Examples for Robust Deep Learning},\n  author =       {Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4334--4343},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ren18a/ren18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ren18a.html},\n  abstract = \t {Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns. However, they can also easily overfit to training set biases and label noises. In addition to various regularizers, example reweighting algorithms are popular solutions to these problems, but they require careful tuning of additional hyperparameters, such as example mining schedules and regularization hyperparameters. In contrast to past reweighting methods, which typically consist of functions of the cost value of each example, in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions. To determine the example weights, our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set. Our proposed method can be easily implemented on any type of deep network, does not require any additional hyperparameter tuning, and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ren18a/ren18a.pdf",
        "supp": "",
        "pdf_size": 2922359,
        "gs_citation": 1831,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17871432661582272860&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Uber Advanced Technologies Group, Toronto ON, CANADA + Department of Computer Science, University of Toronto, Toronto ON, CANADA; Uber Advanced Technologies Group, Toronto ON, CANADA + Department of Computer Science, University of Toronto, Toronto ON, CANADA; Uber Advanced Technologies Group, Toronto ON, CANADA + Department of Computer Science, University of Toronto, Toronto ON, CANADA; Uber Advanced Technologies Group, Toronto ON, CANADA + Department of Computer Science, University of Toronto, Toronto ON, CANADA",
        "aff_domain": "uber.com; ; ; ",
        "email": "uber.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ren18a.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "Uber Advanced Technologies Group;University of Toronto",
        "aff_unique_dep": "Advanced Technologies Group;Department of Computer Science",
        "aff_unique_url": "https://www.uber.com;https://www.utoronto.ca",
        "aff_unique_abbr": "Uber ATG;U of T",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Learning to Speed Up Structured Output Prediction",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2489",
        "id": "2489",
        "author_site": "Xingyuan Pan, Vivek Srikumar",
        "author": "Xingyuan Pan; Vivek Srikumar",
        "abstract": "Predicting structured outputs can be computationally onerous due to the combinatorially large output spaces. In this paper, we focus on reducing the prediction time of a trained black-box structured classifier without losing accuracy. To do so, we train a speedup classifier that learns to mimic a black-box classifier under the learning-to-search approach. As the structured classifier predicts more examples, the speedup classifier will operate as a learned heuristic to guide search to favorable regions of the output space. We present a mistake bound for the speedup classifier and identify inference situations where it can independently make correct judgments without input features. We evaluate our method on the task of entity and relation extraction and show that the speedup classifier outperforms even greedy search in terms of speed without loss of accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-pan18b,\n  title = \t {Learning to Speed Up Structured Output Prediction},\n  author =       {Pan, Xingyuan and Srikumar, Vivek},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3996--4005},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pan18b/pan18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pan18b.html},\n  abstract = \t {Predicting structured outputs can be computationally onerous due to the combinatorially large output spaces. In this paper, we focus on reducing the prediction time of a trained black-box structured classifier without losing accuracy. To do so, we train a speedup classifier that learns to mimic a black-box classifier under the learning-to-search approach. As the structured classifier predicts more examples, the speedup classifier will operate as a learned heuristic to guide search to favorable regions of the output space. We present a mistake bound for the speedup classifier and identify inference situations where it can independently make correct judgments without input features. We evaluate our method on the task of entity and relation extraction and show that the speedup classifier outperforms even greedy search in terms of speed without loss of accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pan18b/pan18b.pdf",
        "supp": "",
        "pdf_size": 310253,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12484498825166123815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "School of Computing, University of Utah, Salt Lake City, Utah, USA; School of Computing, University of Utah, Salt Lake City, Utah, USA",
        "aff_domain": "cs.utah.edu;cs.utah.edu",
        "email": "cs.utah.edu;cs.utah.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/pan18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Salt Lake City",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Learning to search with MCTSnets",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2233",
        "id": "2233",
        "author_site": "Arthur Guez, Theophane Weber, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals, Daan Wierstra, Remi Munos, David Silver",
        "author": "Arthur Guez; Theophane Weber; Ioannis Antonoglou; Karen Simonyan; Oriol Vinyals; Daan Wierstra; Remi Munos; David Silver",
        "abstract": "Planning problems are among the most important and well-studied problems in artificial intelligence. They are most typically solved by tree search algorithms that simulate ahead into the future, evaluate future states, and back-up those evaluations to the root of a search tree. Among these algorithms, Monte-Carlo tree search (MCTS) is one of the most general, powerful and widely used. A typical implementation of MCTS uses cleverly designed rules, optimised to the particular characteristics of the domain. These rules control where the simulation traverses, what to evaluate in the states that are reached, and how to back-up those evaluations. In this paper we instead learn where, what and how to search. Our architecture, which we call an MCTSnet, incorporates simulation-based search inside a neural network, by expanding, evaluating and backing-up a vector embedding. The parameters of the network are trained end-to-end using gradient-based optimisation. When applied to small searches in the well-known planning problem Sokoban, the learned search algorithm significantly outperformed MCTS baselines.",
        "bibtex": "@InProceedings{pmlr-v80-guez18a,\n  title = \t {Learning to search with {MCTS}nets},\n  author =       {Guez, Arthur and Weber, Theophane and Antonoglou, Ioannis and Simonyan, Karen and Vinyals, Oriol and Wierstra, Daan and Munos, Remi and Silver, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1822--1831},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/guez18a/guez18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/guez18a.html},\n  abstract = \t {Planning problems are among the most important and well-studied problems in artificial intelligence. They are most typically solved by tree search algorithms that simulate ahead into the future, evaluate future states, and back-up those evaluations to the root of a search tree. Among these algorithms, Monte-Carlo tree search (MCTS) is one of the most general, powerful and widely used. A typical implementation of MCTS uses cleverly designed rules, optimised to the particular characteristics of the domain. These rules control where the simulation traverses, what to evaluate in the states that are reached, and how to back-up those evaluations. In this paper we instead learn where, what and how to search. Our architecture, which we call an MCTSnet, incorporates simulation-based search inside a neural network, by expanding, evaluating and backing-up a vector embedding. The parameters of the network are trained end-to-end using gradient-based optimisation. When applied to small searches in the well-known planning problem Sokoban, the learned search algorithm significantly outperformed MCTS baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/guez18a/guez18a.pdf",
        "supp": "",
        "pdf_size": 2328922,
        "gs_citation": 107,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2965404279553213316&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "google.com;google.com; ; ; ; ; ; ",
        "email": "google.com;google.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/guez18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Learning unknown ODE models with Gaussian processes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2277",
        "id": "2277",
        "author_site": "Markus Heinonen, Cagatay Yildiz, Henrik Mannerstr\u00f6m, Jukka Intosalmi, Harri L\u00e4hdesm\u00e4ki",
        "author": "Markus Heinonen; Cagatay Yildiz; Henrik Mannerstr\u00f6m; Jukka Intosalmi; Harri L\u00e4hdesm\u00e4ki",
        "abstract": "In conventional ODE modelling coefficients of an equation driving the system state forward in time are estimated. However, for many complex systems it is practically impossible to determine the equations or interactions governing the underlying dynamics. In these settings, parametric ODE model cannot be formulated. Here, we overcome this issue by introducing a novel paradigm of nonparametric ODE modelling that can learn the underlying dynamics of arbitrary continuous-time systems without prior knowledge. We propose to learn non-linear, unknown differential functions from state observations using Gaussian process vector fields within the exact ODE formalism. We demonstrate the model\u2019s capabilities to infer dynamics from sparse data and to simulate the system forward into future.",
        "bibtex": "@InProceedings{pmlr-v80-heinonen18a,\n  title = \t {Learning unknown {ODE} models with {G}aussian processes},\n  author =       {Heinonen, Markus and Yildiz, Cagatay and Mannerstr{\\\"o}m, Henrik and Intosalmi, Jukka and L{\\\"a}hdesm{\\\"a}ki, Harri},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1959--1968},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/heinonen18a/heinonen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/heinonen18a.html},\n  abstract = \t {In conventional ODE modelling coefficients of an equation driving the system state forward in time are estimated. However, for many complex systems it is practically impossible to determine the equations or interactions governing the underlying dynamics. In these settings, parametric ODE model cannot be formulated. Here, we overcome this issue by introducing a novel paradigm of nonparametric ODE modelling that can learn the underlying dynamics of arbitrary continuous-time systems without prior knowledge. We propose to learn non-linear, unknown differential functions from state observations using Gaussian process vector fields within the exact ODE formalism. We demonstrate the model\u2019s capabilities to infer dynamics from sparse data and to simulate the system forward into future.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/heinonen18a/heinonen18a.pdf",
        "supp": "",
        "pdf_size": 2598562,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5804235817829238713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Aalto University, Finland+Helsinki Institute of Information Technology HIIT, Finland; Aalto University, Finland; Aalto University, Finland; Aalto University, Finland; Aalto University, Finland",
        "aff_domain": "aalto.fi; ; ; ; ",
        "email": "aalto.fi; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/heinonen18a.html",
        "aff_unique_index": "0+1;0;0;0;0",
        "aff_unique_norm": "Aalto University;Helsinki Institute of Information Technology",
        "aff_unique_dep": ";HIIT",
        "aff_unique_url": "https://www.aalto.fi;",
        "aff_unique_abbr": "Aalto;HIIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "title": "Learning with Abandonment",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1965",
        "id": "1965",
        "author_site": "Sven Schmit, Ramesh Johari",
        "author": "Sven Schmit; Ramesh Johari",
        "abstract": "Consider a platform that wants to learn a personalized policy for each user, but the platform faces the risk of a user abandoning the platform if they are dissatisfied with the actions of the platform. For example, a platform is interested in personalizing the number of newsletters it sends, but faces the risk that the user unsubscribes forever. We propose a general thresholded learning model for scenarios like this, and discuss the structure of optimal policies. We describe salient features of optimal personalization algorithms and how feedback the platform receives impacts the results. Furthermore, we investigate how the platform can efficiently learn the heterogeneity across users by interacting with a population and provide performance guarantees.",
        "bibtex": "@InProceedings{pmlr-v80-schmit18a,\n  title = \t {Learning with Abandonment},\n  author =       {Schmit, Sven and Johari, Ramesh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4509--4517},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/schmit18a/schmit18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/schmit18a.html},\n  abstract = \t {Consider a platform that wants to learn a personalized policy for each user, but the platform faces the risk of a user abandoning the platform if they are dissatisfied with the actions of the platform. For example, a platform is interested in personalizing the number of newsletters it sends, but faces the risk that the user unsubscribes forever. We propose a general thresholded learning model for scenarios like this, and discuss the structure of optimal policies. We describe salient features of optimal personalization algorithms and how feedback the platform receives impacts the results. Furthermore, we investigate how the platform can efficiently learn the heterogeneity across users by interacting with a population and provide performance guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/schmit18a/schmit18a.pdf",
        "supp": "",
        "pdf_size": 1999961,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5599696763306308098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA, USA; Management Science & Engineering, Stanford University, Stanford, CA, USA",
        "aff_domain": "stanford.edu; ",
        "email": "stanford.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/schmit18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Institute for Computational and Mathematical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Least-Squares Temporal Difference Learning for the Linear Quadratic Regulator",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2004",
        "id": "2004",
        "author_site": "Stephen Tu, Benjamin Recht",
        "author": "Stephen Tu; Benjamin Recht",
        "abstract": "Reinforcement learning (RL) has been successfully used to solve many continuous control tasks. Despite its impressive results however, fundamental questions regarding the sample complexity of RL on continuous problems remain open. We study the performance of RL in this setting by considering the behavior of the Least-Squares Temporal Difference (LSTD) estimator on the classic Linear Quadratic Regulator (LQR) problem from optimal control. We give the first finite-time analysis of the number of samples needed to estimate the value function for a fixed static state-feedback policy to within epsilon-relative error. In the process of deriving our result, we give a general characterization for when the minimum eigenvalue of the empirical covariance matrix formed along the sample path of a fast-mixing stochastic process concentrates above zero, extending a result by Koltchinskii and Mendelson in the independent covariates setting. Finally, we provide experimental evidence indicating that our analysis correctly captures the qualitative behavior of LSTD on several LQR instances.",
        "bibtex": "@InProceedings{pmlr-v80-tu18a,\n  title = \t {Least-Squares Temporal Difference Learning for the Linear Quadratic Regulator},\n  author =       {Tu, Stephen and Recht, Benjamin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5005--5014},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tu18a/tu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tu18a.html},\n  abstract = \t {Reinforcement learning (RL) has been successfully used to solve many continuous control tasks. Despite its impressive results however, fundamental questions regarding the sample complexity of RL on continuous problems remain open. We study the performance of RL in this setting by considering the behavior of the Least-Squares Temporal Difference (LSTD) estimator on the classic Linear Quadratic Regulator (LQR) problem from optimal control. We give the first finite-time analysis of the number of samples needed to estimate the value function for a fixed static state-feedback policy to within epsilon-relative error. In the process of deriving our result, we give a general characterization for when the minimum eigenvalue of the empirical covariance matrix formed along the sample path of a fast-mixing stochastic process concentrates above zero, extending a result by Koltchinskii and Mendelson in the independent covariates setting. Finally, we provide experimental evidence indicating that our analysis correctly captures the qualitative behavior of LSTD on several LQR instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tu18a/tu18a.pdf",
        "supp": "",
        "pdf_size": 2940687,
        "gs_citation": 154,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18122494581713760490&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "EECS Department, University of California, Berkeley; EECS Department, University of California, Berkeley",
        "aff_domain": "berkeley.edu; ",
        "email": "berkeley.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/tu18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "EECS Department",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Let\u2019s be Honest: An Optimal No-Regret Framework for Zero-Sum Games",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1975",
        "id": "1975",
        "author_site": "Ehsan Asadi Kangarshahi, Ya-Ping Hsieh, Mehmet Fatih Sahin, Volkan Cevher",
        "author": "Ehsan Asadi Kangarshahi; Ya-Ping Hsieh; Mehmet Fatih Sahin; Volkan Cevher",
        "abstract": "We revisit the problem of solving two-player zero-sum games in the decentralized setting. We propose a simple algorithmic framework that simultaneously achieves the best rates for honest regret as well as adversarial regret, and in addition resolves the open problem of removing the logarithmic terms in convergence to the value of the game. We achieve this goal in three steps. First, we provide a novel analysis of the optimistic mirror descent (OMD), showing that it can be modified to guarantee fast convergence for both honest regret and value of the game, when the players are playing collaboratively. Second, we propose a new algorithm, dubbed as robust optimistic mirror descent (ROMD), which attains optimal adversarial regret without knowing the time horizon beforehand. Finally, we propose a simple signaling scheme, which enables us to bridge OMD and ROMD to achieve the best of both worlds. Numerical examples are presented to support our theoretical claims and show that our non-adaptive ROMD algorithm can be competitive to OMD with adaptive step-size selection.",
        "bibtex": "@InProceedings{pmlr-v80-kangarshahi18a,\n  title = \t {Let\u2019s be Honest: An Optimal No-Regret Framework for Zero-Sum Games},\n  author =       {Kangarshahi, Ehsan Asadi and Hsieh, Ya-Ping and Sahin, Mehmet Fatih and Cevher, Volkan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2488--2496},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kangarshahi18a/kangarshahi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kangarshahi18a.html},\n  abstract = \t {We revisit the problem of solving two-player zero-sum games in the decentralized setting. We propose a simple algorithmic framework that simultaneously achieves the best rates for honest regret as well as adversarial regret, and in addition resolves the open problem of removing the logarithmic terms in convergence to the value of the game. We achieve this goal in three steps. First, we provide a novel analysis of the optimistic mirror descent (OMD), showing that it can be modified to guarantee fast convergence for both honest regret and value of the game, when the players are playing collaboratively. Second, we propose a new algorithm, dubbed as robust optimistic mirror descent (ROMD), which attains optimal adversarial regret without knowing the time horizon beforehand. Finally, we propose a simple signaling scheme, which enables us to bridge OMD and ROMD to achieve the best of both worlds. Numerical examples are presented to support our theoretical claims and show that our non-adaptive ROMD algorithm can be competitive to OMD with adaptive step-size selection.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kangarshahi18a/kangarshahi18a.pdf",
        "supp": "",
        "pdf_size": 367133,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12746874613789648266&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "LIONS, EPFL, Switzerland; LIONS, EPFL, Switzerland; LIONS, EPFL, Switzerland; LIONS, EPFL, Switzerland",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch;epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kangarshahi18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "LIONS",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Level-Set Methods for Finite-Sum Constrained Convex Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2122",
        "id": "2122",
        "author_site": "Qihang Lin, Runchao Ma, Tianbao Yang",
        "author": "Qihang Lin; Runchao Ma; Tianbao Yang",
        "abstract": "We consider the constrained optimization where the objective function and the constraints are defined as summation of finitely many loss functions. This model has applications in machine learning such as Neyman-Pearson classification. We consider two level-set methods to solve this class of problems, an existing inexact Newton method and a new feasible level-set method. To update the level parameter towards the optimality, both methods require an oracle that generates upper and lower bounds as well as an affine-minorant of the level function. To construct the desired oracle, we reformulate the level function as the value of a saddle-point problem using the conjugate and perspective of the loss functions. Then a stochastic variance-reduced gradient method with a special Bregman divergence is proposed as the oracle for solving that saddle-point problem. The special divergence ensures the proximal mapping in each iteration can be solved in a closed form. The total complexity of both level-set methods using the proposed oracle are analyzed.",
        "bibtex": "@InProceedings{pmlr-v80-lin18c,\n  title = \t {Level-Set Methods for Finite-Sum Constrained Convex Optimization},\n  author =       {Lin, Qihang and Ma, Runchao and Yang, Tianbao},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3112--3121},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lin18c/lin18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lin18c.html},\n  abstract = \t {We consider the constrained optimization where the objective function and the constraints are defined as summation of finitely many loss functions. This model has applications in machine learning such as Neyman-Pearson classification. We consider two level-set methods to solve this class of problems, an existing inexact Newton method and a new feasible level-set method. To update the level parameter towards the optimality, both methods require an oracle that generates upper and lower bounds as well as an affine-minorant of the level function. To construct the desired oracle, we reformulate the level function as the value of a saddle-point problem using the conjugate and perspective of the loss functions. Then a stochastic variance-reduced gradient method with a special Bregman divergence is proposed as the oracle for solving that saddle-point problem. The special divergence ensures the proximal mapping in each iteration can be solved in a closed form. The total complexity of both level-set methods using the proposed oracle are analyzed.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lin18c/lin18c.pdf",
        "supp": "",
        "pdf_size": 463994,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1089363595227430403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Management Sciences Department, University of Iowa, Iowa City, IA, USA; Management Sciences Department, University of Iowa, Iowa City, IA, USA; Computer Science Department, University of Iowa, Iowa City, IA, USA",
        "aff_domain": "uiowa.edu; ; ",
        "email": "uiowa.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lin18c.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Iowa",
        "aff_unique_dep": "Management Sciences Department",
        "aff_unique_url": "https://www.uiowa.edu",
        "aff_unique_abbr": "UIowa",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Iowa City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski $p$-Norms",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2163",
        "id": "2163",
        "author_site": "Charlie Dickens, Graham Cormode, David Woodruff",
        "author": "Charlie Dickens; Graham Cormode; David Woodruff",
        "abstract": "Work on approximate linear algebra has led to efficient distributed and streaming algorithms for problems such as approximate matrix multiplication, low rank approximation, and regression, primarily for the Euclidean norm $\\ell_2$. We study other $\\ell_p$ norms, which are more robust for $p < 2$, and can be used to find outliers for $p > 2$. Unlike previous algorithms for such norms, we give algorithms that are (1) deterministic, (2) work simultaneously for every $p \\geq 1$, including $p = \\infty$, and (3) can be implemented in both distributed and streaming environments. We study $\\ell_p$-regression, entrywise $\\ell_p$-low rank approximation, and versions of approximate matrix multiplication.",
        "bibtex": "@InProceedings{pmlr-v80-dickens18a,\n  title = \t {Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in {M}inkowski $p$-Norms},\n  author =       {Dickens, Charlie and Cormode, Graham and Woodruff, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1243--1251},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dickens18a/dickens18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dickens18a.html},\n  abstract = \t {Work on approximate linear algebra has led to efficient distributed and streaming algorithms for problems such as approximate matrix multiplication, low rank approximation, and regression, primarily for the Euclidean norm $\\ell_2$. We study other $\\ell_p$ norms, which are more robust for $p < 2$, and can be used to find outliers for $p > 2$. Unlike previous algorithms for such norms, we give algorithms that are (1) deterministic, (2) work simultaneously for every $p \\geq 1$, including $p = \\infty$, and (3) can be implemented in both distributed and streaming environments. We study $\\ell_p$-regression, entrywise $\\ell_p$-low rank approximation, and versions of approximate matrix multiplication.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dickens18a/dickens18a.pdf",
        "supp": "",
        "pdf_size": 3853453,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11955647056335201850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Department of Computer Science, University of Warwick, Coventry, UK+School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Department of Computer Science, University of Warwick, Coventry, UK+School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA",
        "aff_domain": "warwick.ac.uk;warwick.ac.uk; ",
        "email": "warwick.ac.uk;warwick.ac.uk; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/dickens18a.html",
        "aff_unique_index": "0+1;0+1;1",
        "aff_unique_norm": "University of Warwick;Carnegie Mellon University",
        "aff_unique_dep": "Department of Computer Science;School of Computer Science",
        "aff_unique_url": "https://warwick.ac.uk;https://www.cmu.edu",
        "aff_unique_abbr": "Warwick;CMU",
        "aff_campus_unique_index": "0+1;0+1;1",
        "aff_campus_unique": "Coventry;Pittsburgh",
        "aff_country_unique_index": "0+1;0+1;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2215",
        "id": "2215",
        "author_site": "Shuai Zheng, James Kwok",
        "author": "Shuai Zheng; James Tin-Yau Kwok",
        "abstract": "Variance reduction has been commonly used in stochastic optimization. It relies crucially on the assumption that the data set is finite. However, when the data are imputed with random noise as in data augmentation, the perturbed data set becomes essentially infinite. Recently, the stochastic MISO (S-MISO) algorithm is introduced to address this expected risk minimization problem. Though it converges faster than SGD, a significant amount of memory is required. In this paper, we propose two SGD-like algorithms for expected risk minimization with random perturbation, namely, stochastic sample average gradient (SSAG) and stochastic SAGA (S-SAGA). The memory cost of SSAG does not depend on the sample size, while that of S-SAGA is the same as those of variance reduction methods on unperturbed data. Theoretical analysis and experimental results on logistic regression and AUC maximization show that SSAG has faster convergence rate than SGD with comparable space requirement while S-SAGA outperforms S-MISO in terms of both iteration complexity and storage.",
        "bibtex": "@InProceedings{pmlr-v80-zheng18a,\n  title = \t {Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data},\n  author =       {Zheng, Shuai and Kwok, James Tin-Yau},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5932--5940},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zheng18a/zheng18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zheng18a.html},\n  abstract = \t {Variance reduction has been commonly used in stochastic optimization. It relies crucially on the assumption that the data set is finite. However, when the data are imputed with random noise as in data augmentation, the perturbed data set becomes essentially infinite. Recently, the stochastic MISO (S-MISO) algorithm is introduced to address this expected risk minimization problem. Though it converges faster than SGD, a significant amount of memory is required. In this paper, we propose two SGD-like algorithms for expected risk minimization with random perturbation, namely, stochastic sample average gradient (SSAG) and stochastic SAGA (S-SAGA). The memory cost of SSAG does not depend on the sample size, while that of S-SAGA is the same as those of variance reduction methods on unperturbed data. Theoretical analysis and experimental results on logistic regression and AUC maximization show that SSAG has faster convergence rate than SGD with comparable space requirement while S-SAGA outperforms S-MISO in terms of both iteration complexity and storage.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zheng18a/zheng18a.pdf",
        "supp": "",
        "pdf_size": 337799,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8097995663258777323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong",
        "aff_domain": "cse.ust.hk; ",
        "email": "cse.ust.hk; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/zheng18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2226",
        "id": "2226",
        "author_site": "Ahmed M. Alaa, Mihaela van der Schaar",
        "author": "Ahmed Alaa; Mihaela Schaar",
        "abstract": "Estimating heterogeneous treatment effects from observational data is a central problem in many domains. Because counterfactual data is inaccessible, the problem differs fundamentally from supervised learning, and entails a more complex set of modeling choices. Despite a variety of recently proposed algorithmic solutions, a principled guideline for building estimators of treatment effects using machine learning algorithms is still lacking. In this paper, we provide such a guideline by characterizing the fundamental limits of estimating heterogeneous treatment effects, and establishing conditions under which these limits can be achieved. Our analysis reveals that the relative importance of the different aspects of observational data vary with the sample size. For instance, we show that selection bias matters only in small-sample regimes, whereas with a large sample size, the way an algorithm models the control and treated outcomes is what bottlenecks its performance. Guided by our analysis, we build a practical algorithm for estimating treatment effects using a non-stationary Gaussian processes with doubly-robust hyperparameters. Using a standard semi-synthetic simulation setup, we show that our algorithm outperforms the state-of-the-art, and that the behavior of existing algorithms conforms with our analysis.",
        "bibtex": "@InProceedings{pmlr-v80-alaa18a,\n  title = \t {Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design},\n  author =       {Alaa, Ahmed and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {129--138},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/alaa18a/alaa18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/alaa18a.html},\n  abstract = \t {Estimating heterogeneous treatment effects from observational data is a central problem in many domains. Because counterfactual data is inaccessible, the problem differs fundamentally from supervised learning, and entails a more complex set of modeling choices. Despite a variety of recently proposed algorithmic solutions, a principled guideline for building estimators of treatment effects using machine learning algorithms is still lacking. In this paper, we provide such a guideline by characterizing the fundamental limits of estimating heterogeneous treatment effects, and establishing conditions under which these limits can be achieved. Our analysis reveals that the relative importance of the different aspects of observational data vary with the sample size. For instance, we show that selection bias matters only in small-sample regimes, whereas with a large sample size, the way an algorithm models the control and treated outcomes is what bottlenecks its performance. Guided by our analysis, we build a practical algorithm for estimating treatment effects using a non-stationary Gaussian processes with doubly-robust hyperparameters. Using a standard semi-synthetic simulation setup, we show that our algorithm outperforms the state-of-the-art, and that the behavior of existing algorithms conforms with our analysis.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/alaa18a/alaa18a.pdf",
        "supp": "",
        "pdf_size": 1003798,
        "gs_citation": 177,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3972489950246437255&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Los Angeles, USA+University of Oxford, Oxford, UK+Alan Turing Institute, London, UK; University of California, Los Angeles, USA+University of Oxford, Oxford, UK+Alan Turing Institute, London, UK",
        "aff_domain": "ucla.edu; ",
        "email": "ucla.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/alaa18a.html",
        "aff_unique_index": "0+1+2;0+1+2",
        "aff_unique_norm": "University of California, Los Angeles;University of Oxford;Alan Turing Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucla.edu;https://www.ox.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "UCLA;Oxford;ATI",
        "aff_campus_unique_index": "0+1+2;0+1+2",
        "aff_campus_unique": "Los Angeles;Oxford;London",
        "aff_country_unique_index": "0+1+1;0+1+1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Linear Spectral Estimators and an Application to Phase Retrieval",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2280",
        "id": "2280",
        "author_site": "Ramina Ghods, Andrew Lan, Tom Goldstein, Christoph Studer",
        "author": "Ramina Ghods; Andrew Lan; Tom Goldstein; Christoph Studer",
        "abstract": "Phase retrieval refers to the problem of recovering real- or complex-valued vectors from magnitude measurements. The best-known algorithms for this problem are iterative in nature and rely on so-called spectral initializers that provide accurate initialization vectors. We propose a novel class of estimators suitable for general nonlinear measurement systems, called linear spectral estimators (LSPEs), which can be used to compute accurate initialization vectors for phase retrieval problems. The proposed LSPEs not only provide accurate initialization vectors for noisy phase retrieval systems with structured or random measurement matrices, but also enable the derivation of sharp and nonasymptotic mean-squared error bounds. We demonstrate the efficacy of LSPEs on synthetic and real-world phase retrieval problems, and we show that our estimators significantly outperform existing methods for structured measurement systems that arise in practice.",
        "bibtex": "@InProceedings{pmlr-v80-ghods18a,\n  title = \t {Linear Spectral Estimators and an Application to Phase Retrieval},\n  author =       {Ghods, Ramina and Lan, Andrew and Goldstein, Tom and Studer, Christoph},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1734--1743},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ghods18a/ghods18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ghods18a.html},\n  abstract = \t {Phase retrieval refers to the problem of recovering real- or complex-valued vectors from magnitude measurements. The best-known algorithms for this problem are iterative in nature and rely on so-called spectral initializers that provide accurate initialization vectors. We propose a novel class of estimators suitable for general nonlinear measurement systems, called linear spectral estimators (LSPEs), which can be used to compute accurate initialization vectors for phase retrieval problems. The proposed LSPEs not only provide accurate initialization vectors for noisy phase retrieval systems with structured or random measurement matrices, but also enable the derivation of sharp and nonasymptotic mean-squared error bounds. We demonstrate the efficacy of LSPEs on synthetic and real-world phase retrieval problems, and we show that our estimators significantly outperform existing methods for structured measurement systems that arise in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ghods18a/ghods18a.pdf",
        "supp": "",
        "pdf_size": 852429,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15928847683869538561&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "School of Electrical and Computer Engineering, Cornell University; Department of EE, Princeton University; University of Maryland; School of Electrical and Computer Engineering, Cornell University",
        "aff_domain": "cornell.edu; ; ;cornell.edu",
        "email": "cornell.edu; ; ;cornell.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ghods18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Cornell University;Princeton University;University of Maryland",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Electrical Engineering;",
        "aff_unique_url": "https://www.cornell.edu;https://www.princeton.edu;https://www/umd.edu",
        "aff_unique_abbr": "Cornell;Princeton;UMD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Lipschitz Continuity in Model-based Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2467",
        "id": "2467",
        "author_site": "Kavosh Asadi, Dipendra Misra, Michael L. Littman",
        "author": "Kavosh Asadi; Dipendra Misra; Michael Littman",
        "abstract": "We examine the impact of learning Lipschitz continuous models in the context of model-based reinforcement learning. We provide a novel bound on multi-step prediction error of Lipschitz models where we quantify the error using the Wasserstein metric. We go on to prove an error bound for the value-function estimate arising from Lipschitz models and show that the estimated value function is itself Lipschitz. We conclude with empirical results that show the benefits of controlling the Lipschitz constant of neural-network models.",
        "bibtex": "@InProceedings{pmlr-v80-asadi18a,\n  title = \t {{L}ipschitz Continuity in Model-based Reinforcement Learning},\n  author =       {Asadi, Kavosh and Misra, Dipendra and Littman, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {264--273},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/asadi18a/asadi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/asadi18a.html},\n  abstract = \t {We examine the impact of learning Lipschitz continuous models in the context of model-based reinforcement learning. We provide a novel bound on multi-step prediction error of Lipschitz models where we quantify the error using the Wasserstein metric. We go on to prove an error bound for the value-function estimate arising from Lipschitz models and show that the estimated value function is itself Lipschitz. We conclude with empirical results that show the benefits of controlling the Lipschitz constant of neural-network models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/asadi18a/asadi18a.pdf",
        "supp": "",
        "pdf_size": 2304675,
        "gs_citation": 193,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7519868301941005316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Brown University, Providence, USA+Department of Computer Science and Cornell Tech, Cornell University, New York, USA; Department of Computer Science and Cornell Tech, Cornell University, New York, USA; Department of Computer Science, Brown University, Providence, USA",
        "aff_domain": "brown.edu; ; ",
        "email": "brown.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/asadi18a.html",
        "aff_unique_index": "0+1;1;0",
        "aff_unique_norm": "Brown University;Cornell University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science and Cornell Tech",
        "aff_unique_url": "https://www.brown.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Brown;Cornell",
        "aff_campus_unique_index": "0+1;1;0",
        "aff_campus_unique": "Providence;New York",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Local Convergence Properties of SAGA/Prox-SVRG and Acceleration",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1974",
        "id": "1974",
        "author_site": "Clarice Poon, Jingwei Liang, Carola-Bibiane Sch\u00f6nlieb",
        "author": "Clarice Poon; Jingwei Liang; Carola Schoenlieb",
        "abstract": "In this paper, we present a local convergence anal- ysis for a class of stochastic optimisation meth- ods: the proximal variance reduced stochastic gradient methods, and mainly focus on SAGA (Defazio et al., 2014) and Prox-SVRG (Xiao & Zhang, 2014). Under the assumption that the non-smooth component of the optimisation prob- lem is partly smooth relative to a smooth mani- fold, we present a unified framework for the local convergence analysis of SAGA/Prox-SVRG: (i) the sequences generated by the methods are able to identify the smooth manifold in a finite num- ber of iterations; (ii) then the sequence enters a local linear convergence regime. Furthermore, we discuss various possibilities for accelerating these algorithms, including adapting to better lo- cal parameters, and applying higher-order deter- ministic/stochastic optimisation methods which can achieve super-linear convergence. Several concrete examples arising from machine learning are considered to demonstrate the obtained result.",
        "bibtex": "@InProceedings{pmlr-v80-poon18a,\n  title = \t {Local Convergence Properties of {SAGA}/{P}rox-{SVRG} and Acceleration},\n  author =       {Poon, Clarice and Liang, Jingwei and Schoenlieb, Carola},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4124--4132},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/poon18a/poon18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/poon18a.html},\n  abstract = \t {In this paper, we present a local convergence anal- ysis for a class of stochastic optimisation meth- ods: the proximal variance reduced stochastic gradient methods, and mainly focus on SAGA (Defazio et al., 2014) and Prox-SVRG (Xiao & Zhang, 2014). Under the assumption that the non-smooth component of the optimisation prob- lem is partly smooth relative to a smooth mani- fold, we present a unified framework for the local convergence analysis of SAGA/Prox-SVRG: (i) the sequences generated by the methods are able to identify the smooth manifold in a finite num- ber of iterations; (ii) then the sequence enters a local linear convergence regime. Furthermore, we discuss various possibilities for accelerating these algorithms, including adapting to better lo- cal parameters, and applying higher-order deter- ministic/stochastic optimisation methods which can achieve super-linear convergence. Several concrete examples arising from machine learning are considered to demonstrate the obtained result.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/poon18a/poon18a.pdf",
        "supp": "",
        "pdf_size": 866808,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12517501002751750903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "DAMTP, University of Cambridge; DAMTP, University of Cambridge; DAMTP, University of Cambridge",
        "aff_domain": "maths.cam.ac.uk;cam.ac.uk; ",
        "email": "maths.cam.ac.uk;cam.ac.uk; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/poon18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Applied Mathematics and Theoretical Physics",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Local Density Estimation in High Dimensions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2460",
        "id": "2460",
        "author_site": "Xian Wu, Moses Charikar, Vishnu Natchu",
        "author": "Xian Wu; Moses Charikar; Vishnu Natchu",
        "abstract": "An important question that arises in the study of high dimensional vector representations learned from data is: given a set D of vectors and a query q, estimate the number of points within a specified distance threshold of q. Our algorithm uses locality sensitive hashing to preprocess the data to accurately and efficiently estimate the answers to such questions via an unbiased estimator that uses importance sampling. A key innovation is the ability to maintain a small number of hash tables via preprocessing data structures and algorithms that sample from multiple buckets in each hash table. We give bounds on the space requirements and query complexity of our scheme, and demonstrate the effectiveness of our algorithm by experiments on a standard word embedding dataset.",
        "bibtex": "@InProceedings{pmlr-v80-wu18a,\n  title = \t {Local Density Estimation in High Dimensions},\n  author =       {Wu, Xian and Charikar, Moses and Natchu, Vishnu},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5296--5305},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18a/wu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18a.html},\n  abstract = \t {An important question that arises in the study of high dimensional vector representations learned from data is: given a set D of vectors and a query q, estimate the number of points within a specified distance threshold of q. Our algorithm uses locality sensitive hashing to preprocess the data to accurately and efficiently estimate the answers to such questions via an unbiased estimator that uses importance sampling. A key innovation is the ability to maintain a small number of hash tables via preprocessing data structures and algorithms that sample from multiple buckets in each hash table. We give bounds on the space requirements and query complexity of our scheme, and demonstrate the effectiveness of our algorithm by experiments on a standard word embedding dataset.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18a/wu18a.pdf",
        "supp": "",
        "pdf_size": 437700,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18227807613693764114&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Stanford University, USA; Stanford University, USA; Laserlike Inc, USA",
        "aff_domain": "stanford.edu; ; ",
        "email": "stanford.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wu18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Stanford University;Laserlike Inc",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;",
        "aff_unique_abbr": "Stanford;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Local Private Hypothesis Testing: Chi-Square Tests",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2346",
        "id": "2346",
        "author_site": "Marco Gaboardi, Ryan Rogers",
        "author": "Marco Gaboardi; Ryan Rogers",
        "abstract": "The local model for differential privacy is emerging as the reference model for practical applications of collecting and sharing sensitive information while satisfying strong privacy guarantees. In the local model, there is no trusted entity which is allowed to have each individual\u2019s raw data as is assumed in the traditional curator model. Individuals\u2019 data are usually perturbed before sharing them. We explore the design of private hypothesis tests in the local model, where each data entry is perturbed to ensure the privacy of each participant. Specifically, we analyze locally private chi-square tests for goodness of fit and independence testing.",
        "bibtex": "@InProceedings{pmlr-v80-gaboardi18a,\n  title = \t {Local Private Hypothesis Testing: {C}hi-Square Tests},\n  author =       {Gaboardi, Marco and Rogers, Ryan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1626--1635},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gaboardi18a/gaboardi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gaboardi18a.html},\n  abstract = \t {The local model for differential privacy is emerging as the reference model for practical applications of collecting and sharing sensitive information while satisfying strong privacy guarantees. In the local model, there is no trusted entity which is allowed to have each individual\u2019s raw data as is assumed in the traditional curator model. Individuals\u2019 data are usually perturbed before sharing them. We explore the design of private hypothesis tests in the local model, where each data entry is perturbed to ensure the privacy of each participant. Specifically, we analyze locally private chi-square tests for goodness of fit and independence testing.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gaboardi18a/gaboardi18a.pdf",
        "supp": "",
        "pdf_size": 407595,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13992914620670508043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "University at Buffalo, Buffalo, NY, USA; University of Pennsylvania, Philadelphia, PA, USA",
        "aff_domain": "buffalo.edu; ",
        "email": "buffalo.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/gaboardi18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University at Buffalo;University of Pennsylvania",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.buffalo.edu;https://www.upenn.edu",
        "aff_unique_abbr": "UB;UPenn",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Buffalo;Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Locally Private Hypothesis Testing",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2071",
        "id": "2071",
        "author": "Or Sheffet",
        "abstract": "We initiate the study of differentially private hypothesis testing in the local-model, under both the standard (symmetric) randomized-response mechanism (Warner 1965, Kasiviswanathan et al, 2008) and the newer (non-symmetric) mechanisms (Bassily & Smith, 2015, Bassily et al, 2017). First, we study the general framework of mapping each user\u2019s type into a signal and show that the problem of finding the maximum-likelihood distribution over the signals is feasible. Then we discuss the randomized-response mechanism and show that, in essence, it maps the null- and alternative-hypotheses onto new sets, an affine translation of the original sets. We then give sample complexity bounds for identity and independence testing under randomized-response. We then move to the newer non-symmetric mechanisms and show that there too the problem of finding the maximum-likelihood distribution is feasible. Under the mechanism of Bassily et al we give identity and independence testers with better sample complexity than the testers in the symmetric case, and we also propose a $\\chi^2$-based identity tester which we investigate empirically.",
        "bibtex": "@InProceedings{pmlr-v80-sheffet18a,\n  title = \t {Locally Private Hypothesis Testing},\n  author =       {Sheffet, Or},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4605--4614},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sheffet18a/sheffet18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sheffet18a.html},\n  abstract = \t {We initiate the study of differentially private hypothesis testing in the local-model, under both the standard (symmetric) randomized-response mechanism (Warner 1965, Kasiviswanathan et al, 2008) and the newer (non-symmetric) mechanisms (Bassily & Smith, 2015, Bassily et al, 2017). First, we study the general framework of mapping each user\u2019s type into a signal and show that the problem of finding the maximum-likelihood distribution over the signals is feasible. Then we discuss the randomized-response mechanism and show that, in essence, it maps the null- and alternative-hypotheses onto new sets, an affine translation of the original sets. We then give sample complexity bounds for identity and independence testing under randomized-response. We then move to the newer non-symmetric mechanisms and show that there too the problem of finding the maximum-likelihood distribution is feasible. Under the mechanism of Bassily et al we give identity and independence testers with better sample complexity than the testers in the symmetric case, and we also propose a $\\chi^2$-based identity tester which we investigate empirically.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sheffet18a/sheffet18a.pdf",
        "supp": "",
        "pdf_size": 688275,
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11671168013099844810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Dept. of Computing Science, University of Alberta",
        "aff_domain": "ualberta.ca",
        "email": "ualberta.ca",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/sheffet18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Dept. of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Loss Decomposition for Fast Learning in Large Output Spaces",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2391",
        "id": "2391",
        "author_site": "En-Hsu Yen, Satyen Kale, Felix Xinnan Yu, Daniel Holtmann-Rice, Sanjiv Kumar, Pradeep Ravikumar",
        "author": "Ian En-Hsu Yen; Satyen Kale; Felix Yu; Daniel Holtmann-Rice; Sanjiv Kumar; Pradeep Ravikumar",
        "abstract": "For problems with large output spaces, evaluation of the loss function and its gradient are expensive, typically taking linear time in the size of the output space. Recently, methods have been developed to speed up learning via efficient data structures for Nearest-Neighbor Search (NNS) or Maximum Inner-Product Search (MIPS). However, the performance of such data structures typically degrades in high dimensions. In this work, we propose a novel technique to reduce the intractable high dimensional search problem to several much more tractable lower dimensional ones via dual decomposition of the loss function. At the same time, we demonstrate guaranteed convergence to the original loss via a greedy message passing procedure. In our experiments on multiclass and multilabel classification with hundreds of thousands of classes, as well as training skip-gram word embeddings with a vocabulary size of half a million, our technique consistently improves the accuracy of search-based gradient approximation methods and outperforms sampling-based gradient approximation methods by a large margin.",
        "bibtex": "@InProceedings{pmlr-v80-yen18a,\n  title = \t {Loss Decomposition for Fast Learning in Large Output Spaces},\n  author =       {Yen, Ian En-Hsu and Kale, Satyen and Yu, Felix and Holtmann-Rice, Daniel and Kumar, Sanjiv and Ravikumar, Pradeep},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5640--5649},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yen18a/yen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yen18a.html},\n  abstract = \t {For problems with large output spaces, evaluation of the loss function and its gradient are expensive, typically taking linear time in the size of the output space. Recently, methods have been developed to speed up learning via efficient data structures for Nearest-Neighbor Search (NNS) or Maximum Inner-Product Search (MIPS). However, the performance of such data structures typically degrades in high dimensions. In this work, we propose a novel technique to reduce the intractable high dimensional search problem to several much more tractable lower dimensional ones via dual decomposition of the loss function. At the same time, we demonstrate guaranteed convergence to the original loss via a greedy message passing procedure. In our experiments on multiclass and multilabel classification with hundreds of thousands of classes, as well as training skip-gram word embeddings with a vocabulary size of half a million, our technique consistently improves the accuracy of search-based gradient approximation methods and outperforms sampling-based gradient approximation methods by a large margin.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yen18a/yen18a.pdf",
        "supp": "",
        "pdf_size": 415125,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16393522951999939979&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Carnegie Mellon University, Pittsburgh, USA; Google, New York, USA; Google, New York, USA; Google, New York, USA; Google, New York, USA; Carnegie Mellon University, Pittsburgh, USA",
        "aff_domain": "cs.cmu.edu;google.com; ; ; ;cs.cmu.edu",
        "email": "cs.cmu.edu;google.com; ; ; ;cs.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/yen18a.html",
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.cmu.edu;https://www.google.com",
        "aff_unique_abbr": "CMU;Google",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Pittsburgh;New York",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Low-Rank Riemannian Optimization on Positive Semidefinite Stochastic Matrices with Applications to Graph Clustering",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2061",
        "id": "2061",
        "author_site": "Ahmed Douik, Babak Hassibi",
        "author": "Ahmed Douik; Babak Hassibi",
        "abstract": "This paper develops a Riemannian optimization framework for solving optimization problems on the set of symmetric positive semidefinite stochastic matrices. The paper first reformulates the problem by factorizing the optimization variable as $\\mathbf{X}=\\mathbf{Y}\\mathbf{Y}^T$ and deriving conditions on $p$, i.e., the number of columns of $\\mathbf{Y}$, under which the factorization yields a satisfactory solution. The reparameterization of the problem allows its formulation as an optimization over either an embedded or quotient Riemannian manifold whose geometries are investigated. In particular, the paper explicitly derives the tangent space, Riemannian gradients and retraction operator that allow the design of efficient optimization methods on the proposed manifolds. The numerical results reveal that, when the optimal solution has a known low-rank, the resulting algorithms present a clear complexity advantage when compared with state-of-the-art Euclidean and Riemannian approaches for graph clustering applications.",
        "bibtex": "@InProceedings{pmlr-v80-douik18a,\n  title = \t {Low-Rank {R}iemannian Optimization on Positive Semidefinite Stochastic Matrices with Applications to Graph Clustering},\n  author =       {Douik, Ahmed and Hassibi, Babak},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1299--1308},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/douik18a/douik18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/douik18a.html},\n  abstract = \t {This paper develops a Riemannian optimization framework for solving optimization problems on the set of symmetric positive semidefinite stochastic matrices. The paper first reformulates the problem by factorizing the optimization variable as $\\mathbf{X}=\\mathbf{Y}\\mathbf{Y}^T$ and deriving conditions on $p$, i.e., the number of columns of $\\mathbf{Y}$, under which the factorization yields a satisfactory solution. The reparameterization of the problem allows its formulation as an optimization over either an embedded or quotient Riemannian manifold whose geometries are investigated. In particular, the paper explicitly derives the tangent space, Riemannian gradients and retraction operator that allow the design of efficient optimization methods on the proposed manifolds. The numerical results reveal that, when the optimal solution has a known low-rank, the resulting algorithms present a clear complexity advantage when compared with state-of-the-art Euclidean and Riemannian approaches for graph clustering applications.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/douik18a/douik18a.pdf",
        "supp": "",
        "pdf_size": 359976,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10152762593423630069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering, California Institute of Technology, CA, USA; Department of Electrical Engineering, California Institute of Technology, CA, USA",
        "aff_domain": "caltech.edu; ",
        "email": "caltech.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/douik18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Lyapunov Functions for First-Order Methods: Tight Automated Convergence Guarantees",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2168",
        "id": "2168",
        "author_site": "Adrien Taylor, Bryan Van Scoy, Laurent Lessard",
        "author": "Adrien Taylor; Bryan Van Scoy; Laurent Lessard",
        "abstract": "We present a novel way of generating Lyapunov functions for proving linear convergence rates of first-order optimization methods. Our approach provably obtains the fastest linear convergence rate that can be verified by a quadratic Lyapunov function (with given states), and only relies on solving a small-sized semidefinite program. Our approach combines the advantages of performance estimation problems (PEP, due to Drori and Teboulle (2014)) and integral quadratic constraints (IQC, due to Lessard et al. (2016)), and relies on convex interpolation (due to Taylor et al. (2017c;b)).",
        "bibtex": "@InProceedings{pmlr-v80-taylor18a,\n  title = \t {{L}yapunov Functions for First-Order Methods: Tight Automated Convergence Guarantees},\n  author =       {Taylor, Adrien and Van Scoy, Bryan and Lessard, Laurent},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4897--4906},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/taylor18a/taylor18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/taylor18a.html},\n  abstract = \t {We present a novel way of generating Lyapunov functions for proving linear convergence rates of first-order optimization methods. Our approach provably obtains the fastest linear convergence rate that can be verified by a quadratic Lyapunov function (with given states), and only relies on solving a small-sized semidefinite program. Our approach combines the advantages of performance estimation problems (PEP, due to Drori and Teboulle (2014)) and integral quadratic constraints (IQC, due to Lessard et al. (2016)), and relies on convex interpolation (due to Taylor et al. (2017c;b)).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/taylor18a/taylor18a.pdf",
        "supp": "",
        "pdf_size": 337059,
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1395570422835062279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "INRIA, D\u00b4epartement d\u2019informatique de l\u2019ENS, \u00b4Ecole normale sup\u00b4erieure, CNRS, PSL Research University, Paris, France+Wisconsin Institute for Discovery, University of Wisconsin\u2013Madison, Madison, Wisconsin, USA; Wisconsin Institute for Discovery, University of Wisconsin\u2013Madison, Madison, Wisconsin, USA+Department of Electrical and Computer Engineering, University of Wisconsin\u2013Madison, Madison, Wisconsin, USA; Wisconsin Institute for Discovery, University of Wisconsin\u2013Madison, Madison, Wisconsin, USA+Department of Electrical and Computer Engineering, University of Wisconsin\u2013Madison, Madison, Wisconsin, USA",
        "aff_domain": "inria.fr;wisc.edu;wisc.edu",
        "email": "inria.fr;wisc.edu;wisc.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/taylor18a.html",
        "aff_unique_index": "0+1;1+1;1+1",
        "aff_unique_norm": "INRIA;University of Wisconsin\u2013Madison",
        "aff_unique_dep": "D\u00b4epartement d\u2019informatique de l\u2019ENS;Wisconsin Institute for Discovery",
        "aff_unique_url": "https://www.inria.fr;https://wid.wisc.edu",
        "aff_unique_abbr": "INRIA;UW\u2013Madison",
        "aff_campus_unique_index": "0+1;1+1;1+1",
        "aff_campus_unique": "Paris;Madison",
        "aff_country_unique_index": "0+1;1+1;1+1",
        "aff_country_unique": "France;United States"
    },
    {
        "title": "MAGAN: Aligning Biological Manifolds",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2455",
        "id": "2455",
        "author_site": "Matt Amodio, Smita Krishnaswamy",
        "author": "Matthew Amodio; Smita Krishnaswamy",
        "abstract": "It is increasingly common in many types of natural and physical systems (especially biological systems) to have different types of measurements performed on the same underlying system. In such settings, it is important to align the manifolds arising from each measurement in order to integrate such data and gain an improved picture of the system; we tackle this problem using generative adversarial networks (GANs). Recent attempts to use GANs to find correspondences between sets of samples do not explicitly perform proper alignment of manifolds. We present the new Manifold Aligning GAN (MAGAN) that aligns two manifolds such that related points in each measurement space are aligned. We demonstrate applications of MAGAN in single-cell biology in integrating two different measurement types together: cells from the same tissue are measured with both genomic (single-cell RNA-sequencing) and proteomic (mass cytometry) technologies. We show that MAGAN successfully aligns manifolds such that known correlations between measured markers are improved compared to other recently proposed models.",
        "bibtex": "@InProceedings{pmlr-v80-amodio18a,\n  title = \t {{MAGAN}: Aligning Biological Manifolds},\n  author =       {Amodio, Matthew and Krishnaswamy, Smita},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {215--223},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/amodio18a/amodio18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/amodio18a.html},\n  abstract = \t {It is increasingly common in many types of natural and physical systems (especially biological systems) to have different types of measurements performed on the same underlying system. In such settings, it is important to align the manifolds arising from each measurement in order to integrate such data and gain an improved picture of the system; we tackle this problem using generative adversarial networks (GANs). Recent attempts to use GANs to find correspondences between sets of samples do not explicitly perform proper alignment of manifolds. We present the new Manifold Aligning GAN (MAGAN) that aligns two manifolds such that related points in each measurement space are aligned. We demonstrate applications of MAGAN in single-cell biology in integrating two different measurement types together: cells from the same tissue are measured with both genomic (single-cell RNA-sequencing) and proteomic (mass cytometry) technologies. We show that MAGAN successfully aligns manifolds such that known correlations between measured markers are improved compared to other recently proposed models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/amodio18a/amodio18a.pdf",
        "supp": "",
        "pdf_size": 737347,
        "gs_citation": 101,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2850609560851515473&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Yale University; Department of Genetics, Yale University",
        "aff_domain": "yale.edu; ",
        "email": "yale.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/amodio18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "MISSION: Ultra Large-Scale Feature Selection using Count-Sketches",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2249",
        "id": "2249",
        "author_site": "Amirali Aghazadeh, Ryan Spring, Daniel LeJeune, Gautam Dasarathy, Anshumali Shrivastava, Richard Baraniuk",
        "author": "Amirali Aghazadeh; Ryan Spring; Daniel Lejeune; Gautam Dasarathy; Anshumali Shrivastava;  baraniuk",
        "abstract": "Feature selection is an important challenge in machine learning. It plays a crucial role in the explainability of machine-driven decisions that are rapidly permeating throughout modern society. Unfortunately, the explosion in the size and dimensionality of real-world datasets poses a severe challenge to standard feature selection algorithms. Today, it is not uncommon for datasets to have billions of dimensions. At such scale, even storing the feature vector is impossible, causing most existing feature selection methods to fail. Workarounds like feature hashing, a standard approach to large-scale machine learning, helps with the computational feasibility, but at the cost of losing the interpretability of features. In this paper, we present MISSION, a novel framework for ultra large-scale feature selection that performs stochastic gradient descent while maintaining an efficient representation of the features in memory using a Count-Sketch data structure. MISSION retains the simplicity of feature hashing without sacrificing the interpretability of the features while using only O(log^2(p)) working memory. We demonstrate that MISSION accurately and efficiently performs feature selection on real-world, large-scale datasets with billions of dimensions.",
        "bibtex": "@InProceedings{pmlr-v80-aghazadeh18a,\n  title = \t {{MISSION}: Ultra Large-Scale Feature Selection using Count-Sketches},\n  author =       {Aghazadeh, Amirali and Spring, Ryan and Lejeune, Daniel and Dasarathy, Gautam and Shrivastava, Anshumali and richard baraniuk},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {80--88},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/aghazadeh18a/aghazadeh18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/aghazadeh18a.html},\n  abstract = \t {Feature selection is an important challenge in machine learning. It plays a crucial role in the explainability of machine-driven decisions that are rapidly permeating throughout modern society. Unfortunately, the explosion in the size and dimensionality of real-world datasets poses a severe challenge to standard feature selection algorithms. Today, it is not uncommon for datasets to have billions of dimensions. At such scale, even storing the feature vector is impossible, causing most existing feature selection methods to fail. Workarounds like feature hashing, a standard approach to large-scale machine learning, helps with the computational feasibility, but at the cost of losing the interpretability of features. In this paper, we present MISSION, a novel framework for ultra large-scale feature selection that performs stochastic gradient descent while maintaining an efficient representation of the features in memory using a Count-Sketch data structure. MISSION retains the simplicity of feature hashing without sacrificing the interpretability of the features while using only O(log^2(p)) working memory. We demonstrate that MISSION accurately and efficiently performs feature selection on real-world, large-scale datasets with billions of dimensions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/aghazadeh18a/aghazadeh18a.pdf",
        "supp": "",
        "pdf_size": 1192013,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7532201827567458901&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/aghazadeh18a.html"
    },
    {
        "title": "MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1897",
        "id": "1897",
        "author_site": "Bo Zhao, Xinwei Sun, Yanwei Fu, Yuan Yao, Yizhou Wang",
        "author": "Bo Zhao; Xinwei Sun; Yanwei Fu; Yuan Yao; Yizhou Wang",
        "abstract": "It is one typical and general topic of learning a good embedding model to efficiently learn the representation coefficients between two spaces/subspaces. To solve this task, $L_{1}$ regularization is widely used for the pursuit of feature selection and avoiding overfitting, and yet the sparse estimation of features in $L_{1}$ regularization may cause the underfitting of training data. $L_{2}$ regularization is also frequently used, but it is a biased estimator. In this paper, we propose the idea that the features consist of three orthogonal parts,",
        "bibtex": "@InProceedings{pmlr-v80-zhao18c,\n  title = \t {{MS}plit {LBI}: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning},\n  author =       {Zhao, Bo and Sun, Xinwei and Fu, Yanwei and Yao, Yuan and Wang, Yizhou},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5912--5921},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhao18c/zhao18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhao18c.html},\n  abstract = \t {It is one typical and general topic of learning a good embedding model to efficiently learn the representation coefficients between two spaces/subspaces. To solve this task, $L_{1}$ regularization is widely used for the pursuit of feature selection and avoiding overfitting, and yet the sparse estimation of features in $L_{1}$ regularization may cause the underfitting of training data. $L_{2}$ regularization is also frequently used, but it is a biased estimator. In this paper, we propose the idea that the features consist of three orthogonal parts,",
        "pdf": "http://proceedings.mlr.press/v80/zhao18c/zhao18c.pdf",
        "supp": "",
        "pdf_size": 726898,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1249010609215873214&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/zhao18c.html"
    },
    {
        "title": "Machine Theory of Mind",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2159",
        "id": "2159",
        "author_site": "Neil Rabinowitz, Frank Perbet, Francis Song, Chiyuan Zhang, S. M. Ali Eslami, Matthew Botvinick",
        "author": "Neil Rabinowitz; Frank Perbet; Francis Song; Chiyuan Zhang; S. M. Ali Eslami; Matthew Botvinick",
        "abstract": "Theory of mind (ToM) broadly refers to humans\u2019 ability to represent the mental states of others, including their desires, beliefs, and intentions. We design a Theory of Mind neural network {\u2013} a ToMnet {\u2013} which uses meta-learning to build such models of the agents it encounters. The ToMnet learns a strong prior model for agents\u2019 future behaviour, and, using only a small number of behavioural observations, can bootstrap to richer predictions about agents\u2019 characteristics and mental states. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep RL agents from varied populations, and that it passes classic ToM tasks such as the \"Sally-Anne\" test of recognising that others can hold false beliefs about the world.",
        "bibtex": "@InProceedings{pmlr-v80-rabinowitz18a,\n  title = \t {Machine Theory of Mind},\n  author =       {Rabinowitz, Neil and Perbet, Frank and Song, Francis and Zhang, Chiyuan and Eslami, S. M. Ali and Botvinick, Matthew},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4218--4227},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rabinowitz18a/rabinowitz18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rabinowitz18a.html},\n  abstract = \t {Theory of mind (ToM) broadly refers to humans\u2019 ability to represent the mental states of others, including their desires, beliefs, and intentions. We design a Theory of Mind neural network {\u2013} a ToMnet {\u2013} which uses meta-learning to build such models of the agents it encounters. The ToMnet learns a strong prior model for agents\u2019 future behaviour, and, using only a small number of behavioural observations, can bootstrap to richer predictions about agents\u2019 characteristics and mental states. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep RL agents from varied populations, and that it passes classic ToM tasks such as the \"Sally-Anne\" test of recognising that others can hold false beliefs about the world.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rabinowitz18a/rabinowitz18a.pdf",
        "supp": "",
        "pdf_size": 5862736,
        "gs_citation": 732,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6267278380616425333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "arxiv.org/abs/1802.07740",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/rabinowitz18a.html"
    },
    {
        "title": "Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2111",
        "id": "2111",
        "author_site": "Zeyuan Allen-Zhu, Sebastien Bubeck, Yuanzhi Li",
        "author": "Zeyuan Allen-Zhu; Sebastien Bubeck; Yuanzhi Li",
        "abstract": "Regret bounds in online learning compare the player\u2019s performance to $L*$, the optimal performance in hindsight with a fixed strategy. Typically such bounds scale with the square root of the time horizon $T$. The more refined concept of first-order regret bound replaces this with a scaling $\\sqrt{L*}$, which may be much smaller than $\\sqrt{T}$. It is well known that minor variants of standard algorithms satisfy first-order regret bounds in the full information and multi-armed bandit settings. In a COLT 2017 open problem, Agarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that existing techniques do not seem sufficient to obtain first-order regret bounds for the contextual bandit problem. In the present paper, we resolve this open problem by presenting a new strategy based on augmenting the policy space.",
        "bibtex": "@InProceedings{pmlr-v80-allen-zhu18b,\n  title = \t {Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits},\n  author =       {Allen-Zhu, Zeyuan and Bubeck, Sebastien and Li, Yuanzhi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {186--194},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/allen-zhu18b/allen-zhu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/allen-zhu18b.html},\n  abstract = \t {Regret bounds in online learning compare the player\u2019s performance to $L*$, the optimal performance in hindsight with a fixed strategy. Typically such bounds scale with the square root of the time horizon $T$. The more refined concept of first-order regret bound replaces this with a scaling $\\sqrt{L*}$, which may be much smaller than $\\sqrt{T}$. It is well known that minor variants of standard algorithms satisfy first-order regret bounds in the full information and multi-armed bandit settings. In a COLT 2017 open problem, Agarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that existing techniques do not seem sufficient to obtain first-order regret bounds for the contextual bandit problem. In the present paper, we resolve this open problem by presenting a new strategy based on augmenting the policy space.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/allen-zhu18b/allen-zhu18b.pdf",
        "supp": "",
        "pdf_size": 410852,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6188156794022188605&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Microsoft Research AI; Microsoft Research AI; Princeton University",
        "aff_domain": "csail.mit.edu;microsoft.com;cs.princeton.edu",
        "email": "csail.mit.edu;microsoft.com;cs.princeton.edu",
        "github": "",
        "project": "https://arxiv.org/abs/1802.03386",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/allen-zhu18b.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Microsoft;Princeton University",
        "aff_unique_dep": "AI;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.princeton.edu",
        "aff_unique_abbr": "MSR;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Markov Modulated Gaussian Cox Processes for Semi-Stationary Intensity Modeling of Events Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2047",
        "id": "2047",
        "author": "Minyoung Kim",
        "abstract": "The Cox process is a flexible event model that can account for uncertainty of the intensity function in the Poisson process. However, previous approaches make strong assumptions in terms of time stationarity, potentially failing to generalize when the data do not conform to the assumed stationarity conditions. In this paper we bring up two most popular Cox models representing two extremes, and propose a novel semi-stationary Cox process model that can take benefits from both models. Our model has a set of Gaussian process latent functions governed by a latent stationary Markov process where we provide analytic derivations for the variational inference. Empirical evaluations on several synthetic and real-world events data including the football shot attempts and daily earthquakes, demonstrate that the proposed model is promising, can yield improved generalization performance over existing approaches.",
        "bibtex": "@InProceedings{pmlr-v80-kim18a,\n  title = \t {{M}arkov Modulated {G}aussian {C}ox Processes for Semi-Stationary Intensity Modeling of Events Data},\n  author =       {Kim, Minyoung},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2640--2648},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kim18a/kim18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kim18a.html},\n  abstract = \t {The Cox process is a flexible event model that can account for uncertainty of the intensity function in the Poisson process. However, previous approaches make strong assumptions in terms of time stationarity, potentially failing to generalize when the data do not conform to the assumed stationarity conditions. In this paper we bring up two most popular Cox models representing two extremes, and propose a novel semi-stationary Cox process model that can take benefits from both models. Our model has a set of Gaussian process latent functions governed by a latent stationary Markov process where we provide analytic derivations for the variational inference. Empirical evaluations on several synthetic and real-world events data including the football shot attempts and daily earthquakes, demonstrate that the proposed model is promising, can yield improved generalization performance over existing approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kim18a/kim18a.pdf",
        "supp": "",
        "pdf_size": 455132,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4703405380363365515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Seoul National University of Science & Technology, Korea + Rutgers University, Piscataway, NJ, USA",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/kim18a.html",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "Seoul National University of Science & Technology;Rutgers University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.rutgers.edu",
        "aff_unique_abbr": "SNUST;Rutgers",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Piscataway",
        "aff_country_unique_index": "0+1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "title": "Massively Parallel Algorithms and Hardness for Single-Linkage Clustering under $\\ell_p$ Distances",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2366",
        "id": "2366",
        "author_site": "Grigory Yaroslavtsev, Adithya Vadapalli",
        "author": "Grigory Yaroslavtsev; Adithya Vadapalli",
        "abstract": "We present first massively parallel (MPC) algorithms and hardness of approximation results for computing Single-Linkage Clustering of n input d-dimensional vectors under Hamming, $\\ell_1, \\ell_2$ and $\\ell_\\infty$ distances. All our algorithms run in O(log n) rounds of MPC for any fixed d and achieve (1+\\epsilon)-approximation for all distances (except Hamming for which we show an exact algorithm). We also show constant-factor inapproximability results for o(\\log n)-round algorithms under standard MPC hardness assumptions (for sufficiently large dimension depending on the distance used). Efficiency of implementation of our algorithms in Apache Spark is demonstrated through experiments on the largest available vector datasets from the UCI machine learning repository exhibiting speedups of several orders of magnitude.",
        "bibtex": "@InProceedings{pmlr-v80-yaroslavtsev18a,\n  title = \t {Massively Parallel Algorithms and Hardness for Single-Linkage Clustering under $\\ell_p$ Distances},\n  author =       {Yaroslavtsev, Grigory and Vadapalli, Adithya},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5600--5609},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yaroslavtsev18a/yaroslavtsev18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yaroslavtsev18a.html},\n  abstract = \t {We present first massively parallel (MPC) algorithms and hardness of approximation results for computing Single-Linkage Clustering of n input d-dimensional vectors under Hamming, $\\ell_1, \\ell_2$ and $\\ell_\\infty$ distances. All our algorithms run in O(log n) rounds of MPC for any fixed d and achieve (1+\\epsilon)-approximation for all distances (except Hamming for which we show an exact algorithm). We also show constant-factor inapproximability results for o(\\log n)-round algorithms under standard MPC hardness assumptions (for sufficiently large dimension depending on the distance used). Efficiency of implementation of our algorithms in Apache Spark is demonstrated through experiments on the largest available vector datasets from the UCI machine learning repository exhibiting speedups of several orders of magnitude.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yaroslavtsev18a/yaroslavtsev18a.pdf",
        "supp": "",
        "pdf_size": 332561,
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2361375922122176345&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Indiana University, Bloomington, Indiana, United States; Department of Computer Science, Indiana University, Bloomington, Indiana, United States",
        "aff_domain": "grigory.us;iu.edu",
        "email": "grigory.us;iu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/yaroslavtsev18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indiana University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.indiana.edu",
        "aff_unique_abbr": "IU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bloomington",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2069",
        "id": "2069",
        "author_site": "Vladimir Braverman, Stephen Chestnut, Robert Krauthgamer, Yi Li, David Woodruff, Lin Yang",
        "author": "Vladimir Braverman; Stephen Chestnut; Robert Krauthgamer; Yi Li; David Woodruff; Lin Yang",
        "abstract": "A central problem in mining massive data streams is characterizing which functions of an underlying frequency vector can be approximated efficiently. Given the prevalence of large scale linear algebra problems in machine learning, recently there has been considerable effort in extending this data stream problem to that of estimating functions of a matrix. This setting generalizes classical problems to the analogous ones for matrices. For example, instead of estimating frequent-item counts, we now wish to estimate \u201cfrequent-direction\u201d counts. A related example is to estimate norms, which now correspond to estimating a vector norm on the singular values of the matrix. Despite recent efforts, the current understanding for such matrix problems is considerably weaker than that for vector problems. We study a number of aspects of estimating matrix norms in a stream that have not previously been considered: (1) multi-pass algorithms, (2) algorithms that see the underlying matrix one row at a time, and (3) time-efficient algorithms. Our multi-pass and row-order algorithms use less memory than what is provably required in the single-pass and entrywise-update models, and thus give separations between these models (in terms of memory). Moreover, all of our algorithms are considerably faster than previous ones. We also prove a number of lower bounds, and obtain for instance, a near-complete characterization of the memory required of row-order algorithms for estimating Schatten $p$-norms of sparse matrices. We complement our results with numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v80-braverman18a,\n  title = \t {Matrix Norms in Data Streams: Faster, Multi-Pass and Row-Order},\n  author =       {Braverman, Vladimir and Chestnut, Stephen and Krauthgamer, Robert and Li, Yi and Woodruff, David and Yang, Lin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {649--658},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/braverman18a/braverman18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/braverman18a.html},\n  abstract = \t {A central problem in mining massive data streams is characterizing which functions of an underlying frequency vector can be approximated efficiently. Given the prevalence of large scale linear algebra problems in machine learning, recently there has been considerable effort in extending this data stream problem to that of estimating functions of a matrix. This setting generalizes classical problems to the analogous ones for matrices. For example, instead of estimating frequent-item counts, we now wish to estimate \u201cfrequent-direction\u201d counts. A related example is to estimate norms, which now correspond to estimating a vector norm on the singular values of the matrix. Despite recent efforts, the current understanding for such matrix problems is considerably weaker than that for vector problems. We study a number of aspects of estimating matrix norms in a stream that have not previously been considered: (1) multi-pass algorithms, (2) algorithms that see the underlying matrix one row at a time, and (3) time-efficient algorithms. Our multi-pass and row-order algorithms use less memory than what is provably required in the single-pass and entrywise-update models, and thus give separations between these models (in terms of memory). Moreover, all of our algorithms are considerably faster than previous ones. We also prove a number of lower bounds, and obtain for instance, a near-complete characterization of the memory required of row-order algorithms for estimating Schatten $p$-norms of sparse matrices. We complement our results with numerical experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/braverman18a/braverman18a.pdf",
        "supp": "",
        "pdf_size": 624063,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8512117224537765603&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Johns Hopkins University; ETH Zurich; Weizmann Institute of Science; Nanyang Technological University; Carnegie Mellon University; Princeton University",
        "aff_domain": "princeton.edu; ; ; ; ; ",
        "email": "princeton.edu; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/braverman18a.html",
        "aff_unique_index": "0;1;2;3;4;5",
        "aff_unique_norm": "Johns Hopkins University;ETH Zurich;Weizmann Institute of Science;Nanyang Technological University;Carnegie Mellon University;Princeton University",
        "aff_unique_dep": ";;;;;",
        "aff_unique_url": "https://www.jhu.edu;https://www.ethz.ch;https://www.weizmann.org.il;https://www.ntu.edu.sg;https://www.cmu.edu;https://www.princeton.edu",
        "aff_unique_abbr": "JHU;ETHZ;Weizmann;NTU;CMU;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;3;0;0",
        "aff_country_unique": "United States;Switzerland;Israel;Singapore"
    },
    {
        "title": "Max-Mahalanobis Linear Discriminant Analysis Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2079",
        "id": "2079",
        "author_site": "Tianyu Pang, Chao Du, Jun Zhu",
        "author": "Tianyu Pang; Chao Du; Jun Zhu",
        "abstract": "A deep neural network (DNN) consists of a nonlinear transformation from an input to a feature representation, followed by a common softmax linear classifier. Though many efforts have been devoted to designing a proper architecture for nonlinear transformation, little investigation has been done on the classifier part. In this paper, we show that a properly designed classifier can improve robustness to adversarial attacks and lead to better prediction results. Specifically, we define a Max-Mahalanobis distribution (MMD) and theoretically show that if the input distributes as a MMD, the linear discriminant analysis (LDA) classifier will have the best robustness to adversarial examples. We further propose a novel Max-Mahalanobis linear discriminant analysis (MM-LDA) network, which explicitly maps a complicated data distribution in the input space to a MMD in the latent feature space and then applies LDA to make predictions. Our results demonstrate that the MM-LDA networks are significantly more robust to adversarial attacks, and have better performance in class-biased classification.",
        "bibtex": "@InProceedings{pmlr-v80-pang18a,\n  title = \t {Max-{M}ahalanobis Linear Discriminant Analysis Networks},\n  author =       {Pang, Tianyu and Du, Chao and Zhu, Jun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4016--4025},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pang18a/pang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pang18a.html},\n  abstract = \t {A deep neural network (DNN) consists of a nonlinear transformation from an input to a feature representation, followed by a common softmax linear classifier. Though many efforts have been devoted to designing a proper architecture for nonlinear transformation, little investigation has been done on the classifier part. In this paper, we show that a properly designed classifier can improve robustness to adversarial attacks and lead to better prediction results. Specifically, we define a Max-Mahalanobis distribution (MMD) and theoretically show that if the input distributes as a MMD, the linear discriminant analysis (LDA) classifier will have the best robustness to adversarial examples. We further propose a novel Max-Mahalanobis linear discriminant analysis (MM-LDA) network, which explicitly maps a complicated data distribution in the input space to a MMD in the latent feature space and then applies LDA to make predictions. Our results demonstrate that the MM-LDA networks are significantly more robust to adversarial attacks, and have better performance in class-biased classification.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pang18a/pang18a.pdf",
        "supp": "",
        "pdf_size": 567449,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1310490945606447616&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China",
        "aff_domain": "mail.tsinghua.edu.cn; ; ",
        "email": "mail.tsinghua.edu.cn; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/pang18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Mean Field Multi-Agent Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2458",
        "id": "2458",
        "author_site": "Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, Jun Wang",
        "author": "Yaodong Yang; Rui Luo; Minne Li; Ming Zhou; Weinan Zhang; Jun Wang",
        "abstract": "Existing multi-agent reinforcement learning methods are limited typically to a small number of agents. When the agent number increases largely, the learning becomes intractable due to the curse of the dimensionality and the exponential growth of agent interactions. In this paper, we present Mean Field Reinforcement Learning where the interactions within the population of agents are approximated by those between a single agent and the average effect from the overall population or neighboring agents; the interplay between the two entities is mutually reinforced: the learning of the individual agent\u2019s optimal policy depends on the dynamics of the population, while the dynamics of the population change according to the collective patterns of the individual policies. We develop practical mean field Q-learning and mean field Actor-Critic algorithms and analyze the convergence of the solution to Nash equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games justify the learning effectiveness of our mean field approaches. In addition, we report the first result to solve the Ising model via model-free reinforcement learning methods.",
        "bibtex": "@InProceedings{pmlr-v80-yang18d,\n  title = \t {Mean Field Multi-Agent Reinforcement Learning},\n  author =       {Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5571--5580},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yang18d/yang18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yang18d.html},\n  abstract = \t {Existing multi-agent reinforcement learning methods are limited typically to a small number of agents. When the agent number increases largely, the learning becomes intractable due to the curse of the dimensionality and the exponential growth of agent interactions. In this paper, we present Mean Field Reinforcement Learning where the interactions within the population of agents are approximated by those between a single agent and the average effect from the overall population or neighboring agents; the interplay between the two entities is mutually reinforced: the learning of the individual agent\u2019s optimal policy depends on the dynamics of the population, while the dynamics of the population change according to the collective patterns of the individual policies. We develop practical mean field Q-learning and mean field Actor-Critic algorithms and analyze the convergence of the solution to Nash equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games justify the learning effectiveness of our mean field approaches. In addition, we report the first result to solve the Ising model via model-free reinforcement learning methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yang18d/yang18d.pdf",
        "supp": "",
        "pdf_size": 3549094,
        "gs_citation": 902,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18365585657208114611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University College London; University College London; University College London; Shanghai Jiao Tong University; Shanghai Jiao Tong University; University College London",
        "aff_domain": "cs.ucl.ac.uk;cs.ucl.ac.uk;cs.ucl.ac.uk;sjtu.edu.cn;sjtu.edu.cn;cs.ucl.ac.uk",
        "email": "cs.ucl.ac.uk;cs.ucl.ac.uk;cs.ucl.ac.uk;sjtu.edu.cn;sjtu.edu.cn;cs.ucl.ac.uk",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/yang18d.html",
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "University College London;Shanghai Jiao Tong University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "UCL;SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "title": "Measuring abstract reasoning in neural networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2194",
        "id": "2194",
        "author_site": "Adam Santoro, Feilx Hill, David GT Barrett, Ari S Morcos, Timothy Lillicrap",
        "author": "David Barrett; Felix Hill; Adam Santoro; Ari Morcos; Timothy Lillicrap",
        "abstract": "Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation \u2019regimes\u2019 in which the training data and test questions differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model\u2019s ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.",
        "bibtex": "@InProceedings{pmlr-v80-barrett18a,\n  title = \t {Measuring abstract reasoning in neural networks},\n  author =       {Barrett, David and Hill, Felix and Santoro, Adam and Morcos, Ari and Lillicrap, Timothy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {511--520},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/barrett18a/barrett18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/barrett18a.html},\n  abstract = \t {Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation \u2019regimes\u2019 in which the training data and test questions differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model\u2019s ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/barrett18a/barrett18a.pdf",
        "supp": "",
        "pdf_size": 623708,
        "gs_citation": 283,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4952119051738101930&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom",
        "aff_domain": "google.com;google.com;google.com; ; ",
        "email": "google.com;google.com;google.com; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/barrett18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1952",
        "id": "1952",
        "author_site": "Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, Li Fei-Fei",
        "author": "Lu Jiang; Zhengyuan Zhou; Thomas Leung; Li-Jia Li; Li Fei-Fei",
        "abstract": "Recent deep networks are capable of memorizing the entire data even when the labels are completely random. To overcome the overfitting on corrupted labels, we propose a novel technique of learning another neural network, called MentorNet, to supervise the training of the base deep networks, namely, StudentNet. During training, MentorNet provides a curriculum (sample weighting scheme) for StudentNet to focus on the sample the label of which is probably correct. Unlike the existing curriculum that is usually predefined by human experts, MentorNet learns a data-driven curriculum dynamically with StudentNet. Experimental results demonstrate that our approach can significantly improve the generalization performance of deep networks trained on corrupted training data. Notably, to the best of our knowledge, we achieve the best-published result on WebVision, a large benchmark containing 2.2 million images of real-world noisy labels.",
        "bibtex": "@InProceedings{pmlr-v80-jiang18c,\n  title = \t {{M}entor{N}et: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels},\n  author =       {Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2304--2313},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jiang18c/jiang18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jiang18c.html},\n  abstract = \t {Recent deep networks are capable of memorizing the entire data even when the labels are completely random. To overcome the overfitting on corrupted labels, we propose a novel technique of learning another neural network, called MentorNet, to supervise the training of the base deep networks, namely, StudentNet. During training, MentorNet provides a curriculum (sample weighting scheme) for StudentNet to focus on the sample the label of which is probably correct. Unlike the existing curriculum that is usually predefined by human experts, MentorNet learns a data-driven curriculum dynamically with StudentNet. Experimental results demonstrate that our approach can significantly improve the generalization performance of deep networks trained on corrupted training data. Notably, to the best of our knowledge, we achieve the best-published result on WebVision, a large benchmark containing 2.2 million images of real-world noisy labels.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jiang18c/jiang18c.pdf",
        "supp": "",
        "pdf_size": 724170,
        "gs_citation": 1917,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18276912967596258717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Google Inc., Mountain View, United States+Stanford University, Stanford, United States; Stanford University, Stanford, United States; Google Inc., Mountain View, United States; Google Inc., Mountain View, United States+Stanford University, Stanford, United States; Google Inc., Mountain View, United States+Stanford University, Stanford, United States",
        "aff_domain": "google.com; ; ; ; ",
        "email": "google.com; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/jiang18c.html",
        "aff_unique_index": "0+1;1;0;0+1;0+1",
        "aff_unique_norm": "Google;Stanford University",
        "aff_unique_dep": "Google Inc.;",
        "aff_unique_url": "https://www.google.com;https://www.stanford.edu",
        "aff_unique_abbr": "Google;Stanford",
        "aff_campus_unique_index": "0+1;1;0;0+1;0+1",
        "aff_campus_unique": "Mountain View;Stanford",
        "aff_country_unique_index": "0+0;0;0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Message Passing Stein Variational Gradient Descent",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1915",
        "id": "1915",
        "author_site": "Jingwei Zhuo, Chang Liu, Jiaxin Shi, Jun Zhu, Ning Chen, Bo Zhang",
        "author": "Jingwei Zhuo; Chang Liu; Jiaxin Shi; Jun Zhu; Ning Chen; Bo Zhang",
        "abstract": "Stein variational gradient descent (SVGD) is a recently proposed particle-based Bayesian inference method, which has attracted a lot of interest due to its remarkable approximation ability and particle efficiency compared to traditional variational inference and Markov Chain Monte Carlo methods. However, we observed that particles of SVGD tend to collapse to modes of the target distribution, and this particle degeneracy phenomenon becomes more severe with higher dimensions. Our theoretical analysis finds out that there exists a negative correlation between the dimensionality and the repulsive force of SVGD which should be blamed for this phenomenon. We propose Message Passing SVGD (MP-SVGD) to solve this problem. By leveraging the conditional independence structure of probabilistic graphical models (PGMs), MP-SVGD converts the original high-dimensional global inference problem into a set of local ones over the Markov blanket with lower dimensions. Experimental results show its advantages of preventing vanishing repulsive force in high-dimensional space over SVGD, and its particle efficiency and approximation flexibility over other inference methods on graphical models.",
        "bibtex": "@InProceedings{pmlr-v80-zhuo18a,\n  title = \t {Message Passing Stein Variational Gradient Descent},\n  author =       {Zhuo, Jingwei and Liu, Chang and Shi, Jiaxin and Zhu, Jun and Chen, Ning and Zhang, Bo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {6018--6027},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhuo18a/zhuo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhuo18a.html},\n  abstract = \t {Stein variational gradient descent (SVGD) is a recently proposed particle-based Bayesian inference method, which has attracted a lot of interest due to its remarkable approximation ability and particle efficiency compared to traditional variational inference and Markov Chain Monte Carlo methods. However, we observed that particles of SVGD tend to collapse to modes of the target distribution, and this particle degeneracy phenomenon becomes more severe with higher dimensions. Our theoretical analysis finds out that there exists a negative correlation between the dimensionality and the repulsive force of SVGD which should be blamed for this phenomenon. We propose Message Passing SVGD (MP-SVGD) to solve this problem. By leveraging the conditional independence structure of probabilistic graphical models (PGMs), MP-SVGD converts the original high-dimensional global inference problem into a set of local ones over the Markov blanket with lower dimensions. Experimental results show its advantages of preventing vanishing repulsive force in high-dimensional space over SVGD, and its particle efficiency and approximation flexibility over other inference methods on graphical models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhuo18a/zhuo18a.pdf",
        "supp": "",
        "pdf_size": 1698988,
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3984919858268334052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China",
        "aff_domain": "mails.tsinghua.edu.cn; ; ;tsinghua.edu.cn; ; ",
        "email": "mails.tsinghua.edu.cn; ; ;tsinghua.edu.cn; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/zhuo18a.html",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1976",
        "id": "1976",
        "author_site": "Ron Amit, Ron Meir",
        "author": "Ron Amit; Ron Meir",
        "abstract": "In meta-learning an agent extracts knowledge from observed tasks, aiming to facilitate learning of novel future tasks. Under the assumption that future tasks are \u2018related\u2019 to previous tasks, accumulated knowledge should be learned in such a way that they capture the common structure across learned tasks, while allowing the learner sufficient flexibility to adapt to novel aspects of a new task. We present a framework for meta-learning that is based on generalization error bounds, allowing us to extend various PAC-Bayes bounds to meta-learning. Learning takes place through the construction of a distribution over hypotheses based on the observed tasks, and its utilization for learning a new task. Thus, prior knowledge is incorporated through setting an experience-dependent prior for novel tasks. We develop a gradient-based algorithm, and implement it for deep neural networks, based on minimizing an objective function derived from the bounds, and demonstrate its effectiveness numerically. In addition to establishing the improved performance available through meta-learning, we demonstrate the intuitive way by which prior information is manifested at different levels of the network.",
        "bibtex": "@InProceedings{pmlr-v80-amit18a,\n  title = \t {Meta-Learning by Adjusting Priors Based on Extended {PAC}-{B}ayes Theory},\n  author =       {Amit, Ron and Meir, Ron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {205--214},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/amit18a/amit18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/amit18a.html},\n  abstract = \t {In meta-learning an agent extracts knowledge from observed tasks, aiming to facilitate learning of novel future tasks. Under the assumption that future tasks are \u2018related\u2019 to previous tasks, accumulated knowledge should be learned in such a way that they capture the common structure across learned tasks, while allowing the learner sufficient flexibility to adapt to novel aspects of a new task. We present a framework for meta-learning that is based on generalization error bounds, allowing us to extend various PAC-Bayes bounds to meta-learning. Learning takes place through the construction of a distribution over hypotheses based on the observed tasks, and its utilization for learning a new task. Thus, prior knowledge is incorporated through setting an experience-dependent prior for novel tasks. We develop a gradient-based algorithm, and implement it for deep neural networks, based on minimizing an objective function derived from the bounds, and demonstrate its effectiveness numerically. In addition to establishing the improved performance available through meta-learning, we demonstrate the intuitive way by which prior information is manifested at different levels of the network.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/amit18a/amit18a.pdf",
        "supp": "",
        "pdf_size": 2630059,
        "gs_citation": 227,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7282416635315381727&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "The Viterbi Faculty of Electrical Engineering, Technion - Israel Institute of Technology, Haifa, Israel; The Viterbi Faculty of Electrical Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "aff_domain": "campus.technion.ac.il;ee.technion.ac.il",
        "email": "campus.technion.ac.il;ee.technion.ac.il",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/amit18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Viterbi Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Minibatch Gibbs Sampling on Large Graphical Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2383",
        "id": "2383",
        "author_site": "Christopher De Sa, Vincent Chen,  Wong",
        "author": "Chris De Sa; Vincent Chen; Wing Wong",
        "abstract": "Gibbs sampling is the de facto Markov chain Monte Carlo method used for inference and learning on large scale graphical models. For complicated factor graphs with lots of factors, the performance of Gibbs sampling can be limited by the computational cost of executing a single update step of the Markov chain. This cost is proportional to the degree of the graph, the number of factors adjacent to each variable. In this paper, we show how this cost can be reduced by using minibatching: subsampling the factors to form an estimate of their sum. We introduce several minibatched variants of Gibbs, show that they can be made unbiased, prove bounds on their convergence rates, and show that under some conditions they can result in asymptotic single-update-run-time speedups over plain Gibbs sampling.",
        "bibtex": "@InProceedings{pmlr-v80-desa18a,\n  title = \t {Minibatch Gibbs Sampling on Large Graphical Models},\n  author =       {De Sa, Chris and Chen, Vincent and Wong, Wing},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1165--1173},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/desa18a/desa18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/desa18a.html},\n  abstract = \t {Gibbs sampling is the de facto Markov chain Monte Carlo method used for inference and learning on large scale graphical models. For complicated factor graphs with lots of factors, the performance of Gibbs sampling can be limited by the computational cost of executing a single update step of the Markov chain. This cost is proportional to the degree of the graph, the number of factors adjacent to each variable. In this paper, we show how this cost can be reduced by using minibatching: subsampling the factors to form an estimate of their sum. We introduce several minibatched variants of Gibbs, show that they can be made unbiased, prove bounds on their convergence rates, and show that under some conditions they can result in asymptotic single-update-run-time speedups over plain Gibbs sampling.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/desa18a/desa18a.pdf",
        "supp": "",
        "pdf_size": 621490,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12232491523014922763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Statistics, Stanford University, Stanford, CA, USA",
        "aff_domain": "cs.cornell.edu; ; ",
        "email": "cs.cornell.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/desa18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Cornell University;Stanford University",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics",
        "aff_unique_url": "https://www.cornell.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Cornell;Stanford",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Ithaca;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2472",
        "id": "2472",
        "author_site": "Raj Agrawal, Caroline Uhler, Tamara Broderick",
        "author": "Raj Agrawal; Caroline Uhler; Tamara Broderick",
        "abstract": "Learning a Bayesian network (BN) from data can be useful for decision-making or discovering causal relationships. However, traditional methods often fail in modern applications, which exhibit a larger number of observed variables than data points. The resulting uncertainty about the underlying network as well as the desire to incorporate prior information recommend a Bayesian approach to learning the BN, but the highly combinatorial structure of BNs poses a striking challenge for inference. The current state-of-the-art methods such as order MCMC are faster than previous methods but prevent the use of many natural structural priors and still have running time exponential in the maximum indegree of the true directed acyclic graph (DAG) of the BN. We here propose an alternative posterior approximation based on the observation that, if we incorporate empirical conditional independence tests, we can focus on a high-probability DAG associated with each order of the vertices. We show that our method allows the desired flexibility in prior specification, removes timing dependence on the maximum indegree, and yields provably good posterior approximations; in addition, we show that it achieves superior accuracy, scalability, and sampler mixing on several datasets.",
        "bibtex": "@InProceedings{pmlr-v80-agrawal18a,\n  title = \t {Minimal I-{MAP} {MCMC} for Scalable Structure Discovery in Causal {DAG} Models},\n  author =       {Agrawal, Raj and Uhler, Caroline and Broderick, Tamara},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {89--98},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/agrawal18a/agrawal18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/agrawal18a.html},\n  abstract = \t {Learning a Bayesian network (BN) from data can be useful for decision-making or discovering causal relationships. However, traditional methods often fail in modern applications, which exhibit a larger number of observed variables than data points. The resulting uncertainty about the underlying network as well as the desire to incorporate prior information recommend a Bayesian approach to learning the BN, but the highly combinatorial structure of BNs poses a striking challenge for inference. The current state-of-the-art methods such as order MCMC are faster than previous methods but prevent the use of many natural structural priors and still have running time exponential in the maximum indegree of the true directed acyclic graph (DAG) of the BN. We here propose an alternative posterior approximation based on the observation that, if we incorporate empirical conditional independence tests, we can focus on a high-probability DAG associated with each order of the vertices. We show that our method allows the desired flexibility in prior specification, removes timing dependence on the maximum indegree, and yields provably good posterior approximations; in addition, we show that it achieves superior accuracy, scalability, and sampler mixing on several datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/agrawal18a/agrawal18a.pdf",
        "supp": "",
        "pdf_size": 2145571,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17725312954086657022&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/agrawal18a.html"
    },
    {
        "title": "Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2469",
        "id": "2469",
        "author_site": "xue wang, Mingcheng Wei, Tao Yao",
        "author": "Xue Wang; Mingcheng Wei; Tao Yao",
        "abstract": "In this paper, we propose a Minimax Concave Penalized Multi-Armed Bandit (MCP-Bandit) algorithm for a decision-maker facing high-dimensional data with latent sparse structure in an online learning and decision-making process. We demonstrate that the MCP-Bandit algorithm asymptotically achieves the optimal cumulative regret in sample size T, O(log T), and further attains a tighter bound in both covariates dimension d and the number of significant covariates s, O(s^2 (s + log d). In addition, we develop a linear approximation method, the 2-step Weighted Lasso procedure, to identify the MCP estimator for the MCP-Bandit algorithm under non-i.i.d. samples. Using this procedure, the MCP estimator matches the oracle estimator with high probability. Finally, we present two experiments to benchmark our proposed the MCP-Bandit algorithm to other bandit algorithms. Both experiments demonstrate that the MCP-Bandit algorithm performs favorably over other benchmark algorithms, especially when there is a high level of data sparsity or when the sample size is not too small.",
        "bibtex": "@InProceedings{pmlr-v80-wang18j,\n  title = \t {Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates},\n  author =       {Wang, Xue and Wei, Mingcheng and Yao, Tao},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5200--5208},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18j/wang18j.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18j.html},\n  abstract = \t {In this paper, we propose a Minimax Concave Penalized Multi-Armed Bandit (MCP-Bandit) algorithm for a decision-maker facing high-dimensional data with latent sparse structure in an online learning and decision-making process. We demonstrate that the MCP-Bandit algorithm asymptotically achieves the optimal cumulative regret in sample size T, O(log T), and further attains a tighter bound in both covariates dimension d and the number of significant covariates s, O(s^2 (s + log d). In addition, we develop a linear approximation method, the 2-step Weighted Lasso procedure, to identify the MCP estimator for the MCP-Bandit algorithm under non-i.i.d. samples. Using this procedure, the MCP estimator matches the oracle estimator with high probability. Finally, we present two experiments to benchmark our proposed the MCP-Bandit algorithm to other bandit algorithms. Both experiments demonstrate that the MCP-Bandit algorithm performs favorably over other benchmark algorithms, especially when there is a high level of data sparsity or when the sample size is not too small.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18j/wang18j.pdf",
        "supp": "",
        "pdf_size": 843142,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6820020900132293936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Pennsylvania State University; University at Buffalo; Pennsylvania State University",
        "aff_domain": "psu.edu;buffalo.edu;psu.edu",
        "email": "psu.edu;buffalo.edu;psu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wang18j.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Pennsylvania State University;University at Buffalo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.psu.edu;https://www.buffalo.edu",
        "aff_unique_abbr": "PSU;UB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Mitigating Bias in Adaptive Data Gathering via Differential Privacy",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2339",
        "id": "2339",
        "author_site": "Seth Neel, Aaron Roth",
        "author": "Seth Neel; Aaron Roth",
        "abstract": "Data that is gathered adaptively \u2014 via bandit algorithms, for example \u2014 exhibits bias. This is true both when gathering simple numeric valued data \u2014 the empirical means kept track of by stochastic bandit algorithms are biased downwards \u2014 and when gathering more complicated data \u2014 running hypothesis tests on complex data gathered via contextual bandit algorithms leads to false discovery. In this paper, we show that this problem is mitigated if the data collection procedure is differentially private. This lets us both bound the bias of simple numeric valued quantities (like the empirical means of stochastic bandit algorithms), and correct the p-values of hypothesis tests run on the adaptively gathered data. Moreover, there exist differentially private bandit algorithms with near optimal regret bounds: we apply existing theorems in the simple stochastic case, and give a new analysis for linear contextual bandits. We complement our theoretical results with experiments validating our theory.",
        "bibtex": "@InProceedings{pmlr-v80-neel18a,\n  title = \t {Mitigating Bias in Adaptive Data Gathering via Differential Privacy},\n  author =       {Neel, Seth and Roth, Aaron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3720--3729},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/neel18a/neel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/neel18a.html},\n  abstract = \t {Data that is gathered adaptively \u2014 via bandit algorithms, for example \u2014 exhibits bias. This is true both when gathering simple numeric valued data \u2014 the empirical means kept track of by stochastic bandit algorithms are biased downwards \u2014 and when gathering more complicated data \u2014 running hypothesis tests on complex data gathered via contextual bandit algorithms leads to false discovery. In this paper, we show that this problem is mitigated if the data collection procedure is differentially private. This lets us both bound the bias of simple numeric valued quantities (like the empirical means of stochastic bandit algorithms), and correct the p-values of hypothesis tests run on the adaptively gathered data. Moreover, there exist differentially private bandit algorithms with near optimal regret bounds: we apply existing theorems in the simple stochastic case, and give a new analysis for linear contextual bandits. We complement our theoretical results with experiments validating our theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/neel18a/neel18a.pdf",
        "supp": "",
        "pdf_size": 436157,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7110568990558719455&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, The Wharton School, University of Pennsylvania; Department of Computer Science, University of Pennsylvania",
        "aff_domain": "gmail.com;cis.upenn.edu",
        "email": "gmail.com;cis.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/neel18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Mix & Match Agent Curricula for Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2187",
        "id": "2187",
        "author_site": "Wojciech Czarnecki, Siddhant Jayakumar, Max Jaderberg, Leonard Hasenclever, Yee Teh, Nicolas Heess, Simon Osindero, Razvan Pascanu",
        "author": "Wojciech Czarnecki; Siddhant Jayakumar; Max Jaderberg; Leonard Hasenclever; Yee Whye Teh; Nicolas Heess; Simon Osindero; Razvan Pascanu",
        "abstract": "We introduce Mix and match (M&M) \u2013 a training framework designed to facilitate rapid and effective learning in RL agents that would be too slow or too challenging to train otherwise.The key innovation is a procedure that allows us to automatically form a curriculum over agents. Through such a curriculum we can progressively train more complex agents by, effectively, bootstrapping from solutions found by simpler agents.In contradistinction to typical curriculum learning approaches, we do not gradually modify the tasks or environments presented, but instead use a process to gradually alter how the policy is represented internally.We show the broad applicability of our method by demonstrating significant performance gains in three different experimental setups: (1) We train an agent able to control more than 700 actions in a challenging 3D first-person task; using our method to progress through an action-space curriculum we achieve both faster training and better final performance than one obtains using traditional methods.(2) We further show that M&M can be used successfully to progress through a curriculum of architectural variants defining an agents internal state. (3) Finally, we illustrate how a variant of our method can be used to improve agent performance in a multitask setting.",
        "bibtex": "@InProceedings{pmlr-v80-czarnecki18a,\n  title = \t {Mix & Match Agent Curricula for Reinforcement Learning},\n  author =       {Czarnecki, Wojciech and Jayakumar, Siddhant and Jaderberg, Max and Hasenclever, Leonard and Teh, Yee Whye and Heess, Nicolas and Osindero, Simon and Pascanu, Razvan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1087--1095},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/czarnecki18a/czarnecki18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/czarnecki18a.html},\n  abstract = \t {We introduce Mix and match (M&M) \u2013 a training framework designed to facilitate rapid and effective learning in RL agents that would be too slow or too challenging to train otherwise.The key innovation is a procedure that allows us to automatically form a curriculum over agents. Through such a curriculum we can progressively train more complex agents by, effectively, bootstrapping from solutions found by simpler agents.In contradistinction to typical curriculum learning approaches, we do not gradually modify the tasks or environments presented, but instead use a process to gradually alter how the policy is represented internally.We show the broad applicability of our method by demonstrating significant performance gains in three different experimental setups: (1) We train an agent able to control more than 700 actions in a challenging 3D first-person task; using our method to progress through an action-space curriculum we achieve both faster training and better final performance than one obtains using traditional methods.(2) We further show that M&M can be used successfully to progress through a curriculum of architectural variants defining an agents internal state. (3) Finally, we illustrate how a variant of our method can be used to improve agent performance in a multitask setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/czarnecki18a/czarnecki18a.pdf",
        "supp": "",
        "pdf_size": 1875619,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14134731477361377932&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "google.com;google.com; ; ; ; ; ; ",
        "email": "google.com;google.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/czarnecki18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Mixed batches and symmetric discriminators for GAN training",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2234",
        "id": "2234",
        "author_site": "Thomas LUCAS, Corentin Tallec, Yann Ollivier, Jakob Verbeek",
        "author": "Thomas LUCAS; Corentin Tallec; Yann Ollivier; Jakob Verbeek",
        "abstract": "Generative adversarial networks (GANs) are pow- erful generative models based on providing feed- back to a generative network via a discriminator network. However, the discriminator usually as- sesses individual samples. This prevents the dis- criminator from accessing global distributional statistics of generated samples, and often leads to mode dropping: the generator models only part of the target distribution. We propose to feed the discriminator with mixed batches of true and fake samples, and train it to predict the ratio of true samples in the batch. The latter score does not depend on the order of samples in a batch. Rather than learning this invariance, we introduce a generic permutation-invariant discriminator ar- chitecture. This architecture is provably a uni- versal approximator of all symmetric functions. Experimentally, our approach reduces mode col- lapse in GANs on two synthetic datasets, and obtains good results on the CIFAR10 and CelebA datasets, both qualitatively and quantitatively.",
        "bibtex": "@InProceedings{pmlr-v80-lucas18a,\n  title = \t {Mixed batches and symmetric discriminators for {GAN} training},\n  author =       {LUCAS, Thomas and Tallec, Corentin and Ollivier, Yann and Verbeek, Jakob},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2844--2853},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lucas18a/lucas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lucas18a.html},\n  abstract = \t {Generative adversarial networks (GANs) are pow- erful generative models based on providing feed- back to a generative network via a discriminator network. However, the discriminator usually as- sesses individual samples. This prevents the dis- criminator from accessing global distributional statistics of generated samples, and often leads to mode dropping: the generator models only part of the target distribution. We propose to feed the discriminator with mixed batches of true and fake samples, and train it to predict the ratio of true samples in the batch. The latter score does not depend on the order of samples in a batch. Rather than learning this invariance, we introduce a generic permutation-invariant discriminator ar- chitecture. This architecture is provably a uni- versal approximator of all symmetric functions. Experimentally, our approach reduces mode col- lapse in GANs on two synthetic datasets, and obtains good results on the CIFAR10 and CelebA datasets, both qualitatively and quantitatively.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lucas18a/lucas18a.pdf",
        "supp": "",
        "pdf_size": 4008939,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8351590937268780197&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Universit \u00b4e Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France; Universit \u00b4e Paris Sud, INRIA, \u00b4equipe TAU, Gif-sur-Yvette, 91190, France; Universit \u00b4e Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France; Facebook Arti\ufb01cial Intelligence Research Paris, France",
        "aff_domain": "inria.fr;inria.fr; ; ",
        "email": "inria.fr;inria.fr; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/lucas18a.html",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Universit\u00e9 Grenoble Alpes;Universit\u00e9 Paris Sud;Meta",
        "aff_unique_dep": ";INRIA, \u00e9quipe TAU;Artificial Intelligence Research",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://www.universite-paris-sud.fr;https://research.facebook.com",
        "aff_unique_abbr": "UGA;UPS;FAIR",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Grenoble;Gif-sur-Yvette;Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Model-Level Dual Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2172",
        "id": "2172",
        "author_site": "Yingce Xia, Xu Tan, Fei Tian, Tao Qin, Nenghai Yu, Tie-Yan Liu",
        "author": "Yingce Xia; Xu Tan; Fei Tian; Tao Qin; Nenghai Yu; Tie-Yan Liu",
        "abstract": "Many artificial intelligence tasks appear in dual forms like English$\\leftrightarrow$French translation and speech$\\leftrightarrow$text transformation. Existing dual learning schemes, which are proposed to solve a pair of such dual tasks, explore how to leverage such dualities from data level. In this work, we propose a new learning framework, model-level dual learning, which takes duality of tasks into consideration while designing the architectures for the primal/dual models, and ties the model parameters that playing similar roles in the two tasks. We study both symmetric and asymmetric model-level dual learning. Our algorithms achieve significant improvements on neural machine translation and sentiment analysis.",
        "bibtex": "@InProceedings{pmlr-v80-xia18a,\n  title = \t {Model-Level Dual Learning},\n  author =       {Xia, Yingce and Tan, Xu and Tian, Fei and Qin, Tao and Yu, Nenghai and Liu, Tie-Yan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5383--5392},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xia18a/xia18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xia18a.html},\n  abstract = \t {Many artificial intelligence tasks appear in dual forms like English$\\leftrightarrow$French translation and speech$\\leftrightarrow$text transformation. Existing dual learning schemes, which are proposed to solve a pair of such dual tasks, explore how to leverage such dualities from data level. In this work, we propose a new learning framework, model-level dual learning, which takes duality of tasks into consideration while designing the architectures for the primal/dual models, and ties the model parameters that playing similar roles in the two tasks. We study both symmetric and asymmetric model-level dual learning. Our algorithms achieve significant improvements on neural machine translation and sentiment analysis.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xia18a/xia18a.pdf",
        "supp": "",
        "pdf_size": 518317,
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7901523809540914624&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Information Science and Technology, University of Science and Technology of China, Hefei, China+Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Microsoft Research, Beijing, China",
        "aff_domain": "ustc.edu.cn;microsoft.com;microsoft.com;microsoft.com;ustc.edu.cn;microsoft.com",
        "email": "ustc.edu.cn;microsoft.com;microsoft.com;microsoft.com;ustc.edu.cn;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/xia18a.html",
        "aff_unique_index": "0+1;1;1;1;0;1",
        "aff_unique_norm": "University of Science and Technology of China;Microsoft",
        "aff_unique_dep": "School of Information Science and Technology;Microsoft Research",
        "aff_unique_url": "http://www.ustc.edu.cn;https://www.microsoft.com/en-us/research/group/microsoft-research-asia",
        "aff_unique_abbr": "USTC;MSR",
        "aff_campus_unique_index": "0+1;1;1;1;0;1",
        "aff_campus_unique": "Hefei;Beijing",
        "aff_country_unique_index": "0+0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Modeling Others using Oneself in Multi-Agent Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2319",
        "id": "2319",
        "author_site": "Roberta Raileanu, Emily Denton, Arthur Szlam, Facebook Rob Fergus",
        "author": "Roberta Raileanu; Emily Denton; Arthur Szlam; Rob Fergus",
        "abstract": "We consider the multi-agent reinforcement learning setting with imperfect information. The reward function depends on the hidden goals of both agents, so the agents must infer the other players\u2019 goals from their observed behavior in order to maximize their returns. We propose a new approach for learning in these domains: Self Other-Modeling (SOM), in which an agent uses its own policy to predict the other agent\u2019s actions and update its belief of their hidden goal in an online manner. We evaluate this approach on three different tasks and show that the agents are able to learn better policies using their estimate of the other players\u2019 goals, in both cooperative and competitive settings.",
        "bibtex": "@InProceedings{pmlr-v80-raileanu18a,\n  title = \t {Modeling Others using Oneself in Multi-Agent Reinforcement Learning},\n  author =       {Raileanu, Roberta and Denton, Emily and Szlam, Arthur and Fergus, Rob},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4257--4266},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/raileanu18a/raileanu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/raileanu18a.html},\n  abstract = \t {We consider the multi-agent reinforcement learning setting with imperfect information. The reward function depends on the hidden goals of both agents, so the agents must infer the other players\u2019 goals from their observed behavior in order to maximize their returns. We propose a new approach for learning in these domains: Self Other-Modeling (SOM), in which an agent uses its own policy to predict the other agent\u2019s actions and update its belief of their hidden goal in an online manner. We evaluate this approach on three different tasks and show that the agents are able to learn better policies using their estimate of the other players\u2019 goals, in both cooperative and competitive settings.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/raileanu18a/raileanu18a.pdf",
        "supp": "",
        "pdf_size": 878240,
        "gs_citation": 264,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18366591039277738503&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "New York University; New York University; Facebook AI Research; New York University + Facebook AI Research",
        "aff_domain": "cs.nyu.edu; ; ; ",
        "email": "cs.nyu.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/raileanu18a.html",
        "aff_unique_index": "0;0;1;0+1",
        "aff_unique_norm": "New York University;Meta",
        "aff_unique_dep": ";Facebook AI Research",
        "aff_unique_url": "https://www.nyu.edu;https://research.facebook.com",
        "aff_unique_abbr": "NYU;FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Modeling Sparse Deviations for Compressed Sensing using Generative Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2331",
        "id": "2331",
        "author_site": "Manik Dhar, Aditya Grover, Stefano Ermon",
        "author": "Manik Dhar; Aditya Grover; Stefano Ermon",
        "abstract": "In compressed sensing, a small number of linear measurements can be used to reconstruct an unknown signal. Existing approaches leverage assumptions on the structure of these signals, such as sparsity or the availability of a generative model. A domain-specific generative model can provide a stronger prior and thus allow for recovery with far fewer measurements. However, unlike sparsity-based approaches, existing methods based on generative models guarantee exact recovery only over their support, which is typically only a small subset of the space on which the signals are defined. We propose Sparse-Gen, a framework that allows for sparse deviations from the support set, thereby achieving the best of both worlds by using a domain specific prior and allowing reconstruction over the full space of signals. Theoretically, our framework provides a new class of signals that can be acquired using compressed sensing, reducing classic sparse vector recovery to a special case and avoiding the restrictive support due to a generative model prior. Empirically, we observe consistent improvements in reconstruction accuracy over competing approaches, especially in the more practical setting of transfer compressed sensing where a generative model for a data-rich, source domain aids sensing on a data-scarce, target domain.",
        "bibtex": "@InProceedings{pmlr-v80-dhar18a,\n  title = \t {Modeling Sparse Deviations for Compressed Sensing using Generative Models},\n  author =       {Dhar, Manik and Grover, Aditya and Ermon, Stefano},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1214--1223},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dhar18a/dhar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dhar18a.html},\n  abstract = \t {In compressed sensing, a small number of linear measurements can be used to reconstruct an unknown signal. Existing approaches leverage assumptions on the structure of these signals, such as sparsity or the availability of a generative model. A domain-specific generative model can provide a stronger prior and thus allow for recovery with far fewer measurements. However, unlike sparsity-based approaches, existing methods based on generative models guarantee exact recovery only over their support, which is typically only a small subset of the space on which the signals are defined. We propose Sparse-Gen, a framework that allows for sparse deviations from the support set, thereby achieving the best of both worlds by using a domain specific prior and allowing reconstruction over the full space of signals. Theoretically, our framework provides a new class of signals that can be acquired using compressed sensing, reducing classic sparse vector recovery to a special case and avoiding the restrictive support due to a generative model prior. Empirically, we observe consistent improvements in reconstruction accuracy over competing approaches, especially in the more practical setting of transfer compressed sensing where a generative model for a data-rich, source domain aids sensing on a data-scarce, target domain.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dhar18a/dhar18a.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=179324557679605519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/dhar18a.html"
    },
    {
        "title": "More Robust Doubly Robust Off-policy Evaluation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2068",
        "id": "2068",
        "author_site": "Mehrdad Farajtabar, Yinlam Chow, Mohammad Ghavamzadeh",
        "author": "Mehrdad Farajtabar; Yinlam Chow; Mohammad Ghavamzadeh",
        "abstract": "We study the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of a policy from the data generated by another policy(ies). In particular, we focus on the doubly robust (DR) estimators that consist of an importance sampling (IS) component and a performance model, and utilize the low (or zero) bias of IS and low variance of the model at the same time. Although the accuracy of the model has a huge impact on the overall performance of DR, most of the work on using the DR estimators in OPE has been focused on improving the IS part, and not much on how to learn the model. In this paper, we propose alternative DR estimators, called more robust doubly robust (MRDR), that learn the model parameter by minimizing the variance of the DR estimator. We first present a formulation for learning the DR model in RL. We then derive formulas for the variance of the DR estimator in both contextual bandits and RL, such that their gradients w.r.t. the model parameters can be estimated from the samples, and propose methods to efficiently minimize the variance. We prove that the MRDR estimators are strongly consistent and asymptotically optimal. Finally, we evaluate MRDR in bandits and RL benchmark problems, and compare its performance with the existing methods.",
        "bibtex": "@InProceedings{pmlr-v80-farajtabar18a,\n  title = \t {More Robust Doubly Robust Off-policy Evaluation},\n  author =       {Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1447--1456},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/farajtabar18a/farajtabar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/farajtabar18a.html},\n  abstract = \t {We study the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of a policy from the data generated by another policy(ies). In particular, we focus on the doubly robust (DR) estimators that consist of an importance sampling (IS) component and a performance model, and utilize the low (or zero) bias of IS and low variance of the model at the same time. Although the accuracy of the model has a huge impact on the overall performance of DR, most of the work on using the DR estimators in OPE has been focused on improving the IS part, and not much on how to learn the model. In this paper, we propose alternative DR estimators, called more robust doubly robust (MRDR), that learn the model parameter by minimizing the variance of the DR estimator. We first present a formulation for learning the DR model in RL. We then derive formulas for the variance of the DR estimator in both contextual bandits and RL, such that their gradients w.r.t. the model parameters can be estimated from the samples, and propose methods to efficiently minimize the variance. We prove that the MRDR estimators are strongly consistent and asymptotically optimal. Finally, we evaluate MRDR in bandits and RL benchmark problems, and compare its performance with the existing methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/farajtabar18a/farajtabar18a.pdf",
        "supp": "",
        "pdf_size": 1064500,
        "gs_citation": 308,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16469362534120978273&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Georgia Tech; DeepMind; DeepMind",
        "aff_domain": " gatech.edu;google.com; google.com",
        "email": " gatech.edu;google.com; google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/farajtabar18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Georgia Institute of Technology;DeepMind",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://deepmind.com",
        "aff_unique_abbr": "Georgia Tech;DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Multi-Fidelity Black-Box Optimization with Hierarchical Partitions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2264",
        "id": "2264",
        "author_site": "Rajat Sen, kirthevasan kandasamy, Sanjay Shakkottai",
        "author": "Rajat Sen; Kirthevasan Kandasamy; Sanjay Shakkottai",
        "abstract": "Motivated by settings such as hyper-parameter tuning and physical simulations, we consider the problem of black-box optimization of a function. Multi-fidelity techniques have become popular for applications where exact function evaluations are expensive, but coarse (biased) approximations are available at much lower cost. A canonical example is that of hyper-parameter selection in a learning algorithm. The learning algorithm can be trained for fewer iterations \u2013 this results in a lower cost, but its validation error is only coarsely indicative of the same if the algorithm had been trained till completion. We incorporate the multi-fidelity setup into the powerful framework of black-box optimization through hierarchical partitioning. We develop tree-search based multi-fidelity algorithms with theoretical guarantees on simple regret. We finally demonstrate the performance gains of our algorithms on both real and synthetic datasets.",
        "bibtex": "@InProceedings{pmlr-v80-sen18a,\n  title = \t {Multi-Fidelity Black-Box Optimization with Hierarchical Partitions},\n  author =       {Sen, Rajat and Kandasamy, Kirthevasan and Shakkottai, Sanjay},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4538--4547},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sen18a/sen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sen18a.html},\n  abstract = \t {Motivated by settings such as hyper-parameter tuning and physical simulations, we consider the problem of black-box optimization of a function. Multi-fidelity techniques have become popular for applications where exact function evaluations are expensive, but coarse (biased) approximations are available at much lower cost. A canonical example is that of hyper-parameter selection in a learning algorithm. The learning algorithm can be trained for fewer iterations \u2013 this results in a lower cost, but its validation error is only coarsely indicative of the same if the algorithm had been trained till completion. We incorporate the multi-fidelity setup into the powerful framework of black-box optimization through hierarchical partitioning. We develop tree-search based multi-fidelity algorithms with theoretical guarantees on simple regret. We finally demonstrate the performance gains of our algorithms on both real and synthetic datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sen18a/sen18a.pdf",
        "supp": "",
        "pdf_size": 703483,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11658829516940727340&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Texas at Austin; Carnegie Mellon University; University of Texas at Austin",
        "aff_domain": "utexas.edu; ; ",
        "email": "utexas.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/sen18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Austin;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UT Austin;CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Multicalibration: Calibration for the (Computationally-Identifiable) Masses",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2448",
        "id": "2448",
        "author_site": "Ursula Hebert-Johnson, Michael Kim, Omer Reingold, Guy Rothblum",
        "author": "Ursula Hebert-Johnson; Michael Kim; Omer Reingold; Guy Rothblum",
        "abstract": "We develop and study multicalibration as a new measure of fairness in machine learning that aims to mitigate inadvertent or malicious discrimination that is introduced at training time (even from ground truth data). Multicalibration guarantees meaningful (calibrated) predictions for every subpopulation that can be identified within a specified class of computations. The specified class can be quite rich; in particular, it can contain many overlapping subgroups of a protected group. We demonstrate that in many settings this strong notion of protection from discrimination is provably attainable and aligned with the goal of obtaining accurate predictions. Along the way, we present algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and illustrate tight connections to the agnostic learning model.",
        "bibtex": "@InProceedings{pmlr-v80-hebert-johnson18a,\n  title = \t {Multicalibration: Calibration for the ({C}omputationally-Identifiable) Masses},\n  author =       {Hebert-Johnson, Ursula and Kim, Michael and Reingold, Omer and Rothblum, Guy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1939--1948},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hebert-johnson18a/hebert-johnson18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hebert-johnson18a.html},\n  abstract = \t {We develop and study multicalibration as a new measure of fairness in machine learning that aims to mitigate inadvertent or malicious discrimination that is introduced at training time (even from ground truth data). Multicalibration guarantees meaningful (calibrated) predictions for every subpopulation that can be identified within a specified class of computations. The specified class can be quite rich; in particular, it can contain many overlapping subgroups of a protected group. We demonstrate that in many settings this strong notion of protection from discrimination is provably attainable and aligned with the goal of obtaining accurate predictions. Along the way, we present algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and illustrate tight connections to the agnostic learning model.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hebert-johnson18a/hebert-johnson18a.pdf",
        "supp": "",
        "pdf_size": 257772,
        "gs_citation": 564,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=758240470582756958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Computer Science Department, Stanford University, Stanford, CA; Computer Science Department, Stanford University, Stanford, CA; Computer Science Department, Stanford University, Stanford, CA; Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel",
        "aff_domain": "cs.stanford.edu; ; ; ",
        "email": "cs.stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/hebert-johnson18a.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Stanford University;Weizmann Institute of Science",
        "aff_unique_dep": "Computer Science Department;Department of Computer Science and Applied Mathematics",
        "aff_unique_url": "https://www.stanford.edu;https://www.weizmann.ac.il",
        "aff_unique_abbr": "Stanford;Weizmann",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Stanford;Rehovot",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Mutual Information Neural Estimation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2440",
        "id": "2440",
        "author_site": "Mohamed Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, R Devon Hjelm, Aaron Courville",
        "author": "Mohamed Ishmael Belghazi; Aristide Baratin; Sai Rajeshwar; Sherjil Ozair; Yoshua Bengio; Aaron Courville; Devon Hjelm",
        "abstract": "We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement the Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.",
        "bibtex": "@InProceedings{pmlr-v80-belghazi18a,\n  title = \t {Mutual Information Neural Estimation},\n  author =       {Belghazi, Mohamed Ishmael and Baratin, Aristide and Rajeshwar, Sai and Ozair, Sherjil and Bengio, Yoshua and Courville, Aaron and Hjelm, Devon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {531--540},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/belghazi18a/belghazi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/belghazi18a.html},\n  abstract = \t {We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement the Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/belghazi18a/belghazi18a.pdf",
        "supp": "",
        "pdf_size": 1431105,
        "gs_citation": 1758,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16497997789447227818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO); Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Department of Mathematics and Statistics, McGill University+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO); Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO); Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO); Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO); Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO); Montr \u00b4eal Institute for Learning Algorithms (MILA), University of Montr \u00b4eal+Canadian Institute for Advanced Research (CIFAR)+The Institute for Data Valorization (IV ADO)",
        "aff_domain": "gmail.com; ; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/belghazi18a.html",
        "aff_unique_index": "0+1+2;0+3+1+2;0+1+2;0+1+2;0+1+2;0+1+2;0+1+2",
        "aff_unique_norm": "University of Montr\u00e9al;Canadian Institute for Advanced Research;Institute for Data Valorization;McGill University",
        "aff_unique_dep": "Montr\u00e9al Institute for Learning Algorithms (MILA);;;Department of Mathematics and Statistics",
        "aff_unique_url": "https://www.mila.quebec;https://www.cifar.ca;https://www.ivedo.ca;https://www.mcgill.ca",
        "aff_unique_abbr": "MILA;CIFAR;IV ADO;McGill",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Montr\u00e9al;",
        "aff_country_unique_index": "0+0+0;0+0+0+0;0+0+0;0+0+0;0+0+0;0+0+0;0+0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Near Optimal Frequent Directions for Sketching Dense and Sparse Matrices",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2125",
        "id": "2125",
        "author": "Zengfeng Huang",
        "abstract": "Given a large matrix $A\\in\\real^{n\\times d}$, we consider the problem of computing a sketch matrix $B\\in\\real^{\\ell\\times d}$ which is significantly smaller than but still well approximates $A$. We are interested in minimizing the",
        "bibtex": "@InProceedings{pmlr-v80-huang18a,\n  title = \t {Near Optimal Frequent Directions for Sketching Dense and Sparse Matrices},\n  author =       {Huang, Zengfeng},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2048--2057},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/huang18a/huang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/huang18a.html},\n  abstract = \t {Given a large matrix $A\\in\\real^{n\\times d}$, we consider the problem of computing a sketch matrix $B\\in\\real^{\\ell\\times d}$ which is significantly smaller than but still well approximates $A$. We are interested in minimizing the",
        "pdf": "http://proceedings.mlr.press/v80/huang18a/huang18a.pdf",
        "supp": "",
        "pdf_size": 324635,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3070428133208651207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Data Science, Fudan University, China",
        "aff_domain": "fudan.edu.cn",
        "email": "fudan.edu.cn",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/huang18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Fudan University",
        "aff_unique_dep": "School of Data Science",
        "aff_unique_url": "https://www.fudan.edu.cn",
        "aff_unique_abbr": "Fudan",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "title": "Nearly Optimal Robust Subspace Tracking",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2285",
        "id": "2285",
        "author_site": "Praneeth Narayanamurthy, Namrata Vaswani",
        "author": "Praneeth Narayanamurthy; Namrata Vaswani",
        "abstract": "Robust subspace tracking (RST) can be simply understood as a dynamic (time-varying) extension of robust PCA. More precisely, it is the problem of tracking data lying in a fixed or slowly-changing low-dimensional subspace while being robust to sparse outliers. This work develops a recursive projected compressive sensing algorithm called \u201cNearly Optimal RST (NORST)\u201d, and obtains one of the first guarantees for it. We show that NORST provably solves RST under weakened standard RPCA assumptions, slow subspace change, and a lower bound on (most) outlier magnitudes. Our guarantee shows that (i) NORST is online (after initialization) and enjoys near-optimal values of tracking delay, lower bound on required delay between subspace change times, and of memory complexity; and (ii) it has a significantly improved worst-case outlier tolerance compared with all previous robust PCA or RST methods without requiring any model on how the outlier support is generated.",
        "bibtex": "@InProceedings{pmlr-v80-narayanamurthy18a,\n  title = \t {Nearly Optimal Robust Subspace Tracking},\n  author =       {Narayanamurthy, Praneeth and Vaswani, Namrata},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3701--3709},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/narayanamurthy18a/narayanamurthy18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/narayanamurthy18a.html},\n  abstract = \t {Robust subspace tracking (RST) can be simply understood as a dynamic (time-varying) extension of robust PCA. More precisely, it is the problem of tracking data lying in a fixed or slowly-changing low-dimensional subspace while being robust to sparse outliers. This work develops a recursive projected compressive sensing algorithm called \u201cNearly Optimal RST (NORST)\u201d, and obtains one of the first guarantees for it. We show that NORST provably solves RST under weakened standard RPCA assumptions, slow subspace change, and a lower bound on (most) outlier magnitudes. Our guarantee shows that (i) NORST is online (after initialization) and enjoys near-optimal values of tracking delay, lower bound on required delay between subspace change times, and of memory complexity; and (ii) it has a significantly improved worst-case outlier tolerance compared with all previous robust PCA or RST methods without requiring any model on how the outlier support is generated.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/narayanamurthy18a/narayanamurthy18a.pdf",
        "supp": "",
        "pdf_size": 660612,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11197141106222317789&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical and Computer Engineering, Iowa State University, USA; Department of Electrical and Computer Engineering, Iowa State University, USA",
        "aff_domain": "iastate.edu;iastate.edu",
        "email": "iastate.edu;iastate.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/narayanamurthy18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "NetGAN: Generating Graphs via Random Walks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2193",
        "id": "2193",
        "author_site": "Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z\u00fcgner, Stephan G\u00fcnnemann",
        "author": "Aleksandar Bojchevski; Oleksandr Shchur; Daniel Z\u00fcgner; Stephan G\u00fcnnemann",
        "abstract": "We propose NetGAN - the first implicit generative model for graphs able to mimic real-world networks. We pose the problem of graph generation as learning the distribution of biased random walks over the input graph. The proposed model is based on a stochastic neural network that generates discrete output samples and is trained using the Wasserstein GAN objective. NetGAN is able to produce graphs that exhibit well-known network patterns without explicitly specifying them in the model definition. At the same time, our model exhibits strong generalization properties, as highlighted by its competitive link prediction performance, despite not being trained specifically for this task. Being the first approach to combine both of these desirable properties, NetGAN opens exciting avenues for further research.",
        "bibtex": "@InProceedings{pmlr-v80-bojchevski18a,\n  title = \t {{N}et{GAN}: Generating Graphs via Random Walks},\n  author =       {Bojchevski, Aleksandar and Shchur, Oleksandr and Z{\\\"u}gner, Daniel and G{\\\"u}nnemann, Stephan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {610--619},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bojchevski18a/bojchevski18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bojchevski18a.html},\n  abstract = \t {We propose NetGAN - the first implicit generative model for graphs able to mimic real-world networks. We pose the problem of graph generation as learning the distribution of biased random walks over the input graph. The proposed model is based on a stochastic neural network that generates discrete output samples and is trained using the Wasserstein GAN objective. NetGAN is able to produce graphs that exhibit well-known network patterns without explicitly specifying them in the model definition. At the same time, our model exhibits strong generalization properties, as highlighted by its competitive link prediction performance, despite not being trained specifically for this task. Being the first approach to combine both of these desirable properties, NetGAN opens exciting avenues for further research.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bojchevski18a/bojchevski18a.pdf",
        "supp": "",
        "pdf_size": 909033,
        "gs_citation": 505,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14864177647161830102&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich",
        "aff_domain": "in.tum.de; ; ; ",
        "email": "in.tum.de; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/bojchevski18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Network Global Testing by Counting Graphlets",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2338",
        "id": "2338",
        "author_site": "Jiashun Jin, Zheng Ke, Shengming Luo",
        "author": "Jiashun Jin; Zheng Ke; Shengming Luo",
        "abstract": "Consider a large social network with possibly severe degree heterogeneity and mixed-memberships. We are interested in testing whether the network has only one community or there are more than one communities. The problem is known to be non-trivial, partially due to the presence of severe degree heterogeneity. We construct a class of test statistics using the numbers of short paths and short cycles, and the key to our approach is a general framework for canceling the effects of degree heterogeneity. The tests compare favorably with existing methods. We support our methods with careful analysis and numerical study with simulated data and a real data example.",
        "bibtex": "@InProceedings{pmlr-v80-jin18b,\n  title = \t {Network Global Testing by Counting Graphlets},\n  author =       {Jin, Jiashun and Ke, Zheng and Luo, Shengming},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2333--2341},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jin18b/jin18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jin18b.html},\n  abstract = \t {Consider a large social network with possibly severe degree heterogeneity and mixed-memberships. We are interested in testing whether the network has only one community or there are more than one communities. The problem is known to be non-trivial, partially due to the presence of severe degree heterogeneity. We construct a class of test statistics using the numbers of short paths and short cycles, and the key to our approach is a general framework for canceling the effects of degree heterogeneity. The tests compare favorably with existing methods. We support our methods with careful analysis and numerical study with simulated data and a real data example.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jin18b/jin18b.pdf",
        "supp": "",
        "pdf_size": 471538,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12056991248462234640&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, USA+*; Department of Statistics, University of Chicago, Chicago, USA; Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, USA",
        "aff_domain": "stat.cmu.edu; ; ",
        "email": "stat.cmu.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jin18b.html",
        "aff_unique_index": "0;2;0",
        "aff_unique_norm": "Carnegie Mellon University;;University of Chicago",
        "aff_unique_dep": "Department of Statistics and Data Science;;Department of Statistics",
        "aff_unique_url": "https://www.cmu.edu;;https://www.uchicago.edu",
        "aff_unique_abbr": "CMU;;UChicago",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Pittsburgh;;Chicago",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "title": "Neural Autoregressive Flows",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2394",
        "id": "2394",
        "author_site": "Chin-Wei Huang, David Krueger, Alexandre Lacoste, Aaron Courville",
        "author": "Chin-Wei Huang; David Krueger; Alexandre Lacoste; Aaron Courville",
        "abstract": "Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows (MAF) (Papamakarios et al., 2017), and to accelerate state-of-the-art WaveNet-based speech synthesis to 20x faster than real-time (Oord et al., 2017), via Inverse Autoregressive Flows (IAF) (Kingma et al., 2016). We unify and generalize these approaches, replacing the (conditionally) affine univariate transformations of MAF/IAF with a more general class of invertible univariate transformations expressed as monotonic neural networks. We demonstrate that the proposed neural autoregressive flows (NAF) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions. Experimentally, NAF yields state-of-the-art performance on a suite of density estimation tasks and outperforms IAF in variational autoencoders trained on binarized MNIST.",
        "bibtex": "@InProceedings{pmlr-v80-huang18d,\n  title = \t {Neural Autoregressive Flows},\n  author =       {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2078--2087},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/huang18d/huang18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/huang18d.html},\n  abstract = \t {Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows (MAF) (Papamakarios et al., 2017), and to accelerate state-of-the-art WaveNet-based speech synthesis to 20x faster than real-time (Oord et al., 2017), via Inverse Autoregressive Flows (IAF) (Kingma et al., 2016). We unify and generalize these approaches, replacing the (conditionally) affine univariate transformations of MAF/IAF with a more general class of invertible univariate transformations expressed as monotonic neural networks. We demonstrate that the proposed neural autoregressive flows (NAF) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions. Experimentally, NAF yields state-of-the-art performance on a suite of density estimation tasks and outperforms IAF in variational autoencoders trained on binarized MNIST.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/huang18d/huang18d.pdf",
        "supp": "",
        "pdf_size": 1478226,
        "gs_citation": 588,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12117495056265504475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "MILA, University of Montreal+Element AI+CIFAR fellow; MILA, University of Montreal+Element AI+CIFAR fellow; Element AI; MILA, University of Montreal+CIFAR fellow",
        "aff_domain": "umontreal.ca; ; ; ",
        "email": "umontreal.ca; ; ; ",
        "github": "https://github.com/CW-Huang/NAF",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/huang18d.html",
        "aff_unique_index": "0+1+2;0+1+2;1;0+2",
        "aff_unique_norm": "University of Montreal;Element AI;Canadian Institute for Advanced Research",
        "aff_unique_dep": "MILA;;",
        "aff_unique_url": "https://www.mila.quebec;https://www.elementai.com;https://www.cifar.ca",
        "aff_unique_abbr": "MILA;Element AI;CIFAR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montreal;",
        "aff_country_unique_index": "0+0+0;0+0+0;0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Neural Dynamic Programming for Musical Self Similarity",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2100",
        "id": "2100",
        "author_site": "Christian Walder, Dongwoo Kim",
        "author": "Christian Walder; Dongwoo Kim",
        "abstract": "We present a neural sequence model designed specifically for symbolic music. The model is based on a learned edit distance mechanism which generalises a classic recursion from computer science, leading to a neural dynamic program. Repeated motifs are detected by learning the transformations between them. We represent the arising computational dependencies using a novel data structure, the edit tree; this perspective suggests natural approximations which afford the scaling up of our otherwise cubic time algorithm. We demonstrate our model on real and synthetic data; in all cases it out-performs a strong stacked long short-term memory benchmark.",
        "bibtex": "@InProceedings{pmlr-v80-walder18a,\n  title = \t {Neural Dynamic Programming for Musical Self Similarity},\n  author =       {Walder, Christian and Kim, Dongwoo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5105--5113},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/walder18a/walder18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/walder18a.html},\n  abstract = \t {We present a neural sequence model designed specifically for symbolic music. The model is based on a learned edit distance mechanism which generalises a classic recursion from computer science, leading to a neural dynamic program. Repeated motifs are detected by learning the transformations between them. We represent the arising computational dependencies using a novel data structure, the edit tree; this perspective suggests natural approximations which afford the scaling up of our otherwise cubic time algorithm. We demonstrate our model on real and synthetic data; in all cases it out-performs a strong stacked long short-term memory benchmark.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/walder18a/walder18a.pdf",
        "supp": "",
        "pdf_size": 967787,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8159536972933997736&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "CSIRO Data61, Black Mountain, Australia+The Australian National University; Data to Decisions CRC, Kent Town, SA, Australia+The Australian National University",
        "aff_domain": "data61.csiro.au; ",
        "email": "data61.csiro.au; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/walder18a.html",
        "aff_unique_index": "0+1;2+1",
        "aff_unique_norm": "CSIRO Data61;Australian National University;Data to Decisions CRC",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.csiro.au/en/Research/Data61;https://www.anu.edu.au;",
        "aff_unique_abbr": "CSIRO Data61;ANU;",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Black Mountain;;Kent Town",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Australia"
    },
    {
        "title": "Neural Inverse Rendering for General Reflectance Photometric Stereo",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1901",
        "id": "1901",
        "author_site": "Tatsunori Taniai, Takanori Maehara",
        "author": "Tatsunori Taniai; Takanori Maehara",
        "abstract": "We present a novel convolutional neural network architecture for photometric stereo (Woodham, 1980), a problem of recovering 3D object surface normals from multiple images observed under varying illuminations. Despite its long history in computer vision, the problem still shows fundamental challenges for surfaces with unknown general reflectance properties (BRDFs). Leveraging deep neural networks to learn complicated reflectance models is promising, but studies in this direction are very limited due to difficulties in acquiring accurate ground truth for training and also in designing networks invariant to permutation of input images. In order to address these challenges, we propose a physics based unsupervised learning framework where surface normals and BRDFs are predicted by the network and fed into the rendering equation to synthesize observed images. The network weights are optimized during testing by minimizing reconstruction loss between observed and synthesized images. Thus, our learning process does not require ground truth normals or even pre-training on external images. Our method is shown to achieve the state-of-the-art performance on a challenging real-world scene benchmark.",
        "bibtex": "@InProceedings{pmlr-v80-taniai18a,\n  title = \t {Neural Inverse Rendering for General Reflectance Photometric Stereo},\n  author =       {Taniai, Tatsunori and Maehara, Takanori},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4857--4866},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/taniai18a/taniai18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/taniai18a.html},\n  abstract = \t {We present a novel convolutional neural network architecture for photometric stereo (Woodham, 1980), a problem of recovering 3D object surface normals from multiple images observed under varying illuminations. Despite its long history in computer vision, the problem still shows fundamental challenges for surfaces with unknown general reflectance properties (BRDFs). Leveraging deep neural networks to learn complicated reflectance models is promising, but studies in this direction are very limited due to difficulties in acquiring accurate ground truth for training and also in designing networks invariant to permutation of input images. In order to address these challenges, we propose a physics based unsupervised learning framework where surface normals and BRDFs are predicted by the network and fed into the rendering equation to synthesize observed images. The network weights are optimized during testing by minimizing reconstruction loss between observed and synthesized images. Thus, our learning process does not require ground truth normals or even pre-training on external images. Our method is shown to achieve the state-of-the-art performance on a challenging real-world scene benchmark.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/taniai18a/taniai18a.pdf",
        "supp": "",
        "pdf_size": 2350644,
        "gs_citation": 120,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12856087892135445929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "RIKEN Center for Advanced Intelligence Project (RIKEN AIP), Nihonbashi, Tokyo, Japan; RIKEN Center for Advanced Intelligence Project (RIKEN AIP), Nihonbashi, Tokyo, Japan",
        "aff_domain": "riken.jp; ",
        "email": "riken.jp; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/taniai18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "RIKEN Center for Advanced Intelligence Project",
        "aff_unique_dep": "Advanced Intelligence Project",
        "aff_unique_url": "https://www.riken.jp/en/research/labs/aip/",
        "aff_unique_abbr": "RIKEN AIP",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nihonbashi",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2272",
        "id": "2272",
        "author_site": "Quynh Nguyen, Mahesh Mukkamala, Matthias Hein",
        "author": "Quynh Nguyen; Mahesh Chandra Mukkamala; Matthias Hein",
        "abstract": "In the recent literature the important role of depth in deep learning has been emphasized. In this paper we argue that sufficient width of a feedforward network is equally important by answering the simple question under which conditions the decision regions of a neural network are connected. It turns out that for a class of activation functions including leaky ReLU, neural networks having a pyramidal structure, that is no layer has more hidden units than the input dimension, produce necessarily connected decision regions. This implies that a sufficiently wide hidden layer is necessary to guarantee that the network can produce disconnected decision regions. We discuss the implications of this result for the construction of neural networks, in particular the relation to the problem of adversarial manipulation of classifiers.",
        "bibtex": "@InProceedings{pmlr-v80-nguyen18b,\n  title = \t {Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions},\n  author =       {Nguyen, Quynh and Mukkamala, Mahesh Chandra and Hein, Matthias},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3740--3749},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nguyen18b/nguyen18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nguyen18b.html},\n  abstract = \t {In the recent literature the important role of depth in deep learning has been emphasized. In this paper we argue that sufficient width of a feedforward network is equally important by answering the simple question under which conditions the decision regions of a neural network are connected. It turns out that for a class of activation functions including leaky ReLU, neural networks having a pyramidal structure, that is no layer has more hidden units than the input dimension, produce necessarily connected decision regions. This implies that a sufficiently wide hidden layer is necessary to guarantee that the network can produce disconnected decision regions. We discuss the implications of this result for the construction of neural networks, in particular the relation to the problem of adversarial manipulation of classifiers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nguyen18b/nguyen18b.pdf",
        "supp": "",
        "pdf_size": 507357,
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1794621718092687263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Mathematics and Computer Science, Saarland University, Germany; Department of Mathematics and Computer Science, Saarland University, Germany; University of T\u00fcbingen, Germany",
        "aff_domain": "cs.uni-saarland.de; ; ",
        "email": "cs.uni-saarland.de; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/nguyen18b.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Saarland University;University of T\u00fcbingen",
        "aff_unique_dep": "Department of Mathematics and Computer Science;",
        "aff_unique_url": "https://www.uni-saarland.de;https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "Saarland U;Uni T\u00fcbingen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Neural Program Synthesis from Diverse Demonstration Videos",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1909",
        "id": "1909",
        "author_site": "Shao-Hua Sun, Hyeonwoo Noh, Sriram Somasundaram, Joseph Lim",
        "author": "Shao-Hua Sun; Hyeonwoo Noh; Sriram Somasundaram; Joseph Lim",
        "abstract": "Interpreting decision making logic in demonstration videos is key to collaborating with and mimicking humans. To empower machines with this ability, we propose a neural program synthesizer that is able to explicitly synthesize underlying programs from behaviorally diverse and visually complicated demonstration videos. We introduce a summarizer module as part of our model to improve the network\u2019s ability to integrate multiple demonstrations varying in behavior. We also employ a multi-task objective to encourage the model to learn meaningful intermediate representations for end-to-end training. We show that our model is able to reliably synthesize underlying programs as well as capture diverse behaviors exhibited in demonstrations. The code is available at https://shaohua0116.github.io/demo2program.",
        "bibtex": "@InProceedings{pmlr-v80-sun18a,\n  title = \t {Neural Program Synthesis from Diverse Demonstration Videos},\n  author =       {Sun, Shao-Hua and Noh, Hyeonwoo and Somasundaram, Sriram and Lim, Joseph},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4790--4799},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sun18a/sun18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sun18a.html},\n  abstract = \t {Interpreting decision making logic in demonstration videos is key to collaborating with and mimicking humans. To empower machines with this ability, we propose a neural program synthesizer that is able to explicitly synthesize underlying programs from behaviorally diverse and visually complicated demonstration videos. We introduce a summarizer module as part of our model to improve the network\u2019s ability to integrate multiple demonstrations varying in behavior. We also employ a multi-task objective to encourage the model to learn meaningful intermediate representations for end-to-end training. We show that our model is able to reliably synthesize underlying programs as well as capture diverse behaviors exhibited in demonstrations. The code is available at https://shaohua0116.github.io/demo2program.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sun18a/sun18a.pdf",
        "supp": "",
        "pdf_size": 3660734,
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8601250289863980800&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Southern California, California, USA+1; Department of Computer Science and Engineering, POSTECH, Pohang, Korea+2; Department of Computer Science, University of Southern California, California, USA; Department of Computer Science, University of Southern California, California, USA",
        "aff_domain": "usc.edu; ; ; ",
        "email": "usc.edu; ; ; ",
        "github": "https://shaohua0116.github.io/demo2program",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sun18a.html",
        "aff_unique_index": "0;2;0;0",
        "aff_unique_norm": "University of Southern California;;POSTECH",
        "aff_unique_dep": "Department of Computer Science;;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.usc.edu;;https://www.postech.ac.kr",
        "aff_unique_abbr": "USC;;POSTECH",
        "aff_campus_unique_index": "0;2;0;0",
        "aff_campus_unique": "Los Angeles;;Pohang",
        "aff_country_unique_index": "0;2;0;0",
        "aff_country_unique": "United States;;South Korea"
    },
    {
        "title": "Neural Relational Inference for Interacting Systems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2083",
        "id": "2083",
        "author_site": "Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, Richard Zemel",
        "author": "Thomas Kipf; Ethan Fetaya; Kuan-Chieh Wang; Max Welling; Richard Zemel",
        "abstract": "Interacting systems are prevalent in nature, from dynamical systems in physics to complex societal dynamics. The interplay of components can give rise to complex behavior, which can often be explained using a simple model of the system\u2019s constituent parts. In this work, we introduce the neural relational inference (NRI) model: an unsupervised model that learns to infer interactions while simultaneously learning the dynamics purely from observational data. Our model takes the form of a variational auto-encoder, in which the latent code represents the underlying interaction graph and the reconstruction is based on graph neural networks. In experiments on simulated physical systems, we show that our NRI model can accurately recover ground-truth interactions in an unsupervised manner. We further demonstrate that we can find an interpretable structure and predict complex dynamics in real motion capture and sports tracking data.",
        "bibtex": "@InProceedings{pmlr-v80-kipf18a,\n  title = \t {Neural Relational Inference for Interacting Systems},\n  author =       {Kipf, Thomas and Fetaya, Ethan and Wang, Kuan-Chieh and Welling, Max and Zemel, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2688--2697},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kipf18a/kipf18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kipf18a.html},\n  abstract = \t {Interacting systems are prevalent in nature, from dynamical systems in physics to complex societal dynamics. The interplay of components can give rise to complex behavior, which can often be explained using a simple model of the system\u2019s constituent parts. In this work, we introduce the neural relational inference (NRI) model: an unsupervised model that learns to infer interactions while simultaneously learning the dynamics purely from observational data. Our model takes the form of a variational auto-encoder, in which the latent code represents the underlying interaction graph and the reconstruction is based on graph neural networks. In experiments on simulated physical systems, we show that our NRI model can accurately recover ground-truth interactions in an unsupervised manner. We further demonstrate that we can find an interpretable structure and predict complex dynamics in real motion capture and sports tracking data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kipf18a/kipf18a.pdf",
        "supp": "",
        "pdf_size": 2064181,
        "gs_citation": 1115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5985084190905139950&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "University of Amsterdam, Amsterdam, The Netherlands+Canadian Institute for Advanced Research, Toronto, Canada; University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada+Canadian Institute for Advanced Research, Toronto, Canada; University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada+Canadian Institute for Advanced Research, Toronto, Canada; University of Amsterdam, Amsterdam, The Netherlands+Canadian Institute for Advanced Research, Toronto, Canada; University of Toronto, Toronto, Canada+Vector Institute, Toronto, Canada+Canadian Institute for Advanced Research, Toronto, Canada",
        "aff_domain": "uva.nl; ; ; ; ",
        "email": "uva.nl; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/kipf18a.html",
        "aff_unique_index": "0+1;2+3+1;2+3+1;0+1;2+3+1",
        "aff_unique_norm": "University of Amsterdam;Canadian Institute for Advanced Research;University of Toronto;Vector Institute",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.uva.nl;https://www.cifar.ca;https://www.utoronto.ca;https://vectorinstitute.ai",
        "aff_unique_abbr": "UvA;CIFAR;U of T;Vector Institute",
        "aff_campus_unique_index": "0+1;1+1+1;1+1+1;0+1;1+1+1",
        "aff_campus_unique": "Amsterdam;Toronto",
        "aff_country_unique_index": "0+1;1+1+1;1+1+1;0+1;1+1+1",
        "aff_country_unique": "Netherlands;Canada"
    },
    {
        "title": "Noise2Noise: Learning Image Restoration without Clean Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2014",
        "id": "2014",
        "author_site": "Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, Timo Aila",
        "author": "Jaakko Lehtinen; Jacob Munkberg; Jon Hasselgren; Samuli Laine; Tero Karras; Miika Aittala; Timo Aila",
        "abstract": "We apply basic statistical reasoning to signal reconstruction by machine learning - learning to map corrupted observations to clean signals - with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans - all corrupted by different processes - based on noisy data only.",
        "bibtex": "@InProceedings{pmlr-v80-lehtinen18a,\n  title = \t {{N}oise2{N}oise: Learning Image Restoration without Clean Data},\n  author =       {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2965--2974},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lehtinen18a/lehtinen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lehtinen18a.html},\n  abstract = \t {We apply basic statistical reasoning to signal reconstruction by machine learning - learning to map corrupted observations to clean signals - with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans - all corrupted by different processes - based on noisy data only.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lehtinen18a/lehtinen18a.pdf",
        "supp": "",
        "pdf_size": 9737285,
        "gs_citation": 2251,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16764673643469433149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; MIT CSAIL; NVIDIA",
        "aff_domain": "nvidia.com; ; ; ; ; ; ",
        "email": "nvidia.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/lehtinen18a.html",
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "NVIDIA;Massachusetts Institute of Technology",
        "aff_unique_dep": "NVIDIA Corporation;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.nvidia.com;https://www.csail.mit.edu",
        "aff_unique_abbr": "NVIDIA;MIT CSAIL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Noisin: Unbiased Regularization for Recurrent Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2407",
        "id": "2407",
        "author_site": "Adji Bousso Dieng, Rajesh Ranganath, Jaan Altosaar, David Blei",
        "author": "Adji Bousso Dieng; Rajesh Ranganath; Jaan Altosaar; David Blei",
        "abstract": "Recurrent neural networks (RNNs) are powerful models of sequential data. They have been successfully used in domains such as text and speech. However, RNNs are susceptible to overfitting; regularization is important. In this paper we develop Noisin, a new method for regularizing RNNs. Noisin injects random noise into the hidden states of the RNN and then maximizes the corresponding marginal likelihood of the data. We show how Noisin applies to any RNN and we study many different types of noise. Noisin is unbiased\u2013it preserves the underlying RNN on average. We characterize how Noisin regularizes its RNN both theoretically and empirically. On language modeling benchmarks, Noisin improves over dropout by as much as 12.2% on the Penn Treebank and 9.4% on the Wikitext-2 dataset. We also compared the state-of-the-art language model of Yang et al. 2017, both with and without Noisin. On the Penn Treebank, the method with Noisin more quickly reaches state-of-the-art performance.",
        "bibtex": "@InProceedings{pmlr-v80-dieng18a,\n  title = \t {Noisin: Unbiased Regularization for Recurrent Neural Networks},\n  author =       {Dieng, Adji Bousso and Ranganath, Rajesh and Altosaar, Jaan and Blei, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1252--1261},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dieng18a/dieng18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dieng18a.html},\n  abstract = \t {Recurrent neural networks (RNNs) are powerful models of sequential data. They have been successfully used in domains such as text and speech. However, RNNs are susceptible to overfitting; regularization is important. In this paper we develop Noisin, a new method for regularizing RNNs. Noisin injects random noise into the hidden states of the RNN and then maximizes the corresponding marginal likelihood of the data. We show how Noisin applies to any RNN and we study many different types of noise. Noisin is unbiased\u2013it preserves the underlying RNN on average. We characterize how Noisin regularizes its RNN both theoretically and empirically. On language modeling benchmarks, Noisin improves over dropout by as much as 12.2% on the Penn Treebank and 9.4% on the Wikitext-2 dataset. We also compared the state-of-the-art language model of Yang et al. 2017, both with and without Noisin. On the Penn Treebank, the method with Noisin more quickly reaches state-of-the-art performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dieng18a/dieng18a.pdf",
        "supp": "",
        "pdf_size": 477646,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15974640378867623230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Columbia University; New York University; Princeton University; Columbia University",
        "aff_domain": "columbia.edu; ; ; ",
        "email": "columbia.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/dieng18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Columbia University;New York University;Princeton University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.columbia.edu;https://www.nyu.edu;https://www.princeton.edu",
        "aff_unique_abbr": "Columbia;NYU;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Noisy Natural Gradient as Variational Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2250",
        "id": "2250",
        "author_site": "Guodong Zhang, Shengyang Sun, David Duvenaud, Roger Grosse",
        "author": "Guodong Zhang; Shengyang Sun; David Duvenaud; Roger Grosse",
        "abstract": "Variational Bayesian neural nets combine the flexibility of deep learning with Bayesian uncertainty estimation. Unfortunately, there is a tradeoff between cheap but simple variational families (e.g.\u00a0fully factorized) or expensive and complicated inference procedures. We show that natural gradient ascent with adaptive weight noise implicitly fits a variational posterior to maximize the evidence lower bound (ELBO). This insight allows us to train full-covariance, fully factorized, or matrix-variate Gaussian variational posteriors using noisy versions of natural gradient, Adam, and K-FAC, respectively, making it possible to scale up to modern-size ConvNets. On standard regression benchmarks, our noisy K-FAC algorithm makes better predictions and matches Hamiltonian Monte Carlo\u2019s predictive variances better than existing methods. Its improved uncertainty estimates lead to more efficient exploration in active learning, and intrinsic motivation for reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18l,\n  title = \t {Noisy Natural Gradient as Variational Inference},\n  author =       {Zhang, Guodong and Sun, Shengyang and Duvenaud, David and Grosse, Roger},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5852--5861},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18l/zhang18l.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18l.html},\n  abstract = \t {Variational Bayesian neural nets combine the flexibility of deep learning with Bayesian uncertainty estimation. Unfortunately, there is a tradeoff between cheap but simple variational families (e.g.\u00a0fully factorized) or expensive and complicated inference procedures. We show that natural gradient ascent with adaptive weight noise implicitly fits a variational posterior to maximize the evidence lower bound (ELBO). This insight allows us to train full-covariance, fully factorized, or matrix-variate Gaussian variational posteriors using noisy versions of natural gradient, Adam, and K-FAC, respectively, making it possible to scale up to modern-size ConvNets. On standard regression benchmarks, our noisy K-FAC algorithm makes better predictions and matches Hamiltonian Monte Carlo\u2019s predictive variances better than existing methods. Its improved uncertainty estimates lead to more efficient exploration in active learning, and intrinsic motivation for reinforcement learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18l/zhang18l.pdf",
        "supp": "",
        "pdf_size": 2906477,
        "gs_citation": 266,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10374645130289516657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of Toronto, Canada+Vector Institute, Toronto, Canada; Department of Computer Science, University of Toronto, Canada+Vector Institute, Toronto, Canada; Department of Computer Science, University of Toronto, Canada+Vector Institute, Toronto, Canada; Department of Computer Science, University of Toronto, Canada+Vector Institute, Toronto, Canada",
        "aff_domain": "cs.toronto.edu;cs.toronto.edu; ; ",
        "email": "cs.toronto.edu;cs.toronto.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/zhang18l.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "University of Toronto;Vector Institute",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.utoronto.ca;https://vectorinstitute.ai",
        "aff_unique_abbr": "U of T;Vector Institute",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Non-convex Conditional Gradient Sliding",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1947",
        "id": "1947",
        "author_site": "chao qu, Yan Li, Huan Xu",
        "author": "Chao Qu; Yan Li; Huan Xu",
        "abstract": "We investigate a projection free optimization method, namely non-convex conditional gradient sliding (NCGS) for non-convex optimization problems on the batch, stochastic and finite-sum settings. Conditional gradient sliding (CGS) method, by integrating Nesterov\u2019s accelerated gradient method with Frank-Wolfe (FW) method in a smart way, outperforms FW for convex optimization, by reducing the amount of gradient computations. However, the study of CGS in the non-convex setting is limited. In this paper, we propose the non-convex conditional gradient sliding (NCGS) methods and analyze their convergence properties. We also leverage the idea of variance reduction from the recent progress in convex optimization to obtain a new algorithm termed",
        "bibtex": "@InProceedings{pmlr-v80-qu18a,\n  title = \t {Non-convex Conditional Gradient Sliding},\n  author =       {Qu, Chao and Li, Yan and Xu, Huan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4208--4217},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/qu18a/qu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/qu18a.html},\n  abstract = \t {We investigate a projection free optimization method, namely non-convex conditional gradient sliding (NCGS) for non-convex optimization problems on the batch, stochastic and finite-sum settings. Conditional gradient sliding (CGS) method, by integrating Nesterov\u2019s accelerated gradient method with Frank-Wolfe (FW) method in a smart way, outperforms FW for convex optimization, by reducing the amount of gradient computations. However, the study of CGS in the non-convex setting is limited. In this paper, we propose the non-convex conditional gradient sliding (NCGS) methods and analyze their convergence properties. We also leverage the idea of variance reduction from the recent progress in convex optimization to obtain a new algorithm termed",
        "pdf": "http://proceedings.mlr.press/v80/qu18a/qu18a.pdf",
        "supp": "",
        "pdf_size": 421009,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3290111019299299629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "EE faculty, Technion, Israel; H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, USA; H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, USA",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/qu18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Technion;Georgia Institute of Technology",
        "aff_unique_dep": "EE faculty;H. Milton Stewart School of Industrial and Systems Engineering",
        "aff_unique_url": "https://www.technion.ac.il;https://www.gatech.edu",
        "aff_unique_abbr": "Technion;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "title": "Non-linear motor control by local learning in spiking neural networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2311",
        "id": "2311",
        "author_site": "Aditya Gilra, Wulfram Gerstner",
        "author": "Aditya Gilra; Wulfram Gerstner",
        "abstract": "Learning weights in a spiking neural network with hidden neurons, using local, stable and online rules, to control non-linear body dynamics is an open problem. Here, we employ a supervised scheme, Feedback-based Online Local Learning Of Weights (FOLLOW), to train a heterogeneous network of spiking neurons with hidden layers, to control a two-link arm so as to reproduce a desired state trajectory. We show that the network learns an inverse model of the non-linear dynamics, i.e. it infers from state trajectory as input to the network, the continuous-time command that produced the trajectory. Connection weights are adjusted via a local plasticity rule that involves pre-synaptic firing and post-synaptic feedback of the error in the inferred command. We propose a network architecture, termed differential feedforward, and show that it gives a lower test error than other feedforward and recurrent architectures. We demonstrate the performance of the inverse model to control a two-link arm along a desired trajectory.",
        "bibtex": "@InProceedings{pmlr-v80-gilra18a,\n  title = \t {Non-linear motor control by local learning in spiking neural networks},\n  author =       {Gilra, Aditya and Gerstner, Wulfram},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1773--1782},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gilra18a/gilra18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gilra18a.html},\n  abstract = \t {Learning weights in a spiking neural network with hidden neurons, using local, stable and online rules, to control non-linear body dynamics is an open problem. Here, we employ a supervised scheme, Feedback-based Online Local Learning Of Weights (FOLLOW), to train a heterogeneous network of spiking neurons with hidden layers, to control a two-link arm so as to reproduce a desired state trajectory. We show that the network learns an inverse model of the non-linear dynamics, i.e. it infers from state trajectory as input to the network, the continuous-time command that produced the trajectory. Connection weights are adjusted via a local plasticity rule that involves pre-synaptic firing and post-synaptic feedback of the error in the inferred command. We propose a network architecture, termed differential feedforward, and show that it gives a lower test error than other feedforward and recurrent architectures. We demonstrate the performance of the inverse model to control a two-link arm along a desired trajectory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gilra18a/gilra18a.pdf",
        "supp": "",
        "pdf_size": 873995,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12598107525226436803&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Computer and Communication Sciences, and Brain-Mind Institute, School of Life Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1015 Lausanne EPFL, Switzerland+Institute for Genetics, University of Bonn, Kirschallee 1, 53115 Bonn, Germany; School of Computer and Communication Sciences, and Brain-Mind Institute, School of Life Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1015 Lausanne EPFL, Switzerland",
        "aff_domain": "unibonn.de; ",
        "email": "unibonn.de; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/gilra18a.html",
        "aff_unique_index": "0+1;0",
        "aff_unique_norm": "EPFL;University of Bonn",
        "aff_unique_dep": "School of Computer and Communication Sciences;Institute for Genetics",
        "aff_unique_url": "https://www.epfl.ch;https://www.uni-bonn.de",
        "aff_unique_abbr": "EPFL;Uni Bonn",
        "aff_campus_unique_index": "0+1;0",
        "aff_campus_unique": "Lausanne;Bonn",
        "aff_country_unique_index": "0+1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "title": "Nonconvex Optimization for Regression with Fairness Constraints",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2037",
        "id": "2037",
        "author_site": "Junpei Komiyama, Akiko Takeda, Junya Honda, Hajime Shimao",
        "author": "Junpei Komiyama; Akiko Takeda; Junya Honda; Hajime Shimao",
        "abstract": "The unfairness of a regressor is evaluated by measuring the correlation between the estimator and the sensitive attribute (e.g., race, gender, age), and the coefficient of determination (CoD) is a natural extension of the correlation coefficient when more than one sensitive attribute exists. As is well known, there is a trade-off between fairness and accuracy of a regressor, which implies a perfectly fair optimizer does not always yield a useful prediction. Taking this into consideration, we optimize the accuracy of the estimation subject to a user-defined level of fairness. However, a fairness level as a constraint induces a nonconvexity of the feasible region, which disables the use of an off-the-shelf convex optimizer. Despite such nonconvexity, we show an exact solution is available by using tools of global optimization theory. Furthermore, we propose a nonlinear extension of the method by kernel representation. Unlike most of existing fairness-aware machine learning methods, our method allows us to deal with numeric and multiple sensitive attributes.",
        "bibtex": "@InProceedings{pmlr-v80-komiyama18a,\n  title = \t {Nonconvex Optimization for Regression with Fairness Constraints},\n  author =       {Komiyama, Junpei and Takeda, Akiko and Honda, Junya and Shimao, Hajime},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2737--2746},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/komiyama18a/komiyama18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/komiyama18a.html},\n  abstract = \t {The unfairness of a regressor is evaluated by measuring the correlation between the estimator and the sensitive attribute (e.g., race, gender, age), and the coefficient of determination (CoD) is a natural extension of the correlation coefficient when more than one sensitive attribute exists. As is well known, there is a trade-off between fairness and accuracy of a regressor, which implies a perfectly fair optimizer does not always yield a useful prediction. Taking this into consideration, we optimize the accuracy of the estimation subject to a user-defined level of fairness. However, a fairness level as a constraint induces a nonconvexity of the feasible region, which disables the use of an off-the-shelf convex optimizer. Despite such nonconvexity, we show an exact solution is available by using tools of global optimization theory. Furthermore, we propose a nonlinear extension of the method by kernel representation. Unlike most of existing fairness-aware machine learning methods, our method allows us to deal with numeric and multiple sensitive attributes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/komiyama18a/komiyama18a.pdf",
        "supp": "",
        "pdf_size": 301134,
        "gs_citation": 140,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9324671354987177692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "The University of Tokyo, Tokyo, Japan + RIKEN AIP, Tokyo, Japan; The University of Tokyo, Tokyo, Japan + RIKEN AIP, Tokyo, Japan; The University of Tokyo, Tokyo, Japan + RIKEN AIP, Tokyo, Japan; Santa Fe Institute, New Mexico, United States",
        "aff_domain": "komiyama.info; ; ; ",
        "email": "komiyama.info; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/komiyama18a.html",
        "aff_unique_index": "0+1;0+1;0+1;2",
        "aff_unique_norm": "University of Tokyo;RIKEN AIP;Santa Fe Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://aip.Riken.jp;https://www santafe.edu",
        "aff_unique_abbr": "UTokyo;RIKEN AIP;SFI",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0+0;0+0;0+0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "title": "Nonoverlap-Promoting Variable Selection",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1886",
        "id": "1886",
        "author_site": "Pengtao Xie, Hongbao Zhang, Yichen Zhu, Eric Xing",
        "author": "Pengtao Xie; Hongbao Zhang; Yichen Zhu; Eric Xing",
        "abstract": "Variable selection is a classic problem in machine learning (ML), widely used to find important explanatory factors, and improve generalization performance and interpretability of ML models. In this paper, we consider variable selection for models where multiple responses are to be predicted based on the same set of covariates. Since each response is relevant to a unique subset of covariates, we desire the selected variables for different responses have small overlap. We propose a regularizer that simultaneously encourage orthogonality and sparsity, which jointly brings in an effect of reducing overlap. We apply this regularizer to four model instances and develop efficient algorithms to solve the regularized problems. We provide a formal analysis on why the proposed regularizer can reduce generalization error. Experiments on both simulation studies and real-world datasets demonstrate the effectiveness of the proposed regularizer in selecting less-overlapped variables and improving generalization performance.",
        "bibtex": "@InProceedings{pmlr-v80-xie18b,\n  title = \t {Nonoverlap-Promoting Variable Selection},\n  author =       {Xie, Pengtao and Zhang, Hongbao and Zhu, Yichen and Xing, Eric},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5413--5422},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xie18b/xie18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xie18b.html},\n  abstract = \t {Variable selection is a classic problem in machine learning (ML), widely used to find important explanatory factors, and improve generalization performance and interpretability of ML models. In this paper, we consider variable selection for models where multiple responses are to be predicted based on the same set of covariates. Since each response is relevant to a unique subset of covariates, we desire the selected variables for different responses have small overlap. We propose a regularizer that simultaneously encourage orthogonality and sparsity, which jointly brings in an effect of reducing overlap. We apply this regularizer to four model instances and develop efficient algorithms to solve the regularized problems. We provide a formal analysis on why the proposed regularizer can reduce generalization error. Experiments on both simulation studies and real-world datasets demonstrate the effectiveness of the proposed regularizer in selecting less-overlapped variables and improving generalization performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xie18b/xie18b.pdf",
        "supp": "",
        "pdf_size": 392085,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11880720135719562390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Petuum Inc + School of Computer Science, Carnegie Mellon University; School of Computer Science, Carnegie Mellon University; School of Mathematical Sciences, Peking University; Petuum Inc + School of Computer Science, Carnegie Mellon University",
        "aff_domain": "petuum.com; ; ;petuum.com",
        "email": "petuum.com; ; ;petuum.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/xie18b.html",
        "aff_unique_index": "0+1;1;2;0+1",
        "aff_unique_norm": "Petuum Inc;Carnegie Mellon University;Peking University",
        "aff_unique_dep": ";School of Computer Science;School of Mathematical Sciences",
        "aff_unique_url": "https://www.petuum.com;https://www.cmu.edu;http://www.pku.edu.cn",
        "aff_unique_abbr": ";CMU;PKU",
        "aff_campus_unique_index": "1;1;2;1",
        "aff_campus_unique": ";Pittsburgh;Beijing",
        "aff_country_unique_index": "0+0;0;1;0+0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2095",
        "id": "2095",
        "author_site": "Yichong Xu, Hariank Muthakana, Sivaraman Balakrishnan, Aarti Singh, Artur Dubrawski",
        "author": "Yichong Xu; Hariank Muthakana; Sivaraman Balakrishnan; Aarti Singh; Artur Dubrawski",
        "abstract": "In supervised learning, we leverage a labeled dataset to design methods for function estimation. In many practical situations, we are able to obtain alternative feedback, possibly at a low cost. A broad goal is to understand the usefulness of, and to design algorithms to exploit, this alternative feedback. We focus on a semi-supervised setting where we obtain additional ordinal (or comparison) information for potentially unlabeled samples. We consider ordinal feedback of varying qualities where we have either a perfect ordering of the samples, a noisy ordering of the samples or noisy pairwise comparisons between the samples. We provide a precise quantification of the usefulness of these types of ordinal feedback in non-parametric regression, showing that in many cases it is possible to accurately estimate an underlying function with a very small labeled set, effectively escaping the curse of dimensionality. We develop an algorithm called Ranking-Regression (RR) and analyze its accuracy as a function of size of the labeled and unlabeled datasets and various noise parameters. We also present lower bounds, that establish fundamental limits for the task and show that RR is optimal in a variety of settings. Finally, we present experiments that show the efficacy of RR and investigate its robustness to various sources of noise and model-misspecification.",
        "bibtex": "@InProceedings{pmlr-v80-xu18e,\n  title = \t {Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information},\n  author =       {Xu, Yichong and Muthakana, Hariank and Balakrishnan, Sivaraman and Singh, Aarti and Dubrawski, Artur},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5473--5482},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18e/xu18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18e.html},\n  abstract = \t {In supervised learning, we leverage a labeled dataset to design methods for function estimation. In many practical situations, we are able to obtain alternative feedback, possibly at a low cost. A broad goal is to understand the usefulness of, and to design algorithms to exploit, this alternative feedback. We focus on a semi-supervised setting where we obtain additional ordinal (or comparison) information for potentially unlabeled samples. We consider ordinal feedback of varying qualities where we have either a perfect ordering of the samples, a noisy ordering of the samples or noisy pairwise comparisons between the samples. We provide a precise quantification of the usefulness of these types of ordinal feedback in non-parametric regression, showing that in many cases it is possible to accurately estimate an underlying function with a very small labeled set, effectively escaping the curse of dimensionality. We develop an algorithm called Ranking-Regression (RR) and analyze its accuracy as a function of size of the labeled and unlabeled datasets and various noise parameters. We also present lower bounds, that establish fundamental limits for the task and show that RR is optimal in a variety of settings. Finally, we present experiments that show the efficacy of RR and investigate its robustness to various sources of noise and model-misspecification.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18e/xu18e.pdf",
        "supp": "",
        "pdf_size": 4164123,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2678795384271462367&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA+Auton Lab, Carnegie Mellon University, Pittsburgh, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA; Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, USA; Auton Lab, Carnegie Mellon University, Pittsburgh, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA",
        "aff_domain": "cs.cmu.edu; ; ; ; ",
        "email": "cs.cmu.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/xu18e.html",
        "aff_unique_index": "0+0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0+0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0+0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Nonparametric variable importance using an augmented neural network with multi-task learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2042",
        "id": "2042",
        "author_site": "Jean Feng, Brian Williamson, Noah Simon, Marco Carone",
        "author": "Jean Feng; Brian Williamson; Noah Simon; Marco Carone",
        "abstract": "In predictive modeling applications, it is often of interest to determine the relative contribution of subsets of features in explaining the variability of an outcome. It is useful to consider this variable importance as a function of the unknown, underlying data-generating mechanism rather than the specific predictive algorithm used to fit the data. In this paper, we connect these ideas in nonparametric variable importance to machine learning, and provide a method for efficient estimation of variable importance when building a predictive model using a neural network. We show how a single augmented neural network with multi-task learning simultaneously estimates the importance of many feature subsets, improving on previous procedures for estimating importance. We demonstrate on simulated data that our method is both accurate and computationally efficient, and apply our method to both a study of heart disease and for predicting mortality in ICU patients.",
        "bibtex": "@InProceedings{pmlr-v80-feng18a,\n  title = \t {Nonparametric variable importance using an augmented neural network with multi-task learning},\n  author =       {Feng, Jean and Williamson, Brian and Simon, Noah and Carone, Marco},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1496--1505},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/feng18a/feng18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/feng18a.html},\n  abstract = \t {In predictive modeling applications, it is often of interest to determine the relative contribution of subsets of features in explaining the variability of an outcome. It is useful to consider this variable importance as a function of the unknown, underlying data-generating mechanism rather than the specific predictive algorithm used to fit the data. In this paper, we connect these ideas in nonparametric variable importance to machine learning, and provide a method for efficient estimation of variable importance when building a predictive model using a neural network. We show how a single augmented neural network with multi-task learning simultaneously estimates the importance of many feature subsets, improving on previous procedures for estimating importance. We demonstrate on simulated data that our method is both accurate and computationally efficient, and apply our method to both a study of heart disease and for predicting mortality in ICU patients.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/feng18a/feng18a.pdf",
        "supp": "",
        "pdf_size": 908879,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=626109963873101656&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Biostatistics, University of Washington, Seattle, Washington, USA+Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, Washington, USA; Department of Biostatistics, University of Washington, Seattle, Washington, USA+Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, Washington, USA; Department of Biostatistics, University of Washington, Seattle, Washington, USA; Department of Biostatistics, University of Washington, Seattle, Washington, USA",
        "aff_domain": "uw.edu;uw.edu; ; ",
        "email": "uw.edu;uw.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/feng18a.html",
        "aff_unique_index": "0+1;0+1;0;0",
        "aff_unique_norm": "University of Washington;Fred Hutchinson Cancer Research Center",
        "aff_unique_dep": "Department of Biostatistics;Vaccine and Infectious Disease Division",
        "aff_unique_url": "https://www.washington.edu;https://www.fredhutch.org",
        "aff_unique_abbr": "UW;Fred Hutch",
        "aff_campus_unique_index": "0+0;0+0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Not All Samples Are Created Equal: Deep Learning with Importance Sampling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2178",
        "id": "2178",
        "author_site": "Angelos Katharopoulos, Francois Fleuret",
        "author": "Angelos Katharopoulos; Francois Fleuret",
        "abstract": "Deep Neural Network training spends most of the computation on examples that are properly handled, and could be ignored. We propose to mitigate this phenomenon with a principled importance sampling scheme that focuses computation on \"informative\" examples, and reduces the variance of the stochastic gradients during training. Our contribution is twofold: first, we derive a tractable upper bound to the per-sample gradient norm, and second we derive an estimator of the variance reduction achieved with importance sampling, which enables us to switch it on when it will result in an actual speedup. The resulting scheme can be used by changing a few lines of code in a standard SGD procedure, and we demonstrate experimentally on image classification, CNN fine-tuning, and RNN training, that for a fixed wall-clock time budget, it provides a reduction of the train losses of up to an order of magnitude and a relative improvement of test errors between 5% and 17%.",
        "bibtex": "@InProceedings{pmlr-v80-katharopoulos18a,\n  title = \t {Not All Samples Are Created Equal: Deep Learning with Importance Sampling},\n  author =       {Katharopoulos, Angelos and Fleuret, Francois},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2525--2534},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/katharopoulos18a/katharopoulos18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/katharopoulos18a.html},\n  abstract = \t {Deep Neural Network training spends most of the computation on examples that are properly handled, and could be ignored. We propose to mitigate this phenomenon with a principled importance sampling scheme that focuses computation on \"informative\" examples, and reduces the variance of the stochastic gradients during training. Our contribution is twofold: first, we derive a tractable upper bound to the per-sample gradient norm, and second we derive an estimator of the variance reduction achieved with importance sampling, which enables us to switch it on when it will result in an actual speedup. The resulting scheme can be used by changing a few lines of code in a standard SGD procedure, and we demonstrate experimentally on image classification, CNN fine-tuning, and RNN training, that for a fixed wall-clock time budget, it provides a reduction of the train losses of up to an order of magnitude and a relative improvement of test errors between 5% and 17%.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/katharopoulos18a/katharopoulos18a.pdf",
        "supp": "",
        "pdf_size": 547433,
        "gs_citation": 652,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6287347937947055060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Idiap Research Institute, Martigny, Switzerland+EPFL, Lausanne, Switzerland; Idiap Research Institute, Martigny, Switzerland+EPFL, Lausanne, Switzerland",
        "aff_domain": "idiap.ch; ",
        "email": "idiap.ch; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/katharopoulos18a.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Idiap Research Institute;EPFL",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.idiap.ch;https://www.epfl.ch",
        "aff_unique_abbr": "Idiap;EPFL",
        "aff_campus_unique_index": "0+1;0+1",
        "aff_campus_unique": "Martigny;Lausanne",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2119",
        "id": "2119",
        "author_site": "Patrick Schwab, Emanuela Keller, Carl Muroi, David J. Mack, Christian Str\u00e4ssle, Walter Karlen",
        "author": "Patrick Schwab; Emanuela Keller; Carl Muroi; David J. Mack; Christian Str\u00e4ssle; Walter Karlen",
        "abstract": "Patients in the intensive care unit (ICU) require constant and close supervision. To assist clinical staff in this task, hospitals use monitoring systems that trigger audiovisual alarms if their algorithms indicate that a patient\u2019s condition may be worsening. However, current monitoring systems are extremely sensitive to movement artefacts and technical errors. As a result, they typically trigger hundreds to thousands of false alarms per patient per day - drowning the important alarms in noise and adding to the exhaustion of clinical staff. In this setting, data is abundantly available, but obtaining trustworthy annotations by experts is laborious and expensive. We frame the problem of false alarm reduction from multivariate time series as a machine-learning task and address it with a novel multitask network architecture that utilises distant supervision through multiple related auxiliary tasks in order to reduce the number of expensive labels required for training. We show that our approach leads to significant improvements over several state-of-the-art baselines on real-world ICU data and provide new insights on the importance of task selection and architectural choices in distantly supervised multitask learning.",
        "bibtex": "@InProceedings{pmlr-v80-schwab18a,\n  title = \t {Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care},\n  author =       {Schwab, Patrick and Keller, Emanuela and Muroi, Carl and Mack, David J. and Str{\\\"a}ssle, Christian and Karlen, Walter},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4518--4527},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/schwab18a/schwab18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/schwab18a.html},\n  abstract = \t {Patients in the intensive care unit (ICU) require constant and close supervision. To assist clinical staff in this task, hospitals use monitoring systems that trigger audiovisual alarms if their algorithms indicate that a patient\u2019s condition may be worsening. However, current monitoring systems are extremely sensitive to movement artefacts and technical errors. As a result, they typically trigger hundreds to thousands of false alarms per patient per day - drowning the important alarms in noise and adding to the exhaustion of clinical staff. In this setting, data is abundantly available, but obtaining trustworthy annotations by experts is laborious and expensive. We frame the problem of false alarm reduction from multivariate time series as a machine-learning task and address it with a novel multitask network architecture that utilises distant supervision through multiple related auxiliary tasks in order to reduce the number of expensive labels required for training. We show that our approach leads to significant improvements over several state-of-the-art baselines on real-world ICU data and provide new insights on the importance of task selection and architectural choices in distantly supervised multitask learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/schwab18a/schwab18a.pdf",
        "supp": "",
        "pdf_size": 1153001,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13897538253893011334&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Institute of Robotics and Intelligent Systems, ETH Zurich, Switzerland; Neurocritical Care Unit, Department of Neurosurgery, University Hospital Zurich, Switzerland; Neurocritical Care Unit, Department of Neurosurgery, University Hospital Zurich, Switzerland; Neurocritical Care Unit, Department of Neurosurgery, University Hospital Zurich, Switzerland; Neurocritical Care Unit, Department of Neurosurgery, University Hospital Zurich, Switzerland; Institute of Robotics and Intelligent Systems, ETH Zurich, Switzerland",
        "aff_domain": "hest.ethz.ch; ; ; ; ; ",
        "email": "hest.ethz.ch; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/schwab18a.html",
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "ETH Zurich;University Hospital Zurich",
        "aff_unique_dep": "Institute of Robotics and Intelligent Systems;Department of Neurosurgery",
        "aff_unique_url": "https://www.ethz.ch;https://www.uhz.ch",
        "aff_unique_abbr": "ETHZ;UHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2217",
        "id": "2217",
        "author_site": "Anish Athalye, Nicholas Carlini, David Wagner",
        "author": "Anish Athalye; Nicholas Carlini; David Wagner",
        "abstract": "We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.",
        "bibtex": "@InProceedings{pmlr-v80-athalye18a,\n  title = \t {Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},\n  author =       {Athalye, Anish and Carlini, Nicholas and Wagner, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {274--283},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/athalye18a.html},\n  abstract = \t {We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf",
        "supp": "",
        "pdf_size": 275659,
        "gs_citation": 3860,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16371153415378772336&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Massachusetts Institute of Technology; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "mit.edu;cs.berkeley.edu; ",
        "email": "mit.edu;cs.berkeley.edu; ",
        "github": "https://github.com/anishathalye/obfuscated-gradients",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/athalye18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "MIT;UC Berkeley",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On Acceleration with Noise-Corrupted Gradients",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2173",
        "id": "2173",
        "author_site": "Michael Cohen, Jelena Diakonikolas, Orecchia Lorenzo",
        "author": "Michael Cohen; Jelena Diakonikolas; Lorenzo Orecchia",
        "abstract": "Accelerated algorithms have broad applications in large-scale optimization, due to their generality and fast convergence. However, their stability in the practical setting of noise-corrupted gradient oracles is not well-understood. This paper provides two main technical contributions: (i) a new accelerated method AGDP that generalizes Nesterov\u2019s AGD and improves on the recent method AXGD (Diakonikolas & Orecchia, 2018), and (ii) a theoretical study of accelerated algorithms under noisy and inexact gradient oracles, which is supported by numerical experiments. This study leverages the simplicity of AGDP and its analysis to clarify the interaction between noise and acceleration and to suggest modifications to the algorithm that reduce the mean and variance of the error incurred due to the gradient noise.",
        "bibtex": "@InProceedings{pmlr-v80-cohen18a,\n  title = \t {On Acceleration with Noise-Corrupted Gradients},\n  author =       {Cohen, Michael and Diakonikolas, Jelena and Orecchia, Lorenzo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1019--1028},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cohen18a/cohen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cohen18a.html},\n  abstract = \t {Accelerated algorithms have broad applications in large-scale optimization, due to their generality and fast convergence. However, their stability in the practical setting of noise-corrupted gradient oracles is not well-understood. This paper provides two main technical contributions: (i) a new accelerated method AGDP that generalizes Nesterov\u2019s AGD and improves on the recent method AXGD (Diakonikolas & Orecchia, 2018), and (ii) a theoretical study of accelerated algorithms under noisy and inexact gradient oracles, which is supported by numerical experiments. This study leverages the simplicity of AGDP and its analysis to clarify the interaction between noise and acceleration and to suggest modifications to the algorithm that reduce the mean and variance of the error incurred due to the gradient noise.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cohen18a/cohen18a.pdf",
        "supp": "",
        "pdf_size": 1103273,
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16397669826408244663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of EECS, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Computer Science, Boston University, Boston, MA, USA; Department of Computer Science, Boston University, Boston, MA, USA",
        "aff_domain": "mit.edu;bu.edu;bu.edu",
        "email": "mit.edu;bu.edu;bu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/cohen18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Boston University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Department of Computer Science",
        "aff_unique_url": "https://web.mit.edu;https://www.bu.edu",
        "aff_unique_abbr": "MIT;BU",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Cambridge;Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On Learning Sparsely Used Dictionaries from Incomplete Samples",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2099",
        "id": "2099",
        "author_site": "Thanh Nguyen, Akshay Soni, Chinmay Hegde",
        "author": "Thanh Nguyen; Akshay Soni; Chinmay Hegde",
        "abstract": "Existing algorithms for dictionary learning assume that the entries of the (high-dimensional) input data are fully observed. However, in several practical applications, only an incomplete fraction of the data entries may be available. For incomplete settings, no provably correct and polynomial-time algorithm has been reported in the dictionary learning literature. In this paper, we provide provable approaches for learning \u2013 from incomplete samples \u2013 a family of dictionaries whose atoms have sufficiently \u201cspread-out\u201d mass. First, we propose a descent-style iterative algorithm that linearly converges to the true dictionary when provided a sufficiently coarse initial estimate. Second, we propose an initialization algorithm that utilizes a small number of extra fully observed samples to produce such a coarse initial estimate. Finally, we theoretically analyze their performance and provide asymptotic statistical and computational guarantees.",
        "bibtex": "@InProceedings{pmlr-v80-nguyen18e,\n  title = \t {On Learning Sparsely Used Dictionaries from Incomplete Samples},\n  author =       {Nguyen, Thanh and Soni, Akshay and Hegde, Chinmay},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3769--3778},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nguyen18e/nguyen18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nguyen18e.html},\n  abstract = \t {Existing algorithms for dictionary learning assume that the entries of the (high-dimensional) input data are fully observed. However, in several practical applications, only an incomplete fraction of the data entries may be available. For incomplete settings, no provably correct and polynomial-time algorithm has been reported in the dictionary learning literature. In this paper, we provide provable approaches for learning \u2013 from incomplete samples \u2013 a family of dictionaries whose atoms have sufficiently \u201cspread-out\u201d mass. First, we propose a descent-style iterative algorithm that linearly converges to the true dictionary when provided a sufficiently coarse initial estimate. Second, we propose an initialization algorithm that utilizes a small number of extra fully observed samples to produce such a coarse initial estimate. Finally, we theoretically analyze their performance and provide asymptotic statistical and computational guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nguyen18e/nguyen18e.pdf",
        "supp": "",
        "pdf_size": 480248,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9959958568281969610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Iowa State University; Yahoo! Research; Iowa State University",
        "aff_domain": "iastate.edu; ; ",
        "email": "iastate.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/nguyen18e.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Iowa State University;Yahoo!",
        "aff_unique_dep": ";Yahoo! Research",
        "aff_unique_url": "https://www.iastate.edu;https://research.yahoo.com",
        "aff_unique_abbr": "ISU;Yahoo!",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On Matching Pursuit and Coordinate Descent",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2228",
        "id": "2228",
        "author_site": "Francesco Locatello, Anant Raj, Sai Praneeth Reddy Karimireddy, Gunnar Ratsch, Bernhard Sch\u00f6lkopf, Sebastian Stich, Martin Jaggi",
        "author": "Francesco Locatello; Anant Raj; Sai Praneeth Karimireddy; Gunnar Raetsch; Bernhard Sch\u00f6lkopf; Sebastian Stich; Martin Jaggi",
        "abstract": "Two popular examples of first-order optimization methods over linear spaces are coordinate descent and matching pursuit algorithms, with their randomized variants. While the former targets the optimization by moving along coordinates, the latter considers a generalized notion of directions. Exploiting the connection between the two algorithms, we present a unified analysis of both, providing affine invariant sublinear $O(1/t)$ rates on smooth objectives and linear convergence on strongly convex objectives. As a byproduct of our affine invariant analysis of matching pursuit, our rates for steepest coordinate descent are the tightest known. Furthermore, we show the first accelerated convergence rate $O(1/t^2)$ for matching pursuit and steepest coordinate descent on convex objectives.",
        "bibtex": "@InProceedings{pmlr-v80-locatello18a,\n  title = \t {On Matching Pursuit and Coordinate Descent},\n  author =       {Locatello, Francesco and Raj, Anant and Karimireddy, Sai Praneeth and Raetsch, Gunnar and Sch{\\\"o}lkopf, Bernhard and Stich, Sebastian and Jaggi, Martin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3198--3207},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/locatello18a/locatello18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/locatello18a.html},\n  abstract = \t {Two popular examples of first-order optimization methods over linear spaces are coordinate descent and matching pursuit algorithms, with their randomized variants. While the former targets the optimization by moving along coordinates, the latter considers a generalized notion of directions. Exploiting the connection between the two algorithms, we present a unified analysis of both, providing affine invariant sublinear $O(1/t)$ rates on smooth objectives and linear convergence on strongly convex objectives. As a byproduct of our affine invariant analysis of matching pursuit, our rates for steepest coordinate descent are the tightest known. Furthermore, we show the first accelerated convergence rate $O(1/t^2)$ for matching pursuit and steepest coordinate descent on convex objectives.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/locatello18a/locatello18a.pdf",
        "supp": "",
        "pdf_size": 503330,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14447450939980198854&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany+Dept. of Computer Science, ETH Zurich, Zurich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; EPFL, Lausanne, Switzerland; Dept. of Computer Science, ETH Zurich, Zurich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland",
        "aff_domain": "tuebingen.mpg.de;tuebingen.mpg.de; ; ; ; ; ",
        "email": "tuebingen.mpg.de;tuebingen.mpg.de; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/locatello18a.html",
        "aff_unique_index": "0+1;0;2;1;0;2;2",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;ETH Zurich;EPFL",
        "aff_unique_dep": ";Dept. of Computer Science;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.ethz.ch;https://www.epfl.ch",
        "aff_unique_abbr": "MPI-IS;ETHZ;EPFL",
        "aff_campus_unique_index": "0+1;0;2;1;0;2;2",
        "aff_campus_unique": "T\u00fcbingen;Zurich;Lausanne",
        "aff_country_unique_index": "0+1;0;1;1;0;1;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "title": "On Nesting Monte Carlo Estimators",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1874",
        "id": "1874",
        "author_site": "Tom Rainforth, Rob Cornish, Hongseok Yang, andrew warrington, Frank Wood",
        "author": "Tom Rainforth; Rob Cornish; Hongseok Yang; Andrew Warrington; Frank Wood",
        "abstract": "Many problems in machine learning and statistics involve nested expectations and thus do not permit conventional Monte Carlo (MC) estimation. For such problems, one must nest estimators, such that terms in an outer estimator themselves involve calculation of a separate, nested, estimation. We investigate the statistical implications of nesting MC estimators, including cases of multiple levels of nesting, and establish the conditions under which they converge. We derive corresponding rates of convergence and provide empirical evidence that these rates are observed in practice. We further establish a number of pitfalls that can arise from naive nesting of MC estimators, provide guidelines about how these can be avoided, and lay out novel methods for reformulating certain classes of nested expectation problems into single expectations, leading to improved convergence rates. We demonstrate the applicability of our work by using our results to develop a new estimator for discrete Bayesian experimental design problems and derive error bounds for a class of variational objectives.",
        "bibtex": "@InProceedings{pmlr-v80-rainforth18a,\n  title = \t {On Nesting {M}onte {C}arlo Estimators},\n  author =       {Rainforth, Tom and Cornish, Rob and Yang, Hongseok and Warrington, Andrew and Wood, Frank},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4267--4276},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rainforth18a/rainforth18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rainforth18a.html},\n  abstract = \t {Many problems in machine learning and statistics involve nested expectations and thus do not permit conventional Monte Carlo (MC) estimation. For such problems, one must nest estimators, such that terms in an outer estimator themselves involve calculation of a separate, nested, estimation. We investigate the statistical implications of nesting MC estimators, including cases of multiple levels of nesting, and establish the conditions under which they converge. We derive corresponding rates of convergence and provide empirical evidence that these rates are observed in practice. We further establish a number of pitfalls that can arise from naive nesting of MC estimators, provide guidelines about how these can be avoided, and lay out novel methods for reformulating certain classes of nested expectation problems into single expectations, leading to improved convergence rates. We demonstrate the applicability of our work by using our results to develop a new estimator for discrete Bayesian experimental design problems and derive error bounds for a class of variational objectives.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rainforth18a/rainforth18a.pdf",
        "supp": "",
        "pdf_size": 2446137,
        "gs_citation": 175,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1229634929947747937&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/rainforth18a.html"
    },
    {
        "title": "On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2476",
        "id": "2476",
        "author_site": "Risi Kondor, Shubhendu Trivedi",
        "author": "Risi Kondor; Shubhendu Trivedi",
        "abstract": "Convolutional neural networks have been extremely successful in the image recognition domain because they ensure equivariance with respect to translations. There have been many recent attempts to generalize this framework to other domains, including graphs and data lying on manifolds. In this paper we give a rigorous, theoretical treatment of convolution and equivariance in neural networks with respect to not just translations, but the action of any compact group. Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient, but also a necessary condition for equivariance to the action of a compact group. Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.",
        "bibtex": "@InProceedings{pmlr-v80-kondor18a,\n  title = \t {On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups},\n  author =       {Kondor, Risi and Trivedi, Shubhendu},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2747--2755},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kondor18a/kondor18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kondor18a.html},\n  abstract = \t {Convolutional neural networks have been extremely successful in the image recognition domain because they ensure equivariance with respect to translations. There have been many recent attempts to generalize this framework to other domains, including graphs and data lying on manifolds. In this paper we give a rigorous, theoretical treatment of convolution and equivariance in neural networks with respect to not just translations, but the action of any compact group. Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient, but also a necessary condition for equivariance to the action of a compact group. Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kondor18a/kondor18a.pdf",
        "supp": "",
        "pdf_size": 286072,
        "gs_citation": 602,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9202958939197040845&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Departments of Statistics and Computer Science, The University of Chicago; Toyota Technological Institute at Chicago",
        "aff_domain": "cs.uchicago.edu;ttic.edu",
        "email": "cs.uchicago.edu;ttic.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kondor18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Chicago;Toyota Technological Institute at Chicago",
        "aff_unique_dep": "Departments of Statistics and Computer Science;",
        "aff_unique_url": "https://www.uchicago.edu;https://www.tti-chicago.org",
        "aff_unique_abbr": "UChicago;TTI Chicago",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On the Implicit Bias of Dropout",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2354",
        "id": "2354",
        "author_site": "Poorya Mianjy, Raman Arora, Rene Vidal",
        "author": "Poorya Mianjy; Raman Arora; Rene Vidal",
        "abstract": "Algorithmic approaches endow deep learning systems with implicit bias that helps them generalize even in over-parametrized settings. In this paper, we focus on understanding such a bias induced in learning through dropout, a popular technique to avoid overfitting in deep learning. For single hidden-layer linear neural networks, we show that dropout tends to make the norm of incoming/outgoing weight vectors of all the hidden nodes equal. In addition, we provide a complete characterization of the optimization landscape induced by dropout.",
        "bibtex": "@InProceedings{pmlr-v80-mianjy18b,\n  title = \t {On the Implicit Bias of Dropout},\n  author =       {Mianjy, Poorya and Arora, Raman and Vidal, Rene},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3540--3548},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mianjy18b/mianjy18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mianjy18b.html},\n  abstract = \t {Algorithmic approaches endow deep learning systems with implicit bias that helps them generalize even in over-parametrized settings. In this paper, we focus on understanding such a bias induced in learning through dropout, a popular technique to avoid overfitting in deep learning. For single hidden-layer linear neural networks, we show that dropout tends to make the norm of incoming/outgoing weight vectors of all the hidden nodes equal. In addition, we provide a complete characterization of the optimization landscape induced by dropout.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mianjy18b/mianjy18b.pdf",
        "supp": "",
        "pdf_size": 3121771,
        "gs_citation": 93,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15383588520801528278&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Johns Hopkins University; Department of Computer Science, Johns Hopkins University; Department of Biomedical Engineering, Johns Hopkins University",
        "aff_domain": "jhu.edu;cs.jhu.edu;jhu.edu",
        "email": "jhu.edu;cs.jhu.edu;jhu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mianjy18b.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On the Limitations of First-Order Approximation in GAN Dynamics",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2342",
        "id": "2342",
        "author_site": "Jerry Li, Aleksander Madry, John Peebles, Ludwig Schmidt",
        "author": "Jerry Li; Aleksander Madry; John Peebles; Ludwig Schmidt",
        "abstract": "While Generative Adversarial Networks (GANs) have demonstrated promising performance on multiple vision tasks, their learning dynamics are not yet well understood, both in theory and in practice. To address this issue, we study GAN dynamics in a simple yet rich parametric model that exhibits several of the common problematic convergence behaviors such as vanishing gradients, mode collapse, and diverging or oscillatory behavior. In spite of the non-convex nature of our model, we are able to perform a rigorous theoretical analysis of its convergence behavior. Our analysis reveals an interesting dichotomy: a GAN with an optimal discriminator provably converges, while first order approximations of the discriminator steps lead to unstable GAN dynamics and mode collapse. Our result suggests that using first order discriminator steps (the de-facto standard in most existing GAN setups) might be one of the factors that makes GAN training challenging in practice.",
        "bibtex": "@InProceedings{pmlr-v80-li18d,\n  title = \t {On the Limitations of First-Order Approximation in {GAN} Dynamics},\n  author =       {Li, Jerry and Madry, Aleksander and Peebles, John and Schmidt, Ludwig},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3005--3013},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18d/li18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18d.html},\n  abstract = \t {While Generative Adversarial Networks (GANs) have demonstrated promising performance on multiple vision tasks, their learning dynamics are not yet well understood, both in theory and in practice. To address this issue, we study GAN dynamics in a simple yet rich parametric model that exhibits several of the common problematic convergence behaviors such as vanishing gradients, mode collapse, and diverging or oscillatory behavior. In spite of the non-convex nature of our model, we are able to perform a rigorous theoretical analysis of its convergence behavior. Our analysis reveals an interesting dichotomy: a GAN with an optimal discriminator provably converges, while first order approximations of the discriminator steps lead to unstable GAN dynamics and mode collapse. Our result suggests that using first order discriminator steps (the de-facto standard in most existing GAN setups) might be one of the factors that makes GAN training challenging in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18d/li18d.pdf",
        "supp": "",
        "pdf_size": 890575,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12853395852540879423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "MIT; MIT; MIT; MIT",
        "aff_domain": "mit.edu; ; ; ",
        "email": "mit.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/li18d.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2422",
        "id": "2422",
        "author_site": "Sanjeev Arora, Nadav Cohen, Elad Hazan",
        "author": "Sanjeev Arora; Nadav Cohen; Elad Hazan",
        "abstract": "Conventional wisdom in deep learning states that increasing depth improves expressiveness but complicates optimization. This paper suggests that, sometimes, increasing depth can speed up optimization. The effect of depth on optimization is decoupled from expressiveness by focusing on settings where additional layers amount to overparameterization \u2013 linear neural networks, a well-studied model. Theoretical analysis, as well as experiments, show that here depth acts as a preconditioner which may accelerate convergence. Even on simple convex problems such as linear regression with $\\ell_p$ loss, $p>2$, gradient descent can benefit from transitioning to a non-convex overparameterized objective, more than it would from some common acceleration schemes. We also prove that it is mathematically impossible to obtain the acceleration effect of overparametrization via gradients of any regularizer.",
        "bibtex": "@InProceedings{pmlr-v80-arora18a,\n  title = \t {On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization},\n  author =       {Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {244--253},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/arora18a/arora18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/arora18a.html},\n  abstract = \t {Conventional wisdom in deep learning states that increasing depth improves expressiveness but complicates optimization. This paper suggests that, sometimes, increasing depth can speed up optimization. The effect of depth on optimization is decoupled from expressiveness by focusing on settings where additional layers amount to overparameterization \u2013 linear neural networks, a well-studied model. Theoretical analysis, as well as experiments, show that here depth acts as a preconditioner which may accelerate convergence. Even on simple convex problems such as linear regression with $\\ell_p$ loss, $p>2$, gradient descent can benefit from transitioning to a non-convex overparameterized objective, more than it would from some common acceleration schemes. We also prove that it is mathematically impossible to obtain the acceleration effect of overparametrization via gradients of any regularizer.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/arora18a/arora18a.pdf",
        "supp": "",
        "pdf_size": 733638,
        "gs_citation": 609,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=648079330581556685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Computer Science, Princeton University, Princeton, NJ, USA+School of Mathematics, Institute for Advanced Study, Princeton, NJ, USA; School of Mathematics, Institute for Advanced Study, Princeton, NJ, USA; Department of Computer Science, Princeton University, Princeton, NJ, USA+Google Brain, USA",
        "aff_domain": "cs.princeton.edu;ias.edu;cs.princeton.edu",
        "email": "cs.princeton.edu;ias.edu;cs.princeton.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/arora18a.html",
        "aff_unique_index": "0+1;1;0+2",
        "aff_unique_norm": "Princeton University;Institute for Advanced Study;Google",
        "aff_unique_dep": "Department of Computer Science;School of Mathematics;Google Brain",
        "aff_unique_url": "https://www.princeton.edu;https://www.ias.edu;https://brain.google.com",
        "aff_unique_abbr": "Princeton;IAS;Google Brain",
        "aff_campus_unique_index": "0+0;0;0+1",
        "aff_campus_unique": "Princeton;Mountain View",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On the Power of Over-parametrization in Neural Networks with Quadratic Activation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1923",
        "id": "1923",
        "author_site": "Simon Du, Jason Lee",
        "author": "Simon Du; Jason Lee",
        "abstract": "We provide new theoretical insights on why over-parametrization is effective in learning neural networks. For a $k$ hidden node shallow network with quadratic activation and $n$ training data points, we show as long as $ k \\ge \\sqrt{2n}$, over-parametrization enables local search algorithms to find a",
        "bibtex": "@InProceedings{pmlr-v80-du18a,\n  title = \t {On the Power of Over-parametrization in Neural Networks with Quadratic Activation},\n  author =       {Du, Simon and Lee, Jason},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1329--1338},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/du18a/du18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/du18a.html},\n  abstract = \t {We provide new theoretical insights on why over-parametrization is effective in learning neural networks. For a $k$ hidden node shallow network with quadratic activation and $n$ training data points, we show as long as $ k \\ge \\sqrt{2n}$, over-parametrization enables local search algorithms to find a",
        "pdf": "http://proceedings.mlr.press/v80/du18a/du18a.pdf",
        "supp": "",
        "pdf_size": 309367,
        "gs_citation": 303,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=700042473071047065&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Machine Learning Department, Carnegie Mellon University; Department of Data Sciences and Operations, University of Southern California",
        "aff_domain": "cs.cmu.edu; ",
        "email": "cs.cmu.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/du18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Carnegie Mellon University;University of Southern California",
        "aff_unique_dep": "Machine Learning Department;Department of Data Sciences and Operations",
        "aff_unique_url": "https://www.cmu.edu;https://www.usc.edu",
        "aff_unique_abbr": "CMU;USC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On the Relationship between Data Efficiency and Error for Uncertainty Sampling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2390",
        "id": "2390",
        "author_site": "Stephen Mussmann, Percy Liang",
        "author": "Stephen Mussmann; Percy Liang",
        "abstract": "While active learning offers potential cost savings, the actual data efficiency\u2014the reduction in amount of labeled data needed to obtain the same error rate\u2014observed in practice is mixed. This paper poses a basic question: when is active learning actually helpful? We provide an answer for logistic regression with the popular active learning algorithm, uncertainty sampling. Empirically, on 21 datasets from OpenML, we find a strong inverse correlation between data efficiency and the error rate of the final classifier. Theoretically, we show that for a variant of uncertainty sampling, the asymptotic data efficiency is within a constant factor of the inverse error rate of the limiting classifier.",
        "bibtex": "@InProceedings{pmlr-v80-mussmann18a,\n  title = \t {On the Relationship between Data Efficiency and Error for Uncertainty Sampling},\n  author =       {Mussmann, Stephen and Liang, Percy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3674--3682},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mussmann18a/mussmann18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mussmann18a.html},\n  abstract = \t {While active learning offers potential cost savings, the actual data efficiency\u2014the reduction in amount of labeled data needed to obtain the same error rate\u2014observed in practice is mixed. This paper poses a basic question: when is active learning actually helpful? We provide an answer for logistic regression with the popular active learning algorithm, uncertainty sampling. Empirically, on 21 datasets from OpenML, we find a strong inverse correlation between data efficiency and the error rate of the final classifier. Theoretically, we show that for a variant of uncertainty sampling, the asymptotic data efficiency is within a constant factor of the inverse error rate of the limiting classifier.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mussmann18a/mussmann18a.pdf",
        "supp": "",
        "pdf_size": 386198,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10483847003621526394&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "stanford.edu; ",
        "email": "stanford.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/mussmann18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "On the Spectrum of Random Features Maps of High Dimensional Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1898",
        "id": "1898",
        "author_site": "Zhenyu Liao, Romain Couillet",
        "author": "Zhenyu Liao; Romain Couillet",
        "abstract": "Random feature maps are ubiquitous in modern statistical machine learning, where they generalize random projections by means of powerful, yet often difficult to analyze nonlinear operators. In this paper we leverage the \"concentration\" phenomenon induced by random matrix theory to perform a spectral analysis on the Gram matrix of these random feature maps, here for Gaussian mixture models of simultaneously large dimension and size. Our results are instrumental to a deeper understanding on the interplay of the nonlinearity and the statistics of the data, thereby allowing for a better tuning of random feature-based techniques.",
        "bibtex": "@InProceedings{pmlr-v80-liao18a,\n  title = \t {On the Spectrum of Random Features Maps of High Dimensional Data},\n  author =       {Liao, Zhenyu and Couillet, Romain},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3063--3071},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liao18a/liao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liao18a.html},\n  abstract = \t {Random feature maps are ubiquitous in modern statistical machine learning, where they generalize random projections by means of powerful, yet often difficult to analyze nonlinear operators. In this paper we leverage the \"concentration\" phenomenon induced by random matrix theory to perform a spectral analysis on the Gram matrix of these random feature maps, here for Gaussian mixture models of simultaneously large dimension and size. Our results are instrumental to a deeper understanding on the interplay of the nonlinearity and the statistics of the data, thereby allowing for a better tuning of random feature-based techniques.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liao18a/liao18a.pdf",
        "supp": "",
        "pdf_size": 804634,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4838372697610829936&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Laboratoire des Signaux et Syst\u00e8mes (L2S), CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France+G-STATS Data Science Chair, GIPSA-lab, University Grenobles-Alpes, France; Laboratoire des Signaux et Syst\u00e8mes (L2S), CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France+G-STATS Data Science Chair, GIPSA-lab, University Grenobles-Alpes, France",
        "aff_domain": "l2s.centralesupelec.fr;centralesupelec.fr",
        "email": "l2s.centralesupelec.fr;centralesupelec.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/liao18a.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "CentraleSup\u00e9lec;University Grenobles-Alpes",
        "aff_unique_dep": "Laboratoire des Signaux et Syst\u00e8mes (L2S);GIPSA-lab",
        "aff_unique_url": "https://www.centralesupelec.fr;https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "CentraleSup\u00e9lec;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "France"
    },
    {
        "title": "On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2094",
        "id": "2094",
        "author_site": "Niladri Chatterji, Nicolas Flammarion, Yian Ma, Peter Bartlett, Michael Jordan",
        "author": "Niladri Chatterji; Nicolas Flammarion; Yian Ma; Peter Bartlett; Michael Jordan",
        "abstract": "We provide convergence guarantees in Wasserstein distance for a variety of variance-reduction methods: SAGA Langevin diffusion, SVRG Langevin diffusion and control-variate underdamped Langevin diffusion. We analyze these methods under a uniform set of assumptions on the log-posterior distribution, assuming it to be smooth, strongly convex and Hessian Lipschitz. This is achieved by a new proof technique combining ideas from finite-sum optimization and the analysis of sampling methods. Our sharp theoretical bounds allow us to identify regimes of interest where each method performs better than the others. Our theory is verified with experiments on real-world and synthetic datasets.",
        "bibtex": "@InProceedings{pmlr-v80-chatterji18a,\n  title = \t {On the Theory of Variance Reduction for Stochastic Gradient {M}onte {C}arlo},\n  author =       {Chatterji, Niladri and Flammarion, Nicolas and Ma, Yian and Bartlett, Peter and Jordan, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {764--773},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chatterji18a/chatterji18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chatterji18a.html},\n  abstract = \t {We provide convergence guarantees in Wasserstein distance for a variety of variance-reduction methods: SAGA Langevin diffusion, SVRG Langevin diffusion and control-variate underdamped Langevin diffusion. We analyze these methods under a uniform set of assumptions on the log-posterior distribution, assuming it to be smooth, strongly convex and Hessian Lipschitz. This is achieved by a new proof technique combining ideas from finite-sum optimization and the analysis of sampling methods. Our sharp theoretical bounds allow us to identify regimes of interest where each method performs better than the others. Our theory is verified with experiments on real-world and synthetic datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chatterji18a/chatterji18a.pdf",
        "supp": "",
        "pdf_size": 742926,
        "gs_citation": 113,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14849315505233539375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Physics; Division of Computer Science; Division of Computer Science; Division of Computer Science + Department of Statistics; Division of Computer Science + Department of Statistics",
        "aff_domain": "berkeley.edu; ; ; ; ",
        "email": "berkeley.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/chatterji18a.html",
        "aff_unique_index": "0;1;1;1+2;1+2",
        "aff_unique_norm": "Institution not specified;Division of Computer Science;University Affiliation Not Specified",
        "aff_unique_dep": "Department of Physics;Computer Science;Department of Statistics",
        "aff_unique_url": ";;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": ";",
        "aff_country_unique": ""
    },
    {
        "title": "One-Shot Segmentation in Clutter",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2303",
        "id": "2303",
        "author_site": "Claudio Michaelis, Matthias Bethge, Alexander Ecker",
        "author": "Claudio Michaelis; Matthias Bethge; Alexander Ecker",
        "abstract": "We tackle the problem of one-shot segmentation: finding and segmenting a previously unseen object in a cluttered scene based on a single instruction example. We propose a novel dataset, which we call",
        "bibtex": "@InProceedings{pmlr-v80-michaelis18a,\n  title = \t {One-Shot Segmentation in Clutter},\n  author =       {Michaelis, Claudio and Bethge, Matthias and Ecker, Alexander},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3549--3558},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/michaelis18a/michaelis18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/michaelis18a.html},\n  abstract = \t {We tackle the problem of one-shot segmentation: finding and segmenting a previously unseen object in a cluttered scene based on a single instruction example. We propose a novel dataset, which we call",
        "pdf": "http://proceedings.mlr.press/v80/michaelis18a/michaelis18a.pdf",
        "supp": "",
        "pdf_size": 608680,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14253967975584352267&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Centre for Integrative Neuroscience and Institute for Theoretical Physics, University of T\u00fcbingen, Germany+Bernstein Centre for Computational Neuroscience, T\u00fcbingen, Germany+Max Planck Institute for Biological Cybernetics, T\u00fcbingen, Germany+Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine, Houston, TX, USA; Centre for Integrative Neuroscience and Institute for Theoretical Physics, University of T\u00fcbingen, Germany+Bernstein Centre for Computational Neuroscience, T\u00fcbingen, Germany+Max Planck Institute for Biological Cybernetics, T\u00fcbingen, Germany; Centre for Integrative Neuroscience and Institute for Theoretical Physics, University of T\u00fcbingen, Germany+Bernstein Centre for Computational Neuroscience, T\u00fcbingen, Germany+Max Planck Institute for Biological Cybernetics, T\u00fcbingen, Germany+Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine, Houston, TX, USA",
        "aff_domain": "uni-tuebingen.de;uni-tuebingen.de;uni-tuebingen.de",
        "email": "uni-tuebingen.de;uni-tuebingen.de;uni-tuebingen.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/michaelis18a.html",
        "aff_unique_index": "0+1+2+3;0+1+2;0+1+2+3",
        "aff_unique_norm": "University of T\u00fcbingen;Bernstein Centre for Computational Neuroscience;Max Planck Institute for Biological Cybernetics;Baylor College of Medicine",
        "aff_unique_dep": "Centre for Integrative Neuroscience, Institute for Theoretical Physics;;;Center for Neuroscience and Artificial Intelligence",
        "aff_unique_url": "https://www.uni-tuebingen.de;;https://www.biocybernetics.mpg.de;https://www.bcm.edu",
        "aff_unique_abbr": ";;MPIBC;BCM",
        "aff_campus_unique_index": "1+1+2;1+1;1+1+2",
        "aff_campus_unique": ";T\u00fcbingen;Houston",
        "aff_country_unique_index": "0+0+0+1;0+0+0;0+0+0+1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "title": "Online Convolutional Sparse Coding with Sample-Dependent Dictionary",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2192",
        "id": "2192",
        "author_site": "Yaqing WANG, Quanming Yao, James Kwok, Lionel NI",
        "author": "Yaqing Wang; Quanming Yao; James Tin-Yau Kwok; Lionel M. NI",
        "abstract": "Convolutional sparse coding (CSC) has been popularly used for the learning of shift-invariant dictionaries in image and signal processing. However, existing methods have limited scalability. In this paper, instead of convolving with a dictionary shared by all samples, we propose the use of a sample-dependent dictionary in which each filter is a linear combination of a small set of base filters learned from data. This added flexibility allows a large number of sample-dependent patterns to be captured, which is especially useful in the handling of large or high-dimensional data sets. Computationally, the resultant model can be efficiently learned by online learning. Extensive experimental results on a number of data sets show that the proposed method outperforms existing CSC algorithms with significantly reduced time and space complexities.",
        "bibtex": "@InProceedings{pmlr-v80-wang18k,\n  title = \t {Online Convolutional Sparse Coding with Sample-Dependent Dictionary},\n  author =       {Wang, Yaqing and Yao, Quanming and Kwok, James Tin-Yau and NI, Lionel M.},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5209--5218},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18k/wang18k.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18k.html},\n  abstract = \t {Convolutional sparse coding (CSC) has been popularly used for the learning of shift-invariant dictionaries in image and signal processing. However, existing methods have limited scalability. In this paper, instead of convolving with a dictionary shared by all samples, we propose the use of a sample-dependent dictionary in which each filter is a linear combination of a small set of base filters learned from data. This added flexibility allows a large number of sample-dependent patterns to be captured, which is especially useful in the handling of large or high-dimensional data sets. Computationally, the resultant model can be efficiently learned by online learning. Extensive experimental results on a number of data sets show that the proposed method outperforms existing CSC algorithms with significantly reduced time and space complexities.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18k/wang18k.pdf",
        "supp": "",
        "pdf_size": 755589,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7281425324028842662&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology University, Hong Kong; Department of Computer Science and Engineering, Hong Kong University of Science and Technology University, Hong Kong + Paradigm Inc, Beijing, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology University, Hong Kong; Department of Computer and Information Science, University of Macau, Macau",
        "aff_domain": "cse.ust.hk; ; ; ",
        "email": "cse.ust.hk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/wang18k.html",
        "aff_unique_index": "0;0+1;0;2",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Paradigm Inc;University of Macau",
        "aff_unique_dep": "Department of Computer Science and Engineering;;Department of Computer and Information Science",
        "aff_unique_url": "https://www.ust.hk;;https://www.um.edu.mo",
        "aff_unique_abbr": "HKUST;;UM",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Hong Kong SAR;;Macau SAR",
        "aff_country_unique_index": "0;0+0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Online Learning with Abstention",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2113",
        "id": "2113",
        "author_site": "Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, Scott Yang",
        "author": "Corinna Cortes; Giulia DeSalvo; Claudio Gentile; Mehryar Mohri; Scott Yang",
        "abstract": "We present an extensive study of a key problem in online learning where the learner can opt to abstain from making a prediction, at a certain cost. In the adversarial setting, we show how existing online algorithms and guarantees can be adapted to this problem. In the stochastic setting, we first point out a bias problem that limits the straightforward extension of algorithms such as UCB-N to this context. Next, we give a new algorithm, UCB-GT, that exploits historical data and time-varying feedback graphs. We show that this algorithm benefits from more favorable regret guarantees than a natural extension of UCB-N . We further report the results of a series of experiments demonstrating that UCB-GT largely outperforms that extension of UCB-N, as well as other standard baselines.",
        "bibtex": "@InProceedings{pmlr-v80-cortes18a,\n  title = \t {Online Learning with Abstention},\n  author =       {Cortes, Corinna and DeSalvo, Giulia and Gentile, Claudio and Mohri, Mehryar and Yang, Scott},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1059--1067},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cortes18a/cortes18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cortes18a.html},\n  abstract = \t {We present an extensive study of a key problem in online learning where the learner can opt to abstain from making a prediction, at a certain cost. In the adversarial setting, we show how existing online algorithms and guarantees can be adapted to this problem. In the stochastic setting, we first point out a bias problem that limits the straightforward extension of algorithms such as UCB-N to this context. Next, we give a new algorithm, UCB-GT, that exploits historical data and time-varying feedback graphs. We show that this algorithm benefits from more favorable regret guarantees than a natural extension of UCB-N . We further report the results of a series of experiments demonstrating that UCB-GT largely outperforms that extension of UCB-N, as well as other standard baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cortes18a/cortes18a.pdf",
        "supp": "",
        "pdf_size": 3133444,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1322081644501262008&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Google Research, New York, NY; Google Research, New York, NY; INRIA Lille Nord Europe + Courant Institute of Mathematical Sciences, New York, NY; Courant Institute of Mathematical Sciences, New York, NY; D. E. Shaw & Co., New York, NY",
        "aff_domain": "google.com;google.com;inria.fr;cims.nyu.edu;shaw.com",
        "email": "google.com;google.com;inria.fr;cims.nyu.edu;shaw.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/cortes18a.html",
        "aff_unique_index": "0;0;1+2;2;3",
        "aff_unique_norm": "Google;INRIA;Courant Institute of Mathematical Sciences;D. E. Shaw & Co.",
        "aff_unique_dep": "Google Research;;Mathematical Sciences;",
        "aff_unique_url": "https://research.google;https://www.inria.fr;https://courant.nyu.edu;https://www.deshaw.com",
        "aff_unique_abbr": "Google Research;INRIA;Courant;DES",
        "aff_campus_unique_index": "0;0;1+0;0",
        "aff_campus_unique": "New York;Lille;",
        "aff_country_unique_index": "0;0;1+0;0;0",
        "aff_country_unique": "United States;France"
    },
    {
        "title": "Online Linear Quadratic Control",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2142",
        "id": "2142",
        "author_site": "Alon Cohen, Avinatan Hasidim, Tomer Koren, Nevena Lazic, Yishay Mansour, Kunal Talwar",
        "author": "Alon Cohen; Avinatan Hasidim; Tomer Koren; Nevena Lazic; Yishay Mansour; Kunal Talwar",
        "abstract": "We study the problem of controlling linear time-invariant systems with known noisy dynamics and adversarially chosen quadratic losses. We present the first efficient online learning algorithms in this setting that guarantee $O(\\sqrt{T})$ regret under mild assumptions, where $T$ is the time horizon. Our algorithms rely on a novel SDP relaxation for the steady-state distribution of the system. Crucially, and in contrast to previously proposed relaxations, the feasible solutions of our SDP all correspond to \u201cstrongly stable\u201d policies that mix exponentially fast to a steady state.",
        "bibtex": "@InProceedings{pmlr-v80-cohen18b,\n  title = \t {Online Linear Quadratic Control},\n  author =       {Cohen, Alon and Hasidim, Avinatan and Koren, Tomer and Lazic, Nevena and Mansour, Yishay and Talwar, Kunal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1029--1038},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cohen18b/cohen18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cohen18b.html},\n  abstract = \t {We study the problem of controlling linear time-invariant systems with known noisy dynamics and adversarially chosen quadratic losses. We present the first efficient online learning algorithms in this setting that guarantee $O(\\sqrt{T})$ regret under mild assumptions, where $T$ is the time horizon. Our algorithms rely on a novel SDP relaxation for the steady-state distribution of the system. Crucially, and in contrast to previously proposed relaxations, the feasible solutions of our SDP all correspond to \u201cstrongly stable\u201d policies that mix exponentially fast to a steady state.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cohen18b/cohen18b.pdf",
        "supp": "",
        "pdf_size": 435212,
        "gs_citation": 169,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5894396538928709949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research, Tel Aviv + Technion\u2014Israel Inst. of Technology + Bar Ilan University; Google Research, Tel Aviv + Technion\u2014Israel Inst. of Technology + Bar Ilan University; Google Brain, Mountain View; Google Brain, Mountain View; Tel Aviv University + Google Research, Tel Aviv + Technion\u2014Israel Inst. of Technology + Bar Ilan University; Google Brain, Mountain View",
        "aff_domain": "google.com;google.com;google.com;google.com;tau.ac.il;google.com",
        "email": "google.com;google.com;google.com;google.com;tau.ac.il;google.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/cohen18b.html",
        "aff_unique_index": "0+1+2;0+1+2;0;0;3+0+1+2;0",
        "aff_unique_norm": "Google;Technion\u2014Israel Institute of Technology;Bar-Ilan University;Tel Aviv University",
        "aff_unique_dep": "Google Research;;;",
        "aff_unique_url": "https://research.google;https://www.technion.ac.il/en/;https://www.biu.ac.il;https://www.tau.ac.il",
        "aff_unique_abbr": "Google;Technion;BIU;TAU",
        "aff_campus_unique_index": "0;0;2;2;0;2",
        "aff_campus_unique": "Tel Aviv;;Mountain View",
        "aff_country_unique_index": "0+0+0;0+0+0;1;1;0+0+0+0;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "title": "Open Category Detection with PAC Guarantees",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2115",
        "id": "2115",
        "author_site": "Si Liu, Risheek Garrepalli, Thomas Dietterich, Alan Fern, Dan Hendrycks",
        "author": "Si Liu; Risheek Garrepalli; Thomas Dietterich; Alan Fern; Dan Hendrycks",
        "abstract": "Open category detection is the problem of detecting \"alien\" test instances that belong to categories or classes that were not present in the training data. In many applications, reliably detecting such aliens is central to ensuring the safety and accuracy of test set predictions. Unfortunately, there are no algorithms that provide theoretical guarantees on their ability to detect aliens under general assumptions. Further, while there are algorithms for open category detection, there are few empirical results that directly report alien detection rates. Thus, there are significant theoretical and empirical gaps in our understanding of open category detection. In this paper, we take a step toward addressing this gap by studying a simple, but practically-relevant variant of open category detection. In our setting, we are provided with a \"clean\" training set that contains only the target categories of interest and an unlabeled \"contaminated\u201d training set that contains a fraction alpha of alien examples. Under the assumption that we know an upper bound on alpha we develop an algorithm with PAC-style guarantees on the alien detection rate, while aiming to minimize false alarms. Empirical results on synthetic and standard benchmark datasets demonstrate the regimes in which the algorithm can be effective and provide a baseline for further advancements.",
        "bibtex": "@InProceedings{pmlr-v80-liu18e,\n  title = \t {Open Category Detection with {PAC} Guarantees},\n  author =       {Liu, Si and Garrepalli, Risheek and Dietterich, Thomas and Fern, Alan and Hendrycks, Dan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3169--3178},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18e/liu18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18e.html},\n  abstract = \t {Open category detection is the problem of detecting \"alien\" test instances that belong to categories or classes that were not present in the training data. In many applications, reliably detecting such aliens is central to ensuring the safety and accuracy of test set predictions. Unfortunately, there are no algorithms that provide theoretical guarantees on their ability to detect aliens under general assumptions. Further, while there are algorithms for open category detection, there are few empirical results that directly report alien detection rates. Thus, there are significant theoretical and empirical gaps in our understanding of open category detection. In this paper, we take a step toward addressing this gap by studying a simple, but practically-relevant variant of open category detection. In our setting, we are provided with a \"clean\" training set that contains only the target categories of interest and an unlabeled \"contaminated\u201d training set that contains a fraction alpha of alien examples. Under the assumption that we know an upper bound on alpha we develop an algorithm with PAC-style guarantees on the alien detection rate, while aiming to minimize false alarms. Empirical results on synthetic and standard benchmark datasets demonstrate the regimes in which the algorithm can be effective and provide a baseline for further advancements.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18e/liu18e.pdf",
        "supp": "",
        "pdf_size": 508093,
        "gs_citation": 115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16442088261883676309&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/liu18e.html"
    },
    {
        "title": "Optimal Distributed Learning with Multi-pass Stochastic Gradient Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2484",
        "id": "2484",
        "author_site": "Junhong Lin, Volkan Cevher",
        "author": "Junhong Lin; Volkan Cevher",
        "abstract": "We study generalization properties of distributed algorithms in the setting of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We investigate distributed stochastic gradient methods (SGM), with mini-batches and multi-passes over the data. We show that optimal generalization error bounds can be retained for distributed SGM provided that the partition level is not too large. Our results are superior to the state-of-the-art theory, covering the cases that the regression function may not be in the hypothesis spaces. Particularly, our results show that distributed SGM has a smaller theoretical computational complexity, compared with distributed kernel ridge regression (KRR) and classic SGM.",
        "bibtex": "@InProceedings{pmlr-v80-lin18a,\n  title = \t {Optimal Distributed Learning with Multi-pass Stochastic Gradient Methods},\n  author =       {Lin, Junhong and Cevher, Volkan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3092--3101},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lin18a/lin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lin18a.html},\n  abstract = \t {We study generalization properties of distributed algorithms in the setting of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We investigate distributed stochastic gradient methods (SGM), with mini-batches and multi-passes over the data. We show that optimal generalization error bounds can be retained for distributed SGM provided that the partition level is not too large. Our results are superior to the state-of-the-art theory, covering the cases that the regression function may not be in the hypothesis spaces. Particularly, our results show that distributed SGM has a smaller theoretical computational complexity, compared with distributed kernel ridge regression (KRR) and classic SGM.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lin18a/lin18a.pdf",
        "supp": "",
        "pdf_size": 447326,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5788001570848044564&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Laboratory for Information and Inference Systems, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Laboratory for Information and Inference Systems, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
        "aff_domain": "epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/lin18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Laboratory for Information and Inference Systems",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Optimal Rates of Sketched-regularized Algorithms for Least-Squares Regression over Hilbert Spaces",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2379",
        "id": "2379",
        "author_site": "Junhong Lin, Volkan Cevher",
        "author": "Junhong Lin; Volkan Cevher",
        "abstract": "We investigate regularized algorithms combining with projection for least-squares regression problem over a Hilbert space, covering nonparametric regression over a reproducing kernel Hilbert space. We prove convergence results with respect to variants of norms, under a capacity assumption on the hypothesis space and a regularity condition on the target function. As a result, we obtain optimal rates for regularized algorithms with randomized sketches, provided that the sketch dimension is proportional to the effective dimension up to a logarithmic factor. As a byproduct, we obtain similar results for Nystr\u00f6m regularized algorithms. Our results provide optimal, distribution-dependent rates for sketched/Nystr\u00f6m regularized algorithms, considering both the attainable and non-attainable cases.",
        "bibtex": "@InProceedings{pmlr-v80-lin18b,\n  title = \t {Optimal Rates of Sketched-regularized Algorithms for Least-Squares Regression over {H}ilbert Spaces},\n  author =       {Lin, Junhong and Cevher, Volkan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3102--3111},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lin18b/lin18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lin18b.html},\n  abstract = \t {We investigate regularized algorithms combining with projection for least-squares regression problem over a Hilbert space, covering nonparametric regression over a reproducing kernel Hilbert space. We prove convergence results with respect to variants of norms, under a capacity assumption on the hypothesis space and a regularity condition on the target function. As a result, we obtain optimal rates for regularized algorithms with randomized sketches, provided that the sketch dimension is proportional to the effective dimension up to a logarithmic factor. As a byproduct, we obtain similar results for Nystr\u00f6m regularized algorithms. Our results provide optimal, distribution-dependent rates for sketched/Nystr\u00f6m regularized algorithms, considering both the attainable and non-attainable cases.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lin18b/lin18b.pdf",
        "supp": "",
        "pdf_size": 331043,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17948344039689050112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Laboratory for Information and Inference Systems, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland; Laboratory for Information and Inference Systems, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
        "aff_domain": "epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/lin18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Laboratory for Information and Inference Systems",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Optimal Tuning for Divide-and-conquer Kernel Ridge Regression with Massive Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2205",
        "id": "2205",
        "author_site": "Ganggang Xu, Zuofeng Shang, Guang Cheng",
        "author": "Ganggang Xu; Zuofeng Shang; Guang Cheng",
        "abstract": "Divide-and-conquer is a powerful approach for large and massive data analysis. In the nonparameteric regression setting, although various theoretical frameworks have been established to achieve optimality in estimation or hypothesis testing, how to choose the tuning parameter in a practically effective way is still an open problem. In this paper, we propose a data-driven procedure based on divide-and-conquer for selecting the tuning parameters in kernel ridge regression by modifying the popular Generalized Cross-validation (GCV, Wahba, 1990). While the proposed criterion is computationally scalable for massive data sets, it is also shown under mild conditions to be asymptotically optimal in the sense that minimizing the proposed distributed-GCV (dGCV) criterion is equivalent to minimizing the true global conditional empirical loss of the averaged function estimator, extending the existing optimality results of GCV to the divide-and-conquer framework.",
        "bibtex": "@InProceedings{pmlr-v80-xu18f,\n  title = \t {Optimal Tuning for Divide-and-conquer Kernel Ridge Regression with Massive Data},\n  author =       {Xu, Ganggang and Shang, Zuofeng and Cheng, Guang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5483--5491},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18f/xu18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18f.html},\n  abstract = \t {Divide-and-conquer is a powerful approach for large and massive data analysis. In the nonparameteric regression setting, although various theoretical frameworks have been established to achieve optimality in estimation or hypothesis testing, how to choose the tuning parameter in a practically effective way is still an open problem. In this paper, we propose a data-driven procedure based on divide-and-conquer for selecting the tuning parameters in kernel ridge regression by modifying the popular Generalized Cross-validation (GCV, Wahba, 1990). While the proposed criterion is computationally scalable for massive data sets, it is also shown under mild conditions to be asymptotically optimal in the sense that minimizing the proposed distributed-GCV (dGCV) criterion is equivalent to minimizing the true global conditional empirical loss of the averaged function estimator, extending the existing optimality results of GCV to the divide-and-conquer framework.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18f/xu18f.pdf",
        "supp": "",
        "pdf_size": 332550,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11463436981705096286&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Mathematical Sciences, Binghamton University, the State University of New York, Binghamton, NY, USA; Department of Mathematical Sciences, IUPUI, Indianapolis, IN, USA; Department of Statistics, Purdue University, West Lafayette, IN, USA",
        "aff_domain": "math.binghamton.edu; ; ",
        "email": "math.binghamton.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/xu18f.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Binghamton University;Indiana University-Purdue University Indianapolis;Purdue University",
        "aff_unique_dep": "Department of Mathematical Sciences;Department of Mathematical Sciences;Department of Statistics",
        "aff_unique_url": "https://www.binghamton.edu;https://www.iupui.edu;https://www.purdue.edu",
        "aff_unique_abbr": "Binghamton U;IUPUI;Purdue",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Binghamton;Indianapolis;West Lafayette",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Optimization Landscape and Expressivity of Deep CNNs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2011",
        "id": "2011",
        "author_site": "Quynh Nguyen, Matthias Hein",
        "author": "Quynh Nguyen; Matthias Hein",
        "abstract": "We analyze the loss landscape and expressiveness of practical deep convolutional neural networks (CNNs) with shared weights and max pooling layers. We show that such CNNs produce linearly independent features at a \u201cwide\u201d layer which has more neurons than the number of training samples. This condition holds e.g. for the VGG network. Furthermore, we provide for such wide CNNs necessary and sufficient conditions for global minima with zero training error. For the case where the wide layer is followed by a fully connected layer we show that almost every critical point of the empirical loss is a global minimum with zero training error. Our analysis suggests that both depth and width are very important in deep learning. While depth brings more representational power and allows the network to learn high level features, width smoothes the optimization landscape of the loss function in the sense that a sufficiently wide network has a well-behaved loss surface with almost no bad local minima.",
        "bibtex": "@InProceedings{pmlr-v80-nguyen18a,\n  title = \t {Optimization Landscape and Expressivity of Deep {CNN}s},\n  author =       {Nguyen, Quynh and Hein, Matthias},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3730--3739},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nguyen18a/nguyen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nguyen18a.html},\n  abstract = \t {We analyze the loss landscape and expressiveness of practical deep convolutional neural networks (CNNs) with shared weights and max pooling layers. We show that such CNNs produce linearly independent features at a \u201cwide\u201d layer which has more neurons than the number of training samples. This condition holds e.g. for the VGG network. Furthermore, we provide for such wide CNNs necessary and sufficient conditions for global minima with zero training error. For the case where the wide layer is followed by a fully connected layer we show that almost every critical point of the empirical loss is a global minimum with zero training error. Our analysis suggests that both depth and width are very important in deep learning. While depth brings more representational power and allows the network to learn high level features, width smoothes the optimization landscape of the loss function in the sense that a sufficiently wide network has a well-behaved loss surface with almost no bad local minima.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nguyen18a/nguyen18a.pdf",
        "supp": "",
        "pdf_size": 352263,
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5467251945180601105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Mathematics and Computer Science, Saarland University, Germany; University of T\u00fcbingen, Germany",
        "aff_domain": "cs.uni-saarland.de; ",
        "email": "cs.uni-saarland.de; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/nguyen18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Saarland University;University of T\u00fcbingen",
        "aff_unique_dep": "Department of Mathematics and Computer Science;",
        "aff_unique_url": "https://www.uni-saarland.de;https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "Saarland U;Uni T\u00fcbingen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Optimization, fast and slow: optimally switching between local and Bayesian optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2224",
        "id": "2224",
        "author_site": "Mark McLeod, Stephen Roberts, Michael A Osborne",
        "author": "Mark McLeod; Stephen Roberts; Michael A. Osborne",
        "abstract": "We develop the first Bayesian Optimization algorithm, BLOSSOM, which selects between multiple alternative acquisition functions and traditional local optimization at each step. This is combined with a novel stopping condition based on expected regret. This pairing allows us to obtain the best characteristics of both local and Bayesian optimization, making efficient use of function evaluations while yielding superior convergence to the global minimum on a selection of optimization problems, and also halting optimization once a principled and intuitive stopping condition has been fulfilled.",
        "bibtex": "@InProceedings{pmlr-v80-mcleod18a,\n  title = \t {Optimization, fast and slow: optimally switching between local and {B}ayesian optimization},\n  author =       {McLeod, Mark and Roberts, Stephen and Osborne, Michael A.},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3443--3452},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mcleod18a/mcleod18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mcleod18a.html},\n  abstract = \t {We develop the first Bayesian Optimization algorithm, BLOSSOM, which selects between multiple alternative acquisition functions and traditional local optimization at each step. This is combined with a novel stopping condition based on expected regret. This pairing allows us to obtain the best characteristics of both local and Bayesian optimization, making efficient use of function evaluations while yielding superior convergence to the global minimum on a selection of optimization problems, and also halting optimization once a principled and intuitive stopping condition has been fulfilled.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mcleod18a/mcleod18a.pdf",
        "supp": "",
        "pdf_size": 895326,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6241493477815440111&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Engineering Science, University of Oxford + Oxford-Man Institute of Quantitative Finance; Department of Engineering Science, University of Oxford + Oxford-Man Institute of Quantitative Finance; Department of Engineering Science, University of Oxford + Oxford-Man Institute of Quantitative Finance",
        "aff_domain": "robots.ox.ac.uk; ; ",
        "email": "robots.ox.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mcleod18a.html",
        "aff_unique_index": "0+0;0+0;0+0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Optimizing the Latent Space of Generative Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2235",
        "id": "2235",
        "author_site": "Piotr Bojanowski, Armand Joulin, David Lopez-Paz, Arthur Szlam",
        "author": "Piotr Bojanowski; Armand Joulin; David Lopez-Pas; Arthur Szlam",
        "abstract": "Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images. In most successful applications, GAN models share two common aspects: solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions; and parameterizing the generator and the discriminator as deep convolutional neural networks. The goal of this paper is to disentangle the contribution of these two factors to the success of GANs. In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators using simple reconstruction losses. Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors; all of this without the adversarial optimization scheme.",
        "bibtex": "@InProceedings{pmlr-v80-bojanowski18a,\n  title = \t {Optimizing the Latent Space of Generative Networks},\n  author =       {Bojanowski, Piotr and Joulin, Armand and Lopez-Pas, David and Szlam, Arthur},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {600--609},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bojanowski18a/bojanowski18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bojanowski18a.html},\n  abstract = \t {Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images. In most successful applications, GAN models share two common aspects: solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions; and parameterizing the generator and the discriminator as deep convolutional neural networks. The goal of this paper is to disentangle the contribution of these two factors to the success of GANs. In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators using simple reconstruction losses. Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors; all of this without the adversarial optimization scheme.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bojanowski18a/bojanowski18a.pdf",
        "supp": "",
        "pdf_size": 8177727,
        "gs_citation": 543,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7705272916319621438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research",
        "aff_domain": "fb.com; ; ; ",
        "email": "fb.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/bojanowski18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Orthogonal Machine Learning: Power and Limitations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2409",
        "id": "2409",
        "author_site": "Ilias Zadik, Lester Mackey, Vasilis Syrgkanis",
        "author": "Lester Mackey; Vasilis Syrgkanis; Ilias Zadik",
        "abstract": "Double machine learning provides n^{1/2}-consistent estimates of parameters of interest even when high-dimensional or nonparametric nuisance parameters are estimated at an n^{-1/4} rate. The key is to employ Neyman-orthogonal moment equations which are first-order insensitive to perturbations in the nuisance parameters. We show that the n^{-1/4} requirement can be improved to n^{-1/(2k+2)} by employing a k-th order notion of orthogonality that grants robustness to more complex or higher-dimensional nuisance parameters. In the partially linear regression setting popular in causal inference, we show that we can construct second-order orthogonal moments if and only if the treatment residual is not normally distributed. Our proof relies on Stein\u2019s lemma and may be of independent interest. We conclude by demonstrating the robustness benefits of an explicit doubly-orthogonal estimation procedure for treatment effect.",
        "bibtex": "@InProceedings{pmlr-v80-mackey18a,\n  title = \t {Orthogonal Machine Learning: Power and Limitations},\n  author =       {Mackey, Lester and Syrgkanis, Vasilis and Zadik, Ilias},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3375--3383},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mackey18a/mackey18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mackey18a.html},\n  abstract = \t {Double machine learning provides n^{1/2}-consistent estimates of parameters of interest even when high-dimensional or nonparametric nuisance parameters are estimated at an n^{-1/4} rate. The key is to employ Neyman-orthogonal moment equations which are first-order insensitive to perturbations in the nuisance parameters. We show that the n^{-1/4} requirement can be improved to n^{-1/(2k+2)} by employing a k-th order notion of orthogonality that grants robustness to more complex or higher-dimensional nuisance parameters. In the partially linear regression setting popular in causal inference, we show that we can construct second-order orthogonal moments if and only if the treatment residual is not normally distributed. Our proof relies on Stein\u2019s lemma and may be of independent interest. We conclude by demonstrating the robustness benefits of an explicit doubly-orthogonal estimation procedure for treatment effect.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mackey18a/mackey18a.pdf",
        "supp": "",
        "pdf_size": 1205580,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5809392484253895551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Microsoft Research New England, USA; Microsoft Research New England, USA; Operations Research Center, MIT, USA",
        "aff_domain": "microsoft.com;microsoft.com;mit.edu",
        "email": "microsoft.com;microsoft.com;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mackey18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Microsoft;Massachusetts Institute of Technology",
        "aff_unique_dep": "Microsoft Research;Operations Research Center",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-new-england;https://web.mit.edu",
        "aff_unique_abbr": "MSR NE;MIT",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "New England;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Orthogonal Recurrent Neural Networks with Scaled Cayley Transform",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2397",
        "id": "2397",
        "author_site": "Kyle Helfrich, Devin Willmott, Qiang Ye",
        "author": "Kyle Helfrich; Devin Willmott; Qiang Ye",
        "abstract": "Recurrent Neural Networks (RNNs) are designed to handle sequential data but suffer from vanishing or exploding gradients. Recent work on Unitary Recurrent Neural Networks (uRNNs) have been used to address this issue and in some cases, exceed the capabilities of Long Short-Term Memory networks (LSTMs). We propose a simpler and novel update scheme to maintain orthogonal recurrent weight matrices without using complex valued matrices. This is done by parametrizing with a skew-symmetric matrix using the Cayley transform; such a parametrization is unable to represent matrices with negative one eigenvalues, but this limitation is overcome by scaling the recurrent weight matrix by a diagonal matrix consisting of ones and negative ones. The proposed training scheme involves a straightforward gradient calculation and update step. In several experiments, the proposed scaled Cayley orthogonal recurrent neural network (scoRNN) achieves superior results with fewer trainable parameters than other unitary RNNs.",
        "bibtex": "@InProceedings{pmlr-v80-helfrich18a,\n  title = \t {Orthogonal Recurrent Neural Networks with Scaled {C}ayley Transform},\n  author =       {Helfrich, Kyle and Willmott, Devin and Ye, Qiang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1969--1978},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/helfrich18a/helfrich18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/helfrich18a.html},\n  abstract = \t {Recurrent Neural Networks (RNNs) are designed to handle sequential data but suffer from vanishing or exploding gradients. Recent work on Unitary Recurrent Neural Networks (uRNNs) have been used to address this issue and in some cases, exceed the capabilities of Long Short-Term Memory networks (LSTMs). We propose a simpler and novel update scheme to maintain orthogonal recurrent weight matrices without using complex valued matrices. This is done by parametrizing with a skew-symmetric matrix using the Cayley transform; such a parametrization is unable to represent matrices with negative one eigenvalues, but this limitation is overcome by scaling the recurrent weight matrix by a diagonal matrix consisting of ones and negative ones. The proposed training scheme involves a straightforward gradient calculation and update step. In several experiments, the proposed scaled Cayley orthogonal recurrent neural network (scoRNN) achieves superior results with fewer trainable parameters than other unitary RNNs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/helfrich18a/helfrich18a.pdf",
        "supp": "",
        "pdf_size": 787767,
        "gs_citation": 162,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10576322947857760953&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Mathematics, University of Kentucky, Lexington, Kentucky, USA; Department of Mathematics, University of Kentucky, Lexington, Kentucky, USA; Department of Mathematics, University of Kentucky, Lexington, Kentucky, USA",
        "aff_domain": "uky.edu;uky.edu; ",
        "email": "uky.edu;uky.edu; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/helfrich18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Kentucky",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.uky.edu",
        "aff_unique_abbr": "UK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lexington",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1884",
        "id": "1884",
        "author_site": "Pengtao Xie, Wei Wu, Yichen Zhu, Eric Xing",
        "author": "Pengtao Xie; Wei Wu; Yichen Zhu; Eric Xing",
        "abstract": "Distance metric learning (DML), which learns a distance metric from labeled \"similar\" and \"dissimilar\" data pairs, is widely utilized. Recently, several works investigate orthogonality-promoting regularization (OPR), which encourages the projection vectors in DML to be close to being orthogonal, to achieve three effects: (1) high balancedness \u2013 achieving comparable performance on both frequent and infrequent classes; (2) high compactness \u2013 using a small number of projection vectors to achieve a \"good\" metric; (3) good generalizability \u2013 alleviating overfitting to training data. While showing promising results, these approaches suffer three problems. First, they involve solving non-convex optimization problems where achieving the global optimal is NP-hard. Second, it lacks a theoretical understanding why OPR can lead to balancedness. Third, the current generalization error analysis of OPR is not directly on the regularizer. In this paper, we address these three issues by (1) seeking convex relaxations of the original nonconvex problems so that the global optimal is guaranteed to be achievable; (2) providing a formal analysis on OPR\u2019s capability of promoting balancedness; (3) providing a theoretical analysis that directly reveals the relationship between OPR and generalization performance. Experiments on various datasets demonstrate that our convex methods are more effective in promoting balancedness, compactness, and generalization, and are computationally more efficient, compared with the nonconvex methods.",
        "bibtex": "@InProceedings{pmlr-v80-xie18a,\n  title = \t {Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis},\n  author =       {Xie, Pengtao and Wu, Wei and Zhu, Yichen and Xing, Eric},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5403--5412},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xie18a/xie18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xie18a.html},\n  abstract = \t {Distance metric learning (DML), which learns a distance metric from labeled \"similar\" and \"dissimilar\" data pairs, is widely utilized. Recently, several works investigate orthogonality-promoting regularization (OPR), which encourages the projection vectors in DML to be close to being orthogonal, to achieve three effects: (1) high balancedness \u2013 achieving comparable performance on both frequent and infrequent classes; (2) high compactness \u2013 using a small number of projection vectors to achieve a \"good\" metric; (3) good generalizability \u2013 alleviating overfitting to training data. While showing promising results, these approaches suffer three problems. First, they involve solving non-convex optimization problems where achieving the global optimal is NP-hard. Second, it lacks a theoretical understanding why OPR can lead to balancedness. Third, the current generalization error analysis of OPR is not directly on the regularizer. In this paper, we address these three issues by (1) seeking convex relaxations of the original nonconvex problems so that the global optimal is guaranteed to be achievable; (2) providing a formal analysis on OPR\u2019s capability of promoting balancedness; (3) providing a theoretical analysis that directly reveals the relationship between OPR and generalization performance. Experiments on various datasets demonstrate that our convex methods are more effective in promoting balancedness, compactness, and generalization, and are computationally more efficient, compared with the nonconvex methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xie18a/xie18a.pdf",
        "supp": "",
        "pdf_size": 343098,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8864487228051095703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Petuum Inc + School of Computer Science, Carnegie Mellon University; School of Computer Science, Carnegie Mellon University; School of Mathematical Sciences, Peking University; Petuum Inc + School of Computer Science, Carnegie Mellon University",
        "aff_domain": "petuum.com; ; ;petuum.com",
        "email": "petuum.com; ; ;petuum.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/xie18a.html",
        "aff_unique_index": "0+1;1;2;0+1",
        "aff_unique_norm": "Petuum Inc;Carnegie Mellon University;Peking University",
        "aff_unique_dep": ";School of Computer Science;School of Mathematical Sciences",
        "aff_unique_url": "https://www.petuum.com;https://www.cmu.edu;http://www.pku.edu.cn",
        "aff_unique_abbr": ";CMU;PKU",
        "aff_campus_unique_index": "1;1;2;1",
        "aff_campus_unique": ";Pittsburgh;Beijing",
        "aff_country_unique_index": "0+0;0;1;0+0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Out-of-sample extension of graph adjacency spectral embedding",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1937",
        "id": "1937",
        "author_site": "Keith Levin, Fred Roosta, Michael Mahoney, Carey Priebe",
        "author": "Keith Levin; Fred Roosta; Michael Mahoney; Carey Priebe",
        "abstract": "Many popular dimensionality reduction procedures have out-of-sample extensions, which allow a practitioner to apply a learned embedding to observations not seen in the initial training sample. In this work, we consider the problem of obtaining an out-of-sample extension for the adjacency spectral embedding, a procedure for embedding the vertices of a graph into Euclidean space. We present two different approaches to this problem, one based on a least-squares objective and the other based on a maximum-likelihood formulation. We show that if the graph of interest is drawn according to a certain latent position model called a random dot product graph, then both of these out-of-sample extensions estimate the true latent position of the out-of-sample vertex with the same error rate. Further, we prove a central limit theorem for the least-squares-based extension, showing that the estimate is asymptotically normal about the truth in the large-graph limit.",
        "bibtex": "@InProceedings{pmlr-v80-levin18a,\n  title = \t {Out-of-sample extension of graph adjacency spectral embedding},\n  author =       {Levin, Keith and Roosta, Fred and Mahoney, Michael and Priebe, Carey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2975--2984},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/levin18a/levin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/levin18a.html},\n  abstract = \t {Many popular dimensionality reduction procedures have out-of-sample extensions, which allow a practitioner to apply a learned embedding to observations not seen in the initial training sample. In this work, we consider the problem of obtaining an out-of-sample extension for the adjacency spectral embedding, a procedure for embedding the vertices of a graph into Euclidean space. We present two different approaches to this problem, one based on a least-squares objective and the other based on a maximum-likelihood formulation. We show that if the graph of interest is drawn according to a certain latent position model called a random dot product graph, then both of these out-of-sample extensions estimate the true latent position of the out-of-sample vertex with the same error rate. Further, we prove a central limit theorem for the least-squares-based extension, showing that the estimate is asymptotically normal about the truth in the large-graph limit.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/levin18a/levin18a.pdf",
        "supp": "",
        "pdf_size": 1468738,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8735422732724805055&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics, University of Michigan, USA; School of Mathematics and Physics, University of Queensland, Australia + International Computer Science Institute, Berkeley, USA + Department of Statistics, University of California at Berkeley, USA; International Computer Science Institute, Berkeley, USA + Department of Statistics, University of California at Berkeley, USA; Department of Applied Mathematics and Statistics, Johns Hopkins University, USA",
        "aff_domain": "umich.edu; ; ; ",
        "email": "umich.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/levin18a.html",
        "aff_unique_index": "0;1+2+3;2+3;4",
        "aff_unique_norm": "University of Michigan;University of Queensland;International Computer Science Institute;University of California, Berkeley;Johns Hopkins University",
        "aff_unique_dep": "Department of Statistics;School of Mathematics and Physics;;Department of Statistics;Department of Applied Mathematics and Statistics",
        "aff_unique_url": "https://www.umich.edu;https://www.uq.edu.au;https://www.icsi.berkeley.edu/;https://www.berkeley.edu;https://www.jhu.edu",
        "aff_unique_abbr": "UM;UQ;ICSI;UC Berkeley;JHU",
        "aff_campus_unique_index": "1+1;1+1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1+0+0;0+0;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "title": "Overcoming Catastrophic Forgetting with Hard Attention to the Task",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2155",
        "id": "2155",
        "author_site": "Joan Serr\u00e0, Didac Suris, Marius Miron, Alexandros Karatzoglou",
        "author": "Joan Serra; Didac Suris; Marius Miron; Alexandros Karatzoglou",
        "abstract": "Catastrophic forgetting occurs when a neural network loses the information learned in a previous task after training on subsequent tasks. This problem remains a hurdle for artificial intelligence systems with sequential learning capabilities. In this paper, we propose a task-based hard attention mechanism that preserves previous tasks\u2019 information without affecting the current task\u2019s learning. A hard attention mask is learned concurrently to every task, through stochastic gradient descent, and previous masks are exploited to condition such learning. We show that the proposed mechanism is effective for reducing catastrophic forgetting, cutting current rates by 45 to 80%. We also show that it is robust to different hyperparameter choices, and that it offers a number of monitoring capabilities. The approach features the possibility to control both the stability and compactness of the learned knowledge, which we believe makes it also attractive for online learning or network compression applications.",
        "bibtex": "@InProceedings{pmlr-v80-serra18a,\n  title = \t {Overcoming Catastrophic Forgetting with Hard Attention to the Task},\n  author =       {Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4548--4557},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/serra18a/serra18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/serra18a.html},\n  abstract = \t {Catastrophic forgetting occurs when a neural network loses the information learned in a previous task after training on subsequent tasks. This problem remains a hurdle for artificial intelligence systems with sequential learning capabilities. In this paper, we propose a task-based hard attention mechanism that preserves previous tasks\u2019 information without affecting the current task\u2019s learning. A hard attention mask is learned concurrently to every task, through stochastic gradient descent, and previous masks are exploited to condition such learning. We show that the proposed mechanism is effective for reducing catastrophic forgetting, cutting current rates by 45 to 80%. We also show that it is robust to different hyperparameter choices, and that it offers a number of monitoring capabilities. The approach features the possibility to control both the stability and compactness of the learned knowledge, which we believe makes it also attractive for online learning or network compression applications.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/serra18a/serra18a.pdf",
        "supp": "",
        "pdf_size": 2197711,
        "gs_citation": 1374,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11086231050694477723&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Telef\u00f3nica Research, Barcelona, Spain+Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain; Telef\u00f3nica Research, Barcelona, Spain+Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain+Universitat Pompeu Fabra, Barcelona, Spain; Telef\u00f3nica Research, Barcelona, Spain+Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain+Universitat Pompeu Fabra, Barcelona, Spain; Telef\u00f3nica Research, Barcelona, Spain+Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain+Universitat Pompeu Fabra, Barcelona, Spain",
        "aff_domain": "telefonica.com; ; ; ",
        "email": "telefonica.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/serra18a.html",
        "aff_unique_index": "0+1;0+1+2;0+1+2;0+1+2",
        "aff_unique_norm": "Telef\u00f3nica Research;Universitat Polit\u00e8cnica de Catalunya;Universitat Pompeu Fabra",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.telefonica.com/research;https://www.upc.edu;https://www.upf.edu/",
        "aff_unique_abbr": ";UPC;UPF",
        "aff_campus_unique_index": "0+0;0+0+0;0+0+0;0+0+0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0+0;0+0+0;0+0+0;0+0+0",
        "aff_country_unique": "Spain"
    },
    {
        "title": "PDE-Net: Learning PDEs from Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1934",
        "id": "1934",
        "author_site": "Zichao Long, Yiping Lu, Xianzhong Ma, Bin Dong",
        "author": "Zichao Long; Yiping Lu; Xianzhong Ma; Bin Dong",
        "abstract": "Partial differential equations (PDEs) play a prominent role in many disciplines of science and engineering. PDEs are commonly derived based on empirical observations. However, with the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models. Comparing with existing approaches, our approach has the most flexibility by learning both differential operators and the nonlinear response function of the underlying PDE model. A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network. These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory). Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.",
        "bibtex": "@InProceedings{pmlr-v80-long18a,\n  title = \t {{PDE}-Net: Learning {PDE}s from Data},\n  author =       {Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3208--3216},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/long18a/long18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/long18a.html},\n  abstract = \t {Partial differential equations (PDEs) play a prominent role in many disciplines of science and engineering. PDEs are commonly derived based on empirical observations. However, with the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models. Comparing with existing approaches, our approach has the most flexibility by learning both differential operators and the nonlinear response function of the underlying PDE model. A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network. These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory). Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/long18a/long18a.pdf",
        "supp": "",
        "pdf_size": 2442130,
        "gs_citation": 983,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12110088803814108713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "School of Mathematical Sciences, Peking University, Beijing, China+Beijing Computational Science Research Center, Beijing, China; School of Mathematical Sciences, Peking University, Beijing, China+Beijing Computational Science Research Center, Beijing, China; School of Mathematical Sciences, Peking University, Beijing, China+Beijing Computational Science Research Center, Beijing, China; Beijing International Center for Mathematical Research, Peking University, Beijing, China+Center for Data Science, Peking University+Laboratory for Biomedical Image Analysis, Beijing Institute of Big Data Research",
        "aff_domain": "pku.edu.cn;pku.edu.cn;pku.edu.cn;math.pku.edu.cn",
        "email": "pku.edu.cn;pku.edu.cn;pku.edu.cn;math.pku.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/long18a.html",
        "aff_unique_index": "0+1;0+1;0+1;0+0+2",
        "aff_unique_norm": "Peking University;Beijing Computational Science Research Center;Beijing Institute of Big Data Research",
        "aff_unique_dep": "School of Mathematical Sciences;;Laboratory for Biomedical Image Analysis",
        "aff_unique_url": "http://www.pku.edu.cn;;",
        "aff_unique_abbr": "PKU;;",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1978",
        "id": "1978",
        "author_site": "Paavo Parmas, Carl E Rasmussen, Jan Peters, Kenji Doya",
        "author": "Paavo Parmas; Carl Edward Rasmussen; Jan Peters; Kenji Doya",
        "abstract": "Previously, the exploding gradient problem has been explained to be central in deep learning and model-based reinforcement learning, because it causes numerical issues and instability in optimization. Our experiments in model-based reinforcement learning imply that the problem is not just a numerical issue, but it may be caused by a fundamental chaos-like nature of long chains of nonlinear computations. Not only do the magnitudes of the gradients become large, the direction of the gradients becomes essentially random. We show that reparameterization gradients suffer from the problem, while likelihood ratio gradients are robust. Using our insights, we develop a model-based policy search framework, Probabilistic Inference for Particle-Based Policy Search (PIPPS), which is easily extensible, and allows for almost arbitrary models and policies, while simultaneously matching the performance of previous data-efficient learning algorithms. Finally, we invent the total propagation algorithm, which efficiently computes a union over all pathwise derivative depths during a single backwards pass, automatically giving greater weight to estimators with lower variance, sometimes improving over reparameterization gradients by $10^6$ times.",
        "bibtex": "@InProceedings{pmlr-v80-parmas18a,\n  title = \t {{PIPPS}: Flexible Model-Based Policy Search Robust to the Curse of Chaos},\n  author =       {Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4065--4074},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/parmas18a/parmas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/parmas18a.html},\n  abstract = \t {Previously, the exploding gradient problem has been explained to be central in deep learning and model-based reinforcement learning, because it causes numerical issues and instability in optimization. Our experiments in model-based reinforcement learning imply that the problem is not just a numerical issue, but it may be caused by a fundamental chaos-like nature of long chains of nonlinear computations. Not only do the magnitudes of the gradients become large, the direction of the gradients becomes essentially random. We show that reparameterization gradients suffer from the problem, while likelihood ratio gradients are robust. Using our insights, we develop a model-based policy search framework, Probabilistic Inference for Particle-Based Policy Search (PIPPS), which is easily extensible, and allows for almost arbitrary models and policies, while simultaneously matching the performance of previous data-efficient learning algorithms. Finally, we invent the total propagation algorithm, which efficiently computes a union over all pathwise derivative depths during a single backwards pass, automatically giving greater weight to estimators with lower variance, sometimes improving over reparameterization gradients by $10^6$ times.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/parmas18a/parmas18a.pdf",
        "supp": "",
        "pdf_size": 2912817,
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8640168252000745898&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Okinawa Institute of Science and Technology Graduate University, Okinawa, Japan; University of Cambridge, Cambridge, UK; TU Darmstadt, Darmstadt, Germany+Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Okinawa Institute of Science and Technology Graduate University, Okinawa, Japan",
        "aff_domain": "oist.jp; ; ; ",
        "email": "oist.jp; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/parmas18a.html",
        "aff_unique_index": "0;1;2+3;0",
        "aff_unique_norm": "Okinawa Institute of Science and Technology Graduate University;University of Cambridge;Technische Universit\u00e4t Darmstadt;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.oist.jp;https://www.cam.ac.uk;https://www.tu-darmstadt.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "OIST;Cambridge;TU Darmstadt;MPI-IS",
        "aff_campus_unique_index": "0;1;2+3;0",
        "aff_campus_unique": "Okinawa;Cambridge;Darmstadt;T\u00fcbingen",
        "aff_country_unique_index": "0;1;2+2;0",
        "aff_country_unique": "Japan;United Kingdom;Germany"
    },
    {
        "title": "Parallel Bayesian Network Structure Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1918",
        "id": "1918",
        "author_site": "Tian Gao, Dennis Wei",
        "author": "Tian Gao; Dennis Wei",
        "abstract": "Recent advances in Bayesian Network (BN) structure learning have focused on local-to-global learning, where the graph structure is learned via one local subgraph at a time. As a natural progression, we investigate parallel learning of BN structures via multiple learning agents simultaneously, where each agent learns one local subgraph at a time. We find that parallel learning can reduce the number of subgraphs requiring structure learning by storing previously queried results and communicating (even partial) results among agents. More specifically, by using novel rules on query subset and superset inference, many subgraph structures can be inferred without learning. We provide a sound and complete parallel structure learning (PSL) algorithm, and demonstrate its improved efficiency over state-of-the-art single-thread learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-gao18b,\n  title = \t {Parallel {B}ayesian Network Structure Learning},\n  author =       {Gao, Tian and Wei, Dennis},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1685--1694},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gao18b/gao18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gao18b.html},\n  abstract = \t {Recent advances in Bayesian Network (BN) structure learning have focused on local-to-global learning, where the graph structure is learned via one local subgraph at a time. As a natural progression, we investigate parallel learning of BN structures via multiple learning agents simultaneously, where each agent learns one local subgraph at a time. We find that parallel learning can reduce the number of subgraphs requiring structure learning by storing previously queried results and communicating (even partial) results among agents. More specifically, by using novel rules on query subset and superset inference, many subgraph structures can be inferred without learning. We provide a sound and complete parallel structure learning (PSL) algorithm, and demonstrate its improved efficiency over state-of-the-art single-thread learning algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gao18b/gao18b.pdf",
        "supp": "",
        "pdf_size": 318806,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9907369494911988929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "IBM Research, Yorktown Heights, NY 10598 USA; IBM Research, Yorktown Heights, NY 10598 USA",
        "aff_domain": "us.ibm.com; ",
        "email": "us.ibm.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/gao18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "IBM",
        "aff_unique_dep": "IBM Research",
        "aff_unique_url": "https://www.ibm.com/research",
        "aff_unique_abbr": "IBM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Yorktown Heights",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Parallel WaveNet: Fast High-Fidelity Speech Synthesis",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2198",
        "id": "2198",
        "author_site": "A\u00e4ron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Koray Kavukcuoglu, George van den Driessche, Edward Lockhart, Luis C Cobo, Florian Stimberg, Norman Casagrande, Dominik Grewe, Seb Noury, Sander Dieleman, Erich Elsen, Nal Kalchbrenner, Heiga Zen, Alex Graves, Helen King, Tom Walters, Dan Belov, Demis Hassabis",
        "author": "Aaron Oord; Yazhe Li; Igor Babuschkin; Karen Simonyan; Oriol Vinyals; Koray Kavukcuoglu; George Driessche; Edward Lockhart; Luis Cobo; Florian Stimberg; Norman Casagrande; Dominik Grewe; Seb Noury; Sander Dieleman; Erich Elsen; Nal Kalchbrenner; Heiga Zen; Alex Graves; Helen King; Tom Walters; Dan Belov; Demis Hassabis",
        "abstract": "The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today\u2019s massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, a 1000x speed up relative to the original WaveNet, and capable of serving multiple English and Japanese voices in a production setting.",
        "bibtex": "@InProceedings{pmlr-v80-oord18a,\n  title = \t {Parallel {W}ave{N}et: Fast High-Fidelity Speech Synthesis},\n  author =       {van den Oord, Aaron and Li, Yazhe and Babuschkin, Igor and Simonyan, Karen and Vinyals, Oriol and Kavukcuoglu, Koray and van den Driessche, George and Lockhart, Edward and Cobo, Luis and Stimberg, Florian and Casagrande, Norman and Grewe, Dominik and Noury, Seb and Dieleman, Sander and Elsen, Erich and Kalchbrenner, Nal and Zen, Heiga and Graves, Alex and King, Helen and Walters, Tom and Belov, Dan and Hassabis, Demis},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3918--3926},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/oord18a/oord18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/oord18a.html},\n  abstract = \t {The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today\u2019s massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, a 1000x speed up relative to the original WaveNet, and capable of serving multiple English and Japanese voices in a production setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/oord18a/oord18a.pdf",
        "supp": "",
        "pdf_size": 431745,
        "gs_citation": 1053,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3067193348358118725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom; DeepMind Technologies, London, United Kingdom",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 22,
        "oa": "https://proceedings.mlr.press/v80/oord18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind Technologies",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Parallel and Streaming Algorithms for K-Core Decomposition",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2186",
        "id": "2186",
        "author_site": "Hossein Esfandiari, Silvio Lattanzi, Vahab Mirrokni",
        "author": "Hossein Esfandiari; Silvio Lattanzi; Vahab Mirrokni",
        "abstract": "The k-core decomposition is a fundamental primitive in many machine learning and data mining applications. We present the first distributed and the first streaming algorithms to compute and maintain an approximate k-core decomposition with provable guarantees. Our algorithms achieve rigorous bounds on space complexity while bounding the number of passes or number of rounds of computation. We do so by presenting a new powerful sketching technique for k-core decomposition, and then by showing it can be computed efficiently in both streaming and MapReduce models. Finally, we confirm the effectiveness of our sketching technique empirically on a number of publicly available graphs.",
        "bibtex": "@InProceedings{pmlr-v80-esfandiari18a,\n  title = \t {Parallel and Streaming Algorithms for K-Core Decomposition},\n  author =       {Esfandiari, Hossein and Lattanzi, Silvio and Mirrokni, Vahab},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1397--1406},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/esfandiari18a/esfandiari18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/esfandiari18a.html},\n  abstract = \t {The k-core decomposition is a fundamental primitive in many machine learning and data mining applications. We present the first distributed and the first streaming algorithms to compute and maintain an approximate k-core decomposition with provable guarantees. Our algorithms achieve rigorous bounds on space complexity while bounding the number of passes or number of rounds of computation. We do so by presenting a new powerful sketching technique for k-core decomposition, and then by showing it can be computed efficiently in both streaming and MapReduce models. Finally, we confirm the effectiveness of our sketching technique empirically on a number of publicly available graphs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/esfandiari18a/esfandiari18a.pdf",
        "supp": "",
        "pdf_size": 575086,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3762398224403365714&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; Google Research; Google Research",
        "aff_domain": "googol.com; ; ",
        "email": "googol.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/esfandiari18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Parameterized Algorithms for the Matrix Completion Problem",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2254",
        "id": "2254",
        "author_site": "Robert Ganian, DePaul Iyad Kanj, Sebastian Ordyniak, Stefan Szeider",
        "author": "Robert Ganian; Iyad Kanj; Sebastian Ordyniak; Stefan Szeider",
        "abstract": "We consider two matrix completion problems, in which we are given a matrix with missing entries and the task is to complete the matrix in a way that (1) minimizes the rank, or (2) minimizes the number of distinct rows. We study the parameterized complexity of the two aforementioned problems with respect to several parameters of interest, including the minimum number of matrix rows, columns, and rows plus columns needed to cover all missing entries. We obtain new algorithmic results showing that, for the bounded domain case, both problems are fixed-parameter tractable with respect to all aforementioned parameters. We complement these results with a lower-bound result for the unbounded domain case that rules out fixed-parameter tractability w.r.t. some of the parameters under consideration.",
        "bibtex": "@InProceedings{pmlr-v80-ganian18a,\n  title = \t {Parameterized Algorithms for the Matrix Completion Problem},\n  author =       {Ganian, Robert and Kanj, Iyad and Ordyniak, Sebastian and Szeider, Stefan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1656--1665},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ganian18a/ganian18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ganian18a.html},\n  abstract = \t {We consider two matrix completion problems, in which we are given a matrix with missing entries and the task is to complete the matrix in a way that (1) minimizes the rank, or (2) minimizes the number of distinct rows. We study the parameterized complexity of the two aforementioned problems with respect to several parameters of interest, including the minimum number of matrix rows, columns, and rows plus columns needed to cover all missing entries. We obtain new algorithmic results showing that, for the bounded domain case, both problems are fixed-parameter tractable with respect to all aforementioned parameters. We complement these results with a lower-bound result for the unbounded domain case that rules out fixed-parameter tractability w.r.t. some of the parameters under consideration.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ganian18a/ganian18a.pdf",
        "supp": "",
        "pdf_size": 334755,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1344799400300950847&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Algorithms and Complexity Group, TU Wien, Vienna, Austria; School of Computing, DePaul University, Chicago, USA; Algorithms Group, University of Sheffield, Sheffield, UK; Algorithms and Complexity Group, TU Wien, Vienna, Austria",
        "aff_domain": "gmail.com;cdm.depaul.edu;gmail.com;szeider.net",
        "email": "gmail.com;cdm.depaul.edu;gmail.com;szeider.net",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ganian18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "TU Wien;DePaul University;University of Sheffield",
        "aff_unique_dep": "Algorithms and Complexity Group;School of Computing;Algorithms Group",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.depaul.edu;https://www.sheffield.ac.uk",
        "aff_unique_abbr": "TU Wien;DePaul;Sheffield",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Vienna;Chicago;Sheffield",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Austria;United States;United Kingdom"
    },
    {
        "title": "Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2206",
        "id": "2206",
        "author_site": "Jan-Hendrik Lange, Andreas Karrenbauer, Bjoern Andres",
        "author": "Jan-Hendrik Lange; Andreas Karrenbauer; Bjoern Andres",
        "abstract": "Weighted correlation clustering is hard to solve and hard to approximate for general graphs. Its applications in network analysis and computer vision call for efficient algorithms. To this end, we make three contributions: We establish partial optimality conditions that can be checked efficiently, and doing so recursively solves the problem for series-parallel graphs to optimality, in linear time. We exploit the packing dual of the problem to compute a heuristic, but non-trivial lower bound faster than that of a canonical linear program relaxation. We introduce a re-weighting with the dual solution by which efficient local search algorithms converge to better feasible solutions. The effectiveness of our methods is demonstrated empirically on a number of benchmark instances.",
        "bibtex": "@InProceedings{pmlr-v80-lange18a,\n  title = \t {Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering},\n  author =       {Lange, Jan-Hendrik and Karrenbauer, Andreas and Andres, Bjoern},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2892--2901},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lange18a/lange18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lange18a.html},\n  abstract = \t {Weighted correlation clustering is hard to solve and hard to approximate for general graphs. Its applications in network analysis and computer vision call for efficient algorithms. To this end, we make three contributions: We establish partial optimality conditions that can be checked efficiently, and doing so recursively solves the problem for series-parallel graphs to optimality, in linear time. We exploit the packing dual of the problem to compute a heuristic, but non-trivial lower bound faster than that of a canonical linear program relaxation. We introduce a re-weighting with the dual solution by which efficient local search algorithms converge to better feasible solutions. The effectiveness of our methods is demonstrated empirically on a number of benchmark instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lange18a/lange18a.pdf",
        "supp": "",
        "pdf_size": 398961,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10719780778257370097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Max Planck Institute for Informatics, Saarbr\u00fccken, Germany+Saarland University, Saarbr\u00fccken, Germany; Max Planck Institute for Informatics, Saarbr\u00fccken, Germany; Bosch Center for AI, Renningen, Germany+University of T\u00fcbingen, Germany",
        "aff_domain": "mpi-inf.mpg.de; ; ",
        "email": "mpi-inf.mpg.de; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/lange18a.html",
        "aff_unique_index": "0+1;0;2+3",
        "aff_unique_norm": "Max Planck Institute for Informatics;Saarland University;Bosch Center for AI;University of T\u00fcbingen",
        "aff_unique_dep": ";;AI;",
        "aff_unique_url": "https://mpi-inf.mpg.de;https://www.uni-saarland.de;https://www.bosch.com/research/ai/;https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "MPII;UdS;BCAI;Uni T\u00fcbingen",
        "aff_campus_unique_index": "0+0;0;1",
        "aff_campus_unique": "Saarbr\u00fccken;Renningen;",
        "aff_country_unique_index": "0+0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Path Consistency Learning in Tsallis Entropy Regularized MDPs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2344",
        "id": "2344",
        "author_site": "Yinlam Chow, Ofir Nachum, Mohammad Ghavamzadeh",
        "author": "Yinlam Chow; Ofir Nachum; Mohammad Ghavamzadeh",
        "abstract": "We study the sparse entropy-regularized reinforcement learning (ERL) problem in which the entropy term is a special form of the Tsallis entropy. The optimal policy of this formulation is sparse, i.e., at each state, it has non-zero probability for only a small number of actions. This addresses the main drawback of the standard Shannon entropy-regularized RL (soft ERL) formulation, in which the optimal policy is softmax, and thus, may assign a non-negligible probability mass to non-optimal actions. This problem is aggravated as the number of actions is increased. In this paper, we follow the work of Nachum et al. (2017) in the soft ERL setting, and propose a class of novel path consistency learning (PCL) algorithms, called sparse PCL, for the sparse ERL problem that can work with both on-policy and off-policy data. We first derive a sparse consistency equation that specifies a relationship between the optimal value function and policy of the sparse ERL along any system trajectory. Crucially, a weak form of the converse is also true, and we quantify the sub-optimality of a policy which satisfies sparse consistency, and show that as we increase the number of actions, this sub-optimality is better than that of the soft ERL optimal policy. We then use this result to derive the sparse PCL algorithms. We empirically compare sparse PCL with its soft counterpart, and show its advantage, especially in problems with a large number of actions.",
        "bibtex": "@InProceedings{pmlr-v80-chow18a,\n  title = \t {Path Consistency Learning in {T}sallis Entropy Regularized {MDP}s},\n  author =       {Chow, Yinlam and Nachum, Ofir and Ghavamzadeh, Mohammad},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {979--988},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chow18a/chow18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chow18a.html},\n  abstract = \t {We study the sparse entropy-regularized reinforcement learning (ERL) problem in which the entropy term is a special form of the Tsallis entropy. The optimal policy of this formulation is sparse, i.e., at each state, it has non-zero probability for only a small number of actions. This addresses the main drawback of the standard Shannon entropy-regularized RL (soft ERL) formulation, in which the optimal policy is softmax, and thus, may assign a non-negligible probability mass to non-optimal actions. This problem is aggravated as the number of actions is increased. In this paper, we follow the work of Nachum et al. (2017) in the soft ERL setting, and propose a class of novel path consistency learning (PCL) algorithms, called sparse PCL, for the sparse ERL problem that can work with both on-policy and off-policy data. We first derive a sparse consistency equation that specifies a relationship between the optimal value function and policy of the sparse ERL along any system trajectory. Crucially, a weak form of the converse is also true, and we quantify the sub-optimality of a policy which satisfies sparse consistency, and show that as we increase the number of actions, this sub-optimality is better than that of the soft ERL optimal policy. We then use this result to derive the sparse PCL algorithms. We empirically compare sparse PCL with its soft counterpart, and show its advantage, especially in problems with a large number of actions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chow18a/chow18a.pdf",
        "supp": "",
        "pdf_size": 1613528,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16330089212099190685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Google Brain; DeepMind; DeepMind",
        "aff_domain": "google.com;google.com;deepmind.com",
        "email": "google.com;google.com;deepmind.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chow18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Google;DeepMind",
        "aff_unique_dep": "Google Brain;",
        "aff_unique_url": "https://brain.google.com;https://deepmind.com",
        "aff_unique_abbr": "Google Brain;DeepMind",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Path-Level Network Transformation for Efficient Architecture Search",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2208",
        "id": "2208",
        "author_site": "Han Cai, Jiacheng Yang, Weinan Zhang, Song Han, Yong Yu",
        "author": "Han Cai; Jiacheng Yang; Weinan Zhang; Song Han; Yong Yu",
        "abstract": "We introduce a new function-preserving transformation for efficient neural architecture search. This network transformation allows reusing previously trained networks and existing successful architectures that improves sample efficiency. We aim to address the limitation of current network transformation operations that can only perform layer-level architecture modifications, such as adding (pruning) filters or inserting (removing) a layer, which fails to change the topology of connection paths. Our proposed path-level transformation operations enable the meta-controller to modify the path topology of the given network while keeping the merits of reusing weights, and thus allow efficiently designing effective structures with complex path topologies like Inception models. We further propose a bidirectional tree-structured reinforcement learning meta-controller to explore a simple yet highly expressive tree-structured architecture space that can be viewed as a generalization of multi-branch architectures. We experimented on the image classification datasets with limited computational resources (about 200 GPU-hours), where we observed improved parameter efficiency and better test results (97.70% test accuracy on CIFAR-10 with 14.3M parameters and 74.6% top-1 accuracy on ImageNet in the mobile setting), demonstrating the effectiveness and transferability of our designed architectures.",
        "bibtex": "@InProceedings{pmlr-v80-cai18a,\n  title = \t {Path-Level Network Transformation for Efficient Architecture Search},\n  author =       {Cai, Han and Yang, Jiacheng and Zhang, Weinan and Han, Song and Yu, Yong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {678--687},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/cai18a/cai18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/cai18a.html},\n  abstract = \t {We introduce a new function-preserving transformation for efficient neural architecture search. This network transformation allows reusing previously trained networks and existing successful architectures that improves sample efficiency. We aim to address the limitation of current network transformation operations that can only perform layer-level architecture modifications, such as adding (pruning) filters or inserting (removing) a layer, which fails to change the topology of connection paths. Our proposed path-level transformation operations enable the meta-controller to modify the path topology of the given network while keeping the merits of reusing weights, and thus allow efficiently designing effective structures with complex path topologies like Inception models. We further propose a bidirectional tree-structured reinforcement learning meta-controller to explore a simple yet highly expressive tree-structured architecture space that can be viewed as a generalization of multi-branch architectures. We experimented on the image classification datasets with limited computational resources (about 200 GPU-hours), where we observed improved parameter efficiency and better test results (97.70% test accuracy on CIFAR-10 with 14.3M parameters and 74.6% top-1 accuracy on ImageNet in the mobile setting), demonstrating the effectiveness and transferability of our designed architectures.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/cai18a/cai18a.pdf",
        "supp": "",
        "pdf_size": 2611149,
        "gs_citation": 287,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17606554867892755331&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Massachusetts Institute of Technology; Shanghai Jiao Tong University",
        "aff_domain": "apex.sjtu.edu.cn; ; ; ; ",
        "email": "apex.sjtu.edu.cn; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/cai18a.html",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://web.mit.edu",
        "aff_unique_abbr": "SJTU;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Pathwise Derivatives Beyond the Reparameterization Trick",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2213",
        "id": "2213",
        "author_site": "Martin Jankowiak, Fritz Obermeyer",
        "author": "Martin Jankowiak; Fritz Obermeyer",
        "abstract": "We observe that gradients computed via the reparameterization trick are in direct correspondence with solutions of the transport equation in the formalism of optimal transport. We use this perspective to compute (approximate) pathwise gradients for probability distributions not directly amenable to the reparameterization trick: Gamma, Beta, and Dirichlet. We further observe that when the reparameterization trick is applied to the Cholesky-factorized multivariate Normal distribution, the resulting gradients are suboptimal in the sense of optimal transport. We derive the optimal gradients and show that they have reduced variance in a Gaussian Process regression task. We demonstrate with a variety of synthetic experiments and stochastic variational inference tasks that our pathwise gradients are competitive with other methods.",
        "bibtex": "@InProceedings{pmlr-v80-jankowiak18a,\n  title = \t {Pathwise Derivatives Beyond the Reparameterization Trick},\n  author =       {Jankowiak, Martin and Obermeyer, Fritz},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2235--2244},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jankowiak18a/jankowiak18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jankowiak18a.html},\n  abstract = \t {We observe that gradients computed via the reparameterization trick are in direct correspondence with solutions of the transport equation in the formalism of optimal transport. We use this perspective to compute (approximate) pathwise gradients for probability distributions not directly amenable to the reparameterization trick: Gamma, Beta, and Dirichlet. We further observe that when the reparameterization trick is applied to the Cholesky-factorized multivariate Normal distribution, the resulting gradients are suboptimal in the sense of optimal transport. We derive the optimal gradients and show that they have reduced variance in a Gaussian Process regression task. We demonstrate with a variety of synthetic experiments and stochastic variational inference tasks that our pathwise gradients are competitive with other methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jankowiak18a/jankowiak18a.pdf",
        "supp": "",
        "pdf_size": 5029928,
        "gs_citation": 140,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9424167058513547795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Uber AI Labs, San Francisco, USA; Uber AI Labs, San Francisco, USA",
        "aff_domain": "uber.com;uber.com",
        "email": "uber.com;uber.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/jankowiak18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Uber",
        "aff_unique_dep": "Uber AI Labs",
        "aff_unique_url": "https://www.uber.com",
        "aff_unique_abbr": "Uber",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Francisco",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "PixelSNAIL: An Improved Autoregressive Generative Model",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2296",
        "id": "2296",
        "author_site": "Xi Chen, Nikhil Mishra, Mostafa Rohaninejad, Pieter Abbeel",
        "author": "XI Chen; Nikhil Mishra; Mostafa Rohaninejad; Pieter Abbeel",
        "abstract": "Autoregressive generative models achieve the best results in density estimation tasks involving high dimensional data, such as images or audio. They pose density estimation as a sequence modeling task, where a recurrent neural network (RNN) models the conditional distribution over the next element conditioned on all previous elements. In this paradigm, the bottleneck is the extent to which the RNN can model long-range dependencies, and the most successful approaches rely on causal convolutions. Taking inspiration from recent work in meta reinforcement learning, where dealing with long-range dependencies is also essential, we introduce a new generative model architecture that combines causal convolutions with self attention. In this paper, we describe the resulting model and present state-of-the-art log-likelihood results on heavily benchmarked datasets: CIFAR-10, $32 \\times 32$ ImageNet and $64 \\times 64$ ImageNet. Our implementation will be made available at \\url{https://github.com/neocxi/pixelsnail-public}.",
        "bibtex": "@InProceedings{pmlr-v80-chen18h,\n  title = \t {{P}ixel{SNAIL}: An Improved Autoregressive Generative Model},\n  author =       {Chen, XI and Mishra, Nikhil and Rohaninejad, Mostafa and Abbeel, Pieter},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {864--872},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18h/chen18h.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18h.html},\n  abstract = \t {Autoregressive generative models achieve the best results in density estimation tasks involving high dimensional data, such as images or audio. They pose density estimation as a sequence modeling task, where a recurrent neural network (RNN) models the conditional distribution over the next element conditioned on all previous elements. In this paradigm, the bottleneck is the extent to which the RNN can model long-range dependencies, and the most successful approaches rely on causal convolutions. Taking inspiration from recent work in meta reinforcement learning, where dealing with long-range dependencies is also essential, we introduce a new generative model architecture that combines causal convolutions with self attention. In this paper, we describe the resulting model and present state-of-the-art log-likelihood results on heavily benchmarked datasets: CIFAR-10, $32 \\times 32$ ImageNet and $64 \\times 64$ ImageNet. Our implementation will be made available at \\url{https://github.com/neocxi/pixelsnail-public}.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18h/chen18h.pdf",
        "supp": "",
        "pdf_size": 1217978,
        "gs_citation": 335,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3510281947390800354&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "covariant.ai+UC Berkeley, EECS Dept.; covariant.ai+UC Berkeley, EECS Dept.; covariant.ai+UC Berkeley, EECS Dept.; covariant.ai+UC Berkeley, EECS Dept.",
        "aff_domain": "covariant.ai; ; ; ",
        "email": "covariant.ai; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/chen18h.html",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "Covariant AI;University of California, Berkeley",
        "aff_unique_dep": ";Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.covariant.ai;https://www.berkeley.edu",
        "aff_unique_abbr": "Covariant AI;UC Berkeley",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Policy Optimization as Wasserstein Gradient Flows",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2121",
        "id": "2121",
        "author_site": "RUIYI (ROY) ZHANG, Changyou Chen, Chunyuan Li, Lawrence Carin",
        "author": "Ruiyi Zhang; Changyou Chen; Chunyuan Li; Lawrence Carin",
        "abstract": "Policy optimization is a core component of reinforcement learning (RL), and most existing RL methods directly optimize parameters of a policy based on maximizing the expected total reward, or its surrogate. Though often achieving encouraging empirical success, its correspondence to policy-distribution optimization has been unclear mathematically. We place policy optimization into the space of probability measures, and interpret it as Wasserstein gradient flows. On the probability-measure space, under specified circumstances, policy optimization becomes convex in terms of distribution optimization. To make optimization feasible, we develop efficient algorithms by numerically solving the corresponding discrete gradient flows. Our technique is applicable to several RL settings, and is related to many state-of-the-art policy-optimization algorithms. Specifically, we define gradient flows on both the parameter-distribution space and policy-distribution space, leading to what we term indirect-policy and direct-policy learning frameworks, respectively. Extensive experiments verify the effectiveness of our framework, often obtaining better performance compared to related algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18a,\n  title = \t {Policy Optimization as {W}asserstein Gradient Flows},\n  author =       {Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Carin, Lawrence},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5737--5746},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18a/zhang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18a.html},\n  abstract = \t {Policy optimization is a core component of reinforcement learning (RL), and most existing RL methods directly optimize parameters of a policy based on maximizing the expected total reward, or its surrogate. Though often achieving encouraging empirical success, its correspondence to policy-distribution optimization has been unclear mathematically. We place policy optimization into the space of probability measures, and interpret it as Wasserstein gradient flows. On the probability-measure space, under specified circumstances, policy optimization becomes convex in terms of distribution optimization. To make optimization feasible, we develop efficient algorithms by numerically solving the corresponding discrete gradient flows. Our technique is applicable to several RL settings, and is related to many state-of-the-art policy-optimization algorithms. Specifically, we define gradient flows on both the parameter-distribution space and policy-distribution space, leading to what we term indirect-policy and direct-policy learning frameworks, respectively. Extensive experiments verify the effectiveness of our framework, often obtaining better performance compared to related algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18a/zhang18a.pdf",
        "supp": "",
        "pdf_size": 1738322,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9982196800712758478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Duke University; SUNY at Buffalo; Duke University; Duke University",
        "aff_domain": "duke.edu;gmail.com;duke.edu;duke.edu",
        "email": "duke.edu;gmail.com;duke.edu;duke.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/zhang18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Duke University;State University of New York at Buffalo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.duke.edu;https://www.buffalo.edu",
        "aff_unique_abbr": "Duke;SUNY Buffalo",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Buffalo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Policy Optimization with Demonstrations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1956",
        "id": "1956",
        "author_site": "Bingyi Kang, Zequn Jie, Jiashi Feng",
        "author": "Bingyi Kang; Zequn Jie; Jiashi Feng",
        "abstract": "Exploration remains a significant challenge to reinforcement learning methods, especially in environments where reward signals are sparse. Recent methods of learning from demonstrations have shown to be promising in overcoming exploration difficulties but typically require considerable high-quality demonstrations that are difficult to collect. We propose to effectively leverage available demonstrations to guide exploration through enforcing occupancy measure matching between the learned policy and current demonstrations, and develop a novel Policy Optimization from Demonstration (POfD) method. We show that POfD induces implicit dynamic reward shaping and brings provable benefits for policy improvement. Furthermore, it can be combined with policy gradient methods to produce state-of-the-art results, as demonstrated experimentally on a range of popular benchmark sparse-reward tasks, even when the demonstrations are few and imperfect.",
        "bibtex": "@InProceedings{pmlr-v80-kang18a,\n  title = \t {Policy Optimization with Demonstrations},\n  author =       {Kang, Bingyi and Jie, Zequn and Feng, Jiashi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2469--2478},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kang18a/kang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kang18a.html},\n  abstract = \t {Exploration remains a significant challenge to reinforcement learning methods, especially in environments where reward signals are sparse. Recent methods of learning from demonstrations have shown to be promising in overcoming exploration difficulties but typically require considerable high-quality demonstrations that are difficult to collect. We propose to effectively leverage available demonstrations to guide exploration through enforcing occupancy measure matching between the learned policy and current demonstrations, and develop a novel Policy Optimization from Demonstration (POfD) method. We show that POfD induces implicit dynamic reward shaping and brings provable benefits for policy improvement. Furthermore, it can be combined with policy gradient methods to produce state-of-the-art results, as demonstrated experimentally on a range of popular benchmark sparse-reward tasks, even when the demonstrations are few and imperfect.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kang18a/kang18a.pdf",
        "supp": "",
        "pdf_size": 1505573,
        "gs_citation": 203,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=990958762973910318&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Tencent AI Lab, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore",
        "aff_domain": "u.nus.edu; ; ",
        "email": "u.nus.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kang18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "National University of Singapore;Tencent",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Tencent AI Lab",
        "aff_unique_url": "https://www.nus.edu.sg;https://ai.tencent.com",
        "aff_unique_abbr": "NUS;Tencent AI Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "title": "Policy and Value Transfer in Lifelong Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2271",
        "id": "2271",
        "author_site": "David Abel, Yuu Jinnai, Sophie Guo, George Konidaris, Michael L. Littman",
        "author": "David Abel; Yuu Jinnai; Sophie Yue Guo; George Konidaris; Michael Littman",
        "abstract": "We consider the problem of how best to use prior experience to bootstrap lifelong learning, where an agent faces a series of task instances drawn from some task distribution. First, we identify the initial policy that optimizes expected performance over the distribution of tasks for increasingly complex classes of policy and task distributions. We empirically demonstrate the relative performance of each policy class\u2019 optimal element in a variety of simple task distributions. We then consider value-function initialization methods that preserve PAC guarantees while simultaneously minimizing the learning required in two learning algorithms, yielding MaxQInit, a practical new method for value-function-based transfer. We show that MaxQInit performs well in simple lifelong RL experiments.",
        "bibtex": "@InProceedings{pmlr-v80-abel18b,\n  title = \t {Policy and Value Transfer in Lifelong Reinforcement Learning},\n  author =       {Abel, David and Jinnai, Yuu and Guo, Sophie Yue and Konidaris, George and Littman, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {20--29},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/abel18b/abel18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/abel18b.html},\n  abstract = \t {We consider the problem of how best to use prior experience to bootstrap lifelong learning, where an agent faces a series of task instances drawn from some task distribution. First, we identify the initial policy that optimizes expected performance over the distribution of tasks for increasingly complex classes of policy and task distributions. We empirically demonstrate the relative performance of each policy class\u2019 optimal element in a variety of simple task distributions. We then consider value-function initialization methods that preserve PAC guarantees while simultaneously minimizing the learning required in two learning algorithms, yielding MaxQInit, a practical new method for value-function-based transfer. We show that MaxQInit performs well in simple lifelong RL experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/abel18b/abel18b.pdf",
        "supp": "",
        "pdf_size": 2015759,
        "gs_citation": 109,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9527993441219720147&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University",
        "aff_domain": "brown.edu;brown.edu; ; ; ",
        "email": "brown.edu;brown.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/abel18b.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Practical Contextual Bandits with Regression Oracles",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2475",
        "id": "2475",
        "author_site": "Dylan Foster, Alekh Agarwal, Miroslav Dudik, Haipeng Luo, Robert Schapire",
        "author": "Dylan Foster; Alekh Agarwal; Miroslav Dudik; Haipeng Luo; Robert Schapire",
        "abstract": "A major challenge in contextual bandits is to design general-purpose algorithms that are both practically useful and theoretically well-founded. We present a new technique that has the empirical and computational advantages of realizability-based approaches combined with the flexibility of agnostic methods. Our algorithms leverage the availability of a regression oracle for the value-function class, a more realistic and reasonable oracle than the classification oracles over policies typically assumed by agnostic methods. Our approach generalizes both UCB and LinUCB to far more expressive possible model classes and achieves low regret under certain distributional assumptions. In an extensive empirical evaluation, we find that our approach typically matches or outperforms both realizability-based and agnostic baselines.",
        "bibtex": "@InProceedings{pmlr-v80-foster18a,\n  title = \t {Practical Contextual Bandits with Regression Oracles},\n  author =       {Foster, Dylan and Agarwal, Alekh and Dudik, Miroslav and Luo, Haipeng and Schapire, Robert},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1539--1548},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/foster18a/foster18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/foster18a.html},\n  abstract = \t {A major challenge in contextual bandits is to design general-purpose algorithms that are both practically useful and theoretically well-founded. We present a new technique that has the empirical and computational advantages of realizability-based approaches combined with the flexibility of agnostic methods. Our algorithms leverage the availability of a regression oracle for the value-function class, a more realistic and reasonable oracle than the classification oracles over policies typically assumed by agnostic methods. Our approach generalizes both UCB and LinUCB to far more expressive possible model classes and achieves low regret under certain distributional assumptions. In an extensive empirical evaluation, we find that our approach typically matches or outperforms both realizability-based and agnostic baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/foster18a/foster18a.pdf",
        "supp": "",
        "pdf_size": 2336445,
        "gs_citation": 156,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2636976660780914362&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Cornell University; Microsoft Research; Microsoft Research; University of Southern California; Microsoft Research",
        "aff_domain": "cornell.edu; ; ; ; ",
        "email": "cornell.edu; ; ; ; ",
        "github": "",
        "project": "http://hunch.net/~rwil/",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/foster18a.html",
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Cornell University;Microsoft;University of Southern California",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://www.cornell.edu;https://www.microsoft.com/en-us/research;https://www.usc.edu",
        "aff_unique_abbr": "Cornell;MSR;USC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1967",
        "id": "1967",
        "author_site": "Yunbo Wang, Zhifeng Gao, Mingsheng Long, Jianmin Wang, Philip Yu",
        "author": "Yunbo Wang; Zhifeng Gao; Mingsheng Long; Jianmin Wang; Philip S Yu",
        "abstract": "We present PredRNN++, a recurrent network for spatiotemporal predictive learning. In pursuit of a great modeling capability for short-term video dynamics, we make our network deeper in time by leveraging a new recurrent structure named Causal LSTM with cascaded dual memories. To alleviate the gradient propagation difficulties in deep predictive models, we propose a Gradient Highway Unit, which provides alternative quick routes for the gradient flows from outputs back to long-range previous inputs. The gradient highway units work seamlessly with the causal LSTMs, enabling our model to capture the short-term and the long-term video dependencies adaptively. Our model achieves state-of-the-art prediction results on both synthetic and real video datasets, showing its power in modeling entangled motions.",
        "bibtex": "@InProceedings{pmlr-v80-wang18b,\n  title = \t {{P}red{RNN}++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning},\n  author =       {Wang, Yunbo and Gao, Zhifeng and Long, Mingsheng and Wang, Jianmin and Yu, Philip S},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5123--5132},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18b/wang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18b.html},\n  abstract = \t {We present PredRNN++, a recurrent network for spatiotemporal predictive learning. In pursuit of a great modeling capability for short-term video dynamics, we make our network deeper in time by leveraging a new recurrent structure named Causal LSTM with cascaded dual memories. To alleviate the gradient propagation difficulties in deep predictive models, we propose a Gradient Highway Unit, which provides alternative quick routes for the gradient flows from outputs back to long-range previous inputs. The gradient highway units work seamlessly with the causal LSTMs, enabling our model to capture the short-term and the long-term video dependencies adaptively. Our model achieves state-of-the-art prediction results on both synthetic and real video datasets, showing its power in modeling entangled motions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18b/wang18b.pdf",
        "supp": "",
        "pdf_size": 3823245,
        "gs_citation": 706,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16975551372418150051&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China",
        "aff_domain": "mails.tsinghua.edu.cn; ;tsinghua.edu.cn; ; ",
        "email": "mails.tsinghua.edu.cn; ;tsinghua.edu.cn; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/wang18b.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "School of Software",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Predict and Constrain: Modeling Cardinality in Deep Structured Prediction",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2368",
        "id": "2368",
        "author_site": "Nataly Brukhim, Amir Globerson",
        "author": "Nataly Brukhim; Amir Globerson",
        "abstract": "Many machine learning problems require the prediction of multi-dimensional labels. Such structured prediction models can benefit from modeling dependencies between labels. Recently, several deep learning approaches to structured prediction have been proposed. Here we focus on capturing cardinality constraints in such models. Namely, constraining the number of non-zero labels that the model outputs. Such constraints have proven very useful in previous structured prediction methods, but it is a challenge to introduce them into a deep learning approach. Here we show how to do this via a novel deep architecture. Our approach outperforms strong baselines, achieving state-of-the-art results on multi-label classification benchmarks.",
        "bibtex": "@InProceedings{pmlr-v80-brukhim18a,\n  title = \t {Predict and Constrain: Modeling Cardinality in Deep Structured Prediction},\n  author =       {Brukhim, Nataly and Globerson, Amir},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {659--667},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/brukhim18a/brukhim18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/brukhim18a.html},\n  abstract = \t {Many machine learning problems require the prediction of multi-dimensional labels. Such structured prediction models can benefit from modeling dependencies between labels. Recently, several deep learning approaches to structured prediction have been proposed. Here we focus on capturing cardinality constraints in such models. Namely, constraining the number of non-zero labels that the model outputs. Such constraints have proven very useful in previous structured prediction methods, but it is a challenge to introduce them into a deep learning approach. Here we show how to do this via a novel deep architecture. Our approach outperforms strong baselines, achieving state-of-the-art results on multi-label classification benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/brukhim18a/brukhim18a.pdf",
        "supp": "",
        "pdf_size": 346921,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5160891839675039776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Tel Aviv University, Blavatnik School of Computer Science; Tel Aviv University, Blavatnik School of Computer Science",
        "aff_domain": "mail.tau.ac.il;post.tau.ac.il",
        "email": "mail.tau.ac.il;post.tau.ac.il",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/brukhim18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tel Aviv University",
        "aff_unique_dep": "Blavatnik School of Computer Science",
        "aff_unique_url": "https://www.tau.ac.il",
        "aff_unique_abbr": "TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Prediction Rule Reshaping",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2222",
        "id": "2222",
        "author_site": "Matt Bonakdarpour, Sabyasachi Chatterjee, Rina Barber, John Lafferty",
        "author": "Matt Bonakdarpour; Sabyasachi Chatterjee; Rina Foygel Barber; John Lafferty",
        "abstract": "Two methods are proposed for high-dimensional shape-constrained regression and classification. These methods reshape pre-trained prediction rules to satisfy shape constraints like monotonicity and convexity. The first method can be applied to any pre-trained prediction rule, while the second method deals specifically with random forests. In both cases, efficient algorithms are developed for computing the estimators, and experiments are performed to demonstrate their performance on four datasets. We find that reshaping methods enforce shape constraints without compromising predictive accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-bonakdarpour18a,\n  title = \t {Prediction Rule Reshaping},\n  author =       {Bonakdarpour, Matt and Chatterjee, Sabyasachi and Barber, Rina Foygel and Lafferty, John},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {630--638},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bonakdarpour18a/bonakdarpour18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bonakdarpour18a.html},\n  abstract = \t {Two methods are proposed for high-dimensional shape-constrained regression and classification. These methods reshape pre-trained prediction rules to satisfy shape constraints like monotonicity and convexity. The first method can be applied to any pre-trained prediction rule, while the second method deals specifically with random forests. In both cases, efficient algorithms are developed for computing the estimators, and experiments are performed to demonstrate their performance on four datasets. We find that reshaping methods enforce shape constraints without compromising predictive accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bonakdarpour18a/bonakdarpour18a.pdf",
        "supp": "",
        "pdf_size": 271715,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9459314451240648886&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, The University of Chicago; Department of Statistics, University of Illinois at Urbana-Champaign; Department of Statistics, The University of Chicago; Department of Statistics and Data Science, Yale University",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/bonakdarpour18a.html",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Chicago;University of Illinois Urbana-Champaign;Yale University",
        "aff_unique_dep": "Department of Statistics;Department of Statistics;Department of Statistics and Data Science",
        "aff_unique_url": "https://www.uchicago.edu;https://illinois.edu;https://www.yale.edu",
        "aff_unique_abbr": "UChicago;UIUC;Yale",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2241",
        "id": "2241",
        "author_site": "Michael Kearns, Seth Neel, Aaron Roth, Steven Wu",
        "author": "Michael Kearns; Seth Neel; Aaron Roth; Zhiwei Steven Wu",
        "abstract": "The most prevalent notions of fairness in machine learning fix a small collection of pre-defined groups (such as race or gender), and then ask for approximate parity of some statistic of the classifier (such as false positive rate) across these groups. Constraints of this form are susceptible to fairness gerrymandering, in which a classifier is fair on each individual group, but badly violates the fairness constraint on structured subgroups, such as certain combinations of protected attribute values. We thus consider fairness across exponentially or infinitely many subgroups, defined by a structured class of functions over the protected attributes. We first prove that the problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is computationally equivalent to the problem of weak agnostic learning \u2014 which means it is hard in the worst case, even for simple structured subclasses. However, it also suggests that common heuristics for learning can be applied to successfully solve the auditing problem in practice. We then derive an algorithm that provably converges in a polynomial number of steps to the best subgroup-fair distribution over classifiers, given access to an oracle which can solve the agnostic learning problem. The algorithm is based on a formulation of subgroup fairness as a zero-sum game between a Learner (the primal player) and an Auditor (the dual player). We implement a variant of this algorithm using heuristic oracles, and show that we can effectively both audit and learn fair classifiers on a real dataset.",
        "bibtex": "@InProceedings{pmlr-v80-kearns18a,\n  title = \t {Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness},\n  author =       {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2564--2572},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kearns18a/kearns18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kearns18a.html},\n  abstract = \t {The most prevalent notions of fairness in machine learning fix a small collection of pre-defined groups (such as race or gender), and then ask for approximate parity of some statistic of the classifier (such as false positive rate) across these groups. Constraints of this form are susceptible to fairness gerrymandering, in which a classifier is fair on each individual group, but badly violates the fairness constraint on structured subgroups, such as certain combinations of protected attribute values. We thus consider fairness across exponentially or infinitely many subgroups, defined by a structured class of functions over the protected attributes. We first prove that the problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is computationally equivalent to the problem of weak agnostic learning \u2014 which means it is hard in the worst case, even for simple structured subclasses. However, it also suggests that common heuristics for learning can be applied to successfully solve the auditing problem in practice. We then derive an algorithm that provably converges in a polynomial number of steps to the best subgroup-fair distribution over classifiers, given access to an oracle which can solve the agnostic learning problem. The algorithm is based on a formulation of subgroup fairness as a zero-sum game between a Learner (the primal player) and an Auditor (the dual player). We implement a variant of this algorithm using heuristic oracles, and show that we can effectively both audit and learn fair classifiers on a real dataset.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kearns18a/kearns18a.pdf",
        "supp": "",
        "pdf_size": 549495,
        "gs_citation": 1028,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15519719606954445162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of Pennsylvania; University of Pennsylvania; University of Pennsylvania; Microsoft Research",
        "aff_domain": "cis.upenn.edu;wharton.upenn.edu;cis.upenn.edu;gmail.com",
        "email": "cis.upenn.edu;wharton.upenn.edu;cis.upenn.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/kearns18a.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Pennsylvania;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.upenn.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "UPenn;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Probabilistic Boolean Tensor Decomposition",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1988",
        "id": "1988",
        "author_site": "Tammo Rukat, Christopher Holmes, Christopher Yau",
        "author": "Tammo Rukat; Chris Holmes; Christopher Yau",
        "abstract": "Boolean tensor decomposition approximates data of multi-way binary relationships as product of interpretable low-rank binary factors, following the rules Boolean algebra. Here, we present its first probabilistic treatment. We facilitate scalable sampling-based posterior inference by exploitation of the combinatorial structure of the factor conditionals. Maximum a posteriori estimates consistently outperform existing non-probabilistic approaches. We show that our performance gains can partially be explained by convergence to solutions that occupy relatively large regions of the parameter space, as well as by implicit model averaging. Moreover, the Bayesian treatment facilitates model selection with much greater accuracy than the previously suggested minimum description length based approach. We investigate three real-world data sets. First, temporal interaction networks and behavioural data of university students demonstrate the inference of instructive latent patterns. Next, we decompose a tensor with more than 10 Billion data points, indicating relations of gene expression in cancer patients. Not only does this demonstrate scalability, it also provides an entirely novel perspective on relational properties of continuous data and, in the present example, on the molecular heterogeneity of cancer. Our implementation is available on GitHub: https://github.com/TammoR/LogicalFactorisationMachines",
        "bibtex": "@InProceedings{pmlr-v80-rukat18a,\n  title = \t {Probabilistic Boolean Tensor Decomposition},\n  author =       {Rukat, Tammo and Holmes, Chris and Yau, Christopher},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4413--4422},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rukat18a/rukat18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rukat18a.html},\n  abstract = \t {Boolean tensor decomposition approximates data of multi-way binary relationships as product of interpretable low-rank binary factors, following the rules Boolean algebra. Here, we present its first probabilistic treatment. We facilitate scalable sampling-based posterior inference by exploitation of the combinatorial structure of the factor conditionals. Maximum a posteriori estimates consistently outperform existing non-probabilistic approaches. We show that our performance gains can partially be explained by convergence to solutions that occupy relatively large regions of the parameter space, as well as by implicit model averaging. Moreover, the Bayesian treatment facilitates model selection with much greater accuracy than the previously suggested minimum description length based approach. We investigate three real-world data sets. First, temporal interaction networks and behavioural data of university students demonstrate the inference of instructive latent patterns. Next, we decompose a tensor with more than 10 Billion data points, indicating relations of gene expression in cancer patients. Not only does this demonstrate scalability, it also provides an entirely novel perspective on relational properties of continuous data and, in the present example, on the molecular heterogeneity of cancer. Our implementation is available on GitHub: https://github.com/TammoR/LogicalFactorisationMachines}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rukat18a/rukat18a.pdf",
        "supp": "",
        "pdf_size": 2875832,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11732429422199282970&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistics, University of Oxford, UK+The Alan Turing Institute, London, UK; Department of Statistics, University of Oxford, UK+The Alan Turing Institute, London, UK; Centre for Computational Biology, Institute of Cancer and Genomic Sciences, University of Birmingham, UK+The Alan Turing Institute, London, UK",
        "aff_domain": "stats.ox.ac.uk; ; ",
        "email": "stats.ox.ac.uk; ; ",
        "github": "https://github.com/TammoR/LogicalFactorisationMachines",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/rukat18a.html",
        "aff_unique_index": "0+1;0+1;2+1",
        "aff_unique_norm": "University of Oxford;Alan Turing Institute;University of Birmingham",
        "aff_unique_dep": "Department of Statistics;;Centre for Computational Biology, Institute of Cancer and Genomic Sciences",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.turing.ac.uk;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "Oxford;ATI;UoB",
        "aff_campus_unique_index": "0+1;0+1;1",
        "aff_campus_unique": "Oxford;London;",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Probabilistic Recurrent State-Space Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2070",
        "id": "2070",
        "author_site": "Andreas Doerr, Christian Daniel, Martin Schiegg, Duy Nguyen-Tuong, Stefan Schaal, Marc Toussaint, Sebastian Trimpe",
        "author": "Andreas Doerr; Christian Daniel; Martin Schiegg; Nguyen-Tuong Duy; Stefan Schaal; Marc Toussaint; Trimpe Sebastian",
        "abstract": "State-space models (SSMs) are a highly expressive model class for learning patterns in time series data and for system identification. Deterministic versions of SSMs (e.g., LSTMs) proved extremely successful in modeling complex time series data. Fully probabilistic SSMs, however, are often found hard to train, even for smaller problems. We propose a novel model formulation and a scalable training algorithm based on doubly stochastic variational inference and Gaussian processes. This combination allows efficient incorporation of latent state temporal correlations, which we found to be key to robust training. The effectiveness of the proposed PR-SSM is evaluated on a set of real-world benchmark datasets in comparison to state-of-the-art probabilistic model learning methods. Scalability and robustness are demonstrated on a high dimensional problem.",
        "bibtex": "@InProceedings{pmlr-v80-doerr18a,\n  title = \t {Probabilistic Recurrent State-Space Models},\n  author =       {Doerr, Andreas and Daniel, Christian and Schiegg, Martin and Duy, Nguyen-Tuong and Schaal, Stefan and Toussaint, Marc and Sebastian, Trimpe},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1280--1289},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/doerr18a/doerr18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/doerr18a.html},\n  abstract = \t {State-space models (SSMs) are a highly expressive model class for learning patterns in time series data and for system identification. Deterministic versions of SSMs (e.g., LSTMs) proved extremely successful in modeling complex time series data. Fully probabilistic SSMs, however, are often found hard to train, even for smaller problems. We propose a novel model formulation and a scalable training algorithm based on doubly stochastic variational inference and Gaussian processes. This combination allows efficient incorporation of latent state temporal correlations, which we found to be key to robust training. The effectiveness of the proposed PR-SSM is evaluated on a set of real-world benchmark datasets in comparison to state-of-the-art probabilistic model learning methods. Scalability and robustness are demonstrated on a high dimensional problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/doerr18a/doerr18a.pdf",
        "supp": "",
        "pdf_size": 1852235,
        "gs_citation": 157,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13376246686422250291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Bosch Center for Artificial Intelligence, Renningen, Germany + Max Planck Institute for Intelligent Systems, Stuttgart/T\u00fcbingen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Max Planck Institute for Intelligent Systems, Stuttgart/T\u00fcbingen, Germany + University of Southern California, Los Angeles, USA; Machine Learning and Robotics Lab, University of Stuttgart, Germany; Max Planck Institute for Intelligent Systems, Stuttgart/T\u00fcbingen, Germany",
        "aff_domain": "gmx.net; ; ; ; ; ; ",
        "email": "gmx.net; ; ; ; ; ; ",
        "github": "https://github.com/boschresearch/PR-SSM",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/doerr18a.html",
        "aff_unique_index": "0+1;0;0;0;1+2;3;1",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;Max Planck Institute for Intelligent Systems;University of Southern California;University of Stuttgart",
        "aff_unique_dep": "Artificial Intelligence;;;Machine Learning and Robotics Lab",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.mpi-is.mpg.de;https://www.usc.edu;https://www.ira.uka.de",
        "aff_unique_abbr": "BCAI;MPI-IS;USC;",
        "aff_campus_unique_index": "0+1;0;0;0;1+2;1",
        "aff_campus_unique": "Renningen;Stuttgart/T\u00fcbingen;Los Angeles;",
        "aff_country_unique_index": "0+0;0;0;0;0+1;0;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "title": "Probably Approximately Metric-Fair Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2365",
        "id": "2365",
        "author_site": "Gal Yona, Guy Rothblum",
        "author": "Gal Yona; Guy Rothblum",
        "abstract": "The seminal work of Dwork",
        "bibtex": "@InProceedings{pmlr-v80-yona18a,\n  title = \t {Probably Approximately Metric-Fair Learning},\n  author =       {Yona, Gal and Rothblum, Guy},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5680--5688},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yona18a/yona18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yona18a.html},\n  abstract = \t {The seminal work of Dwork",
        "pdf": "http://proceedings.mlr.press/v80/yona18a/yona18a.pdf",
        "supp": "",
        "pdf_size": 284074,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8846447969410880475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Weizmann Institute of Science; Weizmann Institute of Science",
        "aff_domain": "alum.mit.edu;gmail.com",
        "email": "alum.mit.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/yona18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Weizmann Institute of Science",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.weizmann.org.il",
        "aff_unique_abbr": "Weizmann",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2433",
        "id": "2433",
        "author_site": "Andrea Zanette, Emma Brunskill",
        "author": "Andrea Zanette; Emma Brunskill",
        "abstract": "In order to make good decision under uncertainty an agent must learn from observations. To do so, two of the most common frameworks are Contextual Bandits and Markov Decision Processes (MDPs). In this paper, we study whether there exist algorithms for the more general framework (MDP) which automatically provide the best performance bounds for the specific problem at hand without user intervention and without modifying the algorithm. In particular, it is found that a very minor variant of a recently proposed reinforcement learning algorithm for MDPs already matches the best possible regret bound $\\tilde O (\\sqrt{SAT})$ in the dominant term if deployed on a tabular Contextual Bandit problem despite the agent being agnostic to such setting.",
        "bibtex": "@InProceedings{pmlr-v80-zanette18a,\n  title = \t {Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in {MDP}s},\n  author =       {Zanette, Andrea and Brunskill, Emma},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5747--5755},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zanette18a/zanette18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zanette18a.html},\n  abstract = \t {In order to make good decision under uncertainty an agent must learn from observations. To do so, two of the most common frameworks are Contextual Bandits and Markov Decision Processes (MDPs). In this paper, we study whether there exist algorithms for the more general framework (MDP) which automatically provide the best performance bounds for the specific problem at hand without user intervention and without modifying the algorithm. In particular, it is found that a very minor variant of a recently proposed reinforcement learning algorithm for MDPs already matches the best possible regret bound $\\tilde O (\\sqrt{SAT})$ in the dominant term if deployed on a tabular Contextual Bandit problem despite the agent being agnostic to such setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zanette18a/zanette18a.pdf",
        "supp": "",
        "pdf_size": 428019,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1277201674097081236&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; Stanford University",
        "aff_domain": "stanford.edu; ",
        "email": "stanford.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/zanette18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Programmatically Interpretable Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2203",
        "id": "2203",
        "author_site": "Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, Swarat Chaudhuri",
        "author": "Abhinav Verma; Vijayaraghavan Murali; Rishabh Singh; Pushmeet Kohli; Swarat Chaudhuri",
        "abstract": "We present a reinforcement learning framework, called Programmatically Interpretable Reinforcement Learning (PIRL), that is designed to generate interpretable and verifiable agent policies. Unlike the popular Deep Reinforcement Learning (DRL) paradigm, which represents policies by neural networks, PIRL represents policies using a high-level, domain-specific programming language. Such programmatic policies have the benefits of being more easily interpreted than neural networks, and being amenable to verification by symbolic methods. We propose a new method, called Neurally Directed Program Search (NDPS), for solving the challenging nonsmooth optimization problem of finding a programmatic policy with maximal reward. NDPS works by first learning a neural policy network using DRL, and then performing a local search over programmatic policies that seeks to minimize a distance from this neural \u201coracle\u201d. We evaluate NDPS on the task of learning to drive a simulated car in the TORCS car-racing environment. We demonstrate that NDPS is able to discover human-readable policies that pass some significant performance bars. We also show that PIRL policies can have smoother trajectories, and can be more easily transferred to environments not encountered during training, than corresponding policies discovered by DRL.",
        "bibtex": "@InProceedings{pmlr-v80-verma18a,\n  title = \t {Programmatically Interpretable Reinforcement Learning},\n  author =       {Verma, Abhinav and Murali, Vijayaraghavan and Singh, Rishabh and Kohli, Pushmeet and Chaudhuri, Swarat},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5045--5054},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/verma18a/verma18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/verma18a.html},\n  abstract = \t {We present a reinforcement learning framework, called Programmatically Interpretable Reinforcement Learning (PIRL), that is designed to generate interpretable and verifiable agent policies. Unlike the popular Deep Reinforcement Learning (DRL) paradigm, which represents policies by neural networks, PIRL represents policies using a high-level, domain-specific programming language. Such programmatic policies have the benefits of being more easily interpreted than neural networks, and being amenable to verification by symbolic methods. We propose a new method, called Neurally Directed Program Search (NDPS), for solving the challenging nonsmooth optimization problem of finding a programmatic policy with maximal reward. NDPS works by first learning a neural policy network using DRL, and then performing a local search over programmatic policies that seeks to minimize a distance from this neural \u201coracle\u201d. We evaluate NDPS on the task of learning to drive a simulated car in the TORCS car-racing environment. We demonstrate that NDPS is able to discover human-readable policies that pass some significant performance bars. We also show that PIRL policies can have smoother trajectories, and can be more easily transferred to environments not encountered during training, than corresponding policies discovered by DRL.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/verma18a/verma18a.pdf",
        "supp": "",
        "pdf_size": 818845,
        "gs_citation": 497,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13646255682604631153&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Rice University; Rice University; Google Brain; Deepmind; Rice University",
        "aff_domain": "rice.edu; ; ; ; ",
        "email": "rice.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/verma18a.html",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Rice University;Google;DeepMind",
        "aff_unique_dep": ";Google Brain;",
        "aff_unique_url": "https://www.rice.edu;https://brain.google.com;https://deepmind.com",
        "aff_unique_abbr": "Rice;Google Brain;DeepMind",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Progress & Compress: A scalable framework for continual learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2131",
        "id": "2131",
        "author_site": "Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Teh, Razvan Pascanu, Raia Hadsell",
        "author": "Jonathan Schwarz; Wojciech Czarnecki; Jelena Luketina; Agnieszka Grabska-Barwinska; Yee Whye Teh; Razvan Pascanu; Raia Hadsell",
        "abstract": "We introduce a conceptually simple and scalable framework for continual learning domains where tasks are learned sequentially. Our method is constant in the number of parameters and is designed to preserve performance on previously encountered tasks while accelerating learning progress on subsequent problems. This is achieved by training a network with two components: A knowledge base, capable of solving previously encountered problems, which is connected to an active column that is employed to efficiently learn the current task. After learning a new task, the active column is distilled into the knowledge base, taking care to protect any previously acquired skills. This cycle of active learning (progression) followed by consolidation (compression) requires no architecture growth, no access to or storing of previous data or tasks, and no task-specific parameters. We demonstrate the progress & compress approach on sequential classification of handwritten alphabets as well as two reinforcement learning domains: Atari games and 3D maze navigation.",
        "bibtex": "@InProceedings{pmlr-v80-schwarz18a,\n  title = \t {Progress & Compress: A scalable framework for continual learning},\n  author =       {Schwarz, Jonathan and Czarnecki, Wojciech and Luketina, Jelena and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4528--4537},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/schwarz18a/schwarz18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/schwarz18a.html},\n  abstract = \t {We introduce a conceptually simple and scalable framework for continual learning domains where tasks are learned sequentially. Our method is constant in the number of parameters and is designed to preserve performance on previously encountered tasks while accelerating learning progress on subsequent problems. This is achieved by training a network with two components: A knowledge base, capable of solving previously encountered problems, which is connected to an active column that is employed to efficiently learn the current task. After learning a new task, the active column is distilled into the knowledge base, taking care to protect any previously acquired skills. This cycle of active learning (progression) followed by consolidation (compression) requires no architecture growth, no access to or storing of previous data or tasks, and no task-specific parameters. We demonstrate the progress & compress approach on sequential classification of handwritten alphabets as well as two reinforcement learning domains: Atari games and 3D maze navigation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/schwarz18a/schwarz18a.pdf",
        "supp": "",
        "pdf_size": 1128552,
        "gs_citation": 1080,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=389933910924725889&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "DeepMind, London, United Kingdom; Department of Computer Science, University of Oxford, Oxford, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom",
        "aff_domain": "google.com; ; ; ; ;google.com; ",
        "email": "google.com; ; ; ; ;google.com; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/schwarz18a.html",
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "DeepMind;University of Oxford",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://deepmind.com;https://www.ox.ac.uk",
        "aff_unique_abbr": "DeepMind;Oxford",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "London;Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2385",
        "id": "2385",
        "author_site": "Lin Chen, Christopher Harshaw, Hamed Hassani, Amin Karbasi",
        "author": "Lin Chen; Christopher Harshaw; Hamed Hassani; Amin Karbasi",
        "abstract": "Online optimization has been a successful framework for solving large-scale problems under computational constraints and partial information. Current methods for online convex optimization require either a projection or exact gradient computation at each step, both of which can be prohibitively expensive for large-scale applications. At the same time, there is a growing trend of non-convex optimization in machine learning community and a need for online methods. Continuous DR-submodular functions, which exhibit a natural diminishing returns condition, have recently been proposed as a broad class of non-convex functions which may be efficiently optimized. Although online methods have been introduced, they suffer from similar problems. In this work, we propose Meta-Frank-Wolfe, the first online projection-free algorithm that uses stochastic gradient estimates. The algorithm relies on a careful sampling of gradients in each round and achieves the optimal $O( \\sqrt{T})$ adversarial regret bounds for convex and continuous submodular optimization. We also propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single stochastic gradient estimate in each round and achieves an $O(T^{2/3})$ stochastic regret bound for convex and continuous submodular optimization. We apply our methods to develop a novel \"lifting\" framework for the online discrete submodular maximization and also see that they outperform current state-of-the-art techniques on various experiments.",
        "bibtex": "@InProceedings{pmlr-v80-chen18c,\n  title = \t {Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity},\n  author =       {Chen, Lin and Harshaw, Christopher and Hassani, Hamed and Karbasi, Amin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {814--823},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18c/chen18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18c.html},\n  abstract = \t {Online optimization has been a successful framework for solving large-scale problems under computational constraints and partial information. Current methods for online convex optimization require either a projection or exact gradient computation at each step, both of which can be prohibitively expensive for large-scale applications. At the same time, there is a growing trend of non-convex optimization in machine learning community and a need for online methods. Continuous DR-submodular functions, which exhibit a natural diminishing returns condition, have recently been proposed as a broad class of non-convex functions which may be efficiently optimized. Although online methods have been introduced, they suffer from similar problems. In this work, we propose Meta-Frank-Wolfe, the first online projection-free algorithm that uses stochastic gradient estimates. The algorithm relies on a careful sampling of gradients in each round and achieves the optimal $O( \\sqrt{T})$ adversarial regret bounds for convex and continuous submodular optimization. We also propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single stochastic gradient estimate in each round and achieves an $O(T^{2/3})$ stochastic regret bound for convex and continuous submodular optimization. We apply our methods to develop a novel \"lifting\" framework for the online discrete submodular maximization and also see that they outperform current state-of-the-art techniques on various experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18c/chen18c.pdf",
        "supp": "",
        "pdf_size": 551838,
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1717017216303053879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Yale Institute for Network Science, Yale University, New Haven, CT, USA+Department of Electrical Engineering, Yale University+Department of Computer Science, Yale University; Yale Institute for Network Science, Yale University, New Haven, CT, USA+Department of Electrical Engineering, Yale University+Department of Computer Science, Yale University; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Yale Institute for Network Science, Yale University, New Haven, CT, USA+Department of Electrical Engineering, Yale University+Department of Computer Science, Yale University",
        "aff_domain": "yale.edu; ;upenn.edu;yale.edu",
        "email": "yale.edu; ;upenn.edu;yale.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/chen18c.html",
        "aff_unique_index": "0+0+0;0+0+0;1;0+0+0",
        "aff_unique_norm": "Yale University;University of Pennsylvania",
        "aff_unique_dep": "Yale Institute for Network Science;Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://www.yale.edu;https://www.upenn.edu",
        "aff_unique_abbr": "Yale;UPenn",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "New Haven;;Philadelphia",
        "aff_country_unique_index": "0+0+0;0+0+0;0;0+0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Proportional Allocation: Simple, Distributed, and Diverse Matching with High Entropy",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2388",
        "id": "2388",
        "author_site": "Shipra Agarwal, Morteza Zadimoghaddam, Vahab Mirrokni",
        "author": "Shipra Agrawal; Morteza Zadimoghaddam; Vahab Mirrokni",
        "abstract": "Inspired by many applications of bipartite matching in online advertising and machine learning, we study a simple and natural iterative proportional allocation algorithm: Maintain a priority score $\\priority_a$ for each node $a\\in \\mathds{A}$ on one side of the bipartition, initialized as $\\priority_a=1$. Iteratively allocate the nodes $i\\in \\impressions$ on the other side to eligible nodes in $\\mathds{A}$ in proportion of their priority scores. After each round, for each node $a\\in \\mathds{A}$, decrease or increase the score $\\priority_a$ based on whether it is over- or under- allocated. Our first result is that this simple, distributed algorithm converges to a $(1-\\epsilon)$-approximate fractional $b$-matching solution in $O({\\log n\\over \\epsilon^2} )$ rounds. We also extend the proportional allocation algorithm and convergence results to the maximum weighted matching problem, and show that the algorithm can be naturally tuned to produce maximum matching with",
        "bibtex": "@InProceedings{pmlr-v80-agrawal18b,\n  title = \t {Proportional Allocation: Simple, Distributed, and Diverse Matching with High Entropy},\n  author =       {Agrawal, Shipra and Zadimoghaddam, Morteza and Mirrokni, Vahab},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {99--108},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/agrawal18b/agrawal18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/agrawal18b.html},\n  abstract = \t {Inspired by many applications of bipartite matching in online advertising and machine learning, we study a simple and natural iterative proportional allocation algorithm: Maintain a priority score $\\priority_a$ for each node $a\\in \\mathds{A}$ on one side of the bipartition, initialized as $\\priority_a=1$. Iteratively allocate the nodes $i\\in \\impressions$ on the other side to eligible nodes in $\\mathds{A}$ in proportion of their priority scores. After each round, for each node $a\\in \\mathds{A}$, decrease or increase the score $\\priority_a$ based on whether it is over- or under- allocated. Our first result is that this simple, distributed algorithm converges to a $(1-\\epsilon)$-approximate fractional $b$-matching solution in $O({\\log n\\over \\epsilon^2} )$ rounds. We also extend the proportional allocation algorithm and convergence results to the maximum weighted matching problem, and show that the algorithm can be naturally tuned to produce maximum matching with",
        "pdf": "http://proceedings.mlr.press/v80/agrawal18b/agrawal18b.pdf",
        "supp": "",
        "pdf_size": 367063,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5601268668366219393&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Columbia University; Google Research; Google Research",
        "aff_domain": "columbia.edu;google.com;google.com",
        "email": "columbia.edu;google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/agrawal18b.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Columbia University;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.columbia.edu;https://research.google",
        "aff_unique_abbr": "Columbia;Google Research",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2136",
        "id": "2136",
        "author_site": "Eric Wong, Zico Kolter",
        "author": "Eric Wong; Zico Kolter",
        "abstract": "We propose a method to learn deep ReLU-based classifiers that are provably robust against norm-bounded adversarial perturbations on the training data. For previously unseen examples, the approach is guaranteed to detect all adversarial examples, though it may flag some non-adversarial examples as well. The basic idea is to consider a convex outer approximation of the set of activations reachable through a norm-bounded perturbation, and we develop a robust optimization procedure that minimizes the worst case loss over this outer region (via a linear program). Crucially, we show that the dual problem to this linear program can be represented itself as a deep network similar to the backpropagation network, leading to very efficient optimization approaches that produce guaranteed bounds on the robust loss. The end result is that by executing a few more forward and backward passes through a slightly modified version of the original network (though possibly with much larger batch sizes), we can learn a classifier that is provably robust to any norm-bounded adversarial attack. We illustrate the approach on a number of tasks to train classifiers with robust adversarial guarantees (e.g. for MNIST, we produce a convolutional classifier that provably has less than 5.8% test error for any adversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$).",
        "bibtex": "@InProceedings{pmlr-v80-wong18a,\n  title = \t {Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope},\n  author =       {Wong, Eric and Kolter, Zico},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5286--5295},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wong18a/wong18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wong18a.html},\n  abstract = \t {We propose a method to learn deep ReLU-based classifiers that are provably robust against norm-bounded adversarial perturbations on the training data. For previously unseen examples, the approach is guaranteed to detect all adversarial examples, though it may flag some non-adversarial examples as well. The basic idea is to consider a convex outer approximation of the set of activations reachable through a norm-bounded perturbation, and we develop a robust optimization procedure that minimizes the worst case loss over this outer region (via a linear program). Crucially, we show that the dual problem to this linear program can be represented itself as a deep network similar to the backpropagation network, leading to very efficient optimization approaches that produce guaranteed bounds on the robust loss. The end result is that by executing a few more forward and backward passes through a slightly modified version of the original network (though possibly with much larger batch sizes), we can learn a classifier that is provably robust to any norm-bounded adversarial attack. We illustrate the approach on a number of tasks to train classifiers with robust adversarial guarantees (e.g. for MNIST, we produce a convolutional classifier that provably has less than 5.8% test error for any adversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wong18a/wong18a.pdf",
        "supp": "",
        "pdf_size": 1145131,
        "gs_citation": 1817,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2593701021867797885&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Machine Learning Department, Carnegie Mellon University, Pittsburgh PA, 15213, USA; Computer Science Department, Carnegie Mellon University, Pittsburgh PA, 15213, USA",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu",
        "github": "http://github.com/locuslab/convex_adversarial",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/wong18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Provable Variable Selection for Streaming Features",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2352",
        "id": "2352",
        "author_site": "Jing Wang, Jie Shen, Ping Li",
        "author": "Jing Wang; Jie Shen; Ping Li",
        "abstract": "In large-scale machine learning applications and high-dimensional statistics, it is ubiquitous to address a considerable number of features among which many are redundant. As a remedy, online feature selection has attracted increasing attention in recent years. It sequentially reveals features and evaluates the importance of them. Though online feature selection has proven an elegant methodology, it is usually challenging to carry out a rigorous theoretical characterization. In this work, we propose a provable online feature selection algorithm that utilizes the online leverage score. The selected features are then fed to $k$-means clustering, making the clustering step memory and computationally efficient. We prove that with high probability, performing $k$-means clustering based on the selected feature space does not deviate far from the optimal clustering using the original data. The empirical results on real-world data sets demonstrate the effectiveness of our algorithm.",
        "bibtex": "@InProceedings{pmlr-v80-wang18g,\n  title = \t {Provable Variable Selection for Streaming Features},\n  author =       {Wang, Jing and Shen, Jie and Li, Ping},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5171--5179},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18g/wang18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18g.html},\n  abstract = \t {In large-scale machine learning applications and high-dimensional statistics, it is ubiquitous to address a considerable number of features among which many are redundant. As a remedy, online feature selection has attracted increasing attention in recent years. It sequentially reveals features and evaluates the importance of them. Though online feature selection has proven an elegant methodology, it is usually challenging to carry out a rigorous theoretical characterization. In this work, we propose a provable online feature selection algorithm that utilizes the online leverage score. The selected features are then fed to $k$-means clustering, making the clustering step memory and computationally efficient. We prove that with high probability, performing $k$-means clustering based on the selected feature space does not deviate far from the optimal clustering using the original data. The empirical results on real-world data sets demonstrate the effectiveness of our algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18g/wang18g.pdf",
        "supp": "",
        "pdf_size": 336460,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7740400520613439806&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Cornell University; Rutgers University; Baidu Research",
        "aff_domain": "med.cornell.edu;rutgers.edu;gmail.com",
        "email": "med.cornell.edu;rutgers.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wang18g.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Cornell University;Rutgers University;Baidu",
        "aff_unique_dep": ";;Baidu Research",
        "aff_unique_url": "https://www.cornell.edu;https://www.rutgers.edu;https://research.baidu.com",
        "aff_unique_abbr": "Cornell;Rutgers;Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing\u2014and Back",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2256",
        "id": "2256",
        "author_site": "Elliot Meyerson, Risto Miikkulainen",
        "author": "Elliot Meyerson; Risto Miikkulainen",
        "abstract": "Deep multitask learning boosts performance by sharing learned structure across related tasks. This paper adapts ideas from deep multitask learning to the setting where only a single task is available. The method is formalized as pseudo-task augmentation, in which models are trained with multiple decoders for each task. Pseudo-tasks simulate the effect of training towards closely-related tasks drawn from the same universe. In a suite of experiments, pseudo-task augmentation is shown to improve performance on single-task learning problems. When combined with multitask learning, further improvements are achieved, including state-of-the-art performance on the CelebA dataset, showing that pseudo-task augmentation and multitask learning have complementary value. All in all, pseudo-task augmentation is a broadly applicable and efficient way to boost performance in deep learning systems.",
        "bibtex": "@InProceedings{pmlr-v80-meyerson18a,\n  title = \t {Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing{\u2014}and Back},\n  author =       {Meyerson, Elliot and Miikkulainen, Risto},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3511--3520},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/meyerson18a/meyerson18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/meyerson18a.html},\n  abstract = \t {Deep multitask learning boosts performance by sharing learned structure across related tasks. This paper adapts ideas from deep multitask learning to the setting where only a single task is available. The method is formalized as pseudo-task augmentation, in which models are trained with multiple decoders for each task. Pseudo-tasks simulate the effect of training towards closely-related tasks drawn from the same universe. In a suite of experiments, pseudo-task augmentation is shown to improve performance on single-task learning problems. When combined with multitask learning, further improvements are achieved, including state-of-the-art performance on the CelebA dataset, showing that pseudo-task augmentation and multitask learning have complementary value. All in all, pseudo-task augmentation is a broadly applicable and efficient way to boost performance in deep learning systems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/meyerson18a/meyerson18a.pdf",
        "supp": "",
        "pdf_size": 549192,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16141083319993777988&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Texas at Austin+Sentient Technologies, Inc.; The University of Texas at Austin+Sentient Technologies, Inc.",
        "aff_domain": "cs.utexas.edu; ",
        "email": "cs.utexas.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/meyerson18a.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "University of Texas at Austin;Sentient Technologies",
        "aff_unique_dep": ";Inc.",
        "aff_unique_url": "https://www.utexas.edu;https://www.sentient.ai",
        "aff_unique_abbr": "UT Austin;STI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2389",
        "id": "2389",
        "author_site": "Tabish Rashid, Mikayel Samvelyan, Christian Schroeder, Gregory Farquhar, Jakob Foerster, Shimon Whiteson",
        "author": "Tabish Rashid; Mikayel Samvelyan; Christian Schroeder; Gregory Farquhar; Jakob Foerster; Shimon Whiteson",
        "abstract": "In many real-world settings, a team of agents must coordinate their behaviour while acting in a decentralised way. At the same time, it is often possible to train the agents in a centralised fashion in a simulated or laboratory setting, where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a network that estimates joint action-values as a complex non-linear combination of per-agent values that condition only on local observations. We structurally enforce that the joint-action value is monotonic in the per-agent values, which allows tractable maximisation of the joint action-value in off-policy learning, and guarantees consistency between the centralised and decentralised policies. We evaluate QMIX on a challenging set of StarCraft II micromanagement tasks, and show that QMIX significantly outperforms existing value-based multi-agent reinforcement learning methods.",
        "bibtex": "@InProceedings{pmlr-v80-rashid18a,\n  title = \t {{QMIX}: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},\n  author =       {Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4295--4304},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rashid18a.html},\n  abstract = \t {In many real-world settings, a team of agents must coordinate their behaviour while acting in a decentralised way. At the same time, it is often possible to train the agents in a centralised fashion in a simulated or laboratory setting, where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a network that estimates joint action-values as a complex non-linear combination of per-agent values that condition only on local observations. We structurally enforce that the joint-action value is monotonic in the per-agent values, which allows tractable maximisation of the joint action-value in off-policy learning, and guarantees consistency between the centralised and decentralised policies. We evaluate QMIX on a challenging set of StarCraft II micromanagement tasks, and show that QMIX significantly outperforms existing value-based multi-agent reinforcement learning methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf",
        "supp": "",
        "pdf_size": 2805016,
        "gs_citation": 3090,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3975132673723125155&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "University of Oxford; Russian-Armenian University + University of Oxford; University of Oxford; University of Oxford; University of Oxford; University of Oxford",
        "aff_domain": "cs.ox.ac.uk;samvelyan.com; ; ; ; ",
        "email": "cs.ox.ac.uk;samvelyan.com; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/rashid18a.html",
        "aff_unique_index": "0;1+0;0;0;0;0",
        "aff_unique_norm": "University of Oxford;Russian-Armenian University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;http://www.rau.am",
        "aff_unique_abbr": "Oxford;RAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;0;0;0;0",
        "aff_country_unique": "United Kingdom;Armenia"
    },
    {
        "title": "QuantTree: Histograms for Change Detection in Multivariate Data Streams",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2268",
        "id": "2268",
        "author_site": "Giacomo Boracchi, Diego Carrera, Cristiano Cervellera, Danilo Macci\u00f2",
        "author": "Giacomo Boracchi; Diego Carrera; Cristiano Cervellera; Danilo Macci\u00f2",
        "abstract": "We address the problem of detecting distribution changes in multivariate data streams by means of histograms. Histograms are very general and flexible models, which have been relatively ignored in the change-detection literature as they often require a number of bins that grows unfeasibly with the data dimension. We present QuantTree, a recursive binary splitting scheme that adaptively defines the histogram bins to ease the detection of any distribution change. Our design scheme implies that i) we can easily control the overall number of bins and ii) the bin probabilities do not depend on the distribution of stationary data. This latter is a very relevant aspect in change detection, since thresholds of tests statistics based on these histograms (e.g., the Pearson statistic or the total variation) can be numerically computed from univariate and synthetically generated data, yet guaranteeing a controlled false positive rate. Our experiments show that the proposed histograms are very effective in detecting changes in high dimensional data streams, and that the resulting thresholds can effectively control the false positive rate, even when the number of training samples is relatively small.",
        "bibtex": "@InProceedings{pmlr-v80-boracchi18a,\n  title = \t {{Q}uant{T}ree: Histograms for Change Detection in Multivariate Data Streams},\n  author =       {Boracchi, Giacomo and Carrera, Diego and Cervellera, Cristiano and Macci{\\`o}, Danilo},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {639--648},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/boracchi18a/boracchi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/boracchi18a.html},\n  abstract = \t {We address the problem of detecting distribution changes in multivariate data streams by means of histograms. Histograms are very general and flexible models, which have been relatively ignored in the change-detection literature as they often require a number of bins that grows unfeasibly with the data dimension. We present QuantTree, a recursive binary splitting scheme that adaptively defines the histogram bins to ease the detection of any distribution change. Our design scheme implies that i) we can easily control the overall number of bins and ii) the bin probabilities do not depend on the distribution of stationary data. This latter is a very relevant aspect in change detection, since thresholds of tests statistics based on these histograms (e.g., the Pearson statistic or the total variation) can be numerically computed from univariate and synthetically generated data, yet guaranteeing a controlled false positive rate. Our experiments show that the proposed histograms are very effective in detecting changes in high dimensional data streams, and that the resulting thresholds can effectively control the false positive rate, even when the number of training samples is relatively small.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/boracchi18a/boracchi18a.pdf",
        "supp": "",
        "pdf_size": 386257,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9362392204618160154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingneria, Politecnico di Milano, Milan, Italy; Institute of Intelligent Systems for Automation, National Research Council, Genova, Italy; Institute of Intelligent Systems for Automation, National Research Council, Genova, Italy",
        "aff_domain": "polimi.it;polimi.it;cnr.it;cnr.it",
        "email": "polimi.it;polimi.it;cnr.it;cnr.it",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/boracchi18a.html",
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Politecnico di Milano;National Research Council",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria;Institute of Intelligent Systems for Automation",
        "aff_unique_url": "https://www.polimi.it;https://www.cnr.it",
        "aff_unique_abbr": "Politecnico di Milano;CNR",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Milan;Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "title": "Quasi-Monte Carlo Variational Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2288",
        "id": "2288",
        "author_site": "Alexander Buchholz, Florian Wenzel, Stephan Mandt",
        "author": "Alexander Buchholz; Florian Wenzel; Stephan Mandt",
        "abstract": "Many machine learning problems involve Monte Carlo gradient estimators. As a prominent example, we focus on Monte Carlo variational inference (MCVI) in this paper. The performance of MCVI crucially depends on the variance of its stochastic gradients. We propose variance reduction by means of Quasi-Monte Carlo (QMC) sampling. QMC replaces N i.i.d. samples from a uniform probability distribution by a deterministic sequence of samples of length N. This sequence covers the underlying random variable space more evenly than i.i.d. draws, reducing the variance of the gradient estimator. With our novel approach, both the score function and the reparameterization gradient estimators lead to much faster convergence. We also propose a new algorithm for Monte Carlo objectives, where we operate with a constant learning rate and increase the number of QMC samples per iteration. We prove that this way, our algorithm can converge asymptotically at a faster rate than SGD . We furthermore provide theoretical guarantees on qmc for Monte Carlo objectives that go beyond MCVI , and support our findings by several experiments on large-scale data sets from various domains.",
        "bibtex": "@InProceedings{pmlr-v80-buchholz18a,\n  title = \t {Quasi-{M}onte {C}arlo Variational Inference},\n  author =       {Buchholz, Alexander and Wenzel, Florian and Mandt, Stephan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {668--677},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/buchholz18a/buchholz18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/buchholz18a.html},\n  abstract = \t {Many machine learning problems involve Monte Carlo gradient estimators. As a prominent example, we focus on Monte Carlo variational inference (MCVI) in this paper. The performance of MCVI crucially depends on the variance of its stochastic gradients. We propose variance reduction by means of Quasi-Monte Carlo (QMC) sampling. QMC replaces N i.i.d. samples from a uniform probability distribution by a deterministic sequence of samples of length N. This sequence covers the underlying random variable space more evenly than i.i.d. draws, reducing the variance of the gradient estimator. With our novel approach, both the score function and the reparameterization gradient estimators lead to much faster convergence. We also propose a new algorithm for Monte Carlo objectives, where we operate with a constant learning rate and increase the number of QMC samples per iteration. We prove that this way, our algorithm can converge asymptotically at a faster rate than SGD . We furthermore provide theoretical guarantees on qmc for Monte Carlo objectives that go beyond MCVI , and support our findings by several experiments on large-scale data sets from various domains.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/buchholz18a/buchholz18a.pdf",
        "supp": "",
        "pdf_size": 3331809,
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11814201869765037346&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "ENSAE-CREST, Paris; TU Kaiserslautern, Germany; Disney Research, Los Angeles, USA",
        "aff_domain": "ensae.fr;huberlin.de;gmail.com",
        "email": "ensae.fr;huberlin.de;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/buchholz18a.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "ENSAE-CREST;Technische Universit\u00e4t Kaiserslautern;Disney Research",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ensae.fr;https://www.tu-kl.de;https://research.disney.com",
        "aff_unique_abbr": ";TU Kaiserslautern;Disney Research",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Paris;;Los Angeles",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "France;Germany;United States"
    },
    {
        "title": "Quickshift++: Provably Good Initializations for Sample-Based Mean Shift",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1949",
        "id": "1949",
        "author_site": "Heinrich Jiang, Jennifer Jang, Samory Kpotufe",
        "author": "Heinrich Jiang; Jennifer Jang; Samory Kpotufe",
        "abstract": "We provide initial seedings to the Quick Shift clustering algorithm, which approximate the locally high-density regions of the data. Such seedings act as more stable and expressive cluster-cores than the singleton modes found by Quick Shift. We establish statistical consistency guarantees for this modification. We then show strong clustering performance on real datasets as well as promising applications to image segmentation.",
        "bibtex": "@InProceedings{pmlr-v80-jiang18b,\n  title = \t {Quickshift++: Provably Good Initializations for Sample-Based Mean Shift},\n  author =       {Jiang, Heinrich and Jang, Jennifer and Kpotufe, Samory},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2294--2303},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jiang18b/jiang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jiang18b.html},\n  abstract = \t {We provide initial seedings to the Quick Shift clustering algorithm, which approximate the locally high-density regions of the data. Such seedings act as more stable and expressive cluster-cores than the singleton modes found by Quick Shift. We establish statistical consistency guarantees for this modification. We then show strong clustering performance on real datasets as well as promising applications to image segmentation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jiang18b/jiang18b.pdf",
        "supp": "",
        "pdf_size": 2427398,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9290981772171127937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Google Research, Mountain View, CA; Uber Inc, San Francisco, CA; Princeton University, Princeton, NJ",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jiang18b.html",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Google;Uber;Princeton University",
        "aff_unique_dep": "Google Research;;",
        "aff_unique_url": "https://research.google;https://www.uber.com;https://www.princeton.edu",
        "aff_unique_abbr": "Google;Uber;Princeton",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Mountain View;San Francisco;Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "RLlib: Abstractions for Distributed Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2116",
        "id": "2116",
        "author_site": "Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox, Ken Goldberg, Joseph E Gonzalez, Michael Jordan, Ion Stoica",
        "author": "Eric Liang; Richard Liaw; Robert Nishihara; Philipp Moritz; Roy Fox; Ken Goldberg; Joseph Gonzalez; Michael Jordan; Ion Stoica",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib.io/.",
        "bibtex": "@InProceedings{pmlr-v80-liang18b,\n  title = \t {{RL}lib: Abstractions for Distributed Reinforcement Learning},\n  author =       {Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3053--3062},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liang18b/liang18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liang18b.html},\n  abstract = \t {Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib.io/.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liang18b/liang18b.pdf",
        "supp": "",
        "pdf_size": 1078492,
        "gs_citation": 1200,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9535249560181579239&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "berkeley.edu; ; ; ; ; ; ; ; ",
        "email": "berkeley.edu; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "http://rllib.io",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/liang18b.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Racing Thompson: an Efficient Algorithm for Thompson Sampling with Non-conjugate Priors",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2160",
        "id": "2160",
        "author_site": "Yichi Zhou, Jun Zhu, Jingwei Zhuo",
        "author": "Yichi Zhou; Jun Zhu; Jingwei Zhuo",
        "abstract": "Thompson sampling has impressive empirical performance for many multi-armed bandit problems. But current algorithms for Thompson sampling only work for the case of conjugate priors since they require to perform online Bayesian posterior inference, which is a difficult task when the prior is not conjugate. In this paper, we propose a novel algorithm for Thompson sampling which only requires to draw samples from a tractable proposal distribution. So our algorithm is efficient even when the prior is non-conjugate. To do this, we reformulate Thompson sampling as an optimization proplem via the Gumbel-Max trick. After that we construct a set of random variables and our goal is to identify the one with highest mean which is an instance of best arm identification problems. Finally, we solve it with techniques in best arm identification. Experiments show that our algorithm works well in practice.",
        "bibtex": "@InProceedings{pmlr-v80-zhou18e,\n  title = \t {Racing Thompson: an Efficient Algorithm for Thompson Sampling with Non-conjugate Priors},\n  author =       {Zhou, Yichi and Zhu, Jun and Zhuo, Jingwei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {6000--6008},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhou18e/zhou18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhou18e.html},\n  abstract = \t {Thompson sampling has impressive empirical performance for many multi-armed bandit problems. But current algorithms for Thompson sampling only work for the case of conjugate priors since they require to perform online Bayesian posterior inference, which is a difficult task when the prior is not conjugate. In this paper, we propose a novel algorithm for Thompson sampling which only requires to draw samples from a tractable proposal distribution. So our algorithm is efficient even when the prior is non-conjugate. To do this, we reformulate Thompson sampling as an optimization proplem via the Gumbel-Max trick. After that we construct a set of random variables and our goal is to identify the one with highest mean which is an instance of best arm identification problems. Finally, we solve it with techniques in best arm identification. Experiments show that our algorithm works well in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhou18e/zhou18e.pdf",
        "supp": "",
        "pdf_size": 411133,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9649261896909597628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China",
        "aff_domain": "gmail.com;mail.tsinghua.edu.cn; ",
        "email": "gmail.com;mail.tsinghua.edu.cn; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhou18e.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2027",
        "id": "2027",
        "author_site": "Jinsung Yoon, James Jordon, Mihaela van der Schaar",
        "author": "Jinsung Yoon; James Jordon; Mihaela Schaar",
        "abstract": "Training complex machine learning models for prediction often requires a large amount of data that is not always readily available. Leveraging these external datasets from related but different sources is therefore an important task if good predictive models are to be built for deployment in settings where data can be rare. In this paper we propose a novel approach to the problem in which we use multiple GAN architectures to learn to translate from one dataset to another, thereby allowing us to effectively enlarge the target dataset, and therefore learn better predictive models than if we simply used the target dataset. We show the utility of such an approach, demonstrating that our method improves the prediction performance on the target domain over using just the target dataset and also show that our framework outperforms several other benchmarks on a collection of real-world medical datasets.",
        "bibtex": "@InProceedings{pmlr-v80-yoon18b,\n  title = \t {{R}adial{GAN}: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks},\n  author =       {Yoon, Jinsung and Jordon, James and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5699--5707},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yoon18b/yoon18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yoon18b.html},\n  abstract = \t {Training complex machine learning models for prediction often requires a large amount of data that is not always readily available. Leveraging these external datasets from related but different sources is therefore an important task if good predictive models are to be built for deployment in settings where data can be rare. In this paper we propose a novel approach to the problem in which we use multiple GAN architectures to learn to translate from one dataset to another, thereby allowing us to effectively enlarge the target dataset, and therefore learn better predictive models than if we simply used the target dataset. We show the utility of such an approach, demonstrating that our method improves the prediction performance on the target domain over using just the target dataset and also show that our framework outperforms several other benchmarks on a collection of real-world medical datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yoon18b/yoon18b.pdf",
        "supp": "",
        "pdf_size": 1775986,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11813005602027551862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Los Angeles, CA, USA+Alan Turing Institute, UK; University of Oxford, UK+Alan Turing Institute, UK; University of California, Los Angeles, CA, USA+University of Oxford, UK+Alan Turing Institute, UK",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/yoon18b.html",
        "aff_unique_index": "0+1;2+1;0+2+1",
        "aff_unique_norm": "University of California, Los Angeles;Alan Turing Institute;University of Oxford",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucla.edu;https://www.turing.ac.uk;https://www.ox.ac.uk",
        "aff_unique_abbr": "UCLA;ATI;Oxford",
        "aff_campus_unique_index": "0;;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0+1;1+1;0+1+1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Randomized Block Cubic Newton Method",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2322",
        "id": "2322",
        "author_site": "Nikita Doikov, Peter Richtarik",
        "author": "Nikita Doikov; Peter Richtarik; University Edinburgh",
        "abstract": "We study the problem of minimizing the sum of three convex functions: a differentiable, twice-differentiable and a non-smooth term in a high dimensional setting. To this effect we propose and analyze a randomized block cubic Newton (RBCN) method, which in each iteration builds a model of the objective function formed as the sum of the natural models of its three components: a linear model with a quadratic regularizer for the differentiable term, a quadratic model with a cubic regularizer for the twice differentiable term, and perfect (proximal) model for the nonsmooth term. Our method in each iteration minimizes the model over a random subset of blocks of the search variable. RBCN is the first algorithm with these properties, generalizing several existing methods, matching the best known bounds in all special cases. We establish ${\\cal O}(1/\\epsilon)$, ${\\cal O}(1/\\sqrt{\\epsilon})$ and ${\\cal O}(\\log (1/\\epsilon))$ rates under different assumptions on the component functions. Lastly, we show numerically that our method outperforms the state-of-the-art on a variety of machine learning problems, including cubically regularized least-squares, logistic regression with constraints, and Poisson regression.",
        "bibtex": "@InProceedings{pmlr-v80-doikov18a,\n  title = \t {Randomized Block Cubic {N}ewton Method},\n  author =       {Doikov, Nikita and Richtarik, Peter and of Edinburgh, University},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1290--1298},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/doikov18a/doikov18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/doikov18a.html},\n  abstract = \t {We study the problem of minimizing the sum of three convex functions: a differentiable, twice-differentiable and a non-smooth term in a high dimensional setting. To this effect we propose and analyze a randomized block cubic Newton (RBCN) method, which in each iteration builds a model of the objective function formed as the sum of the natural models of its three components: a linear model with a quadratic regularizer for the differentiable term, a quadratic model with a cubic regularizer for the twice differentiable term, and perfect (proximal) model for the nonsmooth term. Our method in each iteration minimizes the model over a random subset of blocks of the search variable. RBCN is the first algorithm with these properties, generalizing several existing methods, matching the best known bounds in all special cases. We establish ${\\cal O}(1/\\epsilon)$, ${\\cal O}(1/\\sqrt{\\epsilon})$ and ${\\cal O}(\\log (1/\\epsilon))$ rates under different assumptions on the component functions. Lastly, we show numerically that our method outperforms the state-of-the-art on a variety of machine learning problems, including cubically regularized least-squares, logistic regression with constraints, and Poisson regression.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/doikov18a/doikov18a.pdf",
        "supp": "",
        "pdf_size": 577562,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2012877333849456034&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/doikov18a.html"
    },
    {
        "title": "Ranking Distributions based on Noisy Sorting",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2051",
        "id": "2051",
        "author_site": "Adil El Mesaoudi-Paul, Eyke H\u00fcllermeier, Robert Busa-Fekete",
        "author": "Adil El Mesaoudi-Paul; Eyke H\u00fcllermeier; Robert Busa-Fekete",
        "abstract": "We propose a new statistical model for ranking data, i.e., a new family of probability distributions on permutations. Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure, in which deterministic comparisons between pairs of items are replaced by Bernoulli trials. The probability of producing a certain ranking as a result then essentially depends on the Bernoulli parameters, which can be interpreted as pairwise preferences. We show that our model can be written in closed form if insertion or quick sort are used as sorting algorithms, and propose a maximum likelihood approach for parameter estimation. We also introduce a generalization of the model, in which the constraints on pairwise preferences are relaxed, and for which maximum likelihood estimation can be carried out based on a variation of the generalized iterative scaling algorithm. Experimentally, we show that the models perform very well in terms of goodness of fit, compared to existing models for ranking data.",
        "bibtex": "@InProceedings{pmlr-v80-mesaoudi-paul18a,\n  title = \t {Ranking Distributions based on Noisy Sorting},\n  author =       {Mesaoudi-Paul, Adil El and H{\\\"u}llermeier, Eyke and Busa-Fekete, Robert},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3472--3480},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mesaoudi-paul18a/mesaoudi-paul18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mesaoudi-paul18a.html},\n  abstract = \t {We propose a new statistical model for ranking data, i.e., a new family of probability distributions on permutations. Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure, in which deterministic comparisons between pairs of items are replaced by Bernoulli trials. The probability of producing a certain ranking as a result then essentially depends on the Bernoulli parameters, which can be interpreted as pairwise preferences. We show that our model can be written in closed form if insertion or quick sort are used as sorting algorithms, and propose a maximum likelihood approach for parameter estimation. We also introduce a generalization of the model, in which the constraints on pairwise preferences are relaxed, and for which maximum likelihood estimation can be carried out based on a variation of the generalized iterative scaling algorithm. Experimentally, we show that the models perform very well in terms of goodness of fit, compared to existing models for ranking data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mesaoudi-paul18a/mesaoudi-paul18a.pdf",
        "supp": "",
        "pdf_size": 587969,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4480775414453505716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Heinz Nixdorf Institute and Department of Computer Science, Paderborn University, Germany; Heinz Nixdorf Institute and Department of Computer Science, Paderborn University, Germany; Yahoo Research, New York, USA",
        "aff_domain": "upb.de; ; ",
        "email": "upb.de; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mesaoudi-paul18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Paderborn University;Yahoo Research",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uni-paderborn.de;https://research.yahoo.com",
        "aff_unique_abbr": "Uni Paderborn;Yahoo Res.",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "title": "Rapid Adaptation with Conditionally Shifted Neurons",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1966",
        "id": "1966",
        "author_site": "Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, Adam Trischler",
        "author": "Tsendsuren Munkhdalai; Xingdi Yuan; Soroush Mehri; Adam Trischler",
        "abstract": "We describe a mechanism by which artificial neural networks can learn rapid adaptation - the ability to adapt on the fly, with little data, to new tasks - that we call conditionally shifted neurons. We apply this mechanism in the framework of metalearning, where the aim is to replicate some of the flexibility of human learning in machines. Conditionally shifted neurons modify their activation values with task-specific shifts retrieved from a memory module, which is populated rapidly based on limited task experience. On metalearning benchmarks from the vision and language domains, models augmented with conditionally shifted neurons achieve state-of-the-art results.",
        "bibtex": "@InProceedings{pmlr-v80-munkhdalai18a,\n  title = \t {Rapid Adaptation with Conditionally Shifted Neurons},\n  author =       {Munkhdalai, Tsendsuren and Yuan, Xingdi and Mehri, Soroush and Trischler, Adam},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3664--3673},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/munkhdalai18a/munkhdalai18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/munkhdalai18a.html},\n  abstract = \t {We describe a mechanism by which artificial neural networks can learn rapid adaptation - the ability to adapt on the fly, with little data, to new tasks - that we call conditionally shifted neurons. We apply this mechanism in the framework of metalearning, where the aim is to replicate some of the flexibility of human learning in machines. Conditionally shifted neurons modify their activation values with task-specific shifts retrieved from a memory module, which is populated rapidly based on limited task experience. On metalearning benchmarks from the vision and language domains, models augmented with conditionally shifted neurons achieve state-of-the-art results.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/munkhdalai18a/munkhdalai18a.pdf",
        "supp": "",
        "pdf_size": 1209604,
        "gs_citation": 366,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12970806183619866230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Microsoft Research, Montr \u00b4eal, Qu \u00b4ebec, Canada; Microsoft Research, Montr \u00b4eal, Qu \u00b4ebec, Canada; Microsoft Research, Montr \u00b4eal, Qu \u00b4ebec, Canada; Microsoft Research, Montr \u00b4eal, Qu \u00b4ebec, Canada",
        "aff_domain": "microsoft.com; ; ; ",
        "email": "microsoft.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/munkhdalai18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "MSR",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Rates of Convergence of Spectral Methods for Graphon Estimation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2335",
        "id": "2335",
        "author": "Jiaming Xu",
        "abstract": "This paper studies the problem of estimating the graphon function \u2013 a generative mechanism for a class of random graphs that are useful approximations to real networks. Specifically, a graph of $n$ vertices is generated such that each pair of two vertices $i$ and $j$ are connected independently with probability $\\rho_n \\times f(x_i,x_j)$, where $x_i$ is the unknown $d$-dimensional label of vertex $i$, $f$ is an unknown symmetric function, and $\\rho_n$, assumed to be $\\Omega(\\log n/n)$, is a scaling parameter characterizing the graph sparsity. The task is to estimate graphon $f$ given the graph. Recent studies have identified the minimax optimal estimation error rate for $d=1$. However, there exists a wide gap between the known error rates of polynomial-time estimators and the minimax optimal error rate. We improve on the previously known error rates of polynomial-time estimators, by analyzing a spectral method, namely universal singular value thresholding (USVT) algorithm. When $f$ belongs to either H\u00f6lder or Sobolev space with smoothness index $\\alpha$, we show the error rates of USVT are at most $(n\\rho)^{ -2 \\alpha / (2\\alpha+d)}$. These error rates approach the minimax optimal error rate $\\log (n\\rho)/(n\\rho)$ proved in prior work for $d=1$, as $\\alpha$ increases, i.e., $f$ becomes smoother. Furthermore, when $f$ is analytic with infinitely many times differentiability, we show the error rate of USVT is at most $\\log^d (n\\rho)/(n\\rho)$. When $f$ is a step function which corresponds to the stochastic block model with $k$ blocks for some $k$, the error rate of USVT is at most $k/(n\\rho)$, which is larger than the minimax optimal error rate by at most a multiplicative factor $k/\\log k$. This coincides with the computational gap observed in community detection. A key ingredient of our analysis is to derive the eigenvalue decaying rate of the edge probability matrix using piecewise polynomial approximations of the graphon function $f$.",
        "bibtex": "@InProceedings{pmlr-v80-xu18a,\n  title = \t {Rates of Convergence of Spectral Methods for Graphon Estimation},\n  author =       {Xu, Jiaming},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5433--5442},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18a/xu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18a.html},\n  abstract = \t {This paper studies the problem of estimating the graphon function \u2013 a generative mechanism for a class of random graphs that are useful approximations to real networks. Specifically, a graph of $n$ vertices is generated such that each pair of two vertices $i$ and $j$ are connected independently with probability $\\rho_n \\times f(x_i,x_j)$, where $x_i$ is the unknown $d$-dimensional label of vertex $i$, $f$ is an unknown symmetric function, and $\\rho_n$, assumed to be $\\Omega(\\log n/n)$, is a scaling parameter characterizing the graph sparsity. The task is to estimate graphon $f$ given the graph. Recent studies have identified the minimax optimal estimation error rate for $d=1$. However, there exists a wide gap between the known error rates of polynomial-time estimators and the minimax optimal error rate. We improve on the previously known error rates of polynomial-time estimators, by analyzing a spectral method, namely universal singular value thresholding (USVT) algorithm. When $f$ belongs to either H\u00f6lder or Sobolev space with smoothness index $\\alpha$, we show the error rates of USVT are at most $(n\\rho)^{ -2 \\alpha / (2\\alpha+d)}$. These error rates approach the minimax optimal error rate $\\log (n\\rho)/(n\\rho)$ proved in prior work for $d=1$, as $\\alpha$ increases, i.e., $f$ becomes smoother. Furthermore, when $f$ is analytic with infinitely many times differentiability, we show the error rate of USVT is at most $\\log^d (n\\rho)/(n\\rho)$. When $f$ is a step function which corresponds to the stochastic block model with $k$ blocks for some $k$, the error rate of USVT is at most $k/(n\\rho)$, which is larger than the minimax optimal error rate by at most a multiplicative factor $k/\\log k$. This coincides with the computational gap observed in community detection. A key ingredient of our analysis is to derive the eigenvalue decaying rate of the edge probability matrix using piecewise polynomial approximations of the graphon function $f$.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18a/xu18a.pdf",
        "supp": "",
        "pdf_size": 381039,
        "gs_citation": 120,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4387533063028623133&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "The Fuqua School of Business, Duke University, Durham, NC, USA.",
        "aff_domain": "duke.edu",
        "email": "duke.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/xu18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "The Fuqua School of Business",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Rectify Heterogeneous Models with Semantic Mapping",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1971",
        "id": "1971",
        "author_site": "Han-Jia Ye, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou",
        "author": "Han-Jia Ye; De-Chuan Zhan; Yuan Jiang; Zhi-Hua Zhou",
        "abstract": "On the way to the robust learner for real-world applications, there are still great    challenges, including considering unknown environments with limited data. Learnware (Zhou; 2016) describes a novel perspective, and claims that learning models should have reusable and evolvable properties. We propose to Encode Meta InformaTion of features (EMIT), as the model specification for characterizing the changes, which grants the model evolvability to bridge heterogeneous feature spaces. Then, pre-trained models from related tasks can be Reused by our REctiFy via heterOgeneous pRedictor Mapping (REFORM}) framework. In summary, the pre-trained model is adapted to a new environment with different features, through model refining on only a small amount of training data in the current task. Experimental results over both synthetic and real-world tasks with diverse feature configurations validate the effectiveness and practical utility of the proposed framework.",
        "bibtex": "@InProceedings{pmlr-v80-ye18c,\n  title = \t {Rectify Heterogeneous Models with Semantic Mapping},\n  author =       {Ye, Han-Jia and Zhan, De-Chuan and Jiang, Yuan and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5630--5639},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ye2018c/ye2018c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ye18c.html},\n  abstract = \t {On the way to the robust learner for real-world applications, there are still great    challenges, including considering unknown environments with limited data. Learnware (Zhou; 2016) describes a novel perspective, and claims that learning models should have reusable and evolvable properties. We propose to Encode Meta InformaTion of features (EMIT), as the model specification for characterizing the changes, which grants the model evolvability to bridge heterogeneous feature spaces. Then, pre-trained models from related tasks can be Reused by our REctiFy via heterOgeneous pRedictor Mapping (REFORM}) framework. In summary, the pre-trained model is adapted to a new environment with different features, through model refining on only a small amount of training data in the current task. Experimental results over both synthetic and real-world tasks with diverse feature configurations validate the effectiveness and practical utility of the proposed framework.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ye2018c/ye2018c.pdf",
        "supp": "",
        "pdf_size": 1951124,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=510612421439784364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "aff_domain": "lamda.nju.edu.cn; ; ; ",
        "email": "lamda.nju.edu.cn; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ye18c.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Recurrent Predictive State Policy Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2062",
        "id": "2062",
        "author_site": "Ahmed Hefny, Zita Marinho, Wen Sun, Siddhartha Srinivasa, Geoff Gordon",
        "author": "Ahmed Hefny; Zita Marinho; Wen Sun; Siddhartha Srinivasa; Geoffrey Gordon",
        "abstract": "We introduce Recurrent Predictive State Policy(RPSP) networks, a recurrent architecture that brings insights from predictive state representations to reinforcement learning in partially ob-servable environments. Predictive state policy networks consist of a recursive filter, which keeps track of a belief about the state of the environment, and a reactive policy that directly maps beliefs to actions, to maximize the cumulative reward. The recursive filter leverages predictive state representations (PSRs) (Rosencrantz & Gordon, 2004; Sun et al., 2016) by modeling predictive state{\u2014}a prediction of the distribution of future observations conditioned on history and future actions.This representation gives rise to a rich class of statistically consistent algorithms (Hefny et al.,2017) to initialize the recursive filter. Predictive stats serves as an equivalent representation of a belief state. Therefore, the policy component of the RPSP-network can be purely reactive, simplifying training while still allowing optimal behavior. Moreover, we use the PSR interpretation during training as well, by incorporating prediction error in the loss function. The entire network (recursive filter and reactive policy) is still differentiable and can be trained using gradient-based methods. We optimize our policy using a combination of policy gradient based on rewards (Williams, 1992)and gradient descent based on prediction error.We show the efficacy of RPSP-networks on a set of robotic control tasks from OpenAI Gym. We empirically show that RPSP-networks perform well compared with memory-preserving networks such as GRUs, as well as finite memory models, being the overall best performing method.",
        "bibtex": "@InProceedings{pmlr-v80-hefny18a,\n  title = \t {Recurrent Predictive State Policy Networks},\n  author =       {Hefny, Ahmed and Marinho, Zita and Sun, Wen and Srinivasa, Siddhartha and Gordon, Geoffrey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1949--1958},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hefny18a/hefny18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hefny18a.html},\n  abstract = \t {We introduce Recurrent Predictive State Policy(RPSP) networks, a recurrent architecture that brings insights from predictive state representations to reinforcement learning in partially ob-servable environments. Predictive state policy networks consist of a recursive filter, which keeps track of a belief about the state of the environment, and a reactive policy that directly maps beliefs to actions, to maximize the cumulative reward. The recursive filter leverages predictive state representations (PSRs) (Rosencrantz & Gordon, 2004; Sun et al., 2016) by modeling predictive state{\u2014}a prediction of the distribution of future observations conditioned on history and future actions.This representation gives rise to a rich class of statistically consistent algorithms (Hefny et al.,2017) to initialize the recursive filter. Predictive stats serves as an equivalent representation of a belief state. Therefore, the policy component of the RPSP-network can be purely reactive, simplifying training while still allowing optimal behavior. Moreover, we use the PSR interpretation during training as well, by incorporating prediction error in the loss function. The entire network (recursive filter and reactive policy) is still differentiable and can be trained using gradient-based methods. We optimize our policy using a combination of policy gradient based on rewards (Williams, 1992)and gradient descent based on prediction error.We show the efficacy of RPSP-networks on a set of robotic control tasks from OpenAI Gym. We empirically show that RPSP-networks perform well compared with memory-preserving networks such as GRUs, as well as finite memory models, being the overall best performing method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hefny18a/hefny18a.pdf",
        "supp": "",
        "pdf_size": 2216333,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16983852333354823246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA+ISR/IT, Instituto Superior T\u00b4ecnico, Lisbon, Portugal; Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA+Robotics Institute, Carnegie Mellon University, Pittsburgh, USA+ISR/IT, Instituto Superior T\u00b4ecnico, Lisbon, Portugal; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA",
        "aff_domain": "cs.cmu.edu;cmu.edu; ; ; ",
        "email": "cs.cmu.edu;cmu.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/hefny18a.html",
        "aff_unique_index": "0+1;0+0+1;0;2;0",
        "aff_unique_norm": "Carnegie Mellon University;Instituto Superior T\u2019ecnico;University of Washington",
        "aff_unique_dep": "Machine Learning Department;ISR/IT;Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www IST.pt;https://www.washington.edu",
        "aff_unique_abbr": "CMU;IST;UW",
        "aff_campus_unique_index": "0+1;0+0+1;0;2;0",
        "aff_campus_unique": "Pittsburgh;Lisbon;Seattle",
        "aff_country_unique_index": "0+1;0+0+1;0;0;0",
        "aff_country_unique": "United States;Portugal"
    },
    {
        "title": "Regret Minimization for Partially Observable Deep Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2300",
        "id": "2300",
        "author_site": "Peter Jin, EECS Kurt Keutzer, Sergey Levine",
        "author": "Peter Jin; Kurt Keutzer; Sergey Levine",
        "abstract": "Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategies from raw image pixels. However, algorithms that estimate state and state-action value functions typically assume a fully observed state and must compensate for partial observations by using finite length observation histories or recurrent networks. In this work, we propose a new deep reinforcement learning algorithm based on counterfactual regret minimization that iteratively updates an approximation to an advantage-like function and is robust to partially observed state. We demonstrate that this new algorithm can substantially outperform strong baseline methods on several partially observed reinforcement learning tasks: learning first-person 3D navigation in Doom and Minecraft, and acting in the presence of partially observed objects in Doom and Pong.",
        "bibtex": "@InProceedings{pmlr-v80-jin18c,\n  title = \t {Regret Minimization for Partially Observable Deep Reinforcement Learning},\n  author =       {Jin, Peter and Keutzer, Kurt and Levine, Sergey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2342--2351},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jin18c/jin18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jin18c.html},\n  abstract = \t {Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategies from raw image pixels. However, algorithms that estimate state and state-action value functions typically assume a fully observed state and must compensate for partial observations by using finite length observation histories or recurrent networks. In this work, we propose a new deep reinforcement learning algorithm based on counterfactual regret minimization that iteratively updates an approximation to an advantage-like function and is robust to partially observed state. We demonstrate that this new algorithm can substantially outperform strong baseline methods on several partially observed reinforcement learning tasks: learning first-person 3D navigation in Doom and Minecraft, and acting in the presence of partially observed objects in Doom and Pong.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jin18c/jin18c.pdf",
        "supp": "",
        "pdf_size": 3515707,
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=43031357070841216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley",
        "aff_domain": "eecs.berkeley.edu; ; ",
        "email": "eecs.berkeley.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jin18c.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2182",
        "id": "2182",
        "author_site": "Yangchen Pan, Amir-massoud Farahmand, Martha White, Saleh Nabi, Piyush Grover, Daniel Nikovski",
        "author": "Yangchen Pan; Amir-massoud Farahmand; Martha White; Saleh Nabi; Piyush Grover; Daniel Nikovski",
        "abstract": "Recent work has shown that reinforcement learning (RL) is a promising approach to control dynamical systems described by partial differential equations (PDE). This paper shows how to use RL to tackle more general PDE control problems that have continuous high-dimensional action spaces with spatial relationship among action dimensions. In particular, we propose the concept of action descriptors, which encode regularities among spatially-extended action dimensions and enable the agent to control high-dimensional action PDEs. We provide theoretical evidence suggesting that this approach can be more sample efficient compared to a conventional approach that treats each action dimension separately and does not explicitly exploit the spatial regularity of the action space. The action descriptor approach is then used within the deep deterministic policy gradient algorithm. Experiments on two PDE control problems, with up to 256-dimensional continuous actions, show the advantage of the proposed approach over the conventional one.",
        "bibtex": "@InProceedings{pmlr-v80-pan18a,\n  title = \t {Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control},\n  author =       {Pan, Yangchen and Farahmand, Amir-massoud and White, Martha and Nabi, Saleh and Grover, Piyush and Nikovski, Daniel},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3986--3995},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pan18a/pan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pan18a.html},\n  abstract = \t {Recent work has shown that reinforcement learning (RL) is a promising approach to control dynamical systems described by partial differential equations (PDE). This paper shows how to use RL to tackle more general PDE control problems that have continuous high-dimensional action spaces with spatial relationship among action dimensions. In particular, we propose the concept of action descriptors, which encode regularities among spatially-extended action dimensions and enable the agent to control high-dimensional action PDEs. We provide theoretical evidence suggesting that this approach can be more sample efficient compared to a conventional approach that treats each action dimension separately and does not explicitly exploit the spatial regularity of the action space. The action descriptor approach is then used within the deep deterministic policy gradient algorithm. Experiments on two PDE control problems, with up to 256-dimensional continuous actions, show the advantage of the proposed approach over the conventional one.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pan18a/pan18a.pdf",
        "supp": "",
        "pdf_size": 377937,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1079902975975129290&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 16,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/pan18a.html"
    },
    {
        "title": "Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2298",
        "id": "2298",
        "author_site": "Xi Wu, Wooyeong Jang, Jiefeng Chen, Lingjiao Chen, Somesh Jha",
        "author": "Xi Wu; Uyeong Jang; Jiefeng Chen; Lingjiao Chen; Somesh Jha",
        "abstract": "In this paper we study leveraging",
        "bibtex": "@InProceedings{pmlr-v80-wu18e,\n  title = \t {Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training},\n  author =       {Wu, Xi and Jang, Uyeong and Chen, Jiefeng and Chen, Lingjiao and Jha, Somesh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5334--5342},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18e/wu18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18e.html},\n  abstract = \t {In this paper we study leveraging",
        "pdf": "http://proceedings.mlr.press/v80/wu18e/wu18e.pdf",
        "supp": "",
        "pdf_size": 346167,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13742337264510086392&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Google; University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": "cs.wisc.edu; ; ; ; ",
        "email": "cs.wisc.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/wu18e.html",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Google;University of Wisconsin-Madison",
        "aff_unique_dep": "Google;",
        "aff_unique_url": "https://www.google.com;https://www.wisc.edu",
        "aff_unique_abbr": "Google;UW-Madison",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Mountain View;Madison",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Representation Learning on Graphs with Jumping Knowledge Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2453",
        "id": "2453",
        "author_site": "Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, Stefanie Jegelka",
        "author": "Keyulu Xu; Chengtao Li; Yonglong Tian; Tomohiro Sonobe; Ken-ichi Kawarabayashi; Stefanie Jegelka",
        "abstract": "Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of \"neighboring\" nodes that a node\u2019s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture \u2013 jumping knowledge (JK) networks \u2013 that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models\u2019 performance.",
        "bibtex": "@InProceedings{pmlr-v80-xu18c,\n  title = \t {Representation Learning on Graphs with Jumping Knowledge Networks},\n  author =       {Xu, Keyulu and Li, Chengtao and Tian, Yonglong and Sonobe, Tomohiro and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5453--5462},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/xu18c/xu18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/xu18c.html},\n  abstract = \t {Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of \"neighboring\" nodes that a node\u2019s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture \u2013 jumping knowledge (JK) networks \u2013 that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models\u2019 performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/xu18c/xu18c.pdf",
        "supp": "",
        "pdf_size": 1628235,
        "gs_citation": 2591,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12324071567307935777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); National Institute of Informatics, Tokyo; National Institute of Informatics, Tokyo; Massachusetts Institute of Technology (MIT)",
        "aff_domain": "mit.edu; ; ; ; ;mit.edu",
        "email": "mit.edu; ; ; ; ;mit.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/xu18c.html",
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;National Institute of Informatics",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.nii.ac.jp",
        "aff_unique_abbr": "MIT;NII",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "title": "Representation Tradeoffs for Hyperbolic Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2289",
        "id": "2289",
        "author_site": "Frederic Sala, Christopher De Sa, Albert Gu, Christopher Re",
        "author": "Frederic Sala; Chris De Sa; Albert Gu; Christopher Re",
        "abstract": "Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures. We give a combinatorial construction that embeds trees into hyperbolic space with arbitrarily low distortion without optimization. On WordNet, this algorithm obtains a mean-average-precision of 0.989 with only two dimensions, outperforming existing work by 0.11 points. We provide bounds characterizing the precision-dimensionality tradeoff inherent in any hyperbolic embedding. To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS). We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that enables us to reduce dimensionality. Finally, we extract lessons from the algorithms and theory above to design a scalable PyTorch-based implementation that can handle incomplete information.",
        "bibtex": "@InProceedings{pmlr-v80-sala18a,\n  title = \t {Representation Tradeoffs for Hyperbolic Embeddings},\n  author =       {Sala, Frederic and De Sa, Chris and Gu, Albert and Re, Christopher},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4460--4469},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sala18a/sala18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sala18a.html},\n  abstract = \t {Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures. We give a combinatorial construction that embeds trees into hyperbolic space with arbitrarily low distortion without optimization. On WordNet, this algorithm obtains a mean-average-precision of 0.989 with only two dimensions, outperforming existing work by 0.11 points. We provide bounds characterizing the precision-dimensionality tradeoff inherent in any hyperbolic embedding. To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS). We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that enables us to reduce dimensionality. Finally, we extract lessons from the algorithms and theory above to design a scalable PyTorch-based implementation that can handle incomplete information.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sala18a/sala18a.pdf",
        "supp": "",
        "pdf_size": 676044,
        "gs_citation": 540,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3116913561482617946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Cornell University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University",
        "aff_domain": "stanford.edu; ; ; ",
        "email": "stanford.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sala18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Stanford University;Cornell University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Stanford;Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Residual Unfairness in Fair Machine Learning from Prejudiced Data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2314",
        "id": "2314",
        "author_site": "Nathan Kallus, Angela Zhou",
        "author": "Nathan Kallus; Angela Zhou",
        "abstract": "Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies. We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies. This scenario is particularly common in the same applications where fairness is a concern. We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear. We prove that, under certain conditions, fairness-adjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-the-art fair machine learning can have a \"bias in, bias out\" property. When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring. We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.",
        "bibtex": "@InProceedings{pmlr-v80-kallus18a,\n  title = \t {Residual Unfairness in Fair Machine Learning from Prejudiced Data},\n  author =       {Kallus, Nathan and Zhou, Angela},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2439--2448},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kallus18a.html},\n  abstract = \t {Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies. We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies. This scenario is particularly common in the same applications where fairness is a concern. We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear. We prove that, under certain conditions, fairness-adjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-the-art fair machine learning can have a \"bias in, bias out\" property. When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring. We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf",
        "supp": "",
        "pdf_size": 694926,
        "gs_citation": 174,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=405828268498431746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Cornell University, and Cornell Tech, New York; Cornell University, Ithaca, New York",
        "aff_domain": "cornell.edu;cornell.edu",
        "email": "cornell.edu;cornell.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kallus18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Revealing Common Statistical Behaviors in Heterogeneous Populations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2019",
        "id": "2019",
        "author_site": "Andrey Zhitnikov, Rotem Mulayoff, Tomer Michaeli",
        "author": "Andrey Zhitnikov; Rotem Mulayoff; Tomer Michaeli",
        "abstract": "In many areas of neuroscience and biological data analysis, it is desired to reveal common patterns among a group of subjects. Such analyses play important roles e.g., in detecting functional brain networks from fMRI scans and in identifying brain regions which show increased activity in response to certain stimuli. Group level techniques usually assume that all subjects in the group behave according to a single statistical model, or that deviations from the common model have simple parametric forms. Therefore, complex subject-specific deviations from the common model severely impair the performance of such methods. In this paper, we propose nonparametric algorithms for estimating the common covariance matrix and the common density function of several variables in a heterogeneous group of subjects. Our estimates converge to the true model as the number of subjects tends to infinity, under very mild conditions. We illustrate the effectiveness of our methods through extensive simulations as well as on real-data from fMRI scans and from arterial blood pressure and photoplethysmogram measurements.",
        "bibtex": "@InProceedings{pmlr-v80-zhitnikov18a,\n  title = \t {Revealing Common Statistical Behaviors in Heterogeneous Populations},\n  author =       {Zhitnikov, Andrey and Mulayoff, Rotem and Michaeli, Tomer},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5950--5959},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhitnikov18a/zhitnikov18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhitnikov18a.html},\n  abstract = \t {In many areas of neuroscience and biological data analysis, it is desired to reveal common patterns among a group of subjects. Such analyses play important roles e.g., in detecting functional brain networks from fMRI scans and in identifying brain regions which show increased activity in response to certain stimuli. Group level techniques usually assume that all subjects in the group behave according to a single statistical model, or that deviations from the common model have simple parametric forms. Therefore, complex subject-specific deviations from the common model severely impair the performance of such methods. In this paper, we propose nonparametric algorithms for estimating the common covariance matrix and the common density function of several variables in a heterogeneous group of subjects. Our estimates converge to the true model as the number of subjects tends to infinity, under very mild conditions. We illustrate the effectiveness of our methods through extensive simulations as well as on real-data from fMRI scans and from arterial blood pressure and photoplethysmogram measurements.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhitnikov18a/zhitnikov18a.pdf",
        "supp": "",
        "pdf_size": 1479047,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1169258290696258891&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Electrical Engineering Dept., Technion, Israel; Electrical Engineering Dept., Technion, Israel; Electrical Engineering Dept., Technion, Israel",
        "aff_domain": "campus.technion.ac.il;campus.technion.ac.il;ee.technion.ac.il",
        "email": "campus.technion.ac.il;campus.technion.ac.il;ee.technion.ac.il",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhitnikov18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technion",
        "aff_unique_dep": "Electrical Engineering Dept.",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Reviving and Improving Recurrent Back-Propagation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1998",
        "id": "1998",
        "author_site": "Renjie Liao, Yuwen Xiong, Ethan Fetaya, Lisa Zhang, KiJung Yoon, Zachary S Pitkow, Raquel Urtasun, Richard Zemel",
        "author": "Renjie Liao; Yuwen Xiong; Ethan Fetaya; Lisa Zhang; KiJung Yoon; Xaq Pitkow; Raquel Urtasun; Richard Zemel",
        "abstract": "In this paper, we revisit the recurrent back-propagation (RBP) algorithm, discuss the conditions under which it applies as well as how to satisfy them in deep neural networks. We show that RBP can be unstable and propose two variants based on conjugate gradient on the normal equations (CG-RBP) and Neumann series (Neumann-RBP). We further investigate the relationship between Neumann-RBP and back propagation through time (BPTT) and its truncated version (TBPTT). Our Neumann-RBP has the same time complexity as TBPTT but only requires constant memory, whereas TBPTT\u2019s memory cost scales linearly with the number of truncation steps. We examine all RBP variants along with BPTT and TBPTT in three different application domains: associative memory with continuous Hopfield networks, document classification in citation networks using graph neural networks and hyperparameter optimization for fully connected networks. All experiments demonstrate that RBPs, especially the Neumann-RBP variant, are efficient and effective for optimizing convergent recurrent neural networks.",
        "bibtex": "@InProceedings{pmlr-v80-liao18c,\n  title = \t {Reviving and Improving Recurrent Back-Propagation},\n  author =       {Liao, Renjie and Xiong, Yuwen and Fetaya, Ethan and Zhang, Lisa and Yoon, KiJung and Pitkow, Xaq and Urtasun, Raquel and Zemel, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3082--3091},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liao18c/liao18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liao18c.html},\n  abstract = \t {In this paper, we revisit the recurrent back-propagation (RBP) algorithm, discuss the conditions under which it applies as well as how to satisfy them in deep neural networks. We show that RBP can be unstable and propose two variants based on conjugate gradient on the normal equations (CG-RBP) and Neumann series (Neumann-RBP). We further investigate the relationship between Neumann-RBP and back propagation through time (BPTT) and its truncated version (TBPTT). Our Neumann-RBP has the same time complexity as TBPTT but only requires constant memory, whereas TBPTT\u2019s memory cost scales linearly with the number of truncation steps. We examine all RBP variants along with BPTT and TBPTT in three different application domains: associative memory with continuous Hopfield networks, document classification in citation networks using graph neural networks and hyperparameter optimization for fully connected networks. All experiments demonstrate that RBPs, especially the Neumann-RBP variant, are efficient and effective for optimizing convergent recurrent neural networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liao18c/liao18c.pdf",
        "supp": "",
        "pdf_size": 2417563,
        "gs_citation": 150,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8778638717316926195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Toronto+Uber ATG Toronto+Vector Institute; Department of Computer Science, University of Toronto+Uber ATG Toronto+Vector Institute; Department of Computer Science, University of Toronto+Vector Institute; Department of Computer Science, University of Toronto+Vector Institute; Department of Electrical and Computer Engineering, Rice University+Department of Neuroscience, Baylor College of Medicine; Department of Electrical and Computer Engineering, Rice University+Department of Neuroscience, Baylor College of Medicine; Department of Computer Science, University of Toronto+Uber ATG Toronto+Vector Institute; Department of Computer Science, University of Toronto+Vector Institute+Canadian Institute for Advanced Research",
        "aff_domain": "cs.toronto.edu; ; ; ; ; ; ; ",
        "email": "cs.toronto.edu; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/liao18c.html",
        "aff_unique_index": "0+1+2;0+1+2;0+2;0+2;3+4;3+4;0+1+2;0+2+5",
        "aff_unique_norm": "University of Toronto;Uber Advanced Technologies Group;Vector Institute;Rice University;Baylor College of Medicine;Canadian Institute for Advanced Research",
        "aff_unique_dep": "Department of Computer Science;Uber ATG;;Department of Electrical and Computer Engineering;Department of Neuroscience;",
        "aff_unique_url": "https://www.utoronto.ca;https://www.uber.com/atg;https://vectorinstitute.ai/;https://www.rice.edu;https://www.bcm.edu;https://www.cifar.ca",
        "aff_unique_abbr": "U of T;Uber ATG;Vector Institute;Rice;BCM;CIFAR",
        "aff_campus_unique_index": "0+0;0+0;0;0;;;0+0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0+0+0;0+0+0;0+0;0+0;1+1;1+1;0+0+0;0+0+0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "0aedaf87c7",
        "title": "Riemannian Stochastic Recursive Gradient Algorithm",
        "site": "https://proceedings.mlr.press/v80/kasai18a.html",
        "author": "Hiroyuki Kasai; Hiroyuki Sato; Bamdev Mishra",
        "abstract": "Stochastic variance reduction algorithms have recently become popular for minimizing the average of a large, but finite number of loss functions on a Riemannian manifold. The present paper proposes a Riemannian stochastic recursive gradient algorithm (R-SRG), which does not require the inverse of retraction between two distant iterates on the manifold. Convergence analyses of R-SRG are performed on both retraction-convex and non-convex functions under computationally efficient retraction and vector transport operations. The key challenge is analysis of the influence of vector transport along the retraction curve. Numerical evaluations reveal that R-SRG competes well with state-of-the-art Riemannian batch and stochastic gradient algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-kasai18a,\n  title = \t {{R}iemannian Stochastic Recursive Gradient Algorithm},\n  author =       {Kasai, Hiroyuki and Sato, Hiroyuki and Mishra, Bamdev},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2516--2524},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kasai18a/kasai18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kasai18a.html},\n  abstract = \t {Stochastic variance reduction algorithms have recently become popular for minimizing the average of a large, but finite number of loss functions on a Riemannian manifold. The present paper proposes a Riemannian stochastic recursive gradient algorithm (R-SRG), which does not require the inverse of retraction between two distant iterates on the manifold. Convergence analyses of R-SRG are performed on both retraction-convex and non-convex functions under computationally efficient retraction and vector transport operations. The key challenge is analysis of the influence of vector transport along the retraction curve. Numerical evaluations reveal that R-SRG competes well with state-of-the-art Riemannian batch and stochastic gradient algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kasai18a/kasai18a.pdf",
        "supp": "",
        "pdf_size": 204830,
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1195642732107493728&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "The University of Electro-Communications, Japan; Kyoto University, Japan; Microsoft, India",
        "aff_domain": "is.uec.ac.jp; ; ",
        "email": "is.uec.ac.jp; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Electro-Communications;Kyoto University;Microsoft",
        "aff_unique_dep": ";;Microsoft Corporation",
        "aff_unique_url": "https://www.uec.ac.jp;https://www.kyoto-u.ac.jp;https://www.microsoft.com/en-in",
        "aff_unique_abbr": "UEC;Kyoto U;Microsoft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Japan;India"
    },
    {
        "title": "Riemannian Stochastic Recursive Gradient Algorithm with Retraction and Vector Transport and Its Convergence Analysis",
        "author": "Hiroyuki Kasai, Hiroyuki Sato, Bamdev Mishra",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2109",
        "id": "2109"
    },
    {
        "title": "Robust and Scalable Models of Microbiome Dynamics",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2382",
        "id": "2382",
        "author_site": "Travis Gibson, Georg Gerber",
        "author": "Travis Gibson; Georg Gerber",
        "abstract": "Microbes are everywhere, including in and on our bodies, and have been shown to play key roles in a variety of prevalent human diseases. Consequently, there has been intense interest in the design of bacteriotherapies or \"bugs as drugs,\" which are communities of bacteria administered to patients for specific therapeutic applications. Central to the design of such therapeutics is an understanding of the causal microbial interaction network and the population dynamics of the organisms. In this work we present a Bayesian nonparametric model and associated efficient inference algorithm that addresses the key conceptual and practical challenges of learning microbial dynamics from time series microbe abundance data. These challenges include high-dimensional (300+ strains of bacteria in the gut) but temporally sparse and non-uniformly sampled data; high measurement noise; and, nonlinear and physically non-negative dynamics. Our contributions include a new type of dynamical systems model for microbial dynamics based on what we term interaction modules, or learned clusters of latent variables with redundant interaction structure (reducing the expected number of interaction coefficients from O(n^2) to O((log n)^2)); a fully Bayesian formulation of the stochastic dynamical systems model that propagates measurement and latent state uncertainty throughout the model; and introduction of a temporally varying auxiliary variable technique to enable efficient inference by relaxing the hard non-negativity constraint on states. We apply our method to simulated and real data, and demonstrate the utility of our technique for system identification from limited data and gaining new biological insights into bacteriotherapy design.",
        "bibtex": "@InProceedings{pmlr-v80-gibson18a,\n  title = \t {Robust and Scalable Models of Microbiome Dynamics},\n  author =       {Gibson, Travis and Gerber, Georg},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1763--1772},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gibson18a/gibson18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gibson18a.html},\n  abstract = \t {Microbes are everywhere, including in and on our bodies, and have been shown to play key roles in a variety of prevalent human diseases. Consequently, there has been intense interest in the design of bacteriotherapies or \"bugs as drugs,\" which are communities of bacteria administered to patients for specific therapeutic applications. Central to the design of such therapeutics is an understanding of the causal microbial interaction network and the population dynamics of the organisms. In this work we present a Bayesian nonparametric model and associated efficient inference algorithm that addresses the key conceptual and practical challenges of learning microbial dynamics from time series microbe abundance data. These challenges include high-dimensional (300+ strains of bacteria in the gut) but temporally sparse and non-uniformly sampled data; high measurement noise; and, nonlinear and physically non-negative dynamics. Our contributions include a new type of dynamical systems model for microbial dynamics based on what we term interaction modules, or learned clusters of latent variables with redundant interaction structure (reducing the expected number of interaction coefficients from O(n^2) to O((log n)^2)); a fully Bayesian formulation of the stochastic dynamical systems model that propagates measurement and latent state uncertainty throughout the model; and introduction of a temporally varying auxiliary variable technique to enable efficient inference by relaxing the hard non-negativity constraint on states. We apply our method to simulated and real data, and demonstrate the utility of our technique for system identification from limited data and gaining new biological insights into bacteriotherapy design.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gibson18a/gibson18a.pdf",
        "supp": "",
        "pdf_size": 2372803,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5375192108164837722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Massachusetts Host-Microbiome Center, Brigham and Women\u2019s Hospital, Harvard Medical School, Boston, MA, USA; Massachusetts Host-Microbiome Center, Brigham and Women\u2019s Hospital, Harvard Medical School, Boston, MA, USA",
        "aff_domain": "mit.edu;bwh.harvard.edu",
        "email": "mit.edu;bwh.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/gibson18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harvard Medical School",
        "aff_unique_dep": "Massachusetts Host-Microbiome Center",
        "aff_unique_url": "https://hms.harvard.edu",
        "aff_unique_abbr": "HMS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "SADAGRAD: Strongly Adaptive Stochastic Gradient Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2010",
        "id": "2010",
        "author_site": "Zaiyi Chen, Yi Xu, Enhong Chen, Tianbao Yang",
        "author": "Zaiyi Chen; Yi Xu; Enhong Chen; Tianbao Yang",
        "abstract": "Although the convergence rates of existing variants of ADAGRAD have a better dependence on the number of iterations under the strong convexity condition, their iteration complexities have a explicitly linear dependence on the dimensionality of the problem. To alleviate this bad dependence, we propose a simple yet novel variant of ADAGRAD for stochastic (weakly) strongly convex optimization. Different from existing variants, the proposed variant (referred to as SADAGRAD) uses an adaptive restarting scheme in which (i) ADAGRAD serves as a sub-routine and is restarted periodically; (ii) the number of iterations for restarting ADAGRAD depends on the history of learning that incorporates knowledge of the geometry of the data. In addition to the adaptive proximal functions and adaptive number of iterations for restarting, we also develop a variant that is adaptive to the (implicit) strong convexity from the data, which together makes the proposed algorithm strongly adaptive. In terms of iteration complexity, in the worst case SADAGRAD has an O(1/\\epsilon) for finding an \\epsilon-optimal solution similar to other variants. However, it could enjoy faster convergence and much better dependence on the problem\u2019s dimensionality when stochastic gradients are sparse. Extensive experiments on large-scale data sets demonstrate the efficiency of the proposed algorithms in comparison with several variants of ADAGRAD and stochastic gradient method.",
        "bibtex": "@InProceedings{pmlr-v80-chen18m,\n  title = \t {{SADAGRAD}: Strongly Adaptive Stochastic Gradient Methods},\n  author =       {Chen, Zaiyi and Xu, Yi and Chen, Enhong and Yang, Tianbao},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {913--921},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18m/chen18m.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18m.html},\n  abstract = \t {Although the convergence rates of existing variants of ADAGRAD have a better dependence on the number of iterations under the strong convexity condition, their iteration complexities have a explicitly linear dependence on the dimensionality of the problem. To alleviate this bad dependence, we propose a simple yet novel variant of ADAGRAD for stochastic (weakly) strongly convex optimization. Different from existing variants, the proposed variant (referred to as SADAGRAD) uses an adaptive restarting scheme in which (i) ADAGRAD serves as a sub-routine and is restarted periodically; (ii) the number of iterations for restarting ADAGRAD depends on the history of learning that incorporates knowledge of the geometry of the data. In addition to the adaptive proximal functions and adaptive number of iterations for restarting, we also develop a variant that is adaptive to the (implicit) strong convexity from the data, which together makes the proposed algorithm strongly adaptive. In terms of iteration complexity, in the worst case SADAGRAD has an O(1/\\epsilon) for finding an \\epsilon-optimal solution similar to other variants. However, it could enjoy faster convergence and much better dependence on the problem\u2019s dimensionality when stochastic gradients are sparse. Extensive experiments on large-scale data sets demonstrate the efficiency of the proposed algorithms in comparison with several variants of ADAGRAD and stochastic gradient method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18m/chen18m.pdf",
        "supp": "",
        "pdf_size": 702243,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2470227709311040074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of Science and Technology of China, China+The University of Iowa, USA; The University of Iowa, USA; University of Science and Technology of China, China; The University of Iowa, USA",
        "aff_domain": "mail.ustc.edu.cn;uiowa.edu; ;uiowa.edu",
        "email": "mail.ustc.edu.cn;uiowa.edu; ;uiowa.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/chen18m.html",
        "aff_unique_index": "0+1;1;0;1",
        "aff_unique_norm": "University of Science and Technology of China;University of Iowa",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.ustc.edu.cn;https://www.uiowa.edu",
        "aff_unique_abbr": "USTC;UIowa",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "SAFFRON: an Adaptive Algorithm for Online Control of the False Discovery Rate",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2207",
        "id": "2207",
        "author_site": "Aaditya Ramdas, Tijana Zrnic, Martin Wainwright, Michael Jordan",
        "author": "Aaditya Ramdas; Tijana Zrnic; Martin Wainwright; Michael Jordan",
        "abstract": "In the online false discovery rate (FDR) problem, one observes a possibly infinite sequence of $p$-values $P_1,P_2,\u2026$, each testing a different null hypothesis, and an algorithm must pick a sequence of rejection thresholds $\\alpha_1,\\alpha_2,\u2026$ in an online fashion, effectively rejecting the $k$-th null hypothesis whenever $P_k \\leq \\alpha_k$. Importantly, $\\alpha_k$ must be a function of the past, and cannot depend on $P_k$ or any of the later unseen $p$-values, and must be chosen to guarantee that for any time $t$, the FDR up to time $t$ is less than some pre-determined quantity $\\alpha \\in (0,1)$. In this work, we present a powerful new framework for online FDR control that we refer to as \u201cSAFFRON\u201d. Like older alpha-investing algorithms, SAFFRON starts off with an error budget (called alpha-wealth) that it intelligently allocates to different tests over time, earning back some alpha-wealth whenever it makes a new discovery. However, unlike older methods, SAFFRON\u2019s threshold sequence is based on a novel estimate of the alpha fraction that it allocates to true null hypotheses. In the offline setting, algorithms that employ an estimate of the proportion of true nulls are called \u201cadaptive\u201d, hence SAFFRON can be seen as an online analogue of the offline Storey-BH adaptive procedure. Just as Storey-BH is typically more powerful than the Benjamini-Hochberg (BH) procedure under independence, we demonstrate that SAFFRON is also more powerful than its non-adaptive counterparts such as LORD.",
        "bibtex": "@InProceedings{pmlr-v80-ramdas18a,\n  title = \t {{SAFFRON}: an Adaptive Algorithm for Online Control of the False Discovery Rate},\n  author =       {Ramdas, Aaditya and Zrnic, Tijana and Wainwright, Martin and Jordan, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4286--4294},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ramdas18a/ramdas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ramdas18a.html},\n  abstract = \t {In the online false discovery rate (FDR) problem, one observes a possibly infinite sequence of $p$-values $P_1,P_2,\u2026$, each testing a different null hypothesis, and an algorithm must pick a sequence of rejection thresholds $\\alpha_1,\\alpha_2,\u2026$ in an online fashion, effectively rejecting the $k$-th null hypothesis whenever $P_k \\leq \\alpha_k$. Importantly, $\\alpha_k$ must be a function of the past, and cannot depend on $P_k$ or any of the later unseen $p$-values, and must be chosen to guarantee that for any time $t$, the FDR up to time $t$ is less than some pre-determined quantity $\\alpha \\in (0,1)$. In this work, we present a powerful new framework for online FDR control that we refer to as \u201cSAFFRON\u201d. Like older alpha-investing algorithms, SAFFRON starts off with an error budget (called alpha-wealth) that it intelligently allocates to different tests over time, earning back some alpha-wealth whenever it makes a new discovery. However, unlike older methods, SAFFRON\u2019s threshold sequence is based on a novel estimate of the alpha fraction that it allocates to true null hypotheses. In the offline setting, algorithms that employ an estimate of the proportion of true nulls are called \u201cadaptive\u201d, hence SAFFRON can be seen as an online analogue of the offline Storey-BH adaptive procedure. Just as Storey-BH is typically more powerful than the Benjamini-Hochberg (BH) procedure under independence, we demonstrate that SAFFRON is also more powerful than its non-adaptive counterparts such as LORD.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ramdas18a/ramdas18a.pdf",
        "supp": "",
        "pdf_size": 2033821,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3162538214212248602&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Departments of Statistics and Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Departments of Statistics and Electrical Engineering and Computer Sciences, University of California, Berkeley; Departments of Statistics and Electrical Engineering and Computer Sciences, University of California, Berkeley",
        "aff_domain": "eecs.berkeley.edu;eecs.berkeley.edu;eecs.berkeley.edu;eecs.berkeley.edu",
        "email": "eecs.berkeley.edu;eecs.berkeley.edu;eecs.berkeley.edu;eecs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ramdas18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Departments of Statistics and Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2441",
        "id": "2441",
        "author_site": "Bo Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu Chen, Le Song",
        "author": "Bo Dai; Albert Shaw; Lihong Li; Lin Xiao; Niao He; Zhen Liu; Jianshu Chen; Le Song",
        "abstract": "When function approximation is used, solving the Bellman optimality equation with stability guarantees has remained a major open problem in reinforcement learning for decades. The fundamental difficulty is that the Bellman operator may become an expansion in general, resulting in oscillating and even divergent behavior of popular algorithms like Q-learning. In this paper, we revisit the Bellman equation, and reformulate it into a novel primal-dual optimization problem using Nesterov\u2019s smoothing technique and the Legendre-Fenchel transformation. We then develop a new algorithm, called Smoothed Bellman Error Embedding, to solve this optimization problem where any differentiable function class may be used. We provide what we believe to be the first convergence guarantee for general nonlinear function approximation, and analyze the algorithm\u2019s sample complexity. Empirically, our algorithm compares favorably to state-of-the-art baselines in several benchmark control problems.",
        "bibtex": "@InProceedings{pmlr-v80-dai18c,\n  title = \t {{SBEED}: Convergent Reinforcement Learning with Nonlinear Function Approximation},\n  author =       {Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1125--1134},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dai18c/dai18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dai18c.html},\n  abstract = \t {When function approximation is used, solving the Bellman optimality equation with stability guarantees has remained a major open problem in reinforcement learning for decades. The fundamental difficulty is that the Bellman operator may become an expansion in general, resulting in oscillating and even divergent behavior of popular algorithms like Q-learning. In this paper, we revisit the Bellman equation, and reformulate it into a novel primal-dual optimization problem using Nesterov\u2019s smoothing technique and the Legendre-Fenchel transformation. We then develop a new algorithm, called Smoothed Bellman Error Embedding, to solve this optimization problem where any differentiable function class may be used. We provide what we believe to be the first convergence guarantee for general nonlinear function approximation, and analyze the algorithm\u2019s sample complexity. Empirically, our algorithm compares favorably to state-of-the-art baselines in several benchmark control problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dai18c/dai18c.pdf",
        "supp": "",
        "pdf_size": 3512002,
        "gs_citation": 336,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=199898117532548110&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Google Inc.; Microsoft Research; University of Illinois at Urbana Champaign; Georgia Institute of Technology; Tencent AI Lab; Georgia Institute of Technology",
        "aff_domain": "gatech.edu; ; ; ; ; ; ; ",
        "email": "gatech.edu; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/dai18c.html",
        "aff_unique_index": "0;0;1;2;3;0;4;0",
        "aff_unique_norm": "Georgia Institute of Technology;Google;Microsoft;University of Illinois Urbana-Champaign;Tencent",
        "aff_unique_dep": ";Google;Microsoft Research;;Tencent AI Lab",
        "aff_unique_url": "https://www.gatech.edu;https://www.google.com;https://www.microsoft.com/en-us/research;https://illinois.edu;https://ai.tencent.com",
        "aff_unique_abbr": "Georgia Tech;Google;MSR;UIUC;Tencent AI Lab",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Mountain View;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "SGD and Hogwild! Convergence Without the Bounded Gradients Assumption",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2313",
        "id": "2313",
        "author_site": "Lam Nguyen, PHUONG_HA NGUYEN, Marten van Dijk, Peter Richtarik, Katya Scheinberg, Martin Takac",
        "author": "Lam Nguyen; PHUONG HA NGUYEN; Marten Dijk; Peter Richtarik; Katya Scheinberg; Martin Takac",
        "abstract": "Stochastic gradient descent (SGD) is the optimization algorithm of choice in many machine learning applications such as regularized empirical risk minimization and training deep neural networks. The classical convergence analysis of SGD is carried out under the assumption that the norm of the stochastic gradient is uniformly bounded. While this might hold for some loss functions, it is always violated for cases where the objective function is strongly convex. In (Bottou et al.,2016), a new analysis of convergence of SGD is performed under the assumption that stochastic gradients are bounded with respect to the true gradient norm. Here we show that for stochastic problems arising in machine learning such bound always holds; and we also propose an alternative convergence analysis of SGD with diminishing learning rate regime, which results in more relaxed conditions than those in (Bottou et al.,2016). We then move on the asynchronous parallel setting, and prove convergence of Hogwild! algorithm in the same regime, obtaining the first convergence results for this method in the case of diminished learning rate.",
        "bibtex": "@InProceedings{pmlr-v80-nguyen18c,\n  title = \t {{SGD} and Hogwild! {C}onvergence Without the Bounded Gradients Assumption},\n  author =       {Nguyen, Lam and NGUYEN, PHUONG HA and van Dijk, Marten and Richtarik, Peter and Scheinberg, Katya and Takac, Martin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3750--3758},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nguyen18c/nguyen18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nguyen18c.html},\n  abstract = \t {Stochastic gradient descent (SGD) is the optimization algorithm of choice in many machine learning applications such as regularized empirical risk minimization and training deep neural networks. The classical convergence analysis of SGD is carried out under the assumption that the norm of the stochastic gradient is uniformly bounded. While this might hold for some loss functions, it is always violated for cases where the objective function is strongly convex. In (Bottou et al.,2016), a new analysis of convergence of SGD is performed under the assumption that stochastic gradients are bounded with respect to the true gradient norm. Here we show that for stochastic problems arising in machine learning such bound always holds; and we also propose an alternative convergence analysis of SGD with diminishing learning rate regime, which results in more relaxed conditions than those in (Bottou et al.,2016). We then move on the asynchronous parallel setting, and prove convergence of Hogwild! algorithm in the same regime, obtaining the first convergence results for this method in the case of diminished learning rate.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nguyen18c/nguyen18c.pdf",
        "supp": "",
        "pdf_size": 1010164,
        "gs_citation": 266,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5075667541281540650&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "Department of Industrial and Systems Engineering, Lehigh University, USA + IBM Thomas J. Watson Research Center, USA; Department of Electrical and Computer Engineering, University of Connecticut, USA; Department of Electrical and Computer Engineering, University of Connecticut, USA; KAUST, KSA \u2014 Edinburgh, UK \u2014 MIPT, Russia; Department of Industrial and Systems Engineering, Lehigh University, USA; Department of Industrial and Systems Engineering, Lehigh University, USA",
        "aff_domain": "gmail.com;gmail.com;uconn.edu;ed.ac.uk;lehigh.edu;gmail.com",
        "email": "gmail.com;gmail.com;uconn.edu;ed.ac.uk;lehigh.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/nguyen18c.html",
        "aff_unique_index": "0+1;2;2;3;0;0",
        "aff_unique_norm": "Lehigh University;IBM;University of Connecticut;King Abdullah University of Science and Technology",
        "aff_unique_dep": "Department of Industrial and Systems Engineering;IBM Thomas J. Watson Research Center;Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.lehigh.edu;https://www.ibm.com/research/watson;https://www.uconn.edu;https://www.kaust.edu.sa",
        "aff_unique_abbr": "Lehigh;IBM Watson;UConn;KAUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0;1;0;0",
        "aff_country_unique": "United States;Saudi Arabia"
    },
    {
        "title": "SMAC: Simultaneous Mapping and Clustering Using Spectral Decompositions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1899",
        "id": "1899",
        "author_site": "chandrajit bajaj, Tingran Gao, Zihang He, Qixing Huang, Zhenxiao Liang",
        "author": "Chandrajit Bajaj; Tingran Gao; Zihang He; Qixing Huang; Zhenxiao Liang",
        "abstract": "We introduce a principled approach for",
        "bibtex": "@InProceedings{pmlr-v80-bajaj18a,\n  title = \t {{SMAC}: Simultaneous Mapping and Clustering Using Spectral Decompositions},\n  author =       {Bajaj, Chandrajit and Gao, Tingran and He, Zihang and Huang, Qixing and Liang, Zhenxiao},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {324--333},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bajaj18a/bajaj18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bajaj18a.html},\n  abstract = \t {We introduce a principled approach for",
        "pdf": "http://proceedings.mlr.press/v80/bajaj18a/bajaj18a.pdf",
        "supp": "",
        "pdf_size": 3480078,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9495142807567688382&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, The University of Texas at Austin; Department of Statistics, The University of Chicago; Institute for Interdisciplinary Information Sciences, Tsinghua University; Department of Computer Science, The University of Texas at Austin; Institute for Interdisciplinary Information Sciences, Tsinghua University",
        "aff_domain": "cs.utexas.edu; ; ;cs.utexas.edu; ",
        "email": "cs.utexas.edu; ; ;cs.utexas.edu; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/bajaj18a.html",
        "aff_unique_index": "0;1;2;0;2",
        "aff_unique_norm": "University of Texas at Austin;University of Chicago;Tsinghua University",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics;Institute for Interdisciplinary Information Sciences",
        "aff_unique_url": "https://www.utexas.edu;https://www.uchicago.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UT Austin;UChicago;Tsinghua",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "SQL-Rank: A Listwise Approach to Collaborative Ranking",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2098",
        "id": "2098",
        "author_site": "LIWEI WU, Cho-Jui Hsieh, University of California James Sharpnack",
        "author": "Liwei Wu; Cho-Jui Hsieh; James Sharpnack",
        "abstract": "In this paper, we propose a listwise approach for constructing user-specific rankings in recommendation systems in a collaborative fashion. We contrast the listwise approach to previous pointwise and pairwise approaches, which are based on treating either each rating or each pairwise comparison as an independent instance respectively. By extending the work of ListNet (Cao et al., 2007), we cast listwise collaborative ranking as maximum likelihood under a permutation model which applies probability mass to permutations based on a low rank latent score matrix. We present a novel algorithm called SQL-Rank, which can accommodate ties and missing data and can run in linear time. We develop a theoretical framework for analyzing listwise ranking methods based on a novel representation theory for the permutation model. Applying this framework to collaborative ranking, we derive asymptotic statistical rates as the number of users and items grow together. We conclude by demonstrating that our SQL-Rank method often outperforms current state-of-the-art algorithms for implicit feedback such as Weighted-MF and BPR and achieve favorable results when compared to explicit feedback algorithms such as matrix factorization and collaborative ranking.",
        "bibtex": "@InProceedings{pmlr-v80-wu18c,\n  title = \t {{SQL}-Rank: A Listwise Approach to Collaborative Ranking},\n  author =       {Wu, Liwei and Hsieh, Cho-Jui and Sharpnack, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5315--5324},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18c/wu18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18c.html},\n  abstract = \t {In this paper, we propose a listwise approach for constructing user-specific rankings in recommendation systems in a collaborative fashion. We contrast the listwise approach to previous pointwise and pairwise approaches, which are based on treating either each rating or each pairwise comparison as an independent instance respectively. By extending the work of ListNet (Cao et al., 2007), we cast listwise collaborative ranking as maximum likelihood under a permutation model which applies probability mass to permutations based on a low rank latent score matrix. We present a novel algorithm called SQL-Rank, which can accommodate ties and missing data and can run in linear time. We develop a theoretical framework for analyzing listwise ranking methods based on a novel representation theory for the permutation model. Applying this framework to collaborative ranking, we derive asymptotic statistical rates as the number of users and items grow together. We conclude by demonstrating that our SQL-Rank method often outperforms current state-of-the-art algorithms for implicit feedback such as Weighted-MF and BPR and achieve favorable results when compared to explicit feedback algorithms such as matrix factorization and collaborative ranking.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18c/wu18c.pdf",
        "supp": "",
        "pdf_size": 788123,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3011153619955791541&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, University of California, Davis, CA, USA+Department of Computer Science, University of California, Davis, CA, USA; Department of Statistics, University of California, Davis, CA, USA+Department of Computer Science, University of California, Davis, CA, USA; Department of Statistics, University of California, Davis, CA, USA+Department of Computer Science, University of California, Davis, CA, USA",
        "aff_domain": "ucdavis.com; ; ",
        "email": "ucdavis.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wu18c.html",
        "aff_unique_index": "0+0;0+0;0+0",
        "aff_unique_norm": "University of California, Davis",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Davis",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "Davis",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Safe Element Screening for Submodular Function Minimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1883",
        "id": "1883",
        "author_site": "Weizhong Zhang, Bin Hong, Lin Ma, Wei Liu, Tong Zhang",
        "author": "Weizhong Zhang; Bin Hong; Lin Ma; Wei Liu; Tong Zhang",
        "abstract": "Submodular functions are discrete analogs of convex functions, which have applications in various fields, including machine learning and computer vision. However, in large-scale applications, solving Submodular Function Minimization (SFM) problems remains challenging. In this paper, we make the first attempt to extend the emerging technique named screening in large-scale sparse learning to SFM for accelerating its optimization process. We first conduct a careful studying of the relationships between SFM and the corresponding convex proximal problems, as well as the accurate primal optimum estimation of the proximal problems. Relying on this study, we subsequently propose a novel safe screening method to quickly identify the elements guaranteed to be included (we refer to them as active) or excluded (inactive) in the final optimal solution of SFM during the optimization process. By removing the inactive elements and fixing the active ones, the problem size can be dramatically reduced, leading to great savings in the computational cost without sacrificing any accuracy. To the best of our knowledge, the proposed method is the first screening method in the fields of SFM and even combinatorial optimization, thus pointing out a new direction for accelerating SFM algorithms. Experiment results on both synthetic and real datasets demonstrate the significant speedups gained by our approach.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18e,\n  title = \t {Safe Element Screening for Submodular Function Minimization},\n  author =       {Zhang, Weizhong and Hong, Bin and Ma, Lin and Liu, Wei and Zhang, Tong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5786--5795},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18e/zhang18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18e.html},\n  abstract = \t {Submodular functions are discrete analogs of convex functions, which have applications in various fields, including machine learning and computer vision. However, in large-scale applications, solving Submodular Function Minimization (SFM) problems remains challenging. In this paper, we make the first attempt to extend the emerging technique named screening in large-scale sparse learning to SFM for accelerating its optimization process. We first conduct a careful studying of the relationships between SFM and the corresponding convex proximal problems, as well as the accurate primal optimum estimation of the proximal problems. Relying on this study, we subsequently propose a novel safe screening method to quickly identify the elements guaranteed to be included (we refer to them as active) or excluded (inactive) in the final optimal solution of SFM during the optimization process. By removing the inactive elements and fixing the active ones, the problem size can be dramatically reduced, leading to great savings in the computational cost without sacrificing any accuracy. To the best of our knowledge, the proposed method is the first screening method in the fields of SFM and even combinatorial optimization, thus pointing out a new direction for accelerating SFM algorithms. Experiment results on both synthetic and real datasets demonstrate the significant speedups gained by our approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18e/zhang18e.pdf",
        "supp": "",
        "pdf_size": 606662,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15317060090993949475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Tencent AI Lab; State Key Lab of CAD &CG, Zhejiang University; Tencent AI Lab; Tencent AI Lab; Tencent AI Lab",
        "aff_domain": "gmail.com;gmail.com;gmail.com;columbia.edu;tongzhang-ml.org",
        "email": "gmail.com;gmail.com;gmail.com;columbia.edu;tongzhang-ml.org",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/zhang18e.html",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tencent;Zhejiang University",
        "aff_unique_dep": "Tencent AI Lab;State Key Lab of CAD &CG",
        "aff_unique_url": "https://ai.tencent.com;http://www.zju.edu.cn",
        "aff_unique_abbr": "Tencent AI Lab;ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Scalable Bilinear Pi Learning Using State and Action Features",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2330",
        "id": "2330",
        "author_site": "Yichen Chen, Lihong Li, Mengdi Wang",
        "author": "Yichen Chen; Lihong Li; Mengdi Wang",
        "abstract": "Approximate linear programming (ALP) represents one of the major algorithmic families to solve large-scale Markov decision processes (MDP). In this work, we study a primal-dual formulation of the ALP, and develop a scalable, model-free algorithm called bilinear $\\pi$ learning for reinforcement learning when a sampling oracle is provided. This algorithm enjoys a number of advantages. First, it adopts linear and bilinear models to represent the high-dimensional value function and state-action distributions, respectively, using given state and action features. Its run-time complexity depends on the number of features, not the size of the underlying MDPs. Second, it operates in a fully online fashion without having to store any sample, thus having minimal memory footprint. Third, we prove that it is sample-efficient, solving for the optimal policy to high precision with a sample complexity linear in the dimension of the parameter space.",
        "bibtex": "@InProceedings{pmlr-v80-chen18e,\n  title = \t {Scalable Bilinear Pi Learning Using State and Action Features},\n  author =       {Chen, Yichen and Li, Lihong and Wang, Mengdi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {834--843},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18e/chen18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18e.html},\n  abstract = \t {Approximate linear programming (ALP) represents one of the major algorithmic families to solve large-scale Markov decision processes (MDP). In this work, we study a primal-dual formulation of the ALP, and develop a scalable, model-free algorithm called bilinear $\\pi$ learning for reinforcement learning when a sampling oracle is provided. This algorithm enjoys a number of advantages. First, it adopts linear and bilinear models to represent the high-dimensional value function and state-action distributions, respectively, using given state and action features. Its run-time complexity depends on the number of features, not the size of the underlying MDPs. Second, it operates in a fully online fashion without having to store any sample, thus having minimal memory footprint. Third, we prove that it is sample-efficient, solving for the optimal policy to high precision with a sample complexity linear in the dimension of the parameter space.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18e/chen18e.pdf",
        "supp": "",
        "pdf_size": 354344,
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17790401326999704410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Princeton University; Google Inc.; Department of Operations Research and Financial Engineering, Princeton University",
        "aff_domain": "princeton.edu;google.com;princeton.edu",
        "email": "princeton.edu;google.com;princeton.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chen18e.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Princeton University;Google",
        "aff_unique_dep": "Department of Computer Science;Google",
        "aff_unique_url": "https://www.princeton.edu;https://www.google.com",
        "aff_unique_abbr": "Princeton;Google",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1927",
        "id": "1927",
        "author_site": "Ehsan Kazemi, Morteza Zadimoghaddam, Amin Karbasi",
        "author": "Ehsan Kazemi; Morteza Zadimoghaddam; Amin Karbasi",
        "abstract": "Can we efficiently extract useful information from a large user-generated dataset while protecting the privacy of the users and/or ensuring fairness in representation? We cast this problem as an instance of a deletion-robust submodular maximization where part of the data may be deleted or masked due to privacy concerns or fairness criteria. We propose the first memory-efficient centralized, streaming, and distributed methods with constant-factor approximation guarantees against",
        "bibtex": "@InProceedings{pmlr-v80-kazemi18a,\n  title = \t {Scalable Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints},\n  author =       {Kazemi, Ehsan and Zadimoghaddam, Morteza and Karbasi, Amin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2544--2553},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kazemi18a/kazemi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kazemi18a.html},\n  abstract = \t {Can we efficiently extract useful information from a large user-generated dataset while protecting the privacy of the users and/or ensuring fairness in representation? We cast this problem as an instance of a deletion-robust submodular maximization where part of the data may be deleted or masked due to privacy concerns or fairness criteria. We propose the first memory-efficient centralized, streaming, and distributed methods with constant-factor approximation guarantees against",
        "pdf": "http://proceedings.mlr.press/v80/kazemi18a/kazemi18a.pdf",
        "supp": "",
        "pdf_size": 1343151,
        "gs_citation": 84,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1034921809595727020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Yale University, New Haven, Connecticut, USA; Google Research, Zurich, Switzerland; Department of Computer Science, Yale University, New Haven, Connecticut, USA",
        "aff_domain": "yale.edu; ;yale.edu",
        "email": "yale.edu; ;yale.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kazemi18a.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Yale University;Google",
        "aff_unique_dep": "Department of Computer Science;Google Research",
        "aff_unique_url": "https://www.yale.edu;https://research.google",
        "aff_unique_abbr": "Yale;Google",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "New Haven;Zurich",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "title": "Scalable Gaussian Processes with Grid-Structured Eigenfunctions (GP-GRIEF)",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2139",
        "id": "2139",
        "author_site": "Trefor Evans, Prasanth B Nair",
        "author": "Trefor Evans; Prasanth Nair",
        "abstract": "We introduce a kernel approximation strategy that enables computation of the Gaussian process log marginal likelihood and all hyperparameter derivatives in O(p) time. Our GRIEF kernel consists of p eigenfunctions found using a Nystrom approximation from a dense Cartesian product grid of inducing points. By exploiting algebraic properties of Kronecker and Khatri-Rao tensor products, computational complexity of the training procedure can be practically independent of the number of inducing points. This allows us to use arbitrarily many inducing points to achieve a globally accurate kernel approximation, even in high-dimensional problems. The fast likelihood evaluation enables type-I or II Bayesian inference on large-scale datasets. We benchmark our algorithms on real-world problems with up to two-million training points and 10^33 inducing points.",
        "bibtex": "@InProceedings{pmlr-v80-evans18a,\n  title = \t {Scalable {G}aussian Processes with Grid-Structured Eigenfunctions ({GP}-{GRIEF})},\n  author =       {Evans, Trefor and Nair, Prasanth},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1417--1426},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/evans18a/evans18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/evans18a.html},\n  abstract = \t {We introduce a kernel approximation strategy that enables computation of the Gaussian process log marginal likelihood and all hyperparameter derivatives in O(p) time. Our GRIEF kernel consists of p eigenfunctions found using a Nystrom approximation from a dense Cartesian product grid of inducing points. By exploiting algebraic properties of Kronecker and Khatri-Rao tensor products, computational complexity of the training procedure can be practically independent of the number of inducing points. This allows us to use arbitrarily many inducing points to achieve a globally accurate kernel approximation, even in high-dimensional problems. The fast likelihood evaluation enables type-I or II Bayesian inference on large-scale datasets. We benchmark our algorithms on real-world problems with up to two-million training points and 10^33 inducing points.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/evans18a/evans18a.pdf",
        "supp": "",
        "pdf_size": 753814,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16145188730835971053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Toronto; University of Toronto",
        "aff_domain": "mail.utoronto.ca;utias.utoronto.ca",
        "email": "mail.utoronto.ca;utias.utoronto.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/evans18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Scalable approximate Bayesian inference for particle tracking data",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2375",
        "id": "2375",
        "author_site": "Ruoxi Sun, Department of Statistics Liam Paninski",
        "author": "Ruoxi Sun; Liam Paninski",
        "abstract": "Many important datasets in physics, chemistry, and biology consist of noisy sequences of images of multiple moving overlapping particles. In many cases, the observed particles are indistinguishable, leading to unavoidable uncertainty about nearby particles\u2019 identities. Exact Bayesian inference is intractable in this setting, and previous approximate Bayesian methods scale poorly. Non-Bayesian approaches that output a single \u201cbest\u201d estimate of the particle tracks (thus discarding important uncertainty information) are therefore dominant in practice. Here we propose a flexible and scalable amortized approach for Bayesian inference on this task. We introduce a novel neural network method to approximate the (intractable) filter-backward-sample-forward algorithm for Bayesian inference in this setting. By varying the simulated training data for the network, we can perform inference on a wide variety of data types. This approach is therefore highly flexible and improves on the state of the art in terms of accuracy; provides uncertainty estimates about the particle locations and identities; and has a test run-time that scales linearly as a function of the data length and number of particles, thus enabling Bayesian inference in arbitrarily large particle tracking datasets.",
        "bibtex": "@InProceedings{pmlr-v80-sun18b,\n  title = \t {Scalable approximate {B}ayesian inference for particle tracking data},\n  author =       {Sun, Ruoxi and Paninski, Liam},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4800--4809},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sun18b/sun18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sun18b.html},\n  abstract = \t {Many important datasets in physics, chemistry, and biology consist of noisy sequences of images of multiple moving overlapping particles. In many cases, the observed particles are indistinguishable, leading to unavoidable uncertainty about nearby particles\u2019 identities. Exact Bayesian inference is intractable in this setting, and previous approximate Bayesian methods scale poorly. Non-Bayesian approaches that output a single \u201cbest\u201d estimate of the particle tracks (thus discarding important uncertainty information) are therefore dominant in practice. Here we propose a flexible and scalable amortized approach for Bayesian inference on this task. We introduce a novel neural network method to approximate the (intractable) filter-backward-sample-forward algorithm for Bayesian inference in this setting. By varying the simulated training data for the network, we can perform inference on a wide variety of data types. This approach is therefore highly flexible and improves on the state of the art in terms of accuracy; provides uncertainty estimates about the particle locations and identities; and has a test run-time that scales linearly as a function of the data length and number of particles, thus enabling Bayesian inference in arbitrarily large particle tracking datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sun18b/sun18b.pdf",
        "supp": "",
        "pdf_size": 1548155,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8017063234741228178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/sun18b.html"
    },
    {
        "title": "Selecting Representative Examples for Program Synthesis",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2384",
        "id": "2384",
        "author_site": "Yewen Pu, Zachery Miranda, Armando Solar-Lezama, Leslie Kaelbling",
        "author": "Yewen Pu; Zachery Miranda; Armando Solar-Lezama; Leslie Kaelbling",
        "abstract": "Program synthesis is a class of regression problems where one seeks a solution, in the form of a source-code program, mapping the inputs to their corresponding outputs exactly. Due to its precise and combinatorial nature, program synthesis is commonly formulated as a constraint satisfaction problem, where input-output examples are encoded as constraints and solved with a constraint solver. A key challenge of this formulation is scalability: while constraint solvers work well with a few well-chosen examples, a large set of examples can incur significant overhead in both time and memory. We describe a method to discover a subset of examples that is both small and representative: the subset is constructed iteratively, using a neural network to predict the probability of unchosen examples conditioned on the chosen examples in the subset, and greedily adding the least probable example. We empirically evaluate the representativeness of the subsets constructed by our method, and demonstrate such subsets can significantly improve synthesis time and stability.",
        "bibtex": "@InProceedings{pmlr-v80-pu18b,\n  title = \t {Selecting Representative Examples for Program Synthesis},\n  author =       {Pu, Yewen and Miranda, Zachery and Solar-Lezama, Armando and Kaelbling, Leslie},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4161--4170},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pu18b/pu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pu18b.html},\n  abstract = \t {Program synthesis is a class of regression problems where one seeks a solution, in the form of a source-code program, mapping the inputs to their corresponding outputs exactly. Due to its precise and combinatorial nature, program synthesis is commonly formulated as a constraint satisfaction problem, where input-output examples are encoded as constraints and solved with a constraint solver. A key challenge of this formulation is scalability: while constraint solvers work well with a few well-chosen examples, a large set of examples can incur significant overhead in both time and memory. We describe a method to discover a subset of examples that is both small and representative: the subset is constructed iteratively, using a neural network to predict the probability of unchosen examples conditioned on the chosen examples in the subset, and greedily adding the least probable example. We empirically evaluate the representativeness of the subsets constructed by our method, and demonstrate such subsets can significantly improve synthesis time and stability.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pu18b/pu18b.pdf",
        "supp": "",
        "pdf_size": 693377,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18419281465561462811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu; ; ; ",
        "email": "mit.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/pu18b.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Self-Bounded Prediction Suffix Tree via Approximate String Matching",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2112",
        "id": "2112",
        "author_site": "Dongwoo Kim, Christian Walder",
        "author": "Dongwoo Kim; Christian Walder",
        "abstract": "Prediction suffix trees (PST) provide an effective tool for sequence modelling and prediction. Current prediction techniques for PSTs rely on exact matching between the suffix of the current sequence and the previously observed sequence. We present a provably correct algorithm for learning a PST with approximate suffix matching by relaxing the exact matching condition. We then present a self-bounded enhancement of our algorithm where the depth of suffix tree grows automatically in response to the model performance on a training sequence. Through experiments on synthetic datasets as well as three real-world datasets, we show that the approximate matching PST results in better predictive performance than the other variants of PST.",
        "bibtex": "@InProceedings{pmlr-v80-kim18c,\n  title = \t {Self-Bounded Prediction Suffix Tree via Approximate String Matching},\n  author =       {Kim, Dongwoo and Walder, Christian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2659--2667},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kim18c/kim18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kim18c.html},\n  abstract = \t {Prediction suffix trees (PST) provide an effective tool for sequence modelling and prediction. Current prediction techniques for PSTs rely on exact matching between the suffix of the current sequence and the previously observed sequence. We present a provably correct algorithm for learning a PST with approximate suffix matching by relaxing the exact matching condition. We then present a self-bounded enhancement of our algorithm where the depth of suffix tree grows automatically in response to the model performance on a training sequence. Through experiments on synthetic datasets as well as three real-world datasets, we show that the approximate matching PST results in better predictive performance than the other variants of PST.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kim18c/kim18c.pdf",
        "supp": "",
        "pdf_size": 516709,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1172946205716362056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Australian National University, Canberra, ACT, Australia + Data to Decisions CRC, Kent Town, SA, Australia; Data61 at CSIRO, Canberra, ACT, Australia",
        "aff_domain": "anu.edu.au; ",
        "email": "anu.edu.au; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kim18c.html",
        "aff_unique_index": "0+1;2",
        "aff_unique_norm": "Australian National University;Data to Decisions CRC;CSIRO",
        "aff_unique_dep": ";;Data61",
        "aff_unique_url": "https://www.anu.edu.au;;https://www.csiro.au",
        "aff_unique_abbr": "ANU;;CSIRO",
        "aff_campus_unique_index": "0+1;0",
        "aff_campus_unique": "Canberra;Kent Town",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "Australia"
    },
    {
        "title": "Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2337",
        "id": "2337",
        "author_site": "John Co-Reyes, Yu Xuan Liu, Abhishek Gupta, Benjamin Eysenbach, Pieter Abbeel, Sergey Levine",
        "author": "John Co-Reyes; YuXuan Liu; Abhishek Gupta; Benjamin Eysenbach; Pieter Abbeel; Sergey Levine",
        "abstract": "In this work, we take a representation learning perspective on hierarchical reinforcement learning, where the problem of learning lower layers in a hierarchy is transformed into the problem of learning trajectory-level generative models. We show that we can learn continuous latent representations of trajectories, which are effective in solving temporally extended and multi-stage problems. Our proposed model, SeCTAR, draws inspiration from variational autoencoders, and learns latent representations of trajectories. A key component of this method is to learn both a latent-conditioned policy and a latent-conditioned model which are consistent with each other. Given the same latent, the policy generates a trajectory which should match the trajectory predicted by the model. This model provides a built-in prediction mechanism, by predicting the outcome of closed loop policy behavior. We propose a novel algorithm for performing hierarchical RL with this model, combining model-based planning in the learned latent space with an unsupervised exploration objective. We show that our model is effective at reasoning over long horizons with sparse rewards for several simulated tasks, outperforming standard reinforcement learning methods and prior methods for hierarchical reasoning, model-based planning, and exploration. This model provides a built-in prediction mechanism, by predicting the outcome of closed loop policy behavior. We propose a novel algorithm for performing hierarchical RL with this model, combining model-based planning in the learned latent space with an unsupervised exploration objective. We show that our model is effective at reasoning over long horizons with sparse rewards for several simulated tasks, outperforming standard reinforcement learning methods and prior methods for hierarchical reasoning, model-based planning, and exploration.",
        "bibtex": "@InProceedings{pmlr-v80-co-reyes18a,\n  title = \t {Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings},\n  author =       {Co-Reyes, John and Liu, YuXuan and Gupta, Abhishek and Eysenbach, Benjamin and Abbeel, Pieter and Levine, Sergey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1009--1018},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/co-reyes18a/co-reyes18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/co-reyes18a.html},\n  abstract = \t {In this work, we take a representation learning perspective on hierarchical reinforcement learning, where the problem of learning lower layers in a hierarchy is transformed into the problem of learning trajectory-level generative models. We show that we can learn continuous latent representations of trajectories, which are effective in solving temporally extended and multi-stage problems. Our proposed model, SeCTAR, draws inspiration from variational autoencoders, and learns latent representations of trajectories. A key component of this method is to learn both a latent-conditioned policy and a latent-conditioned model which are consistent with each other. Given the same latent, the policy generates a trajectory which should match the trajectory predicted by the model. This model provides a built-in prediction mechanism, by predicting the outcome of closed loop policy behavior. We propose a novel algorithm for performing hierarchical RL with this model, combining model-based planning in the learned latent space with an unsupervised exploration objective. We show that our model is effective at reasoning over long horizons with sparse rewards for several simulated tasks, outperforming standard reinforcement learning methods and prior methods for hierarchical reasoning, model-based planning, and exploration. This model provides a built-in prediction mechanism, by predicting the outcome of closed loop policy behavior. We propose a novel algorithm for performing hierarchical RL with this model, combining model-based planning in the learned latent space with an unsupervised exploration objective. We show that our model is effective at reasoning over long horizons with sparse rewards for several simulated tasks, outperforming standard reinforcement learning methods and prior methods for hierarchical reasoning, model-based planning, and exploration.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/co-reyes18a/co-reyes18a.pdf",
        "supp": "",
        "pdf_size": 711167,
        "gs_citation": 193,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8752774018060046673&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; Google Brain; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "eecs.berkeley.edu;berkeley.edu; ; ; ; ",
        "email": "eecs.berkeley.edu;berkeley.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/co-reyes18a.html",
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": ";Google Brain",
        "aff_unique_url": "https://www.berkeley.edu;https://brain.google.com",
        "aff_unique_abbr": "UC Berkeley;Google Brain",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Self-Imitation Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2101",
        "id": "2101",
        "author_site": "Junhyuk Oh, Yijie Guo, Satinder Singh, Honglak Lee",
        "author": "Junhyuk Oh; Yijie Guo; Satinder Singh; Honglak Lee",
        "abstract": "This paper proposes Self-Imitation Learning (SIL), a simple off-policy actor-critic algorithm that learns to reproduce the agent\u2019s past good decisions. This algorithm is designed to verify our hypothesis that exploiting past good experiences can indirectly drive deep exploration. Our empirical results show that SIL significantly improves advantage actor-critic (A2C) on several hard exploration Atari games and is competitive to the state-of-the-art count-based exploration methods. We also show that SIL improves proximal policy optimization (PPO) on MuJoCo tasks.",
        "bibtex": "@InProceedings{pmlr-v80-oh18b,\n  title = \t {Self-Imitation Learning},\n  author =       {Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3878--3887},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/oh18b/oh18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/oh18b.html},\n  abstract = \t {This paper proposes Self-Imitation Learning (SIL), a simple off-policy actor-critic algorithm that learns to reproduce the agent\u2019s past good decisions. This algorithm is designed to verify our hypothesis that exploiting past good experiences can indirectly drive deep exploration. Our empirical results show that SIL significantly improves advantage actor-critic (A2C) on several hard exploration Atari games and is competitive to the state-of-the-art count-based exploration methods. We also show that SIL improves proximal policy optimization (PPO) on MuJoCo tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/oh18b/oh18b.pdf",
        "supp": "",
        "pdf_size": 3086843,
        "gs_citation": 393,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6282132634766578030&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "University of Michigan; University of Michigan; University of Michigan; Google Brain",
        "aff_domain": "umich.edu;umich.edu; ; ",
        "email": "umich.edu;umich.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/oh18b.html",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Michigan;Google",
        "aff_unique_dep": ";Google Brain",
        "aff_unique_url": "https://www.umich.edu;https://brain.google.com",
        "aff_unique_abbr": "UM;Google Brain",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Semi-Amortized Variational Autoencoders",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1981",
        "id": "1981",
        "author_site": "Yoon Kim, Sam Wiseman, Andrew Miller, David Sontag, Alexander Rush",
        "author": "Yoon Kim; Sam Wiseman; Andrew Miller; David Sontag; Alexander Rush",
        "abstract": "Amortized variational inference (AVI) replaces instance-specific local inference with a global inference network. While AVI has enabled efficient training of deep generative models such as variational autoencoders (VAE), recent empirical work suggests that inference networks can produce suboptimal variational parameters. We propose a hybrid approach, to use AVI to initialize the variational parameters and run stochastic variational inference (SVI) to refine them. Crucially, the local SVI procedure is itself differentiable, so the inference network and generative model can be trained end-to-end with gradient-based optimization. This semi-amortized approach enables the use of rich generative models without experiencing the posterior-collapse phenomenon common in training VAEs for problems like text generation. Experiments show this approach outperforms strong autoregressive and variational baselines on standard text and image datasets.",
        "bibtex": "@InProceedings{pmlr-v80-kim18e,\n  title = \t {Semi-Amortized Variational Autoencoders},\n  author =       {Kim, Yoon and Wiseman, Sam and Miller, Andrew and Sontag, David and Rush, Alexander},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2678--2687},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kim18e/kim18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kim18e.html},\n  abstract = \t {Amortized variational inference (AVI) replaces instance-specific local inference with a global inference network. While AVI has enabled efficient training of deep generative models such as variational autoencoders (VAE), recent empirical work suggests that inference networks can produce suboptimal variational parameters. We propose a hybrid approach, to use AVI to initialize the variational parameters and run stochastic variational inference (SVI) to refine them. Crucially, the local SVI procedure is itself differentiable, so the inference network and generative model can be trained end-to-end with gradient-based optimization. This semi-amortized approach enables the use of rich generative models without experiencing the posterior-collapse phenomenon common in training VAEs for problems like text generation. Experiments show this approach outperforms strong autoregressive and variational baselines on standard text and image datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kim18e/kim18e.pdf",
        "supp": "",
        "pdf_size": 651329,
        "gs_citation": 302,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15696369664604442539&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "School of Engineering and Applied Sciences, Harvard University; School of Engineering and Applied Sciences, Harvard University; School of Engineering and Applied Sciences, Harvard University; CSAIL & IMES, Massachusetts Institute of Technology; School of Engineering and Applied Sciences, Harvard University",
        "aff_domain": "seas.harvard.edu; ; ; ; ",
        "email": "seas.harvard.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/kim18e.html",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Harvard University;Massachusetts Institute of Technology",
        "aff_unique_dep": "School of Engineering and Applied Sciences;Computer Science and Artificial Intelligence Laboratory (CSAIL), Institute for Medical Engineering and Science (IMES)",
        "aff_unique_url": "https://www.harvard.edu;https://www.mit.edu",
        "aff_unique_abbr": "Harvard;MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Semi-Implicit Variational Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2124",
        "id": "2124",
        "author_site": "Mingzhang Yin, Mingyuan Zhou",
        "author": "Mingzhang Yin; Mingyuan Zhou",
        "abstract": "Semi-implicit variational inference (SIVI) is introduced to expand the commonly used analytic variational distribution family, by mixing the variational parameter with a flexible distribution. This mixing distribution can assume any density function, explicit or not, as long as independent random samples can be generated via reparameterization. Not only does SIVI expand the variational family to incorporate highly flexible variational distributions, including implicit ones that have no analytic density functions, but also sandwiches the evidence lower bound (ELBO) between a lower bound and an upper bound, and further derives an asymptotically exact surrogate ELBO that is amenable to optimization via stochastic gradient ascent. With a substantially expanded variational family and a novel optimization algorithm, SIVI is shown to closely match the accuracy of MCMC in inferring the posterior in a variety of Bayesian inference tasks.",
        "bibtex": "@InProceedings{pmlr-v80-yin18b,\n  title = \t {Semi-Implicit Variational Inference},\n  author =       {Yin, Mingzhang and Zhou, Mingyuan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5660--5669},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yin18b/yin18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yin18b.html},\n  abstract = \t {Semi-implicit variational inference (SIVI) is introduced to expand the commonly used analytic variational distribution family, by mixing the variational parameter with a flexible distribution. This mixing distribution can assume any density function, explicit or not, as long as independent random samples can be generated via reparameterization. Not only does SIVI expand the variational family to incorporate highly flexible variational distributions, including implicit ones that have no analytic density functions, but also sandwiches the evidence lower bound (ELBO) between a lower bound and an upper bound, and further derives an asymptotically exact surrogate ELBO that is amenable to optimization via stochastic gradient ascent. With a substantially expanded variational family and a novel optimization algorithm, SIVI is shown to closely match the accuracy of MCMC in inferring the posterior in a variety of Bayesian inference tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yin18b/yin18b.pdf",
        "supp": "",
        "pdf_size": 1863305,
        "gs_citation": 186,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=952314383686625023&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Statistics and Data Sciences; Department of IROM, McCombs School of Business, The University of Texas at Austin",
        "aff_domain": "utexas.edu;mccombs.utexas.edu",
        "email": "utexas.edu;mccombs.utexas.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/yin18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Statistics and Data Sciences",
        "aff_unique_url": "https://www.stat.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Semi-Supervised Learning on Data Streams via Temporal Label Propagation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1879",
        "id": "1879",
        "author_site": "Tal Wagner, Sudipto Guha, Shiva Kasiviswanathan, Nina Mishra",
        "author": "Tal Wagner; Sudipto Guha; Shiva Kasiviswanathan; Nina Mishra",
        "abstract": "We consider the problem of labeling points on a fast-moving data stream when only a small number of labeled examples are available. In our setting, incoming points must be processed efficiently and the stream is too large to store in its entirety. We present a semi-supervised learning algorithm for this task. The algorithm maintains a small synopsis of the stream which can be quickly updated as new points arrive, and labels every incoming point by provably learning from the full history of the stream. Experiments on real datasets validate that the algorithm can quickly and accurately classify points on a stream with a small quantity of labeled examples.",
        "bibtex": "@InProceedings{pmlr-v80-wagner18a,\n  title = \t {Semi-Supervised Learning on Data Streams via Temporal Label Propagation},\n  author =       {Wagner, Tal and Guha, Sudipto and Kasiviswanathan, Shiva and Mishra, Nina},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5095--5104},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wagner18a/wagner18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wagner18a.html},\n  abstract = \t {We consider the problem of labeling points on a fast-moving data stream when only a small number of labeled examples are available. In our setting, incoming points must be processed efficiently and the stream is too large to store in its entirety. We present a semi-supervised learning algorithm for this task. The algorithm maintains a small synopsis of the stream which can be quickly updated as new points arrive, and labels every incoming point by provably learning from the full history of the stream. Experiments on real datasets validate that the algorithm can quickly and accurately classify points on a stream with a small quantity of labeled examples.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wagner18a/wagner18a.pdf",
        "supp": "",
        "pdf_size": 1051277,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8556518542516601885&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "CSAIL, MIT; Amazon; Amazon; Amazon",
        "aff_domain": "mit.edu; ; ; ",
        "email": "mit.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/wagner18a.html",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Amazon",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Amazon.com, Inc.",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.amazon.com",
        "aff_unique_abbr": "MIT;Amazon",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Semi-Supervised Learning via Compact Latent Space Clustering",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2417",
        "id": "2417",
        "author_site": "Konstantinos Kamnitsas, Daniel C. Castro, Loic Le Folgoc, Ian Walker, Ryutaro Tanno, Daniel Rueckert, Ben Glocker, Antonio Criminisi, Aditya Nori",
        "author": "Konstantinos Kamnitsas; Daniel Castro; Loic Le Folgoc; Ian Walker; Ryutaro Tanno; Daniel Rueckert; Ben Glocker; Antonio Criminisi; Aditya Nori",
        "abstract": "We present a novel cost function for semi-supervised learning of neural networks that encourages compact clustering of the latent space to facilitate separation. The key idea is to dynamically create a graph over embeddings of labeled and unlabeled samples of a training batch to capture underlying structure in feature space, and use label propagation to estimate its high and low density regions. We then devise a cost function based on Markov chains on the graph that regularizes the latent space to form a single compact cluster per class, while avoiding to disturb existing clusters during optimization. We evaluate our approach on three benchmarks and compare to state-of-the art with promising results. Our approach combines the benefits of graph-based regularization with efficient, inductive inference, does not require modifications to a network architecture, and can thus be easily applied to existing networks to enable an effective use of unlabeled data.",
        "bibtex": "@InProceedings{pmlr-v80-kamnitsas18a,\n  title = \t {Semi-Supervised Learning via Compact Latent Space Clustering},\n  author =       {Kamnitsas, Konstantinos and Castro, Daniel and Folgoc, Loic Le and Walker, Ian and Tanno, Ryutaro and Rueckert, Daniel and Glocker, Ben and Criminisi, Antonio and Nori, Aditya},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2459--2468},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kamnitsas18a/kamnitsas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kamnitsas18a.html},\n  abstract = \t {We present a novel cost function for semi-supervised learning of neural networks that encourages compact clustering of the latent space to facilitate separation. The key idea is to dynamically create a graph over embeddings of labeled and unlabeled samples of a training batch to capture underlying structure in feature space, and use label propagation to estimate its high and low density regions. We then devise a cost function based on Markov chains on the graph that regularizes the latent space to form a single compact cluster per class, while avoiding to disturb existing clusters during optimization. We evaluate our approach on three benchmarks and compare to state-of-the art with promising results. Our approach combines the benefits of graph-based regularization with efficient, inductive inference, does not require modifications to a network architecture, and can thus be easily applied to existing networks to enable an effective use of unlabeled data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kamnitsas18a/kamnitsas18a.pdf",
        "supp": "",
        "pdf_size": 3775099,
        "gs_citation": 109,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9742996240677804266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Microsoft Research Cambridge, United Kingdom+Imperial College London, United Kingdom; Microsoft Research Cambridge, United Kingdom+Imperial College London, United Kingdom; Imperial College London, United Kingdom; Imperial College London, United Kingdom; Microsoft Research Cambridge, United Kingdom+University College London, United Kingdom; Imperial College London, United Kingdom; Imperial College London, United Kingdom; Microsoft Research Cambridge, United Kingdom; Microsoft Research Cambridge, United Kingdom",
        "aff_domain": "imperial.ac.uk; ; ; ; ; ; ; ; ",
        "email": "imperial.ac.uk; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/kamnitsas18a.html",
        "aff_unique_index": "0+1;0+1;1;1;0+2;1;1;0;0",
        "aff_unique_norm": "Microsoft;Imperial College London;University College London",
        "aff_unique_dep": "Research;;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/cambridge;https://www.imperial.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "MSR Cambridge;ICL;UCL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0+0;0+0;0;0;0+0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Semiparametric Contextual Bandits",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2270",
        "id": "2270",
        "author_site": "Akshay Krishnamurthy, Steven Wu, Vasilis Syrgkanis",
        "author": "Akshay Krishnamurthy; Zhiwei Steven Wu; Vasilis Syrgkanis",
        "abstract": "This paper studies semiparametric contextual bandits, a generalization of the linear stochastic bandit problem where the reward for a chosen action is modeled as a linear function of known action features confounded by a non-linear action-independent term. We design new algorithms that achieve $\\tilde{O}(d\\sqrt{T})$ regret over $T$ rounds, when the linear function is $d$-dimensional, which matches the best known bounds for the simpler unconfounded case and improves on a recent result of Greenwald et al. (2017). Via an empirical evaluation, we show that our algorithms outperform prior approaches when there are non-linear confounding effects on the rewards. Technically, our algorithms use a new reward estimator inspired by doubly-robust approaches and our proofs require new concentration inequalities for self-normalized martingales.",
        "bibtex": "@InProceedings{pmlr-v80-krishnamurthy18a,\n  title = \t {Semiparametric Contextual Bandits},\n  author =       {Krishnamurthy, Akshay and Wu, Zhiwei Steven and Syrgkanis, Vasilis},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2776--2785},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/krishnamurthy18a/krishnamurthy18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/krishnamurthy18a.html},\n  abstract = \t {This paper studies semiparametric contextual bandits, a generalization of the linear stochastic bandit problem where the reward for a chosen action is modeled as a linear function of known action features confounded by a non-linear action-independent term. We design new algorithms that achieve $\\tilde{O}(d\\sqrt{T})$ regret over $T$ rounds, when the linear function is $d$-dimensional, which matches the best known bounds for the simpler unconfounded case and improves on a recent result of Greenwald et al. (2017). Via an empirical evaluation, we show that our algorithms outperform prior approaches when there are non-linear confounding effects on the rewards. Technically, our algorithms use a new reward estimator inspired by doubly-robust approaches and our proofs require new concentration inequalities for self-normalized martingales.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/krishnamurthy18a/krishnamurthy18a.pdf",
        "supp": "",
        "pdf_size": 578828,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8044014700167945410&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Microsoft Research, New York, New York; Microsoft Research, New York, New York; Microsoft Research, Cambridge, Massachusetts",
        "aff_domain": "cs.umass.edu; ; ",
        "email": "cs.umass.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/krishnamurthy18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "MSR",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "New York;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Shampoo: Preconditioned Stochastic Tensor Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2380",
        "id": "2380",
        "author_site": "Vineet Gupta, Tomer Koren, Yoram Singer",
        "author": "Vineet Gupta; Tomer Koren; Yoram Singer",
        "abstract": "Preconditioned gradient methods are among the most general and powerful tools in optimization. However, preconditioning requires storing and manipulating prohibitively large matrices. We describe and analyze a new structure-aware preconditioning algorithm, called Shampoo, for stochastic optimization over tensor spaces. Shampoo maintains a set of preconditioning matrices, each of which operates on a single dimension, contracting over the remaining dimensions. We establish convergence guarantees in the stochastic convex setting, the proof of which builds upon matrix trace inequalities. Our experiments with state-of-the-art deep learning models show that Shampoo is capable of converging considerably faster than commonly used optimizers. Surprisingly, although it involves a more complex update rule, Shampoo\u2019s runtime per step is comparable in practice to that of simple gradient methods such as SGD, AdaGrad, and Adam.",
        "bibtex": "@InProceedings{pmlr-v80-gupta18a,\n  title = \t {Shampoo: Preconditioned Stochastic Tensor Optimization},\n  author =       {Gupta, Vineet and Koren, Tomer and Singer, Yoram},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1842--1850},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gupta18a/gupta18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gupta18a.html},\n  abstract = \t {Preconditioned gradient methods are among the most general and powerful tools in optimization. However, preconditioning requires storing and manipulating prohibitively large matrices. We describe and analyze a new structure-aware preconditioning algorithm, called Shampoo, for stochastic optimization over tensor spaces. Shampoo maintains a set of preconditioning matrices, each of which operates on a single dimension, contracting over the remaining dimensions. We establish convergence guarantees in the stochastic convex setting, the proof of which builds upon matrix trace inequalities. Our experiments with state-of-the-art deep learning models show that Shampoo is capable of converging considerably faster than commonly used optimizers. Surprisingly, although it involves a more complex update rule, Shampoo\u2019s runtime per step is comparable in practice to that of simple gradient methods such as SGD, AdaGrad, and Adam.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gupta18a/gupta18a.pdf",
        "supp": "",
        "pdf_size": 1845568,
        "gs_citation": 259,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15797241218653030681&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Google Brain, Mountain View, CA, USA; Google Brain, Mountain View, CA, USA; Princeton University, Princeton, NJ, USA",
        "aff_domain": "google.com;google.com;princeton.edu",
        "email": "google.com;google.com;princeton.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/gupta18a.html",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Google;Princeton University",
        "aff_unique_dep": "Google Brain;",
        "aff_unique_url": "https://brain.google.com;https://www.princeton.edu",
        "aff_unique_abbr": "Google Brain;Princeton",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Mountain View;Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Signal and Noise Statistics Oblivious Orthogonal Matching Pursuit",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2315",
        "id": "2315",
        "author_site": "Sreejith Kallummil, Sheetal Kalyani",
        "author": "Sreejith Kallummil; Sheetal Kalyani",
        "abstract": "Orthogonal matching pursuit (OMP) is a widely used algorithm for recovering sparse high dimensional vectors in linear regression models. The optimal performance of OMP requires a priori knowledge of either the sparsity of regression vector or noise statistics. Both these statistics are rarely known a priori and are very difficult to estimate. In this paper, we present a novel technique called residual ratio thresholding (RRT) to operate OMP without any a priori knowledge of sparsity and noise statistics and establish finite sample and large sample support recovery guarantees for the same. Both analytical results and numerical simulations in real and synthetic data sets indicate that RRT has a performance comparable to OMP with a priori knowledge of sparsity and noise statistics.",
        "bibtex": "@InProceedings{pmlr-v80-kallummil18a,\n  title = \t {Signal and Noise Statistics Oblivious Orthogonal Matching Pursuit},\n  author =       {Kallummil, Sreejith and Kalyani, Sheetal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2429--2438},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kallummil18a/kallummil18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kallummil18a.html},\n  abstract = \t {Orthogonal matching pursuit (OMP) is a widely used algorithm for recovering sparse high dimensional vectors in linear regression models. The optimal performance of OMP requires a priori knowledge of either the sparsity of regression vector or noise statistics. Both these statistics are rarely known a priori and are very difficult to estimate. In this paper, we present a novel technique called residual ratio thresholding (RRT) to operate OMP without any a priori knowledge of sparsity and noise statistics and establish finite sample and large sample support recovery guarantees for the same. Both analytical results and numerical simulations in real and synthetic data sets indicate that RRT has a performance comparable to OMP with a priori knowledge of sparsity and noise statistics.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kallummil18a/kallummil18a.pdf",
        "supp": "",
        "pdf_size": 385427,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18238104691822600655&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical Engineering, IIT Madras, India; Department of Electrical Engineering, IIT Madras, India",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/kallummil18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "IIT Madras",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.iitm.ac.in",
        "aff_unique_abbr": "IITM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madras",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "Smoothed Action Value Functions for Learning Gaussian Policies",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2086",
        "id": "2086",
        "author_site": "Ofir Nachum, Mohammad Norouzi, George Tucker, Dale Schuurmans",
        "author": "Ofir Nachum; Mohammad Norouzi; George Tucker; Dale Schuurmans",
        "abstract": "State-action value functions (i.e., Q-values) are ubiquitous in reinforcement learning (RL), giving rise to popular algorithms such as SARSA and Q-learning. We propose a new notion of action value defined by a Gaussian smoothed version of the expected Q-value. We show that such smoothed Q-values still satisfy a Bellman equation, making them learnable from experience sampled from an environment. Moreover, the gradients of expected reward with respect to the mean and covariance of a parameterized Gaussian policy can be recovered from the gradient and Hessian of the smoothed Q-value function. Based on these relationships we develop new algorithms for training a Gaussian policy directly from a learned smoothed Q-value approximator. The approach is additionally amenable to proximal optimization by augmenting the objective with a penalty on KL-divergence from a previous policy. We find that the ability to learn both a mean and covariance during training leads to significantly improved results on standard continuous control benchmarks.",
        "bibtex": "@InProceedings{pmlr-v80-nachum18a,\n  title = \t {Smoothed Action Value Functions for Learning {G}aussian Policies},\n  author =       {Nachum, Ofir and Norouzi, Mohammad and Tucker, George and Schuurmans, Dale},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3692--3700},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nachum18a/nachum18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nachum18a.html},\n  abstract = \t {State-action value functions (i.e., Q-values) are ubiquitous in reinforcement learning (RL), giving rise to popular algorithms such as SARSA and Q-learning. We propose a new notion of action value defined by a Gaussian smoothed version of the expected Q-value. We show that such smoothed Q-values still satisfy a Bellman equation, making them learnable from experience sampled from an environment. Moreover, the gradients of expected reward with respect to the mean and covariance of a parameterized Gaussian policy can be recovered from the gradient and Hessian of the smoothed Q-value function. Based on these relationships we develop new algorithms for training a Gaussian policy directly from a learned smoothed Q-value approximator. The approach is additionally amenable to proximal optimization by augmenting the objective with a penalty on KL-divergence from a previous policy. We find that the ability to learn both a mean and covariance during training leads to significantly improved results on standard continuous control benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nachum18a/nachum18a.pdf",
        "supp": "",
        "pdf_size": 703758,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11685444200454508110&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Google Brain; Google Brain; Google Brain; Google Brain + Department of Computing Science, University of Alberta",
        "aff_domain": "google.com; ; ; ",
        "email": "google.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/nachum18a.html",
        "aff_unique_index": "0;0;0;0+1",
        "aff_unique_norm": "Google;University of Alberta",
        "aff_unique_dep": "Google Brain;Department of Computing Science",
        "aff_unique_url": "https://brain.google.com;https://www.ualberta.ca",
        "aff_unique_abbr": "Google Brain;UAlberta",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0+1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1986",
        "id": "1986",
        "author_site": "Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine",
        "author": "Tuomas Haarnoja; Aurick Zhou; Pieter Abbeel; Sergey Levine",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "bibtex": "@InProceedings{pmlr-v80-haarnoja18b,\n  title = \t {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},\n  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1861--1870},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/haarnoja18b.html},\n  abstract = \t {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf",
        "supp": "",
        "pdf_size": 2407011,
        "gs_citation": 11352,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13282174879342015249&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Berkeley Artificial Intelligence Research, University of California, Berkeley, USA; Berkeley Artificial Intelligence Research, University of California, Berkeley, USA; Berkeley Artificial Intelligence Research, University of California, Berkeley, USA; Berkeley Artificial Intelligence Research, University of California, Berkeley, USA",
        "aff_domain": "berkeley.edu; ; ; ",
        "email": "berkeley.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/haarnoja18b.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Berkeley Artificial Intelligence Research",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Solving Partial Assignment Problems using Random Clique Complexes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2170",
        "id": "2170",
        "author_site": "Charu Sharma, Deepak Nathani, Manu Kaul",
        "author": "Charu Sharma; Deepak Nathani; Manohar Kaul",
        "abstract": "We present an alternate formulation of the partial assignment problem as matching random clique complexes, that are higher-order analogues of random graphs, designed to provide a set of invariants that better detect higher-order structure. The proposed method creates random clique adjacency matrices for each k-skeleton of the random clique complexes and matches them, taking into account each point as the affine combination of its geometric neighborhood. We justify our solution theoretically, by analyzing the runtime and storage complexity of our algorithm along with the asymptotic behavior of the quadratic assignment problem (QAP) that is associated with the underlying random clique adjacency matrices. Experiments on both synthetic and real-world datasets, containing severe occlusions and distortions, provide insight into the accuracy, efficiency, and robustness of our approach. We outperform diverse matching algorithms by a significant margin.",
        "bibtex": "@InProceedings{pmlr-v80-sharma18a,\n  title = \t {Solving Partial Assignment Problems using Random Clique Complexes},\n  author =       {Sharma, Charu and Nathani, Deepak and Kaul, Manohar},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4586--4595},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sharma18a/sharma18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sharma18a.html},\n  abstract = \t {We present an alternate formulation of the partial assignment problem as matching random clique complexes, that are higher-order analogues of random graphs, designed to provide a set of invariants that better detect higher-order structure. The proposed method creates random clique adjacency matrices for each k-skeleton of the random clique complexes and matches them, taking into account each point as the affine combination of its geometric neighborhood. We justify our solution theoretically, by analyzing the runtime and storage complexity of our algorithm along with the asymptotic behavior of the quadratic assignment problem (QAP) that is associated with the underlying random clique adjacency matrices. Experiments on both synthetic and real-world datasets, containing severe occlusions and distortions, provide insight into the accuracy, efficiency, and robustness of our approach. We outperform diverse matching algorithms by a significant margin.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sharma18a/sharma18a.pdf",
        "supp": "",
        "pdf_size": 1711422,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Department of Computer Science & Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India; Department of Computer Science & Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India; Department of Computer Science & Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India",
        "aff_domain": "gmail.com;gmail.com;iith.ac.in",
        "email": "gmail.com;gmail.com;iith.ac.in",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/sharma18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Hyderabad",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.iith.ac.in",
        "aff_unique_abbr": "IIT Hyderabad",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "Sound Abstraction and Decomposition of Probabilistic Programs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2418",
        "id": "2418",
        "author_site": "Steven Holtzen, Guy Van den Broeck, Todd Millstein",
        "author": "Steven Holtzen; Guy Broeck; Todd Millstein",
        "abstract": "Probabilistic programming languages are a flexible tool for specifying statistical models, but this flexibility comes at the cost of efficient analysis. It is currently difficult to compactly represent the subtle independence properties of a probabilistic program, and exploit independence properties to decompose inference. Classical graphical model abstractions do capture some properties of the underlying distribution, enabling inference algorithms to operate at the level of the graph topology. However, we observe that graph-based abstractions are often too coarse to capture interesting properties of programs. We propose a form of sound abstraction for probabilistic programs wherein the abstractions are themselves simplified programs. We provide a theoretical foundation for these abstractions, as well as an algorithm to generate them. Experimentally, we also illustrate the practical benefits of our framework as a tool to decompose probabilistic program inference.",
        "bibtex": "@InProceedings{pmlr-v80-holtzen18a,\n  title = \t {Sound Abstraction and Decomposition of Probabilistic Programs},\n  author =       {Holtzen, Steven and Van den Broeck, Guy and Millstein, Todd},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1999--2008},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/holtzen18a/holtzen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/holtzen18a.html},\n  abstract = \t {Probabilistic programming languages are a flexible tool for specifying statistical models, but this flexibility comes at the cost of efficient analysis. It is currently difficult to compactly represent the subtle independence properties of a probabilistic program, and exploit independence properties to decompose inference. Classical graphical model abstractions do capture some properties of the underlying distribution, enabling inference algorithms to operate at the level of the graph topology. However, we observe that graph-based abstractions are often too coarse to capture interesting properties of programs. We propose a form of sound abstraction for probabilistic programs wherein the abstractions are themselves simplified programs. We provide a theoretical foundation for these abstractions, as well as an algorithm to generate them. Experimentally, we also illustrate the practical benefits of our framework as a tool to decompose probabilistic program inference.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/holtzen18a/holtzen18a.pdf",
        "supp": "",
        "pdf_size": 295568,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17341661482165978605&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "aff_domain": "cs.ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "email": "cs.ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/holtzen18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "SparseMAP: Differentiable Sparse Structured Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2043",
        "id": "2043",
        "author_site": "Vlad Niculae, Andre Filipe Torres Martins, Mathieu Blondel, Claire Cardie",
        "author": "Vlad Niculae; Andre Martins; Mathieu Blondel; Claire Cardie",
        "abstract": "Structured prediction requires searching over a combinatorial number of structures. To tackle it, we introduce SparseMAP, a new method for sparse structured inference, together with corresponding loss functions. SparseMAP inference is able to automatically select only a few global structures: it is situated between MAP inference, which picks a single structure, and marginal inference, which assigns probability mass to all structures, including implausible ones. Importantly, SparseMAP can be computed using only calls to a MAP oracle, hence it is applicable even to problems where marginal inference is intractable, such as linear assignment. Moreover, thanks to the solution sparsity, gradient backpropagation is efficient regardless of the structure. SparseMAP thus enables us to augment deep neural networks with generic and sparse structured hidden layers. Experiments in dependency parsing and natural language inference reveal competitive accuracy, improved interpretability, and the ability to capture natural language ambiguities, which is attractive for pipeline systems.",
        "bibtex": "@InProceedings{pmlr-v80-niculae18a,\n  title = \t {{S}parse{MAP}: Differentiable Sparse Structured Inference},\n  author =       {Niculae, Vlad and Martins, Andre and Blondel, Mathieu and Cardie, Claire},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3799--3808},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/niculae18a/niculae18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/niculae18a.html},\n  abstract = \t {Structured prediction requires searching over a combinatorial number of structures. To tackle it, we introduce SparseMAP, a new method for sparse structured inference, together with corresponding loss functions. SparseMAP inference is able to automatically select only a few global structures: it is situated between MAP inference, which picks a single structure, and marginal inference, which assigns probability mass to all structures, including implausible ones. Importantly, SparseMAP can be computed using only calls to a MAP oracle, hence it is applicable even to problems where marginal inference is intractable, such as linear assignment. Moreover, thanks to the solution sparsity, gradient backpropagation is efficient regardless of the structure. SparseMAP thus enables us to augment deep neural networks with generic and sparse structured hidden layers. Experiments in dependency parsing and natural language inference reveal competitive accuracy, improved interpretability, and the ability to capture natural language ambiguities, which is attractive for pipeline systems.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/niculae18a/niculae18a.pdf",
        "supp": "",
        "pdf_size": 427244,
        "gs_citation": 152,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16676407380618945031&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Cornell University, Ithaca, NY; Unbabel & Instituto de Telecomunica\u00e7\u00f5es, Lisbon, Portugal; NTT Communication Science Laboratories, Kyoto, Japan; Cornell University, Ithaca, NY",
        "aff_domain": "vene.ro;unbabel.com;mblondel.org;cs.cornell.edu",
        "email": "vene.ro;unbabel.com;mblondel.org;cs.cornell.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/niculae18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Cornell University;Unbabel;NTT Communication Science Laboratories",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cornell.edu;https://www.unbabel.com;https://www.ntt-csl.com",
        "aff_unique_abbr": "Cornell;Unbabel;",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Ithaca;;Kyoto",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United States;Portugal;Japan"
    },
    {
        "title": "Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1887",
        "id": "1887",
        "author_site": "Jeremias Knoblauch, Theodoros Damoulas",
        "author": "Jeremias Knoblauch; Theodoros Damoulas",
        "abstract": "Bayesian On-line Changepoint Detection is extended to on-line model selection and non-stationary spatio-temporal processes. We propose spatially structured Vector Autoregressions (VARs) for modelling the process between changepoints (CPs) and give an upper bound on the approximation error of such models. The resulting algorithm performs prediction, model selection and CP detection on-line. Its time complexity is linear and its space complexity constant, and thus it is two orders of magnitudes faster than its closest competitor. In addition, it outperforms the state of the art for multivariate data.",
        "bibtex": "@InProceedings{pmlr-v80-knoblauch18a,\n  title = \t {Spatio-temporal {B}ayesian On-line Changepoint Detection with Model Selection},\n  author =       {Knoblauch, Jeremias and Damoulas, Theodoros},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2718--2727},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/knoblauch18a/knoblauch18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/knoblauch18a.html},\n  abstract = \t {Bayesian On-line Changepoint Detection is extended to on-line model selection and non-stationary spatio-temporal processes. We propose spatially structured Vector Autoregressions (VARs) for modelling the process between changepoints (CPs) and give an upper bound on the approximation error of such models. The resulting algorithm performs prediction, model selection and CP detection on-line. Its time complexity is linear and its space complexity constant, and thus it is two orders of magnitudes faster than its closest competitor. In addition, it outperforms the state of the art for multivariate data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/knoblauch18a/knoblauch18a.pdf",
        "supp": "",
        "pdf_size": 3973855,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2758071737310063402&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Statistics, University of Warwick, UK + Department of Computer Science, University of Warwick, UK + The Alan Turing Institute for Data Science & AI, UK; Department of Statistics, University of Warwick, UK + Department of Computer Science, University of Warwick, UK + The Alan Turing Institute for Data Science & AI, UK",
        "aff_domain": "warwick.ac.uk; ",
        "email": "warwick.ac.uk; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/knoblauch18a.html",
        "aff_unique_index": "0+0+1;0+0+1",
        "aff_unique_norm": "University of Warwick;Alan Turing Institute for Data Science & AI",
        "aff_unique_dep": "Department of Statistics;",
        "aff_unique_url": "https://warwick.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Warwick;ATI",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0+0;0+0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Spectrally Approximating Large Graphs with Smaller Graphs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1948",
        "id": "1948",
        "author_site": "Andreas Loukas, Pierre Vandergheynst",
        "author": "Andreas Loukas; Pierre Vandergheynst",
        "abstract": "How does coarsening affect the spectrum of a general graph? We provide conditions such that the principal eigenvalues and eigenspaces of a coarsened and original graph Laplacian matrices are close. The achieved approximation is shown to depend on standard graph-theoretic properties, such as the degree and eigenvalue distributions, as well as on the ratio between the coarsened and actual graph sizes. Our results carry implications for learning methods that utilize coarsening. For the particular case of spectral clustering, they imply that coarse eigenvectors can be used to derive good quality assignments even without refinement{\u2014}this phenomenon was previously observed, but lacked formal justification.",
        "bibtex": "@InProceedings{pmlr-v80-loukas18a,\n  title = \t {Spectrally Approximating Large Graphs with Smaller Graphs},\n  author =       {Loukas, Andreas and Vandergheynst, Pierre},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3237--3246},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/loukas18a/loukas18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/loukas18a.html},\n  abstract = \t {How does coarsening affect the spectrum of a general graph? We provide conditions such that the principal eigenvalues and eigenspaces of a coarsened and original graph Laplacian matrices are close. The achieved approximation is shown to depend on standard graph-theoretic properties, such as the degree and eigenvalue distributions, as well as on the ratio between the coarsened and actual graph sizes. Our results carry implications for learning methods that utilize coarsening. For the particular case of spectral clustering, they imply that coarse eigenvectors can be used to derive good quality assignments even without refinement{\u2014}this phenomenon was previously observed, but lacked formal justification.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/loukas18a/loukas18a.pdf",
        "supp": "",
        "pdf_size": 835826,
        "gs_citation": 139,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7418106412151837776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "\u00b4Ecole Polytechnique F\u00b4ed\u00b4erale Lausanne, Switzerland; \u00b4Ecole Polytechnique F\u00b4ed\u00b4erale Lausanne, Switzerland",
        "aff_domain": "epfl.ch; ",
        "email": "epfl.ch; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/loukas18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Spline Filters For End-to-End Deep Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2291",
        "id": "2291",
        "author_site": "Randall Balestriero, Romain Cosentino, Herve Glotin, Richard Baraniuk",
        "author": "Randall Balestriero; Romain Cosentino; Herve Glotin; Richard Baraniuk",
        "abstract": "We propose to tackle the problem of end-to-end learning for raw waveform signals by introducing learnable continuous time-frequency atoms. The derivation of these filters is achieved by defining a functional space with a given smoothness order and boundary conditions. From this space, we derive the parametric analytical filters. Their differentiability property allows gradient-based optimization. As such, one can utilize any Deep Neural Network (DNN) with these filters. This enables us to tackle in a front-end fashion a large scale bird detection task based on the freefield1010 dataset known to contain key challenges, such as the dimensionality of the inputs data ($>100,000$) and the presence of additional noises: multiple sources and soundscapes.",
        "bibtex": "@InProceedings{pmlr-v80-balestriero18a,\n  title = \t {Spline Filters For End-to-End Deep Learning},\n  author =       {Balestriero, Randall and Cosentino, Romain and Glotin, Herve and Baraniuk, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {364--373},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balestriero18a/balestriero18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balestriero18a.html},\n  abstract = \t {We propose to tackle the problem of end-to-end learning for raw waveform signals by introducing learnable continuous time-frequency atoms. The derivation of these filters is achieved by defining a functional space with a given smoothness order and boundary conditions. From this space, we derive the parametric analytical filters. Their differentiability property allows gradient-based optimization. As such, one can utilize any Deep Neural Network (DNN) with these filters. This enables us to tackle in a front-end fashion a large scale bird detection task based on the freefield1010 dataset known to contain key challenges, such as the dimensionality of the inputs data ($>100,000$) and the presence of additional noises: multiple sources and soundscapes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balestriero18a/balestriero18a.pdf",
        "supp": "",
        "pdf_size": 2187548,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11967315248572594027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "ECE Department, Rice University, Houston, TX; ECE Department, Rice University, Houston, TX; Univ. Toulon, Aix Marseille Univ., CNRS, LIS, DYNI, Marseille, France; ECE Department, Rice University, Houston, TX",
        "aff_domain": "gmail.com;gmail.com;univ-tln.fr;rice.edu",
        "email": "gmail.com;gmail.com;univ-tln.fr;rice.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/balestriero18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Rice University;University of Toulon",
        "aff_unique_dep": "ECE Department;",
        "aff_unique_url": "https://www.rice.edu;https://www.univ-toulon.fr",
        "aff_unique_abbr": "Rice;UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "title": "Spotlight: Optimizing Device Placement for Training Deep Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2032",
        "id": "2032",
        "author_site": "Yuanxiang Gao, Li Chen, Baochun Li",
        "author": "Yuanxiang Gao; Li Chen; Baochun Li",
        "abstract": "Training deep neural networks (DNNs) requires an increasing amount of computation resources, and it becomes typical to use a mixture of GPU and CPU devices. Due to the heterogeneity of these devices, a recent challenge is how each operation in a neural network can be optimally placed on these devices, so that the training process can take the shortest amount of time possible. The current state-of-the-art solution uses reinforcement learning based on the policy gradient method, and it suffers from suboptimal training times. In this paper, we propose Spotlight, a new reinforcement learning algorithm based on proximal policy optimization, designed specifically for finding an optimal device placement for training DNNs. The design of our new algorithm relies upon a new model of the device placement problem: by modeling it as a Markov decision process with multiple stages, we are able to prove that Spotlight achieves a theoretical guarantee on performance improvements. We have implemented Spotlight in the CIFAR-10 benchmark and deployed it on the Google Cloud platform. Extensive experiments have demonstrated that the training time with placements recommended by Spotlight is 60.9% of that recommended by the policy gradient method.",
        "bibtex": "@InProceedings{pmlr-v80-gao18a,\n  title = \t {Spotlight: Optimizing Device Placement for Training Deep Neural Networks},\n  author =       {Gao, Yuanxiang and Chen, Li and Li, Baochun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1676--1684},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/gao18a/gao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/gao18a.html},\n  abstract = \t {Training deep neural networks (DNNs) requires an increasing amount of computation resources, and it becomes typical to use a mixture of GPU and CPU devices. Due to the heterogeneity of these devices, a recent challenge is how each operation in a neural network can be optimally placed on these devices, so that the training process can take the shortest amount of time possible. The current state-of-the-art solution uses reinforcement learning based on the policy gradient method, and it suffers from suboptimal training times. In this paper, we propose Spotlight, a new reinforcement learning algorithm based on proximal policy optimization, designed specifically for finding an optimal device placement for training DNNs. The design of our new algorithm relies upon a new model of the device placement problem: by modeling it as a Markov decision process with multiple stages, we are able to prove that Spotlight achieves a theoretical guarantee on performance improvements. We have implemented Spotlight in the CIFAR-10 benchmark and deployed it on the Google Cloud platform. Extensive experiments have demonstrated that the training time with placements recommended by Spotlight is 60.9% of that recommended by the policy gradient method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/gao18a/gao18a.pdf",
        "supp": "",
        "pdf_size": 648652,
        "gs_citation": 130,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5133777917947337631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical and Computer Engineering, University of Toronto + School of Communication and Information Engineering, University of Electronic Science and Technology of China; Department of Electrical and Computer Engineering, University of Toronto; Department of Electrical and Computer Engineering, University of Toronto",
        "aff_domain": "ece.utoronto.ca;ece.utoronto.ca;ece.toronto.edu",
        "email": "ece.utoronto.ca;ece.utoronto.ca;ece.toronto.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/gao18a.html",
        "aff_unique_index": "0+1;0;0",
        "aff_unique_norm": "University of Toronto;University of Electronic Science and Technology of China",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;School of Communication and Information Engineering",
        "aff_unique_url": "https://www.utoronto.ca;https://www.uestc.edu.cn",
        "aff_unique_abbr": "U of T;UESTC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0+1;0;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "title": "Spurious Local Minima are Common in Two-Layer ReLU Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2033",
        "id": "2033",
        "author_site": "Itay Safran, Ohad Shamir",
        "author": "Itay Safran; Ohad Shamir",
        "abstract": "We consider the optimization problem associated with training simple ReLU neural networks of the form $\\mathbf{x}\\mapsto \\sum_{i=1}^{k}\\max\\{0,\\mathbf{w}_i^\\top \\mathbf{x}\\}$ with respect to the squared loss. We provide a computer-assisted proof that even if the input distribution is standard Gaussian, even if the dimension is arbitrarily large, and even if the target values are generated by such a network, with orthonormal parameter vectors, the problem can still have spurious local minima once $6\\le k\\le 20$. By a concentration of measure argument, this implies that in high input dimensions,",
        "bibtex": "@InProceedings{pmlr-v80-safran18a,\n  title = \t {Spurious Local Minima are Common in Two-Layer {R}e{LU} Neural Networks},\n  author =       {Safran, Itay and Shamir, Ohad},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4433--4441},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/safran18a/safran18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/safran18a.html},\n  abstract = \t {We consider the optimization problem associated with training simple ReLU neural networks of the form $\\mathbf{x}\\mapsto \\sum_{i=1}^{k}\\max\\{0,\\mathbf{w}_i^\\top \\mathbf{x}\\}$ with respect to the squared loss. We provide a computer-assisted proof that even if the input distribution is standard Gaussian, even if the dimension is arbitrarily large, and even if the target values are generated by such a network, with orthonormal parameter vectors, the problem can still have spurious local minima once $6\\le k\\le 20$. By a concentration of measure argument, this implies that in high input dimensions,",
        "pdf": "http://proceedings.mlr.press/v80/safran18a/safran18a.pdf",
        "supp": "",
        "pdf_size": 394703,
        "gs_citation": 327,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2602196713819367782&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Weizmann Institute of Science, Rehovot, Israel; Weizmann Institute of Science, Rehovot, Israel",
        "aff_domain": "weizmann.ac.il;weizmann.ac.il",
        "email": "weizmann.ac.il;weizmann.ac.il",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/safran18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Weizmann Institute of Science",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.weizmann.org.il",
        "aff_unique_abbr": "Weizmann",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Rehovot",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "title": "Stability and Generalization of Learning Algorithms that Converge to Global Optima",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2024",
        "id": "2024",
        "author_site": "Zachary Charles, Dimitris Papailiopoulos",
        "author": "Zachary Charles; Dimitris Papailiopoulos",
        "abstract": "We establish novel generalization bounds for learning algorithms that converge to global minima. We derive black-box stability results that only depend on the convergence of a learning algorithm and the geometry around the minimizers of the empirical risk function. The results are shown for non-convex loss functions satisfying the Polyak-Lojasiewicz (PL) and the quadratic growth (QG) conditions, which we show arise for 1-layer neural networks with leaky ReLU activations and deep neural networks with linear activations. We use our results to establish the stability of first-order methods such as stochastic gradient descent (SGD), gradient descent (GD), randomized coordinate descent (RCD), and the stochastic variance reduced gradient method (SVRG), in both the PL and the strongly convex setting. Our results match or improve state-of-the-art generalization bounds and can easily extend to similar optimization algorithms. Finally, although our results imply comparable stability for SGD and GD in the PL setting, we show that there exist simple quadratic models with multiple local minima where SGD is stable but GD is not.",
        "bibtex": "@InProceedings{pmlr-v80-charles18a,\n  title = \t {Stability and Generalization of Learning Algorithms that Converge to Global Optima},\n  author =       {Charles, Zachary and Papailiopoulos, Dimitris},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {745--754},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/charles18a/charles18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/charles18a.html},\n  abstract = \t {We establish novel generalization bounds for learning algorithms that converge to global minima. We derive black-box stability results that only depend on the convergence of a learning algorithm and the geometry around the minimizers of the empirical risk function. The results are shown for non-convex loss functions satisfying the Polyak-Lojasiewicz (PL) and the quadratic growth (QG) conditions, which we show arise for 1-layer neural networks with leaky ReLU activations and deep neural networks with linear activations. We use our results to establish the stability of first-order methods such as stochastic gradient descent (SGD), gradient descent (GD), randomized coordinate descent (RCD), and the stochastic variance reduced gradient method (SVRG), in both the PL and the strongly convex setting. Our results match or improve state-of-the-art generalization bounds and can easily extend to similar optimization algorithms. Finally, although our results imply comparable stability for SGD and GD in the PL setting, we show that there exist simple quadratic models with multiple local minima where SGD is stable but GD is not.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/charles18a/charles18a.pdf",
        "supp": "",
        "pdf_size": 655071,
        "gs_citation": 198,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15843847144792552199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical and Computer Engineering, University of Wisconsin-Madison, Wisconsin, USA; Department of Electrical and Computer Engineering, University of Wisconsin-Madison, Wisconsin, USA",
        "aff_domain": "wisc.edu;ece.wisc.edu",
        "email": "wisc.edu;ece.wisc.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/charles18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2038",
        "id": "2038",
        "author_site": "Jiong Zhang, Qi Lei, Inderjit Dhillon",
        "author": "Jiong Zhang; Qi Lei; Inderjit Dhillon",
        "abstract": "Vanishing and exploding gradients are two of the main obstacles in training deep neural networks, especially in capturing long range dependencies in recurrent neural networks (RNNs). In this paper, we present an efficient parametrization of the transition matrix of an RNN that allows us to stabilize the gradients that arise in its training. Specifically, we parameterize the transition matrix by its singular value decomposition (SVD), which allows us to explicitly track and control its singular values. We attain efficiency by using tools that are common in numerical linear algebra, namely Householder reflectors for representing the orthogonal matrices that arise in the SVD. By explicitly controlling the singular values, our proposed Spectral-RNN method allows us to easily solve the exploding gradient problem and we observe that it empirically solves the vanishing gradient issue to a large extent. We note that the SVD parameterization can be used for any rectangular weight matrix, hence it can be easily extended to any deep neural network, such as a multi-layer perceptron. Theoretically, we demonstrate that our parameterization does not lose any expressive power, and show how it potentially makes the optimization process easier. Our extensive experimental results also demonstrate that the proposed framework converges faster, and has good generalization, especially in capturing long range dependencies, as shown on the synthetic addition and copy tasks, as well as on MNIST and Penn Tree Bank data sets.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18g,\n  title = \t {Stabilizing Gradients for Deep Neural Networks via Efficient {SVD} Parameterization},\n  author =       {Zhang, Jiong and Lei, Qi and Dhillon, Inderjit},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5806--5814},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18g/zhang18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18g.html},\n  abstract = \t {Vanishing and exploding gradients are two of the main obstacles in training deep neural networks, especially in capturing long range dependencies in recurrent neural networks (RNNs). In this paper, we present an efficient parametrization of the transition matrix of an RNN that allows us to stabilize the gradients that arise in its training. Specifically, we parameterize the transition matrix by its singular value decomposition (SVD), which allows us to explicitly track and control its singular values. We attain efficiency by using tools that are common in numerical linear algebra, namely Householder reflectors for representing the orthogonal matrices that arise in the SVD. By explicitly controlling the singular values, our proposed Spectral-RNN method allows us to easily solve the exploding gradient problem and we observe that it empirically solves the vanishing gradient issue to a large extent. We note that the SVD parameterization can be used for any rectangular weight matrix, hence it can be easily extended to any deep neural network, such as a multi-layer perceptron. Theoretically, we demonstrate that our parameterization does not lose any expressive power, and show how it potentially makes the optimization process easier. Our extensive experimental results also demonstrate that the proposed framework converges faster, and has good generalization, especially in capturing long range dependencies, as shown on the synthetic addition and copy tasks, as well as on MNIST and Penn Tree Bank data sets.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18g/zhang18g.pdf",
        "supp": "",
        "pdf_size": 1977268,
        "gs_citation": 148,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10623363336533108811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Texas at Austin; University of Texas at Austin; University of Texas at Austin + Amazon.com",
        "aff_domain": "utexas.edu; ; ",
        "email": "utexas.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhang18g.html",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "University of Texas at Austin;Amazon",
        "aff_unique_dep": ";Amazon",
        "aff_unique_url": "https://www.utexas.edu;https://www.amazon.com",
        "aff_unique_abbr": "UT Austin;Amazon",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stagewise Safe Bayesian Optimization with Gaussian Processes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2466",
        "id": "2466",
        "author_site": "Yanan Sui, Vincent Zhuang, Joel Burdick, Yisong Yue",
        "author": "Yanan Sui; Vincent Zhuang; Joel Burdick; Yisong Yue",
        "abstract": "Enforcing safety is a key aspect of many problems pertaining to sequential decision making under uncertainty, which require the decisions made at every step to be both informative of the optimal decision and also safe. For example, we value both efficacy and comfort in medical therapy, and efficiency and safety in robotic control. We consider this problem of optimizing an unknown utility function with absolute feedback or preference feedback subject to unknown safety constraints. We develop an efficient safe Bayesian optimization algorithm, StageOpt, that separates safe region expansion and utility function maximization into two distinct stages. Compared to existing approaches which interleave between expansion and optimization, we show that StageOpt is more efficient and naturally applicable to a broader class of problems. We provide theoretical guarantees for both the satisfaction of safety constraints as well as convergence to the optimal utility value. We evaluate StageOpt on both a variety of synthetic experiments, as well as in clinical practice. We demonstrate that StageOpt is more effective than existing safe optimization approaches, and is able to safely and effectively optimize spinal cord stimulation therapy in our clinical experiments.",
        "bibtex": "@InProceedings{pmlr-v80-sui18a,\n  title = \t {Stagewise Safe {B}ayesian Optimization with {G}aussian Processes},\n  author =       {Sui, Yanan and Zhuang, Vincent and Burdick, Joel and Yue, Yisong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4781--4789},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sui18a/sui18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sui18a.html},\n  abstract = \t {Enforcing safety is a key aspect of many problems pertaining to sequential decision making under uncertainty, which require the decisions made at every step to be both informative of the optimal decision and also safe. For example, we value both efficacy and comfort in medical therapy, and efficiency and safety in robotic control. We consider this problem of optimizing an unknown utility function with absolute feedback or preference feedback subject to unknown safety constraints. We develop an efficient safe Bayesian optimization algorithm, StageOpt, that separates safe region expansion and utility function maximization into two distinct stages. Compared to existing approaches which interleave between expansion and optimization, we show that StageOpt is more efficient and naturally applicable to a broader class of problems. We provide theoretical guarantees for both the satisfaction of safety constraints as well as convergence to the optimal utility value. We evaluate StageOpt on both a variety of synthetic experiments, as well as in clinical practice. We demonstrate that StageOpt is more effective than existing safe optimization approaches, and is able to safely and effectively optimize spinal cord stimulation therapy in our clinical experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sui18a/sui18a.pdf",
        "supp": "",
        "pdf_size": 1029833,
        "gs_citation": 190,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11274464460846546402&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "California Institute of Technology; California Institute of Technology; California Institute of Technology; California Institute of Technology",
        "aff_domain": "caltech.edu;caltech.edu;robotics.caltech.edu;caltech.edu",
        "email": "caltech.edu;caltech.edu;robotics.caltech.edu;caltech.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sui18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "State Abstractions for Lifelong Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2087",
        "id": "2087",
        "author_site": "David Abel, Dilip S. Arumugam, Lucas Lehnert, Michael L. Littman",
        "author": "David Abel; Dilip Arumugam; Lucas Lehnert; Michael Littman",
        "abstract": "In lifelong reinforcement learning, agents must effectively transfer knowledge across tasks while simultaneously addressing exploration, credit assignment, and generalization. State abstraction can help overcome these hurdles by compressing the representation used by an agent, thereby reducing the computational and statistical burdens of learning. To this end, we here develop theory to compute and use state abstractions in lifelong reinforcement learning. We introduce two new classes of abstractions: (1) transitive state abstractions, whose optimal form can be computed efficiently, and (2) PAC state abstractions, which are guaranteed to hold with respect to a distribution of tasks. We show that the joint family of transitive PAC abstractions can be acquired efficiently, preserve near optimal-behavior, and experimentally reduce sample complexity in simple domains, thereby yielding a family of desirable abstractions for use in lifelong reinforcement learning. Along with these positive results, we show that there are pathological cases where state abstractions can negatively impact performance.",
        "bibtex": "@InProceedings{pmlr-v80-abel18a,\n  title = \t {State Abstractions for Lifelong Reinforcement Learning},\n  author =       {Abel, David and Arumugam, Dilip and Lehnert, Lucas and Littman, Michael},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {10--19},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/abel18a/abel18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/abel18a.html},\n  abstract = \t {In lifelong reinforcement learning, agents must effectively transfer knowledge across tasks while simultaneously addressing exploration, credit assignment, and generalization. State abstraction can help overcome these hurdles by compressing the representation used by an agent, thereby reducing the computational and statistical burdens of learning. To this end, we here develop theory to compute and use state abstractions in lifelong reinforcement learning. We introduce two new classes of abstractions: (1) transitive state abstractions, whose optimal form can be computed efficiently, and (2) PAC state abstractions, which are guaranteed to hold with respect to a distribution of tasks. We show that the joint family of transitive PAC abstractions can be acquired efficiently, preserve near optimal-behavior, and experimentally reduce sample complexity in simple domains, thereby yielding a family of desirable abstractions for use in lifelong reinforcement learning. Along with these positive results, we show that there are pathological cases where state abstractions can negatively impact performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/abel18a/abel18a.pdf",
        "supp": "",
        "pdf_size": 3463394,
        "gs_citation": 166,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16437481850442184541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University",
        "aff_domain": "brown.edu; ; ; ",
        "email": "brown.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/abel18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "State Space Gaussian Processes with Non-Gaussian Likelihood",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2065",
        "id": "2065",
        "author_site": "Hannes Nickisch, Arno Solin, Alexander Grigorevskiy",
        "author": "Hannes Nickisch; Arno Solin; Alexander Grigorevskiy",
        "abstract": "We provide a comprehensive overview and tooling for GP modelling with non-Gaussian likelihoods using state space methods. The state space formulation allows for solving one-dimensonal GP models in O(n) time and memory complexity. While existing literature has focused on the connection between GP regression and state space methods, the computational primitives allowing for inference using general likelihoods in combination with the Laplace approximation (LA), variational Bayes (VB), and assumed density filtering (ADF) / expectation propagation (EP) schemes has been largely overlooked. We present means of combining the efficient O(n) state space methodology with existing inference methods. We also furher extend existing methods, and provide unifying code implementing all approaches.",
        "bibtex": "@InProceedings{pmlr-v80-nickisch18a,\n  title = \t {State Space {G}aussian Processes with Non-{G}aussian Likelihood},\n  author =       {Nickisch, Hannes and Solin, Arno and Grigorevskiy, Alexander},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3789--3798},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/nickisch18a/nickisch18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/nickisch18a.html},\n  abstract = \t {We provide a comprehensive overview and tooling for GP modelling with non-Gaussian likelihoods using state space methods. The state space formulation allows for solving one-dimensonal GP models in O(n) time and memory complexity. While existing literature has focused on the connection between GP regression and state space methods, the computational primitives allowing for inference using general likelihoods in combination with the Laplace approximation (LA), variational Bayes (VB), and assumed density filtering (ADF) / expectation propagation (EP) schemes has been largely overlooked. We present means of combining the efficient O(n) state space methodology with existing inference methods. We also furher extend existing methods, and provide unifying code implementing all approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/nickisch18a/nickisch18a.pdf",
        "supp": "",
        "pdf_size": 340015,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18260116218218404799&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Digital Imaging, Philips Research, Hamburg, Germany; Department of Computer Science, Aalto University, Espoo, Finland; Department of Computer Science, Aalto University, Espoo, Finland + Silo.AI, Helsinki, Finland",
        "aff_domain": "nickisch.org;aalto.fi; ",
        "email": "nickisch.org;aalto.fi; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/nickisch18a.html",
        "aff_unique_index": "0;1;1+2",
        "aff_unique_norm": "Philips Research;Aalto University;Silo.AI",
        "aff_unique_dep": "Digital Imaging;Department of Computer Science;",
        "aff_unique_url": "https://www.philips.com/research;https://www.aalto.fi;https://silo.ai",
        "aff_unique_abbr": "Philips Res.;Aalto;",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Hamburg;Espoo;",
        "aff_country_unique_index": "0;1;1+1",
        "aff_country_unique": "Germany;Finland"
    },
    {
        "title": "Stein Points",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2275",
        "id": "2275",
        "author_site": "Wilson Ye Chen, Lester Mackey, Jackson Gorham, Francois-Xavier Briol, Chris J Oates",
        "author": "Wilson Ye Chen; Lester Mackey; Jackson Gorham; Francois-Xavier Briol; Chris Oates",
        "abstract": "An important task in computational statistics and machine learning is to approximate a posterior distribution $p(x)$ with an empirical measure supported on a set of representative points $\\{x_i\\}_{i=1}^n$. This paper focuses on methods where the selection of points is essentially deterministic, with an emphasis on achieving accurate approximation when $n$ is small. To this end, we present Stein Points. The idea is to exploit either a greedy or a conditional gradient method to iteratively minimise a kernel Stein discrepancy between the empirical measure and $p(x)$. Our empirical results demonstrate that Stein Points enable accurate approximation of the posterior at modest computational cost. In addition, theoretical results are provided to establish convergence of the method.",
        "bibtex": "@InProceedings{pmlr-v80-chen18f,\n  title = \t {Stein Points},\n  author =       {Chen, Wilson Ye and Mackey, Lester and Gorham, Jackson and Briol, Francois-Xavier and Oates, Chris},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {844--853},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18f/chen18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18f.html},\n  abstract = \t {An important task in computational statistics and machine learning is to approximate a posterior distribution $p(x)$ with an empirical measure supported on a set of representative points $\\{x_i\\}_{i=1}^n$. This paper focuses on methods where the selection of points is essentially deterministic, with an emphasis on achieving accurate approximation when $n$ is small. To this end, we present Stein Points. The idea is to exploit either a greedy or a conditional gradient method to iteratively minimise a kernel Stein discrepancy between the empirical measure and $p(x)$. Our empirical results demonstrate that Stein Points enable accurate approximation of the posterior at modest computational cost. In addition, theoretical results are provided to establish convergence of the method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18f/chen18f.pdf",
        "supp": "",
        "pdf_size": 1167955,
        "gs_citation": 117,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9019835252196634623&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Mathematical and Physical Sciences, University of Technology Sydney, Australia; Microsoft Research New England, USA; Opendoor Labs, Inc., USA; Department of Statistics, University of Warwick, UK+Department of Mathematics, Imperial College London, UK+Alan Turing Institute, UK; School of Mathematics, Statistics and Physics, Newcastle University, UK+Alan Turing Institute, UK",
        "aff_domain": "uts.edu.au;microsoft.com; ;warwick.ac.uk;ncl.ac.uk",
        "email": "uts.edu.au;microsoft.com; ;warwick.ac.uk;ncl.ac.uk",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/chen18f.html",
        "aff_unique_index": "0;1;2;3+4+5;6+5",
        "aff_unique_norm": "University of Technology Sydney;Microsoft;Opendoor Labs, Inc.;University of Warwick;Imperial College London;Alan Turing Institute;Newcastle University",
        "aff_unique_dep": "School of Mathematical and Physical Sciences;Microsoft Research;;Department of Statistics;Department of Mathematics;;School of Mathematics, Statistics and Physics",
        "aff_unique_url": "https://www.uts.edu.au;https://www.microsoft.com/en-us/research/group/microsoft-research-new-england;https://www.opendoor.com;https://warwick.ac.uk;https://www.imperial.ac.uk;https://www.turing.ac.uk;https://www.ncl.ac.uk",
        "aff_unique_abbr": "UTS;MSR NE;;Warwick;Imperial;ATI;NU",
        "aff_campus_unique_index": "1;2;",
        "aff_campus_unique": ";New England;London",
        "aff_country_unique_index": "0;1;1;2+2+2;2+2",
        "aff_country_unique": "Australia;United States;United Kingdom"
    },
    {
        "title": "Stein Variational Gradient Descent Without Gradient",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2105",
        "id": "2105",
        "author_site": "Jun Han, Qiang Liu",
        "author": "Jun Han; Qiang Liu",
        "abstract": "Stein variational gradient decent (SVGD) has been shown to be a powerful approximate inference algorithm for complex distributions. However, the standard SVGD requires calculating the gradient of the target density and cannot be applied when the gradient is unavailable. In this work, we develop a gradient-free variant of SVGD (GF-SVGD), which replaces the true gradient with a surrogate gradient, and corrects the introduced bias by re-weighting the gradients in a proper form. We show that our GF-SVGD can be viewed as the standard SVGD with a special choice of kernel, and hence directly inherits all the theoretical properties of SVGD. We shed insights on the empirical choice of the surrogate gradient and further, propose an annealed GF-SVGD that consistently outperforms a number of recent advanced gradient-free MCMC methods in our empirical studies.",
        "bibtex": "@InProceedings{pmlr-v80-han18b,\n  title = \t {Stein Variational Gradient Descent Without Gradient},\n  author =       {Han, Jun and Liu, Qiang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1900--1908},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/han18b/han18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/han18b.html},\n  abstract = \t {Stein variational gradient decent (SVGD) has been shown to be a powerful approximate inference algorithm for complex distributions. However, the standard SVGD requires calculating the gradient of the target density and cannot be applied when the gradient is unavailable. In this work, we develop a gradient-free variant of SVGD (GF-SVGD), which replaces the true gradient with a surrogate gradient, and corrects the introduced bias by re-weighting the gradients in a proper form. We show that our GF-SVGD can be viewed as the standard SVGD with a special choice of kernel, and hence directly inherits all the theoretical properties of SVGD. We shed insights on the empirical choice of the surrogate gradient and further, propose an annealed GF-SVGD that consistently outperforms a number of recent advanced gradient-free MCMC methods in our empirical studies.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/han18b/han18b.pdf",
        "supp": "",
        "pdf_size": 595251,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3571045216317179971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Computer Science, Dartmouth College; Computer Science, The University of Texas at Austin",
        "aff_domain": "dartmouth.edu;cs.utexas.edu",
        "email": "dartmouth.edu;cs.utexas.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/han18b.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Dartmouth College;University of Texas at Austin",
        "aff_unique_dep": "Computer Science;Computer Science",
        "aff_unique_url": "https://dartmouth.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Dartmouth;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stein Variational Message Passing for Continuous Graphical Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2214",
        "id": "2214",
        "author_site": "Dilin Wang, Zhe Zeng, Qiang Liu",
        "author": "Dilin Wang; Zhe Zeng; Qiang Liu",
        "abstract": "We propose a novel distributed inference algorithm for continuous graphical models, by extending Stein variational gradient descent (SVGD) to leverage the Markov dependency structure of the distribution of interest. Our approach combines SVGD with a set of structured local kernel functions defined on the Markov blanket of each node, which alleviates the curse of high dimensionality and simultaneously yields a distributed algorithm for decentralized inference tasks. We justify our method with theoretical analysis and show that the use of local kernels can be viewed as a new type of localized approximation that matches the target distribution on the conditional distributions of each node over its Markov blanket. Our empirical results show that our method outperforms a variety of baselines including standard MCMC and particle message passing methods.",
        "bibtex": "@InProceedings{pmlr-v80-wang18l,\n  title = \t {Stein Variational Message Passing for Continuous Graphical Models},\n  author =       {Wang, Dilin and Zeng, Zhe and Liu, Qiang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5219--5227},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18l/wang18l.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18l.html},\n  abstract = \t {We propose a novel distributed inference algorithm for continuous graphical models, by extending Stein variational gradient descent (SVGD) to leverage the Markov dependency structure of the distribution of interest. Our approach combines SVGD with a set of structured local kernel functions defined on the Markov blanket of each node, which alleviates the curse of high dimensionality and simultaneously yields a distributed algorithm for decentralized inference tasks. We justify our method with theoretical analysis and show that the use of local kernels can be viewed as a new type of localized approximation that matches the target distribution on the conditional distributions of each node over its Markov blanket. Our empirical results show that our method outperforms a variety of baselines including standard MCMC and particle message passing methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18l/wang18l.pdf",
        "supp": "",
        "pdf_size": 677904,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9940403725514980956&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, The University of Texas at Austin; School of Mathematical Sciences, Zhejiang University; Department of Computer Science, The University of Texas at Austin",
        "aff_domain": "cs.utexas.edu; ;cs.utexas.edu",
        "email": "cs.utexas.edu; ;cs.utexas.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/wang18l.html",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Austin;Zhejiang University",
        "aff_unique_dep": "Department of Computer Science;School of Mathematical Sciences",
        "aff_unique_url": "https://www.utexas.edu;http://www.zju.edu.cn",
        "aff_unique_abbr": "UT Austin;ZJU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Stochastic PCA with $\\ell_2$ and $\\ell_1$ Regularization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2479",
        "id": "2479",
        "author_site": "Poorya Mianjy, Raman Arora",
        "author": "Poorya Mianjy; Raman Arora",
        "abstract": "We revisit convex relaxation based methods for stochastic optimization of principal component analysis (PCA). While methods that directly solve the nonconvex problem have been shown to be optimal in terms of statistical and computational efficiency, the methods based on convex relaxation have been shown to enjoy comparable, or even superior, empirical performance \u2013 this motivates the need for a deeper formal understanding of the latter. Therefore, in this paper, we study variants of stochastic gradient descent for a convex relaxation of PCA with (a) $\\ell_2$, (b) $\\ell_1$, and (c) elastic net ($\\ell_1+\\ell_2)$ regularization in the hope that these variants yield (a) better iteration complexity, (b) better control on the rank of the intermediate iterates, and (c) both, respectively. We show, theoretically and empirically, that compared to previous work on convex relaxation based methods, the proposed variants yield faster convergence and improve overall runtime to achieve a certain user-specified $\\epsilon$-suboptimality on the PCA objective. Furthermore, the proposed methods are shown to converge both in terms of the PCA objective as well as the distance between subspaces. However, there still remains a gap in computational requirements for the proposed methods when compared with existing nonconvex approaches.",
        "bibtex": "@InProceedings{pmlr-v80-mianjy18a,\n  title = \t {Stochastic {PCA} with $\\ell_2$ and $\\ell_1$ Regularization},\n  author =       {Mianjy, Poorya and Arora, Raman},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3531--3539},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mianjy18a/mianjy18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mianjy18a.html},\n  abstract = \t {We revisit convex relaxation based methods for stochastic optimization of principal component analysis (PCA). While methods that directly solve the nonconvex problem have been shown to be optimal in terms of statistical and computational efficiency, the methods based on convex relaxation have been shown to enjoy comparable, or even superior, empirical performance \u2013 this motivates the need for a deeper formal understanding of the latter. Therefore, in this paper, we study variants of stochastic gradient descent for a convex relaxation of PCA with (a) $\\ell_2$, (b) $\\ell_1$, and (c) elastic net ($\\ell_1+\\ell_2)$ regularization in the hope that these variants yield (a) better iteration complexity, (b) better control on the rank of the intermediate iterates, and (c) both, respectively. We show, theoretically and empirically, that compared to previous work on convex relaxation based methods, the proposed variants yield faster convergence and improve overall runtime to achieve a certain user-specified $\\epsilon$-suboptimality on the PCA objective. Furthermore, the proposed methods are shown to converge both in terms of the PCA objective as well as the distance between subspaces. However, there still remains a gap in computational requirements for the proposed methods when compared with existing nonconvex approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mianjy18a/mianjy18a.pdf",
        "supp": "",
        "pdf_size": 885008,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Department of Computer Science, Johns Hopkins University, Baltimore, USA; Department of Computer Science, Johns Hopkins University, Baltimore, USA",
        "aff_domain": "jhu.edu;cs.jhu.edu",
        "email": "jhu.edu;cs.jhu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/mianjy18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stochastic Proximal Algorithms for AUC Maximization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1921",
        "id": "1921",
        "author_site": "Michael Natole Jr, Yiming Ying, Siwei Lyu",
        "author": "Michael Natole; Yiming Ying; Siwei Lyu",
        "abstract": "Stochastic optimization algorithms such as SGDs update the model sequentially with cheap per-iteration costs, making them amenable for large-scale data analysis. However, most of the existing studies focus on the classification accuracy which can not be directly applied to the important problems of maximizing the Area under the ROC curve (AUC) in imbalanced classification and bipartite ranking. In this paper, we develop a novel stochastic proximal algorithm for AUC maximization which is referred to as SPAM. Compared with the previous literature, our algorithm SPAM applies to a non-smooth penalty function, and achieves a convergence rate of O(log t/t) for strongly convex functions while both space and per-iteration costs are of one datum.",
        "bibtex": "@InProceedings{pmlr-v80-natole18a,\n  title = \t {Stochastic Proximal Algorithms for {AUC} Maximization},\n  author =       {Natole, Jr., Michael and Ying, Yiming and Lyu, Siwei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3710--3719},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/natole18a/natole18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/natole18a.html},\n  abstract = \t {Stochastic optimization algorithms such as SGDs update the model sequentially with cheap per-iteration costs, making them amenable for large-scale data analysis. However, most of the existing studies focus on the classification accuracy which can not be directly applied to the important problems of maximizing the Area under the ROC curve (AUC) in imbalanced classification and bipartite ranking. In this paper, we develop a novel stochastic proximal algorithm for AUC maximization which is referred to as SPAM. Compared with the previous literature, our algorithm SPAM applies to a non-smooth penalty function, and achieves a convergence rate of O(log t/t) for strongly convex functions while both space and per-iteration costs are of one datum.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/natole18a/natole18a.pdf",
        "supp": "",
        "pdf_size": 399031,
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7180790009259497227&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Mathematics and Statistics, SUNY at Albany, Albany, NY, USA; Department of Mathematics and Statistics, SUNY at Albany, Albany, NY, USA; Department of Computer Science, SUNY at Albany, Albany, NY, USA",
        "aff_domain": "albany.edu;albany.edu; ",
        "email": "albany.edu;albany.edu; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/natole18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "State University of New York at Albany",
        "aff_unique_dep": "Department of Mathematics and Statistics",
        "aff_unique_url": "https://www.albany.edu",
        "aff_unique_abbr": "SUNY Albany",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Albany",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stochastic Training of Graph Convolutional Networks with Variance Reduction",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2169",
        "id": "2169",
        "author_site": "Jianfei Chen, Jun Zhu, Le Song",
        "author": "Jianfei Chen; Jun Zhu; Le Song",
        "abstract": "Graph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes the representation of a node recursively from its neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop control variate based algorithms with new theoretical guarantee to converge to a local optimum of GCN regardless of the neighbor sampling size. Empirical results show that our algorithms enjoy similar convergence rate and model quality with the exact algorithm using only two neighbors per node. The running time of our algorithms on a large Reddit dataset is only one seventh of previous neighbor sampling algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-chen18p,\n  title = \t {Stochastic Training of Graph Convolutional Networks with Variance Reduction},\n  author =       {Chen, Jianfei and Zhu, Jun and Song, Le},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {942--950},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18p/chen18p.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18p.html},\n  abstract = \t {Graph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes the representation of a node recursively from its neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop control variate based algorithms with new theoretical guarantee to converge to a local optimum of GCN regardless of the neighbor sampling size. Empirical results show that our algorithms enjoy similar convergence rate and model quality with the exact algorithm using only two neighbors per node. The running time of our algorithms on a large Reddit dataset is only one seventh of previous neighbor sampling algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18p/chen18p.pdf",
        "supp": "",
        "pdf_size": 7992697,
        "gs_citation": 685,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14899386604163137460&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Dept. of Comp. Sci. & Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., THBI Lab, Tsinghua University, Beijing, 100084, China; Georgia Institute of Technology + Ant Financial",
        "aff_domain": "mail.tsinghua.edu.cn;mail.tsinghua.edu.cn; ",
        "email": "mail.tsinghua.edu.cn;mail.tsinghua.edu.cn; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chen18p.html",
        "aff_unique_index": "0;0;1+2",
        "aff_unique_norm": "Tsinghua University;Georgia Institute of Technology;Ant Financial",
        "aff_unique_dep": "Department of Computer Science and Technology;;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.gatech.edu;https://www.antgroup.com",
        "aff_unique_abbr": "THU;Georgia Tech;Ant Financial",
        "aff_campus_unique_index": "0;0;",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;1+0",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Stochastic Variance-Reduced Cubic Regularized Newton Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2223",
        "id": "2223",
        "author_site": "Dongruo Zhou, Pan Xu, Quanquan Gu",
        "author": "Dongruo Zhou; Pan Xu; Quanquan Gu",
        "abstract": "We propose a stochastic variance-reduced cubic regularized Newton method (SVRC) for non-convex optimization. At the core of our algorithm is a novel semi-stochastic gradient along with a semi-stochastic Hessian, which are specifically designed for cubic regularization method. We show that our algorithm is guaranteed to converge to an $(\\epsilon,\\sqrt{\\epsilon})$-approximate local minimum within $\\tilde{O}(n^{4/5}/\\epsilon^{3/2})$ second-order oracle calls, which outperforms the state-of-the-art cubic regularization algorithms including subsampled cubic regularization. Our work also sheds light on the application of variance reduction technique to high-order non-convex optimization methods. Thorough experiments on various non-convex optimization problems support our theory.",
        "bibtex": "@InProceedings{pmlr-v80-zhou18d,\n  title = \t {Stochastic Variance-Reduced Cubic Regularized {N}ewton Methods},\n  author =       {Zhou, Dongruo and Xu, Pan and Gu, Quanquan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5990--5999},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhou18d/zhou18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhou18d.html},\n  abstract = \t {We propose a stochastic variance-reduced cubic regularized Newton method (SVRC) for non-convex optimization. At the core of our algorithm is a novel semi-stochastic gradient along with a semi-stochastic Hessian, which are specifically designed for cubic regularization method. We show that our algorithm is guaranteed to converge to an $(\\epsilon,\\sqrt{\\epsilon})$-approximate local minimum within $\\tilde{O}(n^{4/5}/\\epsilon^{3/2})$ second-order oracle calls, which outperforms the state-of-the-art cubic regularization algorithms including subsampled cubic regularization. Our work also sheds light on the application of variance reduction technique to high-order non-convex optimization methods. Thorough experiments on various non-convex optimization problems support our theory.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhou18d/zhou18d.pdf",
        "supp": "",
        "pdf_size": 1132535,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9849632143277784120&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, University of California, Los Angeles, CA 90095, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA",
        "aff_domain": "cs.ucla.edu; ; ",
        "email": "cs.ucla.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhou18d.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stochastic Variance-Reduced Hamilton Monte Carlo Methods",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2347",
        "id": "2347",
        "author_site": "Difan Zou, Pan Xu, Quanquan Gu",
        "author": "Difan Zou; Pan Xu; Quanquan Gu",
        "abstract": "We propose a fast stochastic Hamilton Monte Carlo (HMC) method, for sampling from a smooth and strongly log-concave distribution. At the core of our proposed method is a variance reduction technique inspired by the recent advance in stochastic optimization. We show that, to achieve $\\epsilon$ accuracy in 2-Wasserstein distance, our algorithm achieves $\\tilde O\\big(n+\\kappa^{2}d^{1/2}/\\epsilon+\\kappa^{4/3}d^{1/3}n^{2/3}/\\epsilon^{2/3}\\big)$ gradient complexity (i.e., number of component gradient evaluations), which outperforms the state-of-the-art HMC and stochastic gradient HMC methods in a wide regime. We also extend our algorithm for sampling from smooth and general log-concave distributions, and prove the corresponding gradient complexity as well. Experiments on both synthetic and real data demonstrate the superior performance of our algorithm.",
        "bibtex": "@InProceedings{pmlr-v80-zou18a,\n  title = \t {Stochastic Variance-Reduced {H}amilton {M}onte {C}arlo Methods},\n  author =       {Zou, Difan and Xu, Pan and Gu, Quanquan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {6028--6037},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zou18a/zou18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zou18a.html},\n  abstract = \t {We propose a fast stochastic Hamilton Monte Carlo (HMC) method, for sampling from a smooth and strongly log-concave distribution. At the core of our proposed method is a variance reduction technique inspired by the recent advance in stochastic optimization. We show that, to achieve $\\epsilon$ accuracy in 2-Wasserstein distance, our algorithm achieves $\\tilde O\\big(n+\\kappa^{2}d^{1/2}/\\epsilon+\\kappa^{4/3}d^{1/3}n^{2/3}/\\epsilon^{2/3}\\big)$ gradient complexity (i.e., number of component gradient evaluations), which outperforms the state-of-the-art HMC and stochastic gradient HMC methods in a wide regime. We also extend our algorithm for sampling from smooth and general log-concave distributions, and prove the corresponding gradient complexity as well. Experiments on both synthetic and real data demonstrate the superior performance of our algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zou18a/zou18a.pdf",
        "supp": "",
        "pdf_size": 1337840,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13460934072496616599&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, University of California, Los Angeles, CA 90095, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA",
        "aff_domain": "cs.ucla.edu; ; ",
        "email": "cs.ucla.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zou18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stochastic Variance-Reduced Policy Gradient",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2066",
        "id": "2066",
        "author_site": "Matteo Papini, Damiano Binaghi, Giuseppe Canonaco, Matteo Pirotta, Marcello Restelli",
        "author": "Matteo Papini; Damiano Binaghi; Giuseppe Canonaco; Matteo Pirotta; Marcello Restelli",
        "abstract": "In this paper, we propose a novel reinforcement-learning algorithm consisting in a stochastic variance-reduced version of policy gradient for solving Markov Decision Processes (MDPs). Stochastic variance-reduced gradient (SVRG) methods have proven to be very successful in supervised learning. However, their adaptation to policy gradient is not straightforward and needs to account for I) a non-concave objective function; II) approximations in the full gradient computation; and III) a non-stationary sampling process. The result is SVRPG, a stochastic variance-reduced policy gradient algorithm that leverages on importance weights to preserve the unbiasedness of the gradient estimate. Under standard assumptions on the MDP, we provide convergence guarantees for SVRPG with a convergence rate that is linear under increasing batch sizes. Finally, we suggest practical variants of SVRPG, and we empirically evaluate them on continuous MDPs.",
        "bibtex": "@InProceedings{pmlr-v80-papini18a,\n  title = \t {Stochastic Variance-Reduced Policy Gradient},\n  author =       {Papini, Matteo and Binaghi, Damiano and Canonaco, Giuseppe and Pirotta, Matteo and Restelli, Marcello},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4026--4035},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/papini18a/papini18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/papini18a.html},\n  abstract = \t {In this paper, we propose a novel reinforcement-learning algorithm consisting in a stochastic variance-reduced version of policy gradient for solving Markov Decision Processes (MDPs). Stochastic variance-reduced gradient (SVRG) methods have proven to be very successful in supervised learning. However, their adaptation to policy gradient is not straightforward and needs to account for I) a non-concave objective function; II) approximations in the full gradient computation; and III) a non-stationary sampling process. The result is SVRPG, a stochastic variance-reduced policy gradient algorithm that leverages on importance weights to preserve the unbiasedness of the gradient estimate. Under standard assumptions on the MDP, we provide convergence guarantees for SVRPG with a convergence rate that is linear under increasing batch sizes. Finally, we suggest practical variants of SVRPG, and we empirically evaluate them on continuous MDPs.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/papini18a/papini18a.pdf",
        "supp": "",
        "pdf_size": 526289,
        "gs_citation": 220,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10229080169981298445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Inria; Politecnico di Milano",
        "aff_domain": "polimi.it; ; ; ; ",
        "email": "polimi.it; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/papini18a.html",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Politecnico di Milano;INRIA",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.polimi.it;https://www.inria.fr",
        "aff_unique_abbr": "Polimi;Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Italy;France"
    },
    {
        "title": "Stochastic Video Generation with a Learned Prior",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2191",
        "id": "2191",
        "author_site": "Emily Denton, Rob Fergus",
        "author": "Emily Denton; Rob Fergus",
        "abstract": "Generating video frames that accurately predict future world states is challenging. Existing approaches either fail to capture the full distribution of outcomes, or yield blurry generations, or both. In this paper we introduce a video generation model with a learned prior over stochastic latent variables at each time step. Video frames are generated by drawing samples from this prior and combining them with a deterministic estimate of the future frame. The approach is simple and easily trained end-to-end on a variety of datasets. Sample generations are both varied and sharp, even many frames into the future, and compare favorably to those from existing approaches.",
        "bibtex": "@InProceedings{pmlr-v80-denton18a,\n  title = \t {Stochastic Video Generation with a Learned Prior},\n  author =       {Denton, Emily and Fergus, Rob},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1174--1183},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/denton18a/denton18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/denton18a.html},\n  abstract = \t {Generating video frames that accurately predict future world states is challenging. Existing approaches either fail to capture the full distribution of outcomes, or yield blurry generations, or both. In this paper we introduce a video generation model with a learned prior over stochastic latent variables at each time step. Video frames are generated by drawing samples from this prior and combining them with a deterministic estimate of the future frame. The approach is simple and easily trained end-to-end on a variety of datasets. Sample generations are both varied and sharp, even many frames into the future, and compare favorably to those from existing approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/denton18a/denton18a.pdf",
        "supp": "",
        "pdf_size": 5602083,
        "gs_citation": 629,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9440265505324516729&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "New York University; New York University+Facebook AI Research",
        "aff_domain": "cs.nyu.edu; ",
        "email": "cs.nyu.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/denton18a.html",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "New York University;Meta",
        "aff_unique_dep": ";Facebook AI Research",
        "aff_unique_url": "https://www.nyu.edu;https://research.facebook.com",
        "aff_unique_abbr": "NYU;FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stochastic Wasserstein Barycenters",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2316",
        "id": "2316",
        "author_site": "Sebastian Claici, Edward Chien, Justin Solomon",
        "author": "Sebastian Claici; Edward Chien; Justin Solomon",
        "abstract": "We present a stochastic algorithm to compute the barycenter of a set of probability distributions under the Wasserstein metric from optimal transport. Unlike previous approaches, our method extends to continuous input distributions and allows the support of the barycenter to be adjusted in each iteration. We tackle the problem without regularization, allowing us to recover a sharp output whose support is contained within the support of the true barycenter. We give examples where our algorithm recovers a more meaningful barycenter than previous work. Our method is versatile and can be extended to applications such as generating super samples from a given distribution and recovering blue noise approximations.",
        "bibtex": "@InProceedings{pmlr-v80-claici18a,\n  title = \t {Stochastic {W}asserstein Barycenters},\n  author =       {Claici, Sebastian and Chien, Edward and Solomon, Justin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {999--1008},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/claici18a/claici18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/claici18a.html},\n  abstract = \t {We present a stochastic algorithm to compute the barycenter of a set of probability distributions under the Wasserstein metric from optimal transport. Unlike previous approaches, our method extends to continuous input distributions and allows the support of the barycenter to be adjusted in each iteration. We tackle the problem without regularization, allowing us to recover a sharp output whose support is contained within the support of the true barycenter. We give examples where our algorithm recovers a more meaningful barycenter than previous work. Our method is versatile and can be extended to applications such as generating super samples from a given distribution and recovering blue noise approximations.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/claici18a/claici18a.pdf",
        "supp": "",
        "pdf_size": 1116701,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18265142151722303774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Computer Science and Arti\ufb01cal Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA; Computer Science and Arti\ufb01cal Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA; Computer Science and Arti\ufb01cal Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA",
        "aff_domain": "mit.edu; ; ",
        "email": "mit.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/claici18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Arti\ufb01cal Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "StrassenNets: Deep Learning with a Multiplication Budget",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2167",
        "id": "2167",
        "author_site": "Michael Tschannen, Aran Khanna, Animashree Anandkumar",
        "author": "Michael Tschannen; Aran Khanna; Animashree Anandkumar",
        "abstract": "A large fraction of the arithmetic operations required to evaluate deep neural networks (DNNs) consists of matrix multiplications, in both convolution and fully connected layers. We perform end-to-end learning of low-cost approximations of matrix multiplications in DNN layers by casting matrix multiplications as 2-layer sum-product networks (SPNs) (arithmetic circuits) and learning their (ternary) edge weights from data. The SPNs disentangle multiplication and addition operations and enable us to impose a budget on the number of multiplication operations. Combining our method with knowledge distillation and applying it to image classification DNNs (trained on ImageNet) and language modeling DNNs (using LSTMs), we obtain a first-of-a-kind reduction in number of multiplications (over 99.5%) while maintaining the predictive performance of the full-precision models. Finally, we demonstrate that the proposed framework is able to rediscover Strassen\u2019s matrix multiplication algorithm, learning to multiply $2 \\times 2$ matrices using only 7 multiplications instead of 8.",
        "bibtex": "@InProceedings{pmlr-v80-tschannen18a,\n  title = \t {{S}trassen{N}ets: Deep Learning with a Multiplication Budget},\n  author =       {Tschannen, Michael and Khanna, Aran and Anandkumar, Animashree},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4985--4994},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tschannen18a/tschannen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tschannen18a.html},\n  abstract = \t {A large fraction of the arithmetic operations required to evaluate deep neural networks (DNNs) consists of matrix multiplications, in both convolution and fully connected layers. We perform end-to-end learning of low-cost approximations of matrix multiplications in DNN layers by casting matrix multiplications as 2-layer sum-product networks (SPNs) (arithmetic circuits) and learning their (ternary) edge weights from data. The SPNs disentangle multiplication and addition operations and enable us to impose a budget on the number of multiplication operations. Combining our method with knowledge distillation and applying it to image classification DNNs (trained on ImageNet) and language modeling DNNs (using LSTMs), we obtain a first-of-a-kind reduction in number of multiplications (over 99.5%) while maintaining the predictive performance of the full-precision models. Finally, we demonstrate that the proposed framework is able to rediscover Strassen\u2019s matrix multiplication algorithm, learning to multiply $2 \\times 2$ matrices using only 7 multiplications instead of 8.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tschannen18a/tschannen18a.pdf",
        "supp": "",
        "pdf_size": 363644,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9065345888211174353&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "ETH Z\u00fcrich, Z\u00fcrich, Switzerland (most of this work was done while MT was at Amazon AI); Amazon AI, Palo Alto, CA, USA; Amazon AI, Palo Alto, CA, USA + Caltech, Pasadena, CA, USA",
        "aff_domain": "nari.ee.ethz.ch; ;caltech.edu",
        "email": "nari.ee.ethz.ch; ;caltech.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/tschannen18a.html",
        "aff_unique_index": "0;1;1+2",
        "aff_unique_norm": "ETH Zurich;Amazon;California Institute of Technology",
        "aff_unique_dep": ";Amazon AI;",
        "aff_unique_url": "https://www.ethz.ch;https://www.amazon.com;https://www.caltech.edu",
        "aff_unique_abbr": "ETH;Amazon;Caltech",
        "aff_campus_unique_index": "0;1;1+2",
        "aff_campus_unique": "Z\u00fcrich;Palo Alto;Pasadena",
        "aff_country_unique_index": "0;1;1+1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "title": "Streaming Principal Component Analysis in Noisy Setting",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2459",
        "id": "2459",
        "author_site": "Teodor Vanislavov Marinov, Poorya Mianjy, Raman Arora",
        "author": "Teodor Vanislavov Marinov; Poorya Mianjy; Raman Arora",
        "abstract": "We study streaming algorithms for principal component analysis (PCA) in noisy settings. We present computationally efficient algorithms with sub-linear regret bounds for PCA in the presence of noise, missing data, and gross outliers.",
        "bibtex": "@InProceedings{pmlr-v80-marinov18a,\n  title = \t {Streaming Principal Component Analysis in Noisy Setting},\n  author =       {Marinov, Teodor Vanislavov and Mianjy, Poorya and Arora, Raman},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3413--3422},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/marinov18a/marinov18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/marinov18a.html},\n  abstract = \t {We study streaming algorithms for principal component analysis (PCA) in noisy settings. We present computationally efficient algorithms with sub-linear regret bounds for PCA in the presence of noise, missing data, and gross outliers.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/marinov18a/marinov18a.pdf",
        "supp": "",
        "pdf_size": 555644,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7472465716817922212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Johns Hopkins University, Baltimore, USA; Department of Computer Science, Johns Hopkins University, Baltimore, USA; Department of Computer Science, Johns Hopkins University, Baltimore, USA",
        "aff_domain": "cs.jhu.edu; ; ",
        "email": "cs.jhu.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/marinov18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stronger Generalization Bounds for Deep Nets via a Compression Approach",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2412",
        "id": "2412",
        "author_site": "Sanjeev Arora, Rong Ge, Behnam Neyshabur, Yi Zhang",
        "author": "Sanjeev Arora; Rong Ge; Behnam Neyshabur; Yi Zhang",
        "abstract": "Deep nets generalize well despite having more parameters than the number of training samples. Recent works try to give an explanation using PAC-Bayes and Margin-based analyses, but do not as yet result in sample complexity bounds better than naive parameter counting. The current paper shows generalization bounds that are orders of magnitude better in practice. These rely upon new succinct reparametrizations of the trained net \u2014 a compression that is explicit and efficient. These yield generalization bounds via a simple compression-based framework introduced here. Our results also provide some theoretical justification for widespread empirical success in compressing deep nets. Analysis of correctness of our compression relies upon some newly identified noise stability properties of trained deep nets, which are also experimentally verified. The study of these properties and resulting generalization bounds are also extended to convolutional nets, which had eluded earlier attempts on proving generalization.",
        "bibtex": "@InProceedings{pmlr-v80-arora18b,\n  title = \t {Stronger Generalization Bounds for Deep Nets via a Compression Approach},\n  author =       {Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {254--263},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/arora18b/arora18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/arora18b.html},\n  abstract = \t {Deep nets generalize well despite having more parameters than the number of training samples. Recent works try to give an explanation using PAC-Bayes and Margin-based analyses, but do not as yet result in sample complexity bounds better than naive parameter counting. The current paper shows generalization bounds that are orders of magnitude better in practice. These rely upon new succinct reparametrizations of the trained net \u2014 a compression that is explicit and efficient. These yield generalization bounds via a simple compression-based framework introduced here. Our results also provide some theoretical justification for widespread empirical success in compressing deep nets. Analysis of correctness of our compression relies upon some newly identified noise stability properties of trained deep nets, which are also experimentally verified. The study of these properties and resulting generalization bounds are also extended to convolutional nets, which had eluded earlier attempts on proving generalization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/arora18b/arora18b.pdf",
        "supp": "",
        "pdf_size": 645255,
        "gs_citation": 748,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2741843082009546935&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Princeton University, Computer Science Department; Duke University, Computer Science Department; Institute for Advanced Study, School of Mathematics; Princeton University, Computer Science Department",
        "aff_domain": "cs.duke.edu;ias.edu;cs.princeton.edu; ",
        "email": "cs.duke.edu;ias.edu;cs.princeton.edu; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/arora18b.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Princeton University;Duke University;Institute for Advanced Study",
        "aff_unique_dep": "Computer Science Department;Computer Science Department;School of Mathematics",
        "aff_unique_url": "https://www.princeton.edu;https://www.duke.edu;https://ias.edu",
        "aff_unique_abbr": "Princeton;Duke;IAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Structured Control Nets for Deep Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2282",
        "id": "2282",
        "author_site": "Mario Srouji, Jian Zhang, Ruslan Salakhutdinov",
        "author": "Mario Srouji; Jian Zhang; Ruslan Salakhutdinov",
        "abstract": "In recent years, Deep Reinforcement Learning has made impressive advances in solving several important benchmark problems for sequential decision making. Many control applications use a generic multilayer perceptron (MLP) for non-vision parts of the policy network. In this work, we propose a new neural network architecture for the policy network representation that is simple yet effective. The proposed Structured Control Net (SCN) splits the generic MLP into two separate sub-modules: a nonlinear control module and a linear control module. Intuitively, the nonlinear control is for forward-looking and global control, while the linear control stabilizes the local dynamics around the residual of global control. We hypothesize that this will bring together the benefits of both linear and nonlinear policies: improve training sample efficiency, final episodic reward, and generalization of learned policy, while requiring a smaller network and being generally applicable to different training methods. We validated our hypothesis with competitive results on simulations from OpenAI MuJoCo, Roboschool, Atari, and a custom urban driving environment, with various ablation and generalization tests, trained with multiple black-box and policy gradient training methods. The proposed architecture has the potential to improve upon broader control tasks by incorporating problem specific priors into the architecture. As a case study, we demonstrate much improved performance for locomotion tasks by emulating the biological central pattern generators (CPGs) as the nonlinear part of the architecture.",
        "bibtex": "@InProceedings{pmlr-v80-srouji18a,\n  title = \t {Structured Control Nets for Deep Reinforcement Learning},\n  author =       {Srouji, Mario and Zhang, Jian and Salakhutdinov, Ruslan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4742--4751},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/srouji18a/srouji18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/srouji18a.html},\n  abstract = \t {In recent years, Deep Reinforcement Learning has made impressive advances in solving several important benchmark problems for sequential decision making. Many control applications use a generic multilayer perceptron (MLP) for non-vision parts of the policy network. In this work, we propose a new neural network architecture for the policy network representation that is simple yet effective. The proposed Structured Control Net (SCN) splits the generic MLP into two separate sub-modules: a nonlinear control module and a linear control module. Intuitively, the nonlinear control is for forward-looking and global control, while the linear control stabilizes the local dynamics around the residual of global control. We hypothesize that this will bring together the benefits of both linear and nonlinear policies: improve training sample efficiency, final episodic reward, and generalization of learned policy, while requiring a smaller network and being generally applicable to different training methods. We validated our hypothesis with competitive results on simulations from OpenAI MuJoCo, Roboschool, Atari, and a custom urban driving environment, with various ablation and generalization tests, trained with multiple black-box and policy gradient training methods. The proposed architecture has the potential to improve upon broader control tasks by incorporating problem specific priors into the architecture. As a case study, we demonstrate much improved performance for locomotion tasks by emulating the biological central pattern generators (CPGs) as the nonlinear part of the architecture.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/srouji18a/srouji18a.pdf",
        "supp": "",
        "pdf_size": 2132441,
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17366216991612736519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Carnegie Mellon University; Apple Inc. + Carnegie Mellon University; Apple Inc.",
        "aff_domain": "cmu.edu;apple.com;apple.com",
        "email": "cmu.edu;apple.com;apple.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/srouji18a.html",
        "aff_unique_index": "0;1+0;1",
        "aff_unique_norm": "Carnegie Mellon University;Apple",
        "aff_unique_dep": ";Apple Inc.",
        "aff_unique_url": "https://www.cmu.edu;https://www.apple.com",
        "aff_unique_abbr": "CMU;Apple",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Structured Evolution with Compact Architectures for Scalable Policy Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1907",
        "id": "1907",
        "author_site": "Krzysztof Choromanski, Mark Rowland, Vikas Sindhwani, Richard E Turner, Adrian Weller",
        "author": "Krzysztof Choromanski; Mark Rowland; Vikas Sindhwani; Richard Turner; Adrian Weller",
        "abstract": "We present a new method of blackbox optimization via gradient approximation with the use of structured random orthogonal matrices, providing more accurate estimators than baselines and with provable theoretical guarantees. We show that this algorithm can be successfully applied to learn better quality compact policies than those using standard gradient estimation techniques. The compact policies we learn have several advantages over unstructured ones, including faster training algorithms and faster inference. These benefits are important when the policy is deployed on real hardware with limited resources. Further, compact policies provide more scalable architectures for derivative-free optimization (DFO) in high-dimensional spaces. We show that most robotics tasks from the OpenAI Gym can be solved using neural networks with less than 300 parameters, with almost linear time complexity of the inference phase, with up to 13x fewer parameters relative to the Evolution Strategies (ES) algorithm introduced by Salimans et al. (2017). We do not need heuristics such as fitness shaping to learn good quality policies, resulting in a simple and theoretically motivated training mechanism.",
        "bibtex": "@InProceedings{pmlr-v80-choromanski18a,\n  title = \t {Structured Evolution with Compact Architectures for Scalable Policy Optimization},\n  author =       {Choromanski, Krzysztof and Rowland, Mark and Sindhwani, Vikas and Turner, Richard and Weller, Adrian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {970--978},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/choromanski18a/choromanski18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/choromanski18a.html},\n  abstract = \t {We present a new method of blackbox optimization via gradient approximation with the use of structured random orthogonal matrices, providing more accurate estimators than baselines and with provable theoretical guarantees. We show that this algorithm can be successfully applied to learn better quality compact policies than those using standard gradient estimation techniques. The compact policies we learn have several advantages over unstructured ones, including faster training algorithms and faster inference. These benefits are important when the policy is deployed on real hardware with limited resources. Further, compact policies provide more scalable architectures for derivative-free optimization (DFO) in high-dimensional spaces. We show that most robotics tasks from the OpenAI Gym can be solved using neural networks with less than 300 parameters, with almost linear time complexity of the inference phase, with up to 13x fewer parameters relative to the Evolution Strategies (ES) algorithm introduced by Salimans et al. (2017). We do not need heuristics such as fitness shaping to learn good quality policies, resulting in a simple and theoretically motivated training mechanism.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/choromanski18a/choromanski18a.pdf",
        "supp": "",
        "pdf_size": 395000,
        "gs_citation": 164,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2805662320730904644&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Google Brain Robotics; University of Cambridge; Google Brain Robotics; University of Cambridge; University of Cambridge + The Alan Turing Institute",
        "aff_domain": "google.com;cam.ac.uk; ; ; ",
        "email": "google.com;cam.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/choromanski18a.html",
        "aff_unique_index": "0;1;0;1;1+2",
        "aff_unique_norm": "Google;University of Cambridge;Alan Turing Institute",
        "aff_unique_dep": "Google Brain Robotics;;",
        "aff_unique_url": "https://ai.google;https://www.cam.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Google Brain Robotics;Cambridge;ATI",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Mountain View;Cambridge;",
        "aff_country_unique_index": "0;1;0;1;1+1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "title": "Structured Output Learning with Abstention: Application to Accurate Opinion Prediction",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2199",
        "id": "2199",
        "author_site": "Alexandre Garcia, Telecom-ParisTech Chlo\u00e9 Clavel, Slim Essid, Florence d'Alche-Buc",
        "author": "Alexandre Garcia; Chlo\u00e9 Clavel; Slim Essid; Florence d\u2019Alche-Buc",
        "abstract": "Motivated by Supervised Opinion Analysis, we propose a novel framework devoted to Structured Output Learning with Abstention (SOLA). The structure prediction model is able to abstain from predicting some labels in the structured output at a cost chosen by the user in a flexible way. For that purpose, we decompose the problem into the learning of a pair of predictors, one devoted to structured abstention and the other, to structured output prediction. To compare fully labeled training data with predictions potentially containing abstentions, we define a wide class of asymmetric abstention-aware losses. Learning is achieved by surrogate regression in an appropriate feature space while prediction with abstention is performed by solving a new pre-image problem. Thus, SOLA extends recent ideas about Structured Output Prediction via surrogate problems and calibration theory and enjoys statistical guarantees on the resulting excess risk. Instantiated on a hierarchical abstention-aware loss, SOLA is shown to be relevant for fine-grained opinion mining and gives state-of-the-art results on this task. Moreover, the abstention-aware representations can be used to competitively predict user-review ratings based on a sentence-level opinion predictor.",
        "bibtex": "@InProceedings{pmlr-v80-garcia18a,\n  title = \t {Structured Output Learning with Abstention: Application to Accurate Opinion Prediction},\n  author =       {Garcia, Alexandre and Clavel, Chlo{\\'e} and Essid, Slim and d'Alche-Buc, Florence},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1695--1703},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/garcia18a/garcia18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/garcia18a.html},\n  abstract = \t {Motivated by Supervised Opinion Analysis, we propose a novel framework devoted to Structured Output Learning with Abstention (SOLA). The structure prediction model is able to abstain from predicting some labels in the structured output at a cost chosen by the user in a flexible way. For that purpose, we decompose the problem into the learning of a pair of predictors, one devoted to structured abstention and the other, to structured output prediction. To compare fully labeled training data with predictions potentially containing abstentions, we define a wide class of asymmetric abstention-aware losses. Learning is achieved by surrogate regression in an appropriate feature space while prediction with abstention is performed by solving a new pre-image problem. Thus, SOLA extends recent ideas about Structured Output Prediction via surrogate problems and calibration theory and enjoys statistical guarantees on the resulting excess risk. Instantiated on a hierarchical abstention-aware loss, SOLA is shown to be relevant for fine-grained opinion mining and gives state-of-the-art results on this task. Moreover, the abstention-aware representations can be used to competitively predict user-review ratings based on a sentence-level opinion predictor.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/garcia18a/garcia18a.pdf",
        "supp": "",
        "pdf_size": 447892,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2007458627642412735&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "LTCI, Telecom ParisTech, Paris, France; LTCI, Telecom ParisTech, Paris, France; LTCI, Telecom ParisTech, Paris, France; LTCI, Telecom ParisTech, Paris, France",
        "aff_domain": "enst.fr; ; ; ",
        "email": "enst.fr; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/garcia18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Telecom ParisTech",
        "aff_unique_dep": "LTCI",
        "aff_unique_url": "https://www.telecom-paristech.fr",
        "aff_unique_abbr": "Telecom ParisTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2321",
        "id": "2321",
        "author_site": "Soumya Ghosh, Jiayu Yao, Finale Doshi-Velez",
        "author": "Soumya Ghosh; Jiayu Yao; Finale Doshi-Velez",
        "abstract": "Bayesian Neural Networks (BNNs) have recently received increasing attention for their ability to provide well-calibrated posterior uncertainties. However, model selection\u2014even choosing the number of nodes\u2014remains an open question. Recent work has proposed the use of a horseshoe prior over node pre-activations of a Bayesian neural network, which effectively turns off nodes that do not help explain the data. In this work, we propose several modeling and inference advances that consistently improve the compactness of the model learned while maintaining predictive performance, especially in smaller-sample settings including reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v80-ghosh18a,\n  title = \t {Structured Variational Learning of {B}ayesian Neural Networks with Horseshoe Priors},\n  author =       {Ghosh, Soumya and Yao, Jiayu and Doshi-Velez, Finale},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1744--1753},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ghosh18a/ghosh18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ghosh18a.html},\n  abstract = \t {Bayesian Neural Networks (BNNs) have recently received increasing attention for their ability to provide well-calibrated posterior uncertainties. However, model selection\u2014even choosing the number of nodes\u2014remains an open question. Recent work has proposed the use of a horseshoe prior over node pre-activations of a Bayesian neural network, which effectively turns off nodes that do not help explain the data. In this work, we propose several modeling and inference advances that consistently improve the compactness of the model learned while maintaining predictive performance, especially in smaller-sample settings including reinforcement learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ghosh18a/ghosh18a.pdf",
        "supp": "",
        "pdf_size": 1117454,
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9128418694635359827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "IBM research, Cambridge, MA, USA+MIT-IBM Watson AI Lab; Harvard University, Cambridge, MA, USA; Harvard University, Cambridge, MA, USA",
        "aff_domain": "us.ibm.com; ;seas.harvard.edu",
        "email": "us.ibm.com; ;seas.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ghosh18a.html",
        "aff_unique_index": "0+1;2;2",
        "aff_unique_norm": "IBM;Massachusetts Institute of Technology;Harvard University",
        "aff_unique_dep": "Research;IBM Watson AI Lab;",
        "aff_unique_url": "https://www.ibm.com/research;https://www.mitibmwatsonailab.org;https://www.harvard.edu",
        "aff_unique_abbr": "IBM;MIT-IBM AI Lab;Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Structured Variationally Auto-encoded Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2328",
        "id": "2328",
        "author_site": "Xiaoyu Lu, Javier Gonz\u00e1lez, Zhenwen Dai, Neil Lawrence",
        "author": "Xiaoyu Lu; Javier Gonzalez; Zhenwen Dai; Neil D. Lawrence",
        "abstract": "We tackle the problem of optimizing a black-box objective function defined over a highly-structured input space. This problem is ubiquitous in science and engineering. In machine learning, inferring the structure of a neural network or the Automatic Statistician (AS), where the optimal kernel combination for a Gaussian process is selected, are two important examples. We use the \\as as a case study to describe our approach, that can be easily generalized to other domains. We propose an Structure Generating Variational Auto-encoder (SG-VAE) to embed the original space of kernel combinations into some low-dimensional continuous manifold where Bayesian optimization (BO) ideas are used. This is possible when structural knowledge of the problem is available, which can be given via a simulator or any other form of generating potentially good solutions. The right exploration-exploitation balance is imposed by propagating into the search the uncertainty of the latent space of the SG-VAE, that is computed using variational inference. The key aspect of our approach is that the SG-VAE can be used to bias the search towards relevant regions, making it suitable for transfer learning tasks. Several experiments in various application domains are used to illustrate the utility and generality of the approach described in this work.",
        "bibtex": "@InProceedings{pmlr-v80-lu18c,\n  title = \t {Structured Variationally Auto-encoded Optimization},\n  author =       {Lu, Xiaoyu and Gonzalez, Javier and Dai, Zhenwen and Lawrence, Neil},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3267--3275},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lu18c/lu18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lu18c.html},\n  abstract = \t {We tackle the problem of optimizing a black-box objective function defined over a highly-structured input space. This problem is ubiquitous in science and engineering. In machine learning, inferring the structure of a neural network or the Automatic Statistician (AS), where the optimal kernel combination for a Gaussian process is selected, are two important examples. We use the \\as as a case study to describe our approach, that can be easily generalized to other domains. We propose an Structure Generating Variational Auto-encoder (SG-VAE) to embed the original space of kernel combinations into some low-dimensional continuous manifold where Bayesian optimization (BO) ideas are used. This is possible when structural knowledge of the problem is available, which can be given via a simulator or any other form of generating potentially good solutions. The right exploration-exploitation balance is imposed by propagating into the search the uncertainty of the latent space of the SG-VAE, that is computed using variational inference. The key aspect of our approach is that the SG-VAE can be used to bias the search towards relevant regions, making it suitable for transfer learning tasks. Several experiments in various application domains are used to illustrate the utility and generality of the approach described in this work.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lu18c/lu18c.pdf",
        "supp": "",
        "pdf_size": 4800626,
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9629473550267389476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, University of Oxford; Amazon, Cambridge; Amazon, Cambridge; University of Sheffield + Department of Statistics, University of Oxford",
        "aff_domain": "stats.ox.ac.uk;amazon.com;amazon.com;sheffield.ac.uk",
        "email": "stats.ox.ac.uk;amazon.com;amazon.com;sheffield.ac.uk",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/lu18c.html",
        "aff_unique_index": "0;1;1;2+0",
        "aff_unique_norm": "University of Oxford;Amazon;University of Sheffield",
        "aff_unique_dep": "Department of Statistics;Amazon;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.amazon.com;https://www.sheffield.ac.uk",
        "aff_unique_abbr": "Oxford;Amazon;Sheffield",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Oxford;Cambridge;",
        "aff_country_unique_index": "0;1;1;0+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2317",
        "id": "2317",
        "author_site": "Yuxuan Wang, Daisy Stanton, Yu Zhang, RJ-Skerry Ryan, Eric Battenberg, Joel Shor, Ying Xiao, Ye Jia, Fei Ren, Rif Saurous",
        "author": "Yuxuan Wang; Daisy Stanton; Yu Zhang; RJ-Skerry Ryan; Eric Battenberg; Joel Shor; Ying Xiao; Ye Jia; Fei Ren; Rif A. Saurous",
        "abstract": "In this work, we propose \u201cglobal style tokens\u201d (GSTs), a bank of embeddings that are jointly trained within Tacotron, a state-of-the-art end-to-end speech synthesis system. The embeddings are trained with no explicit labels, yet learn to model a large range of acoustic expressiveness. GSTs lead to a rich set of significant results. The soft interpretable \u201clabels\u201d they generate can be used to control synthesis in novel ways, such as varying speed and speaking style \u2013 independently of the text content. They can also be used for style transfer, replicating the speaking style of a single audio clip across an entire long-form text corpus. When trained on noisy, unlabeled found data, GSTs learn to factorize noise and speaker identity, providing a path towards highly scalable but robust speech synthesis.",
        "bibtex": "@InProceedings{pmlr-v80-wang18h,\n  title = \t {Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis},\n  author =       {Wang, Yuxuan and Stanton, Daisy and Zhang, Yu and Ryan, RJ-Skerry and Battenberg, Eric and Shor, Joel and Xiao, Ying and Jia, Ye and Ren, Fei and Saurous, Rif A.},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5180--5189},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18h/wang18h.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18h.html},\n  abstract = \t {In this work, we propose \u201cglobal style tokens\u201d (GSTs), a bank of embeddings that are jointly trained within Tacotron, a state-of-the-art end-to-end speech synthesis system. The embeddings are trained with no explicit labels, yet learn to model a large range of acoustic expressiveness. GSTs lead to a rich set of significant results. The soft interpretable \u201clabels\u201d they generate can be used to control synthesis in novel ways, such as varying speed and speaking style \u2013 independently of the text content. They can also be used for style transfer, replicating the speaking style of a single audio clip across an entire long-form text corpus. When trained on noisy, unlabeled found data, GSTs learn to factorize noise and speaker identity, providing a path towards highly scalable but robust speech synthesis.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18h/wang18h.pdf",
        "supp": "",
        "pdf_size": 3611806,
        "gs_citation": 1059,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1698068168602840874&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "https://google.github.io/tacotron/publications/global_style_tokens/",
        "author_num": 10,
        "oa": "https://proceedings.mlr.press/v80/wang18h.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral Clustering",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2044",
        "id": "2044",
        "author_site": "Pan Li, Olgica Milenkovic",
        "author": "Pan Li; Olgica Milenkovic",
        "abstract": "We introduce submodular hypergraphs, a family of hypergraphs that have different submodular weights associated with different cuts of hyperedges. Submodular hypergraphs arise in cluster- ing applications in which higher-order structures carry relevant information. For such hypergraphs, we define the notion of p-Laplacians and derive corresponding nodal domain theorems and k-way Cheeger inequalities. We conclude with the description of algorithms for computing the spectra of 1- and 2-Laplacians that constitute the basis of new spectral hypergraph clustering methods.",
        "bibtex": "@InProceedings{pmlr-v80-li18e,\n  title = \t {Submodular Hypergraphs: p-Laplacians, {C}heeger Inequalities and Spectral Clustering},\n  author =       {Li, Pan and Milenkovic, Olgica},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3014--3023},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18e/li18e.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18e.html},\n  abstract = \t {We introduce submodular hypergraphs, a family of hypergraphs that have different submodular weights associated with different cuts of hyperedges. Submodular hypergraphs arise in cluster- ing applications in which higher-order structures carry relevant information. For such hypergraphs, we define the notion of p-Laplacians and derive corresponding nodal domain theorems and k-way Cheeger inequalities. We conclude with the description of algorithms for computing the spectra of 1- and 2-Laplacians that constitute the basis of new spectral hypergraph clustering methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18e/li18e.pdf",
        "supp": "",
        "pdf_size": 374970,
        "gs_citation": 127,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3565527307250795946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, USA; Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, USA",
        "aff_domain": "illinois.edu;illinois.edu",
        "email": "illinois.edu;illinois.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/li18e.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Subspace Embedding and Linear Regression with Orlicz Norm",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2451",
        "id": "2451",
        "author_site": "Alexandr Andoni, Chengyu Lin, Ying Sheng, Peilin Zhong, Ruiqi Zhong",
        "author": "Alexandr Andoni; Chengyu Lin; Ying Sheng; Peilin Zhong; Ruiqi Zhong",
        "abstract": "We consider a generalization of the classic linear regression problem to the case when the loss is an Orlicz norm. An Orlicz norm is parameterized by a non-negative convex function G: R_+ - > R_+ with G(0) = 0: the Orlicz norm of a n-dimensional vector x is defined as |x|_G = inf{ alpha > 0 | sum_{i = 1}^n G( |x_i| / alpha ) < = 1 }. We consider the cases where the function G grows subquadratically. Our main result is based on a new oblivious embedding which embeds the column space of a given nxd matrix A with Orlicz norm into a lower dimensional space with L2 norm. Specifically, we show how to efficiently find an mxn embedding matrix S (m < n), such that for every d-dimensional vector x, we have Omega(1/(d log n)) |Ax|_G < = |SAx|_2 < = O(d^2 log n) |Ax|_G. By applying this subspace embedding technique, we show an approximation algorithm for the regression problem min_x |Ax-b|_G, up to a O( d log^2 n ) factor. As a further application of our techniques, we show how to also use them to improve on the algorithm for the Lp low rank matrix approximation problem for 1 < = p < 2.",
        "bibtex": "@InProceedings{pmlr-v80-andoni18a,\n  title = \t {Subspace Embedding and Linear Regression with Orlicz Norm},\n  author =       {Andoni, Alexandr and Lin, Chengyu and Sheng, Ying and Zhong, Peilin and Zhong, Ruiqi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {224--233},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/andoni18a/andoni18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/andoni18a.html},\n  abstract = \t {We consider a generalization of the classic linear regression problem to the case when the loss is an Orlicz norm. An Orlicz norm is parameterized by a non-negative convex function G: R_+ - > R_+ with G(0) = 0: the Orlicz norm of a n-dimensional vector x is defined as |x|_G = inf{ alpha > 0 | sum_{i = 1}^n G( |x_i| / alpha ) < = 1 }. We consider the cases where the function G grows subquadratically. Our main result is based on a new oblivious embedding which embeds the column space of a given nxd matrix A with Orlicz norm into a lower dimensional space with L2 norm. Specifically, we show how to efficiently find an mxn embedding matrix S (m < n), such that for every d-dimensional vector x, we have Omega(1/(d log n)) |Ax|_G < = |SAx|_2 < = O(d^2 log n) |Ax|_G. By applying this subspace embedding technique, we show an approximation algorithm for the regression problem min_x |Ax-b|_G, up to a O( d log^2 n ) factor. As a further application of our techniques, we show how to also use them to improve on the algorithm for the Lp low rank matrix approximation problem for 1 < = p < 2.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/andoni18a/andoni18a.pdf",
        "supp": "",
        "pdf_size": 487560,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16279794667075566688&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Department, Columbia University; Computer Science Department, Columbia University; Computer Science Department, Columbia University; Computer Science Department, Columbia University; Computer Science Department, Columbia University",
        "aff_domain": "columbia.edu; ; ; ; ",
        "email": "columbia.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/andoni18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Synthesizing Programs for Images using Reinforced Adversarial Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1972",
        "id": "1972",
        "author_site": "Iaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S. M. Ali Eslami, Oriol Vinyals",
        "author": "Yaroslav Ganin; Tejas Kulkarni; Igor Babuschkin; S. M. Ali Eslami; Oriol Vinyals",
        "abstract": "Advances in deep generative networks have led to impressive results in recent years. Nevertheless, such models can often waste their capacity on the minutiae of datasets, presumably due to weak inductive biases in their decoders. This is where graphics engines may come in handy since they abstract away low-level details and represent images as high-level programs. Current methods that combine deep learning and renderers are limited by hand-crafted likelihood or distance functions, a need for large amounts of supervision, or difficulties in scaling their inference algorithms to richer datasets. To mitigate these issues, we present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images. The goal of this agent is to fool a discriminator network that distinguishes between real and rendered data, trained with a distributed reinforcement learning setup without any supervision. A surprising finding is that using the discriminator\u2019s output as a reward signal is the key to allow the agent to make meaningful progress at matching the desired output rendering. To the best of our knowledge, this is the first demonstration of an end-to-end, unsupervised and adversarial inverse graphics agent on challenging real world (MNIST, Omniglot, CelebA) and synthetic 3D datasets. A video of the agent can be found at https://youtu.be/iSyvwAwa7vk.",
        "bibtex": "@InProceedings{pmlr-v80-ganin18a,\n  title = \t {Synthesizing Programs for Images using Reinforced Adversarial Learning},\n  author =       {Ganin, Yaroslav and Kulkarni, Tejas and Babuschkin, Igor and Eslami, S. M. Ali and Vinyals, Oriol},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1666--1675},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ganin18a/ganin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ganin18a.html},\n  abstract = \t {Advances in deep generative networks have led to impressive results in recent years. Nevertheless, such models can often waste their capacity on the minutiae of datasets, presumably due to weak inductive biases in their decoders. This is where graphics engines may come in handy since they abstract away low-level details and represent images as high-level programs. Current methods that combine deep learning and renderers are limited by hand-crafted likelihood or distance functions, a need for large amounts of supervision, or difficulties in scaling their inference algorithms to richer datasets. To mitigate these issues, we present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images. The goal of this agent is to fool a discriminator network that distinguishes between real and rendered data, trained with a distributed reinforcement learning setup without any supervision. A surprising finding is that using the discriminator\u2019s output as a reward signal is the key to allow the agent to make meaningful progress at matching the desired output rendering. To the best of our knowledge, this is the first demonstration of an end-to-end, unsupervised and adversarial inverse graphics agent on challenging real world (MNIST, Omniglot, CelebA) and synthetic 3D datasets. A video of the agent can be found at https://youtu.be/iSyvwAwa7vk.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ganin18a/ganin18a.pdf",
        "supp": "",
        "pdf_size": 2417975,
        "gs_citation": 274,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=99646247067964900&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Montreal Institute for Learning Algorithms, Montreal, Canada+DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom",
        "aff_domain": "gmail.com; ; ; ; ",
        "email": "gmail.com; ; ; ; ",
        "github": "",
        "project": "https://youtu.be/iSyvwAwa7vk",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/ganin18a.html",
        "aff_unique_index": "0+1;1;1;1;1",
        "aff_unique_norm": "Montreal Institute for Learning Algorithms;DeepMind",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://mila.quebec;https://deepmind.com",
        "aff_unique_abbr": "MILA;DeepMind",
        "aff_campus_unique_index": "0+1;1;1;1;1",
        "aff_campus_unique": "Montreal;London",
        "aff_country_unique_index": "0+1;1;1;1;1",
        "aff_country_unique": "Canada;United Kingdom"
    },
    {
        "title": "Synthesizing Robust Adversarial Examples",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2307",
        "id": "2307",
        "author_site": "Anish Athalye, Logan Engstrom, Andrew Ilyas, Kevin Kwok",
        "author": "Anish Athalye; Logan Engstrom; Andrew Ilyas; Kevin Kwok",
        "abstract": "Standard methods for generating adversarial examples for neural networks do not consistently fool neural network classifiers in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations, limiting their relevance to real-world systems. We demonstrate the existence of robust 3D adversarial objects, and we present the first algorithm for synthesizing examples that are adversarial over a chosen distribution of transformations. We synthesize two-dimensional adversarial images that are robust to noise, distortion, and affine transformation. We apply our algorithm to complex three-dimensional objects, using 3D-printing to manufacture the first physical adversarial objects. Our results demonstrate the existence of 3D adversarial objects in the physical world.",
        "bibtex": "@InProceedings{pmlr-v80-athalye18b,\n  title = \t {Synthesizing Robust Adversarial Examples},\n  author =       {Athalye, Anish and Engstrom, Logan and Ilyas, Andrew and Kwok, Kevin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {284--293},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/athalye18b/athalye18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/athalye18b.html},\n  abstract = \t {Standard methods for generating adversarial examples for neural networks do not consistently fool neural network classifiers in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations, limiting their relevance to real-world systems. We demonstrate the existence of robust 3D adversarial objects, and we present the first algorithm for synthesizing examples that are adversarial over a chosen distribution of transformations. We synthesize two-dimensional adversarial images that are robust to noise, distortion, and affine transformation. We apply our algorithm to complex three-dimensional objects, using 3D-printing to manufacture the first physical adversarial objects. Our results demonstrate the existence of 3D adversarial objects in the physical world.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/athalye18b/athalye18b.pdf",
        "supp": "",
        "pdf_size": 1477667,
        "gs_citation": 2125,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4844547796895961001&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Massachusetts Institute of Technology+LabSix; Massachusetts Institute of Technology+LabSix; Massachusetts Institute of Technology+LabSix; LabSix",
        "aff_domain": "mit.edu; ; ; ",
        "email": "mit.edu; ; ; ",
        "github": "",
        "project": "https://youtu.be/YXy6oX1iNoA",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/athalye18b.html",
        "aff_unique_index": "0+1;0+1;0+1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;LabSix",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;",
        "aff_unique_abbr": "MIT;",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "title": "TACO: Learning Task Decomposition via Temporal Alignment for Control",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2465",
        "id": "2465",
        "author_site": "Kyriacos Shiarlis, Markus Wulfmeier, Sasha Salter, Shimon Whiteson, Ingmar Posner",
        "author": "Kyriacos Shiarlis; Markus Wulfmeier; Sasha Salter; Shimon Whiteson; Ingmar Posner",
        "abstract": "Many advanced Learning from Demonstration (LfD) methods consider the decomposition of complex, real-world tasks into simpler sub-tasks. By reusing the corresponding sub-policies within and between tasks, we can provide training data for each policy from different high-level tasks and compose them to perform novel ones. Existing approaches to modular LfD focus either on learning a single high-level task or depend on domain knowledge and temporal segmentation. In contrast, we propose a weakly supervised, domain-agnostic approach based on task sketches, which include only the sequence of sub-tasks performed in each demonstration. Our approach simultaneously aligns the sketches with the observed demonstrations and learns the required sub-policies. This improves generalisation in comparison to separate optimisation procedures. We evaluate the approach on multiple domains, including a simulated 3D robot arm control task using purely image-based observations. The results show that our approach performs commensurately with fully supervised approaches, while requiring significantly less annotation effort.",
        "bibtex": "@InProceedings{pmlr-v80-shiarlis18a,\n  title = \t {{TACO}: Learning Task Decomposition via Temporal Alignment for Control},\n  author =       {Shiarlis, Kyriacos and Wulfmeier, Markus and Salter, Sasha and Whiteson, Shimon and Posner, Ingmar},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4654--4663},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/shiarlis18a/shiarlis18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/shiarlis18a.html},\n  abstract = \t {Many advanced Learning from Demonstration (LfD) methods consider the decomposition of complex, real-world tasks into simpler sub-tasks. By reusing the corresponding sub-policies within and between tasks, we can provide training data for each policy from different high-level tasks and compose them to perform novel ones. Existing approaches to modular LfD focus either on learning a single high-level task or depend on domain knowledge and temporal segmentation. In contrast, we propose a weakly supervised, domain-agnostic approach based on task sketches, which include only the sequence of sub-tasks performed in each demonstration. Our approach simultaneously aligns the sketches with the observed demonstrations and learns the required sub-policies. This improves generalisation in comparison to separate optimisation procedures. We evaluate the approach on multiple domains, including a simulated 3D robot arm control task using purely image-based observations. The results show that our approach performs commensurately with fully supervised approaches, while requiring significantly less annotation effort.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/shiarlis18a/shiarlis18a.pdf",
        "supp": "",
        "pdf_size": 3211171,
        "gs_citation": 117,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6126682606154229535&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Informatics Institute, University of Amsterdam, Netherlands; Department of Engineering Science, University of Oxford, United Kingdom; Department of Engineering Science, University of Oxford, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom; Department of Engineering Science, University of Oxford, United Kingdom",
        "aff_domain": "uva.nl; ; ; ; ",
        "email": "uva.nl; ; ; ; ",
        "github": "",
        "project": "https://sites.google.com/view/taco-ml",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/shiarlis18a.html",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Amsterdam;University of Oxford",
        "aff_unique_dep": "Informatics Institute;Department of Engineering Science",
        "aff_unique_url": "https://www.uva.nl;https://www.ox.ac.uk",
        "aff_unique_abbr": "UvA;Oxford",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Oxford",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Netherlands;United Kingdom"
    },
    {
        "title": "TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2140",
        "id": "2140",
        "author_site": "Amartya Sanyal, Matt Kusner, Adria Gascon, Varun Kanade",
        "author": "Amartya Sanyal; Matt Kusner; Adria Gascon; Varun Kanade",
        "abstract": "Machine learning methods are widely used for a variety of prediction problems. Prediction as a service is a paradigm in which service providers with technological expertise and computational resources may perform predictions for clients. However, data privacy severely restricts the applicability of such services, unless measures to keep client data private (even from the service provider) are designed. Equally important is to minimize the nature of computation and amount of communication required between client and server. Fully homomorphic encryption offers a way out, whereby clients may encrypt their data, and on which the server may perform arithmetic computations. The one drawback of using fully homomorphic encryption is the amount of time required to evaluate large machine learning models on encrypted data. We combine several ideas from the machine learning literature, particularly work on quantization and sparsification of neural networks, together with algorithmic tools to speed-up and parallelize computation using encrypted data.",
        "bibtex": "@InProceedings{pmlr-v80-sanyal18a,\n  title = \t {{TAPAS}: Tricks to Accelerate (encrypted) Prediction As a Service},\n  author =       {Sanyal, Amartya and Kusner, Matt and Gascon, Adria and Kanade, Varun},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4490--4499},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sanyal18a/sanyal18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sanyal18a.html},\n  abstract = \t {Machine learning methods are widely used for a variety of prediction problems. Prediction as a service is a paradigm in which service providers with technological expertise and computational resources may perform predictions for clients. However, data privacy severely restricts the applicability of such services, unless measures to keep client data private (even from the service provider) are designed. Equally important is to minimize the nature of computation and amount of communication required between client and server. Fully homomorphic encryption offers a way out, whereby clients may encrypt their data, and on which the server may perform arithmetic computations. The one drawback of using fully homomorphic encryption is the amount of time required to evaluate large machine learning models on encrypted data. We combine several ideas from the machine learning literature, particularly work on quantization and sparsification of neural networks, together with algorithmic tools to speed-up and parallelize computation using encrypted data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sanyal18a/sanyal18a.pdf",
        "supp": "",
        "pdf_size": 613082,
        "gs_citation": 182,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13862835131458070168&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "University of Oxford; The Alan Turing Institute; University of Warwick; University of Oxford+The Alan Turing Institute",
        "aff_domain": "cs.ox.ac.uk; ; ; ",
        "email": "cs.ox.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sanyal18a.html",
        "aff_unique_index": "0;1;2;0+1",
        "aff_unique_norm": "University of Oxford;Alan Turing Institute;University of Warwick",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.turing.ac.uk;https://www.warwick.ac.uk",
        "aff_unique_abbr": "Oxford;ATI;Warwick",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Tempered Adversarial Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1870",
        "id": "1870",
        "author_site": "Mehdi S. M. Sajjadi, Giambattista Parascandolo, Arash Mehrjou, Bernhard Sch\u00f6lkopf",
        "author": "Mehdi S. M. Sajjadi; Giambattista Parascandolo; Arash Mehrjou; Bernhard Sch\u00f6lkopf",
        "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples which leads to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the generator and discriminator by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this can improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).",
        "bibtex": "@InProceedings{pmlr-v80-sajjadi18a,\n  title = \t {Tempered Adversarial Networks},\n  author =       {Sajjadi, Mehdi S. M. and Parascandolo, Giambattista and Mehrjou, Arash and Sch{\\\"o}lkopf, Bernhard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4451--4459},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/sajjadi18a/sajjadi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/sajjadi18a.html},\n  abstract = \t {Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples which leads to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the generator and discriminator by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this can improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).}\n}",
        "pdf": "http://proceedings.mlr.press/v80/sajjadi18a/sajjadi18a.pdf",
        "supp": "",
        "pdf_size": 3523988,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14474674151316898300&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany+Max Planck ETH Center for Learning Systems, Z\u00fcrich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany+Max Planck ETH Center for Learning Systems, Z\u00fcrich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": "msajjadi.com; ; ; ",
        "email": "msajjadi.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/sajjadi18a.html",
        "aff_unique_index": "0+1;0+1;0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Max Planck ETH Center for Learning Systems",
        "aff_unique_dep": ";Center for Learning Systems",
        "aff_unique_url": "https://www.mpi-is.mpg.de;",
        "aff_unique_abbr": "MPI-IS;",
        "aff_campus_unique_index": "0+1;0+1;0;0",
        "aff_campus_unique": "T\u00fcbingen;Z\u00fcrich",
        "aff_country_unique_index": "0+1;0+1;0;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "title": "Temporal Poisson Square Root Graphical Models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2301",
        "id": "2301",
        "author_site": "Sinong Geng, Zhaobin Kuang, Peggy Peissig, University of Wisconsin David Page",
        "author": "Sinong Geng; Zhaobin Kuang; Peggy Peissig; David Page",
        "abstract": "We propose temporal Poisson square root graphical models (TPSQRs), a generalization of Poisson square root graphical models (PSQRs) specifically designed for modeling longitudinal event data. By estimating the temporal relationships for all possible pairs of event types, TPSQRs can offer a holistic perspective about whether the occurrences of any given event type could excite or inhibit any other type. A TPSQR is learned by estimating a collection of interrelated PSQRs that share the same template parameterization. These PSQRs are estimated jointly in a pseudo-likelihood fashion, where Poisson pseudo-likelihood is used to approximate the original more computationally intensive pseudo-likelihood problem stemming from PSQRs. Theoretically, we demonstrate that under mild assumptions, the Poisson pseudolikelihood approximation is sparsistent for recovering the underlying PSQR. Empirically, we learn TPSQRs from a real-world large-scale electronic health record (EHR) with millions of drug prescription and condition diagnosis events, for adverse drug reaction (ADR) detection. Experimental results demonstrate that the learned TPSQRs can recover ADR signals from the EHR effectively and efficiently.",
        "bibtex": "@InProceedings{pmlr-v80-geng18a,\n  title = \t {Temporal Poisson Square Root Graphical Models},\n  author =       {Geng, Sinong and Kuang, Zhaobin and Peissig, Peggy and Page, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1714--1723},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/geng18a/geng18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/geng18a.html},\n  abstract = \t {We propose temporal Poisson square root graphical models (TPSQRs), a generalization of Poisson square root graphical models (PSQRs) specifically designed for modeling longitudinal event data. By estimating the temporal relationships for all possible pairs of event types, TPSQRs can offer a holistic perspective about whether the occurrences of any given event type could excite or inhibit any other type. A TPSQR is learned by estimating a collection of interrelated PSQRs that share the same template parameterization. These PSQRs are estimated jointly in a pseudo-likelihood fashion, where Poisson pseudo-likelihood is used to approximate the original more computationally intensive pseudo-likelihood problem stemming from PSQRs. Theoretically, we demonstrate that under mild assumptions, the Poisson pseudolikelihood approximation is sparsistent for recovering the underlying PSQR. Empirically, we learn TPSQRs from a real-world large-scale electronic health record (EHR) with millions of drug prescription and condition diagnosis events, for adverse drug reaction (ADR) detection. Experimental results demonstrate that the learned TPSQRs can recover ADR signals from the EHR effectively and efficiently.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/geng18a/geng18a.pdf",
        "supp": "",
        "pdf_size": 580316,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14607342999931961174&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "The University of Wisconsin, Madison; The University of Wisconsin, Madison; Marshfield Clinic Research Institute; The University of Wisconsin, Madison",
        "aff_domain": "wisc.edu; ; ; ",
        "email": "wisc.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/geng18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Wisconsin-Madison;Marshfield Clinic",
        "aff_unique_dep": ";Research Institute",
        "aff_unique_url": "https://www.wisc.edu;https://www.marshfieldclinic.org/research/",
        "aff_unique_abbr": "UW-Madison;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Madison;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Testing Sparsity over Known and Unknown Bases",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2164",
        "id": "2164",
        "author_site": "Siddharth Barman, Arnab Bhattacharyya, Suprovat Ghoshal",
        "author": "Siddharth Barman; Arnab Bhattacharyya; Suprovat Ghoshal",
        "abstract": "Sparsity is a basic property of real vectors that is exploited in a wide variety of machine learning applications. In this work, we describe property testing algorithms for sparsity that observe a low-dimensional projec- tion of the input. We consider two settings. In the first setting, we test sparsity with respect to an unknown basis: given input vectors $y_1 ,...,y_p \\in R^d$ whose concatenation as columns forms $Y \\in R^{d \\times p}$ , does $Y = AX$ for matrices $A \\in R^{d\\times m}$ and $X \\in R^{m \\times p}$ such that each column of $X$ is $k$-sparse, or is $Y$ \u201cfar\u201d from having such a decomposition? In the second setting, we test sparsity with respect to a known basis: for a fixed design ma- trix $A \\in R^{d \\times m}$ , given input vector $y \\in R^d$ , is $y = Ax$ for some $k$-sparse vector $x$ or is $y$ \u201cfar\u201d from having such a decomposition? We analyze our algorithms using tools from high-dimensional geometry and probability.",
        "bibtex": "@InProceedings{pmlr-v80-barman18a,\n  title = \t {Testing Sparsity over Known and Unknown Bases},\n  author =       {Barman, Siddharth and Bhattacharyya, Arnab and Ghoshal, Suprovat},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {491--500},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/barman18a/barman18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/barman18a.html},\n  abstract = \t {Sparsity is a basic property of real vectors that is exploited in a wide variety of machine learning applications. In this work, we describe property testing algorithms for sparsity that observe a low-dimensional projec- tion of the input. We consider two settings. In the first setting, we test sparsity with respect to an unknown basis: given input vectors $y_1 ,...,y_p \\in R^d$ whose concatenation as columns forms $Y \\in R^{d \\times p}$ , does $Y = AX$ for matrices $A \\in R^{d\\times m}$ and $X \\in R^{m \\times p}$ such that each column of $X$ is $k$-sparse, or is $Y$ \u201cfar\u201d from having such a decomposition? In the second setting, we test sparsity with respect to a known basis: for a fixed design ma- trix $A \\in R^{d \\times m}$ , given input vector $y \\in R^d$ , is $y = Ax$ for some $k$-sparse vector $x$ or is $y$ \u201cfar\u201d from having such a decomposition? We analyze our algorithms using tools from high-dimensional geometry and probability.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/barman18a/barman18a.pdf",
        "supp": "",
        "pdf_size": 648347,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11163726394919383119&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",
        "aff_domain": "iisc.ac.in;iisc.ac.in;iisc.ac.in",
        "email": "iisc.ac.in;iisc.ac.in;iisc.ac.in",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/barman18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Department of Computer Science and Automation",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "The Dynamics of Learning: A Random Matrix Approach",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2023",
        "id": "2023",
        "author_site": "Zhenyu Liao, Romain Couillet",
        "author": "Zhenyu Liao; Romain Couillet",
        "abstract": "Understanding the learning dynamics of neural networks is one of the key issues for the improvement of optimization algorithms as well as for the theoretical comprehension of why deep neural nets work so well today. In this paper, we introduce a random matrix-based framework to analyze the learning dynamics of a single-layer linear network on a binary classification problem, for data of simultaneously large dimension and size, trained by gradient descent. Our results provide rich insights into common questions in neural nets, such as overfitting, early stopping and the initialization of training, thereby opening the door for future studies of more elaborate structures and models appearing in today\u2019s neural networks.",
        "bibtex": "@InProceedings{pmlr-v80-liao18b,\n  title = \t {The Dynamics of Learning: A Random Matrix Approach},\n  author =       {Liao, Zhenyu and Couillet, Romain},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3072--3081},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liao18b/liao18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liao18b.html},\n  abstract = \t {Understanding the learning dynamics of neural networks is one of the key issues for the improvement of optimization algorithms as well as for the theoretical comprehension of why deep neural nets work so well today. In this paper, we introduce a random matrix-based framework to analyze the learning dynamics of a single-layer linear network on a binary classification problem, for data of simultaneously large dimension and size, trained by gradient descent. Our results provide rich insights into common questions in neural nets, such as overfitting, early stopping and the initialization of training, thereby opening the door for future studies of more elaborate structures and models appearing in today\u2019s neural networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liao18b/liao18b.pdf",
        "supp": "",
        "pdf_size": 743924,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11901192186965291730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Laboratoire des Signaux et Syst\u00e8mes (L2S), CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France+G-STATS Data Science Chair, GIPSA-lab, University Grenobles-Alpes, France; Laboratoire des Signaux et Syst\u00e8mes (L2S), CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France+G-STATS Data Science Chair, GIPSA-lab, University Grenobles-Alpes, France",
        "aff_domain": "l2s.centralesupelec.fr;centralesupelec.fr",
        "email": "l2s.centralesupelec.fr;centralesupelec.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/liao18b.html",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "CentraleSup\u00e9lec;University Grenobles-Alpes",
        "aff_unique_dep": "Laboratoire des Signaux et Syst\u00e8mes (L2S);GIPSA-lab",
        "aff_unique_url": "https://www.centralesupelec.fr;https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "CentraleSup\u00e9lec;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "France"
    },
    {
        "title": "The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2088",
        "id": "2088",
        "author_site": "Hao Lu, Yuan Cao, Junwei Lu, Han Liu, Zhaoran Wang",
        "author": "Hao Lu; Yuan Cao; Zhuoran Yang; Junwei Lu; Han Liu; Zhaoran Wang",
        "abstract": "We study the hypothesis testing problem of inferring the existence of combinatorial structures in undirected graphical models. Although there exist extensive studies on the information-theoretic limits of this problem, it remains largely unexplored whether such limits can be attained by efficient algorithms. In this paper, we quantify the minimum computational complexity required to attain the information-theoretic limits based on an oracle computational model. We prove that, for testing common combinatorial structures, such as clique, nearest neighbor graph and perfect matching, against an empty graph, or large clique against small clique, the information-theoretic limits are provably unachievable by tractable algorithms in general. More importantly, we define structural quantities called the weak and strong edge densities, which offer deep insight into the existence of such computational-statistical tradeoffs. To the best of our knowledge, our characterization is the first to identify and explain the fundamental tradeoffs between statistics and computation for combinatorial inference problems in undirected graphical models.",
        "bibtex": "@InProceedings{pmlr-v80-lu18a,\n  title = \t {The Edge Density Barrier: Computational-Statistical Tradeoffs in Combinatorial Inference},\n  author =       {Lu, Hao and Cao, Yuan and Yang, Zhuoran and Lu, Junwei and Liu, Han and Wang, Zhaoran},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3247--3256},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/lu18a/lu18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/lu18a.html},\n  abstract = \t {We study the hypothesis testing problem of inferring the existence of combinatorial structures in undirected graphical models. Although there exist extensive studies on the information-theoretic limits of this problem, it remains largely unexplored whether such limits can be attained by efficient algorithms. In this paper, we quantify the minimum computational complexity required to attain the information-theoretic limits based on an oracle computational model. We prove that, for testing common combinatorial structures, such as clique, nearest neighbor graph and perfect matching, against an empty graph, or large clique against small clique, the information-theoretic limits are provably unachievable by tractable algorithms in general. More importantly, we define structural quantities called the weak and strong edge densities, which offer deep insight into the existence of such computational-statistical tradeoffs. To the best of our knowledge, our characterization is the first to identify and explain the fundamental tradeoffs between statistics and computation for combinatorial inference problems in undirected graphical models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/lu18a/lu18a.pdf",
        "supp": "",
        "pdf_size": 691775,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1366180845599811278&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ, USA; Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ, USA; Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ, USA; Department of Biostatistics, Harvard University, Boston, MA, USA; Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Department of Industrial Engineering and Management Sciences, Northwestern University, Evanston, IL, USA",
        "aff_domain": "princeton.edu; ; ; ; ; ",
        "email": "princeton.edu; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/lu18a.html",
        "aff_unique_index": "0;0;0;1;2;2",
        "aff_unique_norm": "Princeton University;Harvard University;Northwestern University",
        "aff_unique_dep": "Department of Operations Research and Financial Engineering;Department of Biostatistics;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.princeton.edu;https://www.harvard.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "Princeton;Harvard;NU",
        "aff_campus_unique_index": "0;0;0;1;2;2",
        "aff_campus_unique": "Princeton;Boston;Evanston",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "The Generalization Error of Dictionary Learning with Moreau Envelopes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1931",
        "id": "1931",
        "author_site": "ALEXANDROS GEORGOGIANNIS",
        "author": "Alexandros Georgogiannis",
        "abstract": "This is a theoretical study on the sample complexity of dictionary learning with a general type of reconstruction loss. The goal is to estimate a $m \\times d$ matrix $D$ of unit-norm columns when the only available information is a set of training samples. Points $x$ in $\\mathbb{R}^m$ are subsequently approximated by the linear combination $Da$ after solving the problem $\\min_{a \\in \\mathbb{R}^d}\u00a0 \\Phi(x - Da) + g(a)$; function $g:\\mathbb{R}^d \\to [0,+\\infty)$ is either an indicator function or a sparsity promoting regularizer. Here is considered the case where $ \\Phi(x) = \\inf_{z \\in \\mathbb{R}^m}\u00a0{ ||x-z||_2^2 + h(||z||_2)}$ and $h$ is an even and univariate function on the real line. Connections are drawn between $\\Phi$ and the Moreau envelope of $h$. A new sample complexity result concerning the $k$-sparse dictionary problem removes the spurious condition on the coherence of $D$ appearing in previous works. Finally, comments are made on the approximation error of certain families of losses. The derived generalization bounds are of order $\\mathcal{O}(\\sqrt{\\log n /n})$ and valid without any further restrictions on the set of dictionaries with unit-norm columns.",
        "bibtex": "@InProceedings{pmlr-v80-georgogiannis18a,\n  title = \t {The Generalization Error of Dictionary Learning with Moreau Envelopes},\n  author =       {Georgogiannis, Alexandros},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1617--1625},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/georgogiannis18a/georgogiannis18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/georgogiannis18a.html},\n  abstract = \t {This is a theoretical study on the sample complexity of dictionary learning with a general type of reconstruction loss. The goal is to estimate a $m \\times d$ matrix $D$ of unit-norm columns when the only available information is a set of training samples. Points $x$ in $\\mathbb{R}^m$ are subsequently approximated by the linear combination $Da$ after solving the problem $\\min_{a \\in \\mathbb{R}^d}\u00a0 \\Phi(x - Da) + g(a)$; function $g:\\mathbb{R}^d \\to [0,+\\infty)$ is either an indicator function or a sparsity promoting regularizer. Here is considered the case where $ \\Phi(x) = \\inf_{z \\in \\mathbb{R}^m}\u00a0{ ||x-z||_2^2 + h(||z||_2)}$ and $h$ is an even and univariate function on the real line. Connections are drawn between $\\Phi$ and the Moreau envelope of $h$. A new sample complexity result concerning the $k$-sparse dictionary problem removes the spurious condition on the coherence of $D$ appearing in previous works. Finally, comments are made on the approximation error of certain families of losses. The derived generalization bounds are of order $\\mathcal{O}(\\sqrt{\\log n /n})$ and valid without any further restrictions on the set of dictionaries with unit-norm columns.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/georgogiannis18a/georgogiannis18a.pdf",
        "supp": "",
        "pdf_size": 453548,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15360031764411727443&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Electrical and Computer Engineering, Technical University of Crete, Greece",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/georgogiannis18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Technical University of Crete",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tuc.gr",
        "aff_unique_abbr": "TUC",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Greece"
    },
    {
        "title": "The Hidden Vulnerability of Distributed Learning in Byzantium",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2351",
        "id": "2351",
        "author_site": "El Mahdi El Mhamdi, Rachid Guerraoui, S\u00e9bastien Rouault",
        "author": "El Mahdi El Mhamdi; Rachid Guerraoui; S\u00e9bastien Rouault",
        "abstract": "While machine learning is going through an era of celebrated success, concerns have been raised about the vulnerability of its backbone: stochastic gradient descent (SGD). Recent approaches have been proposed to ensure the robustness of distributed SGD against adversarial (Byzantine) workers sending",
        "bibtex": "@InProceedings{pmlr-v80-mhamdi18a,\n  title = \t {The Hidden Vulnerability of Distributed Learning in {B}yzantium},\n  author =       {El Mhamdi, El Mahdi and Guerraoui, Rachid and Rouault, S{\\'e}bastien},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3521--3530},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mhamdi18a/mhamdi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mhamdi18a.html},\n  abstract = \t {While machine learning is going through an era of celebrated success, concerns have been raised about the vulnerability of its backbone: stochastic gradient descent (SGD). Recent approaches have been proposed to ensure the robustness of distributed SGD against adversarial (Byzantine) workers sending",
        "pdf": "http://proceedings.mlr.press/v80/mhamdi18a/mhamdi18a.pdf",
        "supp": "",
        "pdf_size": 679594,
        "gs_citation": 788,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9088120930752200793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mhamdi18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "The Hierarchical Adaptive Forgetting Variational Filter",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2185",
        "id": "2185",
        "author": "Vincent Moens",
        "abstract": "A common problem in Machine Learning and statistics consists in detecting whether the current sample in a stream of data belongs to the same distribution as previous ones, is an isolated outlier or inaugurates a new distribution of data. We present a hierarchical Bayesian algorithm that aims at learning a time-specific approximate posterior distribution of the parameters describing the distribution of the data observed. We derive the update equations of the variational parameters of the approximate posterior at each time step for models from the exponential family, and show that these updates find interesting correspondents in Reinforcement Learning (RL). In this perspective, our model can be seen as a hierarchical RL algorithm that learns a posterior distribution according to a certain stability confidence that is, in turn, learned according to its own stability confidence. Finally, we show some applications of our generic model, first in a RL context, next with an adaptive Bayesian Autoregressive model, and finally in the context of Stochastic Gradient Descent optimization.",
        "bibtex": "@InProceedings{pmlr-v80-moens18a,\n  title = \t {The Hierarchical Adaptive Forgetting Variational Filter},\n  author =       {Moens, Vincent},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3606--3615},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/moens18a/moens18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/moens18a.html},\n  abstract = \t {A common problem in Machine Learning and statistics consists in detecting whether the current sample in a stream of data belongs to the same distribution as previous ones, is an isolated outlier or inaugurates a new distribution of data. We present a hierarchical Bayesian algorithm that aims at learning a time-specific approximate posterior distribution of the parameters describing the distribution of the data observed. We derive the update equations of the variational parameters of the approximate posterior at each time step for models from the exponential family, and show that these updates find interesting correspondents in Reinforcement Learning (RL). In this perspective, our model can be seen as a hierarchical RL algorithm that learns a posterior distribution according to a certain stability confidence that is, in turn, learned according to its own stability confidence. Finally, we show some applications of our generic model, first in a RL context, next with an adaptive Bayesian Autoregressive model, and finally in the context of Stochastic Gradient Descent optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/moens18a/moens18a.pdf",
        "supp": "",
        "pdf_size": 5793007,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17727338391641271270&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "COSY, Institute of Neuroscience, Universit\u00e9 Catholique de Louvain, Brussels, Belgium",
        "aff_domain": "uclouvain.be",
        "email": "uclouvain.be",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/moens18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "Universit\u00e9 catholique de Louvain",
        "aff_unique_dep": "Institute of Neuroscience",
        "aff_unique_url": "https://www.uclouvain.be",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Brussels",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Belgium"
    },
    {
        "title": "The Limits of Maxing, Ranking, and Preference Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2103",
        "id": "2103",
        "author_site": "Moein Falahatgar, Ayush Jain, Alon Orlitsky, Venkatadheeraj Pichapati, Vaishakh Ravindrakumar",
        "author": "Moein Falahatgar; Ayush Jain; Alon Orlitsky; Venkatadheeraj Pichapati; Vaishakh Ravindrakumar",
        "abstract": "We present a comprehensive understanding of three important problems in PAC preference learning: maximum selection (maxing), ranking, and estimating",
        "bibtex": "@InProceedings{pmlr-v80-falahatgar18a,\n  title = \t {The Limits of Maxing, Ranking, and Preference Learning},\n  author =       {Falahatgar, Moein and Jain, Ayush and Orlitsky, Alon and Pichapati, Venkatadheeraj and Ravindrakumar, Vaishakh},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1427--1436},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/falahatgar18a/falahatgar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/falahatgar18a.html},\n  abstract = \t {We present a comprehensive understanding of three important problems in PAC preference learning: maximum selection (maxing), ranking, and estimating",
        "pdf": "http://proceedings.mlr.press/v80/falahatgar18a/falahatgar18a.pdf",
        "supp": "",
        "pdf_size": 326408,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4050527315663537264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of California, San Diego; University of California, San Diego; University of California, San Diego; University of California, San Diego; University of California, San Diego",
        "aff_domain": "ucsd.edu; ; ; ; ",
        "email": "ucsd.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/falahatgar18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "The Mechanics of n-Player Differentiable Games",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2030",
        "id": "2030",
        "author_site": "David Balduzzi, Sebastien Racaniere, James Martens, Jakob Foerster, Karl Tuyls, Thore Graepel",
        "author": "David Balduzzi; Sebastien Racaniere; James Martens; Jakob Foerster; Karl Tuyls; Thore Graepel",
        "abstract": "The cornerstone underpinning deep learning is the guarantee that gradient descent on an objective converges to local minima. Unfortunately, this guarantee fails in settings, such as generative adversarial nets, where there are multiple interacting losses. The behavior of gradient-based methods in games is not well understood \u2013 and is becoming increasingly important as adversarial and multi-objective architectures proliferate. In this paper, we develop new techniques to understand and control the dynamics in general games. The key result is to decompose the second-order dynamics into two components. The first is related to potential games, which reduce to gradient descent on an implicit function; the second relates to Hamiltonian games, a new class of games that obey a conservation law, akin to conservation laws in classical mechanical systems. The decomposition motivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding stable fixed points in general games. Basic experiments show SGA is competitive with recently proposed algorithms for finding local Nash equilibria in GANs \u2013 whilst at the same time being applicable to \u2013 and having guarantees in \u2013 much more general games.",
        "bibtex": "@InProceedings{pmlr-v80-balduzzi18a,\n  title = \t {The Mechanics of n-Player Differentiable Games},\n  author =       {Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {354--363},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/balduzzi18a/balduzzi18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/balduzzi18a.html},\n  abstract = \t {The cornerstone underpinning deep learning is the guarantee that gradient descent on an objective converges to local minima. Unfortunately, this guarantee fails in settings, such as generative adversarial nets, where there are multiple interacting losses. The behavior of gradient-based methods in games is not well understood \u2013 and is becoming increasingly important as adversarial and multi-objective architectures proliferate. In this paper, we develop new techniques to understand and control the dynamics in general games. The key result is to decompose the second-order dynamics into two components. The first is related to potential games, which reduce to gradient descent on an implicit function; the second relates to Hamiltonian games, a new class of games that obey a conservation law, akin to conservation laws in classical mechanical systems. The decomposition motivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding stable fixed points in general games. Basic experiments show SGA is competitive with recently proposed algorithms for finding local Nash equilibria in GANs \u2013 whilst at the same time being applicable to \u2013 and having guarantees in \u2013 much more general games.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/balduzzi18a/balduzzi18a.pdf",
        "supp": "",
        "pdf_size": 1060087,
        "gs_citation": 346,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11135839031935517451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "DeepMind; DeepMind; DeepMind; University of Oxford; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/balduzzi18a.html",
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "DeepMind;University of Oxford",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://deepmind.com;https://www.ox.ac.uk",
        "aff_unique_abbr": "DeepMind;Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "The Mirage of Action-Dependent Baselines in Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2355",
        "id": "2355",
        "author_site": "George Tucker, Surya Bhupatiraju, Shixiang Gu, Richard E Turner, Zoubin Ghahramani, Sergey Levine",
        "author": "George Tucker; Surya Bhupatiraju; Shixiang Gu; Richard Turner; Zoubin Ghahramani; Sergey Levine",
        "abstract": "Policy gradient methods are a widely used class of model-free reinforcement learning algorithms where a state-dependent baseline is used to reduce gradient estimator variance. Several recent papers extend the baseline to depend on both the state and action and suggest that this significantly reduces variance and improves sample efficiency without introducing bias into the gradient estimates. To better understand this development, we decompose the variance of the policy gradient estimator and numerically show that learned state-action-dependent baselines do not in fact reduce variance over a state-dependent baseline in commonly tested benchmark domains. We confirm this unexpected result by reviewing the open-source code accompanying these prior papers, and show that subtle implementation decisions cause deviations from the methods presented in the papers and explain the source of the previously observed empirical gains. Furthermore, the variance decomposition highlights areas for improvement, which we demonstrate by illustrating a simple change to the typical value function parameterization that can significantly improve performance.",
        "bibtex": "@InProceedings{pmlr-v80-tucker18a,\n  title = \t {The Mirage of Action-Dependent Baselines in Reinforcement Learning},\n  author =       {Tucker, George and Bhupatiraju, Surya and Gu, Shixiang and Turner, Richard and Ghahramani, Zoubin and Levine, Sergey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5015--5024},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tucker18a/tucker18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tucker18a.html},\n  abstract = \t {Policy gradient methods are a widely used class of model-free reinforcement learning algorithms where a state-dependent baseline is used to reduce gradient estimator variance. Several recent papers extend the baseline to depend on both the state and action and suggest that this significantly reduces variance and improves sample efficiency without introducing bias into the gradient estimates. To better understand this development, we decompose the variance of the policy gradient estimator and numerically show that learned state-action-dependent baselines do not in fact reduce variance over a state-dependent baseline in commonly tested benchmark domains. We confirm this unexpected result by reviewing the open-source code accompanying these prior papers, and show that subtle implementation decisions cause deviations from the methods presented in the papers and explain the source of the previously observed empirical gains. Furthermore, the variance decomposition highlights areas for improvement, which we demonstrate by illustrating a simple change to the typical value function parameterization that can significantly improve performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tucker18a/tucker18a.pdf",
        "supp": "",
        "pdf_size": 1513060,
        "gs_citation": 164,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13283949849919416369&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Google Brain, USA; Google Brain, USA + Google AI Residency; Google Brain, USA + University of Cambridge, UK + Max Planck Institute for Intelligent Systems, Germany; University of Cambridge, UK + Uber AI Labs, USA; University of Cambridge, UK + Uber AI Labs, USA; Google Brain, USA + UC Berkeley, USA",
        "aff_domain": "google.com; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/tucker18a.html",
        "aff_unique_index": "0;0+0;0+1+2;1+3;1+3;0+4",
        "aff_unique_norm": "Google;University of Cambridge;Max Planck Institute for Intelligent Systems;Uber;University of California, Berkeley",
        "aff_unique_dep": "Google Brain;;;Uber AI Labs;",
        "aff_unique_url": "https://brain.google.com;https://www.cam.ac.uk;https://www.mpi-is.mpg.de;https://www.uber.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Google Brain;Cambridge;MPI-IS;Uber;UC Berkeley",
        "aff_campus_unique_index": "0;0+0;0+1;1;1;0+3",
        "aff_campus_unique": "Mountain View;Cambridge;;Berkeley",
        "aff_country_unique_index": "0;0+0;0+1+2;1+0;1+0;0+0",
        "aff_country_unique": "United States;United Kingdom;Germany"
    },
    {
        "title": "The Multilinear Structure of ReLU Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2005",
        "id": "2005",
        "author_site": "Thomas Laurent, James von Brecht",
        "author": "Thomas Laurent; James Brecht",
        "abstract": "We study the loss surface of neural networks equipped with a hinge loss criterion and ReLU or leaky ReLU nonlinearities. Any such network defines a piecewise multilinear form in parameter space. By appealing to harmonic analysis we show that all local minima of such network are non-differentiable, except for those minima that occur in a region of parameter space where the loss surface is perfectly flat. Non-differentiable minima are therefore not technicalities or pathologies; they are heart of the problem when investigating the loss of ReLU networks. As a consequence, we must employ techniques from nonsmooth analysis to study these loss surfaces. We show how to apply these techniques in some illustrative cases.",
        "bibtex": "@InProceedings{pmlr-v80-laurent18b,\n  title = \t {The Multilinear Structure of {R}e{LU} Networks},\n  author =       {Laurent, Thomas and von Brecht, James},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2908--2916},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/laurent18b/laurent18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/laurent18b.html},\n  abstract = \t {We study the loss surface of neural networks equipped with a hinge loss criterion and ReLU or leaky ReLU nonlinearities. Any such network defines a piecewise multilinear form in parameter space. By appealing to harmonic analysis we show that all local minima of such network are non-differentiable, except for those minima that occur in a region of parameter space where the loss surface is perfectly flat. Non-differentiable minima are therefore not technicalities or pathologies; they are heart of the problem when investigating the loss of ReLU networks. As a consequence, we must employ techniques from nonsmooth analysis to study these loss surfaces. We show how to apply these techniques in some illustrative cases.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/laurent18b/laurent18b.pdf",
        "supp": "",
        "pdf_size": 593421,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9309445801242373392&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Mathematics, Loyola Marymount University, Los Angeles, CA 90045, USA; Department of Mathematics and Statistics, California State University, Long Beach, Long Beach, CA 90840, USA",
        "aff_domain": "lmu.edu;csulb.edu",
        "email": "lmu.edu;csulb.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/laurent18b.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Loyola Marymount University;California State University, Long Beach",
        "aff_unique_dep": "Department of Mathematics;Department of Mathematics and Statistics",
        "aff_unique_url": "https://www.lmu.edu;https://www.csulb.edu",
        "aff_unique_abbr": "LMU;CSULB",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Los Angeles;Long Beach",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "The Power of Interpolation: Understanding the Effectiveness of SGD in Modern Over-parametrized Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1968",
        "id": "1968",
        "author_site": "Siyuan Ma, Raef Bassily, Mikhail Belkin",
        "author": "Siyuan Ma; Raef Bassily; Mikhail Belkin",
        "abstract": "In this paper we aim to formally explain the phenomenon of fast convergence of Stochastic Gradient Descent (SGD) observed in modern machine learning. The key observation is that most modern learning architectures are over-parametrized and are trained to interpolate the data by driving the empirical loss (classification and regression) close to zero. While it is still unclear why these interpolated solutions perform well on test data, we show that these regimes allow for fast convergence of SGD, comparable in number of iterations to full gradient descent. For convex loss functions we obtain an exponential convergence bound for",
        "bibtex": "@InProceedings{pmlr-v80-ma18a,\n  title = \t {The Power of Interpolation: Understanding the Effectiveness of {SGD} in Modern Over-parametrized Learning},\n  author =       {Ma, Siyuan and Bassily, Raef and Belkin, Mikhail},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3325--3334},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ma18a/ma18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ma18a.html},\n  abstract = \t {In this paper we aim to formally explain the phenomenon of fast convergence of Stochastic Gradient Descent (SGD) observed in modern machine learning. The key observation is that most modern learning architectures are over-parametrized and are trained to interpolate the data by driving the empirical loss (classification and regression) close to zero. While it is still unclear why these interpolated solutions perform well on test data, we show that these regimes allow for fast convergence of SGD, comparable in number of iterations to full gradient descent. For convex loss functions we obtain an exponential convergence bound for",
        "pdf": "http://proceedings.mlr.press/v80/ma18a/ma18a.pdf",
        "supp": "",
        "pdf_size": 600432,
        "gs_citation": 365,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15695389795433810881&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA",
        "aff_domain": "cse.ohio-state.edu;osu.edu;cse.ohio-state.edu",
        "email": "cse.ohio-state.edu;osu.edu;cse.ohio-state.edu",
        "github": "",
        "project": "arxiv.org/abs/1712.06559",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ma18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "The Uncertainty Bellman Equation and Exploration",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1959",
        "id": "1959",
        "author_site": "Brendan O'Donoghue, Ian Osband, Remi Munos, Vlad Mnih",
        "author": "Brendan O\u2019Donoghue; Ian Osband; Remi Munos; Vlad Mnih",
        "abstract": "We consider the exploration/exploitation problem in reinforcement learning. For exploitation, it is well known that the Bellman equation connects the value at any time-step to the expected value at subsequent time-steps. In this paper we consider a similar uncertainty Bellman equation (UBE), which connects the uncertainty at any time-step to the expected uncertainties at subsequent time-steps, thereby extending the potential exploratory benefit of a policy beyond individual time-steps. We prove that the unique fixed point of the UBE yields an upper bound on the variance of the posterior distribution of the Q-values induced by any policy. This bound can be much tighter than traditional count-based bonuses that compound standard deviation rather than variance. Importantly, and unlike several existing approaches to optimism, this method scales naturally to large systems with complex generalization. Substituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN performance on 51 out of 57 games in the Atari suite.",
        "bibtex": "@InProceedings{pmlr-v80-odonoghue18a,\n  title = \t {The Uncertainty {B}ellman Equation and Exploration},\n  author =       {O'Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Vlad},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3839--3848},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/odonoghue18a/odonoghue18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/odonoghue18a.html},\n  abstract = \t {We consider the exploration/exploitation problem in reinforcement learning. For exploitation, it is well known that the Bellman equation connects the value at any time-step to the expected value at subsequent time-steps. In this paper we consider a similar uncertainty Bellman equation (UBE), which connects the uncertainty at any time-step to the expected uncertainties at subsequent time-steps, thereby extending the potential exploratory benefit of a policy beyond individual time-steps. We prove that the unique fixed point of the UBE yields an upper bound on the variance of the posterior distribution of the Q-values induced by any policy. This bound can be much tighter than traditional count-based bonuses that compound standard deviation rather than variance. Importantly, and unlike several existing approaches to optimism, this method scales naturally to large systems with complex generalization. Substituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN performance on 51 out of 57 games in the Atari suite.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/odonoghue18a/odonoghue18a.pdf",
        "supp": "",
        "pdf_size": 656758,
        "gs_citation": 272,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11922304056351938195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "DeepMind; DeepMind; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ",
        "email": "google.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/odonoghue18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "The Weighted Kendall and High-order Kernels for Permutations",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2305",
        "id": "2305",
        "author_site": "Yunlong Jiao, Jean-Philippe Vert",
        "author": "Yunlong Jiao; Jean-Philippe Vert",
        "abstract": "We propose new positive definite kernels for permutations. First we introduce a weighted version of the Kendall kernel, which allows to weight unequally the contributions of different item pairs in the permutations depending on their ranks. Like the Kendall kernel, we show that the weighted version is invariant to relabeling of items and can be computed efficiently in O(n ln(n)) operations, where n is the number of items in the permutation. Second, we propose a supervised approach to learn the weights by jointly optimizing them with the function estimated by a kernel machine. Third, while the Kendall kernel considers pairwise comparison between items, we extend it by considering higher-order comparisons among tuples of items and show that the supervised approach of learning the weights can be systematically generalized to higher-order permutation kernels.",
        "bibtex": "@InProceedings{pmlr-v80-jiao18a,\n  title = \t {The Weighted {K}endall and High-order Kernels for Permutations},\n  author =       {Jiao, Yunlong and Vert, Jean-Philippe},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2314--2322},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jiao18a/jiao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jiao18a.html},\n  abstract = \t {We propose new positive definite kernels for permutations. First we introduce a weighted version of the Kendall kernel, which allows to weight unequally the contributions of different item pairs in the permutations depending on their ranks. Like the Kendall kernel, we show that the weighted version is invariant to relabeling of items and can be computed efficiently in O(n ln(n)) operations, where n is the number of items in the permutation. Second, we propose a supervised approach to learn the weights by jointly optimizing them with the function estimated by a kernel machine. Third, while the Kendall kernel considers pairwise comparison between items, we extend it by considering higher-order comparisons among tuples of items and show that the supervised approach of learning the weights can be systematically generalized to higher-order permutation kernels.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jiao18a/jiao18a.pdf",
        "supp": "",
        "pdf_size": 306911,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12479886135051163263&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "University of Oxford, Oxford, UK; MINES ParisTech & Institut Curie & Ecole Normale Sup\u00e9rieure, PSL Research University, Paris, France",
        "aff_domain": "oxford.ac.uk;mines-paristech.fr",
        "email": "oxford.ac.uk;mines-paristech.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/jiao18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Oxford;MINES ParisTech",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.mines-paristech.fr",
        "aff_unique_abbr": "Oxford;MPT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Oxford;Paris",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Kingdom;France"
    },
    {
        "title": "The Well-Tempered Lasso",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2401",
        "id": "2401",
        "author_site": "Yuanzhi Li, Yoram Singer",
        "author": "Yuanzhi Li; Yoram Singer",
        "abstract": "We study the complexity of the entire regularization path for least squares regression with 1-norm penalty, known as the Lasso. Every regression parameter in the Lasso changes linearly as a function of the regularization value. The number of changes is regarded as the Lasso\u2019s complexity. Experimental results using exact path following exhibit polynomial complexity of the Lasso in the problem size. Alas, the path complexity of the Lasso on artificially designed regression problems is exponential We use smoothed analysis as a mechanism for bridging the gap between worst case settings and the de facto low complexity. Our analysis assumes that the observed data has a tiny amount of intrinsic noise. We then prove that the Lasso\u2019s complexity is polynomial in the problem size.",
        "bibtex": "@InProceedings{pmlr-v80-li18f,\n  title = \t {The Well-Tempered Lasso},\n  author =       {Li, Yuanzhi and Singer, Yoram},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3024--3032},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18f/li18f.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18f.html},\n  abstract = \t {We study the complexity of the entire regularization path for least squares regression with 1-norm penalty, known as the Lasso. Every regression parameter in the Lasso changes linearly as a function of the regularization value. The number of changes is regarded as the Lasso\u2019s complexity. Experimental results using exact path following exhibit polynomial complexity of the Lasso in the problem size. Alas, the path complexity of the Lasso on artificially designed regression problems is exponential We use smoothed analysis as a mechanism for bridging the gap between worst case settings and the de facto low complexity. Our analysis assumes that the observed data has a tiny amount of intrinsic noise. We then prove that the Lasso\u2019s complexity is polynomial in the problem size.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18f/li18f.pdf",
        "supp": "",
        "pdf_size": 343985,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3051960435601381414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Princeton University; Googol Brain",
        "aff_domain": "cs.princeton.edu; ",
        "email": "cs.princeton.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/li18f.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Princeton University;Google",
        "aff_unique_dep": "Department of Computer Science;Google Brain",
        "aff_unique_url": "https://www.princeton.edu;https://brain.google.com",
        "aff_unique_abbr": "Princeton;Google Brain",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Theoretical Analysis of Image-to-Image Translation with Adversarial Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1892",
        "id": "1892",
        "author_site": "Xudong Pan, Mi Zhang, Daizong Ding",
        "author": "Xudong Pan; Mi Zhang; Daizong Ding",
        "abstract": "Recently, a unified model for image-to-image translation tasks within adversarial learning framework has aroused widespread research interests in computer vision practitioners. Their reported empirical success however lacks solid theoretical interpretations for its inherent mechanism. In this paper, we reformulate their model from a brand-new geometrical perspective and have eventually reached a full interpretation on some interesting but unclear empirical phenomenons from their experiments. Furthermore, by extending the definition of generalization for generative adversarial nets to a broader sense, we have derived a condition to control the generalization capability of their model. According to our derived condition, several practical suggestions have also been proposed on model design and dataset construction as a guidance for further empirical researches.",
        "bibtex": "@InProceedings{pmlr-v80-pan18c,\n  title = \t {Theoretical Analysis of Image-to-Image Translation with Adversarial Learning},\n  author =       {Pan, Xudong and Zhang, Mi and Ding, Daizong},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4006--4015},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pan18c/pan18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pan18c.html},\n  abstract = \t {Recently, a unified model for image-to-image translation tasks within adversarial learning framework has aroused widespread research interests in computer vision practitioners. Their reported empirical success however lacks solid theoretical interpretations for its inherent mechanism. In this paper, we reformulate their model from a brand-new geometrical perspective and have eventually reached a full interpretation on some interesting but unclear empirical phenomenons from their experiments. Furthermore, by extending the definition of generalization for generative adversarial nets to a broader sense, we have derived a condition to control the generalization capability of their model. According to our derived condition, several practical suggestions have also been proposed on model design and dataset construction as a guidance for further empirical researches.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pan18c/pan18c.pdf",
        "supp": "",
        "pdf_size": 281414,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16613567985587797194&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, China",
        "aff_domain": "fudan.edu.cn; ; ",
        "email": "fudan.edu.cn; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/pan18c.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Fudan University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.fudan.edu.cn",
        "aff_unique_abbr": "Fudan",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Theoretical Analysis of Sparse Subspace Clustering with Missing Entries",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1928",
        "id": "1928",
        "author_site": "Manolis Tsakiris, Rene Vidal",
        "author": "Manolis Tsakiris; Rene Vidal",
        "abstract": "Sparse Subspace Clustering (SSC) is a popular unsupervised machine learning method for clustering data lying close to an unknown union of low-dimensional linear subspaces; a problem with numerous applications in pattern recognition and computer vision. Even though the behavior of SSC for complete data is by now well-understood, little is known about its theoretical properties when applied to data with missing entries. In this paper we give theoretical guarantees for SSC with incomplete data, and provide theoretical evidence that projecting the zero-filled data onto the observation pattern of the point being expressed can lead to substantial improvement in performance; a phenomenon already known experimentally. The main insight of our analysis is that even though this projection induces additional missing entries, this is counterbalanced by the fact that the projected and zero-filled data are in effect incomplete points associated with the union of the corresponding projected subspaces, with respect to which the point being expressed is complete. The significance of this phenomenon potentially extends to the entire class of self-expressive methods.",
        "bibtex": "@InProceedings{pmlr-v80-tsakiris18a,\n  title = \t {Theoretical Analysis of Sparse Subspace Clustering with Missing Entries},\n  author =       {Tsakiris, Manolis and Vidal, Rene},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4975--4984},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/tsakiris18a/tsakiris18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/tsakiris18a.html},\n  abstract = \t {Sparse Subspace Clustering (SSC) is a popular unsupervised machine learning method for clustering data lying close to an unknown union of low-dimensional linear subspaces; a problem with numerous applications in pattern recognition and computer vision. Even though the behavior of SSC for complete data is by now well-understood, little is known about its theoretical properties when applied to data with missing entries. In this paper we give theoretical guarantees for SSC with incomplete data, and provide theoretical evidence that projecting the zero-filled data onto the observation pattern of the point being expressed can lead to substantial improvement in performance; a phenomenon already known experimentally. The main insight of our analysis is that even though this projection induces additional missing entries, this is counterbalanced by the fact that the projected and zero-filled data are in effect incomplete points associated with the union of the corresponding projected subspaces, with respect to which the point being expressed is complete. The significance of this phenomenon potentially extends to the entire class of self-expressive methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/tsakiris18a/tsakiris18a.pdf",
        "supp": "",
        "pdf_size": 353284,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1443752514982503970&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Mathematical Institute for Data Science and Department of Biomedical Engineering, Johns Hopkins University, Baltimore, USA",
        "aff_domain": "shanghaitech.edu.cn; ",
        "email": "shanghaitech.edu.cn; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/tsakiris18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "ShanghaiTech University;Johns Hopkins University",
        "aff_unique_dep": "School of Information Science and Technology;Mathematical Institute for Data Science",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;https://www.jhu.edu",
        "aff_unique_abbr": "ShanghaiTech;JHU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Shanghai;Baltimore",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Thompson Sampling for Combinatorial Semi-Bandits",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2120",
        "id": "2120",
        "author_site": "Siwei Wang, Wei Chen",
        "author": "Siwei Wang; Wei Chen",
        "abstract": "We study the application of the Thompson sampling (TS) methodology to the stochastic combinatorial multi-armed bandit (CMAB) framework. We analyze the standard TS algorithm for the general CMAB, and obtain the first distribution-dependent regret bound of $O(m\\log T / \\Delta_{\\min}) $ for TS under general CMAB, where $m$ is the number of arms, $T$ is the time horizon, and $\\Delta_{\\min}$ is the minimum gap between the expected reward of the optimal solution and any non-optimal solution. We also show that one cannot use an approximate oracle in TS algorithm for even MAB problems. Then we expand the analysis to matroid bandit, a special case of CMAB and for which we could remove the independence assumption across arms and achieve a better regret bound. Finally, we use some experiments to show the comparison of regrets of CUCB and CTS algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-wang18a,\n  title = \t {Thompson Sampling for Combinatorial Semi-Bandits},\n  author =       {Wang, Siwei and Chen, Wei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5114--5122},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wang18a/wang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wang18a.html},\n  abstract = \t {We study the application of the Thompson sampling (TS) methodology to the stochastic combinatorial multi-armed bandit (CMAB) framework. We analyze the standard TS algorithm for the general CMAB, and obtain the first distribution-dependent regret bound of $O(m\\log T / \\Delta_{\\min}) $ for TS under general CMAB, where $m$ is the number of arms, $T$ is the time horizon, and $\\Delta_{\\min}$ is the minimum gap between the expected reward of the optimal solution and any non-optimal solution. We also show that one cannot use an approximate oracle in TS algorithm for even MAB problems. Then we expand the analysis to matroid bandit, a special case of CMAB and for which we could remove the independence assumption across arms and achieve a better regret bound. Finally, we use some experiments to show the comparison of regrets of CUCB and CTS algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wang18a/wang18a.pdf",
        "supp": "",
        "pdf_size": 383949,
        "gs_citation": 164,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2807255525078102712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Tsinghua University, Beijing, China; Microsoft Research, Beijing, China",
        "aff_domain": "mails.tsinghua.edu.cn;microsoft.com",
        "email": "mails.tsinghua.edu.cn;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/wang18a.html",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Tsinghua University;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.microsoft.com/en-us/research/group/microsoft-research-asia",
        "aff_unique_abbr": "THU;MSR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Tight Regret Bounds for Bayesian Optimization in One Dimension",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1945",
        "id": "1945",
        "author": "Jonathan Scarlett",
        "abstract": "We consider the problem of Bayesian optimization (BO) in one dimension, under a Gaussian process prior and Gaussian sampling noise. We provide a theoretical analysis showing that, under fairly mild technical assumptions on the kernel, the best possible cumulative regret up to time $T$ behaves as $\\Omega(\\sqrt{T})$ and $O(\\sqrt{T\\log T})$. This gives a tight characterization up to a $\\sqrt{\\log T}$ factor, and includes the first non-trivial lower bound for noisy BO. Our assumptions are satisfied, for example, by the squared exponential and Mat\u00e9rn-$\\nu$ kernels, with the latter requiring $\\nu > 2$. Our results certify the near-optimality of existing bounds (Srinivas",
        "bibtex": "@InProceedings{pmlr-v80-scarlett18a,\n  title = \t {Tight Regret Bounds for {B}ayesian Optimization in One Dimension},\n  author =       {Scarlett, Jonathan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4500--4508},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/scarlett18a/scarlett18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/scarlett18a.html},\n  abstract = \t {We consider the problem of Bayesian optimization (BO) in one dimension, under a Gaussian process prior and Gaussian sampling noise. We provide a theoretical analysis showing that, under fairly mild technical assumptions on the kernel, the best possible cumulative regret up to time $T$ behaves as $\\Omega(\\sqrt{T})$ and $O(\\sqrt{T\\log T})$. This gives a tight characterization up to a $\\sqrt{\\log T}$ factor, and includes the first non-trivial lower bound for noisy BO. Our assumptions are satisfied, for example, by the squared exponential and Mat\u00e9rn-$\\nu$ kernels, with the latter requiring $\\nu > 2$. Our results certify the near-optimality of existing bounds (Srinivas",
        "pdf": "http://proceedings.mlr.press/v80/scarlett18a/scarlett18a.pdf",
        "supp": "",
        "pdf_size": 641151,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14746132759143410767&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science & Department of Mathematics, National University of Singapore",
        "aff_domain": "comp.nus.edu.sg",
        "email": "comp.nus.edu.sg",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/scarlett18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Singapore"
    },
    {
        "title": "Tighter Variational Bounds are Not Necessarily Better",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2399",
        "id": "2399",
        "author_site": "Tom Rainforth, Adam Kosiorek, Tuan Anh Le, Chris Maddison, Maximilian Igl, Frank Wood, Yee-Whye Teh",
        "author": "Tom Rainforth; Adam Kosiorek; Tuan Anh Le; Chris Maddison; Maximilian Igl; Frank Wood; Yee Whye Teh",
        "abstract": "We provide theoretical and empirical evidence that using tighter evidence lower bounds (ELBOs) can be detrimental to the process of learning an inference network by reducing the signal-to-noise ratio of the gradient estimator. Our results call into question common implicit assumptions that tighter ELBOs are better variational objectives for simultaneous model learning and inference amortization schemes. Based on our insights, we introduce three new algorithms: the partially importance weighted auto-encoder (PIWAE), the multiply importance weighted auto-encoder (MIWAE), and the combination importance weighted autoencoder (CIWAE), each of which includes the standard importance weighted auto-encoder (IWAE) as a special case. We show that each can deliver improvements over IWAE, even when performance is measured by the IWAE target itself. Furthermore, our results suggest that PIWAE may be able to deliver simultaneous improvements in the training of both the inference and generative networks.",
        "bibtex": "@InProceedings{pmlr-v80-rainforth18b,\n  title = \t {Tighter Variational Bounds are Not Necessarily Better},\n  author =       {Rainforth, Tom and Kosiorek, Adam and Le, Tuan Anh and Maddison, Chris and Igl, Maximilian and Wood, Frank and Teh, Yee Whye},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4277--4285},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/rainforth18b/rainforth18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/rainforth18b.html},\n  abstract = \t {We provide theoretical and empirical evidence that using tighter evidence lower bounds (ELBOs) can be detrimental to the process of learning an inference network by reducing the signal-to-noise ratio of the gradient estimator. Our results call into question common implicit assumptions that tighter ELBOs are better variational objectives for simultaneous model learning and inference amortization schemes. Based on our insights, we introduce three new algorithms: the partially importance weighted auto-encoder (PIWAE), the multiply importance weighted auto-encoder (MIWAE), and the combination importance weighted autoencoder (CIWAE), each of which includes the standard importance weighted auto-encoder (IWAE) as a special case. We show that each can deliver improvements over IWAE, even when performance is measured by the IWAE target itself. Furthermore, our results suggest that PIWAE may be able to deliver simultaneous improvements in the training of both the inference and generative networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/rainforth18b/rainforth18b.pdf",
        "supp": "",
        "pdf_size": 1080833,
        "gs_citation": 246,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5343656703698198208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Department of Statistics, University of Oxford; Department of Engineering, University of Oxford+Department of Computer Science, University of Oxford; Department of Engineering, University of Oxford; Department of Statistics, University of Oxford; Department of Engineering, University of Oxford; Department of Computer Science, University of British Columbia; Department of Statistics, University of Oxford",
        "aff_domain": "stats.ox.ac.uk; ; ; ; ; ; ",
        "email": "stats.ox.ac.uk; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/rainforth18b.html",
        "aff_unique_index": "0;0;0;2;0",
        "aff_unique_norm": "University of Oxford;;University of British Columbia",
        "aff_unique_dep": "Department of Statistics;;Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk;;https://www.ubc.ca",
        "aff_unique_abbr": "Oxford;;UBC",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Oxford;;Vancouver",
        "aff_country_unique_index": "0;0;0;2;0",
        "aff_country_unique": "United Kingdom;;Canada"
    },
    {
        "title": "Time Limits in Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2463",
        "id": "2463",
        "author_site": "Fabio Pardo, Arash Tavakoli, Vitaly Levdik, Petar Kormushev",
        "author": "Fabio Pardo; Arash Tavakoli; Vitaly Levdik; Petar Kormushev",
        "abstract": "In reinforcement learning, it is common to let an agent interact for a fixed amount of time with its environment before resetting it and repeating the process in a series of episodes. The task that the agent has to learn can either be to maximize its performance over (i) that fixed period, or (ii) an indefinite period where time limits are only used during training to diversify experience. In this paper, we provide a formal account for how time limits could effectively be handled in each of the two cases and explain why not doing so can cause state-aliasing and invalidation of experience replay, leading to suboptimal policies and training instability. In case (i), we argue that the terminations due to time limits are in fact part of the environment, and thus a notion of the remaining time should be included as part of the agent\u2019s input to avoid violation of the Markov property. In case (ii), the time limits are not part of the environment and are only used to facilitate learning. We argue that this insight should be incorporated by bootstrapping from the value of the state at the end of each partial episode. For both cases, we illustrate empirically the significance of our considerations in improving the performance and stability of existing reinforcement learning algorithms, showing state-of-the-art results on several control tasks.",
        "bibtex": "@InProceedings{pmlr-v80-pardo18a,\n  title = \t {Time Limits in Reinforcement Learning},\n  author =       {Pardo, Fabio and Tavakoli, Arash and Levdik, Vitaly and Kormushev, Petar},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4045--4054},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/pardo18a/pardo18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/pardo18a.html},\n  abstract = \t {In reinforcement learning, it is common to let an agent interact for a fixed amount of time with its environment before resetting it and repeating the process in a series of episodes. The task that the agent has to learn can either be to maximize its performance over (i) that fixed period, or (ii) an indefinite period where time limits are only used during training to diversify experience. In this paper, we provide a formal account for how time limits could effectively be handled in each of the two cases and explain why not doing so can cause state-aliasing and invalidation of experience replay, leading to suboptimal policies and training instability. In case (i), we argue that the terminations due to time limits are in fact part of the environment, and thus a notion of the remaining time should be included as part of the agent\u2019s input to avoid violation of the Markov property. In case (ii), the time limits are not part of the environment and are only used to facilitate learning. We argue that this insight should be incorporated by bootstrapping from the value of the state at the end of each partial episode. For both cases, we illustrate empirically the significance of our considerations in improving the performance and stability of existing reinforcement learning algorithms, showing state-of-the-art results on several control tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/pardo18a/pardo18a.pdf",
        "supp": "",
        "pdf_size": 1197963,
        "gs_citation": 213,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1049564009410089349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Robot Intelligence Lab, Imperial College London, UK; Robot Intelligence Lab, Imperial College London, UK; Robot Intelligence Lab, Imperial College London, UK; Robot Intelligence Lab, Imperial College London, UK",
        "aff_domain": "imperial.ac.uk;imperial.ac.uk;imperial.ac.uk;imperial.ac.uk",
        "email": "imperial.ac.uk;imperial.ac.uk;imperial.ac.uk;imperial.ac.uk",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/pardo18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Robot Intelligence Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "To Understand Deep Learning We Need to Understand Kernel Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2026",
        "id": "2026",
        "author_site": "Mikhail Belkin, Siyuan Ma, Soumik Mandal",
        "author": "Mikhail Belkin; Siyuan Ma; Soumik Mandal",
        "abstract": "Generalization performance of classifiers in deep learning has recently become a subject of intense study. Deep models, which are typically heavily over-parametrized, tend to fit the training data exactly. Despite this \u201coverfitting\", they perform well on test data, a phenomenon not yet fully understood. The first point of our paper is that strong performance of overfitted classifiers is not a unique feature of deep learning. Using six real-world and two synthetic datasets, we establish experimentally that kernel machines trained to have zero classification error or near zero regression error (interpolation) perform very well on test data. We proceed to give a lower bound on the norm of zero loss solutions for smooth kernels, showing that they increase nearly exponentially with data size. None of the existing bounds produce non-trivial results for interpolating solutions. We also show experimentally that (non-smooth) Laplacian kernels easily fit random labels, a finding that parallels results recently reported for ReLU neural networks. In contrast, fitting noisy data requires many more epochs for smooth Gaussian kernels. Similar performance of overfitted Laplacian and Gaussian classifiers on test, suggests that generalization is tied to the properties of the kernel function rather than the optimization process. Some key phenomena of deep learning are manifested similarly in kernel methods in the modern \u201coverfitted\" regime. The combination of the experimental and theoretical results presented in this paper indicates a need for new theoretical ideas for understanding properties of classical kernel methods. We argue that progress on understanding deep learning will be difficult until more tractable \u201cshallow\u201d kernel methods are better understood.",
        "bibtex": "@InProceedings{pmlr-v80-belkin18a,\n  title = \t {To Understand Deep Learning We Need to Understand Kernel Learning},\n  author =       {Belkin, Mikhail and Ma, Siyuan and Mandal, Soumik},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {541--549},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/belkin18a/belkin18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/belkin18a.html},\n  abstract = \t {Generalization performance of classifiers in deep learning has recently become a subject of intense study. Deep models, which are typically heavily over-parametrized, tend to fit the training data exactly. Despite this \u201coverfitting\", they perform well on test data, a phenomenon not yet fully understood. The first point of our paper is that strong performance of overfitted classifiers is not a unique feature of deep learning. Using six real-world and two synthetic datasets, we establish experimentally that kernel machines trained to have zero classification error or near zero regression error (interpolation) perform very well on test data. We proceed to give a lower bound on the norm of zero loss solutions for smooth kernels, showing that they increase nearly exponentially with data size. None of the existing bounds produce non-trivial results for interpolating solutions. We also show experimentally that (non-smooth) Laplacian kernels easily fit random labels, a finding that parallels results recently reported for ReLU neural networks. In contrast, fitting noisy data requires many more epochs for smooth Gaussian kernels. Similar performance of overfitted Laplacian and Gaussian classifiers on test, suggests that generalization is tied to the properties of the kernel function rather than the optimization process. Some key phenomena of deep learning are manifested similarly in kernel methods in the modern \u201coverfitted\" regime. The combination of the experimental and theoretical results presented in this paper indicates a need for new theoretical ideas for understanding properties of classical kernel methods. We argue that progress on understanding deep learning will be difficult until more tractable \u201cshallow\u201d kernel methods are better understood.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/belkin18a/belkin18a.pdf",
        "supp": "",
        "pdf_size": 996865,
        "gs_citation": 539,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5478880319822694911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio, USA",
        "aff_domain": "cse.ohio-state.edu;cse.ohio-state.edu;buckeyemail.osu.edu",
        "email": "cse.ohio-state.edu;cse.ohio-state.edu;buckeyemail.osu.edu",
        "github": "",
        "project": "arxiv.org/abs/1802.01396",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/belkin18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ohio State University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.osu.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Topological mixture estimation",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1873",
        "id": "1873",
        "author": "Steve Huntsman",
        "abstract": "We introduce topological mixture estimation, a completely nonparametric and computationally efficient solution to the problem of estimating a one-dimensional mixture with generic unimodal components. We repeatedly perturb the unimodal decomposition of Baryshnikov and Ghrist to produce a topologically and information-theoretically optimal unimodal mixture. We also detail a smoothing process that optimally exploits topological persistence of the unimodal category in a natural way when working directly with sample data. Finally, we illustrate these techniques through examples.",
        "bibtex": "@InProceedings{pmlr-v80-huntsman18a,\n  title = \t {Topological mixture estimation},\n  author =       {Huntsman, Steve},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2088--2097},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/huntsman18a/huntsman18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/huntsman18a.html},\n  abstract = \t {We introduce topological mixture estimation, a completely nonparametric and computationally efficient solution to the problem of estimating a one-dimensional mixture with generic unimodal components. We repeatedly perturb the unimodal decomposition of Baryshnikov and Ghrist to produce a topologically and information-theoretically optimal unimodal mixture. We also detail a smoothing process that optimally exploits topological persistence of the unimodal category in a natural way when working directly with sample data. Finally, we illustrate these techniques through examples.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/huntsman18a/huntsman18a.pdf",
        "supp": "",
        "pdf_size": 1533081,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5144775238736361207&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "BAE Systems FAST Labs, Arlington, VA, USA",
        "aff_domain": "baesystems.com",
        "email": "baesystems.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/huntsman18a.html",
        "aff_unique_index": "0",
        "aff_unique_norm": "BAE Systems",
        "aff_unique_dep": "FAST Labs",
        "aff_unique_url": "https://www.baesystems.com/en-us",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Arlington",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Towards Binary-Valued Gates for Robust LSTM Training",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1916",
        "id": "1916",
        "author_site": "Zhuohan Li, Di He, Fei Tian, Wei Chen, Tao Qin, Liwei Wang, Tie-Yan Liu",
        "author": "Zhuohan Li; Di He; Fei Tian; Wei Chen; Tao Qin; Liwei Wang; Tieyan Liu",
        "abstract": "Long Short-Term Memory (LSTM) is one of the most widely used recurrent structures in sequence modeling. It aims to use gates to control information flow (e.g., whether to skip some information or not) in the recurrent computations, although its practical implementation based on soft gates only partially achieves this goal. In this paper, we propose a new way for LSTM training, which pushes the output values of the gates towards 0 or 1. By doing so, we can better control the information flow: the gates are mostly open or closed, instead of in a middle state, which makes the results more interpretable. Empirical studies show that (1) Although it seems that we restrict the model capacity, there is no performance drop: we achieve better or comparable performances due to its better generalization ability; (2) The outputs of gates are not sensitive to their inputs: we can easily compress the LSTM unit in multiple ways, e.g., low-rank approximation and low-precision approximation. The compressed models are even better than the baseline models without compression.",
        "bibtex": "@InProceedings{pmlr-v80-li18c,\n  title = \t {Towards Binary-Valued Gates for Robust {LSTM} Training},\n  author =       {Li, Zhuohan and He, Di and Tian, Fei and Chen, Wei and Qin, Tao and Wang, Liwei and Liu, Tieyan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2995--3004},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/li18c/li18c.pdf},\n  url = \t {https://proceedings.mlr.press/v80/li18c.html},\n  abstract = \t {Long Short-Term Memory (LSTM) is one of the most widely used recurrent structures in sequence modeling. It aims to use gates to control information flow (e.g., whether to skip some information or not) in the recurrent computations, although its practical implementation based on soft gates only partially achieves this goal. In this paper, we propose a new way for LSTM training, which pushes the output values of the gates towards 0 or 1. By doing so, we can better control the information flow: the gates are mostly open or closed, instead of in a middle state, which makes the results more interpretable. Empirical studies show that (1) Although it seems that we restrict the model capacity, there is no performance drop: we achieve better or comparable performances due to its better generalization ability; (2) The outputs of gates are not sensitive to their inputs: we can easily compress the LSTM unit in multiple ways, e.g., low-rank approximation and low-precision approximation. The compressed models are even better than the baseline models without compression.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/li18c/li18c.pdf",
        "supp": "",
        "pdf_size": 2009004,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9655995199891931380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Key Laboratory of Machine Perception, MOE, School of EECS, Peking University; Key Laboratory of Machine Perception, MOE, School of EECS, Peking University; Microsoft Research; Microsoft Research; Microsoft Research; Key Laboratory of Machine Perception, MOE, School of EECS, Peking University + Center for Data Science, Peking University, Beijing Institute of Big Data Research; Microsoft Research",
        "aff_domain": "pku.edu.cn;pku.edu.cn;microsoft.com;microsoft.com;microsoft.com;pku.edu.cn;microsoft.com",
        "email": "pku.edu.cn;pku.edu.cn;microsoft.com;microsoft.com;microsoft.com;pku.edu.cn;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/li18c.html",
        "aff_unique_index": "0;0;1;1;1;0+0;1",
        "aff_unique_norm": "Peking University;Microsoft",
        "aff_unique_dep": "School of EECS;Microsoft Research",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Peking U;MSR",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;0;1;1;1;0+0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Towards Black-box Iterative Machine Teaching",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2398",
        "id": "2398",
        "author_site": "Weiyang Liu, Bo Dai, Xingguo Li, Zhen Liu, James Rehg, Le Song",
        "author": "Weiyang Liu; Bo Dai; Xingguo Li; Zhen Liu; James Rehg; Le Song",
        "abstract": "In this paper, we make an important step towards the black-box machine teaching by considering the cross-space machine teaching, where the teacher and the learner use different feature representations and the teacher can not fully observe the learner\u2019s model. In such scenario, we study how the teacher is still able to teach the learner to achieve faster convergence rate than the traditional passive learning. We propose an active teacher model that can actively query the learner (i.e., make the learner take exams) for estimating the learner\u2019s status and provably guide the learner to achieve faster convergence. The sample complexities for both teaching and query are provided. In the experiments, we compare the proposed active teacher with the omniscient teacher and verify the effectiveness of the active teacher model.",
        "bibtex": "@InProceedings{pmlr-v80-liu18b,\n  title = \t {Towards Black-box Iterative Machine Teaching},\n  author =       {Liu, Weiyang and Dai, Bo and Li, Xingguo and Liu, Zhen and Rehg, James and Song, Le},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3141--3149},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liu18b/liu18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liu18b.html},\n  abstract = \t {In this paper, we make an important step towards the black-box machine teaching by considering the cross-space machine teaching, where the teacher and the learner use different feature representations and the teacher can not fully observe the learner\u2019s model. In such scenario, we study how the teacher is still able to teach the learner to achieve faster convergence rate than the traditional passive learning. We propose an active teacher model that can actively query the learner (i.e., make the learner take exams) for estimating the learner\u2019s status and provably guide the learner to achieve faster convergence. The sample complexities for both teaching and query are provided. In the experiments, we compare the proposed active teacher with the omniscient teacher and verify the effectiveness of the active teacher model.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liu18b/liu18b.pdf",
        "supp": "",
        "pdf_size": 4699108,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18248265384421877656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Georgia Tech; Georgia Tech; University of Minnesota; Georgia Tech; Georgia Tech; Georgia Tech + Ant Financial",
        "aff_domain": "gatech.edu; ; ; ; ; ",
        "email": "gatech.edu; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "oa": "https://proceedings.mlr.press/v80/liu18b.html",
        "aff_unique_index": "0;0;1;0;0;0+2",
        "aff_unique_norm": "Georgia Institute of Technology;University of Minnesota;Ant Financial",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.gatech.edu;https://www.minnesota.edu;https://www.antgroup.com",
        "aff_unique_abbr": "Georgia Tech;UMN;Ant Financial",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0+1",
        "aff_country_unique": "United States;China"
    },
    {
        "title": "Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2281",
        "id": "2281",
        "author_site": "RJ Skerry-Ryan, Eric Battenberg, Ying Xiao, Yuxuan Wang, Daisy Stanton, Joel Shor, Ron Weiss, Robert Clark, Rif Saurous",
        "author": "RJ Skerry-Ryan; Eric Battenberg; Ying Xiao; Yuxuan Wang; Daisy Stanton; Joel Shor; Ron Weiss; Rob Clark; Rif A. Saurous",
        "abstract": "We present an extension to the Tacotron speech synthesis architecture that learns a latent embedding space of prosody, derived from a reference acoustic representation containing the desired prosody. We show that conditioning Tacotron on this learned embedding space results in synthesized audio that matches the prosody of the reference signal with fine time detail even when the reference and synthesis speakers are different. Additionally, we show that a reference prosody embedding can be used to synthesize text that is different from that of the reference utterance. We define several quantitative and subjective metrics for evaluating prosody transfer, and report results with accompanying audio samples from single-speaker and 44-speaker Tacotron models on a prosody transfer task.",
        "bibtex": "@InProceedings{pmlr-v80-skerry-ryan18a,\n  title = \t {Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron},\n  author =       {Skerry-Ryan, RJ and Battenberg, Eric and Xiao, Ying and Wang, Yuxuan and Stanton, Daisy and Shor, Joel and Weiss, Ron and Clark, Rob and Saurous, Rif A.},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4693--4702},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/skerry-ryan18a/skerry-ryan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/skerry-ryan18a.html},\n  abstract = \t {We present an extension to the Tacotron speech synthesis architecture that learns a latent embedding space of prosody, derived from a reference acoustic representation containing the desired prosody. We show that conditioning Tacotron on this learned embedding space results in synthesized audio that matches the prosody of the reference signal with fine time detail even when the reference and synthesis speakers are different. Additionally, we show that a reference prosody embedding can be used to synthesize text that is different from that of the reference utterance. We define several quantitative and subjective metrics for evaluating prosody transfer, and report results with accompanying audio samples from single-speaker and 44-speaker Tacotron models on a prosody transfer task.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/skerry-ryan18a/skerry-ryan18a.pdf",
        "supp": "",
        "pdf_size": 631787,
        "gs_citation": 749,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4265456351319268572&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.; Google, Inc.",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/skerry-ryan18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Towards Fast Computation of Certified Robustness for ReLU Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2052",
        "id": "2052",
        "author_site": "Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning, Inderjit Dhillon",
        "author": "Lily Weng; Huan Zhang; Hongge Chen; Zhao Song; Cho-Jui Hsieh; Luca Daniel; Duane Boning; Inderjit Dhillon",
        "abstract": "Verifying the robustness property of a general Rectified Linear Unit (ReLU) network is an NP-complete problem. Although finding the exact minimum adversarial distortion is hard, giving a certified lower bound of the minimum distortion is possible. Current available methods of computing such a bound are either time-consuming or deliver low quality bounds that are too loose to be useful. In this paper, we exploit the special structure of ReLU networks and provide two computationally efficient algorithms (Fast-Lin, Fast-Lip) that are able to certify non-trivial lower bounds of minimum adversarial distortions. Experiments show that (1) our methods deliver bounds close to (the gap is 2-3X) exact minimum distortions found by Reluplex in small networks while our algorithms are more than 10,000 times faster; (2) our methods deliver similar quality of bounds (the gap is within 35% and usually around 10%; sometimes our bounds are even better) for larger networks compared to the methods based on solving linear programming problems but our algorithms are 33-14,000 times faster; (3) our method is capable of solving large MNIST and CIFAR networks up to 7 layers with more than 10,000 neurons within tens of seconds on a single CPU core. In addition, we show that there is no polynomial time algorithm that can approximately find the minimum $\\ell_1$ adversarial distortion of a ReLU network with a $0.99\\ln n$ approximation ratio unless NP=P, where $n$ is the number of neurons in the network.",
        "bibtex": "@InProceedings{pmlr-v80-weng18a,\n  title = \t {Towards Fast Computation of Certified Robustness for {R}e{LU} Networks},\n  author =       {Weng, Lily and Zhang, Huan and Chen, Hongge and Song, Zhao and Hsieh, Cho-Jui and Daniel, Luca and Boning, Duane and Dhillon, Inderjit},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5276--5285},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/weng18a/weng18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/weng18a.html},\n  abstract = \t {Verifying the robustness property of a general Rectified Linear Unit (ReLU) network is an NP-complete problem. Although finding the exact minimum adversarial distortion is hard, giving a certified lower bound of the minimum distortion is possible. Current available methods of computing such a bound are either time-consuming or deliver low quality bounds that are too loose to be useful. In this paper, we exploit the special structure of ReLU networks and provide two computationally efficient algorithms (Fast-Lin, Fast-Lip) that are able to certify non-trivial lower bounds of minimum adversarial distortions. Experiments show that (1) our methods deliver bounds close to (the gap is 2-3X) exact minimum distortions found by Reluplex in small networks while our algorithms are more than 10,000 times faster; (2) our methods deliver similar quality of bounds (the gap is within 35% and usually around 10%; sometimes our bounds are even better) for larger networks compared to the methods based on solving linear programming problems but our algorithms are 33-14,000 times faster; (3) our method is capable of solving large MNIST and CIFAR networks up to 7 layers with more than 10,000 neurons within tens of seconds on a single CPU core. In addition, we show that there is no polynomial time algorithm that can approximately find the minimum $\\ell_1$ adversarial distortion of a ReLU network with a $0.99\\ln n$ approximation ratio unless NP=P, where $n$ is the number of neurons in the network.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/weng18a/weng18a.pdf",
        "supp": "",
        "pdf_size": 500467,
        "gs_citation": 866,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13154362274812885800&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Massachusetts Institute of Technology; UC Davis; Massachusetts Institute of Technology + Harvard University; Harvard University + UT Austin; UC Davis; Massachusetts Institute of Technology; UT Austin; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;ucdavis.edu; ; ; ; ; ; ",
        "email": "mit.edu;ucdavis.edu; ; ; ; ; ; ",
        "github": "",
        "project": "https://arxiv.org/pdf/1804.09699",
        "author_num": 8,
        "oa": "https://proceedings.mlr.press/v80/weng18a.html",
        "aff_unique_index": "0;1;0+2;2+3;1;0;3;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of California, Davis;Harvard University;University of Texas at Austin",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://web.mit.edu;https://www.ucdavis.edu;https://www.harvard.edu;https://www.utexas.edu",
        "aff_unique_abbr": "MIT;UC Davis;Harvard;UT Austin",
        "aff_campus_unique_index": "1;;2;1;2",
        "aff_campus_unique": ";Davis;Austin",
        "aff_country_unique_index": "0;0;0+0;0+0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2229",
        "id": "2229",
        "author_site": "Zebang Shen, Aryan Mokhtari, Tengfei Zhou, Peilin Zhao, Hui Qian",
        "author": "Zebang Shen; Aryan Mokhtari; Tengfei Zhou; Peilin Zhao; Hui Qian",
        "abstract": "Recently, the decentralized optimization problem is attracting growing attention. Most existing methods are deterministic with high per-iteration cost and have a convergence rate quadratically depending on the problem condition number. Besides, the dense communication is necessary to ensure the convergence even if the dataset is sparse. In this paper, we generalize the decentralized optimization problem to a monotone operator root finding problem, and propose a stochastic algorithm named DSBA that (1) converges geometrically with a rate linearly depending on the problem condition number, and (2) can be implemented using sparse communication only. Additionally, DSBA handles important learning problems like AUC-maximization which can not be tackled efficiently in the previous problem setting. Experiments on convex minimization and AUC-maximization validate the efficiency of our method.",
        "bibtex": "@InProceedings{pmlr-v80-shen18a,\n  title = \t {Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication},\n  author =       {Shen, Zebang and Mokhtari, Aryan and Zhou, Tengfei and Zhao, Peilin and Qian, Hui},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4624--4633},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/shen18a/shen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/shen18a.html},\n  abstract = \t {Recently, the decentralized optimization problem is attracting growing attention. Most existing methods are deterministic with high per-iteration cost and have a convergence rate quadratically depending on the problem condition number. Besides, the dense communication is necessary to ensure the convergence even if the dataset is sparse. In this paper, we generalize the decentralized optimization problem to a monotone operator root finding problem, and propose a stochastic algorithm named DSBA that (1) converges geometrically with a rate linearly depending on the problem condition number, and (2) can be implemented using sparse communication only. Additionally, DSBA handles important learning problems like AUC-maximization which can not be tackled efficiently in the previous problem setting. Experiments on convex minimization and AUC-maximization validate the efficiency of our method.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/shen18a/shen18a.pdf",
        "supp": "",
        "pdf_size": 562111,
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4868817902181354825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Zhejiang University+Tencent AI Lab; Massachusetts Institute of Technology; Zhejiang University; South China University of Technology; Zhejiang University",
        "aff_domain": "zju.edu.cn;mit.edu;zju.edu.cn;scut.edu.cn;zju.edu.cn",
        "email": "zju.edu.cn;mit.edu;zju.edu.cn;scut.edu.cn;zju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/shen18a.html",
        "aff_unique_index": "0+1;2;0;3;0",
        "aff_unique_norm": "Zhejiang University;Tencent;Massachusetts Institute of Technology;South China University of Technology",
        "aff_unique_dep": ";Tencent AI Lab;;",
        "aff_unique_url": "https://www.zju.edu.cn;https://ai.tencent.com;https://web.mit.edu;https://www.scut.edu.cn",
        "aff_unique_abbr": "ZJU;Tencent AI Lab;MIT;SCUT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "title": "Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2326",
        "id": "2326",
        "author_site": "Aviral Kumar, Sunita Sarawagi, Ujjwal Jain",
        "author": "Aviral Kumar; Sunita Sarawagi; Ujjwal Jain",
        "abstract": "Modern neural networks have recently been found to be poorly calibrated, primarily in the direction of over-confidence. Methods like entropy penalty and temperature smoothing improve calibration by clamping confidence, but in doing so compromise the many legitimately confident predictions. We propose a more principled fix that minimizes an explicit calibration error during training. We present MMCE, a RKHS kernel based measure of calibration that is efficiently trainable alongside the negative likelihood loss without careful hyper-parameter tuning. Theoretically too, MMCE is a sound measure of calibration that is minimized at perfect calibration, and whose finite sample estimates are consistent and enjoy fast convergence rates. Extensive experiments on several network architectures demonstrate that MMCE is a fast, stable, and accurate method to minimize calibration error while maximally preserving the number of high confidence predictions.",
        "bibtex": "@InProceedings{pmlr-v80-kumar18a,\n  title = \t {Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings},\n  author =       {Kumar, Aviral and Sarawagi, Sunita and Jain, Ujjwal},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2805--2814},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/kumar18a/kumar18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/kumar18a.html},\n  abstract = \t {Modern neural networks have recently been found to be poorly calibrated, primarily in the direction of over-confidence. Methods like entropy penalty and temperature smoothing improve calibration by clamping confidence, but in doing so compromise the many legitimately confident predictions. We propose a more principled fix that minimizes an explicit calibration error during training. We present MMCE, a RKHS kernel based measure of calibration that is efficiently trainable alongside the negative likelihood loss without careful hyper-parameter tuning. Theoretically too, MMCE is a sound measure of calibration that is minimized at perfect calibration, and whose finite sample estimates are consistent and enjoy fast convergence rates. Extensive experiments on several network architectures demonstrate that MMCE is a fast, stable, and accurate method to minimize calibration error while maximally preserving the number of high confidence predictions.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/kumar18a/kumar18a.pdf",
        "supp": "",
        "pdf_size": 705867,
        "gs_citation": 351,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3110087003136366065&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Engineering, IIT Bombay, Mumbai, India; Department of Computer Science and Engineering, IIT Bombay, Mumbai, India; Department of Computer Science and Engineering, IIT Bombay, Mumbai, India",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/kumar18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "IIT Bombay",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitb.ac.in",
        "aff_unique_abbr": "IITB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mumbai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "Training Neural Machines with Trace-Based Supervision",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2452",
        "id": "2452",
        "author_site": "Matthew Mirman, Dimitar Dimitrov, Pavle Djordjevic, Timon Gehr, Martin Vechev",
        "author": "Matthew Mirman; Dimitar Dimitrov; Pavle Djordjevic; Timon Gehr; Martin Vechev",
        "abstract": "We investigate the effectiveness of trace-based supervision methods for training existing neural abstract machines. To define the class of neural machines amenable to trace-based supervision, we introduce the concept of a differential neural computational machine (dNCM) and show that several existing architectures (NTMs, NRAMs) can be described as dNCMs. We performed a detailed experimental evaluation with NTM and NRAM machines, showing that additional supervision on the interpretable portions of these architectures leads to better convergence and generalization capabilities of the learning phase than standard training, in both noise-free and noisy scenarios.",
        "bibtex": "@InProceedings{pmlr-v80-mirman18a,\n  title = \t {Training Neural Machines with Trace-Based Supervision},\n  author =       {Mirman, Matthew and Dimitrov, Dimitar and Djordjevic, Pavle and Gehr, Timon and Vechev, Martin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3569--3577},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mirman18a/mirman18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mirman18a.html},\n  abstract = \t {We investigate the effectiveness of trace-based supervision methods for training existing neural abstract machines. To define the class of neural machines amenable to trace-based supervision, we introduce the concept of a differential neural computational machine (dNCM) and show that several existing architectures (NTMs, NRAMs) can be described as dNCMs. We performed a detailed experimental evaluation with NTM and NRAM machines, showing that additional supervision on the interpretable portions of these architectures leads to better convergence and generalization capabilities of the learning phase than standard training, in both noise-free and noisy scenarios.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mirman18a/mirman18a.pdf",
        "supp": "",
        "pdf_size": 1075290,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16401728985070322013&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland",
        "aff_domain": "inf.ethz.ch; ; ; ;inf.ethz.ch",
        "email": "inf.ethz.ch; ; ; ;inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/mirman18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Transfer Learning via Learning to Transfer",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2145",
        "id": "2145",
        "author_site": "Ying WEI, Yu Zhang, Junzhou Huang, Qiang Yang",
        "author": "Ying WEI; Yu Zhang; Junzhou Huang; Qiang Yang",
        "abstract": "In transfer learning, what and how to transfer are two primary issues to be addressed, as different transfer learning algorithms applied between a source and a target domain result in different knowledge transferred and thereby the performance improvement in the target domain. Determining the optimal one that maximizes the performance improvement requires either exhaustive exploration or considerable expertise. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer are the best for a future pair of domains by optimizing the reflection function. We also theoretically analyse the algorithmic stability and generalization bound of L2T, and empirically demonstrate its superiority over several state-of-the-art transfer learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v80-wei18a,\n  title = \t {Transfer Learning via Learning to Transfer},\n  author =       {WEI, Ying and Zhang, Yu and Huang, Junzhou and Yang, Qiang},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5085--5094},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wei18a/wei18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wei18a.html},\n  abstract = \t {In transfer learning, what and how to transfer are two primary issues to be addressed, as different transfer learning algorithms applied between a source and a target domain result in different knowledge transferred and thereby the performance improvement in the target domain. Determining the optimal one that maximizes the performance improvement requires either exhaustive exploration or considerable expertise. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer are the best for a future pair of domains by optimizing the reflection function. We also theoretically analyse the algorithmic stability and generalization bound of L2T, and empirically demonstrate its superiority over several state-of-the-art transfer learning algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wei18a/wei18a.pdf",
        "supp": "",
        "pdf_size": 1004140,
        "gs_citation": 182,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17005783953624896004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Tencent AI Lab; Hong Kong University of Science and Technology + Tencent AI Lab",
        "aff_domain": "gmail.com; ; ;cse.ust.hk",
        "email": "gmail.com; ; ;cse.ust.hk",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/wei18a.html",
        "aff_unique_index": "0;0;1;0+1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Tencent",
        "aff_unique_dep": ";Tencent AI Lab",
        "aff_unique_url": "https://www.ust.hk;https://ai.tencent.com",
        "aff_unique_abbr": "HKUST;Tencent AI Lab",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2081",
        "id": "2081",
        "author_site": "Andre Barreto, Diana Borsa, John Quan, Tom Schaul, David Silver, Matteo Hessel, Daniel J. Mankowitz, Augustin Zidek, Remi Munos",
        "author": "Andre Barreto; Diana Borsa; John Quan; Tom Schaul; David Silver; Matteo Hessel; Daniel Mankowitz; Augustin Zidek; Remi Munos",
        "abstract": "The ability to transfer skills across tasks has the potential to scale up reinforcement learning (RL) agents to environments currently out of reach. Recently, a framework based on two ideas, successor features (SFs) and generalised policy improvement (GPI), has been introduced as a principled way of transferring skills. In this paper we extend the SF&GPI framework in two ways. One of the basic assumptions underlying the original formulation of SF&GPI is that rewards for all tasks of interest can be computed as linear combinations of a fixed set of features. We relax this constraint and show that the theoretical guarantees supporting the framework can be extended to any set of tasks that only differ in the reward function. Our second contribution is to show that one can use the reward functions themselves as features for future tasks, without any loss of expressiveness, thus removing the need to specify a set of features beforehand. This makes it possible to combine SF&GPI with deep learning in a more stable way. We empirically verify this claim on a complex 3D environment where observations are images from a first-person perspective. We show that the transfer promoted by SF&GPI leads to very good policies on unseen tasks almost instantaneously. We also describe how to learn policies specialised to the new tasks in a way that allows them to be added to the agent\u2019s set of skills, and thus be reused in the future.",
        "bibtex": "@InProceedings{pmlr-v80-barreto18a,\n  title = \t {Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement},\n  author =       {Barreto, Andre and Borsa, Diana and Quan, John and Schaul, Tom and Silver, David and Hessel, Matteo and Mankowitz, Daniel and Zidek, Augustin and Munos, Remi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {501--510},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/barreto18a/barreto18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/barreto18a.html},\n  abstract = \t {The ability to transfer skills across tasks has the potential to scale up reinforcement learning (RL) agents to environments currently out of reach. Recently, a framework based on two ideas, successor features (SFs) and generalised policy improvement (GPI), has been introduced as a principled way of transferring skills. In this paper we extend the SF&GPI framework in two ways. One of the basic assumptions underlying the original formulation of SF&GPI is that rewards for all tasks of interest can be computed as linear combinations of a fixed set of features. We relax this constraint and show that the theoretical guarantees supporting the framework can be extended to any set of tasks that only differ in the reward function. Our second contribution is to show that one can use the reward functions themselves as features for future tasks, without any loss of expressiveness, thus removing the need to specify a set of features beforehand. This makes it possible to combine SF&GPI with deep learning in a more stable way. We empirically verify this claim on a complex 3D environment where observations are images from a first-person perspective. We show that the transfer promoted by SF&GPI leads to very good policies on unseen tasks almost instantaneously. We also describe how to learn policies specialised to the new tasks in a way that allows them to be added to the agent\u2019s set of skills, and thus be reused in the future.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/barreto18a/barreto18a.pdf",
        "supp": "",
        "pdf_size": 1663190,
        "gs_citation": 224,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5255884755653201762&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ; ; ; ; ; ",
        "email": "google.com; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 9,
        "oa": "https://proceedings.mlr.press/v80/barreto18a.html",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "title": "Transformation Autoregressive Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2324",
        "id": "2324",
        "author_site": "Junier Oliva, Kumar Avinava Dubey, Manzil Zaheer, Barnab\u00e1s P\u00f3czos, Ruslan Salakhutdinov, Eric Xing, Jeff Schneider",
        "author": "Junier Oliva; Avinava Dubey; Manzil Zaheer; Barnabas Poczos; Ruslan Salakhutdinov; Eric Xing; Jeff Schneider",
        "abstract": "The fundamental task of general density estimation $p(x)$ has been of keen interest to machine learning. In this work, we attempt to systematically characterize methods for density estimation. Broadly speaking, most of the existing methods can be categorized into either using:",
        "bibtex": "@InProceedings{pmlr-v80-oliva18a,\n  title = \t {Transformation Autoregressive Networks},\n  author =       {Oliva, Junier and Dubey, Avinava and Zaheer, Manzil and Poczos, Barnabas and Salakhutdinov, Ruslan and Xing, Eric and Schneider, Jeff},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3898--3907},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/oliva18a/oliva18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/oliva18a.html},\n  abstract = \t {The fundamental task of general density estimation $p(x)$ has been of keen interest to machine learning. In this work, we attempt to systematically characterize methods for density estimation. Broadly speaking, most of the existing methods can be categorized into either using:",
        "pdf": "http://proceedings.mlr.press/v80/oliva18a/oliva18a.pdf",
        "supp": "",
        "pdf_size": 1244565,
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13773040729706836244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Computer Science Department, University of North Carolina, Chapel Hill, NC 27599 + Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA 15213",
        "aff_domain": "cs.unc.edu; ; ; ; ; ; ",
        "email": "cs.unc.edu; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/oliva18a.html",
        "aff_unique_index": "0+1;1;1;1;1;1;1",
        "aff_unique_norm": "University of North Carolina;Carnegie Mellon University",
        "aff_unique_dep": "Computer Science Department;Machine Learning Department",
        "aff_unique_url": "https://www.unc.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UNC;CMU",
        "aff_campus_unique_index": "0+1;1;1;1;1;1;1",
        "aff_campus_unique": "Chapel Hill;Pittsburgh",
        "aff_country_unique_index": "0+0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Tree Edit Distance Learning via Adaptive Symbol Embeddings",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2180",
        "id": "2180",
        "author_site": "Benjamin Paa\u00dfen, Claudio Gallicchio, Alessio Micheli, CITEC Barbara Hammer",
        "author": "Benjamin Paa\u00dfen; Claudio Gallicchio; Alessio Micheli; Barbara Hammer",
        "abstract": "Metric learning has the aim to improve classification accuracy by learning a distance measure which brings data points from the same class closer together and pushes data points from different classes further apart. Recent research has demonstrated that metric learning approaches can also be applied to trees, such as molecular structures, abstract syntax trees of computer programs, or syntax trees of natural language, by learning the cost function of an edit distance, i.e. the costs of replacing, deleting, or inserting nodes in a tree. However, learning such costs directly may yield an edit distance which violates metric axioms, is challenging to interpret, and may not generalize well. In this contribution, we propose a novel metric learning approach for trees which we call embedding edit distance learning (BEDL) and which learns an edit distance indirectly by embedding the tree nodes as vectors, such that the Euclidean distance between those vectors supports class discrimination. We learn such embeddings by reducing the distance to prototypical trees from the same class and increasing the distance to prototypical trees from different classes. In our experiments, we show that BEDL improves upon the state-of-the-art in metric learning for trees on six benchmark data sets, ranging from computer science over biomedical data to a natural-language processing data set containing over 300,000 nodes.",
        "bibtex": "@InProceedings{pmlr-v80-paassen18a,\n  title = \t {Tree Edit Distance Learning via Adaptive Symbol Embeddings},\n  author =       {Paa{\\ss}en, Benjamin and Gallicchio, Claudio and Micheli, Alessio and Hammer, Barbara},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3976--3985},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/paassen18a/paassen18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/paassen18a.html},\n  abstract = \t {Metric learning has the aim to improve classification accuracy by learning a distance measure which brings data points from the same class closer together and pushes data points from different classes further apart. Recent research has demonstrated that metric learning approaches can also be applied to trees, such as molecular structures, abstract syntax trees of computer programs, or syntax trees of natural language, by learning the cost function of an edit distance, i.e. the costs of replacing, deleting, or inserting nodes in a tree. However, learning such costs directly may yield an edit distance which violates metric axioms, is challenging to interpret, and may not generalize well. In this contribution, we propose a novel metric learning approach for trees which we call embedding edit distance learning (BEDL) and which learns an edit distance indirectly by embedding the tree nodes as vectors, such that the Euclidean distance between those vectors supports class discrimination. We learn such embeddings by reducing the distance to prototypical trees from the same class and increasing the distance to prototypical trees from different classes. In our experiments, we show that BEDL improves upon the state-of-the-art in metric learning for trees on six benchmark data sets, ranging from computer science over biomedical data to a natural-language processing data set containing over 300,000 nodes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/paassen18a/paassen18a.pdf",
        "supp": "",
        "pdf_size": 306241,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10154090211620434614&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Cognitive Interaction Technology, Bielefeld University, Germany; Department of Computer Science, University of Pisa, Italy; Department of Computer Science, University of Pisa, Italy; Cognitive Interaction Technology, Bielefeld University, Germany",
        "aff_domain": "techfak.uni-bielefeld.de; ; ; ",
        "email": "techfak.uni-bielefeld.de; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/paassen18a.html",
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Bielefeld University;University of Pisa",
        "aff_unique_dep": "Cognitive Interaction Technology;Department of Computer Science",
        "aff_unique_url": "https://www.uni-bielefeld.de;https://www.unipi.it",
        "aff_unique_abbr": ";UNIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "title": "Tropical Geometry of Deep Neural Networks",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2048",
        "id": "2048",
        "author_site": "Liwen Zhang, Gregory Naisat, Lek-Heng Lim",
        "author": "Liwen Zhang; Gregory Naitzat; Lek-Heng Lim",
        "abstract": "We establish, for the first time, explicit connections between feedforward neural networks with ReLU activation and tropical geometry \u2014 we show that the family of such neural networks is equivalent to the family of tropical rational maps. Among other things, we deduce that feedforward ReLU neural networks with one hidden layer can be characterized by zonotopes, which serve as building blocks for deeper networks; we relate decision boundaries of such neural networks to tropical hypersurfaces, a major object of study in tropical geometry; and we prove that linear regions of such neural networks correspond to vertices of polytopes associated with tropical rational functions. An insight from our tropical formulation is that a deeper network is exponentially more expressive than a shallow network.",
        "bibtex": "@InProceedings{pmlr-v80-zhang18i,\n  title = \t {Tropical Geometry of Deep Neural Networks},\n  author =       {Zhang, Liwen and Naitzat, Gregory and Lim, Lek-Heng},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5824--5832},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhang18i/zhang18i.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhang18i.html},\n  abstract = \t {We establish, for the first time, explicit connections between feedforward neural networks with ReLU activation and tropical geometry \u2014 we show that the family of such neural networks is equivalent to the family of tropical rational maps. Among other things, we deduce that feedforward ReLU neural networks with one hidden layer can be characterized by zonotopes, which serve as building blocks for deeper networks; we relate decision boundaries of such neural networks to tropical hypersurfaces, a major object of study in tropical geometry; and we prove that linear regions of such neural networks correspond to vertices of polytopes associated with tropical rational functions. An insight from our tropical formulation is that a deeper network is exponentially more expressive than a shallow network.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhang18i/zhang18i.pdf",
        "supp": "",
        "pdf_size": 331604,
        "gs_citation": 198,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10037191125536204512&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, University of Chicago, Chicago, IL; Department of Statistics, University of Chicago, Chicago, IL; Department of Statistics, University of Chicago, Chicago, IL + Computational and Applied Mathematics Initiative, University of Chicago, Chicago, IL",
        "aff_domain": "galton.uchicago.edu; ;galton.uchicago.edu",
        "email": "galton.uchicago.edu; ;galton.uchicago.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/zhang18i.html",
        "aff_unique_index": "0;0;0+0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uchicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "0;0;0+0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Unbiased Objective Estimation in Predictive Optimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2001",
        "id": "2001",
        "author_site": "Shinji Ito, Akihiro Yabe, Ryohei Fujimaki",
        "author": "Shinji Ito; Akihiro Yabe; Ryohei Fujimaki",
        "abstract": "For data-driven decision-making, one promising approach, called predictive optimization, is to solve maximization problems i n which the objective function to be maximized is estimated from data. Predictive optimization, however, suffers from the problem of a calculated optimal solution\u2019s being evaluated too optimistically, i.e., the value of the objective function is overestimated. This paper investigates such optimistic bias and presents two methods for correcting it. The first, which is analogous to cross-validation, successfully corrects the optimistic bias but results in underestimation of the true value. Our second method employs resampling techniques to avoid both overestimation and underestimation. We show that the second method, referred to as the parameter perturbation method, achieves asymptotically unbiased estimation. Empirical results for both artificial and real-world datasets demonstrate that our proposed approach successfully corrects the optimistic bias.",
        "bibtex": "@InProceedings{pmlr-v80-ito18a,\n  title = \t {Unbiased Objective Estimation in Predictive Optimization},\n  author =       {Ito, Shinji and Yabe, Akihiro and Fujimaki, Ryohei},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2176--2185},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ito18a/ito18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ito18a.html},\n  abstract = \t {For data-driven decision-making, one promising approach, called predictive optimization, is to solve maximization problems i n which the objective function to be maximized is estimated from data. Predictive optimization, however, suffers from the problem of a calculated optimal solution\u2019s being evaluated too optimistically, i.e., the value of the objective function is overestimated. This paper investigates such optimistic bias and presents two methods for correcting it. The first, which is analogous to cross-validation, successfully corrects the optimistic bias but results in underestimation of the true value. Our second method employs resampling techniques to avoid both overestimation and underestimation. We show that the second method, referred to as the parameter perturbation method, achieves asymptotically unbiased estimation. Empirical results for both artificial and real-world datasets demonstrate that our proposed approach successfully corrects the optimistic bias.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ito18a/ito18a.pdf",
        "supp": "",
        "pdf_size": 412503,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5785289013842584498&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "NEC Corporation; NEC Corporation; NEC Corporation",
        "aff_domain": "me.jp.nec.com; ; ",
        "email": "me.jp.nec.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/ito18a.html",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "NEC Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nec.com",
        "aff_unique_abbr": "NEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Understanding Generalization and Optimization Performance of Deep CNNs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1932",
        "id": "1932",
        "author_site": "Pan Zhou, Jiashi Feng",
        "author": "Pan Zhou; Jiashi Feng",
        "abstract": "This work aims to provide understandings on the remarkable success of deep convolutional neural networks (CNNs) by theoretically analyzing their generalization performance and establishing optimization guarantees for gradient descent based training algorithms. Specifically, for a CNN model consisting of $l$ convolutional layers and one fully connected layer, we prove that its generalization error is bounded by $\\mathcal{O}(\\sqrt{\\theta\\widetilde{\\varrho}/n})$ where $\\theta$ denotes freedom degree of the network parameters and $\\widetilde{\\varrho}=\\mathcal{O}(\\log(\\prod_{i=1}^{l}b_{i} (k_{i}-s_{i}+1)/p)+\\log(b_{l+1}))$ encapsulates architecture parameters including the kernel size $k_{i}$, stride $s_{i}$, pooling size $p$ and parameter magnitude $b_{i}$. To our best knowledge, this is the first generalization bound that only depends on $\\mathcal{O}(\\log(\\prod_{i=1}^{l+1}b_{i}))$, tighter than existing ones that all involve an exponential term like $\\mathcal{O}(\\prod_{i=1}^{l+1}b_{i})$. Besides, we prove that for an arbitrary gradient descent algorithm, the computed approximate stationary point by minimizing empirical risk is also an approximate stationary point to the population risk. This well explains why gradient descent training algorithms usually perform sufficiently well in practice. Furthermore, we prove the one-to-one correspondence and convergence guarantees for the non-degenerate stationary points between the empirical and population risks. It implies that the computed local minimum for the empirical risk is also close to a local minimum for the population risk, thus ensuring that the optimized CNN model well generalizes to new data.",
        "bibtex": "@InProceedings{pmlr-v80-zhou18a,\n  title = \t {Understanding Generalization and Optimization Performance of Deep {CNN}s},\n  author =       {Zhou, Pan and Feng, Jiashi},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5960--5969},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/zhou18a/zhou18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/zhou18a.html},\n  abstract = \t {This work aims to provide understandings on the remarkable success of deep convolutional neural networks (CNNs) by theoretically analyzing their generalization performance and establishing optimization guarantees for gradient descent based training algorithms. Specifically, for a CNN model consisting of $l$ convolutional layers and one fully connected layer, we prove that its generalization error is bounded by $\\mathcal{O}(\\sqrt{\\theta\\widetilde{\\varrho}/n})$ where $\\theta$ denotes freedom degree of the network parameters and $\\widetilde{\\varrho}=\\mathcal{O}(\\log(\\prod_{i=1}^{l}b_{i} (k_{i}-s_{i}+1)/p)+\\log(b_{l+1}))$ encapsulates architecture parameters including the kernel size $k_{i}$, stride $s_{i}$, pooling size $p$ and parameter magnitude $b_{i}$. To our best knowledge, this is the first generalization bound that only depends on $\\mathcal{O}(\\log(\\prod_{i=1}^{l+1}b_{i}))$, tighter than existing ones that all involve an exponential term like $\\mathcal{O}(\\prod_{i=1}^{l+1}b_{i})$. Besides, we prove that for an arbitrary gradient descent algorithm, the computed approximate stationary point by minimizing empirical risk is also an approximate stationary point to the population risk. This well explains why gradient descent training algorithms usually perform sufficiently well in practice. Furthermore, we prove the one-to-one correspondence and convergence guarantees for the non-degenerate stationary points between the empirical and population risks. It implies that the computed local minimum for the empirical risk is also close to a local minimum for the population risk, thus ensuring that the optimized CNN model well generalizes to new data.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/zhou18a/zhou18a.pdf",
        "supp": "",
        "pdf_size": 360274,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17466675625275409353&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical & Computer Engineering (ECE), National University of Singapore, Singapore; Department of Electrical & Computer Engineering (ECE), National University of Singapore, Singapore",
        "aff_domain": "u.nus.edu; ",
        "email": "u.nus.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/zhou18a.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "title": "Understanding and Simplifying One-Shot Architecture Search",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2077",
        "id": "2077",
        "author_site": "Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, Quoc Le",
        "author": "Gabriel Bender; Pieter-Jan Kindermans; Barret Zoph; Vijay Vasudevan; Quoc Le",
        "abstract": "There is growing interest in automating neural network architecture design. Existing architecture search methods can be computationally expensive, requiring thousands of different architectures to be trained from scratch. Recent work has explored",
        "bibtex": "@InProceedings{pmlr-v80-bender18a,\n  title = \t {Understanding and Simplifying One-Shot Architecture Search},\n  author =       {Bender, Gabriel and Kindermans, Pieter-Jan and Zoph, Barret and Vasudevan, Vijay and Le, Quoc},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {550--559},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bender18a/bender18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bender18a.html},\n  abstract = \t {There is growing interest in automating neural network architecture design. Existing architecture search methods can be computationally expensive, requiring thousands of different architectures to be trained from scratch. Recent work has explored",
        "pdf": "http://proceedings.mlr.press/v80/bender18a/bender18a.pdf",
        "supp": "",
        "pdf_size": 608254,
        "gs_citation": 932,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7510080748852519361&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Brain, Mountain View, CA; Google Brain, Mountain View, CA; Google Brain, Mountain View, CA; Google Brain, Mountain View, CA; Google Brain, Mountain View, CA",
        "aff_domain": "google.com; ; ; ; ",
        "email": "google.com; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/bender18a.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Brain",
        "aff_unique_url": "https://brain.google.com",
        "aff_unique_abbr": "Google Brain",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Understanding the Loss Surface of Neural Networks for Binary Classification",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2237",
        "id": "2237",
        "author_site": "SHIYU LIANG, Ruoyu Sun, Yixuan Li, R Srikant",
        "author": "SHIYU LIANG; Ruoyu Sun; Yixuan Li; Rayadurgam Srikant",
        "abstract": "It is widely conjectured that training algorithms for neural networks are successful because all local minima lead to similar performance; for example, see (LeCun et al., 2015; Choromanska et al., 2015; Dauphin et al., 2014). Performance is typically measured in terms of two metrics: training performance and generalization performance. Here we focus on the training performance of neural networks for binary classification, and provide conditions under which the training error is zero at all local minima of appropriately chosen surrogate loss functions. Our conditions are roughly in the following form: the neurons have to be increasing and strictly convex, the neural network should either be single-layered or is multi-layered with a shortcut-like connection, and the surrogate loss function should be a smooth version of hinge loss. We also provide counterexamples to show that, when these conditions are relaxed, the result may not hold.",
        "bibtex": "@InProceedings{pmlr-v80-liang18a,\n  title = \t {Understanding the Loss Surface of Neural Networks for Binary Classification},\n  author =       {LIANG, SHIYU and Sun, Ruoyu and Li, Yixuan and Srikant, Rayadurgam},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2835--2843},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/liang18a/liang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/liang18a.html},\n  abstract = \t {It is widely conjectured that training algorithms for neural networks are successful because all local minima lead to similar performance; for example, see (LeCun et al., 2015; Choromanska et al., 2015; Dauphin et al., 2014). Performance is typically measured in terms of two metrics: training performance and generalization performance. Here we focus on the training performance of neural networks for binary classification, and provide conditions under which the training error is zero at all local minima of appropriately chosen surrogate loss functions. Our conditions are roughly in the following form: the neurons have to be increasing and strictly convex, the neural network should either be single-layered or is multi-layered with a shortcut-like connection, and the surrogate loss function should be a smooth version of hinge loss. We also provide counterexamples to show that, when these conditions are relaxed, the result may not hold.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/liang18a/liang18a.pdf",
        "supp": "",
        "pdf_size": 343768,
        "gs_citation": 99,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=111227920399475959&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; Facebook Research; University of Illinois at Urbana-Champaign",
        "aff_domain": "illinois.edu;illinois.edu;fb.com;illinois.edu",
        "email": "illinois.edu;illinois.edu;fb.com;illinois.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/liang18a.html",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Meta",
        "aff_unique_dep": ";Facebook Research",
        "aff_unique_url": "https://illinois.edu;https://research.facebook.com",
        "aff_unique_abbr": "UIUC;FB Research",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2340",
        "id": "2340",
        "author_site": "Aravind Srinivas, Allan Jabri, Pieter Abbeel, Sergey Levine, Chelsea Finn",
        "author": "Aravind Srinivas; Allan Jabri; Pieter Abbeel; Sergey Levine; Chelsea Finn",
        "abstract": "A key challenge in complex visuomotor control is learning abstract representations that are effective for specifying goals, planning, and generalization. To this end, we introduce universal planning networks (UPN). UPNs embed differentiable planning within a goal-directed policy. This planning computation unrolls a forward model in a latent space and infers an optimal action plan through gradient descent trajectory optimization. The plan-by-gradient-descent process and its underlying representations are learned end-to-end to directly optimize a supervised imitation learning objective. We find that the representations learned are not only effective for goal-directed visual imitation via gradient-based trajectory optimization, but can also provide a metric for specifying goals using images. The learned representations can be leveraged to specify distance-based rewards to reach new target states for model-free reinforcement learning, resulting in substantially more effective learning when solving new tasks described via image based goals. We were able to achieve successful transfer of visuomotor planning strategies across robots with significantly different morphologies and actuation capabilities. Visit https://sites.google. com/view/upn-public/home for video highlights.",
        "bibtex": "@InProceedings{pmlr-v80-srinivas18b,\n  title = \t {Universal Planning Networks: Learning Generalizable Representations for Visuomotor Control},\n  author =       {Srinivas, Aravind and Jabri, Allan and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4732--4741},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/srinivas18b/srinivas18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/srinivas18b.html},\n  abstract = \t {A key challenge in complex visuomotor control is learning abstract representations that are effective for specifying goals, planning, and generalization. To this end, we introduce universal planning networks (UPN). UPNs embed differentiable planning within a goal-directed policy. This planning computation unrolls a forward model in a latent space and infers an optimal action plan through gradient descent trajectory optimization. The plan-by-gradient-descent process and its underlying representations are learned end-to-end to directly optimize a supervised imitation learning objective. We find that the representations learned are not only effective for goal-directed visual imitation via gradient-based trajectory optimization, but can also provide a metric for specifying goals using images. The learned representations can be leveraged to specify distance-based rewards to reach new target states for model-free reinforcement learning, resulting in substantially more effective learning when solving new tasks described via image based goals. We were able to achieve successful transfer of visuomotor planning strategies across robots with significantly different morphologies and actuation capabilities. Visit https://sites.google. com/view/upn-public/home for video highlights.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/srinivas18b/srinivas18b.pdf",
        "supp": "",
        "pdf_size": 2360783,
        "gs_citation": 325,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14495958812828932181&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "UC Berkeley, Computer Science; UC Berkeley, Computer Science; UC Berkeley, Computer Science; UC Berkeley, Computer Science; UC Berkeley, Computer Science",
        "aff_domain": "cs.berkeley.edu; ; ; ; ",
        "email": "cs.berkeley.edu; ; ; ; ",
        "github": "",
        "project": "https://sites.google.com/view/upn-public/home",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/srinivas18b.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Using Inherent Structures to design Lean 2-layer RBMs",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2376",
        "id": "2376",
        "author_site": "Abhishek Bansal, Abhinav Anand, Chiranjib Bhattacharyya",
        "author": "Abhishek Bansal; Abhinav Anand; Chiranjib Bhattacharyya",
        "abstract": "Understanding the representational power of Restricted Boltzmann Machines (RBMs) with multiple layers is an ill-understood problem and is an area of active research. Motivated from the approach of",
        "bibtex": "@InProceedings{pmlr-v80-bansal18a,\n  title = \t {Using Inherent Structures to design Lean 2-layer {RBM}s},\n  author =       {Bansal, Abhishek and Anand, Abhinav and Bhattacharyya, Chiranjib},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {443--451},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bansal18a/bansal18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bansal18a.html},\n  abstract = \t {Understanding the representational power of Restricted Boltzmann Machines (RBMs) with multiple layers is an ill-understood problem and is an area of active research. Motivated from the approach of",
        "pdf": "http://proceedings.mlr.press/v80/bansal18a/bansal18a.pdf",
        "supp": "",
        "pdf_size": 2464472,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13504391511433471809&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "IBM Research; Dept of CSA, IISc, Bengaluru, India; Dept of CSA, IISc, Bengaluru, India",
        "aff_domain": "in.ibm.com;iisc.ac.in;iisc.ac.in",
        "email": "in.ibm.com;iisc.ac.in;iisc.ac.in",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/bansal18a.html",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "IBM;Indian Institute of Science",
        "aff_unique_dep": "IBM Research;Department of Computer Science and Automation",
        "aff_unique_url": "https://www.ibm.com/research;https://www.iisc.ac.in",
        "aff_unique_abbr": "IBM;IISc",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Bengaluru",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;India"
    },
    {
        "title": "Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2454",
        "id": "2454",
        "author_site": "Rodrigo A Toro Icarte, Toryn Q Klassen, Richard Valenzano, Sheila McIlraith",
        "author": "Rodrigo Toro Icarte; Toryn Klassen; Richard Valenzano; Sheila McIlraith",
        "abstract": "In this paper we propose Reward Machines {\u2014} a type of finite state machine that supports the specification of reward functions while exposing reward function structure to the learner and supporting decomposition. We then present Q-Learning for Reward Machines (QRM), an algorithm which appropriately decomposes the reward machine and uses off-policy q-learning to simultaneously learn subpolicies for the different components. QRM is guaranteed to converge to an optimal policy in the tabular case, in contrast to Hierarchical Reinforcement Learning methods which might converge to suboptimal policies. We demonstrate this behavior experimentally in two discrete domains. We also show how function approximation methods like neural networks can be incorporated into QRM, and that doing so can find better policies more quickly than hierarchical methods in a domain with a continuous state space.",
        "bibtex": "@InProceedings{pmlr-v80-icarte18a,\n  title = \t {Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning},\n  author =       {Icarte, Rodrigo Toro and Klassen, Toryn and Valenzano, Richard and McIlraith, Sheila},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2107--2116},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/icarte18a/icarte18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/icarte18a.html},\n  abstract = \t {In this paper we propose Reward Machines {\u2014} a type of finite state machine that supports the specification of reward functions while exposing reward function structure to the learner and supporting decomposition. We then present Q-Learning for Reward Machines (QRM), an algorithm which appropriately decomposes the reward machine and uses off-policy q-learning to simultaneously learn subpolicies for the different components. QRM is guaranteed to converge to an optimal policy in the tabular case, in contrast to Hierarchical Reinforcement Learning methods which might converge to suboptimal policies. We demonstrate this behavior experimentally in two discrete domains. We also show how function approximation methods like neural networks can be incorporated into QRM, and that doing so can find better policies more quickly than hierarchical methods in a domain with a continuous state space.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/icarte18a/icarte18a.pdf",
        "supp": "",
        "pdf_size": 318210,
        "gs_citation": 397,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16231989593380594554&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of Toronto, Toronto, Ontario, Canada+Vector Institute, Toronto, Ontario, Canada; Department of Computer Science, University of Toronto, Toronto, Ontario, Canada; Element AI, Toronto, Ontario, Canada; Department of Computer Science, University of Toronto, Toronto, Ontario, Canada+Vector Institute, Toronto, Ontario, Canada",
        "aff_domain": "cs.toronto.edu; ; ; ",
        "email": "cs.toronto.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/icarte18a.html",
        "aff_unique_index": "0+1;0;2;0+1",
        "aff_unique_norm": "University of Toronto;Vector Institute;Element AI",
        "aff_unique_dep": "Department of Computer Science;;",
        "aff_unique_url": "https://www.utoronto.ca;https://vectorinstitute.ai;https://www.elementai.com",
        "aff_unique_abbr": "U of T;Vector Institute;",
        "aff_campus_unique_index": "0+0;0;0;0+0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0+0;0;0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "title": "Variable Selection via Penalized Neural Network: a Drop-Out-One Loss Approach",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1995",
        "id": "1995",
        "author_site": "Mao Ye, Yan Sun",
        "author": "Mao Ye; Yan Sun",
        "abstract": "We propose a variable selection method for high dimensional regression models, which allows for complex, nonlinear, and high-order interactions among variables. The proposed method approximates this complex system using a penalized neural network and selects explanatory variables by measuring their utility in explaining the variance of the response variable. This measurement is based on a novel statistic called Drop-Out-One Loss. The proposed method also allows (overlapping) group variable selection. We prove that the proposed method can select relevant variables and exclude irrelevant variables with probability one as the sample size goes to infinity, which is referred to as the Oracle Property. Experimental results on simulated and real world datasets show the efficiency of our method in terms of variable selection and prediction accuracy.",
        "bibtex": "@InProceedings{pmlr-v80-ye18b,\n  title = \t {Variable Selection via Penalized Neural Network: a Drop-Out-One Loss Approach},\n  author =       {Ye, Mao and Sun, Yan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5620--5629},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ye18b/ye18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ye18b.html},\n  abstract = \t {We propose a variable selection method for high dimensional regression models, which allows for complex, nonlinear, and high-order interactions among variables. The proposed method approximates this complex system using a penalized neural network and selects explanatory variables by measuring their utility in explaining the variance of the response variable. This measurement is based on a novel statistic called Drop-Out-One Loss. The proposed method also allows (overlapping) group variable selection. We prove that the proposed method can select relevant variables and exclude irrelevant variables with probability one as the sample size goes to infinity, which is referred to as the Oracle Property. Experimental results on simulated and real world datasets show the efficiency of our method in terms of variable selection and prediction accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ye18b/ye18b.pdf",
        "supp": "",
        "pdf_size": 1448662,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16961773023800380773&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistics, Purdue University, West Lafayette, IN, USA; Department of Statistics, Purdue University, West Lafayette, IN, USA",
        "aff_domain": "purdue.edu; ",
        "email": "purdue.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/ye18b.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2204",
        "id": "2204",
        "author_site": "Hang Wu, May Wang",
        "author": "Hang Wu; May Wang",
        "abstract": "Off-policy learning, the task of evaluating and improving policies using historic data collected from a logging policy, is important because on-policy evaluation is usually expensive and has adverse impacts. One of the major challenge of off-policy learning is to derive counterfactual estimators that also has low variance and thus low generalization error. In this work, inspired by learning bounds for importance sampling problems, we present a new counterfactual learning principle for off-policy learning with bandit feedbacks. Our method regularizes the generalization error by minimizing the distribution divergence between the logging policy and the new policy, and removes the need for iterating through all training samples to compute sample variance regularization in prior work. With neural network policies, our end-to-end training algorithms using variational divergence minimization showed significant improvement over conventional baseline algorithms and is also consistent with our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v80-wu18g,\n  title = \t {Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization},\n  author =       {Wu, Hang and Wang, May},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5353--5362},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/wu18g/wu18g.pdf},\n  url = \t {https://proceedings.mlr.press/v80/wu18g.html},\n  abstract = \t {Off-policy learning, the task of evaluating and improving policies using historic data collected from a logging policy, is important because on-policy evaluation is usually expensive and has adverse impacts. One of the major challenge of off-policy learning is to derive counterfactual estimators that also has low variance and thus low generalization error. In this work, inspired by learning bounds for importance sampling problems, we present a new counterfactual learning principle for off-policy learning with bandit feedbacks. Our method regularizes the generalization error by minimizing the distribution divergence between the logging policy and the new policy, and removes the need for iterating through all training samples to compute sample variance regularization in prior work. With neural network policies, our end-to-end training algorithms using variational divergence minimization showed significant improvement over conventional baseline algorithms and is also consistent with our theoretical results.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/wu18g/wu18g.pdf",
        "supp": "",
        "pdf_size": 402972,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16906275230514657049&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology",
        "aff_domain": "gatech.edu; ",
        "email": "gatech.edu; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/wu18g.html",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Variational Bayesian dropout: pitfalls and fixes",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2336",
        "id": "2336",
        "author_site": "Jiri Hron, Alexander Matthews, Zoubin Ghahramani",
        "author": "Jiri Hron; Alex Matthews; Zoubin Ghahramani",
        "abstract": "Dropout, a stochastic regularisation technique for training of neural networks, has recently been reinterpreted as a specific type of approximate inference algorithm for Bayesian neural networks. The main contribution of the reinterpretation is in providing a theoretical framework useful for analysing and extending the algorithm. We show that the proposed framework suffers from several issues; from undefined or pathological behaviour of the true posterior related to use of improper priors, to an ill-defined variational objective due to singularity of the approximating distribution relative to the true posterior. Our analysis of the improper log uniform prior used in variational Gaussian dropout suggests the pathologies are generally irredeemable, and that the algorithm still works only because the variational formulation annuls some of the pathologies. To address the singularity issue, we proffer Quasi-KL (QKL) divergence, a new approximate inference objective for approximation of high-dimensional distributions. We show that motivations for variational Bernoulli dropout based on discretisation and noise have QKL as a limit. Properties of QKL are studied both theoretically and on a simple practical example which shows that the QKL-optimal approximation of a full rank Gaussian with a degenerate one naturally leads to the Principal Component Analysis solution.",
        "bibtex": "@InProceedings{pmlr-v80-hron18a,\n  title = \t {Variational {B}ayesian dropout: pitfalls and fixes},\n  author =       {Hron, Jiri and Matthews, Alex and Ghahramani, Zoubin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2019--2028},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/hron18a/hron18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/hron18a.html},\n  abstract = \t {Dropout, a stochastic regularisation technique for training of neural networks, has recently been reinterpreted as a specific type of approximate inference algorithm for Bayesian neural networks. The main contribution of the reinterpretation is in providing a theoretical framework useful for analysing and extending the algorithm. We show that the proposed framework suffers from several issues; from undefined or pathological behaviour of the true posterior related to use of improper priors, to an ill-defined variational objective due to singularity of the approximating distribution relative to the true posterior. Our analysis of the improper log uniform prior used in variational Gaussian dropout suggests the pathologies are generally irredeemable, and that the algorithm still works only because the variational formulation annuls some of the pathologies. To address the singularity issue, we proffer Quasi-KL (QKL) divergence, a new approximate inference objective for approximation of high-dimensional distributions. We show that motivations for variational Bernoulli dropout based on discretisation and noise have QKL as a limit. Properties of QKL are studied both theoretically and on a simple practical example which shows that the QKL-optimal approximation of a full rank Gaussian with a degenerate one naturally leads to the Principal Component Analysis solution.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/hron18a/hron18a.pdf",
        "supp": "",
        "pdf_size": 2478804,
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4894118081020421199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Department of Engineering, University of Cambridge, Cambridge, United Kingdom + Uber AI Labs, San Francisco, California, USA",
        "aff_domain": "cam.ac.uk; ; ",
        "email": "cam.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/hron18a.html",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "University of Cambridge;Uber",
        "aff_unique_dep": "Department of Engineering;Uber AI Labs",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.uber.com",
        "aff_unique_abbr": "Cambridge;Uber",
        "aff_campus_unique_index": "0;0;0+1",
        "aff_campus_unique": "Cambridge;San Francisco",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "title": "Variational Inference and Model Selection with Generalized Evidence Bounds",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2377",
        "id": "2377",
        "author_site": "Liqun Chen, Chenyang Tao, RUIYI (ROY) ZHANG, Ricardo Henao, Lawrence Carin",
        "author": "Liqun Chen; Chenyang Tao; Ruiyi Zhang; Ricardo Henao; Lawrence Carin Duke",
        "abstract": "Recent advances on the scalability and flexibility of variational inference have made it successful at unravelling hidden patterns in complex data. In this work we propose a new variational bound formulation, yielding an estimator that extends beyond the conventional variational bound. It naturally subsumes the importance-weighted and Renyi bounds as special cases, and it is provably sharper than these counterparts. We also present an improved estimator for variational learning, and advocate a novel high signal-to-variance ratio update rule for the variational parameters. We discuss model-selection issues associated with existing evidence-lower-bound-based variational inference procedures, and show how to leverage the flexibility of our new formulation to address them. Empirical evidence is provided to validate our claims.",
        "bibtex": "@InProceedings{pmlr-v80-chen18k,\n  title = \t {Variational Inference and Model Selection with Generalized Evidence Bounds},\n  author =       {Chen, Liqun and Tao, Chenyang and Zhang, Ruiyi and Henao, Ricardo and Duke, Lawrence Carin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {893--902},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18k/chen18k.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18k.html},\n  abstract = \t {Recent advances on the scalability and flexibility of variational inference have made it successful at unravelling hidden patterns in complex data. In this work we propose a new variational bound formulation, yielding an estimator that extends beyond the conventional variational bound. It naturally subsumes the importance-weighted and Renyi bounds as special cases, and it is provably sharper than these counterparts. We also present an improved estimator for variational learning, and advocate a novel high signal-to-variance ratio update rule for the variational parameters. We discuss model-selection issues associated with existing evidence-lower-bound-based variational inference procedures, and show how to leverage the flexibility of our new formulation to address them. Empirical evidence is provided to validate our claims.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18k/chen18k.pdf",
        "supp": "",
        "pdf_size": 1266453,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7837341122996371666&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Electrical & Computer Engineering, Duke University; Electrical & Computer Engineering, Duke University; Electrical & Computer Engineering, Duke University; Electrical & Computer Engineering, Duke University; Electrical & Computer Engineering, Duke University",
        "aff_domain": "duke.edu;duke.edu; ; ; ",
        "email": "duke.edu;duke.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "oa": "https://proceedings.mlr.press/v80/chen18k.html",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Electrical & Computer Engineering",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Variational Network Inference: Strong and Stable with Concrete Support",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1878",
        "id": "1878",
        "author_site": "Amir Dezfouli, Edwin Bonilla, Richard Nock",
        "author": "Amir Dezfouli; Edwin Bonilla; Richard Nock",
        "abstract": "Traditional methods for the discovery of latent network structures are limited in two ways: they either assume that all the signal comes from the network (i.e. there is no source of signal outside the network) or they place constraints on the network parameters to ensure model or algorithmic stability. We address these limitations by proposing a model that incorporates a Gaussian process prior on a network-independent component and formally proving that we get algorithmic stability for free while providing a novel perspective on model stability as well as robustness results and precise intervals for key inference parameters. We show that, on three applications, our approach outperforms previous methods consistently.",
        "bibtex": "@InProceedings{pmlr-v80-dezfouli18a,\n  title = \t {Variational Network Inference: Strong and Stable with Concrete Support},\n  author =       {Dezfouli, Amir and Bonilla, Edwin and Nock, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1204--1213},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/dezfouli18a/dezfouli18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/dezfouli18a.html},\n  abstract = \t {Traditional methods for the discovery of latent network structures are limited in two ways: they either assume that all the signal comes from the network (i.e. there is no source of signal outside the network) or they place constraints on the network parameters to ensure model or algorithmic stability. We address these limitations by proposing a model that incorporates a Gaussian process prior on a network-independent component and formally proving that we get algorithmic stability for free while providing a novel perspective on model stability as well as robustness results and precise intervals for key inference parameters. We show that, on three applications, our approach outperforms previous methods consistently.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/dezfouli18a/dezfouli18a.pdf",
        "supp": "",
        "pdf_size": 2036557,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:kPbDaLvnbucJ:scholar.google.com/&scioq=Variational+Network+Inference:+Strong+and+Stable+with+Concrete+Support&hl=en&as_sdt=0,14",
        "gs_version_total": 8,
        "aff": "UNSW, Sydney + Data61; UNSW, Sydney; Data61, the Australian National University and the University of Sydney",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/dezfouli18a.html",
        "aff_unique_index": "0+1;0;2",
        "aff_unique_norm": "University of New South Wales;Data61;Australian National University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.unsw.edu.au;https://data61.csiro.au;https://www.anu.edu.au",
        "aff_unique_abbr": "UNSW;Data61;ANU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "title": "Video Prediction with Appearance and Motion Conditions",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1926",
        "id": "1926",
        "author_site": "Yunseok Jang, Gunhee Kim, Yale Song",
        "author": "Yunseok Jang; Gunhee Kim; Yale Song",
        "abstract": "Video prediction aims to generate realistic future frames by learning dynamic visual patterns. One fundamental challenge is to deal with future uncertainty: How should a model behave when there are multiple correct, equally probable future? We propose an Appearance-Motion Conditional GAN to address this challenge. We provide appearance and motion information as conditions that specify how the future may look like, reducing the level of uncertainty. Our model consists of a generator, two discriminators taking charge of appearance and motion pathways, and a perceptual ranking module that encourages videos of similar conditions to look similar. To train our model, we develop a novel conditioning scheme that consists of different combinations of appearance and motion conditions. We evaluate our model using facial expression and human action datasets and report favorable results compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v80-jang18a,\n  title = \t {Video Prediction with Appearance and Motion Conditions},\n  author =       {Jang, Yunseok and Kim, Gunhee and Song, Yale},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2225--2234},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jang18a/jang18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jang18a.html},\n  abstract = \t {Video prediction aims to generate realistic future frames by learning dynamic visual patterns. One fundamental challenge is to deal with future uncertainty: How should a model behave when there are multiple correct, equally probable future? We propose an Appearance-Motion Conditional GAN to address this challenge. We provide appearance and motion information as conditions that specify how the future may look like, reducing the level of uncertainty. Our model consists of a generator, two discriminators taking charge of appearance and motion pathways, and a perceptual ranking module that encourages videos of similar conditions to look similar. To train our model, we develop a novel conditioning scheme that consists of different combinations of appearance and motion conditions. We evaluate our model using facial expression and human action datasets and report favorable results compared to existing methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jang18a/jang18a.pdf",
        "supp": "",
        "pdf_size": 2209509,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18381316342083452502&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Michigan, Ann Arbor+Yahoo Research; Seoul National University+Yahoo Research; Microsoft AI & Research",
        "aff_domain": "umich.edu;snu.ac.kr;microsoft.com",
        "email": "umich.edu;snu.ac.kr;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/jang18a.html",
        "aff_unique_index": "0+1;2+1;3",
        "aff_unique_norm": "University of Michigan;Yahoo;Seoul National University;Microsoft",
        "aff_unique_dep": ";Yahoo Research;;Microsoft AI & Research",
        "aff_unique_url": "https://www.umich.edu;https://research.yahoo.com;https://www.snu.ac.kr;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "UM;Yahoo Research;SNU;Microsoft AI",
        "aff_campus_unique_index": "0;",
        "aff_campus_unique": "Ann Arbor;",
        "aff_country_unique_index": "0+0;1+0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "title": "Visualizing and Understanding Atari Agents",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1987",
        "id": "1987",
        "author_site": "Samuel Greydanus, Anurag Koul, Jonathan Dodge, Alan Fern",
        "author": "Samuel Greydanus; Anurag Koul; Jonathan Dodge; Alan Fern",
        "abstract": "While deep reinforcement learning (deep RL) agents are effective at maximizing rewards, it is often unclear what strategies they use to do so. In this paper, we take a step toward explaining deep RL agents through a case study using Atari 2600 environments. In particular, we focus on using saliency maps to understand how an agent learns and executes a policy. We introduce a method for generating useful saliency maps and use it to show 1) what strong agents attend to, 2) whether agents are making decisions for the right or wrong reasons, and 3) how agents evolve during learning. We also test our method on non-expert human subjects and find that it improves their ability to reason about these agents. Overall, our results show that saliency information can provide significant insight into an RL agent\u2019s decisions and learning behavior.",
        "bibtex": "@InProceedings{pmlr-v80-greydanus18a,\n  title = \t {Visualizing and Understanding {A}tari Agents},\n  author =       {Greydanus, Samuel and Koul, Anurag and Dodge, Jonathan and Fern, Alan},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1792--1801},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/greydanus18a/greydanus18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/greydanus18a.html},\n  abstract = \t {While deep reinforcement learning (deep RL) agents are effective at maximizing rewards, it is often unclear what strategies they use to do so. In this paper, we take a step toward explaining deep RL agents through a case study using Atari 2600 environments. In particular, we focus on using saliency maps to understand how an agent learns and executes a policy. We introduce a method for generating useful saliency maps and use it to show 1) what strong agents attend to, 2) whether agents are making decisions for the right or wrong reasons, and 3) how agents evolve during learning. We also test our method on non-expert human subjects and find that it improves their ability to reason about these agents. Overall, our results show that saliency information can provide significant insight into an RL agent\u2019s decisions and learning behavior.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/greydanus18a/greydanus18a.pdf",
        "supp": "",
        "pdf_size": 2588674,
        "gs_citation": 464,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2974426333741298395&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Oregon State University; Oregon State University; Oregon State University; Oregon State University",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "github.com/greydanus/visualize atari",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/greydanus18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "WHInter: A Working set algorithm for High-dimensional sparse second order Interaction models",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2255",
        "id": "2255",
        "author_site": "Marine LE MORVAN, Jean-Philippe Vert",
        "author": "Marine Le Morvan; Jean-Philippe Vert",
        "abstract": "Learning sparse linear models with two-way interactions is desirable in many application domains such as genomics. $\\ell_1$-regularised linear models are popular to estimate sparse models, yet standard implementations fail to address specifically the quadratic explosion of candidate two-way interactions in high dimensions, and typically do not scale to genetic data with hundreds of thousands of features. Here we present WHInter, a working set algorithm to solve large $\\ell_1$-regularised problems with two-way interactions for binary design matrices. The novelty of WHInter stems from a new bound to efficiently identify working sets while avoiding to scan all features, and on fast computations inspired from solutions to the maximum inner product search problem. We apply WHInter to simulated and real genetic data and show that it is more scalable and two orders of magnitude faster than the state of the art.",
        "bibtex": "@InProceedings{pmlr-v80-morvan18a,\n  title = \t {{WHI}nter: A Working set algorithm for High-dimensional sparse second order Interaction models},\n  author =       {Morvan, Marine Le and Vert, Jean-Philippe},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3635--3644},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/morvan18a/morvan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/morvan18a.html},\n  abstract = \t {Learning sparse linear models with two-way interactions is desirable in many application domains such as genomics. $\\ell_1$-regularised linear models are popular to estimate sparse models, yet standard implementations fail to address specifically the quadratic explosion of candidate two-way interactions in high dimensions, and typically do not scale to genetic data with hundreds of thousands of features. Here we present WHInter, a working set algorithm to solve large $\\ell_1$-regularised problems with two-way interactions for binary design matrices. The novelty of WHInter stems from a new bound to efficiently identify working sets while avoiding to scan all features, and on fast computations inspired from solutions to the maximum inner product search problem. We apply WHInter to simulated and real genetic data and show that it is more scalable and two orders of magnitude faster than the state of the art.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/morvan18a/morvan18a.pdf",
        "supp": "",
        "pdf_size": 416585,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11328009343954251919&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "MINES ParisTech, PSL Research University, CBIO-Centre for Computational Biology, 75006 Paris, France+Institut Curie, PSL Research University, 75005 Paris, France+INSERM, U900, 75005 Paris, France; MINES ParisTech, PSL Research University, CBIO-Centre for Computational Biology, 75006 Paris, France+Institut Curie, PSL Research University, 75005 Paris, France+INSERM, U900, 75005 Paris, France+Ecole Normale Sup\u00e9rieure, Department of Mathematics and Applications, 75005 Paris, France",
        "aff_domain": "mines-paristech.fr;mines-paristech.fr",
        "email": "mines-paristech.fr;mines-paristech.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "oa": "https://proceedings.mlr.press/v80/morvan18a.html",
        "aff_unique_index": "0+1+2;0+1+2+3",
        "aff_unique_norm": "MINES ParisTech;Institut Curie;Institut National de la Sant\u00e9 et de la Recherche M\u00e9dicale;Ecole Normale Sup\u00e9rieure",
        "aff_unique_dep": "CBIO-Centre for Computational Biology;;Unit\u00e9 900;Department of Mathematics and Applications",
        "aff_unique_url": "https://www.minesparistech.fr;https://www.institut-curie.org;https://www.inserm.fr;https://www.ens.fr",
        "aff_unique_abbr": "MPT;Institut Curie;INSERM;ENS",
        "aff_campus_unique_index": "0+0;0+0+0",
        "aff_campus_unique": "Paris;",
        "aff_country_unique_index": "0+0+0;0+0+0+0",
        "aff_country_unique": "France"
    },
    {
        "title": "WSNet: Compact and Efficient Networks Through Weight Sampling",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2402",
        "id": "2402",
        "author_site": "Xiaojie Jin, Yingzhen Yang, Ning Xu, Jianchao Yang, Nebojsa Jojic, Jiashi Feng, Shuicheng Yan",
        "author": "Xiaojie Jin; Yingzhen Yang; Ning Xu; Jianchao Yang; Nebojsa Jojic; Jiashi Feng; Shuicheng Yan",
        "abstract": "We present a new approach and a novel architecture, termed WSNet, for learning compact and efficient deep neural networks. Existing approaches conventionally learn full model parameters independently and then compress them via ad hoc processing such as model pruning or filter factorization. Alternatively, WSNet proposes learning model parameters by sampling from a compact set of learnable parameters, which naturally enforces parameter sharing throughout the learning process. We demonstrate that such a novel weight sampling approach (and induced WSNet) promotes both weights and computation sharing favorably. By employing this method, we can more efficiently learn much smaller networks with competitive performance compared to baseline networks with equal numbers of convolution filters. Specifically, we consider learning compact and efficient 1D convolutional neural networks for audio classification. Extensive experiments on multiple audio classification datasets verify the effectiveness of WSNet. Combined with weight quantization, the resulted models are up to 180x smaller and theoretically up to 16x faster than the well-established baselines, without noticeable performance drop.",
        "bibtex": "@InProceedings{pmlr-v80-jin18d,\n  title = \t {{WSN}et: Compact and Efficient Networks Through Weight Sampling},\n  author =       {Jin, Xiaojie and Yang, Yingzhen and Xu, Ning and Yang, Jianchao and Jojic, Nebojsa and Feng, Jiashi and Yan, Shuicheng},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {2352--2361},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/jin18d/jin18d.pdf},\n  url = \t {https://proceedings.mlr.press/v80/jin18d.html},\n  abstract = \t {We present a new approach and a novel architecture, termed WSNet, for learning compact and efficient deep neural networks. Existing approaches conventionally learn full model parameters independently and then compress them via ad hoc processing such as model pruning or filter factorization. Alternatively, WSNet proposes learning model parameters by sampling from a compact set of learnable parameters, which naturally enforces parameter sharing throughout the learning process. We demonstrate that such a novel weight sampling approach (and induced WSNet) promotes both weights and computation sharing favorably. By employing this method, we can more efficiently learn much smaller networks with competitive performance compared to baseline networks with equal numbers of convolution filters. Specifically, we consider learning compact and efficient 1D convolutional neural networks for audio classification. Extensive experiments on multiple audio classification datasets verify the effectiveness of WSNet. Combined with weight quantization, the resulted models are up to 180x smaller and theoretically up to 16x faster than the well-established baselines, without noticeable performance drop.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/jin18d/jin18d.pdf",
        "supp": "",
        "pdf_size": 910255,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7505777960129682502&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "National University of Singapore; Snap Inc. Research; Snap Inc. Research; Bytedance Inc.; Microsoft Research; National University of Singapore; 360 AI Institute",
        "aff_domain": "gmail.com; ; ; ; ; ; ",
        "email": "gmail.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/jin18d.html",
        "aff_unique_index": "0;1;1;2;3;0;4",
        "aff_unique_norm": "National University of Singapore;Snap Inc.;Bytedance Inc.;Microsoft;360 AI Institute",
        "aff_unique_dep": ";Research;;Microsoft Research;",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.snap.com;https://www.bytedance.com;https://www.microsoft.com/en-us/research;",
        "aff_unique_abbr": "NUS;Snap;Bytedance;MSR;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;1;0;2",
        "aff_country_unique": "Singapore;United States;China"
    },
    {
        "title": "Weakly Consistent Optimal Pricing Algorithms in Repeated Posted-Price Auctions with Strategic Buyer",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1911",
        "id": "1911",
        "author": "Alexey Drutsa",
        "abstract": "We study revenue optimization learning algorithms for repeated posted-price auctions where a seller interacts with a single strategic buyer that holds a fixed private valuation for a good and seeks to maximize his cumulative discounted surplus. We propose a novel algorithm that never decreases offered prices and has a tight strategic regret bound of $\\Theta(\\log\\log T)$. This result closes the open research question on the existence of a no-regret horizon-independent weakly consistent pricing. We also show that the property of non-decreasing prices is nearly necessary for a weakly consistent algorithm to be a no-regret one.",
        "bibtex": "@InProceedings{pmlr-v80-drutsa18a,\n  title = \t {Weakly Consistent Optimal Pricing Algorithms in Repeated Posted-Price Auctions with Strategic Buyer},\n  author =       {Drutsa, Alexey},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {1319--1328},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/drutsa18a/drutsa18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/drutsa18a.html},\n  abstract = \t {We study revenue optimization learning algorithms for repeated posted-price auctions where a seller interacts with a single strategic buyer that holds a fixed private valuation for a good and seeks to maximize his cumulative discounted surplus. We propose a novel algorithm that never decreases offered prices and has a tight strategic regret bound of $\\Theta(\\log\\log T)$. This result closes the open research question on the existence of a no-regret horizon-independent weakly consistent pricing. We also show that the property of non-decreasing prices is nearly necessary for a weakly consistent algorithm to be a no-regret one.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/drutsa18a/drutsa18a.pdf",
        "supp": "",
        "pdf_size": 372258,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7950431938184491800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Yandex, Moscow, Russia+Faculty of Mechanics and Mathematics, Lomonosov Moscow State University, Moscow, Russia",
        "aff_domain": "yandex.ru",
        "email": "yandex.ru",
        "github": "",
        "project": "",
        "author_num": 1,
        "oa": "https://proceedings.mlr.press/v80/drutsa18a.html",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "Yandex;Lomonosov Moscow State University",
        "aff_unique_dep": ";Faculty of Mechanics and Mathematics",
        "aff_unique_url": "https://yandex.com;https://www.msu.ru",
        "aff_unique_abbr": "Yandex;MSU",
        "aff_campus_unique_index": "0+0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "title": "Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2031",
        "id": "2031",
        "author_site": "Lin Chen, Moran Feldman, Amin Karbasi",
        "author": "Lin Chen; Moran Feldman; Amin Karbasi",
        "abstract": "Submodular functions are a broad class of set functions that naturally arise in many machine learning applications. Due to their combinatorial structures, there has been a myriad of algorithms for maximizing such functions under various constraints. Unfortunately, once a function deviates from submodularity (even slightly), the known algorithms may perform arbitrarily poorly. Amending this issue, by obtaining approximation results for functions obeying properties that generalize submodularity, has been the focus of several recent works. One such class, known as weakly submodular functions, has received a lot of recent attention from the machine learning community due to its strong connections to restricted strong convexity and sparse reconstruction. In this paper, we prove that a randomized version of the greedy algorithm achieves an approximation ratio of $(1 + 1/\\gamma )^{-2}$ for weakly submodular maximization subject to a general matroid constraint, where $\\gamma$ is a parameter measuring the distance from submodularity. To the best of our knowledge, this is the first algorithm with a non-trivial approximation guarantee for this constrained optimization problem. Moreover, our experimental results show that our proposed algorithm performs well in a variety of real-world problems, including regression, video summarization, splice site detection, and black-box interpretation.",
        "bibtex": "@InProceedings{pmlr-v80-chen18b,\n  title = \t {Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?},\n  author =       {Chen, Lin and Feldman, Moran and Karbasi, Amin},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {804--813},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/chen18b/chen18b.pdf},\n  url = \t {https://proceedings.mlr.press/v80/chen18b.html},\n  abstract = \t {Submodular functions are a broad class of set functions that naturally arise in many machine learning applications. Due to their combinatorial structures, there has been a myriad of algorithms for maximizing such functions under various constraints. Unfortunately, once a function deviates from submodularity (even slightly), the known algorithms may perform arbitrarily poorly. Amending this issue, by obtaining approximation results for functions obeying properties that generalize submodularity, has been the focus of several recent works. One such class, known as weakly submodular functions, has received a lot of recent attention from the machine learning community due to its strong connections to restricted strong convexity and sparse reconstruction. In this paper, we prove that a randomized version of the greedy algorithm achieves an approximation ratio of $(1 + 1/\\gamma )^{-2}$ for weakly submodular maximization subject to a general matroid constraint, where $\\gamma$ is a parameter measuring the distance from submodularity. To the best of our knowledge, this is the first algorithm with a non-trivial approximation guarantee for this constrained optimization problem. Moreover, our experimental results show that our proposed algorithm performs well in a variety of real-world problems, including regression, video summarization, splice site detection, and black-box interpretation.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/chen18b/chen18b.pdf",
        "supp": "",
        "pdf_size": 5045033,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6667074900582022073&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Yale Institute for Network Science, Yale University, New Haven, CT, USA+Department of Electrical Engineering, Yale University; Department of Mathematics and Computer Science, Open University of Israel, Ra'anana, Israel; Yale Institute for Network Science, Yale University, New Haven, CT, USA+Department of Electrical Engineering, Yale University",
        "aff_domain": "yale.edu; ;yale.edu",
        "email": "yale.edu; ;yale.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/chen18b.html",
        "aff_unique_index": "0+0;1;0+0",
        "aff_unique_norm": "Yale University;Open University of Israel",
        "aff_unique_dep": "Yale Institute for Network Science;Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.yale.edu;https://www.openu.ac.il",
        "aff_unique_abbr": "Yale;OUI",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "New Haven;;Ra'anana",
        "aff_country_unique_index": "0+0;1;0+0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "title": "Weightless: Lossy weight encoding for deep neural network compression",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2218",
        "id": "2218",
        "author_site": "Brandon Reagen, Udit Gupta, Bob Adolf, Michael Mitzenmacher, Alexander Rush, Gu-Yeon Wei, David Brooks",
        "author": "Brandon Reagan; Udit Gupta; Bob Adolf; Michael Mitzenmacher; Alexander Rush; Gu-Yeon Wei; David Brooks",
        "abstract": "The large memory requirements of deep neural networks limit their deployment and adoption on many devices. Model compression methods effectively reduce the memory requirements of these models, usually through applying transformations such as weight pruning or quantization. In this paper, we present a novel scheme for lossy weight encoding co-designed with weight simplification techniques. The encoding is based on the Bloomier filter, a probabilistic data structure that can save space at the cost of introducing random errors. Leveraging the ability of neural networks to tolerate these imperfections and by re-training around the errors, the proposed technique, named Weightless, can compress weights by up to 496x without loss of model accuracy. This results in up to a 1.51x improvement over the state-of-the-art.",
        "bibtex": "@InProceedings{pmlr-v80-reagan18a,\n  title = \t {Weightless: Lossy weight encoding for deep neural network compression},\n  author =       {Reagan, Brandon and Gupta, Udit and Adolf, Bob and Mitzenmacher, Michael and Rush, Alexander and Wei, Gu-Yeon and Brooks, David},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {4324--4333},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/reagan18a/reagan18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/reagan18a.html},\n  abstract = \t {The large memory requirements of deep neural networks limit their deployment and adoption on many devices. Model compression methods effectively reduce the memory requirements of these models, usually through applying transformations such as weight pruning or quantization. In this paper, we present a novel scheme for lossy weight encoding co-designed with weight simplification techniques. The encoding is based on the Bloomier filter, a probabilistic data structure that can save space at the cost of introducing random errors. Leveraging the ability of neural networks to tolerate these imperfections and by re-training around the errors, the proposed technique, named Weightless, can compress weights by up to 496x without loss of model accuracy. This results in up to a 1.51x improvement over the state-of-the-art.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/reagan18a/reagan18a.pdf",
        "supp": "",
        "pdf_size": 577010,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15524028552507582001&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Harvard University; Harvard University; Harvard University; Harvard University; Harvard University; Harvard University+Facebook; Harvard University+Facebook",
        "aff_domain": "fas.harvard.edu; ; ; ; ; ; ",
        "email": "fas.harvard.edu; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "oa": "https://proceedings.mlr.press/v80/reagan18a.html",
        "aff_unique_index": "0;0;0;0;0;0+1;0+1",
        "aff_unique_norm": "Harvard University;Meta",
        "aff_unique_dep": ";Facebook, Inc.",
        "aff_unique_url": "https://www.harvard.edu;https://www.facebook.com",
        "aff_unique_abbr": "Harvard;FB",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Which Training Methods for GANs do actually Converge?",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/1900",
        "id": "1900",
        "author_site": "Lars Mescheder, Andreas Geiger, Sebastian Nowozin",
        "author": "Lars Mescheder; Andreas Geiger; Sebastian Nowozin",
        "abstract": "Recent work has shown local convergence of GAN training for absolutely continuous data and generator distributions. In this paper, we show that the requirement of absolute continuity is necessary: we describe a simple yet prototypical counterexample showing that in the more realistic case of distributions that are not absolutely continuous, unregularized GAN training is not always convergent. Furthermore, we discuss regularization strategies that were recently proposed to stabilize GAN training. Our analysis shows that GAN training with instance noise or zero-centered gradient penalties converges. On the other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number of discriminator updates per generator update do not always converge to the equilibrium point. We discuss these results, leading us to a new explanation for the stability problems of GAN training. Based on our analysis, we extend our convergence results to more general GANs and prove local convergence for simplified gradient penalties even if the generator and data distributions lie on lower dimensional manifolds. We find these penalties to work well in practice and use them to learn high-resolution generative image models for a variety of datasets with little hyperparameter tuning.",
        "bibtex": "@InProceedings{pmlr-v80-mescheder18a,\n  title = \t {Which Training Methods for {GAN}s do actually Converge?},\n  author =       {Mescheder, Lars and Geiger, Andreas and Nowozin, Sebastian},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3481--3490},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/mescheder18a/mescheder18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/mescheder18a.html},\n  abstract = \t {Recent work has shown local convergence of GAN training for absolutely continuous data and generator distributions. In this paper, we show that the requirement of absolute continuity is necessary: we describe a simple yet prototypical counterexample showing that in the more realistic case of distributions that are not absolutely continuous, unregularized GAN training is not always convergent. Furthermore, we discuss regularization strategies that were recently proposed to stabilize GAN training. Our analysis shows that GAN training with instance noise or zero-centered gradient penalties converges. On the other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number of discriminator updates per generator update do not always converge to the equilibrium point. We discuss these results, leading us to a new explanation for the stability problems of GAN training. Based on our analysis, we extend our convergence results to more general GANs and prove local convergence for simplified gradient penalties even if the generator and data distributions lie on lower dimensional manifolds. We find these penalties to work well in practice and use them to learn high-resolution generative image models for a variety of datasets with little hyperparameter tuning.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/mescheder18a/mescheder18a.pdf",
        "supp": "",
        "pdf_size": 540903,
        "gs_citation": 1800,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11334901664651510839&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "MPI T\u00fcbingen, Germany+ETH Z\u00fcrich, Switzerland; MPI T\u00fcbingen, Germany+ETH Z\u00fcrich, Switzerland; Microsoft Research, Cambridge, UK",
        "aff_domain": "tue.mpg.de; ; ",
        "email": "tue.mpg.de; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "oa": "https://proceedings.mlr.press/v80/mescheder18a.html",
        "aff_unique_index": "0+1;0+1;2",
        "aff_unique_norm": "Max Planck Institute for Biological Cybernetics;ETH Zurich;Microsoft",
        "aff_unique_dep": ";;Microsoft Research",
        "aff_unique_url": "https://www.mpi-cbg.de;https://www.ethz.ch;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "MPI;ETHZ;MSR",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "T\u00fcbingen;;Cambridge",
        "aff_country_unique_index": "0+1;0+1;2",
        "aff_country_unique": "Germany;Switzerland;United Kingdom"
    },
    {
        "title": "Yes, but Did It Work?: Evaluating Variational Inference",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2055",
        "id": "2055",
        "author_site": "Yuling Yao, Aki Vehtari, Daniel Simpson, Andrew Gelman",
        "author": "Yuling Yao; Aki Vehtari; Daniel Simpson; Andrew Gelman",
        "abstract": "While it\u2019s always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation. We propose two diagnostic algorithms to alleviate this problem. The Pareto-smoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulation-based calibration (VSBC) assesses the average performance of point estimates.",
        "bibtex": "@InProceedings{pmlr-v80-yao18a,\n  title = \t {Yes, but Did It Work?: Evaluating Variational Inference},\n  author =       {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {5581--5590},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/yao18a/yao18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/yao18a.html},\n  abstract = \t {While it\u2019s always possible to compute a variational approximation to a posterior distribution, it can be difficult to discover problems with this approximation. We propose two diagnostic algorithms to alleviate this problem. The Pareto-smoothed importance sampling (PSIS) diagnostic gives a goodness of fit measurement for joint distributions, while simultaneously improving the error in the estimate. The variational simulation-based calibration (VSBC) assesses the average performance of point estimates.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/yao18a/yao18a.pdf",
        "supp": "",
        "pdf_size": 657359,
        "gs_citation": 199,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16612262779014542273&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Statistics, Columbia University, NY, USA; Helsinki Institute for Information Technology, Department of Computer Science, Aalto University, Finland; Department of Statistical Sciences, University of Toronto, Canada; Department of Statistics, Columbia University, NY, USA",
        "aff_domain": "columbia.edu; ; ; ",
        "email": "columbia.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/yao18a.html",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Columbia University;Aalto University;University of Toronto",
        "aff_unique_dep": "Department of Statistics;Department of Computer Science;Department of Statistical Sciences",
        "aff_unique_url": "https://www.columbia.edu;https://www.aalto.fi;https://www.utoronto.ca",
        "aff_unique_abbr": "Columbia;Aalto;U of T",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "New York;Helsinki;",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United States;Finland;Canada"
    },
    {
        "title": "oi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2410",
        "id": "2410",
        "author_site": "Samuel Ainsworth, Nicholas J Foti, Adrian KC Lee, Emily Fox",
        "author": "Samuel K. Ainsworth; Nicholas J. Foti; Adrian K. C. Lee; Emily B. Fox",
        "abstract": "Deep generative models have recently yielded encouraging results in producing subjectively realistic samples of complex data. Far less attention has been paid to making these generative models interpretable. In many scenarios, ranging from scientific applications to finance, the observed variables have a natural grouping. It is often of interest to understand systems of interaction amongst these groups, and latent factor models (LFMs) are an attractive approach. However, traditional LFMs are limited by assuming a linear correlation structure. We present an output interpretable VAE (oi-VAE) for grouped data that models complex, nonlinear latent-to-observed relationships. We combine a structured VAE comprised of group-specific generators with a sparsity-inducing prior. We demonstrate that oi-VAE yields meaningful notions of interpretability in the analysis of motion capture and MEG data. We further show that in these situations, the regularization inherent to oi-VAE can actually lead to improved generalization and learned generative processes.",
        "bibtex": "@InProceedings{pmlr-v80-ainsworth18a,\n  title = \t {oi-{VAE}: Output Interpretable {VAE}s for Nonlinear Group Factor Analysis},\n  author =       {Ainsworth, Samuel K. and Foti, Nicholas J. and Lee, Adrian K. C. and Fox, Emily B.},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {119--128},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/ainsworth18a/ainsworth18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/ainsworth18a.html},\n  abstract = \t {Deep generative models have recently yielded encouraging results in producing subjectively realistic samples of complex data. Far less attention has been paid to making these generative models interpretable. In many scenarios, ranging from scientific applications to finance, the observed variables have a natural grouping. It is often of interest to understand systems of interaction amongst these groups, and latent factor models (LFMs) are an attractive approach. However, traditional LFMs are limited by assuming a linear correlation structure. We present an output interpretable VAE (oi-VAE) for grouped data that models complex, nonlinear latent-to-observed relationships. We combine a structured VAE comprised of group-specific generators with a sparsity-inducing prior. We demonstrate that oi-VAE yields meaningful notions of interpretability in the analysis of motion capture and MEG data. We further show that in these situations, the regularization inherent to oi-VAE can actually lead to improved generalization and learned generative processes.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/ainsworth18a/ainsworth18a.pdf",
        "supp": "",
        "pdf_size": 1314823,
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5681439984340511156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Paul G. Allen School of Computer Science and Engineering, University of Washington; Paul G. Allen School of Computer Science and Engineering, University of Washington; Institute for Learning & Brain Sciences and Department of Speech and Hearing Sciences, University of Washington; Paul G. Allen School of Computer Science and Engineering, University of Washington",
        "aff_domain": "gmail.com;uw.edu;uw.edu;uw.edu",
        "email": "gmail.com;uw.edu;uw.edu;uw.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/ainsworth18a.html",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Paul G. Allen School of Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "prDeep: Robust Phase Retrieval with a Flexible Deep Network",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2480",
        "id": "2480",
        "author_site": "Christopher Metzler, Phillip Schniter, Ashok Veeraraghavan, Richard Baraniuk",
        "author": "Christopher Metzler; Phillip Schniter; Ashok Veeraraghavan; Richard Baraniuk",
        "abstract": "Phase retrieval algorithms have become an important component in many modern computational imaging systems. For instance, in the context of ptychography and speckle correlation imaging, they enable imaging past the diffraction limit and through scattering media, respectively. Unfortunately, traditional phase retrieval algorithms struggle in the presence of noise. Progress has been made recently on developing more robust algorithms using signal priors, but at the expense of limiting the range of supported measurement models (e.g., to Gaussian or coded diffraction patterns). In this work we leverage the regularization-by-denoising framework and a convolutional neural network denoiser to create prDeep, a new phase retrieval algorithm that is both robust and broadly applicable. We test and validate prDeep in simulation to demonstrate that it is robust to noise and can handle a variety of system models.",
        "bibtex": "@InProceedings{pmlr-v80-metzler18a,\n  title = \t {pr{D}eep: Robust Phase Retrieval with a Flexible Deep Network},\n  author =       {Metzler, Christopher and Schniter, Phillip and Veeraraghavan, Ashok and Baraniuk, Richard},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {3501--3510},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/metzler18a/metzler18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/metzler18a.html},\n  abstract = \t {Phase retrieval algorithms have become an important component in many modern computational imaging systems. For instance, in the context of ptychography and speckle correlation imaging, they enable imaging past the diffraction limit and through scattering media, respectively. Unfortunately, traditional phase retrieval algorithms struggle in the presence of noise. Progress has been made recently on developing more robust algorithms using signal priors, but at the expense of limiting the range of supported measurement models (e.g., to Gaussian or coded diffraction patterns). In this work we leverage the regularization-by-denoising framework and a convolutional neural network denoiser to create prDeep, a new phase retrieval algorithm that is both robust and broadly applicable. We test and validate prDeep in simulation to demonstrate that it is robust to noise and can handle a variety of system models.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/metzler18a/metzler18a.pdf",
        "supp": "",
        "pdf_size": 2745323,
        "gs_citation": 250,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13840213498750434607&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical and Computer Engineering, Rice University, Houston, TX; The Ohio State University, Columbus, OH; Department of Electrical and Computer Engineering, Rice University, Houston, TX; Department of Electrical and Computer Engineering, Rice University, Houston, TX",
        "aff_domain": "rice.edu; ; ; ",
        "email": "rice.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/metzler18a.html",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Rice University;Ohio State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.rice.edu;https://www.osu.edu",
        "aff_unique_abbr": "Rice;OSU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Houston;Columbus",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "signSGD: Compressed Optimisation for Non-Convex Problems",
        "status": "Oral",
        "track": "main",
        "site": "https://icml.cc/virtual/2018/poster/2356",
        "id": "2356",
        "author_site": "Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, Anima Anandkumar",
        "author": "Jeremy Bernstein; Yu-Xiang Wang; Kamyar Azizzadenesheli; Animashree Anandkumar",
        "abstract": "Training large neural networks requires distributing learning across multiple workers, where the cost of communicating gradients can be a significant bottleneck. signSGD alleviates this problem by transmitting just the sign of each minibatch stochastic gradient. We prove that it can get the best of both worlds: compressed gradients and SGD-level convergence rate. The relative $\\ell_1/\\ell_2$ geometry of gradients, noise and curvature informs whether signSGD or SGD is theoretically better suited to a particular problem. On the practical side we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models. We extend our theory to the distributed setting, where the parameter server uses majority vote to aggregate gradient signs from each worker enabling 1-bit compression of worker-server communication in both directions. Using a theorem by Gauss we prove that majority vote can achieve the same reduction in variance as full precision distributed SGD. Thus, there is great promise for sign-based optimisation schemes to achieve fast communication and fast convergence. Code to reproduce experiments is to be found at https://github.com/jxbz/signSGD.",
        "bibtex": "@InProceedings{pmlr-v80-bernstein18a,\n  title = \t {sign{SGD}: Compressed Optimisation for Non-Convex Problems},\n  author =       {Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},\n  booktitle = \t {Proceedings of the 35th International Conference on Machine Learning},\n  pages = \t {560--569},\n  year = \t {2018},\n  editor = \t {Dy, Jennifer and Krause, Andreas},\n  volume = \t {80},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {10--15 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v80/bernstein18a/bernstein18a.pdf},\n  url = \t {https://proceedings.mlr.press/v80/bernstein18a.html},\n  abstract = \t {Training large neural networks requires distributing learning across multiple workers, where the cost of communicating gradients can be a significant bottleneck. signSGD alleviates this problem by transmitting just the sign of each minibatch stochastic gradient. We prove that it can get the best of both worlds: compressed gradients and SGD-level convergence rate. The relative $\\ell_1/\\ell_2$ geometry of gradients, noise and curvature informs whether signSGD or SGD is theoretically better suited to a particular problem. On the practical side we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models. We extend our theory to the distributed setting, where the parameter server uses majority vote to aggregate gradient signs from each worker enabling 1-bit compression of worker-server communication in both directions. Using a theorem by Gauss we prove that majority vote can achieve the same reduction in variance as full precision distributed SGD. Thus, there is great promise for sign-based optimisation schemes to achieve fast communication and fast convergence. Code to reproduce experiments is to be found at https://github.com/jxbz/signSGD.}\n}",
        "pdf": "http://proceedings.mlr.press/v80/bernstein18a/bernstein18a.pdf",
        "supp": "",
        "pdf_size": 656094,
        "gs_citation": 1258,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2554335502701113649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Caltech; Amazon AI; UC Santa Barbara; UC Irvine",
        "aff_domain": "caltech.edu;amazon.edu; ; ",
        "email": "caltech.edu;amazon.edu; ; ",
        "github": "https://github.com/jxbz/signSGD",
        "project": "",
        "author_num": 4,
        "oa": "https://proceedings.mlr.press/v80/bernstein18a.html",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "California Institute of Technology;Amazon;University of California, Santa Barbara;University of California, Irvine",
        "aff_unique_dep": ";Amazon AI;;",
        "aff_unique_url": "https://www.caltech.edu;https://www.amazon.com;https://www.ucsb.edu;https://www.uci.edu",
        "aff_unique_abbr": "Caltech;Amazon;UCSB;UCI",
        "aff_campus_unique_index": "0;2;3",
        "aff_campus_unique": "Pasadena;;Santa Barbara;Irvine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    }
]