[
    {
        "id": "c0c5e1d2bd",
        "title": "3D Manifold Topology Based Medical Image Data\r Augmentation",
        "site": "https://proceedings.mlr.press/v189/huang23a.html",
        "author": "Jisui Huang; Na Lei",
        "abstract": "Data augmentation is an effective and universal\r technique for improving the generalization\r performance of deep neural networks. Current data\r augmentation implementations usually involve\r geometric and photometric transformations. However,\r none of them considers the topological information\r in images, which is an important global invariant of\r the three-dimensional manifold. In our\r implementation, we design a novel method that finds\r the generator of the first homology group,\r i.e. closed loops cannot shrink to a point, of 3D\r image and erases the bounding box of a random\r loop. To the best of our knowledge, it is the first\r time that data augmentation based on the first\r homology group of the three-dimensional image is\r applied in medical image augmentation. Our numerical\r experiments demonstrate that the proposed approach\r outperforms the state-of-the-art method.",
        "bibtex": "@InProceedings{pmlr-v189-huang23a,\n  title = \t {3D Manifold Topology Based Medical Image Data\r Augmentation},\n  author =       {Huang, Jisui and Lei, Na},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {499--514},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/huang23a/huang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/huang23a.html},\n  abstract = \t {Data augmentation is an effective and universal\r technique for improving the generalization\r performance of deep neural networks. Current data\r augmentation implementations usually involve\r geometric and photometric transformations. However,\r none of them considers the topological information\r in images, which is an important global invariant of\r the three-dimensional manifold. In our\r implementation, we design a novel method that finds\r the generator of the first homology group,\r i.e. closed loops cannot shrink to a point, of 3D\r image and erases the bounding box of a random\r loop. To the best of our knowledge, it is the first\r time that data augmentation based on the first\r homology group of the three-dimensional image is\r applied in medical image augmentation. Our numerical\r experiments demonstrate that the proposed approach\r outperforms the state-of-the-art method.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/huang23a/huang23a.pdf",
        "supp": "",
        "pdf_size": 6119899,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:HxjwHc7XnMQJ:scholar.google.com/&scioq=3D+Manifold+Topology+Based+Medical+Image+Data%0D+Augmentation&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "aff": "Beijing Advanced Innovation Center for Imaging Theory and Technology, Capital Normal University, Beijing; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian",
        "aff_domain": "cnu.edu.cn;dlut.edu.cn",
        "email": "cnu.edu.cn;dlut.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Capital Normal University;Dalian University of Technology",
        "aff_unique_dep": "Beijing Advanced Innovation Center for Imaging Theory and Technology;Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province",
        "aff_unique_url": "http://www.cnu.edu.cn;http://www.dlut.edu.cn",
        "aff_unique_abbr": "CNU;DUT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Beijing;Dalian",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "1978021973",
        "title": "A Novel Differentiable Mixed-Precision Quantization\r Search Framework for Alleviating the Matthew Effect\r and Improving Robustness",
        "site": "https://proceedings.mlr.press/v189/zhou23a.html",
        "author": "Hengyi Zhou; Hongyi He; Wanchen Liu; Yuhai Li; Haonan Zhang; Longjun Liu",
        "abstract": "Network quantization is an effective and widely-used\r model compression technique. Recently, several works\r apply differentiable neural architectural search\r (NAS) methods to mixed-precision quantization (MPQ)\r and achieve encouraging results. However, the nature\r of differentiable architecture search can lead to\r the Matthew Effect in the mixed-precision. The\r candidates with higher bit-widths would be trained\r maturely earlier while the candidates with lower\r bit-widths may never have the chance to express the\r desired function. To address this issue, we propose\r a novel mixed-precision quantization framework. The\r mixed-precision search is resolved as a distribution\r learning problem, which alleviates the Matthew\r effect and improves the generalization\r ability. Meanwhile, different from generic\r differentiable NAS methods, search space will grow\r rapidly as the depth of the network increases in the\r mixed-precision quantization search. This makes the\r supernet harder to train and the search process\r unstable. To this end, we add a skip connection with\r a gradually decreasing architecture weight between\r convolutional layers in the supernet to improve\r robustness. The skip connection will help the\r optimization of the search process and will not\r participate in the bit width competition. Extensive\r experiments on CIFAR-10 and ImageNet demonstrate the\r effectiveness of the proposed methods. For example,\r when quantizing ResNet-50 on ImageNet, we achieve a\r state-of-the-art 156.10x Bitops compression rate\r while maintaining a 75.87$%$ accuracy.",
        "bibtex": "@InProceedings{pmlr-v189-zhou23a,\n  title = \t {A Novel Differentiable Mixed-Precision Quantization\r Search Framework for Alleviating the Matthew Effect\r and Improving Robustness},\n  author =       {Zhou, Hengyi and He, Hongyi and Liu, Wanchen and Li, Yuhai and Zhang, Haonan and Liu, Longjun},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1277--1292},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/zhou23a/zhou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/zhou23a.html},\n  abstract = \t {Network quantization is an effective and widely-used\r model compression technique. Recently, several works\r apply differentiable neural architectural search\r (NAS) methods to mixed-precision quantization (MPQ)\r and achieve encouraging results. However, the nature\r of differentiable architecture search can lead to\r the Matthew Effect in the mixed-precision. The\r candidates with higher bit-widths would be trained\r maturely earlier while the candidates with lower\r bit-widths may never have the chance to express the\r desired function. To address this issue, we propose\r a novel mixed-precision quantization framework. The\r mixed-precision search is resolved as a distribution\r learning problem, which alleviates the Matthew\r effect and improves the generalization\r ability. Meanwhile, different from generic\r differentiable NAS methods, search space will grow\r rapidly as the depth of the network increases in the\r mixed-precision quantization search. This makes the\r supernet harder to train and the search process\r unstable. To this end, we add a skip connection with\r a gradually decreasing architecture weight between\r convolutional layers in the supernet to improve\r robustness. The skip connection will help the\r optimization of the search process and will not\r participate in the bit width competition. Extensive\r experiments on CIFAR-10 and ImageNet demonstrate the\r effectiveness of the proposed methods. For example,\r when quantizing ResNet-50 on ImageNet, we achieve a\r state-of-the-art 156.10x Bitops compression rate\r while maintaining a 75.87$%$ accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/zhou23a/zhou23a.pdf",
        "supp": "",
        "pdf_size": 581497,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:gQmsrJiwMRkJ:scholar.google.com/&scioq=A+Novel+Differentiable+Mixed-Precision+Quantization%0D+Search+Framework+for+Alleviating+the+Matthew+Effect%0D+and+Improving+Robustness&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; Science and Technology on Electro-Optical Information Security control Laboratory; Science and Technology on Electro-Optical Information Security control Laboratory; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University",
        "aff_domain": "stu.xjtu.edu.cn;stu.xjtu.edu.cn;cetc.com.cn;gmail.com;stu.xjtu.edu.cn;xjtu.edu.cn",
        "email": "stu.xjtu.edu.cn;stu.xjtu.edu.cn;cetc.com.cn;gmail.com;stu.xjtu.edu.cn;xjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University;Science and Technology on Electro-Optical Information Security control Laboratory",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics;",
        "aff_unique_url": "http://www.xjtu.edu.cn;",
        "aff_unique_abbr": "XJTU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xi'an;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "829eb48da0",
        "title": "A Novel Graph Aggregation Method Based on Feature\r Distribution Around Each Ego-node for Heterophily",
        "site": "https://proceedings.mlr.press/v189/haruta23a.html",
        "author": "Shuichiro Haruta; Tatsuya Konishi; Mori Kurokawa",
        "abstract": "In this paper, we propose a novel graph aggregation\r method based on feature distribution around each\r ego-node (a node to which features are aggregated)\r for heterophily. In heterophily graphs, labels of\r neighboring nodes can be uniformly distributed. In\r such case, aggregated features by existing GNNs will\r be always similar regardless of the label of\r ego-node and fail to capture useful information for\r a node classification task. Since the existing\r methods basically ignore label distribution around\r the ego-node, we attempt to handle heterophily\r graphs through dynamic aggregations so that nodes\r with similar vicinity characteristics exhibit\r similar behavior. In particular, we adjust the\r amount of aggregation based on the features\r generated by higher-order neighbors, since they\r reflect the label distribution around each\r ego-node. By doing this, we can take the influence\r of distant nodes into account while adapting local\r structures of each node. Extensive experiments\r demonstrate that the proposed method achieves higher\r performance in heterophily graphs by up to 14.68%\r compared with existing methods.",
        "bibtex": "@InProceedings{pmlr-v189-haruta23a,\n  title = \t {A Novel Graph Aggregation Method Based on Feature\r Distribution Around Each Ego-node for Heterophily},\n  author =       {Haruta, Shuichiro and Konishi, Tatsuya and Kurokawa, Mori},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {452--466},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/haruta23a/haruta23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/haruta23a.html},\n  abstract = \t {In this paper, we propose a novel graph aggregation\r method based on feature distribution around each\r ego-node (a node to which features are aggregated)\r for heterophily. In heterophily graphs, labels of\r neighboring nodes can be uniformly distributed. In\r such case, aggregated features by existing GNNs will\r be always similar regardless of the label of\r ego-node and fail to capture useful information for\r a node classification task. Since the existing\r methods basically ignore label distribution around\r the ego-node, we attempt to handle heterophily\r graphs through dynamic aggregations so that nodes\r with similar vicinity characteristics exhibit\r similar behavior. In particular, we adjust the\r amount of aggregation based on the features\r generated by higher-order neighbors, since they\r reflect the label distribution around each\r ego-node. By doing this, we can take the influence\r of distant nodes into account while adapting local\r structures of each node. Extensive experiments\r demonstrate that the proposed method achieves higher\r performance in heterophily graphs by up to 14.68%\r compared with existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/haruta23a/haruta23a.pdf",
        "supp": "",
        "pdf_size": 412203,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ObV4JkpV_cQJ:scholar.google.com/&scioq=A+Novel+Graph+Aggregation+Method+Based+on+Feature%0D+Distribution+Around+Each+Ego-node+for+Heterophily&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "KDDI Research, Inc. 2-1-15 Ohara, Fujimino-shi, Saitama, 356-8502, Japan; KDDI Research, Inc. 2-1-15 Ohara, Fujimino-shi, Saitama, 356-8502, Japan; KDDI Research, Inc. 2-1-15 Ohara, Fujimino-shi, Saitama, 356-8502, Japan",
        "aff_domain": "kddi.com;kddi.com;kddi.com",
        "email": "kddi.com;kddi.com;kddi.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KDDI Research, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kddi-research.com",
        "aff_unique_abbr": "KDDI Research",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "3b89791e6e",
        "title": "A Self-improving Skin Lesions Diagnosis Framework\r Via Pseudo-labeling and Self-distillation",
        "site": "https://proceedings.mlr.press/v189/deng23a.html",
        "author": "Shaochang Deng; Mengxiao Yin; Feng Yang",
        "abstract": "In the past few years, supervised-based deep\r learning methods has yielded good results in skin\r lesions diagnosis tasks. Unfortunately, obtaining\r large of labels for medical images is expensive and\r time consuming. In this paper, we propose a\r self-improving skin lesions diagnosis (SISLD)\r framework to explore useful information in unlabeled\r data. We first propose a semi-supervised model\r ${f}$, which combining consistency and\r class-balanced pseudo-labeling to make full use of\r unlabeled data in scenarios with sparse manually\r labeled samples, and obtain a teacher model\r ${f_{t}}$ by semi-supervised self-training. Then, we\r introduce self-distillation method to enable\r knowledge distillation for the diagnosis of skin\r lesions. Finally, we measure diagnostic\r effectiveness in the context of label sparsity and\r class imbalance. The experiments on skin lesion\r images dataset ISIC2018 shows that SISLD achieves\r significant improvements in AUC, Accuracy,\r Specificity and Sensitivity.",
        "bibtex": "@InProceedings{pmlr-v189-deng23a,\n  title = \t {A Self-improving Skin Lesions Diagnosis Framework\r Via Pseudo-labeling and Self-distillation},\n  author =       {Deng, Shaochang and Yin, Mengxiao and Yang, Feng},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {296--310},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/deng23a/deng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/deng23a.html},\n  abstract = \t {In the past few years, supervised-based deep\r learning methods has yielded good results in skin\r lesions diagnosis tasks. Unfortunately, obtaining\r large of labels for medical images is expensive and\r time consuming. In this paper, we propose a\r self-improving skin lesions diagnosis (SISLD)\r framework to explore useful information in unlabeled\r data. We first propose a semi-supervised model\r ${f}$, which combining consistency and\r class-balanced pseudo-labeling to make full use of\r unlabeled data in scenarios with sparse manually\r labeled samples, and obtain a teacher model\r ${f_{t}}$ by semi-supervised self-training. Then, we\r introduce self-distillation method to enable\r knowledge distillation for the diagnosis of skin\r lesions. Finally, we measure diagnostic\r effectiveness in the context of label sparsity and\r class imbalance. The experiments on skin lesion\r images dataset ISIC2018 shows that SISLD achieves\r significant improvements in AUC, Accuracy,\r Specificity and Sensitivity.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/deng23a/deng23a.pdf",
        "supp": "",
        "pdf_size": 4526709,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16387387199538458923&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "04e81e4542",
        "title": "A two-stream convolution architecture for ESC based\r on audio feature distanglement",
        "site": "https://proceedings.mlr.press/v189/chang23a.html",
        "author": "Zhenghao Chang; Ruhan He; Yongsheng Yu; Zili Zhang; GeLi Bai",
        "abstract": "ESC (Environmental Sound Classification) is an\r active area of research in the field of audio\r classification that has made significant progress in\r recent years. The current mainstream ESC methods are\r based on increasing the dimension of the extracted\r audio features and therefore draw on the\r two-dimensional convolution methods used in image\r processing. However, two-dimensional convolution is\r expensive to train and the complexity of the\r corresponding model is usually very high. In\r response to these issues, we propose a novel\r two-stream neural network model by the idea of\r disentanglement, which uses onedimensional\r convolution for feature extraction to disentangle\r the audio features into the time and frequency\r domains separately. Our approach balances\r computational pressure with classification accuracy\r well. The accuracy of our approach on the Urbansound\r 8k and Esc-10 datasets was 98.51% and 97.50%,\r respectively, which exceeds that of most\r models. Meanwhile, the model complexity is also\r lower.",
        "bibtex": "@InProceedings{pmlr-v189-chang23a,\n  title = \t {A two-stream convolution architecture for ESC based\r on audio feature distanglement},\n  author =       {Chang, Zhenghao and He, Ruhan and Yu, Yongsheng and Zhang, Zili and Bai, GeLi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {153--168},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/chang23a/chang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/chang23a.html},\n  abstract = \t { ESC (Environmental Sound Classification) is an\r active area of research in the field of audio\r classification that has made significant progress in\r recent years. The current mainstream ESC methods are\r based on increasing the dimension of the extracted\r audio features and therefore draw on the\r two-dimensional convolution methods used in image\r processing. However, two-dimensional convolution is\r expensive to train and the complexity of the\r corresponding model is usually very high. In\r response to these issues, we propose a novel\r two-stream neural network model by the idea of\r disentanglement, which uses onedimensional\r convolution for feature extraction to disentangle\r the audio features into the time and frequency\r domains separately. Our approach balances\r computational pressure with classification accuracy\r well. The accuracy of our approach on the Urbansound\r 8k and Esc-10 datasets was 98.51% and 97.50%,\r respectively, which exceeds that of most\r models. Meanwhile, the model complexity is also\r lower.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/chang23a/chang23a.pdf",
        "supp": "",
        "pdf_size": 904458,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10776307104571955044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Hubei Provincial Engineering Research Center for Intelligent Textile and Fashion (Wuhan Textile University); Hubei Provincial Engineering Research Center for Intelligent Textile and Fashion (Wuhan Textile University); State Key Laboratory of Silicate Materials for Architectures, Wuhan University of Technology; School of Computer Science and Artificial IntelligenceWuhan Textile University; College of Computer and Information Engineering, Inner Mongolia Agricultural University",
        "aff_domain": "QQ.com;wtu.edu.cn;whut.edu.cn;wtu.edu.cn;qq.com",
        "email": "QQ.com;wtu.edu.cn;whut.edu.cn;wtu.edu.cn;qq.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Wuhan Textile University;Wuhan University of Technology;Inner Mongolia Agricultural University",
        "aff_unique_dep": "Hubei Provincial Engineering Research Center for Intelligent Textile and Fashion;State Key Laboratory of Silicate Materials for Architectures;College of Computer and Information Engineering",
        "aff_unique_url": "http://www.wtu.edu.cn;http://www.wut.edu.cn;",
        "aff_unique_abbr": "WTU;;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wuhan;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "3f89d20504",
        "title": "AFRNN: Stable RNN with Top Down Feedback and\r Antisymmetry",
        "site": "https://proceedings.mlr.press/v189/schwabe23a.html",
        "author": "Tim Schwabe; Tobias Glasmachers; Maribel Acosta",
        "abstract": "Recurrent Neural Networks are an integral part of\r modern machine learning. They are good at performing\r tasks on sequential data. However, long sequences\r are still a problem for those models due to the\r well-known exploding/vanishing gradient problem. In\r this work, we build on recent approaches to\r interpreting the gradient problem as instability of\r the underlying dynamical system. We extend previous\r approaches to systems with top-down feedback, which\r is abundant in biological neural networks. We prove\r that the resulting system is stable for arbitrary\r depth and width and confirm this empirically. We\r further show that its performance is on par with\r LSTM and related approaches on standard benchmarks.",
        "bibtex": "@InProceedings{pmlr-v189-schwabe23a,\n  title = \t {AFRNN: Stable RNN with Top Down Feedback and\r Antisymmetry},\n  author =       {Schwabe, Tim and Glasmachers, Tobias and Acosta, Maribel},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {880--894},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/schwabe23a/schwabe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/schwabe23a.html},\n  abstract = \t {Recurrent Neural Networks are an integral part of\r modern machine learning. They are good at performing\r tasks on sequential data. However, long sequences\r are still a problem for those models due to the\r well-known exploding/vanishing gradient problem. In\r this work, we build on recent approaches to\r interpreting the gradient problem as instability of\r the underlying dynamical system. We extend previous\r approaches to systems with top-down feedback, which\r is abundant in biological neural networks. We prove\r that the resulting system is stable for arbitrary\r depth and width and confirm this empirically. We\r further show that its performance is on par with\r LSTM and related approaches on standard benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/schwabe23a/schwabe23a.pdf",
        "supp": "",
        "pdf_size": 983876,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:KE5HhHKPuOYJ:scholar.google.com/&scioq=AFRNN:+Stable+RNN+with+Top+Down+Feedback+and%0D+Antisymmetry&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Ruhr University Bochum, Faculty of Computer Science; Ruhr University Bochum, Faculty of Computer Science; Ruhr University Bochum, Faculty of Computer Science",
        "aff_domain": "rub.de;ini.rub.de;rub.de",
        "email": "rub.de;ini.rub.de;rub.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ruhr University Bochum",
        "aff_unique_dep": "Faculty of Computer Science",
        "aff_unique_url": "https://www.ruhr-uni-bochum.de",
        "aff_unique_abbr": "RUB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "252901c03c",
        "title": "AIIR-MIX: Multi-Agent Reinforcement Learning Meets\r Attention Individual Intrinsic Reward Mixing\r Network",
        "site": "https://proceedings.mlr.press/v189/li23d.html",
        "author": "Wei Li; Weiyan Liu; Shitong Shao; Shiyi Huang",
        "abstract": "Deducing the contribution of each agent and\r assigning the corresponding reward to them is a\r crucial problem in cooperative Multi-Agent\r Reinforcement Learning (MARL). Previous studies try\r to resolve the issue through designing an intrinsic\r reward function, but the intrinsic reward is simply\r combined with the environment reward by summation in\r these studies, which makes the performance of their\r MARL framework unsatisfactory. We propose a novel\r method named Attention Individual Intrinsic Reward\r Mixing Network (AIIR-MIX) in MARL, and the\r contributions of AIIR-MIX are listed as follows:\r \\textbf{(a)} we construct a novel intrinsic reward\r network based on the attention mechanism to make\r teamwork more effective. \\textbf{(b)} we propose a\r Mixing network that is able to combine intrinsic and\r extrinsic rewards non-linearly and dynamically in\r response to changing conditions of the\r environment. We compare AIIR-MIX with many\r State-Of-The-Art (SOTA) MARL methods on battle games\r in StarCraft II. And the results demonstrate that\r AIIR-MIX performs admirably and can defeat the\r current advanced methods on average test win\r rate. To validate the effectiveness of AIIR-MIX, we\r conduct additional ablation studies. The results\r show that AIIR-MIX can dynamically assign each agent\r a real-time intrinsic reward in accordance with\r their actual contribution.",
        "bibtex": "@InProceedings{pmlr-v189-li23d,\n  title = \t {AIIR-MIX: Multi-Agent Reinforcement Learning Meets\r Attention Individual Intrinsic Reward Mixing\r Network},\n  author =       {Li, Wei and Liu, Weiyan and Shao, Shitong and Huang, Shiyi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {579--594},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/li23d/li23d.pdf},\n  url = \t {https://proceedings.mlr.press/v189/li23d.html},\n  abstract = \t {Deducing the contribution of each agent and\r assigning the corresponding reward to them is a\r crucial problem in cooperative Multi-Agent\r Reinforcement Learning (MARL). Previous studies try\r to resolve the issue through designing an intrinsic\r reward function, but the intrinsic reward is simply\r combined with the environment reward by summation in\r these studies, which makes the performance of their\r MARL framework unsatisfactory. We propose a novel\r method named Attention Individual Intrinsic Reward\r Mixing Network (AIIR-MIX) in MARL, and the\r contributions of AIIR-MIX are listed as follows:\r \\textbf{(a)} we construct a novel intrinsic reward\r network based on the attention mechanism to make\r teamwork more effective. \\textbf{(b)} we propose a\r Mixing network that is able to combine intrinsic and\r extrinsic rewards non-linearly and dynamically in\r response to changing conditions of the\r environment. We compare AIIR-MIX with many\r State-Of-The-Art (SOTA) MARL methods on battle games\r in StarCraft II. And the results demonstrate that\r AIIR-MIX performs admirably and can defeat the\r current advanced methods on average test win\r rate. To validate the effectiveness of AIIR-MIX, we\r conduct additional ablation studies. The results\r show that AIIR-MIX can dynamically assign each agent\r a real-time intrinsic reward in accordance with\r their actual contribution.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/li23d/li23d.pdf",
        "supp": "",
        "pdf_size": 3649774,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10288010690747728788&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Instrument Science and Engieering, Southeast University, Nanjing, Jiangsu 210096, China; School of Instrument Science and Engieering, Southeast University, Nanjing, Jiangsu 210096, China; School of Instrument Science and Engieering, Southeast University, Nanjing, Jiangsu 210096, China; School of Instrument Science and Engieering, Southeast University, Nanjing, Jiangsu 210096, China",
        "aff_domain": "seu.edu.cn;seu.edu.cn;seu.edu.cn;seu.edu.cn",
        "email": "seu.edu.cn;seu.edu.cn;seu.edu.cn;seu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "223a9c084c",
        "title": "AS-IntroVAE: Adversarial Similarity Distance Makes\r Robust IntroVAE",
        "site": "https://proceedings.mlr.press/v189/changjie23a.html",
        "author": "Lu Changjie; Zheng Shen; Wang Zirui; Dib Omar; Gupta Gaurav",
        "abstract": "Recently, introspective models like IntroVAE and\r S-IntroVAE have excelled in image generation and\r reconstruction tasks. The principal characteristic\r of introspective models is the adversarial learning\r of VAE, where the encoder attempts to distinguish\r between the real and the fake (i.e., synthesized)\r images. However, due to the unavailability of an\r effective metric to evaluate the difference between\r the real and the fake images, the posterior collapse\r and the vanishing gradient problem still exist,\r reducing the fidelity of the synthesized images. In\r this paper, we propose a new variation of IntroVAE\r called Adversarial Similarity Distance Introspective\r Variational Autoencoder (AS-IntroVAE). We\r theoretically analyze the vanishing gradient problem\r and construct a new Adversarial Similarity Distance\r (AS-Distance) using the 2-Wasserstein distance and\r the kernel trick. With weight annealing on\r AS-Distance and KL-Divergence, the AS-IntroVAE are\r able to generate stable and high-quality images. The\r posterior collapse problem is addressed by making\r per-batch attempts to transform the image so that it\r better fits the prior distribution in the latent\r space. Compared with the per-image approach, this\r strategy fosters more diverse distributions in the\r latent space, allowing our model to produce images\r of great diversity. Comprehensive experiments on\r benchmark datasets demonstrate the effectiveness of\r AS-IntroVAE on image generation and reconstruction\r tasks.",
        "bibtex": "@InProceedings{pmlr-v189-changjie23a,\n  title = \t {AS-IntroVAE: Adversarial Similarity Distance Makes\r Robust IntroVAE},\n  author =       {Changjie, Lu and Shen, Zheng and Zirui, Wang and Omar, Dib and Gaurav, Gupta},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {658--673},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/changjie23a/changjie23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/changjie23a.html},\n  abstract = \t {Recently, introspective models like IntroVAE and\r S-IntroVAE have excelled in image generation and\r reconstruction tasks. The principal characteristic\r of introspective models is the adversarial learning\r of VAE, where the encoder attempts to distinguish\r between the real and the fake (i.e., synthesized)\r images. However, due to the unavailability of an\r effective metric to evaluate the difference between\r the real and the fake images, the posterior collapse\r and the vanishing gradient problem still exist,\r reducing the fidelity of the synthesized images. In\r this paper, we propose a new variation of IntroVAE\r called Adversarial Similarity Distance Introspective\r Variational Autoencoder (AS-IntroVAE). We\r theoretically analyze the vanishing gradient problem\r and construct a new Adversarial Similarity Distance\r (AS-Distance) using the 2-Wasserstein distance and\r the kernel trick. With weight annealing on\r AS-Distance and KL-Divergence, the AS-IntroVAE are\r able to generate stable and high-quality images. The\r posterior collapse problem is addressed by making\r per-batch attempts to transform the image so that it\r better fits the prior distribution in the latent\r space. Compared with the per-image approach, this\r strategy fosters more diverse distributions in the\r latent space, allowing our model to produce images\r of great diversity. Comprehensive experiments on\r benchmark datasets demonstrate the effectiveness of\r AS-IntroVAE on image generation and reconstruction\r tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/changjie23a/changjie23a.pdf",
        "supp": "",
        "pdf_size": 3741124,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3779771393143354077&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Wenzhou-Kean University, Wenzhou, China; Carnegie Mellon University, Pittsburgh, USA+Wenzhou-Kean University, Wenzhou, China; Zhejiang University, Hangzhou, China; Wenzhou-Kean University, Wenzhou, China; Wenzhou-Kean University, Wenzhou, China",
        "aff_domain": "kean.edu;andrew.cmu.edu;126.com;kean.edu;kean.edu",
        "email": "kean.edu;andrew.cmu.edu;126.com;kean.edu;kean.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;2;0;0",
        "aff_unique_norm": "Wenzhou-Kean University;Carnegie Mellon University;Zhejiang University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.wku.edu.cn;https://www.cmu.edu;http://www.zju.edu.cn",
        "aff_unique_abbr": ";CMU;ZJU",
        "aff_campus_unique_index": "0;1+0;2;0;0",
        "aff_campus_unique": "Wenzhou;Pittsburgh;Hangzhou",
        "aff_country_unique_index": "0;1+0;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "076076596f",
        "title": "Adversarial Laser Spot: Robust and Covert\r Physical-World Attack to DNNs",
        "site": "https://proceedings.mlr.press/v189/hu23b.html",
        "author": "Chengyin Hu; Yilong Wang; Kalibinuer Tiliwalidi; Wen Li",
        "abstract": "Most existing deep neural networks (DNNs) are easily\r disturbed by slight noise. However, there are few\r researches on physical attacks by deploying lighting\r equipment. The light-based physical attacks has\r excellent covertness, which brings great security\r risks to many vision-based applications (such as\r self-driving). Therefore, we propose a light-based\r physical attack, called adversarial laser spot\r (AdvLS), which optimizes the physical parameters of\r laser spots through genetic algorithm to perform\r physical attacks. It realizes robust and covert\r physical attack by using low-cost laser\r equipment. As far as we know, AdvLS is the first\r light-based physical attack that perform physical\r attacks in the daytime. A large number of\r experiments in the digital and physical environments\r show that AdvLS has excellent robustness and\r covertness. In addition, through in-depth analysis\r of the experimental data, we find that the\r adversarial perturbations generated by AdvLS have\r superior adversarial attack migration. The\r experimental results show that AdvLS impose serious\r interference to advanced DNNs, we call for the\r attention of the proposed AdvLS.",
        "bibtex": "@InProceedings{pmlr-v189-hu23b,\n  title = \t {Adversarial Laser Spot: Robust and Covert\r Physical-World Attack to DNNs},\n  author =       {Hu, Chengyin and Wang, Yilong and Tiliwalidi, Kalibinuer and Li, Wen},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {483--498},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/hu23b/hu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/hu23b.html},\n  abstract = \t {Most existing deep neural networks (DNNs) are easily\r disturbed by slight noise. However, there are few\r researches on physical attacks by deploying lighting\r equipment. The light-based physical attacks has\r excellent covertness, which brings great security\r risks to many vision-based applications (such as\r self-driving). Therefore, we propose a light-based\r physical attack, called adversarial laser spot\r (AdvLS), which optimizes the physical parameters of\r laser spots through genetic algorithm to perform\r physical attacks. It realizes robust and covert\r physical attack by using low-cost laser\r equipment. As far as we know, AdvLS is the first\r light-based physical attack that perform physical\r attacks in the daytime. A large number of\r experiments in the digital and physical environments\r show that AdvLS has excellent robustness and\r covertness. In addition, through in-depth analysis\r of the experimental data, we find that the\r adversarial perturbations generated by AdvLS have\r superior adversarial attack migration. The\r experimental results show that AdvLS impose serious\r interference to advanced DNNs, we call for the\r attention of the proposed AdvLS.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/hu23b/hu23b.pdf",
        "supp": "",
        "pdf_size": 5861862,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15040724227212945561&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Electronic Science and Technology of China; Chongqing Jiaotong University; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China",
        "aff_domain": "qq.com;163.com;qq.com;uestc.edu.cn",
        "email": "qq.com;163.com;qq.com;uestc.edu.cn",
        "github": "https://github.com/ChengYinHu/AdvLS",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Chongqing Jiao Tong University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uestc.edu.cn;http://www.cqjtu.edu.cn",
        "aff_unique_abbr": "UESTC;CQJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "b30eafd5eb",
        "title": "An Enhanced Human Activity Recognition Algorithm with Positional Attention",
        "site": "https://proceedings.mlr.press/v189/xu23a.html",
        "author": "Chenyang Xu; Jianfei Shen; Feiyi Fan; Tian Qiu; Zhihong Mao",
        "abstract": "Human activity recognition (HAR) attracts widespread attention from researchers recently, and deep learning is employed as a dominant paradigm of solving HAR problems. The previous techniques rely on domain knowledge or attention mechanism extract long-range dependency in temporal dimension and cross channel correlation in sensor\u2019s channel dimension. In this paper, a HAR model with positional attention (PA), termed as PA-HAR, is presented. To enhance the features in both sensor\u2019s channel and temporal dimensions, we propose to split the sensor signals into two 1D features to capture the long-range dependency along the temporal-axis and signal\u2019s cross-channel information along the sensor\u2019s channel-axis. Furthermore, we embed the features with positional information by encoding the generated features into pairs of temporal-aware and sensor\u2019s channel-aware attention maps and weighting the input feature maps. Extensive experiments based on five public datasets demonstrate that the proposed PA-HAR algorithm achieves a competitive performance in HAR related tasks compared with the state-of-the-art approaches.",
        "bibtex": "@InProceedings{pmlr-v189-xu23a,\n  title = \t {An Enhanced Human Activity Recognition Algorithm with Positional Attention},\n  author =       {Xu, Chenyang and Shen, Jianfei and Fan, Feiyi and Qiu, Tian and Mao, Zhihong},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1181--1196},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/xu23a/xu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/xu23a.html},\n  abstract = \t {Human activity recognition (HAR) attracts widespread attention from researchers recently, and deep learning is employed as a dominant paradigm of solving HAR problems. The previous techniques rely on domain knowledge or attention mechanism extract long-range dependency in temporal dimension and cross channel correlation in sensor\u2019s channel dimension. In this paper, a HAR model with positional attention (PA), termed as PA-HAR, is presented. To enhance the features in both sensor\u2019s channel and temporal dimensions, we propose to split the sensor signals into two 1D features to capture the long-range dependency along the temporal-axis and signal\u2019s cross-channel information along the sensor\u2019s channel-axis. Furthermore, we embed the features with positional information by encoding the generated features into pairs of temporal-aware and sensor\u2019s channel-aware attention maps and weighting the input feature maps. Extensive experiments based on five public datasets demonstrate that the proposed PA-HAR algorithm achieves a competitive performance in HAR related tasks compared with the state-of-the-art approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/xu23a/xu23a.pdf",
        "supp": "",
        "pdf_size": 737510,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4269027308387000183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Intelligent Manufacturing Department, Wu Yi University, Jiangmen, Guangdong, 529020, China+Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100090, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100090, China+Shandong Academy of Intelligent Computing Technology, Jinan, Shandong, 250102, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100090, China; Intelligent Manufacturing Department, Wu Yi University, Jiangmen, Guangdong, 529020, China; Intelligent Manufacturing Department, Wu Yi University, Jiangmen, Guangdong, 529020, China",
        "aff_domain": "gmail.com;ict.ac.cn;ict.ac.cn;hotmail.com;126.com",
        "email": "gmail.com;ict.ac.cn;ict.ac.cn;hotmail.com;126.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1+2;1;0;0",
        "aff_unique_norm": "Wu Yi University;Chinese Academy of Sciences;Shandong Academy of Intelligent Computing Technology",
        "aff_unique_dep": "Intelligent Manufacturing Department;Institute of Computing Technology;",
        "aff_unique_url": ";http://www.ict.ac.cn;",
        "aff_unique_abbr": ";CAS;",
        "aff_campus_unique_index": "0+1;1+2;1;0;0",
        "aff_campus_unique": "Jiangmen;Beijing;Jinan",
        "aff_country_unique_index": "0+0;0+0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8c2612c2ae",
        "title": "Asynchronous Personalized Federated Learning with\r Irregular Clients",
        "site": "https://proceedings.mlr.press/v189/ma23b.html",
        "author": "Zichen Ma; Yu Lu; Wenye Li; Shuguang Cui",
        "abstract": "To provide intelligent and personalized models for\r clients, personalized federated learning (PFL)\r enables learning from data, identifying patterns,\r and making automated decisions in a\r privacy-preserving manner. PFL involves independent\r training for multiple clients with synchronous\r aggregation steps. However, the assumptions made by\r existing works are not realistic given the\r heterogeneity of clients. In particular, the volume\r and distribution of collected data vary in the\r training process, and the clients also vary in their\r available system configurations, which leads to vast\r heterogeneity in the system. To address these\r challenges, we present an \\textit{asynchronous}\r method (AsyPFL), where clients learn personalized\r models w.r.t. local data by making the most\r informative parameters less volatile. The central\r server aggregates model parameters\r asynchronously. In addition, we also reformulate PFL\r by unifying both synchronous and asynchronous\r updating schemes with an asynchrony-related\r parameter. Theoretically, we show that AsyPFL\u2019s\r convergence rate is state-of-the-art and provide\r guarantees of choosing key hyperparameters\r optimally. With these theoretical guarantees, we\r validate AsyPFL on different tasks with non-IID and\r staleness settings. The results indicate that, given\r a large proportion of irregular clients, AsyPFL\r excels at empirical performance compared with\r vanilla PFL algorithms on non-IID and IID cases.",
        "bibtex": "@InProceedings{pmlr-v189-ma23b,\n  title = \t {Asynchronous Personalized Federated Learning with\r Irregular Clients},\n  author =       {Ma, Zichen and Lu, Yu and Li, Wenye and Cui, Shuguang},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {706--721},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/ma23b/ma23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/ma23b.html},\n  abstract = \t {To provide intelligent and personalized models for\r clients, personalized federated learning (PFL)\r enables learning from data, identifying patterns,\r and making automated decisions in a\r privacy-preserving manner. PFL involves independent\r training for multiple clients with synchronous\r aggregation steps. However, the assumptions made by\r existing works are not realistic given the\r heterogeneity of clients. In particular, the volume\r and distribution of collected data vary in the\r training process, and the clients also vary in their\r available system configurations, which leads to vast\r heterogeneity in the system. To address these\r challenges, we present an \\textit{asynchronous}\r method (AsyPFL), where clients learn personalized\r models w.r.t. local data by making the most\r informative parameters less volatile. The central\r server aggregates model parameters\r asynchronously. In addition, we also reformulate PFL\r by unifying both synchronous and asynchronous\r updating schemes with an asynchrony-related\r parameter. Theoretically, we show that AsyPFL\u2019s\r convergence rate is state-of-the-art and provide\r guarantees of choosing key hyperparameters\r optimally. With these theoretical guarantees, we\r validate AsyPFL on different tasks with non-IID and\r staleness settings. The results indicate that, given\r a large proportion of irregular clients, AsyPFL\r excels at empirical performance compared with\r vanilla PFL algorithms on non-IID and IID cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/ma23b/ma23b.pdf",
        "supp": "",
        "pdf_size": 888270,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3550650308661540244&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "JD AI Research, Beijing, China + The Chinese University of Hong Kong, Shenzhen, Guangdong, China; JD AI Research, Beijing, China + The Chinese University of Hong Kong, Shenzhen, Guangdong, China; The Chinese University of Hong Kong, Shenzhen, Guangdong, China; The Chinese University of Hong Kong, Shenzhen, Guangdong, China",
        "aff_domain": "link.cuhk.edu.cn;link.cuhk.edu.cn;cuhk.edu.cn;cuhk.edu.cn",
        "email": "link.cuhk.edu.cn;link.cuhk.edu.cn;cuhk.edu.cn;cuhk.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;1;1",
        "aff_unique_norm": "JD;Chinese University of Hong Kong",
        "aff_unique_dep": "JD AI Research;",
        "aff_unique_url": ";https://www.cuhk.edu.cn",
        "aff_unique_abbr": ";CUHK",
        "aff_campus_unique_index": "0+1;0+1;1;1",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "ae0788ae4a",
        "title": "Auto-Physics-Encoder: Using Physics-Informed Latent\r Layer Two-Way Physics Flow for Monitoring Systems\r with Unobservability",
        "site": "https://proceedings.mlr.press/v189/sundaray23a.html",
        "author": "Priyabrata Sundaray; Yang Weng",
        "abstract": "With the Internet of Everything (IoE) nowadays,\r monitoring edge systems is essential for\r coordinating everything into an IoE web. However, it\r is hard to monitor edge systems due to limited\r system information and limited sensors. To infer\r system information and provide robust monitoring\r capability, machine learning models were used to\r approximate mapping rules between different\r measurements. However, mapping rule learning using\r traditional machine learning tools is one way only,\r e.g., from measurement variables to the state vector\r variables. And, it is hard to be reverted, leading\r to over-fitting because of inconsistency between the\r forward and inverse learnings. Hence, we propose a\r structural deep neural network framework to provide\r a coherent two-way functional approximation. For\r physical regularization, we embed network size into\r the number of variables in the latent layers. We\r also utilize state sensors in the \u2018latent layer\u2019 to\r guide other latent variables to create state\r sets. The performance of reconstruction for the\r two-way mapping rule is validated extensively using\r test cases in the engineering, physics, and\r mathematical analysis domain.",
        "bibtex": "@InProceedings{pmlr-v189-sundaray23a,\n  title = \t {Auto-Physics-Encoder: Using Physics-Informed Latent\r Layer Two-Way Physics Flow for Monitoring Systems\r with Unobservability},\n  author =       {Sundaray, Priyabrata and Weng, Yang},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {958--973},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/sundaray23a/sundaray23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/sundaray23a.html},\n  abstract = \t {With the Internet of Everything (IoE) nowadays,\r monitoring edge systems is essential for\r coordinating everything into an IoE web. However, it\r is hard to monitor edge systems due to limited\r system information and limited sensors. To infer\r system information and provide robust monitoring\r capability, machine learning models were used to\r approximate mapping rules between different\r measurements. However, mapping rule learning using\r traditional machine learning tools is one way only,\r e.g., from measurement variables to the state vector\r variables. And, it is hard to be reverted, leading\r to over-fitting because of inconsistency between the\r forward and inverse learnings. Hence, we propose a\r structural deep neural network framework to provide\r a coherent two-way functional approximation. For\r physical regularization, we embed network size into\r the number of variables in the latent layers. We\r also utilize state sensors in the \u2018latent layer\u2019 to\r guide other latent variables to create state\r sets. The performance of reconstruction for the\r two-way mapping rule is validated extensively using\r test cases in the engineering, physics, and\r mathematical analysis domain.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/sundaray23a/sundaray23a.pdf",
        "supp": "",
        "pdf_size": 1567981,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:atOj62yUzmkJ:scholar.google.com/&scioq=Auto-Physics-Encoder:+Using+Physics-Informed+Latent%0D+Layer+Two-Way+Physics+Flow+for+Monitoring+Systems%0D+with+Unobservability&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "Arizona State University, Tempe, AZ, USA; Arizona State University, Tempe, AZ, USA",
        "aff_domain": "asu.edu;asu.edu",
        "email": "asu.edu;asu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "db49d5c378",
        "title": "Autonomous Myocardial Infarction Detection from\r Electrocardiogram with a Multi Label Classification\r Approach",
        "site": "https://proceedings.mlr.press/v189/singh23a.html",
        "author": "Vishwa Mohan Singh; Vibhor Saran; Pooja Kadambi",
        "abstract": "Myocardial Infarctions (MI) or heart attacks are\r among the most common medical emergencies\r globally. Such an episode often has mild or varied\r symptoms, making it hard to diagnose and respond in\r a timely manner. An electrocardiogram (ECG) is used\r to analyze the heart\u2019s electrical activity and,\r through this help, clinicians detect and localize a\r heart attack. However, interpretation of the ECG is\r made manually by trained professionals. In order to\r make this diagnosis more efficient, multiple methods\r have tried to automate the MI detection and\r localization process. In this work, we aim to create\r a more effective method of MI detection by\r restructuring the localization as a multi-label\r classification (MLC) problem, in which one set of\r attributes can belong to one or more classes. For\r this classification, features like the ST-deviation,\r T wave amplitude, and R-S ratios have been extracted\r and fed into the MLC model, which in our case, is a\r chain classifier of random forest. This proposed\r model will have five classes as the target, which\r represent the locations where an MI can occur. Our\r method achieves the best overall hamming accuracy of\r 81.49% in a k-fold cross validation test, with the\r highest accuracy for an individual class being\r 97.72% for anterior.",
        "bibtex": "@InProceedings{pmlr-v189-singh23a,\n  title = \t {Autonomous Myocardial Infarction Detection from\r Electrocardiogram with a Multi Label Classification\r Approach},\n  author =       {Singh, Vishwa Mohan and Saran, Vibhor and Kadambi, Pooja},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {911--926},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/singh23a/singh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/singh23a.html},\n  abstract = \t {Myocardial Infarctions (MI) or heart attacks are\r among the most common medical emergencies\r globally. Such an episode often has mild or varied\r symptoms, making it hard to diagnose and respond in\r a timely manner. An electrocardiogram (ECG) is used\r to analyze the heart\u2019s electrical activity and,\r through this help, clinicians detect and localize a\r heart attack. However, interpretation of the ECG is\r made manually by trained professionals. In order to\r make this diagnosis more efficient, multiple methods\r have tried to automate the MI detection and\r localization process. In this work, we aim to create\r a more effective method of MI detection by\r restructuring the localization as a multi-label\r classification (MLC) problem, in which one set of\r attributes can belong to one or more classes. For\r this classification, features like the ST-deviation,\r T wave amplitude, and R-S ratios have been extracted\r and fed into the MLC model, which in our case, is a\r chain classifier of random forest. This proposed\r model will have five classes as the target, which\r represent the locations where an MI can occur. Our\r method achieves the best overall hamming accuracy of\r 81.49% in a k-fold cross validation test, with the\r highest accuracy for an individual class being\r 97.72% for anterior.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/singh23a/singh23a.pdf",
        "supp": "",
        "pdf_size": 1120399,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18328658805891312075&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Turtle Shell Technologies Pvt. Ltd., India; Turtle Shell Technologies Pvt. Ltd., India; Turtle Shell Technologies Pvt. Ltd., India",
        "aff_domain": "dozee.io;dozee.io;dozee.io",
        "email": "dozee.io;dozee.io;dozee.io",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Turtle Shell Technologies Pvt. Ltd.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "00f27bd64e",
        "title": "BINAS: Bilinear Interpretable Neural Architecture\r Search",
        "site": "https://proceedings.mlr.press/v189/nayman23a.html",
        "author": "Niv Nayman; Yonathan Aflalo; Asaf Noy; Lihi Zelnik-Manor",
        "abstract": "Realistic use of neural networks often requires\r adhering to multiple constraints on latency, energy\r and memory among others.  A popular approach to find\r fitting networks is through constrained Neural\r Architecture Search (NAS). However, previous methods\r use complicated predictors for the accuracy of the\r network.  Those predictors are hard to interpret and\r sensitive to many hyperparameters to be tuned,\r hence, the resulting accuracy of the generated\r models is often harmed.  In this work we resolve\r this by introducing Bilinear Interpretable Neural\r Architecture Search (BINAS), that is based on an\r accurate and simple bilinear formulation of both an\r accuracy estimator and the expected resource\r requirement, together with a scalable search method\r with theoretical guarantees. The simplicity of our\r proposed estimator together with the intuitive way\r it is constructed bring interpretability through\r many insights about the contribution of different\r design choices. For example, we find that in the\r examined search space, adding depth and width is\r more effective at deeper stages of the network and\r at the beginning of each resolution stage.  Our\r experiments show that BINAS generates comparable to\r or better architectures than other state-of-the-art\r NAS methods within a reduced search cost for each\r additional generated network, while strictly\r satisfying the resource constraints.",
        "bibtex": "@InProceedings{pmlr-v189-nayman23a,\n  title = \t {BINAS: Bilinear Interpretable Neural Architecture\r Search},\n  author =       {Nayman, Niv and Aflalo, Yonathan and Noy, Asaf and Zelnik-Manor, Lihi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {786--801},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/nayman23a/nayman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/nayman23a.html},\n  abstract = \t {Realistic use of neural networks often requires\r adhering to multiple constraints on latency, energy\r and memory among others.  A popular approach to find\r fitting networks is through constrained Neural\r Architecture Search (NAS). However, previous methods\r use complicated predictors for the accuracy of the\r network.  Those predictors are hard to interpret and\r sensitive to many hyperparameters to be tuned,\r hence, the resulting accuracy of the generated\r models is often harmed.  In this work we resolve\r this by introducing Bilinear Interpretable Neural\r Architecture Search (BINAS), that is based on an\r accurate and simple bilinear formulation of both an\r accuracy estimator and the expected resource\r requirement, together with a scalable search method\r with theoretical guarantees. The simplicity of our\r proposed estimator together with the intuitive way\r it is constructed bring interpretability through\r many insights about the contribution of different\r design choices. For example, we find that in the\r examined search space, adding depth and width is\r more effective at deeper stages of the network and\r at the beginning of each resolution stage.  Our\r experiments show that BINAS generates comparable to\r or better architectures than other state-of-the-art\r NAS methods within a reduced search cost for each\r additional generated network, while strictly\r satisfying the resource constraints.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/nayman23a/nayman23a.pdf",
        "supp": "",
        "pdf_size": 12271831,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13561424450733091124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Technion - Israel Institute of Technology, Haifa, Israel+; Amazon Alexa Shopping, Tel-Aviv, Israel+; Alibaba Group, Tel Aviv, Israel; Technion - Israel Institute of Technology, Haifa, Israel+",
        "aff_domain": "campus.technion.ac.il;amazon.com;alibaba-inc.com;technion.ac.il",
        "email": "campus.technion.ac.il;amazon.com;alibaba-inc.com;technion.ac.il",
        "github": "https://github.com/Alibaba-MIIL/BINAS",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology;Amazon;Alibaba Group",
        "aff_unique_dep": ";Alexa Shopping;",
        "aff_unique_url": "https://www.technion.ac.il;https://www.amazon.com;https://www.alibaba.com",
        "aff_unique_abbr": "Technion;Amazon;Alibaba",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Haifa;Tel-Aviv;Tel Aviv",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "5a9e5f4d2c",
        "title": "Balanced Spatial-Temporal Graph Structure Learning\r for Multivariate Time Series Forecasting: A\r Trade-off between Efficiency and Flexibility",
        "site": "https://proceedings.mlr.press/v189/chen23a.html",
        "author": "Weijun Chen; Yanze Wang; Chengshuo Du; Zhenglong Jia; Feng Liu; Ran Chen",
        "abstract": "Accurate forecasting of multivariate time series is\r an extensively studied subject in finance,\r transportation, and computer science. Fully mining\r the correlation and causation between the variables\r in a multivariate time series exhibits noticeable\r results in improving the performance of a time\r series model. Recently, some models have explored\r the dependencies between variables through\r end-to-end graph structure learning without the need\r for predefined graphs. However, current models do\r not incorporate the trade-off between efficiency and\r flexibility and make insufficient use of the\r information contained in time series in the design\r of graph structure learning algorithms. This paper\r alleviates the above issues by proposing Balanced\r Graph Structure Learning for Forecasting (BGSLF), a\r novel and effective deep learning model that joins\r graph structure learning and\r forecasting. Technically, BGSLF leverages the\r spatial information into convolutional operations\r and extracts temporal dynamics using the diffusion\r convolutional recurrent network. The proposed\r framework emphasizes the trade-off between\r efficiency and flexibility by introducing\r Multi-Graph Generation Network (MGN) and Graph\r Selection Module. In addition, a method named Smooth\r Sparse Unit (SSU) is designed to sparse the learned\r graph structures, which conforms to the sparse\r spatial correlations in the real world. Extensive\r experiments on four real-world datasets demonstrate\r that our model achieves state-of-the-art\r performances with minor trainable parameters. Our\r code is publicly available at\r https://github.com/onceCWJ/BGSLF.",
        "bibtex": "@InProceedings{pmlr-v189-chen23a,\n  title = \t {Balanced Spatial-Temporal Graph Structure Learning\r for Multivariate Time Series Forecasting: A\r Trade-off between Efficiency and Flexibility},\n  author =       {Chen, Weijun and Wang, Yanze and Du, Chengshuo and Jia, Zhenglong and Liu, Feng and Chen, Ran},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {185--200},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/chen23a/chen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/chen23a.html},\n  abstract = \t {Accurate forecasting of multivariate time series is\r an extensively studied subject in finance,\r transportation, and computer science. Fully mining\r the correlation and causation between the variables\r in a multivariate time series exhibits noticeable\r results in improving the performance of a time\r series model. Recently, some models have explored\r the dependencies between variables through\r end-to-end graph structure learning without the need\r for predefined graphs. However, current models do\r not incorporate the trade-off between efficiency and\r flexibility and make insufficient use of the\r information contained in time series in the design\r of graph structure learning algorithms. This paper\r alleviates the above issues by proposing Balanced\r Graph Structure Learning for Forecasting (BGSLF), a\r novel and effective deep learning model that joins\r graph structure learning and\r forecasting. Technically, BGSLF leverages the\r spatial information into convolutional operations\r and extracts temporal dynamics using the diffusion\r convolutional recurrent network. The proposed\r framework emphasizes the trade-off between\r efficiency and flexibility by introducing\r Multi-Graph Generation Network (MGN) and Graph\r Selection Module. In addition, a method named Smooth\r Sparse Unit (SSU) is designed to sparse the learned\r graph structures, which conforms to the sparse\r spatial correlations in the real world. Extensive\r experiments on four real-world datasets demonstrate\r that our model achieves state-of-the-art\r performances with minor trainable parameters. Our\r code is publicly available at\r https://github.com/onceCWJ/BGSLF.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/chen23a/chen23a.pdf",
        "supp": "",
        "pdf_size": 1036498,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10218999376974478389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "School of Computer Science, Peking University; School of Intelligence Science and Technology, Peking University; School of Intelligence Science and Technology, Peking University; School of Intelligence Science and Technology, Peking University; School of Intelligence Science and Technology, Peking University + Beihang University; Beihang University",
        "aff_domain": "gmail.com;gmail.com;gmail.com;gmail.com;gmail.com;gmail.com",
        "email": "gmail.com;gmail.com;gmail.com;gmail.com;gmail.com;gmail.com",
        "github": "https://github.com/onceCWJ/BGSLF",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0+1;1",
        "aff_unique_norm": "Peking University;Beihang University",
        "aff_unique_dep": "School of Computer Science;",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.buaa.edu.cn/",
        "aff_unique_abbr": "PKU;BUAA",
        "aff_campus_unique_index": "0;",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "694d4413ac",
        "title": "BayesAdapter: Being Bayesian, Inexpensively and\r Reliably, via Bayesian Fine-tuning",
        "site": "https://proceedings.mlr.press/v189/deng23b.html",
        "author": "Zhijie Deng; Jun Zhu",
        "abstract": "Despite their theoretical appealingness, Bayesian\r neural networks (BNNs) are left behind in real-world\r adoption, mainly due to persistent concerns on their\r scalability, accessibility, and reliability. In this\r work, we develop the BayesAdapter framework to\r relieve these concerns. In particular, we propose to\r adapt pre-trained deterministic NNs to be\r variational BNNs via cost-effective Bayesian\r fine-tuning. Technically, we develop a modularized\r implementation for the learning of variational BNNs,\r and refurbish the generally applicable exemplar\r reparameterization trick through exemplar\r parallelization to efficiently reduce the gradient\r variance in stochastic variational inference. Based\r on the the lightweight Bayesian learning paradigm,\r we conduct extensive experiments on a variety of\r benchmarks, and show that our method can\r consistently induce posteriors with higher quality\r than competitive baselines, yet significantly\r reducing training overheads.",
        "bibtex": "@InProceedings{pmlr-v189-deng23b,\n  title = \t {BayesAdapter: Being Bayesian, Inexpensively and\r Reliably, via Bayesian Fine-tuning},\n  author =       {Deng, Zhijie and Zhu, Jun},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {280--295},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/deng23b/deng23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/deng23b.html},\n  abstract = \t {Despite their theoretical appealingness, Bayesian\r neural networks (BNNs) are left behind in real-world\r adoption, mainly due to persistent concerns on their\r scalability, accessibility, and reliability. In this\r work, we develop the BayesAdapter framework to\r relieve these concerns. In particular, we propose to\r adapt pre-trained deterministic NNs to be\r variational BNNs via cost-effective Bayesian\r fine-tuning. Technically, we develop a modularized\r implementation for the learning of variational BNNs,\r and refurbish the generally applicable exemplar\r reparameterization trick through exemplar\r parallelization to efficiently reduce the gradient\r variance in stochastic variational inference. Based\r on the the lightweight Bayesian learning paradigm,\r we conduct extensive experiments on a variety of\r benchmarks, and show that our method can\r consistently induce posteriors with higher quality\r than competitive baselines, yet significantly\r reducing training overheads.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/deng23b/deng23b.pdf",
        "supp": "",
        "pdf_size": 1000874,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=523660536377798543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Research Institute, Shanghai Jiao Tong University; Dept. of Comp. Sci. & Tech., BNRist Center, THU-Bosch Joint ML Center, Tsinghua University",
        "aff_domain": "sjtu.edu.cn;mail.tsinghua.edu.cn",
        "email": "sjtu.edu.cn;mail.tsinghua.edu.cn",
        "github": "https://github.com/thudzj/ScalableBDL",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Tsinghua University",
        "aff_unique_dep": "Research Institute;Dept. of Comp. Sci. & Tech.",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "SJTU;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "bab79217d9",
        "title": "Bayesian Change-Point Detection for Bandit Feedback\r in Non-stationary Environments",
        "site": "https://proceedings.mlr.press/v189/alami23a.html",
        "author": "Reda Alami",
        "abstract": "The stochastic multi-armed bandit problem has been\r widely studied under the stationary\r assumption. However in real world problems and\r industrial applications, this assumption is often\r unrealistic because the distributions of rewards may\r change over time. In this paper, we consider the\r piece-wise iid non-stationary stochastic multi-armed\r bandit problem with unknown change-points and we\r focus on the change of mean setup. To solve the\r latter, we propose a change-point based framework\r where we study a class of change-detection based\r optimal bandit policies that actively detects\r change-point using the restarted Bayesian online\r change-point detector and then restarts the bandit\r indices. Analytically, in the context of regret\r minimization, our proposal achieves a\r $\\mathcal{O}(\\sqrt{A T K_T })$ regret upper-bound\r where $K_T$ is the overall number of change-points\r up to the horizon $T$ and $A$ is the number of\r arms. The derived bound matches the existing lower\r bound for abruptly changing environments. Finally,\r we demonstrate the cumulative regret reduction of\r the our proposal over synthetic Bernoulli rewards as\r well as Yahoo! datasets of webpage click-through\r rates.",
        "bibtex": "@InProceedings{pmlr-v189-alami23a,\n  title = \t {Bayesian Change-Point Detection for Bandit Feedback\r in Non-stationary Environments},\n  author =       {Alami, Reda},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {17--31},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/alami23a/alami23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/alami23a.html},\n  abstract = \t {The stochastic multi-armed bandit problem has been\r widely studied under the stationary\r assumption. However in real world problems and\r industrial applications, this assumption is often\r unrealistic because the distributions of rewards may\r change over time. In this paper, we consider the\r piece-wise iid non-stationary stochastic multi-armed\r bandit problem with unknown change-points and we\r focus on the change of mean setup. To solve the\r latter, we propose a change-point based framework\r where we study a class of change-detection based\r optimal bandit policies that actively detects\r change-point using the restarted Bayesian online\r change-point detector and then restarts the bandit\r indices. Analytically, in the context of regret\r minimization, our proposal achieves a\r $\\mathcal{O}(\\sqrt{A T K_T })$ regret upper-bound\r where $K_T$ is the overall number of change-points\r up to the horizon $T$ and $A$ is the number of\r arms. The derived bound matches the existing lower\r bound for abruptly changing environments. Finally,\r we demonstrate the cumulative regret reduction of\r the our proposal over synthetic Bernoulli rewards as\r well as Yahoo! datasets of webpage click-through\r rates.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/alami23a/alami23a.pdf",
        "supp": "",
        "pdf_size": 654743,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1233172835658044028&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, United Arab Emirates",
        "aff_domain": "tii.ae",
        "email": "tii.ae",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Technology Innovation Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Masdar City",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Arab Emirates"
    },
    {
        "id": "494723124d",
        "title": "BeautifAI - Personalised Occasion-based Makeup\r Recommendation",
        "site": "https://proceedings.mlr.press/v189/gulati23a.html",
        "author": "Kshitij Gulati; Gaurav Verma; Mukesh Mohania; Ashish Kundu",
        "abstract": "With the global metamorphosis of the beauty industry\r and the rising demand for beauty products worldwide,\r the need for a robust makeup recommendation system\r has never been more. Despite the significant\r advancements made towards personalised makeup\r recommendation, the current research still falls\r short of incorporating the context of occasion and\r integrating feedback for users. In this work, we\r propose BeautifAI, a novel recommendation system,\r delivering personalised occasion-oriented makeup\r recommendations to users. The proposed work\u2019s novel\r contributions, including incorporating occasion\r context to makeup recommendation and a region-wise\r method using neural embeddings, set our system apart\r from the current work in makeup recommendation. We\r also propose real-time makeup previews and\r continuous makeup feedback to provide a more\r personalised and interactive experience to users.",
        "bibtex": "@InProceedings{pmlr-v189-gulati23a,\n  title = \t {BeautifAI - Personalised Occasion-based Makeup\r Recommendation},\n  author =       {Gulati, Kshitij and Verma, Gaurav and Mohania, Mukesh and Kundu, Ashish},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {407--419},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/gulati23a/gulati23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/gulati23a.html},\n  abstract = \t {With the global metamorphosis of the beauty industry\r and the rising demand for beauty products worldwide,\r the need for a robust makeup recommendation system\r has never been more. Despite the significant\r advancements made towards personalised makeup\r recommendation, the current research still falls\r short of incorporating the context of occasion and\r integrating feedback for users. In this work, we\r propose BeautifAI, a novel recommendation system,\r delivering personalised occasion-oriented makeup\r recommendations to users. The proposed work\u2019s novel\r contributions, including incorporating occasion\r context to makeup recommendation and a region-wise\r method using neural embeddings, set our system apart\r from the current work in makeup recommendation. We\r also propose real-time makeup previews and\r continuous makeup feedback to provide a more\r personalised and interactive experience to users.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/gulati23a/gulati23a.pdf",
        "supp": "",
        "pdf_size": 4901751,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2626599105934500841&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 0,
        "aff": "University of Rochester; Arizona State University; Indraprastha Institute of Information Technology, Delhi; Cisco Research",
        "aff_domain": "iiitd.ac.in;nsut.ac.in;iiitd.ac.in;cisco.com",
        "email": "iiitd.ac.in;nsut.ac.in;iiitd.ac.in;cisco.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "University of Rochester;Arizona State University;Indraprastha Institute of Information Technology;Cisco Systems",
        "aff_unique_dep": ";;;Cisco Research",
        "aff_unique_url": "https://www.rochester.edu;https://www.asu.edu;http://www.iiitd.ac.in;https://www.cisco.com",
        "aff_unique_abbr": "U of R;ASU;IIIT-D;Cisco",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Delhi",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "414c667b90",
        "title": "Bootstrapping a high quality multilingual multimodal\r dataset for Bletchley",
        "site": "https://proceedings.mlr.press/v189/mohammed23a.html",
        "author": "Owais Khan Mohammed; Kriti Aggarwal; Qiang Liu; Saksham Singhal; Johan Bjorck; Subhojit Som",
        "abstract": "Vision-language models have recently made impressive\r strides, primarily driven by large-scale training on\r web data. While pioneering works such as CLIP and\r ALIGN show significant improvements, these are\r focused on English data as it is easy to source them\r from the web. Towards serving non-English-speaking\r demographics, we consider various methods for\r generating multilingual data and find that a simple\r bootstrapping mechanism works surprisingly\r well. Specifically, just using English image\r captions data and text-only multilingual translation\r pairs we train a fairly strong multilingual\r vision-language model and then leverage it to create\r a much cleaner version of the multilingual image\r captions dataset we collected. We demonstrate that\r this dataset which was used to train Bletchley\r result in a strong multi-modal and multilingual\r model which reaches strong performance across\r several multilingual zero-shot tasks. Specifically,\r Bletchley achieves state-of-the-art results on\r multilingual COCO, Multi30k sets, IGLUE WIT and\r xFlickr&CO datasets.",
        "bibtex": "@InProceedings{pmlr-v189-mohammed23a,\n  title = \t {Bootstrapping a high quality multilingual multimodal\r dataset for Bletchley},\n  author =       {Mohammed, Owais Khan and Aggarwal, Kriti and Liu, Qiang and Singhal, Saksham and Bjorck, Johan and Som, Subhojit},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {738--753},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/mohammed23a/mohammed23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/mohammed23a.html},\n  abstract = \t {Vision-language models have recently made impressive\r strides, primarily driven by large-scale training on\r web data. While pioneering works such as CLIP and\r ALIGN show significant improvements, these are\r focused on English data as it is easy to source them\r from the web. Towards serving non-English-speaking\r demographics, we consider various methods for\r generating multilingual data and find that a simple\r bootstrapping mechanism works surprisingly\r well. Specifically, just using English image\r captions data and text-only multilingual translation\r pairs we train a fairly strong multilingual\r vision-language model and then leverage it to create\r a much cleaner version of the multilingual image\r captions dataset we collected. We demonstrate that\r this dataset which was used to train Bletchley\r result in a strong multi-modal and multilingual\r model which reaches strong performance across\r several multilingual zero-shot tasks. Specifically,\r Bletchley achieves state-of-the-art results on\r multilingual COCO, Multi30k sets, IGLUE WIT and\r xFlickr&CO datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/mohammed23a/mohammed23a.pdf",
        "supp": "",
        "pdf_size": 1369013,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16652261460928738203&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft",
        "aff_domain": "microsoft.com;microsoft.com;microsoft.com;microsoft.com;microsoft.com;microsoft.com",
        "email": "microsoft.com;microsoft.com;microsoft.com;microsoft.com;microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Corporation",
        "aff_unique_url": "https://www.microsoft.com",
        "aff_unique_abbr": "Microsoft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c155689ed5",
        "title": "CVaR-Regret Bounds for Multi-armed Bandits",
        "site": "https://proceedings.mlr.press/v189/tan23a.html",
        "author": "Chenmien Tan; Paul Weng",
        "abstract": "In contrast to risk-averse multi-armed bandit (MAB),\r where one aims for a best risk-sensitive arm while\r having a risk-neutral attitude when running the\r risk-averse MAB algorithm, in this paper, we aim for\r a best arm with respect to the mean like in the\r standard MAB, but we adopt a risk-averse attitude\r when running a standard MAB algorithm. Conditional\r value-at-risk (CVaR) of the regret is adopted as the\r metric to evaluate the performance of algorithms,\r which is an extension of the traditional expected\r regret minimization framework. For this new problem,\r we revisit several classic algorithms for stochastic\r and non-stochastic bandits, UCB, MOSS, and Exp3-IX\r with its variants and propose parameters with good\r theoretically guaranteed CVaR-regret, which match\r the results of the expected regret and achieve\r (nearly-)optimality up to constant. In the\r non-stochastic setting, we show that implicit\r exploration achieves a trade-off between the\r variability of the regret and the regret in\r expectation. Numerical experiments are conducted to\r validate our results.",
        "bibtex": "@InProceedings{pmlr-v189-tan23a,\n  title = \t {CVaR-Regret Bounds for Multi-armed Bandits},\n  author =       {Tan, Chenmien and Weng, Paul},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {974--989},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/tan23a/tan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/tan23a.html},\n  abstract = \t {In contrast to risk-averse multi-armed bandit (MAB),\r where one aims for a best risk-sensitive arm while\r having a risk-neutral attitude when running the\r risk-averse MAB algorithm, in this paper, we aim for\r a best arm with respect to the mean like in the\r standard MAB, but we adopt a risk-averse attitude\r when running a standard MAB algorithm. Conditional\r value-at-risk (CVaR) of the regret is adopted as the\r metric to evaluate the performance of algorithms,\r which is an extension of the traditional expected\r regret minimization framework. For this new problem,\r we revisit several classic algorithms for stochastic\r and non-stochastic bandits, UCB, MOSS, and Exp3-IX\r with its variants and propose parameters with good\r theoretically guaranteed CVaR-regret, which match\r the results of the expected regret and achieve\r (nearly-)optimality up to constant. In the\r non-stochastic setting, we show that implicit\r exploration achieves a trade-off between the\r variability of the regret and the regret in\r expectation. Numerical experiments are conducted to\r validate our results.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/tan23a/tan23a.pdf",
        "supp": "",
        "pdf_size": 390883,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=571674215516714385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "University of Nottingham Ningbo China; Shanghai Jiao Tong University",
        "aff_domain": "outlook.com;sjtu.edu.cn",
        "email": "outlook.com;sjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Nottingham;Shanghai Jiao Tong University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nottingham.edu.cn;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "UoN;SJTU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Ningbo;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9c7cda2d39",
        "title": "Circulant-interactive Transformer with\r Dimension-aware Fusion for Multimodal Sentiment\r Analysis",
        "site": "https://proceedings.mlr.press/v189/gong23a.html",
        "author": "Peizhu Gong; Jin Liu; Xiliang Zhang; Xingye Li; Zijun Yu",
        "abstract": "Multimodal sentiment analysis (MSA) is gaining\r traction as a critical tool for understanding human\r behavior and enabling a wide range of\r applications. Since data of different modalities\r might lie in completely distinct spaces, it is very\r challenging to perform effective fusion and analysis\r from asynchronous multimodal streams. Most of\r previous works focused on aligned fusion, which is\r unpractical in real-world scenarios. The recent\r Multimodal Transformer (MulT) approach attends to\r model the correlations between elements from\r different modalities in an unaligned\r manner. However, it collects temporal information by\r self-attention transformer which is a sequence\r model, implying that interactions across distinct\r time steps are not sufficient. In this paper, we\r propose the Citculant-interactive Transformer\r Network with dimension-aware fusion (CITN-DAF),\r which enables parallel computation of different\r modalities among different time steps and alleviates\r inter-modal temporal sensitivity while preserving\r intra-modal semantic order. By incorporating\r circulant matrices into the cross-modal attention\r mechanism, CITN-DAF is aimed to examine all\r conceivable interactions between vectors of\r different modalities. In addition, a dimension-aware\r fusion method is presented, which projects feature\r representations into different subspaces for an\r in-depth fusion. We evaluate CITN-DAF on three\r commonly used sentiment analysis benchmarks\r including CMU-MOSEI, CMU-MOSI and IEMOCAP. Extensive\r experimental results reveal that CITN-DAF is\r superior in cross-modal semantic interactions and\r outperforms the state-of-the-art multimodal\r methods.",
        "bibtex": "@InProceedings{pmlr-v189-gong23a,\n  title = \t {Circulant-interactive Transformer with\r Dimension-aware Fusion for Multimodal Sentiment\r Analysis},\n  author =       {Gong, Peizhu and Liu, Jin and Zhang, Xiliang and Li, Xingye and Yu, Zijun},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {391--406},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/gong23a/gong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/gong23a.html},\n  abstract = \t {Multimodal sentiment analysis (MSA) is gaining\r traction as a critical tool for understanding human\r behavior and enabling a wide range of\r applications. Since data of different modalities\r might lie in completely distinct spaces, it is very\r challenging to perform effective fusion and analysis\r from asynchronous multimodal streams. Most of\r previous works focused on aligned fusion, which is\r unpractical in real-world scenarios. The recent\r Multimodal Transformer (MulT) approach attends to\r model the correlations between elements from\r different modalities in an unaligned\r manner. However, it collects temporal information by\r self-attention transformer which is a sequence\r model, implying that interactions across distinct\r time steps are not sufficient. In this paper, we\r propose the Citculant-interactive Transformer\r Network with dimension-aware fusion (CITN-DAF),\r which enables parallel computation of different\r modalities among different time steps and alleviates\r inter-modal temporal sensitivity while preserving\r intra-modal semantic order. By incorporating\r circulant matrices into the cross-modal attention\r mechanism, CITN-DAF is aimed to examine all\r conceivable interactions between vectors of\r different modalities. In addition, a dimension-aware\r fusion method is presented, which projects feature\r representations into different subspaces for an\r in-depth fusion. We evaluate CITN-DAF on three\r commonly used sentiment analysis benchmarks\r including CMU-MOSEI, CMU-MOSI and IEMOCAP. Extensive\r experimental results reveal that CITN-DAF is\r superior in cross-modal semantic interactions and\r outperforms the state-of-the-art multimodal\r methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/gong23a/gong23a.pdf",
        "supp": "",
        "pdf_size": 2460105,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1964545103855802256&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Shanghai Maritime University; Shanghai Maritime University; Shanghai Maritime University; Shanghai Maritime University; Shanghai Maritime University",
        "aff_domain": "163.com;shmtu.edu.cn;163.com;qq.com;stu.shmtu.edu.cn",
        "email": "163.com;shmtu.edu.cn;163.com;qq.com;stu.shmtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Maritime University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.shmtu.edu.cn",
        "aff_unique_abbr": "SMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "8aae7a0b2b",
        "title": "Constrained Contrastive Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v189/wang23a.html",
        "author": "Haoyu Wang; Xinrui Yang; Yuhang Wang; Lan Xuguang",
        "abstract": "Learning to control from complex observations\r remains a major challenge in the application of\r model-based reinforcement learning (MBRL). Existing\r MBRL methods apply contrastive learning to replace\r pixel-level reconstruction, improving the\r performance of the latent world model. However,\r previous contrastive learning approaches in MBRL\r fail to utilize task-relevant information, making it\r difficult to aggregate observations with the same\r task-relevant information but the different\r task-irrelevant information in latent space. In this\r work, we first propose Constrained Contrastive\r Reinforcement Learning (C2RL), an MBRL method that\r learns a world model through a combination of two\r contrastive losses based on latent dynamics and\r task-relevant state abstraction respectively,\r utilizing reward information to accelerate model\r learning. Then, we propose a hyperparameter $\\beta$\r to balance two kinds of contrastive losses to\r strengthen the representation ability of the latent\r dynamics. The experimental results show that our\r approach outperforms state-of-the-art methods in\r both the natural video and standard background\r setting on challenging DMControl tasks.",
        "bibtex": "@InProceedings{pmlr-v189-wang23a,\n  title = \t {Constrained Contrastive Reinforcement Learning},\n  author =       {Wang, Haoyu and Yang, Xinrui and Wang, Yuhang and Xuguang, Lan},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1070--1084},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/wang23a/wang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/wang23a.html},\n  abstract = \t {Learning to control from complex observations\r remains a major challenge in the application of\r model-based reinforcement learning (MBRL). Existing\r MBRL methods apply contrastive learning to replace\r pixel-level reconstruction, improving the\r performance of the latent world model. However,\r previous contrastive learning approaches in MBRL\r fail to utilize task-relevant information, making it\r difficult to aggregate observations with the same\r task-relevant information but the different\r task-irrelevant information in latent space. In this\r work, we first propose Constrained Contrastive\r Reinforcement Learning (C2RL), an MBRL method that\r learns a world model through a combination of two\r contrastive losses based on latent dynamics and\r task-relevant state abstraction respectively,\r utilizing reward information to accelerate model\r learning. Then, we propose a hyperparameter $\\beta$\r to balance two kinds of contrastive losses to\r strengthen the representation ability of the latent\r dynamics. The experimental results show that our\r approach outperforms state-of-the-art methods in\r both the natural video and standard background\r setting on challenging DMControl tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/wang23a/wang23a.pdf",
        "supp": "",
        "pdf_size": 977055,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11015599496483410650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University",
        "aff_domain": "foxmail.com;stu.xjtu.edu.com;qq.com;mail.xjtu.edu.cn",
        "email": "foxmail.com;stu.xjtu.edu.com;qq.com;mail.xjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "44ef42c1f8",
        "title": "Constrained Density Matching and Modeling for\r Cross-lingual Alignment of Contextualized\r Representations",
        "site": "https://proceedings.mlr.press/v189/zhao23a.html",
        "author": "Wei Zhao; Steffen Eger",
        "abstract": "Multilingual representations pre-trained with\r monolingual data exhibit considerably unequal task\r performances across languages. Previous studies\r address this challenge with resource-intensive\r contextualized alignment, which assumes the\r availability of large parallel data, thereby leaving\r under-represented language communities behind. In\r this work, we attribute the data hungriness of\r previous alignment techniques to two limitations:\r (i) the inability to sufficiently leverage data and\r (ii) these techniques are not trained properly. To\r address these issues, we introduce supervised and\r unsupervised density-based approaches named Real-NVP\r and GAN-Real-NVP, driven by Normalizing Flow, to\r perform alignment, both dissecting the alignment of\r multilingual subspaces into density matching and\r density modeling. We complement these approaches\r with our validation criteria in order to guide the\r training process. Our experiments encompass 16\r alignments, including our approaches, evaluated\r across 6 language pairs, synthetic data and 5 NLP\r tasks. We demonstrate the effectiveness of our\r approaches in the scenarios of limited and no\r parallel data. First, our supervised approach\r trained on 20k parallel data (sentences) mostly\r surpasses Joint-Align and InfoXLM trained on over\r 100k parallel sentences. Second, parallel data can\r be removed without sacrificing performance when\r integrating our unsupervised approach in our\r bootstrapping procedure, which is theoretically\r motivated to enforce equality of multilingual\r subspaces. Moreover, we demonstrate the advantages\r of validation criteria over validation data for\r guiding supervised training.",
        "bibtex": "@InProceedings{pmlr-v189-zhao23a,\n  title = \t {Constrained Density Matching and Modeling for\r Cross-lingual Alignment of Contextualized\r Representations},\n  author =       {Zhao, Wei and Eger, Steffen},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1245--1260},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/zhao23a/zhao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/zhao23a.html},\n  abstract = \t {Multilingual representations pre-trained with\r monolingual data exhibit considerably unequal task\r performances across languages. Previous studies\r address this challenge with resource-intensive\r contextualized alignment, which assumes the\r availability of large parallel data, thereby leaving\r under-represented language communities behind. In\r this work, we attribute the data hungriness of\r previous alignment techniques to two limitations:\r (i) the inability to sufficiently leverage data and\r (ii) these techniques are not trained properly. To\r address these issues, we introduce supervised and\r unsupervised density-based approaches named Real-NVP\r and GAN-Real-NVP, driven by Normalizing Flow, to\r perform alignment, both dissecting the alignment of\r multilingual subspaces into density matching and\r density modeling. We complement these approaches\r with our validation criteria in order to guide the\r training process. Our experiments encompass 16\r alignments, including our approaches, evaluated\r across 6 language pairs, synthetic data and 5 NLP\r tasks. We demonstrate the effectiveness of our\r approaches in the scenarios of limited and no\r parallel data. First, our supervised approach\r trained on 20k parallel data (sentences) mostly\r surpasses Joint-Align and InfoXLM trained on over\r 100k parallel sentences. Second, parallel data can\r be removed without sacrificing performance when\r integrating our unsupervised approach in our\r bootstrapping procedure, which is theoretically\r motivated to enforce equality of multilingual\r subspaces. Moreover, we demonstrate the advantages\r of validation criteria over validation data for\r guiding supervised training.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/zhao23a/zhao23a.pdf",
        "supp": "",
        "pdf_size": 448462,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3844853083887122100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Heidelberg Institute for Theoretical Studies + Fachbereich Informatik, Technische Universit\u00e4t Darmstadt; Technische Fakult\u00e4t, Universit\u00e4t Bielefeld + Fachbereich Informatik, Technische Universit\u00e4t Darmstadt",
        "aff_domain": "h-its.org;uni-bielefeld.de",
        "email": "h-its.org;uni-bielefeld.de",
        "github": "https://github.com/AIPHES/DensityAlign",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2+1",
        "aff_unique_norm": "Heidelberg Institute for Theoretical Studies;Technische Universit\u00e4t Darmstadt;Universit\u00e4t Bielefeld",
        "aff_unique_dep": ";Fachbereich Informatik;Technische Fakult\u00e4t",
        "aff_unique_url": "https://www.hits.org/;https://www.tu-darmstadt.de;https://www.uni-bielefeld.de",
        "aff_unique_abbr": "HITS;TUD;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "cdd6ad7b71",
        "title": "Contrastive Inductive Bias Controlling Networks for\r Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v189/li23a.html",
        "author": "Dongxu Li; Shaochen Wang; Kang Chen; Bin Li",
        "abstract": "Effective learning in an visual-based environment is\r essential for reinforcement learning (RL) agent,\r while it has been empirically observed that learning\r from high dimensional observations such as raw\r pixels is sample-inefficient. For common practice,\r RL algorithms for image input often use encoders\r composed of CNNs to extract useful features from\r high dimensional observations. Recent studies have\r shown that CNNs have strong inductive bias towards\r image styles rather than content (i.e. agent\r shapes), while content is the information that RL\r algorithms should focus on. Inspired by this, we\r suggest reducing the intrinsic style bias of CNNs by\r proposing Contrastive Inductive Bias Controlling\r Networks for RL. It can help RL algorithms\r effectively focus on truly noteworthy information\r like agents\u2019 own characteristics. Our approach\r incorporates two transfer networks and feature\r encoder with contrastive learning methods, guiding\r RL algorithms to learn more efficiently with\r sampling. Extensive experiments show that the\r extended framework greatly enhances the performance\r of existing model-free methods (i.e. SAC), enabling\r it to reach state-of-the-art performance on the\r DeepMind control suite benchmark.",
        "bibtex": "@InProceedings{pmlr-v189-li23a,\n  title = \t {Contrastive Inductive Bias Controlling Networks for\r Reinforcement Learning},\n  author =       {Li, Dongxu and Wang, Shaochen and Chen, Kang and Li, Bin},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {563--578},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/li23a/li23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/li23a.html},\n  abstract = \t {Effective learning in an visual-based environment is\r essential for reinforcement learning (RL) agent,\r while it has been empirically observed that learning\r from high dimensional observations such as raw\r pixels is sample-inefficient. For common practice,\r RL algorithms for image input often use encoders\r composed of CNNs to extract useful features from\r high dimensional observations. Recent studies have\r shown that CNNs have strong inductive bias towards\r image styles rather than content (i.e. agent\r shapes), while content is the information that RL\r algorithms should focus on. Inspired by this, we\r suggest reducing the intrinsic style bias of CNNs by\r proposing Contrastive Inductive Bias Controlling\r Networks for RL. It can help RL algorithms\r effectively focus on truly noteworthy information\r like agents\u2019 own characteristics. Our approach\r incorporates two transfer networks and feature\r encoder with contrastive learning methods, guiding\r RL algorithms to learn more efficiently with\r sampling. Extensive experiments show that the\r extended framework greatly enhances the performance\r of existing model-free methods (i.e. SAC), enabling\r it to reach state-of-the-art performance on the\r DeepMind control suite benchmark.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/li23a/li23a.pdf",
        "supp": "",
        "pdf_size": 1310210,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14796865226017097735&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "aff_domain": "mail.ustc.edu.cn;mail.ustc.edu.cn;mail.ustc.edu.cn;mail.ustc.cn",
        "email": "mail.ustc.edu.cn;mail.ustc.edu.cn;mail.ustc.edu.cn;mail.ustc.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "2e4598c012",
        "title": "Cross-Scale Context Extracted Hashing for\r Fine-Grained Image Binary Encoding",
        "site": "https://proceedings.mlr.press/v189/xue23a.html",
        "author": "Xuetong Xue; Jiaying Shi; Xinxue He; Shenghui Xu; Zhaoming Pan",
        "abstract": "Deep hashing has been widely applied to large-scale\r image retrieval tasks owing to efficient computation\r and low storage cost by encoding high-dimensional\r image data into binary codes. Since binary codes do\r not contain as much information as float features,\r the essence of binary encoding is preserving the\r main context to guarantee retrieval\r quality. However, the existing hashing methods have\r great limitations on suppressing redundant\r background information and accurately encoding from\r Euclidean space to Hamming space by a simple sign\r function. In order to solve these problems, a\r Cross-Scale Context Extracted Hashing Network\r (CSCE-Net) is proposed in this paper. Firstly, we\r design a two-branch framework to capture\r fine-grained local information while maintaining\r high-level global semantic information. Besides,\r Attention guided Information Extraction module (AIE)\r is introduced between two branches, which suppresses\r areas of low context information cooperated with\r global sliding windows. Unlike previous methods, our\r CSCE-Net learns a content-related Dynamic Sign\r Function (DSF) to replace the original simple sign\r function. Therefore, the proposed CSCE-Net is\r context-sensitive and able to perform well on\r accurate image binary encoding. We further\r demonstrate that our CSCE-Net is superior to the\r existing hashing methods, which improves retrieval\r performance on standard benchmarks.",
        "bibtex": "@InProceedings{pmlr-v189-xue23a,\n  title = \t {Cross-Scale Context Extracted Hashing for\r Fine-Grained Image Binary Encoding},\n  author =       {Xue, Xuetong and Shi, Jiaying and He, Xinxue and Xu, Shenghui and Pan, Zhaoming},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1197--1212},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/xue23a/xue23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/xue23a.html},\n  abstract = \t {Deep hashing has been widely applied to large-scale\r image retrieval tasks owing to efficient computation\r and low storage cost by encoding high-dimensional\r image data into binary codes. Since binary codes do\r not contain as much information as float features,\r the essence of binary encoding is preserving the\r main context to guarantee retrieval\r quality. However, the existing hashing methods have\r great limitations on suppressing redundant\r background information and accurately encoding from\r Euclidean space to Hamming space by a simple sign\r function. In order to solve these problems, a\r Cross-Scale Context Extracted Hashing Network\r (CSCE-Net) is proposed in this paper. Firstly, we\r design a two-branch framework to capture\r fine-grained local information while maintaining\r high-level global semantic information. Besides,\r Attention guided Information Extraction module (AIE)\r is introduced between two branches, which suppresses\r areas of low context information cooperated with\r global sliding windows. Unlike previous methods, our\r CSCE-Net learns a content-related Dynamic Sign\r Function (DSF) to replace the original simple sign\r function. Therefore, the proposed CSCE-Net is\r context-sensitive and able to perform well on\r accurate image binary encoding. We further\r demonstrate that our CSCE-Net is superior to the\r existing hashing methods, which improves retrieval\r performance on standard benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/xue23a/xue23a.pdf",
        "supp": "",
        "pdf_size": 7365901,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8199828554071374944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "No.7 Building, Zhongguancun Software Park West, No.10 Xibeiwang East RD, Beijing, China; No.7 Building, Zhongguancun Software Park West, No.10 Xibeiwang East RD, Beijing, China; No.7 Building, Zhongguancun Software Park West, No.10 Xibeiwang East RD, Beijing, China; No.7 Building, Zhongguancun Software Park West, No.10 Xibeiwang East RD, Beijing, China; No.7 Building, Zhongguancun Software Park West, No.10 Xibeiwang East RD, Beijing, China",
        "aff_domain": "corp.netease.com;corp.netease.com;corp.netease.com;corp.netease.com;corp.netease.com",
        "email": "corp.netease.com;corp.netease.com;corp.netease.com;corp.netease.com;corp.netease.com",
        "github": "https://github.com/NetEase-Media/CSCE-Net",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhongguancun Software Park",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "ebbc9b0703",
        "title": "DALE: Differential Accumulated Local Effects for\r efficient and accurate global explanations",
        "site": "https://proceedings.mlr.press/v189/gkolemis23a.html",
        "author": "Vasilis Gkolemis; Theodore Dalamagas; Christos Diou",
        "abstract": "Accumulated Local Effect (ALE) is a method for\r accurately estimating feature effects, overcoming\r fundamental failure modes of previously-existed\r methods, such as Partial Dependence Plots. However,\r \\textit{ALE\u2019s approximation}, i.e.\u00a0the method for\r estimating ALE from the limited samples of the\r training set, faces two weaknesses. First, it does\r not scale well in cases where the input has high\r dimensionality, and, second, it is vulnerable to\r out-of-distribution (OOD) sampling when the training\r set is relatively small. In this paper, we propose a\r novel ALE approximation, called Differential\r Accumulated Local Effects (DALE), which can be used\r in cases where the ML model is differentiable and an\r auto-differentiable framework is accessible. Our\r proposal has significant computational advantages,\r making feature effect estimation applicable to\r high-dimensional Machine Learning scenarios with\r near-zero computational overhead. Furthermore, DALE\r does not create artificial points for calculating\r the feature effect, resolving misleading estimations\r due to OOD sampling. Finally, we formally prove\r that, under some hypotheses, DALE is an unbiased\r estimator of ALE and we present a method for\r quantifying the standard error of the\r explanation. Experiments using both synthetic and\r real datasets demonstrate the value of the proposed\r approach.",
        "bibtex": "@InProceedings{pmlr-v189-gkolemis23a,\n  title = \t {DALE: Differential Accumulated Local Effects for\r efficient and accurate global explanations},\n  author =       {Gkolemis, Vasilis and Dalamagas, Theodore and Diou, Christos},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {375--390},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/gkolemis23a/gkolemis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/gkolemis23a.html},\n  abstract = \t {Accumulated Local Effect (ALE) is a method for\r accurately estimating feature effects, overcoming\r fundamental failure modes of previously-existed\r methods, such as Partial Dependence Plots. However,\r \\textit{ALE\u2019s approximation}, i.e.\u00a0the method for\r estimating ALE from the limited samples of the\r training set, faces two weaknesses. First, it does\r not scale well in cases where the input has high\r dimensionality, and, second, it is vulnerable to\r out-of-distribution (OOD) sampling when the training\r set is relatively small. In this paper, we propose a\r novel ALE approximation, called Differential\r Accumulated Local Effects (DALE), which can be used\r in cases where the ML model is differentiable and an\r auto-differentiable framework is accessible. Our\r proposal has significant computational advantages,\r making feature effect estimation applicable to\r high-dimensional Machine Learning scenarios with\r near-zero computational overhead. Furthermore, DALE\r does not create artificial points for calculating\r the feature effect, resolving misleading estimations\r due to OOD sampling. Finally, we formally prove\r that, under some hypotheses, DALE is an unbiased\r estimator of ALE and we present a method for\r quantifying the standard error of the\r explanation. Experiments using both synthetic and\r real datasets demonstrate the value of the proposed\r approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/gkolemis23a/gkolemis23a.pdf",
        "supp": "",
        "pdf_size": 631967,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13586505312166951772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c05bb1c90a",
        "title": "Deep Reinforcement Learning for High-Frequency\r Market Making",
        "site": "https://proceedings.mlr.press/v189/kumar23a.html",
        "author": "Pankaj Kumar",
        "abstract": "High-frequency market making is a algorithmic\r trading strategy in which an agent provides\r liquidity at the same time as quoting a bid price\r and an ask price on a security. The strategy reap\r profits in the form of the spread between the quoted\r price placed on the buy and sell prices. Due to\r complexity in inventory risk, counterparties to\r trades and information asymmetry, the understanding\r of high-frequency market making algorithms is\r relatively unexplored by academics across\r disciplines. In this paper, we develop realistic\r simulations of limit order markets and use them to\r design a high-frequency market making agent using\r Deep Recurrent Q-Networks. Our approach outperforms\r a prominent benchmark strategy from literature,\r which uses temporal-difference reinforcement\r learning to design market making agents. Using the\r simulation framework, we analyse how the maker-take\r fee, a feature of market design, affects market\r quality and the agent\u2019s profitability. The agents\r successfully reproduce stylised facts in historical\r trade data from each simulation.",
        "bibtex": "@InProceedings{pmlr-v189-kumar23a,\n  title = \t {Deep Reinforcement Learning for High-Frequency\r Market Making},\n  author =       {Kumar, Pankaj},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {531--546},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/kumar23a/kumar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/kumar23a.html},\n  abstract = \t {High-frequency market making is a algorithmic\r trading strategy in which an agent provides\r liquidity at the same time as quoting a bid price\r and an ask price on a security. The strategy reap\r profits in the form of the spread between the quoted\r price placed on the buy and sell prices. Due to\r complexity in inventory risk, counterparties to\r trades and information asymmetry, the understanding\r of high-frequency market making algorithms is\r relatively unexplored by academics across\r disciplines. In this paper, we develop realistic\r simulations of limit order markets and use them to\r design a high-frequency market making agent using\r Deep Recurrent Q-Networks. Our approach outperforms\r a prominent benchmark strategy from literature,\r which uses temporal-difference reinforcement\r learning to design market making agents. Using the\r simulation framework, we analyse how the maker-take\r fee, a feature of market design, affects market\r quality and the agent\u2019s profitability. The agents\r successfully reproduce stylised facts in historical\r trade data from each simulation.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/kumar23a/kumar23a.pdf",
        "supp": "",
        "pdf_size": 422539,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18017707860322013211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Copenhagen Business School, Denmark",
        "aff_domain": "cbs.dk",
        "email": "cbs.dk",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Copenhagen Business School",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cbs.dk",
        "aff_unique_abbr": "CBS",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "1f33d37c2f",
        "title": "Domain Alignment Meets Fully Test-Time Adaptation",
        "site": "https://proceedings.mlr.press/v189/thopalli23a.html",
        "author": "Kowshik Thopalli; Pavan Turaga; Jayaraman J Thiagarajan",
        "abstract": "A foundational requirement of a deployed ML model is\r to generalize to data drawn from a testing\r distribution that is different from training. A\r popular solution to this problem is to adapt a\r pre-trained model to novel domains using only\r unlabeled data. In this paper, we focus on a\r challenging variant of this problem, where access to\r the original source data is restricted. While fully\r test-time adaptation (FTTA) and unsupervised domain\r adaptation (UDA) are closely related, the advances\r in UDA are not readily applicable to TTA, since most\r UDA methods require access to the source\r data. Hence, we propose a new approach, CATTAn, that\r bridges UDA and FTTA, by relaxing the need to access\r entire source data, through a novel deep subspace\r alignment strategy. With a minimal overhead of\r storing the subspace basis set for the source data,\r CATTAn enables unsupervised alignment between source\r and target data during adaptation. Through extensive\r experimental evaluation on multiple 2D and 3D vision\r benchmar ks (ImageNet-C, Office-31, OfficeHome,\r DomainNet, PointDA-10) and model architectures, we\r demonstrate significant gains in FTTA\r performance. Furthermore, we make a number of\r crucial findings on the utility of the alignment\r objective even with inherently robust models,\r pre-trained ViT representations and under low sample\r availability in the target domain.",
        "bibtex": "@InProceedings{pmlr-v189-thopalli23a,\n  title = \t {Domain Alignment Meets Fully Test-Time Adaptation},\n  author =       {Thopalli, Kowshik and Turaga, Pavan and Thiagarajan, Jayaraman J},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1006--1021},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/thopalli23a/thopalli23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/thopalli23a.html},\n  abstract = \t {A foundational requirement of a deployed ML model is\r to generalize to data drawn from a testing\r distribution that is different from training. A\r popular solution to this problem is to adapt a\r pre-trained model to novel domains using only\r unlabeled data. In this paper, we focus on a\r challenging variant of this problem, where access to\r the original source data is restricted. While fully\r test-time adaptation (FTTA) and unsupervised domain\r adaptation (UDA) are closely related, the advances\r in UDA are not readily applicable to TTA, since most\r UDA methods require access to the source\r data. Hence, we propose a new approach, CATTAn, that\r bridges UDA and FTTA, by relaxing the need to access\r entire source data, through a novel deep subspace\r alignment strategy. With a minimal overhead of\r storing the subspace basis set for the source data,\r CATTAn enables unsupervised alignment between source\r and target data during adaptation. Through extensive\r experimental evaluation on multiple 2D and 3D vision\r benchmar ks (ImageNet-C, Office-31, OfficeHome,\r DomainNet, PointDA-10) and model architectures, we\r demonstrate significant gains in FTTA\r performance. Furthermore, we make a number of\r crucial findings on the utility of the alignment\r objective even with inherently robust models,\r pre-trained ViT representations and under low sample\r availability in the target domain.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/thopalli23a/thopalli23a.pdf",
        "supp": "",
        "pdf_size": 1752233,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8385464808831797257&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": "Arizona State University; Arizona State University; Lawrence Livermore National Laboratory",
        "aff_domain": "asu.edu;asu.edu;llnl.gov",
        "email": "asu.edu;asu.edu;llnl.gov",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Arizona State University;Lawrence Livermore National Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.asu.edu;https://www.llnl.gov",
        "aff_unique_abbr": "ASU;LLNL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "641e9d72f6",
        "title": "Dynamic Forward and Backward Sparse Training\r (DFBST): Accelerated Deep Learning through\r Completely Sparse Training Schedule",
        "site": "https://proceedings.mlr.press/v189/pote23a.html",
        "author": "Tejas Pote; Muhammad Athar Ganaie; Atif Hassan; Swanand Khare",
        "abstract": "Neural network sparsification has received a lot of\r attention in recent years. A number of dynamic\r sparse training methods have been developed that\r achieve significant sparsity levels during training,\r ensuring comparable performance to their dense\r counterparts. However, most of these methods update\r all the model parameters using dense gradients. To\r this end, gradient sparsification is achieved either\r by non-dynamic (fixed) schedule or computationally\r expensive dynamic pruning schedule. To alleviate\r these drawbacks, we propose Dynamic Forward and\r Backward Sparse Training (DFBST), an algorithm which\r dynamically sparsifies both the forward and backward\r passes using trainable masks, leading to a\r completely sparse training schedule. In contrast to\r existing sparse training methods, we propose\r separate learning for forward as well as backward\r masks. Our approach achieves state of the art\r performance in terms of both accuracy and sparsity\r compared to existing dynamic pruning algorithms on\r benchmark datasets, namely MNIST, CIFAR-10 and\r CIFAR-100.",
        "bibtex": "@InProceedings{pmlr-v189-pote23a,\n  title = \t {Dynamic Forward and Backward Sparse Training\r (DFBST): Accelerated Deep Learning through\r Completely Sparse Training Schedule},\n  author =       {Pote, Tejas and Ganaie, Muhammad Athar and Hassan, Atif and Khare, Swanand},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {848--863},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/pote23a/pote23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/pote23a.html},\n  abstract = \t {Neural network sparsification has received a lot of\r attention in recent years. A number of dynamic\r sparse training methods have been developed that\r achieve significant sparsity levels during training,\r ensuring comparable performance to their dense\r counterparts. However, most of these methods update\r all the model parameters using dense gradients. To\r this end, gradient sparsification is achieved either\r by non-dynamic (fixed) schedule or computationally\r expensive dynamic pruning schedule. To alleviate\r these drawbacks, we propose Dynamic Forward and\r Backward Sparse Training (DFBST), an algorithm which\r dynamically sparsifies both the forward and backward\r passes using trainable masks, leading to a\r completely sparse training schedule. In contrast to\r existing sparse training methods, we propose\r separate learning for forward as well as backward\r masks. Our approach achieves state of the art\r performance in terms of both accuracy and sparsity\r compared to existing dynamic pruning algorithms on\r benchmark datasets, namely MNIST, CIFAR-10 and\r CIFAR-100.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/pote23a/pote23a.pdf",
        "supp": "",
        "pdf_size": 622877,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rBilBdg3hA4J:scholar.google.com/&scioq=Dynamic+Forward+and+Backward+Sparse+Training%0D+(DFBST):+Accelerated+Deep+Learning+through%0D+Completely+Sparse+Training+Schedule&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Indian Institute of Technology, Kharagpur; Indian Institute of Technology, Kharagpur; Indian Institute of Technology, Kharagpur; Indian Institute of Technology, Kharagpur",
        "aff_domain": "gmail.com;gmail.com;gmail.com;maths.iitkgp.ac.in",
        "email": "gmail.com;gmail.com;gmail.com;maths.iitkgp.ac.in",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iitkgp.ac.in",
        "aff_unique_abbr": "IIT Kharagpur",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kharagpur",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "86d0ee0eef",
        "title": "EENAS: An E\ufb00icient Evolutionary Algorithm for Neural\r Architecture Search",
        "site": "https://proceedings.mlr.press/v189/jian23a.html",
        "author": "Zheng Jian; Han Wenran; Zhang Ying; Ji Shufan",
        "abstract": "Neural Architecture Search (NAS) has been widely\r applied to automatic neural architecture\r design. Traditional NAS methods often evaluate a\r large number of architectures, leading to expensive\r computation overhead.  To speed-up architecture\r search, recent NAS methods try to employ network\r estimation strategies for guidance of promising\r architecture selection.  In this paper, we have\r proposed an efficient evolutionary algorithm for\r NAS, which adapts the most advanced proxy of\r synthetic signal bases for architecture\r estimation. Extensive experiments show that our\r method outperforms state-of-the-art NAS methods, on\r NAS-Bench-101 search space and NAS-Bench-201 search\r space (CIFAR-10, CIFAR-100 and\r ImageNet16-120). Compared with existing works, our\r method could identify better architectures with\r greatly reduced search time.",
        "bibtex": "@InProceedings{pmlr-v189-jian23a,\n  title = \t {EENAS: An E\ufb00icient Evolutionary Algorithm for Neural\r Architecture Search},\n  author =       {Jian, Zheng and Wenran, Han and Ying, Zhang and Shufan, Ji},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1261--1276},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/jian23a/jian23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/jian23a.html},\n  abstract = \t {Neural Architecture Search (NAS) has been widely\r applied to automatic neural architecture\r design. Traditional NAS methods often evaluate a\r large number of architectures, leading to expensive\r computation overhead.  To speed-up architecture\r search, recent NAS methods try to employ network\r estimation strategies for guidance of promising\r architecture selection.  In this paper, we have\r proposed an efficient evolutionary algorithm for\r NAS, which adapts the most advanced proxy of\r synthetic signal bases for architecture\r estimation. Extensive experiments show that our\r method outperforms state-of-the-art NAS methods, on\r NAS-Bench-101 search space and NAS-Bench-201 search\r space (CIFAR-10, CIFAR-100 and\r ImageNet16-120). Compared with existing works, our\r method could identify better architectures with\r greatly reduced search time.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/jian23a/jian23a.pdf",
        "supp": "",
        "pdf_size": 3144841,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11247141242351077789&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Beihang University, Beijing, P.R. China, 100191; Beihang University, Beijing, P.R. China, 100191; Beihang University, Beijing, P.R. China, 100191; Beihang University, Beijing, P.R. China, 100191",
        "aff_domain": "buaa.edu.cn;buaa.edu.cn;buaa.edu.cn;buaa.edu.cn",
        "email": "buaa.edu.cn;buaa.edu.cn;buaa.edu.cn;buaa.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.buaa.edu.cn/",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "52c53e5de3",
        "title": "Efficient Deep Clustering of Human Activities and\r How to Improve Evaluation",
        "site": "https://proceedings.mlr.press/v189/mahon23a.html",
        "author": "Louis Mahon; Thomas Lukasiewicz",
        "abstract": "There has been much recent research on human\r activity recognition (HAR), due to the proliferation\r of wearable sensors in watches and phones, and the\r advances of deep learning methods, which avoid the\r need to manually extract features from raw sensor\r signals. A significant disadvantage of deep learning\r applied to HAR is the need for manually labelled\r training data, which is especially difficult to\r obtain for HAR datasets. Progress is starting to be\r made in the unsupervised setting, in the form of\r deep HAR clustering models, which can assign labels\r to data without having been given any labels to\r train on, but there are problems with evaluating\r deep HAR clustering models, which makes assessing\r the field and devising new methods difficult. In\r this paper, we highlight several distinct problems\r with how deep HAR clustering models are evaluated,\r describing these problems in detail and conducting\r careful experiments to explicate the effect that\r they can have on results. Additionally, we present a\r new deep clustering model for HAR. When tested under\r our proposed settings, our model performs better\r than (or on par with) existing models, while also\r being more efficient and scalable by avoiding the\r need for an autoencoder.",
        "bibtex": "@InProceedings{pmlr-v189-mahon23a,\n  title = \t {Efficient Deep Clustering of Human Activities and\r How to Improve Evaluation},\n  author =       {Mahon, Louis and Lukasiewicz, Thomas},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {722--737},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/mahon23a/mahon23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/mahon23a.html},\n  abstract = \t {There has been much recent research on human\r activity recognition (HAR), due to the proliferation\r of wearable sensors in watches and phones, and the\r advances of deep learning methods, which avoid the\r need to manually extract features from raw sensor\r signals. A significant disadvantage of deep learning\r applied to HAR is the need for manually labelled\r training data, which is especially difficult to\r obtain for HAR datasets. Progress is starting to be\r made in the unsupervised setting, in the form of\r deep HAR clustering models, which can assign labels\r to data without having been given any labels to\r train on, but there are problems with evaluating\r deep HAR clustering models, which makes assessing\r the field and devising new methods difficult. In\r this paper, we highlight several distinct problems\r with how deep HAR clustering models are evaluated,\r describing these problems in detail and conducting\r careful experiments to explicate the effect that\r they can have on results. Additionally, we present a\r new deep clustering model for HAR. When tested under\r our proposed settings, our model performs better\r than (or on par with) existing models, while also\r being more efficient and scalable by avoiding the\r need for an autoencoder.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/mahon23a/mahon23a.pdf",
        "supp": "",
        "pdf_size": 310870,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15874750137025168557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Institute for Language, Cognition and Computation, University of Edinburgh, UK+Department of Computer Science, University of Oxford, UK; Institute of Logic and Computation, TU Wien, Austria+Department of Computer Science, University of Oxford, UK",
        "aff_domain": "cs.ox.ac.uk;cs.ox.ac.uk",
        "email": "cs.ox.ac.uk;cs.ox.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2+1",
        "aff_unique_norm": "University of Edinburgh;University of Oxford;TU Wien",
        "aff_unique_dep": "Institute for Language, Cognition and Computation;Department of Computer Science;Institute of Logic and Computation",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ox.ac.uk;https://www.tuwien.ac.at",
        "aff_unique_abbr": "Edinburgh;Oxford;TU Wien",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;1+0",
        "aff_country_unique": "United Kingdom;Austria"
    },
    {
        "id": "e2e14d4278",
        "title": "Embedding Adaptation Network with Transformer for\r Few-Shot Action Recognition",
        "site": "https://proceedings.mlr.press/v189/jin23a.html",
        "author": "Rongrong Jin; Xiao Wang; Guangge Wang; Yang Lu; Hai-Miao Hu; Hanzi Wang",
        "abstract": "Few-shot action recognition aims to classify novel\r action categories using a few training samples. Most\r current few-shot action recognition methods via\r episodic training strategy mainly use the same\r normalization method to normalize feature\r embeddings, leading to limited performance when the\r batch size is small. And some methods learn feature\r embeddings individually without considering the\r whole task, neglecting important interactive\r information between videos in the current\r episode. To address these problems, we propose a\r novel embedding adaptation network with Transformer\r (EANT) for few-shot action\r recognition. Specifically, we first propose an\r improved self-guided instance normalization (SGIN)\r module to adaptively learn class-specific feature\r embeddings in an input-dependent manner. Built upon\r the learned feature embeddings, we design a\r Transformer-based embedding learning (TEL) module to\r learn task-specific feature embeddings by fully\r capturing rich information cross videos in each\r episodic task. Furthermore, we utilize semantic\r knowledge among all sampled training classes as\r additional supervisory information to improve the\r generalization ability of the network. By this\r means, the proposed EANT can be highly effective and\r informative for few-shot action\r recognition. Extensive experiments conducted on\r several challenging few-shot action recognition\r benchmarks show that the proposed EANT outperforms\r several state-of-the-art methods by a large margin.",
        "bibtex": "@InProceedings{pmlr-v189-jin23a,\n  title = \t {Embedding Adaptation Network with Transformer for\r Few-Shot Action Recognition},\n  author =       {Jin, Rongrong and Wang, Xiao and Wang, Guangge and Lu, Yang and Hu, Hai-Miao and Wang, Hanzi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {515--530},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/jin23a/jin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/jin23a.html},\n  abstract = \t {Few-shot action recognition aims to classify novel\r action categories using a few training samples. Most\r current few-shot action recognition methods via\r episodic training strategy mainly use the same\r normalization method to normalize feature\r embeddings, leading to limited performance when the\r batch size is small. And some methods learn feature\r embeddings individually without considering the\r whole task, neglecting important interactive\r information between videos in the current\r episode. To address these problems, we propose a\r novel embedding adaptation network with Transformer\r (EANT) for few-shot action\r recognition. Specifically, we first propose an\r improved self-guided instance normalization (SGIN)\r module to adaptively learn class-specific feature\r embeddings in an input-dependent manner. Built upon\r the learned feature embeddings, we design a\r Transformer-based embedding learning (TEL) module to\r learn task-specific feature embeddings by fully\r capturing rich information cross videos in each\r episodic task. Furthermore, we utilize semantic\r knowledge among all sampled training classes as\r additional supervisory information to improve the\r generalization ability of the network. By this\r means, the proposed EANT can be highly effective and\r informative for few-shot action\r recognition. Extensive experiments conducted on\r several challenging few-shot action recognition\r benchmarks show that the proposed EANT outperforms\r several state-of-the-art methods by a large margin.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/jin23a/jin23a.pdf",
        "supp": "",
        "pdf_size": 710263,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5554143240408749553&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, Xiamen, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, Xiamen, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, Xiamen, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, Xiamen, China; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University, Beijing, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, Xiamen, China",
        "aff_domain": "stu.xmu.edu.cn;stu.xmu.edu.cn;stu.xmu.edu.cn;xmu.edu.cn;163.com;xmu.edu.cn",
        "email": "stu.xmu.edu.cn;stu.xmu.edu.cn;stu.xmu.edu.cn;xmu.edu.cn;163.com;xmu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Xiamen University;Beihang University",
        "aff_unique_dep": "School of Informatics;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.xmu.edu.cn;http://www.buaa.edu.cn",
        "aff_unique_abbr": "XMU;Beihang",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Xiamen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "b088ebe6ba",
        "title": "Evaluating the perceived safety of urban city via\r maximum entropy deep inverse reinforcement learning",
        "site": "https://proceedings.mlr.press/v189/wang23c.html",
        "author": "Yaxuan Wang; Zhixin Zeng; Qijun Zhao",
        "abstract": "Inspired by expert evaluation policy for urban\r perception, we proposed a novel inverse\r reinforcement learning (IRL) based framework for\r predicting urban safety and recovering the\r corresponding reward function. We also presented a\r scalable state representation method to model the\r prediction problem as a Markov decision process\r (MDP) and use reinforcement learning (RL) to solve\r the problem. Additionally, we built a dataset called\r SmallCity based on the crowdsourcing method to\r conduct the research. As far as we know, this is the\r first time the IRL approach has been introduced to\r the urban safety perception and planning field to\r help experts quantitatively analyze perceptual\r features. Our results showed that IRL has promising\r prospects in this field. We will later open-source\r the crowdsourcing data collection site and the model\r proposed in this paper.",
        "bibtex": "@InProceedings{pmlr-v189-wang23c,\n  title = \t {Evaluating the perceived safety of urban city via\r maximum entropy deep inverse reinforcement learning},\n  author =       {Wang, Yaxuan and Zeng, Zhixin and Zhao, Qijun},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1085--1100},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/wang23c/wang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v189/wang23c.html},\n  abstract = \t {Inspired by expert evaluation policy for urban\r perception, we proposed a novel inverse\r reinforcement learning (IRL) based framework for\r predicting urban safety and recovering the\r corresponding reward function. We also presented a\r scalable state representation method to model the\r prediction problem as a Markov decision process\r (MDP) and use reinforcement learning (RL) to solve\r the problem. Additionally, we built a dataset called\r SmallCity based on the crowdsourcing method to\r conduct the research. As far as we know, this is the\r first time the IRL approach has been introduced to\r the urban safety perception and planning field to\r help experts quantitatively analyze perceptual\r features. Our results showed that IRL has promising\r prospects in this field. We will later open-source\r the crowdsourcing data collection site and the model\r proposed in this paper.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/wang23c/wang23c.pdf",
        "supp": "",
        "pdf_size": 4896365,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8527220208891916199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Sichuan University, Chengdu, China; Sichuan University, Chengdu, China; Sichuan University, Chengdu, China",
        "aff_domain": "gmail.com;stu.scu.edu.cn;scu.edu.cn",
        "email": "gmail.com;stu.scu.edu.cn;scu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sichuan University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.scu.edu.cn",
        "aff_unique_abbr": "SCU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "3f518d85b4",
        "title": "Example or Prototype? Learning Concept-Based\r Explanations in Time-Series",
        "site": "https://proceedings.mlr.press/v189/obermair23a.html",
        "author": "Christoph Obermair; Alexander Fuchs; Franz Pernkopf; Lukas Felsberger; Andrea Apollonio; Daniel Wollmann",
        "abstract": "With the continuous increase of deep learning\r applications in safety critical systems, the need\r for an interpretable decision-making process has\r become a priority within the research\r community. While there are many existing explainable\r artificial intelligence algorithms, a systematic\r assessment of the suitability of global explanation\r methods for different applications is not\r available. In this paper, we respond to this demand\r by systematically comparing two existing global\r concept-based explanation methods with our proposed\r global, model-agnostic concept-based explanation\r method for time-series data. This method is based on\r an autoencoder structure and derives abstract global\r explanations called \"prototypes\". The results of a\r human user study and a quantitative analysis show a\r superior performance of the proposed method, but\r also highlight the necessity of tailoring\r explanation methods to the target audience of\r machine learning models.",
        "bibtex": "@InProceedings{pmlr-v189-obermair23a,\n  title = \t {Example or Prototype? Learning Concept-Based\r Explanations in Time-Series},\n  author =       {Obermair, Christoph and Fuchs, Alexander and Pernkopf, Franz and Felsberger, Lukas and Apollonio, Andrea and Wollmann, Daniel},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {816--831},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/obermair23a/obermair23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/obermair23a.html},\n  abstract = \t {With the continuous increase of deep learning\r applications in safety critical systems, the need\r for an interpretable decision-making process has\r become a priority within the research\r community. While there are many existing explainable\r artificial intelligence algorithms, a systematic\r assessment of the suitability of global explanation\r methods for different applications is not\r available. In this paper, we respond to this demand\r by systematically comparing two existing global\r concept-based explanation methods with our proposed\r global, model-agnostic concept-based explanation\r method for time-series data. This method is based on\r an autoencoder structure and derives abstract global\r explanations called \"prototypes\". The results of a\r human user study and a quantitative analysis show a\r superior performance of the proposed method, but\r also highlight the necessity of tailoring\r explanation methods to the target audience of\r machine learning models.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/obermair23a/obermair23a.pdf",
        "supp": "",
        "pdf_size": 559809,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12436759270247197245&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Graz University of Technology, Graz, Austria + CERN, Geneva, Switzerland; Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; CERN, Geneva, Switzerland; CERN, Geneva, Switzerland; CERN, Geneva, Switzerland",
        "aff_domain": "tugraz.at;tugraz.at;tugraz.at;cern.ch;cern.ch;cern.ch",
        "email": "tugraz.at;tugraz.at;tugraz.at;cern.ch;cern.ch;cern.ch",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;1;1;1",
        "aff_unique_norm": "Graz University of Technology;CERN",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tugraz.at;https://home.cern",
        "aff_unique_abbr": "TUGraz;CERN",
        "aff_campus_unique_index": "0+1;0;0;1;1;1",
        "aff_campus_unique": "Graz;Geneva",
        "aff_country_unique_index": "0+1;0;0;1;1;1",
        "aff_country_unique": "Austria;Switzerland"
    },
    {
        "id": "eb5c07fe95",
        "title": "FF-Net: An End-to-end Feature-Fusion Network for\r Double JPEG Detection and Localization",
        "site": "https://proceedings.mlr.press/v189/liu23a.html",
        "author": "Bo Liu; Ranglei Wu; Xiuli Bi; Bin Xiao",
        "abstract": "In the real-world, most images are saved in JPEG\r format, so many forged images are partially or\r totally composed of JPEG images and then saved in\r JPEG format again. In this case, exposing forged\r images can be accomplished by the detection of\r double JPEG compressions. Although the detection\r methods of double JPEG compressions have greatly\r improved, they rely on handcrafted features of image\r patches and cannot locate forgery at pixel-level. To\r break this limitation, we propose an end-to-end\r feature-fusion network (FF-Net) for double\r compression detection and forgery localization. We\r find that JPEG compression fingerprint primarily\r exists on the high-frequency component of an image,\r and the singly and doubly compression yield\r different fingerprints. Therefore, we design two\r encoders cooperatively to learn the compression\r fingerprint directly from the whole image. A decoder\r is deployed to locate the regions with different\r compression fingerprints at pixel-level based on the\r learned compression fingerprint. The experiment\r results verify that the proposed FF-Net can detect\r and locate the forged regions more accurately than\r these existing detection methods. Besides, it has a\r good generalization ability that the network trained\r on one compression case can work in numerous\r compression cases. Moreover, it can detect different\r local forgeries, including copy-move, splicing, and\r object-removal.",
        "bibtex": "@InProceedings{pmlr-v189-liu23a,\n  title = \t {FF-Net: An End-to-end Feature-Fusion Network for\r Double JPEG Detection and Localization},\n  author =       {Liu, Bo and Wu, Ranglei and Bi, Xiuli and Xiao, Bin},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {643--657},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/liu23a/liu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/liu23a.html},\n  abstract = \t {In the real-world, most images are saved in JPEG\r format, so many forged images are partially or\r totally composed of JPEG images and then saved in\r JPEG format again. In this case, exposing forged\r images can be accomplished by the detection of\r double JPEG compressions. Although the detection\r methods of double JPEG compressions have greatly\r improved, they rely on handcrafted features of image\r patches and cannot locate forgery at pixel-level. To\r break this limitation, we propose an end-to-end\r feature-fusion network (FF-Net) for double\r compression detection and forgery localization. We\r find that JPEG compression fingerprint primarily\r exists on the high-frequency component of an image,\r and the singly and doubly compression yield\r different fingerprints. Therefore, we design two\r encoders cooperatively to learn the compression\r fingerprint directly from the whole image. A decoder\r is deployed to locate the regions with different\r compression fingerprints at pixel-level based on the\r learned compression fingerprint. The experiment\r results verify that the proposed FF-Net can detect\r and locate the forged regions more accurately than\r these existing detection methods. Besides, it has a\r good generalization ability that the network trained\r on one compression case can work in numerous\r compression cases. Moreover, it can detect different\r local forgeries, including copy-move, splicing, and\r object-removal.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/liu23a/liu23a.pdf",
        "supp": "",
        "pdf_size": 7427266,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7rNig919Bx8J:scholar.google.com/&scioq=FF-Net:+An+End-to-end+Feature-Fusion+Network+for%0D+Double+JPEG+Detection+and+Localization&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Chongqing University of Posts and Telecommunications; Chongqing University of Posts and Telecommunications; Chongqing University of Posts and Telecommunications; Chongqing University of Posts and Telecommunications",
        "aff_domain": "cqupt.edu.cn;stu.cqupt.edu.cn;cqupt.edu.cn;cqupt.edu.cn",
        "email": "cqupt.edu.cn;stu.cqupt.edu.cn;cqupt.edu.cn;cqupt.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chongqing University of Posts and Telecommunications",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.cqupt.edu.cn",
        "aff_unique_abbr": "CQUPT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "1d10f2147c",
        "title": "FLVoogd: Robust And Privacy Preserving Federated\r Learning",
        "site": "https://proceedings.mlr.press/v189/yuhang23a.html",
        "author": "Tian Yuhang; Wang Rui; Qiao Yanqi; Panaousis Emmanouil; Liang Kaitai",
        "abstract": "In this work, we propose FLVoogd, an updated\r federated learning method in which servers and\r clients collaboratively eliminate Byzantine attacks\r while preserving privacy. In particular, servers use\r automatic Density-based Spatial Clustering of\r Applications with Noise (DBSCAN) combined with\r Secure Multi-party Computation (SMPC) to cluster the\r benign majority without acquiring sensitive personal\r information. Meanwhile, clients build dual models\r and perform test-based distance controlling to\r adjust their local models toward the global one to\r achieve personalizing.  Our framework is automatic\r and adaptive that servers/clients don\u2019t need to tune\r the parameters during the training. In addition, our\r framework leverages SMPC\u2019s operations, including\r multiplications, additions, and comparisons, where\r costly operations, like division and square root,\r are not required. Evaluations are carried out on\r some conventional datasets from the image\r classification field. The result shows that FLVoogd\r can effectively reject malicious uploads in most\r scenarios; meanwhile, it avoids data leakage from\r the server side.",
        "bibtex": "@InProceedings{pmlr-v189-yuhang23a,\n  title = \t {FLVoogd: Robust And Privacy Preserving Federated\r Learning},\n  author =       {Yuhang, Tian and Rui, Wang and Yanqi, Qiao and Emmanouil, Panaousis and Kaitai, Liang},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1022--1037},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/yuhang23a/yuhang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/yuhang23a.html},\n  abstract = \t {In this work, we propose FLVoogd, an updated\r federated learning method in which servers and\r clients collaboratively eliminate Byzantine attacks\r while preserving privacy. In particular, servers use\r automatic Density-based Spatial Clustering of\r Applications with Noise (DBSCAN) combined with\r Secure Multi-party Computation (SMPC) to cluster the\r benign majority without acquiring sensitive personal\r information. Meanwhile, clients build dual models\r and perform test-based distance controlling to\r adjust their local models toward the global one to\r achieve personalizing.  Our framework is automatic\r and adaptive that servers/clients don\u2019t need to tune\r the parameters during the training. In addition, our\r framework leverages SMPC\u2019s operations, including\r multiplications, additions, and comparisons, where\r costly operations, like division and square root,\r are not required. Evaluations are carried out on\r some conventional datasets from the image\r classification field. The result shows that FLVoogd\r can effectively reject malicious uploads in most\r scenarios; meanwhile, it avoids data leakage from\r the server side.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/yuhang23a/yuhang23a.pdf",
        "supp": "",
        "pdf_size": 994718,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9480335311051559013&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Delft University of Technology; Delft University of Technology; Delft University of Technology; University of Greenwich; Delft University of Technology",
        "aff_domain": "student.tudelft.nl;tudelft.nl;tudelft.nl;greenwich.ac.uk;tudelft.nl",
        "email": "student.tudelft.nl;tudelft.nl;tudelft.nl;greenwich.ac.uk;tudelft.nl",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Delft University of Technology;University of Greenwich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tudelft.nl;https://www.gre.ac.uk",
        "aff_unique_abbr": "TU Delft;Greenwich",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Netherlands;United Kingdom"
    },
    {
        "id": "89ba4b1958",
        "title": "Fairness Trade-Offs and Partial Debiasing",
        "site": "https://proceedings.mlr.press/v189/buet-golfouse23b.html",
        "author": "Francois Buet-Golfouse; Islam Utyagulov",
        "abstract": "Previous literature has shown that bias mitigating\r algorithms were sometimes prone to overfitting and\r had poor out-of-sample generalisation. This paper is\r first and foremost concerned with establishing a\r mathematical framework to tackle the specific issue\r of generalisation. Throughout this work, we consider\r fairness trade-offs and objectives mixing\r statistical loss over the whole sample and fairness\r penalties on categories (which could stem from\r different values of protected attributes),\r encompassing partial de-biasing. We do so by\r adopting two different but complementary viewpoints:\r first, we consider a PAC-type setup and derive\r probabilistic upper bounds involving sample-only\r information; second, we leverage an asymptotic\r framework to derive a closed-form limiting\r distribution for the difference between the\r empirical trade-off and the true trade-off. While\r these results provide guarantees for learning\r fairness metrics across categories, they also point\r out to the key (but asymmetric) role played by class\r imbalance. To summarise, learning fairness without\r having access to enough category-level samples is\r hard, and a simple numerical experiment shows that\r it can lead to spurious results.",
        "bibtex": "@InProceedings{pmlr-v189-buet-golfouse23b,\n  title = \t {Fairness Trade-Offs and Partial Debiasing},\n  author =       {Buet-Golfouse, Francois and Utyagulov, Islam},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {112--136},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/buet-golfouse23b/buet-golfouse23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/buet-golfouse23b.html},\n  abstract = \t {Previous literature has shown that bias mitigating\r algorithms were sometimes prone to overfitting and\r had poor out-of-sample generalisation. This paper is\r first and foremost concerned with establishing a\r mathematical framework to tackle the specific issue\r of generalisation. Throughout this work, we consider\r fairness trade-offs and objectives mixing\r statistical loss over the whole sample and fairness\r penalties on categories (which could stem from\r different values of protected attributes),\r encompassing partial de-biasing. We do so by\r adopting two different but complementary viewpoints:\r first, we consider a PAC-type setup and derive\r probabilistic upper bounds involving sample-only\r information; second, we leverage an asymptotic\r framework to derive a closed-form limiting\r distribution for the difference between the\r empirical trade-off and the true trade-off. While\r these results provide guarantees for learning\r fairness metrics across categories, they also point\r out to the key (but asymmetric) role played by class\r imbalance. To summarise, learning fairness without\r having access to enough category-level samples is\r hard, and a simple numerical experiment shows that\r it can lead to spurious results.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/buet-golfouse23b/buet-golfouse23b.pdf",
        "supp": "",
        "pdf_size": 670921,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15691425383825187602&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University College London, London, United Kingdom; Independent Researcher, London, United Kingdom",
        "aff_domain": "ucl.ac.uk;gmail.com",
        "email": "ucl.ac.uk;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University College London;Independent Researcher",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucl.ac.uk;",
        "aff_unique_abbr": "UCL;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "c296caf8c4",
        "title": "Feature Distribution Matching for Federated Domain\r Generalization",
        "site": "https://proceedings.mlr.press/v189/sun23a.html",
        "author": "Yuwei Sun; Ng Chong; Hideya Ochiai",
        "abstract": "Multi-source domain adaptation has been intensively\r studied. The distribution shift in features inherent\r to specific domains causes the negative transfer\r problem, degrading a model\u2019s generality to unseen\r tasks. In Federated Learning (FL), learned model\r parameters are shared to train a global model that\r leverages the underlying knowledge across client\r models trained on separate data\r domains. Nonetheless, the data confidentiality of FL\r hinders the effectiveness of traditional domain\r adaptation methods that require prior knowledge of\r different domain data. We propose a new federated\r domain generalization method called Federated\r Knowledge Alignment (FedKA). FedKA leverages feature\r distribution matching in a global workspace such\r that the global model can learn domain-invariant\r client features under the constraint of unknown\r client data. FedKA employs a federated voting\r mechanism that generates target domain pseudo-labels\r based on the consensus from clients to facilitate\r global model fine-tuning. We performed extensive\r experiments, including an ablation study, to\r evaluate the effectiveness of the proposed method in\r both image and text classification tasks using\r different model architectures. The empirical results\r show that FedKA achieves performance gains of 8.8%\r and 3.5% in Digit-Five and Office-Caltech10,\r respectively, and a gain of 0.7% in Amazon Review\r with extremely limited training data. Moreover, we\r studied the effectiveness of FedKA in alleviating\r the negative transfer of FL based on a new criterion\r called Group Effect. The results show that FedKA can\r reduce negative transfer, improving the performance\r gain via model aggregation by 4 times.",
        "bibtex": "@InProceedings{pmlr-v189-sun23a,\n  title = \t {Feature Distribution Matching for Federated Domain\r Generalization},\n  author =       {Sun, Yuwei and Chong, Ng and Ochiai, Hideya},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {942--957},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/sun23a/sun23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/sun23a.html},\n  abstract = \t {Multi-source domain adaptation has been intensively\r studied. The distribution shift in features inherent\r to specific domains causes the negative transfer\r problem, degrading a model\u2019s generality to unseen\r tasks. In Federated Learning (FL), learned model\r parameters are shared to train a global model that\r leverages the underlying knowledge across client\r models trained on separate data\r domains. Nonetheless, the data confidentiality of FL\r hinders the effectiveness of traditional domain\r adaptation methods that require prior knowledge of\r different domain data. We propose a new federated\r domain generalization method called Federated\r Knowledge Alignment (FedKA). FedKA leverages feature\r distribution matching in a global workspace such\r that the global model can learn domain-invariant\r client features under the constraint of unknown\r client data. FedKA employs a federated voting\r mechanism that generates target domain pseudo-labels\r based on the consensus from clients to facilitate\r global model fine-tuning. We performed extensive\r experiments, including an ablation study, to\r evaluate the effectiveness of the proposed method in\r both image and text classification tasks using\r different model architectures. The empirical results\r show that FedKA achieves performance gains of 8.8%\r and 3.5% in Digit-Five and Office-Caltech10,\r respectively, and a gain of 0.7% in Amazon Review\r with extremely limited training data. Moreover, we\r studied the effectiveness of FedKA in alleviating\r the negative transfer of FL based on a new criterion\r called Group Effect. The results show that FedKA can\r reduce negative transfer, improving the performance\r gain via model aggregation by 4 times.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/sun23a/sun23a.pdf",
        "supp": "",
        "pdf_size": 1638619,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12907156726764349969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "The University of Tokyo/RIKEN AIP; United Nations University; The University of Tokyo",
        "aff_domain": "g.ecc.u-tokyo.ac.jp;unu.edu;elab.ic.i.u-tokyo.ac.jp",
        "email": "g.ecc.u-tokyo.ac.jp;unu.edu;elab.ic.i.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Tokyo;United Nations University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://unu.edu",
        "aff_unique_abbr": "UTokyo;UNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;Unknown"
    },
    {
        "id": "e50e0fc4dd",
        "title": "Graph annotation generative adversarial networks",
        "site": "https://proceedings.mlr.press/v189/boget23a.html",
        "author": "Yoann Boget; Magda Gregorova; Alexandros Kalousis",
        "abstract": "We consider the problem of modelling\r high-dimensional distributions and generating new\r examples of data with complex relational feature\r structure coherent with a graph skeleton. The model\r we propose tackles the problem of generating the\r data features constrained by the specific graph\r structure of each data point by splitting the task\r into two phases. In the first it models the\r distribution of features associated with the nodes\r of the given graph, in the second it complements the\r edge features conditionally on the node features. We\r follow the strategy of implicit distribution\r modelling via generative adversarial network (GAN)\r combined with permutation equivariant message\r passing architecture operating over the sets of\r nodes and edges. This enables generating the feature\r vectors of all the graph objects in one go (in 2\r phases) as opposed to a much slower one-by-one\r generations of sequential models, prevents the need\r for expensive graph matching procedures usually\r needed for likelihood-based generative models, and\r uses efficiently the network capacity by being\r insensitive to the particular node ordering in the\r graph representation. To the best of our knowledge,\r this is the first method that models the feature\r distribution along the graph skeleton allowing for\r generations of annotated graphs with user specified\r structures. Our experiments demonstrate the ability\r of our model to learn complex structured\r distributions through quantitative evaluation over\r three annotated graph datasets.",
        "bibtex": "@InProceedings{pmlr-v189-boget23a,\n  title = \t {Graph annotation generative adversarial networks},\n  author =       {Boget, Yoann and Gregorova, Magda and Kalousis, Alexandros},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {16--16},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/boget23a/boget23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/boget23a.html},\n  abstract = \t {We consider the problem of modelling\r high-dimensional distributions and generating new\r examples of data with complex relational feature\r structure coherent with a graph skeleton. The model\r we propose tackles the problem of generating the\r data features constrained by the specific graph\r structure of each data point by splitting the task\r into two phases. In the first it models the\r distribution of features associated with the nodes\r of the given graph, in the second it complements the\r edge features conditionally on the node features. We\r follow the strategy of implicit distribution\r modelling via generative adversarial network (GAN)\r combined with permutation equivariant message\r passing architecture operating over the sets of\r nodes and edges. This enables generating the feature\r vectors of all the graph objects in one go (in 2\r phases) as opposed to a much slower one-by-one\r generations of sequential models, prevents the need\r for expensive graph matching procedures usually\r needed for likelihood-based generative models, and\r uses efficiently the network capacity by being\r insensitive to the particular node ordering in the\r graph representation. To the best of our knowledge,\r this is the first method that models the feature\r distribution along the graph skeleton allowing for\r generations of annotated graphs with user specified\r structures. Our experiments demonstrate the ability\r of our model to learn complex structured\r distributions through quantitative evaluation over\r three annotated graph datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/boget23a/boget23a.pdf",
        "supp": "",
        "pdf_size": 1065771,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12357037098401865317&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Geneva and Geneva School for Business administration HES-SO; Center for Artificial Intelligence and Robotics (CAIRO), FHWS; Geneva School for Business administration HES-SO",
        "aff_domain": "hesge.ch;fhws.de;hes-so.ch",
        "email": "hesge.ch;fhws.de;hes-so.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Geneva;Fachhochschule W\u00fcrzburg-Schweinfurt;Geneva School for Business and Economics, HES-SO",
        "aff_unique_dep": ";Center for Artificial Intelligence and Robotics;Business Administration",
        "aff_unique_url": "https://www.unige.ch;https://www.fhws.de/;https://www.hes-so.ch/geneva-school-for-business-and-economics",
        "aff_unique_abbr": "UNIGE;FHWS;GSBE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Geneva",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "359f8b9028",
        "title": "Hashing2Vec: Fast Embedding Generation for\r SARS-CoV-2 Spike Sequence Classification",
        "site": "https://proceedings.mlr.press/v189/taslim23a.html",
        "author": "Murad Taslim; Chourasia Prakash; Ali Sarwan; Patterson Murray",
        "abstract": "Due to the ongoing coronavirus (COVID-19) pandemic,\r an unprecedented amount of SARS-CoV-2 sequence data\r is available. The scale of this data has out-paced\r traditional methods for its analysis, while\r machine-learning approaches aimed at clustering and\r classification of SARS-CoV-2 variants is becoming an\r attractive alternative. Since the SARS-CoV-2 genome\r is highly dimensional, considering the much smaller\r spike region can save a great deal of processing.\r As the spike protein mediates the attachment of the\r coronavirus to the host cell, most of the newer and\r more contagious variants can be characterized by\r alterations to the spike protein; hence it is often\r sufficient for characterizing the different\r SARS-CoV-2 variants. Another important consideration\r is to have a fast feature embedding generation,\r which is the subject of this work.  Applying any\r machine learning (ML) model to a biological sequence\r requires first transforming it into a fixed-length\r (numerical) form. While there exist several compact\r embeddings for SARS-CoV-2 spike protein sequences,\r the generation process is computationally expensive\r since the features, added to the resulting vectors,\r are indexed in a na\u00efve fashion.  To solve this\r problem, we propose a fast and alignment-free\r hashing-based approach to design a fixed-length\r feature embedding for spike protein sequences,\r called Hashing2Vec, which can be used as input to\r any standard ML model. Using real-world data, we\r show that the proposed embedding is not only\r efficient to compute but also outperforms current\r state-of-the-art embedding methods in terms of\r classification accuracy. In terms of runtime, we\r achieve up to a 99.8% improvement in the\r Hashing2Vec-based embedding generation as compared\r to the baselines on a set of 7K spike amino acid\r sequences. It also outperforms the baselines on this\r data in terms of predictive performance and achieves\r accuracy and ROC-AUC scores of 86% and 84.4%,\r respectively.",
        "bibtex": "@InProceedings{pmlr-v189-taslim23a,\n  title = \t {Hashing2Vec: Fast Embedding Generation for\r SARS-CoV-2 Spike Sequence Classification},\n  author =       {Taslim, Murad and Prakash, Chourasia and Sarwan, Ali and Murray, Patterson},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {754--769},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/taslim23a/taslim23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/taslim23a.html},\n  abstract = \t { Due to the ongoing coronavirus (COVID-19) pandemic,\r an unprecedented amount of SARS-CoV-2 sequence data\r is available. The scale of this data has out-paced\r traditional methods for its analysis, while\r machine-learning approaches aimed at clustering and\r classification of SARS-CoV-2 variants is becoming an\r attractive alternative. Since the SARS-CoV-2 genome\r is highly dimensional, considering the much smaller\r spike region can save a great deal of processing.\r As the spike protein mediates the attachment of the\r coronavirus to the host cell, most of the newer and\r more contagious variants can be characterized by\r alterations to the spike protein; hence it is often\r sufficient for characterizing the different\r SARS-CoV-2 variants. Another important consideration\r is to have a fast feature embedding generation,\r which is the subject of this work.  Applying any\r machine learning (ML) model to a biological sequence\r requires first transforming it into a fixed-length\r (numerical) form. While there exist several compact\r embeddings for SARS-CoV-2 spike protein sequences,\r the generation process is computationally expensive\r since the features, added to the resulting vectors,\r are indexed in a na\u00efve fashion.  To solve this\r problem, we propose a fast and alignment-free\r hashing-based approach to design a fixed-length\r feature embedding for spike protein sequences,\r called Hashing2Vec, which can be used as input to\r any standard ML model. Using real-world data, we\r show that the proposed embedding is not only\r efficient to compute but also outperforms current\r state-of-the-art embedding methods in terms of\r classification accuracy. In terms of runtime, we\r achieve up to a 99.8% improvement in the\r Hashing2Vec-based embedding generation as compared\r to the baselines on a set of 7K spike amino acid\r sequences. It also outperforms the baselines on this\r data in terms of predictive performance and achieves\r accuracy and ROC-AUC scores of 86% and 84.4%,\r respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/taslim23a/taslim23a.pdf",
        "supp": "",
        "pdf_size": 1859613,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7121007244447159968&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA",
        "aff_domain": "student.gsu.edu;student.gsu.edu;student.gsu.edu;gsu.edu",
        "email": "student.gsu.edu;student.gsu.edu;student.gsu.edu;gsu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.gsu.edu",
        "aff_unique_abbr": "GSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e8493932f1",
        "title": "Interpretable Representation Learning from Temporal\r Multi-view Data",
        "site": "https://proceedings.mlr.press/v189/qiu23a.html",
        "author": "Lin Qiu; Vernon M. Chinchilli; Lin Lin",
        "abstract": "In many scientific problems such as video\r surveillance, modern genomics, and finance, data are\r often collected from diverse measurements across\r time that exhibit time-dependent heterogeneous\r properties. Thus, it is important to not only\r integrate data from multiple sources (called\r multi-view data), but also to incorporate time\r dependency for deep understanding of the underlying\r system. We propose a generative model based on\r variational autoencoder and a recurrent neural\r network to infer the latent dynamics for multi-view\r temporal data.  This approach allows us to identify\r the disentangled latent embeddings across views\r while accounting for the time factor. We invoke our\r proposed model for analyzing three datasets on which\r we demonstrate the effectiveness and the\r interpretability of the model.",
        "bibtex": "@InProceedings{pmlr-v189-qiu23a,\n  title = \t {Interpretable Representation Learning from Temporal\r Multi-view Data},\n  author =       {Qiu, Lin and Chinchilli, Vernon M. and Lin, Lin},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {864--879},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/qiu23a/qiu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/qiu23a.html},\n  abstract = \t {In many scientific problems such as video\r surveillance, modern genomics, and finance, data are\r often collected from diverse measurements across\r time that exhibit time-dependent heterogeneous\r properties. Thus, it is important to not only\r integrate data from multiple sources (called\r multi-view data), but also to incorporate time\r dependency for deep understanding of the underlying\r system. We propose a generative model based on\r variational autoencoder and a recurrent neural\r network to infer the latent dynamics for multi-view\r temporal data.  This approach allows us to identify\r the disentangled latent embeddings across views\r while accounting for the time factor. We invoke our\r proposed model for analyzing three datasets on which\r we demonstrate the effectiveness and the\r interpretability of the model.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/qiu23a/qiu23a.pdf",
        "supp": "",
        "pdf_size": 3558930,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:-PktPiE__g4J:scholar.google.com/&scioq=Interpretable+Representation+Learning+from+Temporal%0D+Multi-view+Data&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "aff": "The Pennsylvania State University; The Pennsylvania State University; Duke University",
        "aff_domain": "gmail.com;psu.edu;duke.edu",
        "email": "gmail.com;psu.edu;duke.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Pennsylvania State University;Duke University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.psu.edu;https://www.duke.edu",
        "aff_unique_abbr": "PSU;Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "df4721211d",
        "title": "Kernelized multi-graph matching",
        "site": "https://proceedings.mlr.press/v189/dupe23a.html",
        "author": "Fran\u00e7ois-Xavier Dup\u00e9; Rohit Yadav; Guillaume Auzias; Sylvain Takerkart",
        "abstract": "Multigraph matching is a recent variant of the graph\r matching problem. In this framework, the\r optimization procedure considers several graphs and\r enforces the consistency of the matches along the\r graphs. This constraint can be formalized as a cycle\r consistency across the pairwise permutation\r matrices, which implies the definition of a universe\r of vertex (Pachauri et al., 2013). The label of each\r vertex is encoded by a sparse vector and the\r dimension of this space corresponds to the rank of\r the bulk permutation matrix, the matrix built from\r the aggregation of all the pairwise permutation\r matrices. The matching problem can then be\r formulated as a non-convex quadratic optimization\r problem (QAP) under constraints imposed on the rank\r and the permutations. In this paper, we introduce a\r novel kernelized multigraph matching technique that\r handles vectors of attributes on both the vertices\r and edges of the graphs, while maintaining a low\r memory usage. We solve the QAP problem using a\r projected power optimization approach and propose\r several projectors leading to improved stability of\r the results. We provide several experiments\r showingthat our method is competitive against other\r unsupervised methods.",
        "bibtex": "@InProceedings{pmlr-v189-dupe23a,\n  title = \t {Kernelized multi-graph matching},\n  author =       {Dup{\\'e}, Fran{\\c c}ois-Xavier and Yadav, Rohit and Auzias, Guillaume and Takerkart, Sylvain},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {311--326},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/dupe23a/dupe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/dupe23a.html},\n  abstract = \t {Multigraph matching is a recent variant of the graph\r matching problem. In this framework, the\r optimization procedure considers several graphs and\r enforces the consistency of the matches along the\r graphs. This constraint can be formalized as a cycle\r consistency across the pairwise permutation\r matrices, which implies the definition of a universe\r of vertex (Pachauri et al., 2013). The label of each\r vertex is encoded by a sparse vector and the\r dimension of this space corresponds to the rank of\r the bulk permutation matrix, the matrix built from\r the aggregation of all the pairwise permutation\r matrices. The matching problem can then be\r formulated as a non-convex quadratic optimization\r problem (QAP) under constraints imposed on the rank\r and the permutations. In this paper, we introduce a\r novel kernelized multigraph matching technique that\r handles vectors of attributes on both the vertices\r and edges of the graphs, while maintaining a low\r memory usage. We solve the QAP problem using a\r projected power optimization approach and propose\r several projectors leading to improved stability of\r the results. We provide several experiments\r showingthat our method is competitive against other\r unsupervised methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/dupe23a/dupe23a.pdf",
        "supp": "",
        "pdf_size": 364744,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11793466717723546047&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Aix Marseille Univ, CNRS, LIS, Marseille, France; Aix Marseille Univ, CNRS, INT, Inst Neurosci Timone, Marseille, France+Aix Marseille Univ, CNRS, LIS, Marseille, France+Aix Marseille Univ, Institut Marseille Imaging, Marseille, France; Aix Marseille Univ, CNRS, INT, Inst Neurosci Timone, Marseille, France; Aix Marseille Univ, CNRS, INT, Inst Neurosci Timone, Marseille, France",
        "aff_domain": "univ-amu.fr;univ-amu.fr;univ-amu.fr;univ-amu.fr",
        "email": "univ-amu.fr;univ-amu.fr;univ-amu.fr;univ-amu.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+0+0;0;0",
        "aff_unique_norm": "Aix Marseille University",
        "aff_unique_dep": "CNRS, LIS",
        "aff_unique_url": "https://www.univ-amu.fr",
        "aff_unique_abbr": "AMU",
        "aff_campus_unique_index": "0;0+0+0;0;0",
        "aff_campus_unique": "Marseille",
        "aff_country_unique_index": "0;0+0+0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "86a10c648a",
        "title": "Layer-wise Adaptive Graph Convolution Networks Using\r Generalized Pagerank",
        "site": "https://proceedings.mlr.press/v189/wimalawarne23a.html",
        "author": "Kishan Wimalawarne; Taiji Suzuki",
        "abstract": "We investigate adaptive layer-wise graph\r convolution in deep GCN models. We propose AdaGPR to\r learn generalized Pageranks at each layer of a GCNII\r network to induce adaptive convolution. We show that\r the generalization bound for AdaGPR is bounded by a\r polynomial of the eigenvalue spectrum of the\r normalized adjacency matrix in the order of the\r number of generalized Pagerank coefficients.  By\r analysing the generalization bounds we show that\r oversmoothing depends on both the convolutions by\r the higher orders of the normalized adjacency matrix\r and the depth of the model.  We performed\r evaluations on node-classification using benchmark\r real data and show that AdaGPR provides improved\r accuracies compared to existing graph convolution\r networks while demonstrating robustness against\r oversmoothing. Further, we demonstrate that analysis\r of coefficients of layer-wise generalized Pageranks\r allows us to qualitatively understand convolution at\r each layer enabling model interpretations.",
        "bibtex": "@InProceedings{pmlr-v189-wimalawarne23a,\n  title = \t {Layer-wise Adaptive Graph Convolution Networks Using\r Generalized Pagerank},\n  author =       {Wimalawarne, Kishan and Suzuki, Taiji},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1117--1132},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/wimalawarne23a/wimalawarne23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/wimalawarne23a.html},\n  abstract = \t { We investigate adaptive layer-wise graph\r convolution in deep GCN models. We propose AdaGPR to\r learn generalized Pageranks at each layer of a GCNII\r network to induce adaptive convolution. We show that\r the generalization bound for AdaGPR is bounded by a\r polynomial of the eigenvalue spectrum of the\r normalized adjacency matrix in the order of the\r number of generalized Pagerank coefficients.  By\r analysing the generalization bounds we show that\r oversmoothing depends on both the convolutions by\r the higher orders of the normalized adjacency matrix\r and the depth of the model.  We performed\r evaluations on node-classification using benchmark\r real data and show that AdaGPR provides improved\r accuracies compared to existing graph convolution\r networks while demonstrating robustness against\r oversmoothing. Further, we demonstrate that analysis\r of coefficients of layer-wise generalized Pageranks\r allows us to qualitatively understand convolution at\r each layer enabling model interpretations.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/wimalawarne23a/wimalawarne23a.pdf",
        "supp": "",
        "pdf_size": 341672,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1706756697770257670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Tokyo, Hongo, Japan; University of Tokyo, Hongo, Japan+RIKEN, Nihombashi, Tokyo, Japan",
        "aff_domain": "gmail.com;mist.i.u-tokyo.ac.jp",
        "email": "gmail.com;mist.i.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "0;0+1",
        "aff_campus_unique": "Hongo;Nihombashi",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "d303941de0",
        "title": "Learning Disentangled Representation in Pruning for\r Real-Time UAV Tracking",
        "site": "https://proceedings.mlr.press/v189/ma23a.html",
        "author": "Siyu Ma; Yuting Liu; Dan Zeng; Yaxin Liao; Xiaoyu Xu; Shuiwang Li",
        "abstract": "Efficiency is a critical issue in UAV tracking\r because of the limitations of computing resources,\r battery capacity, and maximum load of unmanned\r aerial vehicle (UAV). However, deep learning\r (DL)-based trackers hardly achieve real-time\r tracking on a single CPU despite their high tracking\r precision. To the contrary, discriminative\r correlation filters (DCF)-based trackers have high\r efficiency but their precision is barely\r satisfactory. Despite the precision is inferior,\r DCF-based trackers instead of DL-based ones are\r widely applied in UAV tracking to trade precision\r for efficiency. This paper aims to improve the\r efficiency of the DL-based tracker SiamFC++, in\r particular, for UAV tracking using the model\r compression technique, i.e., rank-based filter\r pruning, which has not been well explored\r before. Meanwhile, to combat the potential loss of\r precision caused by pruning we exploit disentangled\r representation learning to disentangle the output\r feature of the backbone into two parts: the\r identity-related features and the identity-unrelated\r features. Only the identity-related features are\r used for subsequent classification and regression\r tasks to improve the effectiveness of the feature\r representation. With the proposed disentangled\r representation in pruning, we achieved higher\r precisions when compressing the original model\r SiamFC++ with a global pruning ratio of\r 0.5. Extensive experiments on four public UAV\r benchmarks, i.e., UAV123@10fps, UAVDT, DTB70, and\r Vistrone2018, show that the proposed tracker\r DP-SiamFC++ strikes a remarkable balance between\r efficiency and precision, and achieves\r state-of-the-art performance in UAV tracking.",
        "bibtex": "@InProceedings{pmlr-v189-ma23a,\n  title = \t {Learning Disentangled Representation in Pruning for\r Real-Time UAV Tracking},\n  author =       {Ma, Siyu and Liu, Yuting and Zeng, Dan and Liao, Yaxin and Xu, Xiaoyu and Li, Shuiwang},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {690--705},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/ma23a/ma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/ma23a.html},\n  abstract = \t {Efficiency is a critical issue in UAV tracking\r because of the limitations of computing resources,\r battery capacity, and maximum load of unmanned\r aerial vehicle (UAV). However, deep learning\r (DL)-based trackers hardly achieve real-time\r tracking on a single CPU despite their high tracking\r precision. To the contrary, discriminative\r correlation filters (DCF)-based trackers have high\r efficiency but their precision is barely\r satisfactory. Despite the precision is inferior,\r DCF-based trackers instead of DL-based ones are\r widely applied in UAV tracking to trade precision\r for efficiency. This paper aims to improve the\r efficiency of the DL-based tracker SiamFC++, in\r particular, for UAV tracking using the model\r compression technique, i.e., rank-based filter\r pruning, which has not been well explored\r before. Meanwhile, to combat the potential loss of\r precision caused by pruning we exploit disentangled\r representation learning to disentangle the output\r feature of the backbone into two parts: the\r identity-related features and the identity-unrelated\r features. Only the identity-related features are\r used for subsequent classification and regression\r tasks to improve the effectiveness of the feature\r representation. With the proposed disentangled\r representation in pruning, we achieved higher\r precisions when compressing the original model\r SiamFC++ with a global pruning ratio of\r 0.5. Extensive experiments on four public UAV\r benchmarks, i.e., UAV123@10fps, UAVDT, DTB70, and\r Vistrone2018, show that the proposed tracker\r DP-SiamFC++ strikes a remarkable balance between\r efficiency and precision, and achieves\r state-of-the-art performance in UAV tracking.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/ma23a/ma23a.pdf",
        "supp": "",
        "pdf_size": 5505445,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5721402775721772060&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Guilin University of Technology, Guilin, China; JD Logistic, Beijing, China; Southern University of Science and Technology, Shenzhen, China; Guilin University of Technology, Guilin, China; Guilin University of Technology, Guilin, China; Guilin University of Technology, Guilin, China",
        "aff_domain": "yeah.net;gmail.com;sustech.edu.cn;163.com;163.com;163.com",
        "email": "yeah.net;gmail.com;sustech.edu.cn;163.com;163.com;163.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "Guilin University of Technology;JD;Southern University of Science and Technology",
        "aff_unique_dep": ";JD Logistic;",
        "aff_unique_url": "http://www.gut.edu.cn;https://www.jd.com;https://www.sustech.edu.cn",
        "aff_unique_abbr": ";JD;SUSTech",
        "aff_campus_unique_index": "0;2;0;0;0",
        "aff_campus_unique": "Guilin;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "bb0472dca9",
        "title": "Learning Practical Communication Strategies in\r Cooperative Multi-Agent Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v189/hu23a.html",
        "author": "Diyi Hu; Chi Zhang; Viktor Prasanna; Bhaskar Krishnamachari",
        "abstract": "In Multi-Agent Reinforcement Learning, communication\r is critical to encourage cooperation among\r agents. Communication in realistic wireless networks\r can be highly unreliable due to network conditions\r varying with agents\u2019 mobility, and stochasticity in\r the transmission process. We propose a framework to\r learn practical communication strategies by\r addressing three fundamental questions: (1)\r \\emph{When}: Agents learn the timing of\r communication based on not only message importance\r but also wireless channel conditions. (2)\r \\emph{What}: Agents augment message contents with\r wireless network measurements to better select the\r game and communication actions. (3) \\emph{How}:\r Agents use a novel neural message encoder to\r preserve all information from received messages,\r regardless of the number and order of\r messages. Simulating standard benchmarks under\r realistic wireless network settings, we show\r significant improvements in game performance,\r convergence speed and communication efficiency\r compared with state-of-the-art.",
        "bibtex": "@InProceedings{pmlr-v189-hu23a,\n  title = \t {Learning Practical Communication Strategies in\r Cooperative Multi-Agent Reinforcement Learning},\n  author =       {Hu, Diyi and Zhang, Chi and Prasanna, Viktor and Krishnamachari, Bhaskar},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {467--482},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/hu23a/hu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/hu23a.html},\n  abstract = \t {In Multi-Agent Reinforcement Learning, communication\r is critical to encourage cooperation among\r agents. Communication in realistic wireless networks\r can be highly unreliable due to network conditions\r varying with agents\u2019 mobility, and stochasticity in\r the transmission process. We propose a framework to\r learn practical communication strategies by\r addressing three fundamental questions: (1)\r \\emph{When}: Agents learn the timing of\r communication based on not only message importance\r but also wireless channel conditions. (2)\r \\emph{What}: Agents augment message contents with\r wireless network measurements to better select the\r game and communication actions. (3) \\emph{How}:\r Agents use a novel neural message encoder to\r preserve all information from received messages,\r regardless of the number and order of\r messages. Simulating standard benchmarks under\r realistic wireless network settings, we show\r significant improvements in game performance,\r convergence speed and communication efficiency\r compared with state-of-the-art.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/hu23a/hu23a.pdf",
        "supp": "",
        "pdf_size": 464619,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9466618498259685573&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Southern California, Los Angeles, CA 90007; University of Southern California, Los Angeles, CA 90007; University of Southern California, Los Angeles, CA 90007; University of Southern California, Los Angeles, CA 90007",
        "aff_domain": "usc.edu;usc.edu;usc.edu;usc.edu",
        "email": "usc.edu;usc.edu;usc.edu;usc.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7b1449a42a",
        "title": "Learning with Domain Knowledge to Develop\r Justifiable Convolutional Networks",
        "site": "https://proceedings.mlr.press/v189/bhosale23a.html",
        "author": "Rimmon Bhosale; Mrinal Das",
        "abstract": "The inherent structure of the Convolutional Neural\r Networks (CNN) allows them to extract features that\r are highly correlated with the classes while\r performing image classification. However, it may\r happen that the extracted features are merely\r coincidental and may not be justifiable from a human\r perspective. For example, from a set of images of\r cows on grassland, CNN can erroneously extract grass\r as the feature of the class cow. There are two main\r limitations to this kind of learning: firstly, in\r many false-negative cases, correct features will not\r be used, and secondly, in false-positive cases the\r system will lack accountability. There is no\r implicit way to inform CNN to learn the features\r that are justifiable from a human perspective to\r resolve these issues. In this paper, we argue that\r if we provide domain knowledge to guide the learning\r process of CNN, it is possible to reliably learn the\r justifiable features. We propose a systematic yet\r simple mechanism to incorporate domain knowledge to\r guide the learning process of the CNNs to extract\r justifiable features. The flip side is that it needs\r additional input. However, we have shown that even\r with minimal additional input our method can\r effectively propagate the knowledge within a class\r during training. We demonstrate that justifiable\r features not only enhance accuracy but also demand\r less amount of data and training time. Moreover, we\r also show that the proposed method is more robust\r against perturbational changes in the input images.",
        "bibtex": "@InProceedings{pmlr-v189-bhosale23a,\n  title = \t {Learning with Domain Knowledge to Develop\r Justifiable Convolutional Networks},\n  author =       {Bhosale, Rimmon and Das, Mrinal},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {64--79},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/bhosale23a/bhosale23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/bhosale23a.html},\n  abstract = \t {The inherent structure of the Convolutional Neural\r Networks (CNN) allows them to extract features that\r are highly correlated with the classes while\r performing image classification. However, it may\r happen that the extracted features are merely\r coincidental and may not be justifiable from a human\r perspective. For example, from a set of images of\r cows on grassland, CNN can erroneously extract grass\r as the feature of the class cow. There are two main\r limitations to this kind of learning: firstly, in\r many false-negative cases, correct features will not\r be used, and secondly, in false-positive cases the\r system will lack accountability. There is no\r implicit way to inform CNN to learn the features\r that are justifiable from a human perspective to\r resolve these issues. In this paper, we argue that\r if we provide domain knowledge to guide the learning\r process of CNN, it is possible to reliably learn the\r justifiable features. We propose a systematic yet\r simple mechanism to incorporate domain knowledge to\r guide the learning process of the CNNs to extract\r justifiable features. The flip side is that it needs\r additional input. However, we have shown that even\r with minimal additional input our method can\r effectively propagate the knowledge within a class\r during training. We demonstrate that justifiable\r features not only enhance accuracy but also demand\r less amount of data and training time. Moreover, we\r also show that the proposed method is more robust\r against perturbational changes in the input images.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/bhosale23a/bhosale23a.pdf",
        "supp": "",
        "pdf_size": 3798555,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9069740990956722397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Indian Institute of Technology, Palakkad, Kerala, India; Indian Institute of Technology, Palakkad, Kerala, India",
        "aff_domain": "gmail.com;iitpkd.ac.in",
        "email": "gmail.com;iitpkd.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Palakkad",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iitpkd.ac.in",
        "aff_unique_abbr": "IIT Palakkad",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Palakkad",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "07325772d4",
        "title": "Learning with Interactive Models over\r Decision-Dependent Distributions",
        "site": "https://proceedings.mlr.press/v189/yuan23a.html",
        "author": "Man-Jie Yuan; Wei Gao",
        "abstract": "Classical supervised learning generally trains one\r model from an i.i.d. data according to an unknown\r yet fixed distribution. In some real applications\r such as finance, however, multiple models may be\r trained by different companies and interacted in a\r dynamic environment, where the data distribution may\r take shift according to different models\u2019\r decisions. In this work, we study two models for\r simplicity, and formalize such scenario as a\r learning problem of two models over\r decision-dependent distributions. We develop the\r Repeated Risk Minimization (RRM) for two models, and\r present a sufficient condition to the existence of\r stable points for RRM, that is, an equilibrium\r notion. We further provide the theoretical analysis\r for the convergence of RRM to stable points based on\r data distribution and finite training sample,\r respectively. We also study more practical\r algorithms, such as gradient descent and stochastic\r gradient descent, to solve the RRM problem with\r convergence guarantees and we finally present some\r empirical studies to validate our theoretical\r analysis.",
        "bibtex": "@InProceedings{pmlr-v189-yuan23a,\n  title = \t {Learning with Interactive Models over\r Decision-Dependent Distributions},\n  author =       {Yuan, Man-Jie and Gao, Wei},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1229--1244},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/yuan23a/yuan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/yuan23a.html},\n  abstract = \t {Classical supervised learning generally trains one\r model from an i.i.d. data according to an unknown\r yet fixed distribution. In some real applications\r such as finance, however, multiple models may be\r trained by different companies and interacted in a\r dynamic environment, where the data distribution may\r take shift according to different models\u2019\r decisions. In this work, we study two models for\r simplicity, and formalize such scenario as a\r learning problem of two models over\r decision-dependent distributions. We develop the\r Repeated Risk Minimization (RRM) for two models, and\r present a sufficient condition to the existence of\r stable points for RRM, that is, an equilibrium\r notion. We further provide the theoretical analysis\r for the convergence of RRM to stable points based on\r data distribution and finite training sample,\r respectively. We also study more practical\r algorithms, such as gradient descent and stochastic\r gradient descent, to solve the RRM problem with\r convergence guarantees and we finally present some\r empirical studies to validate our theoretical\r analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/yuan23a/yuan23a.pdf",
        "supp": "",
        "pdf_size": 2474682,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8584875707364703068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2d8a3f832b",
        "title": "Locally Differentially Private Reinforcement\r Learning for Linear Mixture Markov Decision\r Processes",
        "site": "https://proceedings.mlr.press/v189/liao23a.html",
        "author": "Chonghua Liao; Jiafan He; Quanquan Gu",
        "abstract": "Reinforcement learning (RL) algorithms can be used\r to provide personalized services, which rely on\r users\u2019 private and sensitive data. To protect the\r users\u2019 privacy, privacy-preserving RL algorithms are\r in demand. In this paper, we study RL with linear\r function approximation and local differential\r privacy (LDP) guarantees. We propose a novel\r $(\\varepsilon, \\delta)$-LDP algorithm for learning a\r class of Markov decision processes (MDPs) dubbed\r linear mixture MDPs, and obtains an\r $\\tilde{\\mathcal{O}}(\r d^{5/4}H^{7/4}T^{3/4}\\left(\\log(1/\\delta)\\right)^{1/4}\\sqrt{1/\\varepsilon})$\r regret, where $d$ is the dimension of feature\r mapping, $H$ is the length of the planning horizon,\r and $T$ is the number of interactions with the\r environment.  We also prove a lower bound\r $\\Omega(dH\\sqrt{T}/\\left(e^{\\varepsilon}(e^{\\varepsilon}-1)\\right))$\r for learning linear mixture MDPs under\r $\\varepsilon$-LDP constraint. Experiments on\r synthetic datasets verify the effectiveness of our\r algorithm. To the best of our knowledge, this is the\r first provable privacy-preserving RL algorithm with\r linear function approximation.",
        "bibtex": "@InProceedings{pmlr-v189-liao23a,\n  title = \t {Locally Differentially Private Reinforcement\r Learning for Linear Mixture Markov Decision\r Processes},\n  author =       {Liao, Chonghua and He, Jiafan and Gu, Quanquan},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {627--642},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/liao23a/liao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/liao23a.html},\n  abstract = \t {Reinforcement learning (RL) algorithms can be used\r to provide personalized services, which rely on\r users\u2019 private and sensitive data. To protect the\r users\u2019 privacy, privacy-preserving RL algorithms are\r in demand. In this paper, we study RL with linear\r function approximation and local differential\r privacy (LDP) guarantees. We propose a novel\r $(\\varepsilon, \\delta)$-LDP algorithm for learning a\r class of Markov decision processes (MDPs) dubbed\r linear mixture MDPs, and obtains an\r $\\tilde{\\mathcal{O}}(\r d^{5/4}H^{7/4}T^{3/4}\\left(\\log(1/\\delta)\\right)^{1/4}\\sqrt{1/\\varepsilon})$\r regret, where $d$ is the dimension of feature\r mapping, $H$ is the length of the planning horizon,\r and $T$ is the number of interactions with the\r environment.  We also prove a lower bound\r $\\Omega(dH\\sqrt{T}/\\left(e^{\\varepsilon}(e^{\\varepsilon}-1)\\right))$\r for learning linear mixture MDPs under\r $\\varepsilon$-LDP constraint. Experiments on\r synthetic datasets verify the effectiveness of our\r algorithm. To the best of our knowledge, this is the\r first provable privacy-preserving RL algorithm with\r linear function approximation.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/liao23a/liao23a.pdf",
        "supp": "",
        "pdf_size": 3052683,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9575738557814278367&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Automation, Tsinghua University, Beijing, China, 100084; Department of Computer Science, University of California, Los Angeles, CA 90095, USA; Department of Computer Science, University of California, Los Angeles, CA 90095, USA",
        "aff_domain": "mails.tsinghua.edu.cn;ucla.edu;cs.ucla.edu",
        "email": "mails.tsinghua.edu.cn;ucla.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tsinghua University;University of California, Los Angeles",
        "aff_unique_dep": "Department of Automation;Department of Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.ucla.edu",
        "aff_unique_abbr": "THU;UCLA",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Beijing;Los Angeles",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9b69146faa",
        "title": "Margin Calibration for Long-Tailed Visual\r Recognition",
        "site": "https://proceedings.mlr.press/v189/wang23b.html",
        "author": "Yidong Wang; Bowen Zhang; Wenxin Hou; Zhen Wu; Jindong Wang; Takahiro Shinozaki",
        "abstract": "Long-tailed visual recognition tasks pose great\r challenges for neural networks on how to handle the\r imbalanced predictions between head (common) and\r tail (rare) classes, i.e., models tend to classify\r tail classes as head classes. While existing\r research focused on data resampling and loss\r function engineering, in this paper, we take a\r different perspective: the classification\r margins. We study the relationship between the\r margins and logits and empirically observe that the\r uncalibrated margins and logits are positively\r correlated. We propose a simple yet effective MARgin\r Calibration approach (MARC) to calibrate the margins\r to obtain better logits. We validate MARC through\r extensive experiments on common long-tailed\r benchmarks including CIFAR-LT, ImageNet-LT,\r Places-LT, and iNaturalist-LT. Experimental results\r demonstrate that our MARC achieves favorable results\r on these benchmarks. In addition, MARC is extremely\r easy to implement with just three lines of code. We\r hope this simple approach will motivate people to\r rethink the uncalibrated margins and logits in\r long-tailed visual recognition.",
        "bibtex": "@InProceedings{pmlr-v189-wang23b,\n  title = \t {Margin Calibration for Long-Tailed Visual\r Recognition},\n  author =       {Wang, Yidong and Zhang, Bowen and Hou, Wenxin and Wu, Zhen and Wang, Jindong and Shinozaki, Takahiro},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1101--1116},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/wang23b/wang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/wang23b.html},\n  abstract = \t {Long-tailed visual recognition tasks pose great\r challenges for neural networks on how to handle the\r imbalanced predictions between head (common) and\r tail (rare) classes, i.e., models tend to classify\r tail classes as head classes. While existing\r research focused on data resampling and loss\r function engineering, in this paper, we take a\r different perspective: the classification\r margins. We study the relationship between the\r margins and logits and empirically observe that the\r uncalibrated margins and logits are positively\r correlated. We propose a simple yet effective MARgin\r Calibration approach (MARC) to calibrate the margins\r to obtain better logits. We validate MARC through\r extensive experiments on common long-tailed\r benchmarks including CIFAR-LT, ImageNet-LT,\r Places-LT, and iNaturalist-LT. Experimental results\r demonstrate that our MARC achieves favorable results\r on these benchmarks. In addition, MARC is extremely\r easy to implement with just three lines of code. We\r hope this simple approach will motivate people to\r rethink the uncalibrated margins and logits in\r long-tailed visual recognition.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/wang23b/wang23b.pdf",
        "supp": "",
        "pdf_size": 591324,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2063557883608678280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Tokyo Institute of Technology; Tokyo Institute of Technology; Microsoft STCA; Nanjing University+Microsoft Research Asia; Microsoft Research Asia; Tokyo Institute of Technology",
        "aff_domain": "tokyo-tech.ac.jp;tokyo-tech.ac.jp;microsoft.com;nju.edu.cn;microsoft.com;tokyo-tech.ac.jp",
        "email": "tokyo-tech.ac.jp;tokyo-tech.ac.jp;microsoft.com;nju.edu.cn;microsoft.com;tokyo-tech.ac.jp",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2+1;1;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Microsoft;Nanjing University",
        "aff_unique_dep": ";STCA;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.microsoft.com;https://www.nju.edu.cn",
        "aff_unique_abbr": "Titech;Microsoft;Nanjing U",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Asia",
        "aff_country_unique_index": "0;0;1;2+2;2;0",
        "aff_country_unique": "Japan;United States;China"
    },
    {
        "id": "c1d73e1fe7",
        "title": "Multi Label Loss Correction against Missing and\r Corrupted Labels",
        "site": "https://proceedings.mlr.press/v189/ghiassi23b.html",
        "author": "Amirmasoud Ghiassi; Robert Birke; Lydia.Y Chen",
        "abstract": "Missing and corrupted labels can significantly ruin\r the learning process and, consequently, the\r classifier performance. Multi-label learning where\r each instance is tagged with variable number of\r labels is particularly affected. Although missing\r labels (false-negatives) is a well-studied problem\r in multi-label learning, it is considerably more\r challenging to have both false-negatives (missing\r labels) and false-positives (corrupted labels)\r simultaneously in multi-label datasets. In this\r paper, we propose Multi-Label Loss with Self\r Correction (MLLSC) which is a loss robust against\r coincident missing and corrupted labels. MLLSC\r computes the loss based on the true-positive\r (true-negative) or false-positive (false-negative)\r labels and deep neural network expertise. To\r distinguish between false-positive (false-negative)\r and true-positive (true-negative) labels, we use the\r output probability of the deep neural network during\r the learning process. Our method As MLLSC can be\r combined with different types of multi-label loss\r functions, we also address the label imbalance\r problem of multi-label datasets. Empirical\r evaluation on real-world vision datasets, i.e.,\r MS-COCO, and MIR-FLICKR, shows that our method under\r medium (0.3) and high (0.6) corrupted and missing\r label probabilities outperform the state-of-the-art\r methods by, on average 23.97% and 9.31% mean average\r precision (mAP) points, respectively.",
        "bibtex": "@InProceedings{pmlr-v189-ghiassi23b,\n  title = \t {Multi Label Loss Correction against Missing and\r Corrupted Labels},\n  author =       {Ghiassi, Amirmasoud and Birke, Robert and Chen, Lydia.Y},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {359--374},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/ghiassi23b/ghiassi23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/ghiassi23b.html},\n  abstract = \t {Missing and corrupted labels can significantly ruin\r the learning process and, consequently, the\r classifier performance. Multi-label learning where\r each instance is tagged with variable number of\r labels is particularly affected. Although missing\r labels (false-negatives) is a well-studied problem\r in multi-label learning, it is considerably more\r challenging to have both false-negatives (missing\r labels) and false-positives (corrupted labels)\r simultaneously in multi-label datasets. In this\r paper, we propose Multi-Label Loss with Self\r Correction (MLLSC) which is a loss robust against\r coincident missing and corrupted labels. MLLSC\r computes the loss based on the true-positive\r (true-negative) or false-positive (false-negative)\r labels and deep neural network expertise. To\r distinguish between false-positive (false-negative)\r and true-positive (true-negative) labels, we use the\r output probability of the deep neural network during\r the learning process. Our method As MLLSC can be\r combined with different types of multi-label loss\r functions, we also address the label imbalance\r problem of multi-label datasets. Empirical\r evaluation on real-world vision datasets, i.e.,\r MS-COCO, and MIR-FLICKR, shows that our method under\r medium (0.3) and high (0.6) corrupted and missing\r label probabilities outperform the state-of-the-art\r methods by, on average 23.97% and 9.31% mean average\r precision (mAP) points, respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/ghiassi23b/ghiassi23b.pdf",
        "supp": "",
        "pdf_size": 2086396,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5217186313923110490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Delft University of Technology, Delft, Netherlands; Computer Science dept., University of Turin, Turin, Italy; Delft University of Technology, Delft, Netherlands",
        "aff_domain": "tudelft.nl;unito.it;ieee.org",
        "email": "tudelft.nl;unito.it;ieee.org",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Delft University of Technology;University of Turin",
        "aff_unique_dep": ";Computer Science dept.",
        "aff_unique_url": "https://www.tudelft.nl;https://www.unito.it",
        "aff_unique_abbr": "TU Delft;UniTO",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Delft;Turin",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Netherlands;Italy"
    },
    {
        "id": "2b11d5058c",
        "title": "Multi-Scale Anomaly Detection for Time Series with\r Attention-based Recurrent Autoencoders",
        "site": "https://proceedings.mlr.press/v189/qingning23a.html",
        "author": "Lu Qingning; Li Wenzhong; Zhu Chuanze; Chen Yizhou; Wang Yinke; Zhang Zhijie; Shen Linshan; Lu Sanglu",
        "abstract": "Anomaly detection on time series is an important\r research topic in data mining, which has a wide\r range of applications in financial markets,\r biological data, information technology,\r manufacturing system, etc. However, the existing\r time series anomaly detection methods mainly capture\r temporal features from a single-scale viewpoint,\r which cannot detect multi-scale anomalies\r effectively. In this paper, we propose a novel\r approach of Multi-scale Anomaly Detection for Time\r Series (MAD-TS) with an attention-based recurrent\r autoencoder model to solve the above problem. The\r proposed method adopts a hierarchically connected\r recurrent encoder to extract the features of a time\r series from different levels. The multi-scale\r features are then fused by a hierarchical decoder\r with attention mechanism to reconstruct the original\r sequence at different scales. Based on the\r reconstruction errors at multiple scales, anomaly\r scores can be learned for different data points,\r which can be used to infer the anomaly status of the\r time series. Extensive experiments based on five\r open time series datasets show that the proposed\r MAD-TS method achieves significant performance\r improvement on anomaly detection compared to the\r state-of-the-arts.",
        "bibtex": "@InProceedings{pmlr-v189-qingning23a,\n  title = \t {Multi-Scale Anomaly Detection for Time Series with\r Attention-based Recurrent Autoencoders},\n  author =       {Qingning, Lu and Wenzhong, Li and Chuanze, Zhu and Yizhou, Chen and Yinke, Wang and Zhijie, Zhang and Linshan, Shen and Sanglu, Lu},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {674--689},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/qingning23a/qingning23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/qingning23a.html},\n  abstract = \t {Anomaly detection on time series is an important\r research topic in data mining, which has a wide\r range of applications in financial markets,\r biological data, information technology,\r manufacturing system, etc. However, the existing\r time series anomaly detection methods mainly capture\r temporal features from a single-scale viewpoint,\r which cannot detect multi-scale anomalies\r effectively. In this paper, we propose a novel\r approach of Multi-scale Anomaly Detection for Time\r Series (MAD-TS) with an attention-based recurrent\r autoencoder model to solve the above problem. The\r proposed method adopts a hierarchically connected\r recurrent encoder to extract the features of a time\r series from different levels. The multi-scale\r features are then fused by a hierarchical decoder\r with attention mechanism to reconstruct the original\r sequence at different scales. Based on the\r reconstruction errors at multiple scales, anomaly\r scores can be learned for different data points,\r which can be used to infer the anomaly status of the\r time series. Extensive experiments based on five\r open time series datasets show that the proposed\r MAD-TS method achieves significant performance\r improvement on anomaly detection compared to the\r state-of-the-arts.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/qingning23a/qingning23a.pdf",
        "supp": "",
        "pdf_size": 1556746,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13010351074229917609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing; Department of Computer Science and Technology, Nanjing University, Nanjing",
        "aff_domain": "smail.nju.edu.cn;nju.edu.cn;smail.nju.edu.cn;smail.nju.edu.cn;smail.nju.edu.cn;163.com;smail.nju.edu.cn;nju.edu.cn",
        "email": "smail.nju.edu.cn;nju.edu.cn;smail.nju.edu.cn;smail.nju.edu.cn;smail.nju.edu.cn;163.com;smail.nju.edu.cn;nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "db13fa0b2a",
        "title": "Multi-class Classification from Multiple Unlabeled\r Datasets with Partial Risk Regularization",
        "site": "https://proceedings.mlr.press/v189/tang23a.html",
        "author": "Yuting Tang; Nan Lu; Tianyi Zhang; Masashi Sugiyama",
        "abstract": "Recent years have witnessed a great success of\r supervised deep learning, where predictive models\r were trained from a large amount of fully labeled\r data. However, in practice, labeling such big data\r can be very costly and may not even be possible for\r privacy reasons. Therefore, in this paper, we aim to\r learn an accurate classifier without any class\r labels. More specifically, we consider the case\r where multiple sets of unlabeled data and only their\r class priors, i.e., the proportions of each class,\r are available. Under this problem setup, we first\r derive an unbiased estimator of the classification\r risk that can be estimated from the given unlabeled\r sets and theoretically analyze the generalization\r error of the learned classifier. We then find that\r the classifier obtained as such tends to cause\r overfitting as its empirical risks go negative\r during training. To prevent overfitting, we further\r propose a partial risk regularization that maintains\r the partial risks with respect to unlabeled datasets\r and classes to certain levels. Experiments\r demonstrate that our method effectively mitigates\r overfitting and outperforms state-of-the-art methods\r for learning from multiple unlabeled sets.",
        "bibtex": "@InProceedings{pmlr-v189-tang23a,\n  title = \t {Multi-class Classification from Multiple Unlabeled\r Datasets with Partial Risk Regularization},\n  author =       {Tang, Yuting and Lu, Nan and Zhang, Tianyi and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {990--1005},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/tang23a/tang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/tang23a.html},\n  abstract = \t {Recent years have witnessed a great success of\r supervised deep learning, where predictive models\r were trained from a large amount of fully labeled\r data. However, in practice, labeling such big data\r can be very costly and may not even be possible for\r privacy reasons. Therefore, in this paper, we aim to\r learn an accurate classifier without any class\r labels. More specifically, we consider the case\r where multiple sets of unlabeled data and only their\r class priors, i.e., the proportions of each class,\r are available. Under this problem setup, we first\r derive an unbiased estimator of the classification\r risk that can be estimated from the given unlabeled\r sets and theoretically analyze the generalization\r error of the learned classifier. We then find that\r the classifier obtained as such tends to cause\r overfitting as its empirical risks go negative\r during training. To prevent overfitting, we further\r propose a partial risk regularization that maintains\r the partial risks with respect to unlabeled datasets\r and classes to certain levels. Experiments\r demonstrate that our method effectively mitigates\r overfitting and outperforms state-of-the-art methods\r for learning from multiple unlabeled sets.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/tang23a/tang23a.pdf",
        "supp": "",
        "pdf_size": 614351,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6915277101129272195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Tokyo/RIKEN, Japan; The University of Tokyo/RIKEN, Japan; The University of Tokyo/RIKEN, Japan; RIKEN/The University of Tokyo, Japan",
        "aff_domain": "ms.k.u-tokyo.ac.jp;ms.k.u-tokyo.ac.jp;ms.k.u-tokyo.ac.jp;k.u-tokyo.ac.jp",
        "email": "ms.k.u-tokyo.ac.jp;ms.k.u-tokyo.ac.jp;ms.k.u-tokyo.ac.jp;k.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "df58c235f5",
        "title": "Multi-scale Progressive Gated Transformer for\r Physiological Signal Classification",
        "site": "https://proceedings.mlr.press/v189/zhou23b.html",
        "author": "Wei Zhou; Hao Wang; Yiling Zhang; Cheng Long; Yan Yang; Dongjie Wang",
        "abstract": "Physiological signal classification is of great\r significance for health monitoring and medical\r diagnosis. Deep learning-based methods (e.g. RNN and\r CNN) have been used in this domain to obtain\r reliable predictions. However, the performance of\r existing methods is constrained by the long-term\r dependence and irregular vibration of the univariate\r physiological signal sequence. To overcome these\r limitations, this paper proposes a Multi-scale\r Progressive Gated Transformer (MPGT) model to learn\r multi-scale temporal representations for better\r physiological signal classification. The key\r novelties of MPGT are the proposed Multi-scale\r Temporal Feature extraction (MTF) and Progressive\r Gated Transformer (PGT). The former adopts coarse-\r and fine-grained feature extractors to project the\r input signal data into different temporal\r granularity embedding spaces and the latter\r integrates such multi-scale information for data\r representation. Classification task is then\r conducted on the learned\r representations. Experimental results on real-world\r datasets demonstrate the superiority of the proposed\r model.",
        "bibtex": "@InProceedings{pmlr-v189-zhou23b,\n  title = \t {Multi-scale Progressive Gated Transformer for\r Physiological Signal Classification},\n  author =       {Zhou, Wei and Wang, Hao and Zhang, Yiling and Long, Cheng and Yang, Yan and Wang, Dongjie},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1293--1308},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/zhou23b/zhou23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/zhou23b.html},\n  abstract = \t {Physiological signal classification is of great\r significance for health monitoring and medical\r diagnosis. Deep learning-based methods (e.g. RNN and\r CNN) have been used in this domain to obtain\r reliable predictions. However, the performance of\r existing methods is constrained by the long-term\r dependence and irregular vibration of the univariate\r physiological signal sequence. To overcome these\r limitations, this paper proposes a Multi-scale\r Progressive Gated Transformer (MPGT) model to learn\r multi-scale temporal representations for better\r physiological signal classification. The key\r novelties of MPGT are the proposed Multi-scale\r Temporal Feature extraction (MTF) and Progressive\r Gated Transformer (PGT). The former adopts coarse-\r and fine-grained feature extractors to project the\r input signal data into different temporal\r granularity embedding spaces and the latter\r integrates such multi-scale information for data\r representation. Classification task is then\r conducted on the learned\r representations. Experimental results on real-world\r datasets demonstrate the superiority of the proposed\r model.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/zhou23b/zhou23b.pdf",
        "supp": "",
        "pdf_size": 1134916,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9886779680786745369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Southwest Jiaotong University; Nanyang Technological University; Southwest Jiaotong University; Nanyang Technological University; Southwest Jiaotong University; University of Central Florida",
        "aff_domain": "my.swjtu.edu.cn;gmail.com;foxmail.com;ntu.edu.sg;swjtu.edu.cn;knights.ucf.edu",
        "email": "my.swjtu.edu.cn;gmail.com;foxmail.com;ntu.edu.sg;swjtu.edu.cn;knights.ucf.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;0;2",
        "aff_unique_norm": "Southwest Jiao Tong University;Nanyang Technological University;University of Central Florida",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.swjtu.edu.cn;https://www.ntu.edu.sg;https://www.ucf.edu",
        "aff_unique_abbr": "SWJTU;NTU;UCF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;0;2",
        "aff_country_unique": "China;Singapore;United States"
    },
    {
        "id": "d28316702d",
        "title": "Multiple Imputation with Neural Network Gaussian\r Process for High-dimensional Incomplete Data",
        "site": "https://proceedings.mlr.press/v189/dai23a.html",
        "author": "Zongyu Dai; Zhiqi Bu; Qi Long",
        "abstract": "Missing data are ubiquitous in real world\r applications and, if not adequately handled, may\r lead to the loss of information and biased findings\r in downstream analysis. Particularly,\r high-dimensional incomplete data with a moderate\r sample size, such as analysis of multi-omics data,\r present daunting challenges. Imputation is arguably\r the most popular method for handling missing data,\r though existing imputation methods have a number of\r limitations. Single imputation methods such as\r matrix completion methods do not adequately account\r for imputation uncertainty and hence would yield\r improper statistical inference. In contrast,\r multiple imputation (MI) methods allow for proper\r inference but existing methods do not perform well\r in high-dimensional settings. Our work aims to\r address these significant methodological gaps,\r leveraging recent advances in neural network\r Gaussian process (NNGP) from a Bayesian\r viewpoint. We propose two NNGP-based MI methods,\r namely MI-NNGP, that can apply multiple imputations\r for missing values from a joint (posterior\r predictive) distribution. The MI-NNGP methods are\r shown to significantly outperform existing\r state-of-the-art methods on synthetic and real\r datasets, in terms of imputation error, statistical\r inference, robustness to missing rates, and\r computation costs, under three missing data\r mechanisms, MCAR, MAR, and MNAR.",
        "bibtex": "@InProceedings{pmlr-v189-dai23a,\n  title = \t {Multiple Imputation with Neural Network Gaussian\r Process for High-dimensional Incomplete Data},\n  author =       {Dai, Zongyu and Bu, Zhiqi and Long, Qi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {265--279},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/dai23a/dai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/dai23a.html},\n  abstract = \t {Missing data are ubiquitous in real world\r applications and, if not adequately handled, may\r lead to the loss of information and biased findings\r in downstream analysis. Particularly,\r high-dimensional incomplete data with a moderate\r sample size, such as analysis of multi-omics data,\r present daunting challenges. Imputation is arguably\r the most popular method for handling missing data,\r though existing imputation methods have a number of\r limitations. Single imputation methods such as\r matrix completion methods do not adequately account\r for imputation uncertainty and hence would yield\r improper statistical inference. In contrast,\r multiple imputation (MI) methods allow for proper\r inference but existing methods do not perform well\r in high-dimensional settings. Our work aims to\r address these significant methodological gaps,\r leveraging recent advances in neural network\r Gaussian process (NNGP) from a Bayesian\r viewpoint. We propose two NNGP-based MI methods,\r namely MI-NNGP, that can apply multiple imputations\r for missing values from a joint (posterior\r predictive) distribution. The MI-NNGP methods are\r shown to significantly outperform existing\r state-of-the-art methods on synthetic and real\r datasets, in terms of imputation error, statistical\r inference, robustness to missing rates, and\r computation costs, under three missing data\r mechanisms, MCAR, MAR, and MNAR.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/dai23a/dai23a.pdf",
        "supp": "",
        "pdf_size": 430146,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1051618047856800229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Graduate Group in Applied Mathematics and Computational Science, University of Pennsylvania; Graduate Group in Applied Mathematics and Computational Science, University of Pennsylvania; Division of Biostatistics, University of Pennsylvania",
        "aff_domain": "sas.upenn.edu;sas.upenn.edu;sas.upenn.edu",
        "email": "sas.upenn.edu;sas.upenn.edu;sas.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Graduate Group in Applied Mathematics and Computational Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2a1633ae08",
        "title": "Nighttime Semantic Segmentation with Unsupervised\r Learning and Cross Attention",
        "site": "https://proceedings.mlr.press/v189/cheng23a.html",
        "author": "Jian Cheng; Yang-Feng Hu; Yu Dai; Xue Qiao; Li Yao; Jun-Yan Yang",
        "abstract": "In recent years, semantic segmentation has shown\r very good performance in daytime scenes. But in\r nighttime scenes, semantic segmentation greatly\r reduces its accuracy. Due to the lack of large-scale\r nighttime semantic segmentation datasets, it is\r difficult to directly train segmentation models for\r nighttime scenes. Therefore, it becomes important to\r adapt the daytime scene segmentation model to the\r nighttime scene without directly using the nighttime\r scene segmentation dataset. In this paper, we\r propose a framework based on unsupervised learning\r and cross attention. The proposed method fuses\r supervised daytime scenes and unsupervised nighttime\r scenes, the supervision information in the daytime\r scene and the texture information specific to the\r nighttime scene are fully utilized, and the model is\r adapted to both the daytime scene and the nighttime\r scene. Consistency regulation is used to make\r segmentation model adapt to the complex and\r changeable night scene texture and illumination. In\r view of the coarse correspondence of static objects\r between day and night image pairs in the Dark Zurich\r dataset, cross attention is proposed to make the\r model pay more attention to the parts of the night\r scene which are similar to the daytime\r scene. Extensive experiments on Dark Zurich and\r Nighttime Driving datasets show that our method\r obtains better performance in nighttime semantic\r segmentation.",
        "bibtex": "@InProceedings{pmlr-v189-cheng23a,\n  title = \t {Nighttime Semantic Segmentation with Unsupervised\r Learning and Cross Attention},\n  author =       {Cheng, Jian and Hu, Yang{-}Feng and Dai, Yu and Qiao, Xue and Yao, Li and Yang, Jun{-}Yan},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/cheng23a/cheng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/cheng23a.html},\n  abstract = \t {In recent years, semantic segmentation has shown\r very good performance in daytime scenes. But in\r nighttime scenes, semantic segmentation greatly\r reduces its accuracy. Due to the lack of large-scale\r nighttime semantic segmentation datasets, it is\r difficult to directly train segmentation models for\r nighttime scenes. Therefore, it becomes important to\r adapt the daytime scene segmentation model to the\r nighttime scene without directly using the nighttime\r scene segmentation dataset. In this paper, we\r propose a framework based on unsupervised learning\r and cross attention. The proposed method fuses\r supervised daytime scenes and unsupervised nighttime\r scenes, the supervision information in the daytime\r scene and the texture information specific to the\r nighttime scene are fully utilized, and the model is\r adapted to both the daytime scene and the nighttime\r scene. Consistency regulation is used to make\r segmentation model adapt to the complex and\r changeable night scene texture and illumination. In\r view of the coarse correspondence of static objects\r between day and night image pairs in the Dark Zurich\r dataset, cross attention is proposed to make the\r model pay more attention to the parts of the night\r scene which are similar to the daytime\r scene. Extensive experiments on Dark Zurich and\r Nighttime Driving datasets show that our method\r obtains better performance in nighttime semantic\r segmentation.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/cheng23a/cheng23a.pdf",
        "supp": "",
        "pdf_size": 749094,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:KlTi8Uo5lKAJ:scholar.google.com/&scioq=Nighttime+Semantic+Segmentation+with+Unsupervised%0D+Learning+and+Cross+Attention&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "aff": "School of Computer Science and Engineering, Southeast University, Nanjing, 211189, Jiangsu, China; Aerospace Information Research Institute, Suzhou, 215123, Jiangsu, China; School of Computer Science and Engineering, Southeast University, Nanjing, 211189, Jiangsu, China; Aerospace Information Research Institute, Suzhou, 215123, Jiangsu, China; School of Computer Science and Engineering, Southeast University, Nanjing, 211189, Jiangsu, China+Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, 211189, Jiangsu, China; School of Architect, Southeast University, Nanjing, 211189, Jiangsu, China",
        "aff_domain": "qq.com;aircas.ac.cn;seu.edu.cn;mail.ie.ac.cn;seu.edu.cn;163.com",
        "email": "qq.com;aircas.ac.cn;seu.edu.cn;mail.ie.ac.cn;seu.edu.cn;163.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;0+0;0",
        "aff_unique_norm": "Southeast University;Aerospace Information Research Institute",
        "aff_unique_dep": "School of Computer Science and Engineering;",
        "aff_unique_url": "https://www.seu.edu.cn/;",
        "aff_unique_abbr": "SEU;",
        "aff_campus_unique_index": "0;1;0;1;0+0;0",
        "aff_campus_unique": "Nanjing;Suzhou",
        "aff_country_unique_index": "0;0;0;0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "c46cb4966a",
        "title": "Noise Robust Core-stable Coalitions of Hedonic\r Games",
        "site": "https://proceedings.mlr.press/v189/trivedi23a.html",
        "author": "Prashant Trivedi; Nandyala Hemachandra",
        "abstract": "In this work, we consider the coalition formation\r games with an additional component, \u2018noisy\r preferences\u2019. Moreover, such noisy preferences are\r available only for a sample of coalitions. We\r propose a multiplicative noise model (equivalent to\r an additive noise model) and obtain the prediction\r probability, defined as the probability that the\r estimated PAC core-stable partition of the\r \\emph{noisy} game is also PAC core-stable for the\r \\emph{unknown noise-free} game.  This prediction\r probability depends on the probability of a\r combinatorial construct called an \u2018agreement\r event\u2019. We explicitly obtain the agreement\r probability for $n$ agent noisy game with $l\\geq 2$\r support noise distribution. For a user-given\r satisfaction value on this probability, we identify\r the noise regimes for which an estimated partition\r is noise robust; that is, it is PAC core-stable in\r both the noisy and noise-free games. We obtain\r similar robustness results when the estimated\r partition is not PAC core-stable. These noise\r regimes correspond to the level sets of the\r agreement probability function and are non-convex\r sets. Moreover, an important fact is that the\r prediction probability can be high even if high\r noise values occur with a high probability. Further,\r for a class of top-responsive hedonic games, we\r obtain the bounds on the extra noisy samples\r required to get noise robustness with a user-given\r satisfaction value.  We completely solve the noise\r robustness problem of a $2$ agent hedonic game. In\r particular, we obtain the prediction probability\r function for $l=2$ and $l=3$ noise support\r cases. For $l=2$, the prediction probability is\r convex in noise probability, but the noise robust\r regime is non-convex. Its minimum value, called the\r safety value, is 0.62; so, below 0.62, the noise\r robust regime is the entire probability\r simplex. However, for $l \\geq 3$, the prediction\r probability is non-convex; so, the safety value is\r the global minima of a non-convex function and is\r computationally hard.",
        "bibtex": "@InProceedings{pmlr-v189-trivedi23a,\n  title = \t {Noise Robust Core-stable Coalitions of Hedonic\r Games},\n  author =       {Trivedi, Prashant and Hemachandra, Nandyala},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1038--1053},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/trivedi23a/trivedi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/trivedi23a.html},\n  abstract = \t {In this work, we consider the coalition formation\r games with an additional component, \u2018noisy\r preferences\u2019. Moreover, such noisy preferences are\r available only for a sample of coalitions. We\r propose a multiplicative noise model (equivalent to\r an additive noise model) and obtain the prediction\r probability, defined as the probability that the\r estimated PAC core-stable partition of the\r \\emph{noisy} game is also PAC core-stable for the\r \\emph{unknown noise-free} game.  This prediction\r probability depends on the probability of a\r combinatorial construct called an \u2018agreement\r event\u2019. We explicitly obtain the agreement\r probability for $n$ agent noisy game with $l\\geq 2$\r support noise distribution. For a user-given\r satisfaction value on this probability, we identify\r the noise regimes for which an estimated partition\r is noise robust; that is, it is PAC core-stable in\r both the noisy and noise-free games. We obtain\r similar robustness results when the estimated\r partition is not PAC core-stable. These noise\r regimes correspond to the level sets of the\r agreement probability function and are non-convex\r sets. Moreover, an important fact is that the\r prediction probability can be high even if high\r noise values occur with a high probability. Further,\r for a class of top-responsive hedonic games, we\r obtain the bounds on the extra noisy samples\r required to get noise robustness with a user-given\r satisfaction value.  We completely solve the noise\r robustness problem of a $2$ agent hedonic game. In\r particular, we obtain the prediction probability\r function for $l=2$ and $l=3$ noise support\r cases. For $l=2$, the prediction probability is\r convex in noise probability, but the noise robust\r regime is non-convex. Its minimum value, called the\r safety value, is 0.62; so, below 0.62, the noise\r robust regime is the entire probability\r simplex. However, for $l \\geq 3$, the prediction\r probability is non-convex; so, the safety value is\r the global minima of a non-convex function and is\r computationally hard.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/trivedi23a/trivedi23a.pdf",
        "supp": "",
        "pdf_size": 428277,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5013435803829834350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "IEOR, Indian Institute of Technology Bombay; IEOR, Indian Institute of Technology Bombay",
        "aff_domain": "iitb.ac.in;iitb.ac.in",
        "email": "iitb.ac.in;iitb.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Bombay",
        "aff_unique_dep": "Industrial Engineering and Operations Research",
        "aff_unique_url": "https://www.iitb.ac.in",
        "aff_unique_abbr": "IIT Bombay",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bombay",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "bb4070c925",
        "title": "Noisy Riemannian Gradient Descent for Eigenvalue\r Computation with Application to Inexact Stochastic\r Recursive Gradient Algorithm",
        "site": "https://proceedings.mlr.press/v189/chen23c.html",
        "author": "You-Lin Chen; Zhiqiang Xu; Ping Li",
        "abstract": "We provide a robust convergence analysis of the\r Riemannian gradient descent algorithm for computing\r the leading eigenvector of a real symmetric\r matrix. Our result characterizes the convergence\r behavior of the algorithm under the noisy updates,\r where noises can be generated by a stochastic\r process or could be chosen adversarially. The noisy\r Riemannian gradient descent has a broad range of\r applications in machine learning and statistics,\r e.g., streaming principal component analysis or\r privacy-preserving spectral analysis. In particular,\r we demonstrate the usefulness of our convergence\r bound with a new eigengap-dependent sample\r complexity of the inexact Riemannian stochastic\r recursive gradient algorithm, which utilizes\r mini-batch gradients instead of full gradients in\r outer loops. Our robust convergence paradigm\r strictly improves the state-of-the-art sample\r complexity in terms of the gap dependence.",
        "bibtex": "@InProceedings{pmlr-v189-chen23c,\n  title = \t {Noisy Riemannian Gradient Descent for Eigenvalue\r Computation with Application to Inexact Stochastic\r Recursive Gradient Algorithm},\n  author =       {Chen, You-Lin and Xu, Zhiqiang and Li, Ping},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {201--216},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/chen23c/chen23c.pdf},\n  url = \t {https://proceedings.mlr.press/v189/chen23c.html},\n  abstract = \t {We provide a robust convergence analysis of the\r Riemannian gradient descent algorithm for computing\r the leading eigenvector of a real symmetric\r matrix. Our result characterizes the convergence\r behavior of the algorithm under the noisy updates,\r where noises can be generated by a stochastic\r process or could be chosen adversarially. The noisy\r Riemannian gradient descent has a broad range of\r applications in machine learning and statistics,\r e.g., streaming principal component analysis or\r privacy-preserving spectral analysis. In particular,\r we demonstrate the usefulness of our convergence\r bound with a new eigengap-dependent sample\r complexity of the inexact Riemannian stochastic\r recursive gradient algorithm, which utilizes\r mini-batch gradients instead of full gradients in\r outer loops. Our robust convergence paradigm\r strictly improves the state-of-the-art sample\r complexity in terms of the gap dependence.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/chen23c/chen23c.pdf",
        "supp": "",
        "pdf_size": 449505,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BSzymaVnLLUJ:scholar.google.com/&scioq=Noisy+Riemannian+Gradient+Descent+for+Eigenvalue%0D+Computation+with+Application+to+Inexact+Stochastic%0D+Recursive+Gradient+Algorithm&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research",
        "aff_domain": "gmail.com;gmail.com;gmail.com",
        "email": "gmail.com;gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Cognitive Computing Lab",
        "aff_unique_url": "https://baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "02c07ab9e4",
        "title": "On PAC Learning Halfspaces in Non-interactive Local\r Privacy Model with Public Unlabeled Data",
        "site": "https://proceedings.mlr.press/v189/su23a.html",
        "author": "Jinyan Su; Jinhui Xu; Di Wang",
        "abstract": "In this paper, we study the problem of PAC learning\r halfspaces in the non-interactive local differential\r privacy model (NLDP).  To breach the barrier of\r exponential sample complexity, previous results\r studied a relaxed setting where the server has\r access to some additional public but unlabeled\r data. We continue in this direction. Specifically,\r we consider the problem under the standard setting\r instead of the large margin setting studied\r before. Under different mild assumptions on the\r underlying data distribution, we propose two\r approaches that are based on the Massart noise model\r and self-supervised learning and show that it is\r possible to achieve sample complexities that are\r only linear in the dimension and polynomial in other\r terms for both private and public data, which\r significantly improve the previous results. Our\r methods could also be used for other private PAC\r learning problems.",
        "bibtex": "@InProceedings{pmlr-v189-su23a,\n  title = \t {On PAC Learning Halfspaces in Non-interactive Local\r Privacy Model with Public Unlabeled Data},\n  author =       {Su, Jinyan and Xu, Jinhui and Wang, Di},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {927--941},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/su23a/su23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/su23a.html},\n  abstract = \t {In this paper, we study the problem of PAC learning\r halfspaces in the non-interactive local differential\r privacy model (NLDP).  To breach the barrier of\r exponential sample complexity, previous results\r studied a relaxed setting where the server has\r access to some additional public but unlabeled\r data. We continue in this direction. Specifically,\r we consider the problem under the standard setting\r instead of the large margin setting studied\r before. Under different mild assumptions on the\r underlying data distribution, we propose two\r approaches that are based on the Massart noise model\r and self-supervised learning and show that it is\r possible to achieve sample complexities that are\r only linear in the dimension and polynomial in other\r terms for both private and public data, which\r significantly improve the previous results. Our\r methods could also be used for other private PAC\r learning problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/su23a/su23a.pdf",
        "supp": "",
        "pdf_size": 309540,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=840644201493183188&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) + King Abdullah University of Science and Technology (KAUST); Department of Computer Science and Engineering, State University of New York at Buffalo; Division of CEMSE, Computational Bioscience Research Center, SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence, King Abdullah University of Science and Technology (KAUST)",
        "aff_domain": "MBZUAI.AC.AE;BUFFALO.EDU;KAUST.EDU.SA",
        "email": "MBZUAI.AC.AE;BUFFALO.EDU;KAUST.EDU.SA",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;1",
        "aff_unique_norm": "Mohamed bin Zayed University of Artificial Intelligence;King Abdullah University of Science and Technology;State University of New York at Buffalo",
        "aff_unique_dep": ";;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.mbzuai.ac.ae;https://www.kaust.edu.sa;https://www.buffalo.edu",
        "aff_unique_abbr": "MBZUAI;KAUST;SUNY Buffalo",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Buffalo",
        "aff_country_unique_index": "0+1;2;1",
        "aff_country_unique": "United Arab Emirates;Saudi Arabia;United States"
    },
    {
        "id": "da779b1c21",
        "title": "On the Convergence of Decentralized Adaptive\r Gradient Methods",
        "site": "https://proceedings.mlr.press/v189/chen23b.html",
        "author": "Xiangyi Chen; Belhal Karimi; Weijie Zhao; Ping Li",
        "abstract": "Adaptive gradient methods including Adam, AdaGrad,\r and their variants have been very successful for\r training deep learning models, such as neural\r networks. Meanwhile, given the need for distributed\r computing, distributed optimization algorithms are\r rapidly becoming a focal point. With the growth of\r computing power and the need for using machine\r learning models on mobile devices, the communication\r cost of distributed training algorithms needs\r careful consideration. In this paper, we introduce\r novel convergent decentralized adaptive gradient\r methods and rigorously incorporate adaptive gradient\r methods into decentralized training\r procedures. Specifically, we propose a general\r algorithmic framework that can convert existing\r adaptive gradient methods to their decentralized\r counterparts. In addition, we thoroughly analyze the\r convergence behavior of the proposed algorithmic\r framework and show that if a given adaptive gradient\r method converges, under some specific conditions,\r then its decentralized counterpart is also\r convergent. We illustrate the benefit of our generic\r decentralized framework on prototype methods,\r AMSGrad and AdaGrad.",
        "bibtex": "@InProceedings{pmlr-v189-chen23b,\n  title = \t {On the Convergence of Decentralized Adaptive\r Gradient Methods},\n  author =       {Chen, Xiangyi and Karimi, Belhal and Zhao, Weijie and Li, Ping},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {217--232},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/chen23b/chen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/chen23b.html},\n  abstract = \t {Adaptive gradient methods including Adam, AdaGrad,\r and their variants have been very successful for\r training deep learning models, such as neural\r networks. Meanwhile, given the need for distributed\r computing, distributed optimization algorithms are\r rapidly becoming a focal point. With the growth of\r computing power and the need for using machine\r learning models on mobile devices, the communication\r cost of distributed training algorithms needs\r careful consideration. In this paper, we introduce\r novel convergent decentralized adaptive gradient\r methods and rigorously incorporate adaptive gradient\r methods into decentralized training\r procedures. Specifically, we propose a general\r algorithmic framework that can convert existing\r adaptive gradient methods to their decentralized\r counterparts. In addition, we thoroughly analyze the\r convergence behavior of the proposed algorithmic\r framework and show that if a given adaptive gradient\r method converges, under some specific conditions,\r then its decentralized counterpart is also\r convergent. We illustrate the benefit of our generic\r decentralized framework on prototype methods,\r AMSGrad and AdaGrad.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/chen23b/chen23b.pdf",
        "supp": "",
        "pdf_size": 473287,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12807275350488169867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research",
        "aff_domain": "gmail.com;gmail.com;gmail.com;gmail.com",
        "email": "gmail.com;gmail.com;gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Cognitive Computing Lab",
        "aff_unique_url": "https://baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "f9ea7ded5e",
        "title": "On the Episodic Difficulty of Few-shot Learning",
        "site": "https://proceedings.mlr.press/v189/bai23a.html",
        "author": "Yunwei Bai; Zhenfeng He; Junfeng Hu",
        "abstract": "Dog vs. hot dog and dog vs. wolf, which one tends to\r be a harder comparison task? While simple, this\r question can be meaningful for few-shot\r classification. Few-shot learning enables trained\r models to recognize unseen classes through just a\r few labelled samples. As such, trained few-shot\r models usually have to possess the ability to assess\r the similarity degree between the unlabelled and\r labelled samples. In each few-shot learning episode,\r a combination of the labelled support set and\r unlabelled query set are sampled from the training\r dataset for model-training. In the episodic settings\r of few-shot learning, most algorithms draw the data\r samples uniformly at random for training. However,\r this approach disregards concepts of difficulty of\r each training episode, which may make a difference.\r After all, it is usually easier to differentiate\r between a dog and a hot dog, versus the dog and a\r wolf.  Therefore, in this paper, we delve into the\r concept of episodic difficulty, or difficulty of\r each training episode, discovering several insights\r and proposing strategies to utilize the difficulty.\r Firstly, defining episodic difficulty as a training\r loss, we find and study the correlation between\r episodic difficulty and visual similarity among data\r samples in each episode.  Secondly, we assess the\r respective usefulness of easy and difficult episodes\r for the training process.  Lastly, based on the\r assessment, we design a curriculum for few-shot\r learning to support training with incremental\r difficulty.  We observe that such an approach can\r achieve faster convergence for few-shot algorithms,\r reducing the average training time by around 50%.\r It can also make meta-learning algorithms achieve an\r increase in final testing accuracy scores.",
        "bibtex": "@InProceedings{pmlr-v189-bai23a,\n  title = \t {On the Episodic Difficulty of Few-shot Learning},\n  author =       {Bai, Yunwei and He, Zhenfeng and Hu, Junfeng},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {48--63},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/bai23a/bai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/bai23a.html},\n  abstract = \t {Dog vs. hot dog and dog vs. wolf, which one tends to\r be a harder comparison task? While simple, this\r question can be meaningful for few-shot\r classification. Few-shot learning enables trained\r models to recognize unseen classes through just a\r few labelled samples. As such, trained few-shot\r models usually have to possess the ability to assess\r the similarity degree between the unlabelled and\r labelled samples. In each few-shot learning episode,\r a combination of the labelled support set and\r unlabelled query set are sampled from the training\r dataset for model-training. In the episodic settings\r of few-shot learning, most algorithms draw the data\r samples uniformly at random for training. However,\r this approach disregards concepts of difficulty of\r each training episode, which may make a difference.\r After all, it is usually easier to differentiate\r between a dog and a hot dog, versus the dog and a\r wolf.  Therefore, in this paper, we delve into the\r concept of episodic difficulty, or difficulty of\r each training episode, discovering several insights\r and proposing strategies to utilize the difficulty.\r Firstly, defining episodic difficulty as a training\r loss, we find and study the correlation between\r episodic difficulty and visual similarity among data\r samples in each episode.  Secondly, we assess the\r respective usefulness of easy and difficult episodes\r for the training process.  Lastly, based on the\r assessment, we design a curriculum for few-shot\r learning to support training with incremental\r difficulty.  We observe that such an approach can\r achieve faster convergence for few-shot algorithms,\r reducing the average training time by around 50%.\r It can also make meta-learning algorithms achieve an\r increase in final testing accuracy scores.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/bai23a/bai23a.pdf",
        "supp": "",
        "pdf_size": 621424,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5249526793838573486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore",
        "aff_domain": "u.nus.edu;u.nus.edu;u.nus.edu",
        "email": "u.nus.edu;u.nus.edu;u.nus.edu",
        "github": "https://github.com/WendyBaiYunwei/EpisodicDifficulty",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "519c0039c7",
        "title": "On the Interpretability of Attention Networks",
        "site": "https://proceedings.mlr.press/v189/pandey23a.html",
        "author": "Lakshmi Narayan Pandey; Rahul Vashisht; Harish G. Ramaswamy",
        "abstract": "Attention mechanisms form a core component of\r several successful deep learning architectures, and\r are based on one key idea: \u201cThe output depends only\r on a small (but unknown) segment of the input.\u201d In\r several practical applications like image captioning\r and language translation, this is mostly true. In\r trained models with an attention mechanism, the\r outputs of an intermediate module that encodes the\r segment of input responsible for the output is often\r used as a way to peek into the \u2018reasoning\u2019 of the\r network. We make such a notion more precise for a\r variant of the classification problem that we term\r selective dependence classification (SDC) when used\r with attention model architectures. Under such a\r setting, we demonstrate various error modes where an\r attention model can be accurate but fail to be\r interpretable, and show that such models do occur as\r a result of training. We illustrate various\r situations that can accentuate and mitigate this\r behaviour. Finally, we use our objective definition\r of interpretability for SDC tasks to evaluate a few\r attention model learning algorithms designed to\r encourage sparsity and demonstrate that these\r algorithms help improve interpretability.",
        "bibtex": "@InProceedings{pmlr-v189-pandey23a,\n  title = \t {On the Interpretability of Attention Networks},\n  author =       {Pandey, Lakshmi Narayan and Vashisht, Rahul and Ramaswamy, Harish G.},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {832--847},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/pandey23a/pandey23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/pandey23a.html},\n  abstract = \t {Attention mechanisms form a core component of\r several successful deep learning architectures, and\r are based on one key idea: \u201cThe output depends only\r on a small (but unknown) segment of the input.\u201d In\r several practical applications like image captioning\r and language translation, this is mostly true. In\r trained models with an attention mechanism, the\r outputs of an intermediate module that encodes the\r segment of input responsible for the output is often\r used as a way to peek into the \u2018reasoning\u2019 of the\r network. We make such a notion more precise for a\r variant of the classification problem that we term\r selective dependence classification (SDC) when used\r with attention model architectures. Under such a\r setting, we demonstrate various error modes where an\r attention model can be accurate but fail to be\r interpretable, and show that such models do occur as\r a result of training. We illustrate various\r situations that can accentuate and mitigate this\r behaviour. Finally, we use our objective definition\r of interpretability for SDC tasks to evaluate a few\r attention model learning algorithms designed to\r encourage sparsity and demonstrate that these\r algorithms help improve interpretability.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/pandey23a/pandey23a.pdf",
        "supp": "",
        "pdf_size": 2878704,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8768270145659078670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Department of CSE, IIT Madras, Chennai, India; Department of CSE, IIT Madras, Chennai, India; Department of CSE, IIT Madras, Chennai, India",
        "aff_domain": "gmail.com;cse.iitm.ac.in;cse.iitm.ac.in",
        "email": "gmail.com;cse.iitm.ac.in;cse.iitm.ac.in",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "IIT Madras",
        "aff_unique_dep": "Department of CSE",
        "aff_unique_url": "https://www.iitm.ac.in",
        "aff_unique_abbr": "IITM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chennai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9df8178ab2",
        "title": "On the expressivity of bi-Lipschitz normalizing\r flows",
        "site": "https://proceedings.mlr.press/v189/verine23a.html",
        "author": "Alexandre Verine; Benjamin Negrevergne; Yann Chevaleyre; Fabrice Rossi",
        "abstract": "An invertible function is bi-Lipschitz if both the\r function and its inverse have bounded Lipschitz\r constants. Most state-of-the-art Normalizing Flows\r are bi-Lipschitz by design or by training to limit\r numerical errors (among other things). In this\r paper, we discuss the expressivity of bi-Lipschitz\r Normalizing Flows and identify several target\r distributions that are difficult to approximate\r using such models. Then, we characterize the\r expressivity of bi-Lipschitz Normalizing Flows by\r giving several lower bounds on the Total Variation\r distance between these particularly unfavorable\r distributions and their best possible\r approximation. Finally, we show how to use the\r bounds to adjust the training parameters, and\r discuss potential remedies.",
        "bibtex": "@InProceedings{pmlr-v189-verine23a,\n  title = \t {On the expressivity of bi-Lipschitz normalizing\r flows},\n  author =       {Verine, Alexandre and Negrevergne, Benjamin and Chevaleyre, Yann and Rossi, Fabrice},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1054--1069},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/verine23a/verine23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/verine23a.html},\n  abstract = \t {An invertible function is bi-Lipschitz if both the\r function and its inverse have bounded Lipschitz\r constants. Most state-of-the-art Normalizing Flows\r are bi-Lipschitz by design or by training to limit\r numerical errors (among other things). In this\r paper, we discuss the expressivity of bi-Lipschitz\r Normalizing Flows and identify several target\r distributions that are difficult to approximate\r using such models. Then, we characterize the\r expressivity of bi-Lipschitz Normalizing Flows by\r giving several lower bounds on the Total Variation\r distance between these particularly unfavorable\r distributions and their best possible\r approximation. Finally, we show how to use the\r bounds to adjust the training parameters, and\r discuss potential remedies.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/verine23a/verine23a.pdf",
        "supp": "",
        "pdf_size": 459932,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10465156146571399899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "LAMSADE, Universit\u00e9 Paris-Dauphine, PSL, Paris, France; LAMSADE, Universit\u00e9 Paris-Dauphine, PSL, Paris, France; LAMSADE, Universit\u00e9 Paris-Dauphine, PSL, Paris, France; CEREMADE, Universit\u00e9 Paris-Dauphine, PSL, Paris, France",
        "aff_domain": "dauphine.psl.eu;dauphine.psl.eu;dauphine.psl.eu;ceremade.dauphine.fr",
        "email": "dauphine.psl.eu;dauphine.psl.eu;dauphine.psl.eu;ceremade.dauphine.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Paris-Dauphine",
        "aff_unique_dep": "LAMSADE",
        "aff_unique_url": "https://www.univ-paris-dauphine.fr",
        "aff_unique_abbr": "UPD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "3c30989fe4",
        "title": "One Gradient Frank-Wolfe for Decentralized Online\r Convex and Submodular Optimization",
        "site": "https://proceedings.mlr.press/v189/nguyen23a.html",
        "author": "Tuan-Anh Nguyen; Nguyen Kim Thang; Denis Trystram",
        "abstract": "Decentralized learning has been studied intensively\r in recent years motivated by its wide applications\r in the context of federated learning. The majority\r of previous research focuses on the offline setting\r in which the objective function is static. However,\r the offline setting becomes unrealistic in numerous\r machine learning applications that witness the\r change of massive data. In this paper, we propose\r \\emph{decentralized online} algorithm for convex and\r continuous DR-submodular optimization, two classes\r of functions that are present in a variety of\r machine learning problems. Our algorithms achieve\r performance guarantees comparable to those in the\r centralized offline setting. Moreover, on average,\r each participant performs only a \\emph{single}\r gradient computation per time step. Subsequently, we\r extend our algorithms to the bandit\r setting. Finally, we illustrate the competitive\r performance of our algorithms in real-world\r experiments.",
        "bibtex": "@InProceedings{pmlr-v189-nguyen23a,\n  title = \t {One Gradient Frank-Wolfe for Decentralized Online\r Convex and Submodular Optimization},\n  author =       {Nguyen, Tuan-Anh and Kim Thang, Nguyen and Trystram, Denis},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {802--815},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/nguyen23a/nguyen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/nguyen23a.html},\n  abstract = \t {Decentralized learning has been studied intensively\r in recent years motivated by its wide applications\r in the context of federated learning. The majority\r of previous research focuses on the offline setting\r in which the objective function is static. However,\r the offline setting becomes unrealistic in numerous\r machine learning applications that witness the\r change of massive data. In this paper, we propose\r \\emph{decentralized online} algorithm for convex and\r continuous DR-submodular optimization, two classes\r of functions that are present in a variety of\r machine learning problems. Our algorithms achieve\r performance guarantees comparable to those in the\r centralized offline setting. Moreover, on average,\r each participant performs only a \\emph{single}\r gradient computation per time step. Subsequently, we\r extend our algorithms to the bandit\r setting. Finally, we illustrate the competitive\r performance of our algorithms in real-world\r experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/nguyen23a/nguyen23a.pdf",
        "supp": "",
        "pdf_size": 459005,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5503896589891594727&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "LIG, INRIA, University Grenoble-Alpes; LIG, INRIA, CNRS, Grenoble INP, University Grenoble-Alpes; LIG, INRIA, CNRS, Grenoble INP, University Grenoble-Alpes",
        "aff_domain": "inria.fr;univ-grenoble-alpes.fr;imag.fr",
        "email": "inria.fr;univ-grenoble-alpes.fr;imag.fr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University Grenoble-Alpes",
        "aff_unique_dep": "Laboratoire d'Informatique de Grenoble (LIG)",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Grenoble",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "5f78315837",
        "title": "Out of Distribution Detection via Neural Network\r Anchoring",
        "site": "https://proceedings.mlr.press/v189/anirudh23a.html",
        "author": "Rushil Anirudh; Jayaraman J. Thiagarajan",
        "abstract": "Our goal in this paper is to exploit heteroscedastic\r temperature scaling as a calibration strategy for\r out of distribution (OOD)\r detection. Heteroscedasticity here refers to the\r fact that the optimal temperature parameter for each\r sample can be different, as opposed to conventional\r approaches that use the same value for the entire\r distribution. To enable this, we propose a new\r training strategy called anchoring that can estimate\r appropriate temperature values for each sample,\r leading to state-of-the-art OOD detection\r performance across several benchmarks. Using NTK\r theory, we show that this temperature function\r estimate is closely linked to the epistemic\r uncertainty of the classifier, which explains its\r behavior. In contrast to some of the best-performing\r OOD detection approaches, our method does not\r require exposure to additional outlier datasets,\r custom calibration objectives, or model\r ensembling. Through empirical studies with different\r OOD detection settings \u2013 far OOD, near OOD, and\r semantically coherent OOD - we establish a highly\r effective OOD detection approach.",
        "bibtex": "@InProceedings{pmlr-v189-anirudh23a,\n  title = \t {Out of Distribution Detection via Neural Network\r Anchoring},\n  author =       {Anirudh, Rushil and Thiagarajan, Jayaraman J.},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {32--47},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/anirudh23a/anirudh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/anirudh23a.html},\n  abstract = \t {Our goal in this paper is to exploit heteroscedastic\r temperature scaling as a calibration strategy for\r out of distribution (OOD)\r detection. Heteroscedasticity here refers to the\r fact that the optimal temperature parameter for each\r sample can be different, as opposed to conventional\r approaches that use the same value for the entire\r distribution. To enable this, we propose a new\r training strategy called anchoring that can estimate\r appropriate temperature values for each sample,\r leading to state-of-the-art OOD detection\r performance across several benchmarks. Using NTK\r theory, we show that this temperature function\r estimate is closely linked to the epistemic\r uncertainty of the classifier, which explains its\r behavior. In contrast to some of the best-performing\r OOD detection approaches, our method does not\r require exposure to additional outlier datasets,\r custom calibration objectives, or model\r ensembling. Through empirical studies with different\r OOD detection settings \u2013 far OOD, near OOD, and\r semantically coherent OOD - we establish a highly\r effective OOD detection approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/anirudh23a/anirudh23a.pdf",
        "supp": "",
        "pdf_size": 1073829,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6388083307534561088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Center for Applied Scientific Computing (CASC), Lawrence Livermore National Laboratory; Center for Applied Scientific Computing (CASC), Lawrence Livermore National Laboratory",
        "aff_domain": "llnl.gov;llnl.gov",
        "email": "llnl.gov;llnl.gov",
        "github": "github.com/LLNL/AMP",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Lawrence Livermore National Laboratory",
        "aff_unique_dep": "Center for Applied Scientific Computing (CASC)",
        "aff_unique_url": "https://www.llnl.gov",
        "aff_unique_abbr": "LLNL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6098396927",
        "title": "Pose Guided Human Image Synthesis with Partially\r Decoupled GAN",
        "site": "https://proceedings.mlr.press/v189/wu23a.html",
        "author": "Jianhan Wu; Shijing Si; Jianzong Wang; Xiaoyang Qu; Xiao Jing",
        "abstract": "Pose Guided Human Image Synthesis (PGHIS) is a\r challenging task of transforming a human image from\r the reference pose to a target pose while preserving\r its style. Most existing methods encode the texture\r of the whole reference human image into a latent\r space, and then utilize a decoder to synthesize the\r image texture of the target pose. However, it is\r difficult to recover the detailed texture of the\r whole human image. To alleviate this problem, we\r propose a method by decoupling the human body into\r several parts (\\emph{e.g.}, hair, face, hands, feet,\r \\emph{etc.}) and then using each of these parts to\r guide the synthesis of a realistic image of the\r person, which preserves the detailed information of\r the generated images. In addition, we design a\r multi-head attention-based module for PGHIS. Because\r most convolutional neural network-based methods have\r difficulty in modeling long-range dependency due to\r the convolutional operation, the long-range modeling\r capability of attention mechanism is more suitable\r than convolutional neural networks for pose transfer\r task, especially for sharp pose\r deformation. Extensive experiments on Market-1501\r and DeepFashion datasets reveal that our method\r almost outperforms other existing state-of-the-art\r methods in terms of both qualitative and\r quantitative metrics.",
        "bibtex": "@InProceedings{pmlr-v189-wu23a,\n  title = \t {Pose Guided Human Image Synthesis with Partially\r Decoupled GAN},\n  author =       {Wu, Jianhan and Si, Shijing and Wang, Jianzong and Qu, Xiaoyang and Jing, Xiao},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1133--1148},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/wu23a/wu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/wu23a.html},\n  abstract = \t {Pose Guided Human Image Synthesis (PGHIS) is a\r challenging task of transforming a human image from\r the reference pose to a target pose while preserving\r its style. Most existing methods encode the texture\r of the whole reference human image into a latent\r space, and then utilize a decoder to synthesize the\r image texture of the target pose. However, it is\r difficult to recover the detailed texture of the\r whole human image. To alleviate this problem, we\r propose a method by decoupling the human body into\r several parts (\\emph{e.g.}, hair, face, hands, feet,\r \\emph{etc.}) and then using each of these parts to\r guide the synthesis of a realistic image of the\r person, which preserves the detailed information of\r the generated images. In addition, we design a\r multi-head attention-based module for PGHIS. Because\r most convolutional neural network-based methods have\r difficulty in modeling long-range dependency due to\r the convolutional operation, the long-range modeling\r capability of attention mechanism is more suitable\r than convolutional neural networks for pose transfer\r task, especially for sharp pose\r deformation. Extensive experiments on Market-1501\r and DeepFashion datasets reveal that our method\r almost outperforms other existing state-of-the-art\r methods in terms of both qualitative and\r quantitative metrics.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/wu23a/wu23a.pdf",
        "supp": "",
        "pdf_size": 1762030,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18409805768862890355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Ping An Technology (Shenzhen) Co., Ltd. + University of Science and Technology of China; Ping An Technology (Shenzhen) Co., Ltd.; Ping An Technology (Shenzhen) Co., Ltd. + School of economics and finance, Shanghai International Studies University; Ping An Technology (Shenzhen) Co., Ltd.; Ping An Technology (Shenzhen) Co., Ltd.",
        "aff_domain": "mail.ustc.edu.cn;188.com;outlook.com;gmail.com;pingan.com.cn",
        "email": "mail.ustc.edu.cn;188.com;outlook.com;gmail.com;pingan.com.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0+2;0;0",
        "aff_unique_norm": "Ping An Technology;University of Science and Technology of China;Shanghai International Studies University",
        "aff_unique_dep": ";;School of Economics and Finance",
        "aff_unique_url": "https://www.pingan.com;http://www.ustc.edu.cn;http://www.sisu.edu.cn",
        "aff_unique_abbr": "Ping An Tech;USTC;SISU",
        "aff_campus_unique_index": "0;0;0+2;0;0",
        "aff_campus_unique": "Shenzhen;;Shanghai",
        "aff_country_unique_index": "0+0;0;0+0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "0c3300ba21",
        "title": "Position-dependent partial convolutions for\r supervised spatial interpolation",
        "site": "https://proceedings.mlr.press/v189/hachiya23a.html",
        "author": "Hirotaka Hachiya; Kotaro Nagayoshi; Asako Iwaki; Takahiro Maeda; Naonori Ueda; Hiroyuki Fujiwara",
        "abstract": "Acquiring continuous spatial data, e.g., spatial\r ground motion is essential to assess the damaged\r area and appropriately assign rescue and medical\r teams. To this purpose, spatial interpolation\r methods have been developed to estimate the value of\r unobserved points linearly from neighbor observed\r values, i.e., inverse distance weighting and\r Kriging. Recently, realistic spatial continuous\r environmental data with various scenarios can be\r generated by 3D finite difference methods with a\r high-resolution structure model. It enables us to\r collect supervised data even for unobserved\r points. Along this line, we propose a framework of\r supervised spatial interpolation and apply highly\r advanced deep inpainting methods where we treat\r spatially distributed observed points as a masked\r image and non-linearly expand them through\r convolutional encoder-decoder networks. However, the\r property of translation invariance would avoid\r locally fine-grained interpolation since the\r relation between the target and surrounding\r observation points varies over regions due to its\r topography and subsurface structure. To overcome\r this problem, we propose introducing\r position-dependent convolution where kernel weights\r are adjusted depending on their position on an image\r based on the trainable position-feature map. We show\r the effectiveness of our proposed method, called,\r PoDIM (Position-dependent Deep Inpainting Method),\r through experiments using simulated ground-motion\r data.",
        "bibtex": "@InProceedings{pmlr-v189-hachiya23a,\n  title = \t {Position-dependent partial convolutions for\r supervised spatial interpolation},\n  author =       {Hachiya, Hirotaka and Nagayoshi, Kotaro and Iwaki, Asako and Maeda, Takahiro and Ueda, Naonori and Fujiwara, Hiroyuki},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {420--435},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/hachiya23a/hachiya23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/hachiya23a.html},\n  abstract = \t {Acquiring continuous spatial data, e.g., spatial\r ground motion is essential to assess the damaged\r area and appropriately assign rescue and medical\r teams. To this purpose, spatial interpolation\r methods have been developed to estimate the value of\r unobserved points linearly from neighbor observed\r values, i.e., inverse distance weighting and\r Kriging. Recently, realistic spatial continuous\r environmental data with various scenarios can be\r generated by 3D finite difference methods with a\r high-resolution structure model. It enables us to\r collect supervised data even for unobserved\r points. Along this line, we propose a framework of\r supervised spatial interpolation and apply highly\r advanced deep inpainting methods where we treat\r spatially distributed observed points as a masked\r image and non-linearly expand them through\r convolutional encoder-decoder networks. However, the\r property of translation invariance would avoid\r locally fine-grained interpolation since the\r relation between the target and surrounding\r observation points varies over regions due to its\r topography and subsurface structure. To overcome\r this problem, we propose introducing\r position-dependent convolution where kernel weights\r are adjusted depending on their position on an image\r based on the trainable position-feature map. We show\r the effectiveness of our proposed method, called,\r PoDIM (Position-dependent Deep Inpainting Method),\r through experiments using simulated ground-motion\r data.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/hachiya23a/hachiya23a.pdf",
        "supp": "",
        "pdf_size": 3165724,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4769618819073377896&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Graduate School of Systems Engineering, Wakayama University+Center for AIP, RIKEN; Graduate School of Systems Engineering, Wakayama University+Center for AIP, RIKEN; National Research Institute for Earth Science and Disaster Resilience; National Research Institute for Earth Science and Disaster Resilience; Center for AIP, RIKEN; National Research Institute for Earth Science and Disaster Resilience",
        "aff_domain": "wakayama-u.ac.jp;g.wakayama-u.jp;bosai.go.jp;bosai.go.jp;riken.jp;bosai.go.jp",
        "email": "wakayama-u.ac.jp;g.wakayama-u.jp;bosai.go.jp;bosai.go.jp;riken.jp;bosai.go.jp",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;2;2;1;2",
        "aff_unique_norm": "Wakayama University;RIKEN;National Research Institute for Earth Science and Disaster Resilience",
        "aff_unique_dep": "Graduate School of Systems Engineering;Center for AIP;",
        "aff_unique_url": "https://www.wakayama-u.ac.jp;https://www.riken.jp;https://www.nRIESD.go.jp",
        "aff_unique_abbr": ";RIKEN;NRIESD",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "8ff7edd89f",
        "title": "Probabilistic Adaptive Spatial-Temporal Regularized\r Correlation Filters for UAV Tracking",
        "site": "https://proceedings.mlr.press/v189/li23b.html",
        "author": "Rui Li; Xiao Li",
        "abstract": "Most existing trackers based on spatial-temporal\r regularized correlation filters exploit response map\r variation to adapt regularization terms to object\r appearance changes automatically. However, these\r trackers ignore the high uncertainty of the response\r map when the object is occluded or similar objects\r around, making them unable to learn reliable filters\r accurately. Furthermore, most correlation filters\r use linear interpolation directly to update the\r filter model at each frame, which may cause model\r degradation once the tracking result is inaccurate\r or missing. In this work, we propose a novel\r probabilistic adaptive spatial-temporal regularized\r correlation filters (PASTRCF) to solve the two\r issues mentioned above. A probabilistic model\r constructing the reliability of the response map is\r introduced to accurately utilize the information in\r the response map to learn regularization\r coefficients adaptively. The adaptive threshold\r mechanism provides an appropriate strategy to update\r the filter model to alleviate model\r degradation. Extensive experiments on UAV benchmarks\r have proven the favorable performance of our method\r compared to the state-of-art trackers, with robust\r tracking while ensuring real-time performance.",
        "bibtex": "@InProceedings{pmlr-v189-li23b,\n  title = \t {Probabilistic Adaptive Spatial-Temporal Regularized\r Correlation Filters for UAV Tracking},\n  author =       {Li, Rui and Li, Xiao},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {547--562},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/li23b/li23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/li23b.html},\n  abstract = \t {Most existing trackers based on spatial-temporal\r regularized correlation filters exploit response map\r variation to adapt regularization terms to object\r appearance changes automatically. However, these\r trackers ignore the high uncertainty of the response\r map when the object is occluded or similar objects\r around, making them unable to learn reliable filters\r accurately. Furthermore, most correlation filters\r use linear interpolation directly to update the\r filter model at each frame, which may cause model\r degradation once the tracking result is inaccurate\r or missing. In this work, we propose a novel\r probabilistic adaptive spatial-temporal regularized\r correlation filters (PASTRCF) to solve the two\r issues mentioned above. A probabilistic model\r constructing the reliability of the response map is\r introduced to accurately utilize the information in\r the response map to learn regularization\r coefficients adaptively. The adaptive threshold\r mechanism provides an appropriate strategy to update\r the filter model to alleviate model\r degradation. Extensive experiments on UAV benchmarks\r have proven the favorable performance of our method\r compared to the state-of-art trackers, with robust\r tracking while ensuring real-time performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/li23b/li23b.pdf",
        "supp": "",
        "pdf_size": 5391431,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3K5lTzobi84J:scholar.google.com/&scioq=Probabilistic+Adaptive+Spatial-Temporal+Regularized%0D+Correlation+Filters+for+UAV+Tracking&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Southwest University; Southwest University",
        "aff_domain": "139.com;swu.edu.cn",
        "email": "139.com;swu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Southwest University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.swu.edu.cn",
        "aff_unique_abbr": "SWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "36c198c7d1",
        "title": "Probabilistic Fusion of Neural Networks that\r Incorporates Global Information",
        "site": "https://proceedings.mlr.press/v189/xiao23b.html",
        "author": "Peng Xiao; Biao Zhang; Samuel Cheng; Ke Wei; Shuqin Zhang",
        "abstract": "As one of the approaches in Federated Learning,\r model fusion distills models trained on local\r clients into a global model.  The previous method,\r Probabilistic Federated Neural Matching (PFNM), can\r match and fuse local neural networks with varying\r global model sizes and data heterogeneity using the\r Bayesian nonparametric framework. However, the\r alternating optimization process applied by PFNM\r causes absence of global neuron information. In this\r paper, we propose a new method that extends PFNM by\r introducing a Kullback-Leibler (KL) divergence\r penalty, so that it can exploit information in both\r local and global neurons. We show theoretically that\r the extended PFNM with a penalty derived from KL\r divergence can fix the drawback of PFNM by making a\r balance between Euclidean distance and the prior\r probability of neurons. Experiments on deep\r fully-connected as well as deep convolutional neural\r networks demonstrate that our new method outperforms\r popular state-of-the-art federated learning methods\r in both image classification and semantic\r segmentation tasks.",
        "bibtex": "@InProceedings{pmlr-v189-xiao23b,\n  title = \t {Probabilistic Fusion of Neural Networks that\r Incorporates Global Information},\n  author =       {Xiao, Peng and Zhang, Biao and Cheng, Samuel and Wei, Ke and Zhang, Shuqin},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1149--1164},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/xiao23b/xiao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v189/xiao23b.html},\n  abstract = \t {As one of the approaches in Federated Learning,\r model fusion distills models trained on local\r clients into a global model.  The previous method,\r Probabilistic Federated Neural Matching (PFNM), can\r match and fuse local neural networks with varying\r global model sizes and data heterogeneity using the\r Bayesian nonparametric framework. However, the\r alternating optimization process applied by PFNM\r causes absence of global neuron information. In this\r paper, we propose a new method that extends PFNM by\r introducing a Kullback-Leibler (KL) divergence\r penalty, so that it can exploit information in both\r local and global neurons. We show theoretically that\r the extended PFNM with a penalty derived from KL\r divergence can fix the drawback of PFNM by making a\r balance between Euclidean distance and the prior\r probability of neurons. Experiments on deep\r fully-connected as well as deep convolutional neural\r networks demonstrate that our new method outperforms\r popular state-of-the-art federated learning methods\r in both image classification and semantic\r segmentation tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/xiao23b/xiao23b.pdf",
        "supp": "",
        "pdf_size": 998918,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2743032118340884960&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Computer Science and Technology, Tongji University, Shanghai, China; School of Mathematical Sciences, Fudan University, Shanghai, China; School of Electrical and Computer Engineering, University of Oklahoma, Oklahoma City, US; School of Data Sciences, Fudan University, Shanghai, China; School of Mathematical Sciences, Fudan University, Shanghai, China",
        "aff_domain": "gmail.com;fudan.edu.cn;ou.edu;fudan.edu.cn;fudan.edu.cn",
        "email": "gmail.com;fudan.edu.cn;ou.edu;fudan.edu.cn;fudan.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "Tongji University;Fudan University;University of Oklahoma",
        "aff_unique_dep": "Department of Computer Science and Technology;School of Mathematical Sciences;School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.fudan.edu.cn/en/;https://www.ou.edu",
        "aff_unique_abbr": "Tongji;Fudan;OU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Shanghai;Oklahoma City",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "6f61912cfa",
        "title": "ProtoBandit: Efficient Prototype Selection via\r Multi-Armed Bandits",
        "site": "https://proceedings.mlr.press/v189/chaudhuri23a.html",
        "author": "Arghya Roy Chaudhuri; Pratik Jawanpuria; Bamdev Mishra",
        "abstract": "In this work, we propose a multi-armed bandit based\r framework for identifying a compact set of\r informative data instances (i.e., the prototypes)\r that best represents a given target\r set. Prototypical examples of a given dataset offer\r interpretable insights into the underlying data\r distribution and assist in example-based reasoning,\r thereby influencing every sphere of human decision\r making. A key challenge is the large-scale setting,\r in which similarity comparison between pairs of data\r points needs to be done for almost all possible\r pairs. We propose to overcome this limitation by\r employing stochastic greedy search on the space of\r prototypical examples and multi-armed bandit\r approach for reducing the number of similarity\r comparisons. A salient feature of the proposed\r approach is that the total number of similarity\r comparisons needed is independent of the size of the\r target set. Empirically, we observe that our\r proposed approach, ProtoBandit, reduces the total\r number of similarity computation calls by several\r orders of magnitudes (100-1000 times) while\r obtaining solutions similar in quality to those from\r existing state-of-the-art approaches.",
        "bibtex": "@InProceedings{pmlr-v189-chaudhuri23a,\n  title = \t {{ProtoBandit}: Efficient Prototype Selection via\r Multi-Armed Bandits},\n  author =       {Chaudhuri, Arghya Roy and Jawanpuria, Pratik and Mishra, Bamdev},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {169--184},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/chaudhuri23a/chaudhuri23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/chaudhuri23a.html},\n  abstract = \t {In this work, we propose a multi-armed bandit based\r framework for identifying a compact set of\r informative data instances (i.e., the prototypes)\r that best represents a given target\r set. Prototypical examples of a given dataset offer\r interpretable insights into the underlying data\r distribution and assist in example-based reasoning,\r thereby influencing every sphere of human decision\r making. A key challenge is the large-scale setting,\r in which similarity comparison between pairs of data\r points needs to be done for almost all possible\r pairs. We propose to overcome this limitation by\r employing stochastic greedy search on the space of\r prototypical examples and multi-armed bandit\r approach for reducing the number of similarity\r comparisons. A salient feature of the proposed\r approach is that the total number of similarity\r comparisons needed is independent of the size of the\r target set. Empirically, we observe that our\r proposed approach, ProtoBandit, reduces the total\r number of similarity computation calls by several\r orders of magnitudes (100-1000 times) while\r obtaining solutions similar in quality to those from\r existing state-of-the-art approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/chaudhuri23a/chaudhuri23a.pdf",
        "supp": "",
        "pdf_size": 397704,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=866442224821709777&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft India; Microsoft India; Microsoft India",
        "aff_domain": "microsoft.com;microsoft.com;microsoft.com",
        "email": "microsoft.com;microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Corporation",
        "aff_unique_url": "https://www.microsoft.com/en-in",
        "aff_unique_abbr": "Microsoft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "06a04749a0",
        "title": "RoLNiP: Robust Learning Using Noisy Pairwise\r Comparisons",
        "site": "https://proceedings.mlr.press/v189/maheshwara23a.html",
        "author": "Samartha S. Maheshwara; Naresh Manwani",
        "abstract": "This paper presents a robust approach for learning\r from noisy pairwise comparisons. We propose\r sufficient conditions on the loss function under\r which the risk minimization frame- work becomes\r robust to noise in the pairwise similar dissimilar\r data. Our approach does not require the knowledge of\r noise rate in the uniform noise case. In the case of\r conditional noise, the proposed method depends on\r the noise rates. For such cases, we offer a provably\r correct approach for estimating the noise\r rates. Thus, we propose an end-to-end approach to\r learning robust classifiers in this setting. We\r experimentally show that the proposed approach\r RoLNiP outperforms the robust state-of-the-art\r methods for learning with noisy pairwise\r comparisons.",
        "bibtex": "@InProceedings{pmlr-v189-maheshwara23a,\n  title = \t {RoLNiP: Robust Learning Using Noisy Pairwise\r Comparisons},\n  author =       {Maheshwara, Samartha S. and Manwani, Naresh},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {706--721},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/maheshwara23a/maheshwara23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/maheshwara23a.html},\n  abstract = \t {This paper presents a robust approach for learning\r from noisy pairwise comparisons. We propose\r sufficient conditions on the loss function under\r which the risk minimization frame- work becomes\r robust to noise in the pairwise similar dissimilar\r data. Our approach does not require the knowledge of\r noise rate in the uniform noise case. In the case of\r conditional noise, the proposed method depends on\r the noise rates. For such cases, we offer a provably\r correct approach for estimating the noise\r rates. Thus, we propose an end-to-end approach to\r learning robust classifiers in this setting. We\r experimentally show that the proposed approach\r RoLNiP outperforms the robust state-of-the-art\r methods for learning with noisy pairwise\r comparisons.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/maheshwara23a/maheshwara23a.pdf",
        "supp": "",
        "pdf_size": 1220369,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2479266687291228747&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Machine Learning Lab, Kohli Research Block, IIIT Hyderabad, India; Machine Learning Lab, Kohli Research Block, IIIT Hyderabad, India",
        "aff_domain": "students.iiit.ac.in;iiit.ac.in",
        "email": "students.iiit.ac.in;iiit.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad",
        "aff_unique_dep": "Machine Learning Lab",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "1b8e667075",
        "title": "Robust Direct Learning for Causal Data Fusion",
        "site": "https://proceedings.mlr.press/v189/li23c.html",
        "author": "Xinyu Li; Yilin Li; Qing Cui; Longfei Li; Jun Zhou",
        "abstract": "In the era of big data, the explosive growth of\r multi-source heterogeneous data offers many exciting\r challenges and opportunities for improving the\r inference of conditional average treatment\r effects. In this paper, we investigate homogeneous\r and heterogeneous causal data fusion problems under\r a general setting that allows for the presence of\r source-specific covariates. We provide a direct\r learning framework for integrating multi-source data\r that separates the treatment effect from other\r nuisance functions, and achieves double robustness\r against certain misspecification. To improve\r estimation precision and stability, we propose a\r causal information-aware weighting function\r motivated by theoretical insights from the\r semiparametric efficiency theory; it assigns larger\r weights to samples containing more causal\r information with high interpretability. We introduce\r a two-step algorithm, the weighted multi-source\r direct learner, based on constructing a\r pseudo-outcome and regressing it on covariates under\r a weighted least square criterion; it offers us a\r powerful tool for causal data fusion, enjoying the\r advantages of easy implementation, double robustness\r and model flexibility. In simulation studies, we\r demonstrate the effectiveness of our proposed\r methods in both homogeneous and heterogeneous causal\r data fusion scenarios.",
        "bibtex": "@InProceedings{pmlr-v189-li23c,\n  title = \t {Robust Direct Learning for Causal Data Fusion},\n  author =       {Li, Xinyu and Li, Yilin and Cui, Qing and Li, Longfei and Zhou, Jun},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {611--626},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/li23c/li23c.pdf},\n  url = \t {https://proceedings.mlr.press/v189/li23c.html},\n  abstract = \t {In the era of big data, the explosive growth of\r multi-source heterogeneous data offers many exciting\r challenges and opportunities for improving the\r inference of conditional average treatment\r effects. In this paper, we investigate homogeneous\r and heterogeneous causal data fusion problems under\r a general setting that allows for the presence of\r source-specific covariates. We provide a direct\r learning framework for integrating multi-source data\r that separates the treatment effect from other\r nuisance functions, and achieves double robustness\r against certain misspecification. To improve\r estimation precision and stability, we propose a\r causal information-aware weighting function\r motivated by theoretical insights from the\r semiparametric efficiency theory; it assigns larger\r weights to samples containing more causal\r information with high interpretability. We introduce\r a two-step algorithm, the weighted multi-source\r direct learner, based on constructing a\r pseudo-outcome and regressing it on covariates under\r a weighted least square criterion; it offers us a\r powerful tool for causal data fusion, enjoying the\r advantages of easy implementation, double robustness\r and model flexibility. In simulation studies, we\r demonstrate the effectiveness of our proposed\r methods in both homogeneous and heterogeneous causal\r data fusion scenarios.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/li23c/li23c.pdf",
        "supp": "",
        "pdf_size": 361668,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13004906164083476166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "School of Mathematical Sciences, Peking University, Beijing, China+Ant Group, Hangzhou, China; School of Mathematical Sciences, Peking University, Beijing, China; Ant Group, Hangzhou, China; Ant Group, Hangzhou, China; Ant Group, Hangzhou, China",
        "aff_domain": "pku.edu.cn;pku.edu.cn;antgroup.com;antgroup.com;antfin.com",
        "email": "pku.edu.cn;pku.edu.cn;antgroup.com;antgroup.com;antfin.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;1;1;1",
        "aff_unique_norm": "Peking University;Ant Group",
        "aff_unique_dep": "School of Mathematical Sciences;",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.antgroup.com",
        "aff_unique_abbr": "PKU;Ant Group",
        "aff_campus_unique_index": "0+1;0;1;1;1",
        "aff_campus_unique": "Beijing;Hangzhou",
        "aff_country_unique_index": "0+0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "06233159fe",
        "title": "Robust Multi-Objective Reinforcement Learning with\r Dynamic Preferences",
        "site": "https://proceedings.mlr.press/v189/buet-golfouse23a.html",
        "author": "Francois Buet-Golfouse; Parth Pahwa",
        "abstract": "This paper considers multi-objective reinforcement\r learning (MORL) when preferences over the multiple\r tasks are not perfectly known. Indeed, it is often\r the case in practice that an agent is trying to\r achieve tasks that may have competing goals but does\r not exactly know how to trade them off. The goal of\r MORL is thus to learn optimal policies under a set\r of possible preferences leading to different\r trade-offs on the Pareto frontier. Here, we propose\r a new method by considering the dynamics of\r preferences over tasks. While this is a more\r realistic setup in many scenarios, more importantly,\r it helps us devise a simple and straightforward\r approach by considering a surrogate state space made\r up of both states and preferences, which leads to a\r joint exploration of states and preferences. Static\r (and possibly unknown) preferences can also be\r understood as a limiting case of our framework. In\r sum, this allows us to devise both deep Q-learning\r and actor-critic methods based on planning under a\r preference-dependent policy and learning the\r multi-dimensional value function under said\r policy. Finally, the performance and effectiveness\r of our method are demonstrated in experiments run on\r different domains.",
        "bibtex": "@InProceedings{pmlr-v189-buet-golfouse23a,\n  title = \t {Robust Multi-Objective Reinforcement Learning with\r Dynamic Preferences},\n  author =       {Buet-Golfouse, Francois and Pahwa, Parth},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {96--111},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/buet-golfouse23a/buet-golfouse23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/buet-golfouse23a.html},\n  abstract = \t {This paper considers multi-objective reinforcement\r learning (MORL) when preferences over the multiple\r tasks are not perfectly known. Indeed, it is often\r the case in practice that an agent is trying to\r achieve tasks that may have competing goals but does\r not exactly know how to trade them off. The goal of\r MORL is thus to learn optimal policies under a set\r of possible preferences leading to different\r trade-offs on the Pareto frontier. Here, we propose\r a new method by considering the dynamics of\r preferences over tasks. While this is a more\r realistic setup in many scenarios, more importantly,\r it helps us devise a simple and straightforward\r approach by considering a surrogate state space made\r up of both states and preferences, which leads to a\r joint exploration of states and preferences. Static\r (and possibly unknown) preferences can also be\r understood as a limiting case of our framework. In\r sum, this allows us to devise both deep Q-learning\r and actor-critic methods based on planning under a\r preference-dependent policy and learning the\r multi-dimensional value function under said\r policy. Finally, the performance and effectiveness\r of our method are demonstrated in experiments run on\r different domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/buet-golfouse23a/buet-golfouse23a.pdf",
        "supp": "",
        "pdf_size": 962575,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17992140412063688995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "University College London London, United Kingdom; Independent Researcher London, United Kingdom",
        "aff_domain": "ucl.ac.uk;gmail.com",
        "email": "ucl.ac.uk;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University College London;Independent Researcher",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucl.ac.uk;",
        "aff_unique_abbr": "UCL;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "299c573afd",
        "title": "Robust Scene Text Detection via Learnable Scene\r Transformations",
        "site": "https://proceedings.mlr.press/v189/cao23a.html",
        "author": "Yuheng Cao; Mengjie Zhou; Jie Chen",
        "abstract": "Scene text detection based on deep neural networks\r has been extensively studied in the last few\r years. However, the task of detecting texts in\r complex scenes such as bad weather and image\r distortions has not received sufficient attentions\r in existing works, which is crucial for real-world\r applications such as text translation, autonomous\r driving, etc. In this paper, we propose a novel\r strategy to automatically search for the effective\r scene transformation polices to augment images in\r the training phase. In addition, we build a new\r dataset, Robust-Text, to evaluate the robustness of\r text detection methods in real complex\r scenes. Experiments conducted on the ICDAR2015,\r MSRA-TD500 and Robust-Text datasets demonstrate that\r our method can effectively improve the robustness of\r text detectors in complex scenes.",
        "bibtex": "@InProceedings{pmlr-v189-cao23a,\n  title = \t {Robust Scene Text Detection via Learnable Scene\r Transformations},\n  author =       {Cao, Yuheng and Zhou, Mengjie and Chen, Jie},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {137--152},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/cao23a/cao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/cao23a.html},\n  abstract = \t {Scene text detection based on deep neural networks\r has been extensively studied in the last few\r years. However, the task of detecting texts in\r complex scenes such as bad weather and image\r distortions has not received sufficient attentions\r in existing works, which is crucial for real-world\r applications such as text translation, autonomous\r driving, etc. In this paper, we propose a novel\r strategy to automatically search for the effective\r scene transformation polices to augment images in\r the training phase. In addition, we build a new\r dataset, Robust-Text, to evaluate the robustness of\r text detection methods in real complex\r scenes. Experiments conducted on the ICDAR2015,\r MSRA-TD500 and Robust-Text datasets demonstrate that\r our method can effectively improve the robustness of\r text detectors in complex scenes.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/cao23a/cao23a.pdf",
        "supp": "",
        "pdf_size": 8465102,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0AYUPtOBtaMJ:scholar.google.com/&scioq=Robust+Scene+Text+Detection+via+Learnable+Scene%0D+Transformations&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "School of Electronic Science and Engineering, Southeast University, Nanjing, China; Department of Computer Science, University of Bristol, Bristol, UK; Peking University, Beijing, China",
        "aff_domain": "SEU.EDU.CN;BRISTOL.AC.UK;PKU.EDU.CN",
        "email": "SEU.EDU.CN;BRISTOL.AC.UK;PKU.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Southeast University;University of Bristol;Peking University",
        "aff_unique_dep": "School of Electronic Science and Engineering;Department of Computer Science;",
        "aff_unique_url": "https://www.seu.edu.cn/;https://www.bristol.ac.uk;http://www.pku.edu.cn",
        "aff_unique_abbr": "SEU;UoB;Peking U",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Nanjing;Bristol;Beijing",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "3b73d4b5f7",
        "title": "Robust computation of optimal transport by\r $\u03b2$-potential regularization",
        "site": "https://proceedings.mlr.press/v189/nakamura23a.html",
        "author": "Shintaro Nakamura; Han Bao; Masashi Sugiyama",
        "abstract": "Optimal transport (OT) has become a widely used tool\r in the machine learning field to measure the\r discrepancy between probability distributions. For\r instance, OT is a popular loss function that\r quantifies the discrepancy between an empirical\r distribution and a parametric model. Recently, an\r entropic penalty term and the celebrated Sinkhorn\r algorithm have been commonly used to approximate the\r original OT in a computationally efficient\r way. However, since the Sinkhorn algorithm runs a\r projection associated with the Kullback-Leibler\r divergence, it is often vulnerable to outliers. To\r overcome this problem, we propose regularizing OT\r with the $\\beta$-potential term associated with the\r so-called $\\beta$-divergence, which was developed in\r robust statistics. Our theoretical analysis reveals\r that the $\\beta$-potential can prevent the mass from\r being transported to outliers. We experimentally\r demonstrate that the transport matrix computed with\r our algorithm helps estimate a probability\r distribution robustly even in the presence of\r outliers. In addition, our proposed method can\r successfully detect outliers from a contaminated\r dataset.",
        "bibtex": "@InProceedings{pmlr-v189-nakamura23a,\n  title = \t {Robust computation of optimal transport by\r $\u03b2$-potential regularization},\n  author =       {Nakamura, Shintaro and Bao, Han and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {770--785},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/nakamura23a/nakamura23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/nakamura23a.html},\n  abstract = \t {Optimal transport (OT) has become a widely used tool\r in the machine learning field to measure the\r discrepancy between probability distributions. For\r instance, OT is a popular loss function that\r quantifies the discrepancy between an empirical\r distribution and a parametric model. Recently, an\r entropic penalty term and the celebrated Sinkhorn\r algorithm have been commonly used to approximate the\r original OT in a computationally efficient\r way. However, since the Sinkhorn algorithm runs a\r projection associated with the Kullback-Leibler\r divergence, it is often vulnerable to outliers. To\r overcome this problem, we propose regularizing OT\r with the $\\beta$-potential term associated with the\r so-called $\\beta$-divergence, which was developed in\r robust statistics. Our theoretical analysis reveals\r that the $\\beta$-potential can prevent the mass from\r being transported to outliers. We experimentally\r demonstrate that the transport matrix computed with\r our algorithm helps estimate a probability\r distribution robustly even in the presence of\r outliers. In addition, our proposed method can\r successfully detect outliers from a contaminated\r dataset.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/nakamura23a/nakamura23a.pdf",
        "supp": "",
        "pdf_size": 546408,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:e7s-JgOCxuYJ:scholar.google.com/&scioq=Robust+computation+of+optimal+transport+by%0D+%24%CE%B2%24-potential+regularization&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "The University of Tokyo; Kyoto University; RIKEN AIP center + The University of Tokyo",
        "aff_domain": "g.ecc.u-tokyo.ac.jp;i.kyoto-u.ac.jp;k.u-tokyo.ac.jp",
        "email": "g.ecc.u-tokyo.ac.jp;i.kyoto-u.ac.jp;k.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+0",
        "aff_unique_norm": "University of Tokyo;Kyoto University;RIKEN",
        "aff_unique_dep": ";;AIP center",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.kyoto-u.ac.jp;https://aipcenter.com",
        "aff_unique_abbr": "UTokyo;Kyoto U;RIKEN AIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "89606087df",
        "title": "SNAIL: Semi-Separated Uncertainty Adversarial\r Learning for Universal Domain Adaptation",
        "site": "https://proceedings.mlr.press/v189/han23a.html",
        "author": "Zhongyi Han; Wan Su; Rundong He; Yilong Yin",
        "abstract": "Universal domain adaptation (UniDA) is a new\r sub-topic of unsupervised domain adaptation. It\r handles the problem that the source or target domain\r possibly has open-class samples. The inborn\r challenge is to detect the open-class samples in the\r test phase. Pioneering studies could be viewed as\r dependent-detector-based methods. They cleverly\r design efficient uncertainty metrics (\\eg,\r confidence, entropy, distance) based on the outputs\r of domain adaptation models (predictor) to detect\r open-class samples. However, they have a pain point\r in setting extremely-sensitive and task-dependent\r thresholds on the uncertainty metrics to filter\r open-class samples. To bypass this pain point, we\r propose a semi-separated-detector-based method,\r Semi-Separated Uncertainty Adversarial Learning\r (SNAIL). We build a semi-separated uncertainty\r decision-maker to enable sensitive-threshold-free\r detection. It receives multiple uncertainty metrics\r as attributes and separately learns the thresholds\r of uncertainty metrics in a multi-level decision\r rule. For some challenging tasks, the uncertainty\r margins between common and open classes are subtle,\r leading to difficulty learning optimal decision\r rules. We present the uncertainty separation loss to\r enlarge the uncertainty margin. Further, forcibly\r aligning the distributions could incorrectly align\r the open classes to common classes.  Thanks to the\r open-class detection strategy, we design the\r conditional-weighted adversarial loss that\r adversarially and selectively matches the feature\r distributions to defeat the distribution\r misalignment problem. Extensive experiments show\r that SNAIL remarkably outperforms the\r state-of-the-art domain adaptation methods, with\r over 25% improvements in open-class detection\r accuracy for some tasks.",
        "bibtex": "@InProceedings{pmlr-v189-han23a,\n  title = \t {SNAIL: Semi-Separated Uncertainty Adversarial\r Learning for Universal Domain Adaptation},\n  author =       {Han, Zhongyi and Su, Wan and He, Rundong and Yin, Yilong},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {436--451},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/han23a/han23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/han23a.html},\n  abstract = \t { Universal domain adaptation (UniDA) is a new\r sub-topic of unsupervised domain adaptation. It\r handles the problem that the source or target domain\r possibly has open-class samples. The inborn\r challenge is to detect the open-class samples in the\r test phase. Pioneering studies could be viewed as\r dependent-detector-based methods. They cleverly\r design efficient uncertainty metrics (\\eg,\r confidence, entropy, distance) based on the outputs\r of domain adaptation models (predictor) to detect\r open-class samples. However, they have a pain point\r in setting extremely-sensitive and task-dependent\r thresholds on the uncertainty metrics to filter\r open-class samples. To bypass this pain point, we\r propose a semi-separated-detector-based method,\r Semi-Separated Uncertainty Adversarial Learning\r (SNAIL). We build a semi-separated uncertainty\r decision-maker to enable sensitive-threshold-free\r detection. It receives multiple uncertainty metrics\r as attributes and separately learns the thresholds\r of uncertainty metrics in a multi-level decision\r rule. For some challenging tasks, the uncertainty\r margins between common and open classes are subtle,\r leading to difficulty learning optimal decision\r rules. We present the uncertainty separation loss to\r enlarge the uncertainty margin. Further, forcibly\r aligning the distributions could incorrectly align\r the open classes to common classes.  Thanks to the\r open-class detection strategy, we design the\r conditional-weighted adversarial loss that\r adversarially and selectively matches the feature\r distributions to defeat the distribution\r misalignment problem. Extensive experiments show\r that SNAIL remarkably outperforms the\r state-of-the-art domain adaptation methods, with\r over 25% improvements in open-class detection\r accuracy for some tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/han23a/han23a.pdf",
        "supp": "",
        "pdf_size": 1291208,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6340129878772332041&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "School of Software, Shandong University; School of Software, Shandong University; School of Software, Shandong University; School of Software, Shandong University",
        "aff_domain": "gmail.com;mail.sdu.edu.cn;mail.sdu.edu.cn;sdu.edu.cn",
        "email": "gmail.com;mail.sdu.edu.cn;mail.sdu.edu.cn;sdu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shandong University",
        "aff_unique_dep": "School of Software",
        "aff_unique_url": "http://www.sdu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "92d49de290",
        "title": "Semantic Cross Attention for Few-shot Learning",
        "site": "https://proceedings.mlr.press/v189/xiao23a.html",
        "author": "Bin Xiao; Chien-Liang Liu; Wen-Hoar Hsaio",
        "abstract": "Few-shot learning (FSL) has attracted considerable\r attention recently. Among existing approaches, the\r metric-based method aims to train an embedding\r network that can make similar samples close while\r dissimilar samples as far as possible and achieves\r promising results. FSL is characterized by using\r only a few images to train a model that can\r generalize to novel classes in image classification\r problems, but this setting makes it difficult to\r learn the visual features that can identify the\r images\u2019 appearance variations. The model training is\r likely to move in the wrong direction, as the images\r in an identical semantic class may have dissimilar\r appearances, whereas the images in different\r semantic classes may share a similar appearance. We\r argue that FSL can benefit from additional semantic\r features to learn discriminative feature\r representations. Thus, this study proposes a\r multi-task learning approach to view semantic\r features of label text as an auxiliary task to help\r boost the performance of the FSL task. Our proposed\r model uses word-embedding representations as\r semantic features to help train the embedding\r network and a semantic cross-attention module to\r bridge the semantic features into the typical visual\r modal. The proposed approach is simple, but produces\r excellent results. We apply our proposed approach to\r two previous metric-based FSL methods, all of which\r can substantially improve performance. The source\r code for our model is accessible from github.",
        "bibtex": "@InProceedings{pmlr-v189-xiao23a,\n  title = \t {Semantic Cross Attention for Few-shot Learning},\n  author =       {Xiao, Bin and Liu, Chien-Liang and Hsaio, Wen-Hoar},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1165--1180},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/xiao23a/xiao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/xiao23a.html},\n  abstract = \t {Few-shot learning (FSL) has attracted considerable\r attention recently. Among existing approaches, the\r metric-based method aims to train an embedding\r network that can make similar samples close while\r dissimilar samples as far as possible and achieves\r promising results. FSL is characterized by using\r only a few images to train a model that can\r generalize to novel classes in image classification\r problems, but this setting makes it difficult to\r learn the visual features that can identify the\r images\u2019 appearance variations. The model training is\r likely to move in the wrong direction, as the images\r in an identical semantic class may have dissimilar\r appearances, whereas the images in different\r semantic classes may share a similar appearance. We\r argue that FSL can benefit from additional semantic\r features to learn discriminative feature\r representations. Thus, this study proposes a\r multi-task learning approach to view semantic\r features of label text as an auxiliary task to help\r boost the performance of the FSL task. Our proposed\r model uses word-embedding representations as\r semantic features to help train the embedding\r network and a semantic cross-attention module to\r bridge the semantic features into the typical visual\r modal. The proposed approach is simple, but produces\r excellent results. We apply our proposed approach to\r two previous metric-based FSL methods, all of which\r can substantially improve performance. The source\r code for our model is accessible from github.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/xiao23a/xiao23a.pdf",
        "supp": "",
        "pdf_size": 15150366,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17390774303345317965&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "School of Electrical Engineering and Computer Science, University of Ottawa; Department of Industrial Engineering and Management, National Yang Ming Chiao Tung University; Department of Computer Science and Engineering, Nanya Institute of Technology",
        "aff_domain": "uottawa.ca;nycu.edu.tw;nanya.edu.tw",
        "email": "uottawa.ca;nycu.edu.tw;nanya.edu.tw",
        "github": "https://github.com/uobinxiao/semantic_cross_attention_fsl",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Ottawa;National Yang Ming Chiao Tung University;Nanya Institute of Technology",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;Department of Industrial Engineering and Management;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.uottawa.ca;https://www.nycu.edu.tw;https://www.nit.edu.tw",
        "aff_unique_abbr": "U Ottawa;NYCU;NIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Taiwan",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "0cc2ab9a00",
        "title": "Sliced Wasserstein variational inference",
        "site": "https://proceedings.mlr.press/v189/yi23a.html",
        "author": "Mingxuan Yi; Song Liu",
        "abstract": "Variational Inference approximates an unnormalized\r distribution via the minimization of\r Kullback-Leibler (KL) divergence. Although this\r divergence is efficient for computation and has been\r widely used in applications, it suffers from some\r unreasonable properties. For example, it is not a\r proper metric, i.e., it is non-symmetric and does\r not preserve the triangle inequality. On the other\r hand, optimal transport distances recently have\r shown some advantages over KL divergence. With the\r help of these advantages, we propose a new\r variational inference method by minimizing sliced\r Wasserstein distance\u2013a valid metric arising from\r optimal transport. This sliced Wasserstein distance\r can be approximated simply by running MCMC but\r without solving any optimization problem. Our\r approximation also does not require a tractable\r density function of variational distributions so\r that approximating families can be amortized by\r generators like neural networks. Furthermore, we\r provide an analysis of the theoretical properties of\r our method. Experiments on synthetic and real data\r are illustrated to show the performance of the\r proposed method.",
        "bibtex": "@InProceedings{pmlr-v189-yi23a,\n  title = \t {Sliced Wasserstein variational inference},\n  author =       {Yi, Mingxuan and Liu, Song},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1213--1228},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/yi23a/yi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/yi23a.html},\n  abstract = \t {Variational Inference approximates an unnormalized\r distribution via the minimization of\r Kullback-Leibler (KL) divergence. Although this\r divergence is efficient for computation and has been\r widely used in applications, it suffers from some\r unreasonable properties. For example, it is not a\r proper metric, i.e., it is non-symmetric and does\r not preserve the triangle inequality. On the other\r hand, optimal transport distances recently have\r shown some advantages over KL divergence. With the\r help of these advantages, we propose a new\r variational inference method by minimizing sliced\r Wasserstein distance\u2013a valid metric arising from\r optimal transport. This sliced Wasserstein distance\r can be approximated simply by running MCMC but\r without solving any optimization problem. Our\r approximation also does not require a tractable\r density function of variational distributions so\r that approximating families can be amortized by\r generators like neural networks. Furthermore, we\r provide an analysis of the theoretical properties of\r our method. Experiments on synthetic and real data\r are illustrated to show the performance of the\r proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/yi23a/yi23a.pdf",
        "supp": "",
        "pdf_size": 808032,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5149094093904897084&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "School of Mathematics, University of Bristol, UK; School of Mathematics, University of Bristol, UK",
        "aff_domain": "bristol.ac.uk;bristol.ac.uk",
        "email": "bristol.ac.uk;bristol.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "School of Mathematics",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "182216d307",
        "title": "Temporal aware Multi-Interest Graph Neural Network\r for Session-based Recommendation",
        "site": "https://proceedings.mlr.press/v189/shen23a.html",
        "author": "Qi Shen; Shixuan Zhu; Yitong Pang; Yiming Zhang; Zhihua Wei",
        "abstract": "Session-based recommendation (SBR) is a challenging\r task, which aims at recommending next items based on\r anonymous interaction sequences. Despite the\r superior performance of existing methods for SBR,\r there are still several limitations: (i) Almost all\r existing works concentrate on single interest\r extraction and fail to disentangle multiple\r interests of user, which easily results in\r suboptimal representations for SBR. (ii)\r Furthermore, previous methods also ignore the\r multi-form temporal information, which is\r significant signal to obtain current intention for\r SBR. To address the limitations mentioned above, we\r propose a novel method, called Temporal aware\r Multi-Interest Graph Neural Network (TMI-GNN) to\r disentangle multi-interest and yield refined\r intention representations with the injection of two\r level temporal information. Specifically, by\r appending multiple interest nodes, we construct a\r multi-interest graph for current session, and adopt\r the GNNs to model the item-item relation to capture\r adjacent item transitions, item-interest relation to\r disentangle the multi-interests, and interest-item\r relation to refine the item\r representation. Meanwhile, we incorporate item-level\r time interval signals to guide the item information\r propagation, and interest-level time distribution\r information to assist the scattering of interest\r information. Experiments on three benchmark datasets\r demonstrate that TMI-GNN outperforms other\r state-of-the-art methods consistently.",
        "bibtex": "@InProceedings{pmlr-v189-shen23a,\n  title = \t {Temporal aware Multi-Interest Graph Neural Network\r for Session-based Recommendation},\n  author =       {Shen, Qi and Zhu, Shixuan and Pang, Yitong and Zhang, Yiming and Wei, Zhihua},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/shen23a/shen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/shen23a.html},\n  abstract = \t {Session-based recommendation (SBR) is a challenging\r task, which aims at recommending next items based on\r anonymous interaction sequences. Despite the\r superior performance of existing methods for SBR,\r there are still several limitations: (i) Almost all\r existing works concentrate on single interest\r extraction and fail to disentangle multiple\r interests of user, which easily results in\r suboptimal representations for SBR. (ii)\r Furthermore, previous methods also ignore the\r multi-form temporal information, which is\r significant signal to obtain current intention for\r SBR. To address the limitations mentioned above, we\r propose a novel method, called Temporal aware\r Multi-Interest Graph Neural Network (TMI-GNN) to\r disentangle multi-interest and yield refined\r intention representations with the injection of two\r level temporal information. Specifically, by\r appending multiple interest nodes, we construct a\r multi-interest graph for current session, and adopt\r the GNNs to model the item-item relation to capture\r adjacent item transitions, item-interest relation to\r disentangle the multi-interests, and interest-item\r relation to refine the item\r representation. Meanwhile, we incorporate item-level\r time interval signals to guide the item information\r propagation, and interest-level time distribution\r information to assist the scattering of interest\r information. Experiments on three benchmark datasets\r demonstrate that TMI-GNN outperforms other\r state-of-the-art methods consistently.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/shen23a/shen23a.pdf",
        "supp": "",
        "pdf_size": 467004,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3271801112707799516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Tongji University; Tongji University; Tongji University; Tongji University; Tongji University",
        "aff_domain": "tongji.edu.cn;tongji.edu.cn;tongji.edu.cn;tongji.edu.cn;tongji.edu.cn",
        "email": "tongji.edu.cn;tongji.edu.cn;tongji.edu.cn;tongji.edu.cn;tongji.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "af29140d09",
        "title": "Towards Data-Free Domain Generalization",
        "site": "https://proceedings.mlr.press/v189/frikha23a.html",
        "author": "Ahmed Frikha; Haokun Chen; Denis Krompa\u00df; Thomas Runkler; Volker Tresp",
        "abstract": "In this work, we investigate the unexplored\r intersection of domain generalization (DG) and\r data-free learning. In particular, we address the\r question: How can knowledge contained in models\r trained on different source domains be merged into a\r single model that generalizes well to unseen target\r domains, in the absence of source and target domain\r data? Machine learning models that can cope with\r domain shift are essential for real-world scenarios\r with often changing data distributions. Prior DG\r methods typically rely on using source domain data,\r making them unsuitable for private decentralized\r data. We define the novel problem of Data-Free\r Domain Generalization (DFDG), a practical setting\r where models trained on the source domains\r separately are available instead of the original\r datasets, and investigate how to effectively solve\r the domain generalization problem in that case. We\r propose DEKAN, an approach that extracts and fuses\r domain-specific knowledge from the available teacher\r models into a student model robust to domain\r shift. Our empirical evaluation demonstrates the\r effectiveness of our method which achieves first\r state-of-the-art results in DFDG by significantly\r outperforming data-free knowledge distillation and\r ensemble baselines.",
        "bibtex": "@InProceedings{pmlr-v189-frikha23a,\n  title = \t {Towards Data-Free Domain Generalization},\n  author =       {Frikha, Ahmed and Chen, Haokun and Krompa{\\ss}, Denis and Runkler, Thomas and Tresp, Volker},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {327--342},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/frikha23a/frikha23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/frikha23a.html},\n  abstract = \t {In this work, we investigate the unexplored\r intersection of domain generalization (DG) and\r data-free learning. In particular, we address the\r question: How can knowledge contained in models\r trained on different source domains be merged into a\r single model that generalizes well to unseen target\r domains, in the absence of source and target domain\r data? Machine learning models that can cope with\r domain shift are essential for real-world scenarios\r with often changing data distributions. Prior DG\r methods typically rely on using source domain data,\r making them unsuitable for private decentralized\r data. We define the novel problem of Data-Free\r Domain Generalization (DFDG), a practical setting\r where models trained on the source domains\r separately are available instead of the original\r datasets, and investigate how to effectively solve\r the domain generalization problem in that case. We\r propose DEKAN, an approach that extracts and fuses\r domain-specific knowledge from the available teacher\r models into a student model robust to domain\r shift. Our empirical evaluation demonstrates the\r effectiveness of our method which achieves first\r state-of-the-art results in DFDG by significantly\r outperforming data-free knowledge distillation and\r ensemble baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/frikha23a/frikha23a.pdf",
        "supp": "",
        "pdf_size": 3736982,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5513789517807147287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Siemens Technology + University of Munich; Siemens Technology + University of Munich; Siemens Technology; Siemens Technology + Technical University of Munich; Siemens Technology + University of Munich",
        "aff_domain": "SIEMENS.COM;SIEMENS.COM;SIEMENS.COM;SIEMENS.COM;SIEMENS.COM",
        "email": "SIEMENS.COM;SIEMENS.COM;SIEMENS.COM;SIEMENS.COM;SIEMENS.COM",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0;0+2;0+1",
        "aff_unique_norm": "Siemens AG;University of Munich;Technical University of Munich",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.siemens.com;https://www.uni-muenchen.de;https://www.tum.de",
        "aff_unique_abbr": "Siemens;LMU;TUM",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0;0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "86321d2d3e",
        "title": "Trusted Loss Correction for Noisy Multi-Label\r Learning",
        "site": "https://proceedings.mlr.press/v189/ghiassi23a.html",
        "author": "Amirmasoud Ghiassi; Cosmin Octavian Pene; Robert Birke; Lydia.Y Chen",
        "abstract": "Noisy and corrupted labels are shown to\r significantly undermine the performance of\r multi-label learning, which has multiple labels in\r each image. Correcting the loss via a label\r corruption matrix is effective in improving the\r robustness of single-label classification against\r noisy labels. However, estimating the corruption\r matrix for multi-label problems is no mean feat due\r to the unbalanced distributions of labels and the\r presence of multiple objects that may be mapped into\r the same labels. In this paper, we propose a robust\r multi-label classifier against label noise, TLCM,\r which corrects the loss based on a corruption matrix\r estimated on trusted data. To overcome the challenge\r of unbalanced label distribution and multi-object\r mapping, we use trusted single-label data as\r regulators to correct the multi-label corruption\r matrix. Empirical evaluation on real-world vision\r and object detection datasets, i.e., MS-COCO,\r NUS-WIDE, and MIRFLICKR, shows that our method under\r medium (30%) and high (60%) corruption levels\r outperforms state-of-the-art multi-label classifier\r (ASL) and noise-resilient multi-label classifier\r (MPVAE), by on average 12.5% and 26.3% mean average\r precision (mAP) points, respectively.",
        "bibtex": "@InProceedings{pmlr-v189-ghiassi23a,\n  title = \t {Trusted Loss Correction for Noisy Multi-Label\r Learning},\n  author =       {Ghiassi, Amirmasoud and Pene, Cosmin Octavian and Birke, Robert and Chen, Lydia.Y},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {343--358},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/ghiassi23a/ghiassi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/ghiassi23a.html},\n  abstract = \t {Noisy and corrupted labels are shown to\r significantly undermine the performance of\r multi-label learning, which has multiple labels in\r each image. Correcting the loss via a label\r corruption matrix is effective in improving the\r robustness of single-label classification against\r noisy labels. However, estimating the corruption\r matrix for multi-label problems is no mean feat due\r to the unbalanced distributions of labels and the\r presence of multiple objects that may be mapped into\r the same labels. In this paper, we propose a robust\r multi-label classifier against label noise, TLCM,\r which corrects the loss based on a corruption matrix\r estimated on trusted data. To overcome the challenge\r of unbalanced label distribution and multi-object\r mapping, we use trusted single-label data as\r regulators to correct the multi-label corruption\r matrix. Empirical evaluation on real-world vision\r and object detection datasets, i.e., MS-COCO,\r NUS-WIDE, and MIRFLICKR, shows that our method under\r medium (30%) and high (60%) corruption levels\r outperforms state-of-the-art multi-label classifier\r (ASL) and noise-resilient multi-label classifier\r (MPVAE), by on average 12.5% and 26.3% mean average\r precision (mAP) points, respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/ghiassi23a/ghiassi23a.pdf",
        "supp": "",
        "pdf_size": 3969309,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15486436663188589492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Computer Science dept., University of Turin, Turin, Italy; Delft University of Technology, Delft, Netherlands",
        "aff_domain": "tudelft.nl;gmail.com;unito.it;ieee.org",
        "email": "tudelft.nl;gmail.com;unito.it;ieee.org",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Delft University of Technology;University of Turin",
        "aff_unique_dep": ";Computer Science dept.",
        "aff_unique_url": "https://www.tudelft.nl;https://www.unito.it",
        "aff_unique_abbr": "TU Delft;UniTO",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Delft;Turin",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Netherlands;Italy"
    },
    {
        "id": "e45d5a6566",
        "title": "Unsupervised Photo-to-Caricature Generation with\r Adaptive Select Layer-Instance Normalization and\r Semi-cycle Consistency",
        "site": "https://proceedings.mlr.press/v189/zhiwei23a.html",
        "author": "Li Zhiwei; Cai Weiling; Cairun Wang",
        "abstract": "Unpaired photo to caricature generation is a\r challenging but meaningful task. Generating high\r quality caricatures with rich texture/color and\r plausible exaggeration is important. Previous\r methods often respectively deal with the shape\r transformation and texture/color style. We argue\r that shape transformation can be treated as same as\r texture/color. Thereby, shape transformation and\r texture/color can be transferred at the same\r time. In this paper, we proposed a new method namely\r AdsSe-GAN for photo-to-caricature generation, which\r consists of a new normalization function called\r AdaSLIN and a new semi-cycle consistency loss. The\r AdaSLIN adaptively selects Layer Normalization or\r Instance Normalization to simultaneously transfer\r texture/color and shape transformation. Besides we\r present semi-cycle consistency loss which only\r imposes L1 norm on caricature-to-photo process,\r which is different from existing methods that apply\r cycle consistency loss to preserve the original\r domain information. In fact, while generating\r caricature, taking no account of the cycle\r restriction makes our model generate caricature with\r more distinct exaggeration and higher\r quality. Experimental results on a public caricature\r dataset, WebCaricature, show the effectiveness of\r our proposed method compared with the\r state-of-the-art models.",
        "bibtex": "@InProceedings{pmlr-v189-zhiwei23a,\n  title = \t {Unsupervised Photo-to-Caricature Generation with\r Adaptive Select Layer-Instance Normalization and\r Semi-cycle Consistency},\n  author =       {Zhiwei, Li and Weiling, Cai and Wang, Cairun},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {595--610},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/zhiwei23a/zhiwei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/zhiwei23a.html},\n  abstract = \t {Unpaired photo to caricature generation is a\r challenging but meaningful task. Generating high\r quality caricatures with rich texture/color and\r plausible exaggeration is important. Previous\r methods often respectively deal with the shape\r transformation and texture/color style. We argue\r that shape transformation can be treated as same as\r texture/color. Thereby, shape transformation and\r texture/color can be transferred at the same\r time. In this paper, we proposed a new method namely\r AdsSe-GAN for photo-to-caricature generation, which\r consists of a new normalization function called\r AdaSLIN and a new semi-cycle consistency loss. The\r AdaSLIN adaptively selects Layer Normalization or\r Instance Normalization to simultaneously transfer\r texture/color and shape transformation. Besides we\r present semi-cycle consistency loss which only\r imposes L1 norm on caricature-to-photo process,\r which is different from existing methods that apply\r cycle consistency loss to preserve the original\r domain information. In fact, while generating\r caricature, taking no account of the cycle\r restriction makes our model generate caricature with\r more distinct exaggeration and higher\r quality. Experimental results on a public caricature\r dataset, WebCaricature, show the effectiveness of\r our proposed method compared with the\r state-of-the-art models.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/zhiwei23a/zhiwei23a.pdf",
        "supp": "",
        "pdf_size": 8451380,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:vQTDbzuyX4YJ:scholar.google.com/&scioq=Unsupervised+Photo-to-Caricature+Generation+with%0D+Adaptive+Select+Layer-Instance+Normalization+and%0D+Semi-cycle+Consistency&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Nanjing Normal University; Nanjing Normal University; Nanjing Normal University",
        "aff_domain": "qq.com;qq.com;qq.com",
        "email": "qq.com;qq.com;qq.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanjing Normal University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "NNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "59af783a85",
        "title": "Value Function Approximations via Kernel Embeddings\r for No-Regret Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v189/chowdhury23a.html",
        "author": "Sayak Ray Chowdhury; Rafael Oliveira",
        "abstract": "We consider the regret minimization problem in\r reinforcement learning (RL) in the episodic setting.\r In many real-world RL environments, the state and\r action spaces are continuous or very large. Existing\r approaches establish regret guarantees by either a\r low-dimensional representation of the stochastic\r transition model or an approximation of the\r $Q$-functions. However, the understanding of\r function approximation schemes for state-value\r functions largely remains missing. In this paper, we\r propose an online model-based RL algorithm, namely\r the CME-RL, that learns embeddings of the\r state-transition distribution in a reproducing\r kernel Hilbert space while carefully balancing the\r exploitation-exploration tradeoff. We demonstrate\r the efficiency of our algorithm by proving a\r frequentist (worst-case) regret bound that is of\r order\r $\\tilde{O}\\big(H\\gamma_N\\sqrt{N}\\big)$\\footnote{\r $\\tilde{O}(\\cdot)$ hides only absolute constant and\r poly-logarithmic factors.}, where $H$ is the episode\r length, $N$ is the total number of time steps and\r $\\gamma_N$ is an information theoretic quantity\r relating the effective dimension of the state-action\r feature space. Our method bypasses the need for\r estimating transition probabilities and applies to\r any domain on which kernels can be defined. It also\r brings new insights into the general theory of\r kernel methods for approximate inference and RL\r regret minimization.",
        "bibtex": "@InProceedings{pmlr-v189-chowdhury23a,\n  title = \t {Value Function Approximations via Kernel Embeddings\r for No-Regret Reinforcement Learning},\n  author =       {Chowdhury, Sayak Ray and Oliveira, Rafael},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {249--264},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/chowdhury23a/chowdhury23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/chowdhury23a.html},\n  abstract = \t {We consider the regret minimization problem in\r reinforcement learning (RL) in the episodic setting.\r In many real-world RL environments, the state and\r action spaces are continuous or very large. Existing\r approaches establish regret guarantees by either a\r low-dimensional representation of the stochastic\r transition model or an approximation of the\r $Q$-functions. However, the understanding of\r function approximation schemes for state-value\r functions largely remains missing. In this paper, we\r propose an online model-based RL algorithm, namely\r the CME-RL, that learns embeddings of the\r state-transition distribution in a reproducing\r kernel Hilbert space while carefully balancing the\r exploitation-exploration tradeoff. We demonstrate\r the efficiency of our algorithm by proving a\r frequentist (worst-case) regret bound that is of\r order\r $\\tilde{O}\\big(H\\gamma_N\\sqrt{N}\\big)$\\footnote{\r $\\tilde{O}(\\cdot)$ hides only absolute constant and\r poly-logarithmic factors.}, where $H$ is the episode\r length, $N$ is the total number of time steps and\r $\\gamma_N$ is an information theoretic quantity\r relating the effective dimension of the state-action\r feature space. Our method bypasses the need for\r estimating transition probabilities and applies to\r any domain on which kernels can be defined. It also\r brings new insights into the general theory of\r kernel methods for approximate inference and RL\r regret minimization.}\n}",
        "pdf": "https://proceedings.mlr.press/v189/chowdhury23a/chowdhury23a.pdf",
        "supp": "",
        "pdf_size": 387430,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13468538393594239717&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Microsoft Research, India; The University of Sydney, Australia",
        "aff_domain": "microsoft.com;sydney.edu.au",
        "email": "microsoft.com;sydney.edu.au",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Microsoft;University of Sydney",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/india.aspx;https://www.sydney.edu.au",
        "aff_unique_abbr": "MSR India;USYD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "India;Australia"
    },
    {
        "id": "6927363693",
        "title": "When to Classify Events in Open Times Series?",
        "site": "https://proceedings.mlr.press/v189/achenchabe23a.html",
        "author": "Youssef Achenchabe; Alexis Bondu; Cornu\u00e9jols Antoine; Lemaire Vincent",
        "abstract": "In numerous applications, for instance in predictive\r maintenance, there is a pression to predict events\r ahead of time with as much accuracy as possible\r while not delaying the decision unduly. This\r translates in the optimization of a trade-off\r between earliness and accuracy of the decisions,\r that has been the subject of research for time\r series of finite length and with a unique label. And\r this has led to powerful algorithms for Early\r Classification of Time Series (ECTS). This paper,\r for the first time, investigates such a trade-off\r when events of different classes occur in a\r streaming fashion, with no predefined end.  In the\r Early Classification in Open Time Series problem\r (ECOTS), the task is to predict events, i.e. their\r class and time interval, at the moment that\r optimizes the accuracy vs. earliness\r trade-off. Interestingly, we find that ECTS\r algorithms can be sensibly adapted in a principled\r way to this new problem.  We illustrate our\r methodology by transforming two state-of-the-art\r ECTS algorithms for the ECOTS scenario.Among the\r wide variety of applications that this new approach\r opens up, we develop here a predictive maintenance\r use case that optimizes alarm triggering times, thus\r demonstrating the power of this new approach.",
        "bibtex": "@InProceedings{pmlr-v189-achenchabe23a,\n  title = \t {When to Classify Events in Open Times Series?},\n  author =       {Achenchabe, Youssef and Bondu, Alexis and Antoine, Cornu\\'ejols and Vincent, Lemaire},\n  booktitle = \t {Proceedings of The 14th Asian Conference on Machine\r Learning},\n  pages = \t {1--16},\n  year = \t {2023},\n  editor = \t {Khan, Emtiyaz and Gonen, Mehmet},\n  volume = \t {189},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {12--14 Dec},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v189/achenchabe23a/achenchabe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v189/achenchabe23a.html},\n  abstract = \t {In numerous applications, for instance in predictive\r maintenance, there is a pression to predict events\r ahead of time with as much accuracy as possible\r while not delaying the decision unduly. This\r translates in the optimization of a trade-off\r between earliness and accuracy of the decisions,\r that has been the subject of research for time\r series of finite length and with a unique label. And\r this has led to powerful algorithms for Early\r Classification of Time Series (ECTS). This paper,\r for the first time, investigates such a trade-off\r when events of different classes occur in a\r streaming fashion, with no predefined end.  In the\r Early Classification in Open Time Series problem\r (ECOTS), the task is to predict events, i.e. their\r class and time interval, at the moment that\r optimizes the accuracy vs. earliness\r trade-off. Interestingly, we find that ECTS\r algorithms can be sensibly adapted in a principled\r way to this new problem.  We illustrate our\r methodology by transforming two state-of-the-art\r ECTS algorithms for the ECOTS scenario.Among the\r wide variety of applications that this new approach\r opens up, we develop here a predictive maintenance\r use case that optimizes alarm triggering times, thus\r demonstrating the power of this new approach. }\n}",
        "pdf": "https://proceedings.mlr.press/v189/achenchabe23a/achenchabe23a.pdf",
        "supp": "",
        "pdf_size": 1036459,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16018038363918063407&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Paris-Saclay University + Agroparistech + Orange Labs; Orange Labs, Ch\u02c6 atillon; Paris-Saclay University + Agroparistech; Orange Labs, Lannion",
        "aff_domain": "universite-paris-saclay.fr;orange.com;agroparistech.fr;orange.com",
        "email": "universite-paris-saclay.fr;orange.com;agroparistech.fr;orange.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;3;0+1;3",
        "aff_unique_norm": "Paris-Saclay University;AgroParisTech;Orange;Orange Labs",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.universite-paris-saclay.fr;https://www.agroparistech.fr;https://www.orange.com;https://www.orangelabs.com",
        "aff_unique_abbr": "Paris-Saclay;AgroParisTech;Orange;",
        "aff_campus_unique_index": ";1;;2",
        "aff_campus_unique": ";Ch\u00e2tillon;Lannion",
        "aff_country_unique_index": "0+0+0;0;0+0;0",
        "aff_country_unique": "France"
    }
]