[
    {
        "id": "599cdc73e3",
        "title": "A Blessing of Dimensionality in Membership Inference through Regularization",
        "site": "https://proceedings.mlr.press/v206/tan23b.html",
        "author": "Jasper Tan; Daniel LeJeune; Blake Mason; Hamid Javadi; Richard G. Baraniuk",
        "abstract": "Is overparameterization a privacy liability? In this work, we study the effect that the number of parameters has on a classifier\u2019s vulnerability to membership inference attacks. We first demonstrate how the number of parameters of a model can induce a privacy-utility trade-off: increasing the number of parameters generally improves generalization performance at the expense of lower privacy. However, remarkably, we then show that if coupled with proper regularization, increasing the number of parameters of a model can actually simultaneously increase both its privacy and performance, thereby eliminating the privacy-utility trade-off. Theoretically, we demonstrate this curious phenomenon for logistic regression with ridge regularization in a bi-level feature ensemble setting. Pursuant to our theoretical exploration, we develop a novel leave-one-out analysis tool to precisely characterize the vulnerability of a linear classifier to the optimal membership inference attack. We empirically exhibit this \u201cblessing of dimensionality\u201d for neural networks on a variety of tasks using early stopping as the regularizer",
        "bibtex": "@InProceedings{pmlr-v206-tan23b,\n  title = \t {A Blessing of Dimensionality in Membership Inference through Regularization},\n  author =       {Tan, Jasper and LeJeune, Daniel and Mason, Blake and Javadi, Hamid and Baraniuk, Richard G.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10968--10993},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tan23b/tan23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tan23b.html},\n  abstract = \t {Is overparameterization a privacy liability? In this work, we study the effect that the number of parameters has on a classifier\u2019s vulnerability to membership inference attacks. We first demonstrate how the number of parameters of a model can induce a privacy-utility trade-off: increasing the number of parameters generally improves generalization performance at the expense of lower privacy. However, remarkably, we then show that if coupled with proper regularization, increasing the number of parameters of a model can actually simultaneously increase both its privacy and performance, thereby eliminating the privacy-utility trade-off. Theoretically, we demonstrate this curious phenomenon for logistic regression with ridge regularization in a bi-level feature ensemble setting. Pursuant to our theoretical exploration, we develop a novel leave-one-out analysis tool to precisely characterize the vulnerability of a linear classifier to the optimal membership inference attack. We empirically exhibit this \u201cblessing of dimensionality\u201d for neural networks on a variety of tasks using early stopping as the regularizer}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tan23b/tan23b.pdf",
        "supp": "",
        "pdf_size": 1424210,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7008845024424916481&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Rice University; Stanford University; Rice University; Rice University; Rice University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Rice University;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.rice.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Rice;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6c639afb28",
        "title": "A Bregman Divergence View on the Difference-of-Convex Algorithm",
        "site": "https://proceedings.mlr.press/v206/faust23a.html",
        "author": "Oisin Faust; Hamza Fawzi; James Saunderson",
        "abstract": "The difference of convex (DC) algorithm is a conceptually simple method for the minimization of (non)convex functions that are expressed as the difference of two convex functions. An attractive feature of the algorithm is that it maintains a global overestimator on the function and does not require a choice of step size at each iteration. By adopting a Bregman divergence point of view, we simplify and strengthen many existing non-asymptotic convergence guarantees for the DC algorithm. We further present several sufficient conditions that ensure a linear convergence rate, namely a new DC Polyak-Lojasiewicz condition, as well as a relative strong convexity assumption. Importantly, our conditions do not require smoothness of the objective function. We illustrate our results on a family of minimization problems involving the quantum relative entropy, with applications in quantum information theory.",
        "bibtex": "@InProceedings{pmlr-v206-faust23a,\n  title = \t {A Bregman Divergence View on the Difference-of-Convex Algorithm},\n  author =       {Faust, Oisin and Fawzi, Hamza and Saunderson, James},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3427--3439},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/faust23a/faust23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/faust23a.html},\n  abstract = \t {The difference of convex (DC) algorithm is a conceptually simple method for the minimization of (non)convex functions that are expressed as the difference of two convex functions. An attractive feature of the algorithm is that it maintains a global overestimator on the function and does not require a choice of step size at each iteration. By adopting a Bregman divergence point of view, we simplify and strengthen many existing non-asymptotic convergence guarantees for the DC algorithm. We further present several sufficient conditions that ensure a linear convergence rate, namely a new DC Polyak-Lojasiewicz condition, as well as a relative strong convexity assumption. Importantly, our conditions do not require smoothness of the objective function. We illustrate our results on a family of minimization problems involving the quantum relative entropy, with applications in quantum information theory.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/faust23a/faust23a.pdf",
        "supp": "",
        "pdf_size": 379009,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15381792019804246358&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6f1d41b267",
        "title": "A Case of Exponential Convergence Rates for SVM",
        "site": "https://proceedings.mlr.press/v206/cabannnes23a.html",
        "author": "Vivien Cabannnes; Stefano Vigogna",
        "abstract": "Optimizing the misclassification risk is in general NP-hard. Tractable solvers can be obtained by considering a surrogate regression problem. While convergence to the regression function is typically sublinear, the corresponding classification error can decay much faster. Fast and super fast rates (up to exponential) have been established for general smooth losses on problems where a hard margin is present between classes. This leaves out models based on non-smooth losses such as support vector machines, and problems where there is no hard margin, begging several questions. Are such models incapable of fast convergence? Are they therefore structurally inferior? Is the hard margin condition really necessary to obtain exponential convergence? Developing a new strategy, we provide an answer to these questions. In particular, we show not only that support vector machines can indeed converge exponentially fast, but also that they can do so even without hard margin.",
        "bibtex": "@InProceedings{pmlr-v206-cabannnes23a,\n  title = \t {A Case of Exponential Convergence Rates for SVM},\n  author =       {Cabannnes, Vivien and Vigogna, Stefano},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {359--374},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cabannnes23a/cabannnes23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cabannnes23a.html},\n  abstract = \t {Optimizing the misclassification risk is in general NP-hard. Tractable solvers can be obtained by considering a surrogate regression problem. While convergence to the regression function is typically sublinear, the corresponding classification error can decay much faster. Fast and super fast rates (up to exponential) have been established for general smooth losses on problems where a hard margin is present between classes. This leaves out models based on non-smooth losses such as support vector machines, and problems where there is no hard margin, begging several questions. Are such models incapable of fast convergence? Are they therefore structurally inferior? Is the hard margin condition really necessary to obtain exponential convergence? Developing a new strategy, we provide an answer to these questions. In particular, we show not only that support vector machines can indeed converge exponentially fast, but also that they can do so even without hard margin.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cabannnes23a/cabannnes23a.pdf",
        "supp": "",
        "pdf_size": 2814882,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16325325522616084300&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "meta ai; university of rome tor vergata",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Meta;University of Rome Tor Vergata",
        "aff_unique_dep": "Meta AI;",
        "aff_unique_url": "https://ai.facebook.com;https://www.uniroma2.it",
        "aff_unique_abbr": "Meta AI;Tor Vergata",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Rome",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "f7820cd591",
        "title": "A Conditional Gradient-based Method for Simple Bilevel Optimization with Convex Lower-level Problem",
        "site": "https://proceedings.mlr.press/v206/jiang23a.html",
        "author": "Ruichen Jiang; Nazanin Abolfazli; Aryan Mokhtari; Erfan Yazdandoost Hamedani",
        "abstract": "In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane and then runs a conditional gradient update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${O}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${O}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. We also prove stronger convergence guarantees under the Holderian error bound assumption on the lower-level problem. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered class of bilevel problems.",
        "bibtex": "@InProceedings{pmlr-v206-jiang23a,\n  title = \t {A Conditional Gradient-based Method for Simple Bilevel Optimization with Convex Lower-level Problem},\n  author =       {Jiang, Ruichen and Abolfazli, Nazanin and Mokhtari, Aryan and Yazdandoost Hamedani, Erfan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10305--10323},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jiang23a/jiang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jiang23a.html},\n  abstract = \t {In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane and then runs a conditional gradient update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${O}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${O}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. We also prove stronger convergence guarantees under the Holderian error bound assumption on the lower-level problem. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered class of bilevel problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jiang23a/jiang23a.pdf",
        "supp": "",
        "pdf_size": 1998525,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1039033013679431043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "69d8410aae",
        "title": "A Constant-Factor Approximation Algorithm for Reconciliation $k$-Median",
        "site": "https://proceedings.mlr.press/v206/spoerhase23a.html",
        "author": "Joachim Spoerhase; Kamyar Khodamoradi; Benedikt Riegel; Bruno Ordozgoiti; Aristides Gionis",
        "abstract": "In the reconciliation $k$-median problem we ask to cluster a set of data points by picking $k$ cluster centers so as to minimize the sum of distances of the data points to their cluster centers plus the sum of pairwise distances between the centers. The problem, which is a variant of classic $k$-median, aims to find a set of cluster centers that are not too far from each other, and it has applications, or example, when selecting a committee to deliberate on a controversial topic. This problem was introduced recently (Ordozgoiti et al., 2019), and it was shown that a local-search-based algorithm is always within a factor $O(k)$ of an optimum solution and performs well in practice. In this paper, we demonstrate a close connection of reconciliation $k$-median to a variant of the $k$-facility location problem, in which each potential cluster center has an individual opening cost and we aim at minimizing the sum of client-center distances and the opening costs. This connection enables us to provide a new algorithm for reconciliation $k$-median that yields a constant-factor approximation (independent of $k$). We also provide a sparsification scheme that reduces the number of potential cluster centers to $O(k)$ in order to substantially speed up approximation algorithms. We empirically compare our new algorithms with the previous local-search approach, showing improved performance and stability. In addition, we show how our sparsification approach helps to reduce computation time without significantly compromising the solution quality.",
        "bibtex": "@InProceedings{pmlr-v206-spoerhase23a,\n  title = \t {A Constant-Factor Approximation Algorithm for Reconciliation $k$-Median},\n  author =       {Spoerhase, Joachim and Khodamoradi, Kamyar and Riegel, Benedikt and Ordozgoiti, Bruno and Gionis, Aristides},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1719--1746},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/spoerhase23a/spoerhase23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/spoerhase23a.html},\n  abstract = \t {In the reconciliation $k$-median problem we ask to cluster a set of data points by picking $k$ cluster centers so as to minimize the sum of distances of the data points to their cluster centers plus the sum of pairwise distances between the centers. The problem, which is a variant of classic $k$-median, aims to find a set of cluster centers that are not too far from each other, and it has applications, or example, when selecting a committee to deliberate on a controversial topic. This problem was introduced recently (Ordozgoiti et al., 2019), and it was shown that a local-search-based algorithm is always within a factor $O(k)$ of an optimum solution and performs well in practice. In this paper, we demonstrate a close connection of reconciliation $k$-median to a variant of the $k$-facility location problem, in which each potential cluster center has an individual opening cost and we aim at minimizing the sum of client-center distances and the opening costs. This connection enables us to provide a new algorithm for reconciliation $k$-median that yields a constant-factor approximation (independent of $k$). We also provide a sparsification scheme that reduces the number of potential cluster centers to $O(k)$ in order to substantially speed up approximation algorithms. We empirically compare our new algorithms with the previous local-search approach, showing improved performance and stability. In addition, we show how our sparsification approach helps to reduce computation time without significantly compromising the solution quality.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/spoerhase23a/spoerhase23a.pdf",
        "supp": "",
        "pdf_size": 1124947,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mW0eRdMFuhQJ:scholar.google.com/&scioq=A+Constant-Factor+Approximation+Algorithm+for+Reconciliation+%24k%24-Median&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "University of Shef\ufb01eld, UK; University of British Columbia, BC, Canada; University of Stuttgart, Germany; Queen Mary University of London, UK; KTH Royal Institute of Technology, Sweden",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of Sheffield;University of British Columbia;University of Stuttgart;Queen Mary University of London;KTH Royal Institute of Technology",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.sheffield.ac.uk;https://www.ubc.ca;https://www.uni-stuttgart.de;https://www.qmul.ac.uk;https://www.kth.se",
        "aff_unique_abbr": "Sheffield;UBC;USTuttgart;QMUL;KTH",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Vancouver;London",
        "aff_country_unique_index": "0;1;2;0;3",
        "aff_country_unique": "United Kingdom;Canada;Germany;Sweden"
    },
    {
        "id": "366931e16d",
        "title": "A Contrastive Approach to Online Change Point Detection",
        "site": "https://proceedings.mlr.press/v206/puchkin23a.html",
        "author": "Nikita Puchkin; Valeriia Shcherbakova",
        "abstract": "We suggest a novel procedure for online change point detection. Our approach expands an idea of maximizing a discrepancy measure between points from pre-change and post-change distributions. This leads to a flexible procedure suitable for both parametric and nonparametric scenarios. We prove non-asymptotic bounds on the average running length of the procedure and its expected detection delay. The efficiency of the algorithm is illustrated with numerical experiments on synthetic and real-world data sets.",
        "bibtex": "@InProceedings{pmlr-v206-puchkin23a,\n  title = \t {A Contrastive Approach to Online Change Point Detection},\n  author =       {Puchkin, Nikita and Shcherbakova, Valeriia},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5686--5713},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/puchkin23a/puchkin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/puchkin23a.html},\n  abstract = \t {We suggest a novel procedure for online change point detection. Our approach expands an idea of maximizing a discrepancy measure between points from pre-change and post-change distributions. This leads to a flexible procedure suitable for both parametric and nonparametric scenarios. We prove non-asymptotic bounds on the average running length of the procedure and its expected detection delay. The efficiency of the algorithm is illustrated with numerical experiments on synthetic and real-world data sets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/puchkin23a/puchkin23a.pdf",
        "supp": "",
        "pdf_size": 1512481,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8528189563948427025&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "HSE University and IITP RAS, Moscow, Russian Federation; HSE University and Sberbank of Russia, Moscow, Russian Federation",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "HSE University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.hse.ru",
        "aff_unique_abbr": "HSE",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9595ee44c3",
        "title": "A Faster Sampler for Discrete Determinantal Point Processes",
        "site": "https://proceedings.mlr.press/v206/barthelme23a.html",
        "author": "Simon Barthelm\u00e9; Nicolas Tremblay; Pierre-Olivier Amblard",
        "abstract": "Discrete Determinantal Point Processes (DPPs) have a wide array of potential applications for subsampling datasets. They are however held back in some cases by the high cost of sampling. In the worst-case scenario, the sampling cost scales as $O(n^3)$ where n is the number of elements of the ground set. A popular workaround to this prohibitive cost is to sample DPPs defined by low-rank kernels. In such cases, the cost of standard sampling algorithms scales as $O(np^2 + nm^2)$ where m is the (average) number of samples of the DPP (usually m $\\ll$ n) and p the rank of the kernel used to define the DPP (m $\\leq$ p $\\leq$ n). The first term, $O(np^2)$, comes from a SVD-like step. We focus here on the second term of this cost, $O(nm^2)$, and show that it can be brought down to $O(nm + m^3 log m)$ without loss on the sampling\u2019s exactness. In practice, we observe very substantial speedups compared to the classical algorithm as soon as n $>$ 1, 000. The algorithm described here is a close variant of the standard algorithm for sampling continuous DPPs, and uses rejection sampling. In the specific case of projection DPPs, we also show that any additional sample can be drawn in time $O(m^3 log m)$. Finally, an interesting by-product of the analysis is that a realisation from a DPP is typically contained in a subset of size $O(m \\log m)$ formed using leverage score i.i.d. sampling.",
        "bibtex": "@InProceedings{pmlr-v206-barthelme23a,\n  title = \t {A Faster Sampler for Discrete Determinantal Point Processes},\n  author =       {Barthelm\\'e, Simon and Tremblay, Nicolas and Amblard, Pierre-Olivier},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5582--5592},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/barthelme23a/barthelme23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/barthelme23a.html},\n  abstract = \t {Discrete Determinantal Point Processes (DPPs) have a wide array of potential applications for subsampling datasets. They are however held back in some cases by the high cost of sampling. In the worst-case scenario, the sampling cost scales as $O(n^3)$ where n is the number of elements of the ground set. A popular workaround to this prohibitive cost is to sample DPPs defined by low-rank kernels. In such cases, the cost of standard sampling algorithms scales as $O(np^2 + nm^2)$ where m is the (average) number of samples of the DPP (usually m $\\ll$ n) and p the rank of the kernel used to define the DPP (m $\\leq$ p $\\leq$ n). The first term, $O(np^2)$, comes from a SVD-like step. We focus here on the second term of this cost, $O(nm^2)$, and show that it can be brought down to $O(nm + m^3 log m)$ without loss on the sampling\u2019s exactness. In practice, we observe very substantial speedups compared to the classical algorithm as soon as n $>$ 1, 000. The algorithm described here is a close variant of the standard algorithm for sampling continuous DPPs, and uses rejection sampling. In the specific case of projection DPPs, we also show that any additional sample can be drawn in time $O(m^3 log m)$. Finally, an interesting by-product of the analysis is that a realisation from a DPP is typically contained in a subset of size $O(m \\log m)$ formed using leverage score i.i.d. sampling.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/barthelme23a/barthelme23a.pdf",
        "supp": "",
        "pdf_size": 407390,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12257688699554174498&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d3f45e7584",
        "title": "A Finite Sample Complexity Bound for Distributionally Robust Q-learning",
        "site": "https://proceedings.mlr.press/v206/wang23b.html",
        "author": "Shengbo Wang; Nian Si; Jose Blanchet; Zhengyuan Zhou",
        "abstract": "We consider a reinforcement learning setting in which the deployment environment is different from the training environment. Applying a robust Markov decision processes formulation, we extend the distributionally robust Q-learning framework studied in [Liu et. al. 2022]. Further, we improve the design and analysis of their multi-level Monte Carlo estimator. Assuming access to a simulator, we prove that the worst-case expected sample complexity of our algorithm to learn the optimal robust Q-function within an $\\epsilon$ error in the sup norm is upper bounded by $\\tilde O(|S||A|(1-\\gamma)^{-5}\\epsilon^{-2}p_{\\wedge}^{-6}\\delta^{-4})$, where $\\gamma$ is the discount rate, $p_{\\wedge}$ is the non-zero minimal support probability of the transition kernels and $\\delta$ is the uncertainty size. This is the first sample complexity result for the model-free robust RL problem. Simulation studies further validate our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v206-wang23b,\n  title = \t {A Finite Sample Complexity Bound for Distributionally Robust Q-learning},\n  author =       {Wang, Shengbo and Si, Nian and Blanchet, Jose and Zhou, Zhengyuan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3370--3398},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23b/wang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23b.html},\n  abstract = \t {We consider a reinforcement learning setting in which the deployment environment is different from the training environment. Applying a robust Markov decision processes formulation, we extend the distributionally robust Q-learning framework studied in [Liu et. al. 2022]. Further, we improve the design and analysis of their multi-level Monte Carlo estimator. Assuming access to a simulator, we prove that the worst-case expected sample complexity of our algorithm to learn the optimal robust Q-function within an $\\epsilon$ error in the sup norm is upper bounded by $\\tilde O(|S||A|(1-\\gamma)^{-5}\\epsilon^{-2}p_{\\wedge}^{-6}\\delta^{-4})$, where $\\gamma$ is the discount rate, $p_{\\wedge}$ is the non-zero minimal support probability of the transition kernels and $\\delta$ is the uncertainty size. This is the first sample complexity result for the model-free robust RL problem. Simulation studies further validate our theoretical results.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23b/wang23b.pdf",
        "supp": "",
        "pdf_size": 4682511,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1017030269857519738&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1103a54db2",
        "title": "A Mini-Block Fisher Method for Deep Neural Networks",
        "site": "https://proceedings.mlr.press/v206/bahamou23a.html",
        "author": "Achraf Bahamou; Donald Goldfarb; Yi Ren",
        "abstract": "Deep Neural Networks (DNNs) are currently predominantly trained using first-order methods. Some of these methods (e.g., Adam, AdaGrad, and RMSprop, and their variants) incorporate a small amount of curvature information by using a diagonal matrix to precondition the stochastic gradient. Recently, effective second-order methods, such as KFAC, K-BFGS, Shampoo, and TNT, have been developed for training DNNs, by preconditioning the stochastic gradient by layer-wise block-diagonal matrices. Here we propose a \u201cmini-block Fisher (MBF)\u201d preconditioned stochastic gradient method, that lies in between these two classes of methods. Specifically, our method uses a block-diagonal approximation to the empirical Fisher matrix, where for each layer in the DNN, whether it is convolutional or feed-forward and fully connected, the associated diagonal block is itself block-diagonal and is composed of a large number of mini-blocks of modest size. Our novel approach utilizes the parallelism of GPUs to efficiently perform computations on the large number of matrices in each layer. Consequently, MBF\u2019s per-iteration computational cost is only slightly higher than it is for first-order methods. The performance of MBF is compared to that of several baseline methods, on Autoencoder, Convolutional Neural Network (CNN), and Graph Convolutional Network (GCN) problems, to validate its effectiveness both in terms of time efficiency and generalization power. Finally, it is proved that an idealized version of MBF converges linearly.",
        "bibtex": "@InProceedings{pmlr-v206-bahamou23a,\n  title = \t {A Mini-Block Fisher Method for Deep Neural Networks},\n  author =       {Bahamou, Achraf and Goldfarb, Donald and Ren, Yi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9191--9220},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bahamou23a/bahamou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bahamou23a.html},\n  abstract = \t {Deep Neural Networks (DNNs) are currently predominantly trained using first-order methods. Some of these methods (e.g., Adam, AdaGrad, and RMSprop, and their variants) incorporate a small amount of curvature information by using a diagonal matrix to precondition the stochastic gradient. Recently, effective second-order methods, such as KFAC, K-BFGS, Shampoo, and TNT, have been developed for training DNNs, by preconditioning the stochastic gradient by layer-wise block-diagonal matrices. Here we propose a \u201cmini-block Fisher (MBF)\u201d preconditioned stochastic gradient method, that lies in between these two classes of methods. Specifically, our method uses a block-diagonal approximation to the empirical Fisher matrix, where for each layer in the DNN, whether it is convolutional or feed-forward and fully connected, the associated diagonal block is itself block-diagonal and is composed of a large number of mini-blocks of modest size. Our novel approach utilizes the parallelism of GPUs to efficiently perform computations on the large number of matrices in each layer. Consequently, MBF\u2019s per-iteration computational cost is only slightly higher than it is for first-order methods. The performance of MBF is compared to that of several baseline methods, on Autoencoder, Convolutional Neural Network (CNN), and Graph Convolutional Network (GCN) problems, to validate its effectiveness both in terms of time efficiency and generalization power. Finally, it is proved that an idealized version of MBF converges linearly.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bahamou23a/bahamou23a.pdf",
        "supp": "",
        "pdf_size": 9096556,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15899694015341605904&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "278d2d07b7",
        "title": "A Multi-Task Gaussian Process Model for Inferring Time-Varying Treatment Effects in Panel Data",
        "site": "https://proceedings.mlr.press/v206/chen23d.html",
        "author": "Yehu Chen; Annamaria Prati; Jacob Montgomery; Roman Garnett",
        "abstract": "We introduce a Bayesian multi-task Gaussian process model for estimating treatment effects from panel data, where an intervention outside the observer\u2019s control influences a subset of the observed units. Our model encodes structured temporal dynamics both within and across the treatment and control groups and incorporates a flexible prior for the evolution of treatment effects over time. These innovations aid in inferring posteriors for dynamic treatment effects that encode our uncertainty about the likely trajectories of units in the absence of treatment. We also discuss the asymptotic properties of the joint posterior over counterfactual outcomes and treatment effects, which exhibits intuitive behavior in the large-sample limit. In experiments on both synthetic and real data, our approach performs no worse than existing methods and significantly better when standard assumptions are violated.",
        "bibtex": "@InProceedings{pmlr-v206-chen23d,\n  title = \t {A Multi-Task Gaussian Process Model for Inferring Time-Varying Treatment Effects in Panel Data},\n  author =       {Chen, Yehu and Prati, Annamaria and Montgomery, Jacob and Garnett, Roman},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4068--4088},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23d/chen23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23d.html},\n  abstract = \t {We introduce a Bayesian multi-task Gaussian process model for estimating treatment effects from panel data, where an intervention outside the observer\u2019s control influences a subset of the observed units. Our model encodes structured temporal dynamics both within and across the treatment and control groups and incorporates a flexible prior for the evolution of treatment effects over time. These innovations aid in inferring posteriors for dynamic treatment effects that encode our uncertainty about the likely trajectories of units in the absence of treatment. We also discuss the asymptotic properties of the joint posterior over counterfactual outcomes and treatment effects, which exhibits intuitive behavior in the large-sample limit. In experiments on both synthetic and real data, our approach performs no worse than existing methods and significantly better when standard assumptions are violated.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23d/chen23d.pdf",
        "supp": "",
        "pdf_size": 592936,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13297676389907004857&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ad6c093dfa",
        "title": "A New Causal Decomposition Paradigm towards Health Equity",
        "site": "https://proceedings.mlr.press/v206/sun23a.html",
        "author": "Xinwei Sun; Xiangyu Zheng; Jim Weinstein",
        "abstract": "Causal decomposition has provided a powerful tool to analyze health disparity problems by assessing the proportion of disparity caused by each mediator (the variable that mediates the effect of the exposure on the health outcome). However, most of these methods lack policy implications, as they fail to account for all sources of disparities caused by the mediator. Besides, its identifiability needs to specify a set to be admissible to make the strong ignorability condition hold, which can be problematic as some variables in this set may induce new spurious features. To resolve these issues, under the framework of the structural causal model, we propose a new decomposition, dubbed as adjusted and unadjusted effects, which is able to include all types of disparity by adjusting each mediator\u2019s distribution from the disadvantaged group to the advantaged ones. Besides, by learning the maximal ancestral graph and implementing causal discovery from heterogeneous data, we can identify the admissible set, followed by an efficient algorithm for estimation. The theoretical correctness and efficacy of our method are demonstrated using a synthetic dataset and a common spine disease dataset.",
        "bibtex": "@InProceedings{pmlr-v206-sun23a,\n  title = \t {A New Causal Decomposition Paradigm towards Health Equity},\n  author =       {Sun, Xinwei and Zheng, Xiangyu and Weinstein, Jim},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {875--890},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sun23a/sun23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sun23a.html},\n  abstract = \t {Causal decomposition has provided a powerful tool to analyze health disparity problems by assessing the proportion of disparity caused by each mediator (the variable that mediates the effect of the exposure on the health outcome). However, most of these methods lack policy implications, as they fail to account for all sources of disparities caused by the mediator. Besides, its identifiability needs to specify a set to be admissible to make the strong ignorability condition hold, which can be problematic as some variables in this set may induce new spurious features. To resolve these issues, under the framework of the structural causal model, we propose a new decomposition, dubbed as adjusted and unadjusted effects, which is able to include all types of disparity by adjusting each mediator\u2019s distribution from the disadvantaged group to the advantaged ones. Besides, by learning the maximal ancestral graph and implementing causal discovery from heterogeneous data, we can identify the admissible set, followed by an efficient algorithm for estimation. The theoretical correctness and efficacy of our method are demonstrated using a synthetic dataset and a common spine disease dataset.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sun23a/sun23a.pdf",
        "supp": "",
        "pdf_size": 4578466,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5254107702746701529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "School of Data Science, Fudan University; Department of Statistics, Guanghua School of Management, Peking University; Microsoft Corporation, Microsoft Research, Redmond, WA + Dartmouth, Tuck Business School + Northwestern University, Kellogg School of Business",
        "aff_domain": "fudan.edu.cn; ;microsoft.com",
        "email": "fudan.edu.cn; ;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3+4",
        "aff_unique_norm": "Fudan University;Peking University;Microsoft;Dartmouth College;Northwestern University",
        "aff_unique_dep": "School of Data Science;Department of Statistics, Guanghua School of Management;Microsoft Research;Tuck Business School;Kellogg School of Business",
        "aff_unique_url": "https://www.fudan.edu.cn;http://www.pku.edu.cn;https://www.microsoft.com;https://tuck.dartmouth.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "Fudan;PKU;Microsoft;Dartmouth;NU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Redmond",
        "aff_country_unique_index": "0;0;1+1+1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "c98164e503",
        "title": "A New Modeling Framework for Continuous, Sequential Domains",
        "site": "https://proceedings.mlr.press/v206/dong23a.html",
        "author": "Hailiang Dong; James Amato; Vibhav Gogate; Nicholas Ruozzi",
        "abstract": "Temporal models such as Dynamic Bayesian Networks (DBNs) and Hidden Markov Models (HMMs) have been widely used to model time-dependent sequential data. Typically, these approaches limit focus to discrete domains, employ first-order Markov and stationary assumptions, and limit representational power so that efficient (approximate) inference procedures can be applied. We propose a novel temporal model for continuous domains, where the transition distribution is conditionally tractable: it is modelled as a tractable continuous density over the variables at the current time slice only, while the parameters are controlled using a Recurrent Neural Network (RNN) that takes all previous observations as input. We show that, in this model, various inference tasks can be efficiently implemented using forward filtering with simple gradient ascent. Our experimental results on two different tasks over several real-world sequential datasets demonstrate the superior performance of our model against existing competitors.",
        "bibtex": "@InProceedings{pmlr-v206-dong23a,\n  title = \t {A New Modeling Framework for Continuous, Sequential Domains},\n  author =       {Dong, Hailiang and Amato, James and Gogate, Vibhav and Ruozzi, Nicholas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11118--11131},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dong23a/dong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dong23a.html},\n  abstract = \t {Temporal models such as Dynamic Bayesian Networks (DBNs) and Hidden Markov Models (HMMs) have been widely used to model time-dependent sequential data. Typically, these approaches limit focus to discrete domains, employ first-order Markov and stationary assumptions, and limit representational power so that efficient (approximate) inference procedures can be applied. We propose a novel temporal model for continuous domains, where the transition distribution is conditionally tractable: it is modelled as a tractable continuous density over the variables at the current time slice only, while the parameters are controlled using a Recurrent Neural Network (RNN) that takes all previous observations as input. We show that, in this model, various inference tasks can be efficiently implemented using forward filtering with simple gradient ascent. Our experimental results on two different tasks over several real-world sequential datasets demonstrate the superior performance of our model against existing competitors.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dong23a/dong23a.pdf",
        "supp": "",
        "pdf_size": 1163778,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14585876781272851350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Texas at Dallas, Richardson, TX, 75080, USA; The University of Texas at Dallas, Richardson, TX, 75080, USA; The University of Texas at Dallas, Richardson, TX, 75080, USA; The University of Texas at Dallas, Richardson, TX, 75080, USA",
        "aff_domain": "utdallas.edu;utdallas.edu;utdallas.edu;utdallas.edu",
        "email": "utdallas.edu;utdallas.edu;utdallas.edu;utdallas.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Dallas",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utdallas.edu",
        "aff_unique_abbr": "UT Dallas",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Richardson",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f77b222507",
        "title": "A Novel Stochastic Gradient Descent Algorithm for Learning Principal Subspaces",
        "site": "https://proceedings.mlr.press/v206/lan23a.html",
        "author": "Charline Le Lan; Joshua Greaves; Jesse Farebrother; Mark Rowland; Fabian Pedregosa; Rishabh Agarwal; Marc G. Bellemare",
        "abstract": "Many machine learning problems encode their data as a matrix with a possibly very large number of rows and columns. In several applications like neuroscience, image compression or deep reinforcement learning, the principal subspace of such a matrix provides a useful, low-dimensional representation of individual data. Here, we are interested in determining the $d$-dimensional principal subspace of a given matrix from sample entries, i.e. from small random submatrices. Although a number of sample-based methods exist for this problem (e.g. Oja\u2019s rule (Oja, 1982)), these assume access to full columns of the matrix or particular matrix structure such as symmetry and cannot be combined as-is with neural networks (Baldi et al., 1989). In this paper, we derive an algorithm that learns a principal subspace from sample entries, can be applied when the approximate subspace is represented by a neural network, and hence can be scaled to datasets with an effectively infinite number of rows and columns. Our method consists in defining a loss function whose minimizer is the desired principal subspace, and constructing a gradient estimate of this loss whose bias can be controlled. We complement our theoretical analysis with a series of experiments on synthetic matrices, the MNIST dataset (LeCun et al. 2010) and the reinforcement learning domain PuddleWorld (Sutton, 1995) demonstrating the usefulness of our approach.",
        "bibtex": "@InProceedings{pmlr-v206-lan23a,\n  title = \t {A Novel Stochastic Gradient Descent Algorithm for Learning Principal Subspaces},\n  author =       {Lan, Charline Le and Greaves, Joshua and Farebrother, Jesse and Rowland, Mark and Pedregosa, Fabian and Agarwal, Rishabh and Bellemare, Marc G.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1703--1718},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lan23a/lan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lan23a.html},\n  abstract = \t {Many machine learning problems encode their data as a matrix with a possibly very large number of rows and columns. In several applications like neuroscience, image compression or deep reinforcement learning, the principal subspace of such a matrix provides a useful, low-dimensional representation of individual data. Here, we are interested in determining the $d$-dimensional principal subspace of a given matrix from sample entries, i.e. from small random submatrices. Although a number of sample-based methods exist for this problem (e.g. Oja\u2019s rule (Oja, 1982)), these assume access to full columns of the matrix or particular matrix structure such as symmetry and cannot be combined as-is with neural networks (Baldi et al., 1989). In this paper, we derive an algorithm that learns a principal subspace from sample entries, can be applied when the approximate subspace is represented by a neural network, and hence can be scaled to datasets with an effectively infinite number of rows and columns. Our method consists in defining a loss function whose minimizer is the desired principal subspace, and constructing a gradient estimate of this loss whose bias can be controlled. We complement our theoretical analysis with a series of experiments on synthetic matrices, the MNIST dataset (LeCun et al. 2010) and the reinforcement learning domain PuddleWorld (Sutton, 1995) demonstrating the usefulness of our approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lan23a/lan23a.pdf",
        "supp": "",
        "pdf_size": 1333174,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13430993599397411286&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Oxford; Google Brain; McGill University; DeepMind; Google Brain; Google Brain; Google Brain",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;1;1;1",
        "aff_unique_norm": "University of Oxford;Google;McGill University;DeepMind",
        "aff_unique_dep": ";Google Brain;;",
        "aff_unique_url": "https://www.ox.ac.uk;https://brain.google.com;https://www.mcgill.ca;https://deepmind.com",
        "aff_unique_abbr": "Oxford;Google Brain;McGill;DeepMind",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;2;0;1;1;1",
        "aff_country_unique": "United Kingdom;United States;Canada"
    },
    {
        "id": "4be9b5ee7e",
        "title": "A Sea of Words: An In-Depth Analysis of Anchors for Text Data",
        "site": "https://proceedings.mlr.press/v206/lopardo23a.html",
        "author": "Gianluigi Lopardo; Frederic Precioso; Damien Garreau",
        "abstract": "Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. After formalizing the algorithm for text classification, we present explicit results on different classes of models when the vectorization step is TF-IDF, and words are replaced by a fixed out-of-dictionary token when removed. Our inquiry covers models such as elementary if-then rules and linear classifiers. We then leverage this analysis to gain insights on the behavior of Anchors for any differentiable classifiers. For neural networks, we empirically show that the words corresponding to the highest partial derivatives of the model with respect to the input, reweighted by the inverse document frequencies, are selected by Anchors.",
        "bibtex": "@InProceedings{pmlr-v206-lopardo23a,\n  title = \t {A Sea of Words: An In-Depth Analysis of Anchors for Text Data},\n  author =       {Lopardo, Gianluigi and Precioso, Frederic and Garreau, Damien},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4848--4879},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lopardo23a/lopardo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lopardo23a.html},\n  abstract = \t {Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. After formalizing the algorithm for text classification, we present explicit results on different classes of models when the vectorization step is TF-IDF, and words are replaced by a fixed out-of-dictionary token when removed. Our inquiry covers models such as elementary if-then rules and linear classifiers. We then leverage this analysis to gain insights on the behavior of Anchors for any differentiable classifiers. For neural networks, we empirically show that the words corresponding to the highest partial derivatives of the model with respect to the input, reweighted by the inverse document frequencies, are selected by Anchors.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lopardo23a/lopardo23a.pdf",
        "supp": "",
        "pdf_size": 23371612,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5391862598138590293&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2df88f5d46",
        "title": "A Statistical Analysis of Polyak-Ruppert Averaged Q-Learning",
        "site": "https://proceedings.mlr.press/v206/li23b.html",
        "author": "Xiang Li; Wenhao Yang; Jiadong Liang; Zhihua Zhang; Michael I. Jordan",
        "abstract": "We study Q-learning with Polyak-Ruppert averaging (a.k.a., averaged Q-learning) in a discounted markov decision process in synchronous and tabular settings. Under a Lipschitz condition, we establish a functional central limit theorem for the averaged iteration $\\bar{\\mathbf{Q}}_T$ and show that its standardized partial-sum process converges weakly to a rescaled Brownian motion. The FCLT implies a fully online inference method for reinforcement learning. Furthermore, we show that $\\bar{\\mathbf{Q}}_T$ is the regular asymptotically linear (RAL) estimator for the optimal Q-value function $\\mathbf{Q}^*$ that has the most efficient influence function. We present a nonasymptotic analysis for the $\\ell_{\\infty}$ error, $\\mathbb{E}\\|\\bar{\\mathbf{Q}}_T-\\mathbf{Q}^*\\|_{\\infty}$, showing that it matches the instance-dependent lower bound for polynomial step sizes. Similar results are provided for entropy-regularized Q-Learning without the Lipschitz condition.",
        "bibtex": "@InProceedings{pmlr-v206-li23b,\n  title = \t {A Statistical Analysis of Polyak-Ruppert Averaged Q-Learning},\n  author =       {Li, Xiang and Yang, Wenhao and Liang, Jiadong and Zhang, Zhihua and Jordan, Michael I.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2207--2261},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/li23b/li23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/li23b.html},\n  abstract = \t {We study Q-learning with Polyak-Ruppert averaging (a.k.a., averaged Q-learning) in a discounted markov decision process in synchronous and tabular settings. Under a Lipschitz condition, we establish a functional central limit theorem for the averaged iteration $\\bar{\\mathbf{Q}}_T$ and show that its standardized partial-sum process converges weakly to a rescaled Brownian motion. The FCLT implies a fully online inference method for reinforcement learning. Furthermore, we show that $\\bar{\\mathbf{Q}}_T$ is the regular asymptotically linear (RAL) estimator for the optimal Q-value function $\\mathbf{Q}^*$ that has the most efficient influence function. We present a nonasymptotic analysis for the $\\ell_{\\infty}$ error, $\\mathbb{E}\\|\\bar{\\mathbf{Q}}_T-\\mathbf{Q}^*\\|_{\\infty}$, showing that it matches the instance-dependent lower bound for polynomial step sizes. Similar results are provided for entropy-regularized Q-Learning without the Lipschitz condition.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/li23b/li23b.pdf",
        "supp": "",
        "pdf_size": 892872,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2558165752374672016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Peking University; Peking University; Peking University; Peking University; UC Berkeley",
        "aff_domain": "pku.edu.cn;pku.edu.cn;pku.edu.cn;math.pku.edu.cn;cs.berkeley.edu",
        "email": "pku.edu.cn;pku.edu.cn;pku.edu.cn;math.pku.edu.cn;cs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Peking University;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.berkeley.edu",
        "aff_unique_abbr": "Peking U;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "4c6d7904f1",
        "title": "A Statistical Learning Take on the Concordance Index for Survival Analysis",
        "site": "https://proceedings.mlr.press/v206/elgui23a.html",
        "author": "Kevin Elgui; Alex Nowak; Genevi\u00e8ve Robin",
        "abstract": "The introduction of machine learning (ML) techniques to the field of survival analysis has increased the flexibility of modeling approaches, and ML based models have become state-of-the-art. These models optimize their own cost functions, and their performance is often evaluated using the concordance index (C-index). From a statistical learning perspective, it is therefore an important problem to analyze the relationship between the optimizers of the C-index and those of the ML cost functions. We address this issue by providing C-index Fisher-consistency results and excess risk bounds for several of the commonly used cost functions in survival analysis. We identify conditions under which they are consistent, under the form of three nested families of survival models. We also study the general case where no model assumption is made and present a new, off-the-shelf method that is shown to be consistent with the C-index, although computationally expensive at inference. Finally, we perform limited numerical experiments with simulated data to illustrate our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v206-elgui23a,\n  title = \t {A Statistical Learning Take on the Concordance Index for Survival Analysis},\n  author =       {Elgui, Kevin and Nowak, Alex and Robin, Genevi\\`eve},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4712--4731},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/elgui23a/elgui23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/elgui23a.html},\n  abstract = \t {The introduction of machine learning (ML) techniques to the field of survival analysis has increased the flexibility of modeling approaches, and ML based models have become state-of-the-art. These models optimize their own cost functions, and their performance is often evaluated using the concordance index (C-index). From a statistical learning perspective, it is therefore an important problem to analyze the relationship between the optimizers of the C-index and those of the ML cost functions. We address this issue by providing C-index Fisher-consistency results and excess risk bounds for several of the commonly used cost functions in survival analysis. We identify conditions under which they are consistent, under the form of three nested families of survival models. We also study the general case where no model assumption is made and present a new, off-the-shelf method that is shown to be consistent with the C-index, although computationally expensive at inference. Finally, we perform limited numerical experiments with simulated data to illustrate our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/elgui23a/elgui23a.pdf",
        "supp": "",
        "pdf_size": 2214909,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18192342200405477804&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "24eef78e3e",
        "title": "A Tale of Sampling and Estimation in Discounted Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/metelli23a.html",
        "author": "Alberto Maria Metelli; Mirco Mutti; Marcello Restelli",
        "abstract": "The most relevant problems in discounted reinforcement learning involve estimating the mean of a function under the stationary distribution of a Markov reward process, such as the expected return in policy evaluation, or the policy gradient in policy optimization. In practice, these estimates are produced through a finite-horizon episodic sampling, which neglects the mixing properties of the Markov process. It is mostly unclear how this mismatch between the practical and the ideal setting affects the estimation, and the literature lacks a formal study on the pitfalls of episodic sampling, and how to do it optimally. In this paper, we present a minimax lower bound on the discounted mean estimation problem that explicitly connects the estimation error with the mixing properties of the Markov process and the discount factor. Then, we provide a statistical analysis on a set of notable estimators and the corresponding sampling procedures, which includes the finite-horizon estimators often used in practice. Crucially, we show that estimating the mean by directly sampling from the discounted kernel of the Markov process brings compelling statistical properties w.r.t. the alternative estimators, as it matches the lower bound without requiring a careful tuning of the episode horizon.",
        "bibtex": "@InProceedings{pmlr-v206-metelli23a,\n  title = \t {A Tale of Sampling and Estimation in Discounted Reinforcement Learning},\n  author =       {Metelli, Alberto Maria and Mutti, Mirco and Restelli, Marcello},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4575--4601},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/metelli23a/metelli23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/metelli23a.html},\n  abstract = \t {The most relevant problems in discounted reinforcement learning involve estimating the mean of a function under the stationary distribution of a Markov reward process, such as the expected return in policy evaluation, or the policy gradient in policy optimization. In practice, these estimates are produced through a finite-horizon episodic sampling, which neglects the mixing properties of the Markov process. It is mostly unclear how this mismatch between the practical and the ideal setting affects the estimation, and the literature lacks a formal study on the pitfalls of episodic sampling, and how to do it optimally. In this paper, we present a minimax lower bound on the discounted mean estimation problem that explicitly connects the estimation error with the mixing properties of the Markov process and the discount factor. Then, we provide a statistical analysis on a set of notable estimators and the corresponding sampling procedures, which includes the finite-horizon estimators often used in practice. Crucially, we show that estimating the mean by directly sampling from the discounted kernel of the Markov process brings compelling statistical properties w.r.t. the alternative estimators, as it matches the lower bound without requiring a careful tuning of the episode horizon.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/metelli23a/metelli23a.pdf",
        "supp": "",
        "pdf_size": 561928,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3821817194525504813&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4da177ccee",
        "title": "A Tale of Two Efficient Value Iteration Algorithms for Solving Linear MDPs with Large Action Space",
        "site": "https://proceedings.mlr.press/v206/xu23b.html",
        "author": "Zhaozhuo Xu; Zhao Song; Anshumali Shrivastava",
        "abstract": "Markov Decision Process (MDP) with large action space naturally occurs in many applications such as language processing, information retrieval, and recommendation system. There have been various approaches to solve these MDPs through value iteration (VI). Unfortunately, all VI algorithms require expensive linear scans over the entire action space for value function estimation during each iteration. To this end, we present two provable Least-Squares Value Iteration (LSVI) algorithms with runtime complexity sublinear in the number of actions for linear MDPs. We formulate the value function estimation procedure in VI as an approximate maximum inner product search problem and propose a Locality Sensitive Hashing (LSH) type data structure to solve this problem with sublinear time complexity. Our major contribution is combining the guarantees of approximate maximum inner product search with the regret analysis of reinforcement learning. We prove that, with the appropriate choice of approximation factor, there exists a sweet spot. Our proposed Sublinear LSVI algorithms maintain the same regret as the original LSVI algorithms while reducing the runtime complexity to sublinear in the number of actions. To the best of our knowledge, this is the first work that combines LSH with reinforcement learning that results in provable improvements. We hope that our novel way of combining data structures and the iterative algorithm will open the door for further study into the cost reduction in reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v206-xu23b,\n  title = \t {A Tale of Two Efficient Value Iteration Algorithms for Solving Linear MDPs with Large Action Space},\n  author =       {Xu, Zhaozhuo and Song, Zhao and Shrivastava, Anshumali},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {788--836},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23b/xu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23b.html},\n  abstract = \t {Markov Decision Process (MDP) with large action space naturally occurs in many applications such as language processing, information retrieval, and recommendation system. There have been various approaches to solve these MDPs through value iteration (VI). Unfortunately, all VI algorithms require expensive linear scans over the entire action space for value function estimation during each iteration. To this end, we present two provable Least-Squares Value Iteration (LSVI) algorithms with runtime complexity sublinear in the number of actions for linear MDPs. We formulate the value function estimation procedure in VI as an approximate maximum inner product search problem and propose a Locality Sensitive Hashing (LSH) type data structure to solve this problem with sublinear time complexity. Our major contribution is combining the guarantees of approximate maximum inner product search with the regret analysis of reinforcement learning. We prove that, with the appropriate choice of approximation factor, there exists a sweet spot. Our proposed Sublinear LSVI algorithms maintain the same regret as the original LSVI algorithms while reducing the runtime complexity to sublinear in the number of actions. To the best of our knowledge, this is the first work that combines LSH with reinforcement learning that results in provable improvements. We hope that our novel way of combining data structures and the iterative algorithm will open the door for further study into the cost reduction in reinforcement learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23b/xu23b.pdf",
        "supp": "",
        "pdf_size": 594652,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15785937115488003294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "aa5b53d4bc",
        "title": "A Targeted Accuracy Diagnostic for Variational Approximations",
        "site": "https://proceedings.mlr.press/v206/wang23l.html",
        "author": "Yu Wang; Mikolaj Kasprzak; Jonathan H. Huggins",
        "abstract": "Variational Inference (VI) is an attractive alternative to Markov Chain Monte Carlo (MCMC) due to its computational efficiency in the case of large datasets and/or complex models with high-dimensional parameters. However, evaluating the accuracy of variational approximations remains a challenge. Existing methods characterize the quality of the whole variational distribution, which is almost always poor in realistic applications, even if specific posterior functionals such as the component-wise means or variances are accurate. Hence, these diagnostics are of practical value only in limited circumstances. To address this issue, we propose the\u201cTArgeted Diagnostic for Distribution Approximation Accuracy\u201d (TADDAA), which uses many short parallel MCMC chains to obtain lower bounds on the error of each posterior functional of interest. We also develop a reliability check for TADDAA to determine when the lower bounds should not be trusted. Numerical experiments validate the practical utility and computational efficiency of our approach on a range of synthetic distributions and real-data examples, including sparse logistic regression and Bayesian neural network models.",
        "bibtex": "@InProceedings{pmlr-v206-wang23l,\n  title = \t {A Targeted Accuracy Diagnostic for Variational Approximations},\n  author =       {Wang, Yu and Kasprzak, Mikolaj and Huggins, Jonathan H.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8351--8372},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23l/wang23l.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23l.html},\n  abstract = \t {Variational Inference (VI) is an attractive alternative to Markov Chain Monte Carlo (MCMC) due to its computational efficiency in the case of large datasets and/or complex models with high-dimensional parameters. However, evaluating the accuracy of variational approximations remains a challenge. Existing methods characterize the quality of the whole variational distribution, which is almost always poor in realistic applications, even if specific posterior functionals such as the component-wise means or variances are accurate. Hence, these diagnostics are of practical value only in limited circumstances. To address this issue, we propose the\u201cTArgeted Diagnostic for Distribution Approximation Accuracy\u201d (TADDAA), which uses many short parallel MCMC chains to obtain lower bounds on the error of each posterior functional of interest. We also develop a reliability check for TADDAA to determine when the lower bounds should not be trusted. Numerical experiments validate the practical utility and computational efficiency of our approach on a range of synthetic distributions and real-data examples, including sparse logistic regression and Bayesian neural network models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23l/wang23l.pdf",
        "supp": "",
        "pdf_size": 1278544,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14074848916779921036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Boston University; MIT and University of Luxembourg; Boston University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Boston University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bu.edu;https://web.mit.edu",
        "aff_unique_abbr": "BU;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e70ebeea6d",
        "title": "A Tighter Problem-Dependent Regret Bound for Risk-Sensitive Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/hu23b.html",
        "author": "Xiaoyan Hu; Ho-Fung Leung",
        "abstract": "We study the regret for risk-sensitive reinforcement learning (RL) with the exponential utility in the episodic MDP. Recent works establish both a lower bound $\\Omega((e^{|\\beta|(H-1)/2}-1)\\sqrt{SAT}/|\\beta|)$ and the best known (upper) bound $\\tilde{O}((e^{|\\beta|H}-1)\\sqrt{H^2SAT}/|\\beta|)$, where $H$ is the length of the episode, $S$ the size of state space, $A$ the size of action space, $T$ the total number of timesteps, and $\\beta$ the risk parameter. The gap between the upper and the lower bound is exponential and hence is unsatisfactory. In this paper, we show that a variant of UCB-Advantage algorithm reduces a factor of $\\sqrt{H}$ from the best previously known bound in any arbitrary MDP. To further sharpen the regret bound, we introduce a brand new mechanism of regret analysis and derive a problem-dependent regret bound without prior knowledge of the MDP from the algorithm. This bound is much tighter in MDPs with special structures. Particularly, we show that a regret that matches the information-theoretic lower bound up to logarithmic factors can be attained within a rich class of MDPs, which improves an exponential factor over the best previously known bound. Further, we derive a novel information-theoretic lower bound of $\\Omega(\\max_{h\\in[H]} c_{v,h+1}^*\\sqrt{SAT}/|\\beta|)$, where $\\max_{h\\in[H]} c_{v,h+1}^*$ is a problem-dependent statistic. This lower bound shows that the problem-dependent regret bound achieved by the algorithm is optimal in its dependence on $\\max_{h\\in[H]} c_{v,h+1}^*$.",
        "bibtex": "@InProceedings{pmlr-v206-hu23b,\n  title = \t {A Tighter Problem-Dependent Regret Bound for Risk-Sensitive Reinforcement Learning},\n  author =       {Hu, Xiaoyan and Leung, Ho-Fung},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5411--5437},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hu23b/hu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hu23b.html},\n  abstract = \t {We study the regret for risk-sensitive reinforcement learning (RL) with the exponential utility in the episodic MDP. Recent works establish both a lower bound $\\Omega((e^{|\\beta|(H-1)/2}-1)\\sqrt{SAT}/|\\beta|)$ and the best known (upper) bound $\\tilde{O}((e^{|\\beta|H}-1)\\sqrt{H^2SAT}/|\\beta|)$, where $H$ is the length of the episode, $S$ the size of state space, $A$ the size of action space, $T$ the total number of timesteps, and $\\beta$ the risk parameter. The gap between the upper and the lower bound is exponential and hence is unsatisfactory. In this paper, we show that a variant of UCB-Advantage algorithm reduces a factor of $\\sqrt{H}$ from the best previously known bound in any arbitrary MDP. To further sharpen the regret bound, we introduce a brand new mechanism of regret analysis and derive a problem-dependent regret bound without prior knowledge of the MDP from the algorithm. This bound is much tighter in MDPs with special structures. Particularly, we show that a regret that matches the information-theoretic lower bound up to logarithmic factors can be attained within a rich class of MDPs, which improves an exponential factor over the best previously known bound. Further, we derive a novel information-theoretic lower bound of $\\Omega(\\max_{h\\in[H]} c_{v,h+1}^*\\sqrt{SAT}/|\\beta|)$, where $\\max_{h\\in[H]} c_{v,h+1}^*$ is a problem-dependent statistic. This lower bound shows that the problem-dependent regret bound achieved by the algorithm is optimal in its dependence on $\\max_{h\\in[H]} c_{v,h+1}^*$.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hu23b/hu23b.pdf",
        "supp": "",
        "pdf_size": 454089,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11808990285155421495&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "46f0f7b134",
        "title": "A Unified Perspective on Regularization and Perturbation in Differentiable Subset Selection",
        "site": "https://proceedings.mlr.press/v206/sun23e.html",
        "author": "Xiangqian Sun; Cheuk Hang Leung; Yijun Li; Qi Wu",
        "abstract": "Subset selection, i.e., finding a bunch of items from a collection to achieve specific goals, has wide applications in information retrieval, statistics, and machine learning. To implement an end-to-end learning framework, different relaxed differentiable operators of subset selection are proposed. Most existing work relies on either the regularization method or the perturbation method. In this work, we provide a probabilistic interpretation for regularization relaxation and unify two schemes. Besides, we build some concrete examples to show the generic connection between these two relaxations. Finally, we evaluate the perturbed selector as well as the regularized selector on two tasks: the maximum entropy sampling problem and the feature selection problem. The experimental results show that these two methods can achieve competitive performance against other benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-sun23e,\n  title = \t {A Unified Perspective on Regularization and Perturbation in Differentiable Subset Selection},\n  author =       {Sun, Xiangqian and Leung, Cheuk Hang and Li, Yijun and Wu, Qi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4629--4642},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sun23e/sun23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sun23e.html},\n  abstract = \t {Subset selection, i.e., finding a bunch of items from a collection to achieve specific goals, has wide applications in information retrieval, statistics, and machine learning. To implement an end-to-end learning framework, different relaxed differentiable operators of subset selection are proposed. Most existing work relies on either the regularization method or the perturbation method. In this work, we provide a probabilistic interpretation for regularization relaxation and unify two schemes. Besides, we build some concrete examples to show the generic connection between these two relaxations. Finally, we evaluate the perturbed selector as well as the regularized selector on two tasks: the maximum entropy sampling problem and the feature selection problem. The experimental results show that these two methods can achieve competitive performance against other benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sun23e/sun23e.pdf",
        "supp": "",
        "pdf_size": 3962094,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9870729728719720923&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f899f6d239",
        "title": "A Variance-Reduced and Stabilized Proximal Stochastic Gradient Method with Support Identification Guarantees for Structured Optimization",
        "site": "https://proceedings.mlr.press/v206/dai23a.html",
        "author": "Yutong Dai; Guanyi Wang; Frank E. Curtis; Daniel P. Robinson",
        "abstract": "This paper introduces a new proximal stochastic gradient method with variance reduction and stabilization for minimizing the sum of a convex stochastic function and a group sparsity-inducing regularization function. Since the method may be viewed as a stabilized version of the recently proposed algorithm PStorm, we call our algorithm S-PStorm. Our analysis shows that S-PStorm has strong convergence results. In particular, we prove an upper bound on the number of iterations required by S-PStorm before its iterates correctly identify (with high probability) an optimal support (i.e., the zero and nonzero structure of an optimal solution). Most algorithms in the literature with such a support identification property use variance reduction techniques that require either periodically evaluating an exact gradient or storing a history of stochastic gradients. Unlike these methods, S-PStorm achieves variance reduction without requiring either of these, which is advantageous. Moreover, our support-identification result for S-PStorm shows that, with high probability, an optimal support will be identified correctly in all iterations with index above a threshold. We believe that this type of result is new to the literature since the few existing other results prove that the optimal support is identified with high probability at each iteration with a sufficiently large index (meaning that the optimal support might be identified in some iterations, but not in others). Numerical experiments on regularized logistic loss problems show that S-PStorm outperforms existing methods in various metrics that measure how efficiently and robustly iterates of an algorithm identify an optimal support.",
        "bibtex": "@InProceedings{pmlr-v206-dai23a,\n  title = \t {A Variance-Reduced and Stabilized Proximal Stochastic Gradient Method with Support Identification Guarantees for Structured Optimization},\n  author =       {Dai, Yutong and Wang, Guanyi and Curtis, Frank E. and Robinson, Daniel P.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5107--5133},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dai23a/dai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dai23a.html},\n  abstract = \t {This paper introduces a new proximal stochastic gradient method with variance reduction and stabilization for minimizing the sum of a convex stochastic function and a group sparsity-inducing regularization function. Since the method may be viewed as a stabilized version of the recently proposed algorithm PStorm, we call our algorithm S-PStorm. Our analysis shows that S-PStorm has strong convergence results. In particular, we prove an upper bound on the number of iterations required by S-PStorm before its iterates correctly identify (with high probability) an optimal support (i.e., the zero and nonzero structure of an optimal solution). Most algorithms in the literature with such a support identification property use variance reduction techniques that require either periodically evaluating an exact gradient or storing a history of stochastic gradients. Unlike these methods, S-PStorm achieves variance reduction without requiring either of these, which is advantageous. Moreover, our support-identification result for S-PStorm shows that, with high probability, an optimal support will be identified correctly in all iterations with index above a threshold. We believe that this type of result is new to the literature since the few existing other results prove that the optimal support is identified with high probability at each iteration with a sufficiently large index (meaning that the optimal support might be identified in some iterations, but not in others). Numerical experiments on regularized logistic loss problems show that S-PStorm outperforms existing methods in various metrics that measure how efficiently and robustly iterates of an algorithm identify an optimal support.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dai23a/dai23a.pdf",
        "supp": "",
        "pdf_size": 894243,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12778235155828497781&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "be0f9d7b9f",
        "title": "A principled framework for the design and analysis of token algorithms",
        "site": "https://proceedings.mlr.press/v206/hendrikx23a.html",
        "author": "Hadrien Hendrikx",
        "abstract": "We consider a decentralized optimization problem, in which n nodes collaborate to optimize a global objective function using local communications only. While many decentralized algorithms focus on gossip communications (pairwise averaging), we consider a different scheme, in which a \u201ctoken\u201d that contains the current estimate of the model performs a random walk over the network, and updates its model using the local model of the node it is at. Indeed, token algorithms generally benefit from improved communication efficiency and privacy guarantees. We frame the token algorithm as a randomized gossip algorithm on a conceptual graph, which allows us to prove a series of convergence results for variance-reduced and accelerated token algorithms for the complete graph. We also extend these results to the case of multiple tokens by extending the conceptual graph, and to general graphs by tweaking the communication procedure. The reduction from token to well-studied gossip algorithms leads to tight rates for many token algorithms, and we illustrate their performance empirically.",
        "bibtex": "@InProceedings{pmlr-v206-hendrikx23a,\n  title = \t {A principled framework for the design and analysis of token algorithms},\n  author =       {Hendrikx, Hadrien},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {470--489},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hendrikx23a/hendrikx23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hendrikx23a.html},\n  abstract = \t {We consider a decentralized optimization problem, in which n nodes collaborate to optimize a global objective function using local communications only. While many decentralized algorithms focus on gossip communications (pairwise averaging), we consider a different scheme, in which a \u201ctoken\u201d that contains the current estimate of the model performs a random walk over the network, and updates its model using the local model of the node it is at. Indeed, token algorithms generally benefit from improved communication efficiency and privacy guarantees. We frame the token algorithm as a randomized gossip algorithm on a conceptual graph, which allows us to prove a series of convergence results for variance-reduced and accelerated token algorithms for the complete graph. We also extend these results to the case of multiple tokens by extending the conceptual graph, and to general graphs by tweaking the communication procedure. The reduction from token to well-studied gossip algorithms leads to tight rates for many token algorithms, and we illustrate their performance empirically.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hendrikx23a/hendrikx23a.pdf",
        "supp": "",
        "pdf_size": 686621,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=716452612511274834&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Universite Grenoble Alpes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Grenoble",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "0fbb8f1e97",
        "title": "A stopping criterion for Bayesian optimization by the gap of expected minimum simple regrets",
        "site": "https://proceedings.mlr.press/v206/ishibashi23a.html",
        "author": "Hideaki Ishibashi; Masayuki Karasuyama; Ichiro Takeuchi; Hideitsu Hino",
        "abstract": "Bayesian optimization (BO) improves the efficiency of black-box optimization; however, the associated computational cost and power consumption remain dominant in the application of machine learning methods. This paper proposes a method of determining the stopping time in BO. The proposed criterion is based on the difference between the expectation of the minimum of a variant of the simple regrets before and after evaluating the objective function with a new parameter setting. Unlike existing stopping criteria, the proposed criterion is guaranteed to converge to the theoretically optimal stopping criterion for any choices of arbitrary acquisition functions and threshold values. Moreover, the threshold for the stopping criterion can be determined automatically and adaptively. We experimentally demonstrate that the proposed stopping criterion finds reasonable timing to stop a BO with a small number of evaluations of the objective function.",
        "bibtex": "@InProceedings{pmlr-v206-ishibashi23a,\n  title = \t {A stopping criterion for Bayesian optimization by the gap of expected minimum simple regrets},\n  author =       {Ishibashi, Hideaki and Karasuyama, Masayuki and Takeuchi, Ichiro and Hino, Hideitsu},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6463--6497},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ishibashi23a/ishibashi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ishibashi23a.html},\n  abstract = \t {Bayesian optimization (BO) improves the efficiency of black-box optimization; however, the associated computational cost and power consumption remain dominant in the application of machine learning methods. This paper proposes a method of determining the stopping time in BO. The proposed criterion is based on the difference between the expectation of the minimum of a variant of the simple regrets before and after evaluating the objective function with a new parameter setting. Unlike existing stopping criteria, the proposed criterion is guaranteed to converge to the theoretically optimal stopping criterion for any choices of arbitrary acquisition functions and threshold values. Moreover, the threshold for the stopping criterion can be determined automatically and adaptively. We experimentally demonstrate that the proposed stopping criterion finds reasonable timing to stop a BO with a small number of evaluations of the objective function.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ishibashi23a/ishibashi23a.pdf",
        "supp": "",
        "pdf_size": 19981588,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2253978079951391035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4f3d3fd6f3",
        "title": "ANACONDA: An Improved Dynamic Regret Algorithm for Adaptive Non-Stationary Dueling Bandits",
        "site": "https://proceedings.mlr.press/v206/kleine-buening23a.html",
        "author": "Thomas Kleine Buening; Aadirupa Saha",
        "abstract": "We study the problem of non-stationary dueling bandits and provide the first adaptive dynamic regret algorithm for this problem. The only two existing attempts in this line of work fall short across multiple dimensions, including pessimistic measures of non-stationary complexity and non-adaptive parameter tuning that requires knowledge of the number of preference changes. We develop an elimination-based rescheduling algorithm to overcome these shortcomings and show a near-optimal $\\tilde O(\\sqrt{S^{CW} T})$ dynamic regret bound, where $\\S^{CW}$ is the number of times the Condorcet winner changes in $T$ rounds. This yields the first near-optimal dynamic regret bound for unknown $S^{CW}$. We further study other related notions of non-stationarity for which we also prove near-optimal dynamic regret guarantees under additional assumptions on the preference model.",
        "bibtex": "@InProceedings{pmlr-v206-kleine-buening23a,\n  title = \t {ANACONDA: An Improved Dynamic Regret Algorithm for Adaptive Non-Stationary Dueling Bandits},\n  author =       {Kleine Buening, Thomas and Saha, Aadirupa},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3854--3878},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kleine-buening23a/kleine-buening23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kleine-buening23a.html},\n  abstract = \t {We study the problem of non-stationary dueling bandits and provide the first adaptive dynamic regret algorithm for this problem. The only two existing attempts in this line of work fall short across multiple dimensions, including pessimistic measures of non-stationary complexity and non-adaptive parameter tuning that requires knowledge of the number of preference changes. We develop an elimination-based rescheduling algorithm to overcome these shortcomings and show a near-optimal $\\tilde O(\\sqrt{S^{CW} T})$ dynamic regret bound, where $\\S^{CW}$ is the number of times the Condorcet winner changes in $T$ rounds. This yields the first near-optimal dynamic regret bound for unknown $S^{CW}$. We further study other related notions of non-stationarity for which we also prove near-optimal dynamic regret guarantees under additional assumptions on the preference model.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kleine-buening23a/kleine-buening23a.pdf",
        "supp": "",
        "pdf_size": 460749,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1661880708331436558&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "University of Oslo; TTI Chicago + Apple ML Research, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "University of Oslo;Toyota Technological Institute at Chicago;Apple",
        "aff_unique_dep": ";;Apple ML Research",
        "aff_unique_url": "https://www.uio.no;https://www.tti-chicago.org;https://www.apple.com",
        "aff_unique_abbr": "UiO;TTI;Apple",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Chicago",
        "aff_country_unique_index": "0;1+1",
        "aff_country_unique": "Norway;United States"
    },
    {
        "id": "fd71e6bf1c",
        "title": "ASkewSGD : An Annealed interval-constrained Optimisation method to train Quantized Neural Networks",
        "site": "https://proceedings.mlr.press/v206/leconte23a.html",
        "author": "Louis Leconte; Sholom Schechtman; Eric Moulines",
        "abstract": "In this paper, we develop a new algorithm, Annealed Skewed SGD - AskewSGD - for training deep neural networks (DNNs) with quantized weights. First, we formulate the training of quantized neural networks (QNNs) as a smoothed sequence of interval-constrained optimization problems. Then, we propose a new first-order stochastic method, AskewSGD, to solve each constrained optimization subproblem. Unlike algorithms with active sets and feasible directions, AskewSGD avoids projections or optimization under the entire feasible set and allows iterates that are infeasible. The numerical complexity of AskewSGD is comparable to existing approaches for training QNNs, such as the straight-through gradient estimator used in BinaryConnect, or other state of the art methods (ProxQuant, LUQ). We establish convergence guarantees for AskewSGD (under general assumptions for the objective function). Experimental results show that the AskewSGD algorithm performs better than or on par with state of the art methods in classical benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-leconte23a,\n  title = \t {ASkewSGD : An Annealed interval-constrained Optimisation method to train Quantized Neural Networks},\n  author =       {Leconte, Louis and Schechtman, Sholom and Moulines, Eric},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3644--3663},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/leconte23a/leconte23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/leconte23a.html},\n  abstract = \t {In this paper, we develop a new algorithm, Annealed Skewed SGD - AskewSGD - for training deep neural networks (DNNs) with quantized weights. First, we formulate the training of quantized neural networks (QNNs) as a smoothed sequence of interval-constrained optimization problems. Then, we propose a new first-order stochastic method, AskewSGD, to solve each constrained optimization subproblem. Unlike algorithms with active sets and feasible directions, AskewSGD avoids projections or optimization under the entire feasible set and allows iterates that are infeasible. The numerical complexity of AskewSGD is comparable to existing approaches for training QNNs, such as the straight-through gradient estimator used in BinaryConnect, or other state of the art methods (ProxQuant, LUQ). We establish convergence guarantees for AskewSGD (under general assumptions for the objective function). Experimental results show that the AskewSGD algorithm performs better than or on par with state of the art methods in classical benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/leconte23a/leconte23a.pdf",
        "supp": "",
        "pdf_size": 1966093,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11259896280338114093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "415f2e9274",
        "title": "AUC-based Selective Classification",
        "site": "https://proceedings.mlr.press/v206/pugnana23a.html",
        "author": "Andrea Pugnana; Salvatore Ruggieri",
        "abstract": "Selective classification (or classification with a reject option) pairs a classifier with a selection function to determine whether or not a prediction should be accepted. This framework trades off coverage (probability of accepting a prediction) with predictive performance, typically measured by distributive loss functions. In many application scenarios, such as credit scoring, performance is instead measured by ranking metrics, such as the Area Under the ROC Curve (AUC). We propose a model-agnostic approach to associate a selection function to a given probabilistic binary classifier. The approach is specifically targeted at optimizing the AUC. We provide both theoretical justifications and a novel algorithm, called AUCROSS, to achieve such a goal. Experiments show that our method succeeds in trading-off coverage for AUC, improving over existing selective classification methods targeted at optimizing accuracy.",
        "bibtex": "@InProceedings{pmlr-v206-pugnana23a,\n  title = \t {AUC-based Selective Classification},\n  author =       {Pugnana, Andrea and Ruggieri, Salvatore},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2494--2514},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/pugnana23a/pugnana23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/pugnana23a.html},\n  abstract = \t {Selective classification (or classification with a reject option) pairs a classifier with a selection function to determine whether or not a prediction should be accepted. This framework trades off coverage (probability of accepting a prediction) with predictive performance, typically measured by distributive loss functions. In many application scenarios, such as credit scoring, performance is instead measured by ranking metrics, such as the Area Under the ROC Curve (AUC). We propose a model-agnostic approach to associate a selection function to a given probabilistic binary classifier. The approach is specifically targeted at optimizing the AUC. We provide both theoretical justifications and a novel algorithm, called AUCROSS, to achieve such a goal. Experiments show that our method succeeds in trading-off coverage for AUC, improving over existing selective classification methods targeted at optimizing accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/pugnana23a/pugnana23a.pdf",
        "supp": "",
        "pdf_size": 2206378,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1079806174140377497&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Scuola Normale Superiore; University of Pisa",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Scuola Normale Superiore;University of Pisa",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sns.it;https://www.unipi.it",
        "aff_unique_abbr": "SNS;UNIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "02f558c4cc",
        "title": "Acceleration of Frank-Wolfe Algorithms with Open-Loop Step-Sizes",
        "site": "https://proceedings.mlr.press/v206/wirth23a.html",
        "author": "Elias Wirth; Thomas Kerdreux; Sebastian Pokutta",
        "abstract": "Frank-Wolfe algorithms (FW) are popular first-order methods for solving constrained convex optimization problems that rely on a linear minimization oracle instead of potentially expensive projection-like oracles. Many works have identified accelerated convergence rates under various structural assumptions on the optimization problem and for specific FW variants when using line-search or short-step, requiring feedback from the objective function. Little is known about accelerated convergence regimes when utilizing open-loop step-size rules, a.k.a. FW with pre-determined step-sizes, which are algorithmically extremely simple and stable. Not only is FW with open-loop step-size rules not always subject to the same convergence rate lower bounds as FW with line-search or short-step, but in some specific cases, such as kernel herding in infinite dimensions, it has been empirically observed that FW with open-loop step-size rules leads to faster convergence than FW with line-search or short-step. We propose a partial answer to this unexplained phenomenon in kernel herding, characterize a general setting for which FW with open-loop step-size rules converges non-asymptotically faster than with line-search or short-step, and derive several accelerated convergence results for FW with open-loop step-size rules.",
        "bibtex": "@InProceedings{pmlr-v206-wirth23a,\n  title = \t {Acceleration of Frank-Wolfe Algorithms with Open-Loop Step-Sizes},\n  author =       {Wirth, Elias and Kerdreux, Thomas and Pokutta, Sebastian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {77--100},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wirth23a/wirth23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wirth23a.html},\n  abstract = \t {Frank-Wolfe algorithms (FW) are popular first-order methods for solving constrained convex optimization problems that rely on a linear minimization oracle instead of potentially expensive projection-like oracles. Many works have identified accelerated convergence rates under various structural assumptions on the optimization problem and for specific FW variants when using line-search or short-step, requiring feedback from the objective function. Little is known about accelerated convergence regimes when utilizing open-loop step-size rules, a.k.a. FW with pre-determined step-sizes, which are algorithmically extremely simple and stable. Not only is FW with open-loop step-size rules not always subject to the same convergence rate lower bounds as FW with line-search or short-step, but in some specific cases, such as kernel herding in infinite dimensions, it has been empirically observed that FW with open-loop step-size rules leads to faster convergence than FW with line-search or short-step. We propose a partial answer to this unexplained phenomenon in kernel herding, characterize a general setting for which FW with open-loop step-size rules converges non-asymptotically faster than with line-search or short-step, and derive several accelerated convergence results for FW with open-loop step-size rules.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wirth23a/wirth23a.pdf",
        "supp": "",
        "pdf_size": 1139921,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12386746797490941180&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Berlin Institute of Technology; Geolabe LLC + Berlin Institute of Technology & Zuse Institute Berlin; Berlin Institute of Technology & Zuse Institute Berlin",
        "aff_domain": "math.tu-berlin.de;gmail.com;zib.de",
        "email": "math.tu-berlin.de;gmail.com;zib.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "Berlin Institute of Technology;Geolabe LLC",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tu-berlin.de;",
        "aff_unique_abbr": "TU Berlin;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "1fa6ee2a1f",
        "title": "Active Cost-aware Labeling of Streaming Data",
        "site": "https://proceedings.mlr.press/v206/cai23a.html",
        "author": "Ting Cai; Kirthevasan Kandasamy",
        "abstract": "We study actively labeling streaming data, where an active learner is faced with a stream of data points and must carefully choose which of these points to label via an expensive experiment. Such problems frequently arise in applications such as healthcare and astronomy. We first study a setting when the data\u2019s inputs belong to one of K discrete distributions and formalize this problem via a loss that captures the labeling cost and the prediction error. When the labeling cost is B, our algorithm, which chooses to label a point if the uncertainty is larger than a time and cost dependent threshold, achieves a worst-case upper bound of $\\tilde O(B^{\\frac{1}{3}} K^{\\frac{1}{3}} T^{\\frac{2}{3}})$ on the loss after T rounds. We also provide a more nuanced upper bound which demonstrates that the algorithm can adapt to the arrival pattern, and achieves better performance when the arrival pattern is more favorable. We complement both upper bounds with matching lower bounds. We next study this problem when the inputs belong to a continuous domain and the output of the experiment is a smooth function with bounded RKHS norm. After T rounds in d dimensions, we show that the loss is bounded by $\\tilde O(B^{\\frac{1}{d+3}} T^{\\frac{d+2}{d+3}})$ in an RKHS with a squared exponential kernel and by $\\tilde O(B^{\\frac{1}{2d+3}} T^{\\frac{2d+2}{2d+3}})$ in an RKHS with a Mat\u00e9rn kernel. Our empirical evaluation demonstrates that our method outperforms other baselines in several synthetic experiments and two real experiments in medicine and astronomy.",
        "bibtex": "@InProceedings{pmlr-v206-cai23a,\n  title = \t {Active Cost-aware Labeling of Streaming Data},\n  author =       {Cai, Ting and Kandasamy, Kirthevasan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9117--9136},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cai23a/cai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cai23a.html},\n  abstract = \t {We study actively labeling streaming data, where an active learner is faced with a stream of data points and must carefully choose which of these points to label via an expensive experiment. Such problems frequently arise in applications such as healthcare and astronomy. We first study a setting when the data\u2019s inputs belong to one of K discrete distributions and formalize this problem via a loss that captures the labeling cost and the prediction error. When the labeling cost is B, our algorithm, which chooses to label a point if the uncertainty is larger than a time and cost dependent threshold, achieves a worst-case upper bound of $\\tilde O(B^{\\frac{1}{3}} K^{\\frac{1}{3}} T^{\\frac{2}{3}})$ on the loss after T rounds. We also provide a more nuanced upper bound which demonstrates that the algorithm can adapt to the arrival pattern, and achieves better performance when the arrival pattern is more favorable. We complement both upper bounds with matching lower bounds. We next study this problem when the inputs belong to a continuous domain and the output of the experiment is a smooth function with bounded RKHS norm. After T rounds in d dimensions, we show that the loss is bounded by $\\tilde O(B^{\\frac{1}{d+3}} T^{\\frac{d+2}{d+3}})$ in an RKHS with a squared exponential kernel and by $\\tilde O(B^{\\frac{1}{2d+3}} T^{\\frac{2d+2}{2d+3}})$ in an RKHS with a Mat\u00e9rn kernel. Our empirical evaluation demonstrates that our method outperforms other baselines in several synthetic experiments and two real experiments in medicine and astronomy.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cai23a/cai23a.pdf",
        "supp": "",
        "pdf_size": 5335428,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13647635847511482828&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6a06e72252",
        "title": "Active Exploration via Experiment Design in Markov Chains",
        "site": "https://proceedings.mlr.press/v206/mutny23a.html",
        "author": "Mojmir Mutny; Tadeusz Janik; Andreas Krause",
        "abstract": "A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Classical experimental design optimally allocates the experimental budget into measurements to maximize a notion of utility (e.g., reduction in uncertainty about the unknown quantity). We consider a rich setting, where the experiments are associated with states in a Markov chain, and we can only choose them by selecting a policy controlling the state transitions. This problem captures important applications, from exploration in reinforcement learning to spatial monitoring tasks. We propose an algorithm \u2013 markov-design \u2013 that efficiently selects policies whose measurement allocation provably converges to the optimal one. The algorithm is sequential in nature, adapting its choice of policies (experiments) using past measurements. In addition to our theoretical analysis, we demonstrate our framework on applications in ecological surveillance and pharmacology.",
        "bibtex": "@InProceedings{pmlr-v206-mutny23a,\n  title = \t {Active Exploration via Experiment Design in Markov Chains},\n  author =       {Mutny, Mojmir and Janik, Tadeusz and Krause, Andreas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7349--7374},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mutny23a/mutny23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mutny23a.html},\n  abstract = \t {A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Classical experimental design optimally allocates the experimental budget into measurements to maximize a notion of utility (e.g., reduction in uncertainty about the unknown quantity). We consider a rich setting, where the experiments are associated with states in a Markov chain, and we can only choose them by selecting a policy controlling the state transitions. This problem captures important applications, from exploration in reinforcement learning to spatial monitoring tasks. We propose an algorithm \u2013 markov-design \u2013 that efficiently selects policies whose measurement allocation provably converges to the optimal one. The algorithm is sequential in nature, adapting its choice of policies (experiments) using past measurements. In addition to our theoretical analysis, we demonstrate our framework on applications in ecological surveillance and pharmacology.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mutny23a/mutny23a.pdf",
        "supp": "",
        "pdf_size": 1723473,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3275116022970342625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich; ETH Z\u00fcrich",
        "aff_domain": "inf.ethz.ch;student.ethz.ch;ethz.ch",
        "email": "inf.ethz.ch;student.ethz.ch;ethz.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "e6b376200c",
        "title": "Active Learning for Single Neuron Models with Lipschitz Non-Linearities",
        "site": "https://proceedings.mlr.press/v206/gajjar23a.html",
        "author": "Aarshvi Gajjar; Christopher Musco; Chinmay Hegde",
        "abstract": "We consider the problem of active learning for single neuron models, also sometimes called \u201cridge functions\u201d, in the agnostic setting (under adversarial label noise). Such models have been shown to be broadly effective in modeling physical phenomena, and for constructing surrogate data-driven models for partial differential equations. Surprisingly, we show that for a single neuron model with any Lipschitz non-linearity (such as the ReLU, sigmoid, absolute value, low-degree polynomial, among others), strong provable approximation guarantees can be obtained using a well-known active learning strategy for fitting linear functions in the agnostic setting. Namely, we can collect samples via statistical leverage score sampling, which has been shown to be nearoptimal in other active learning scenarios. We support our theoretical results with empirical simulations showing that our proposed active learning strategy based on leverage score sampling outperforms (ordinary) uniform sampling when fitting single neuron models.",
        "bibtex": "@InProceedings{pmlr-v206-gajjar23a,\n  title = \t {Active Learning for Single Neuron Models with Lipschitz Non-Linearities},\n  author =       {Gajjar, Aarshvi and Musco, Christopher and Hegde, Chinmay},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4101--4113},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gajjar23a/gajjar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gajjar23a.html},\n  abstract = \t {We consider the problem of active learning for single neuron models, also sometimes called \u201cridge functions\u201d, in the agnostic setting (under adversarial label noise). Such models have been shown to be broadly effective in modeling physical phenomena, and for constructing surrogate data-driven models for partial differential equations. Surprisingly, we show that for a single neuron model with any Lipschitz non-linearity (such as the ReLU, sigmoid, absolute value, low-degree polynomial, among others), strong provable approximation guarantees can be obtained using a well-known active learning strategy for fitting linear functions in the agnostic setting. Namely, we can collect samples via statistical leverage score sampling, which has been shown to be nearoptimal in other active learning scenarios. We support our theoretical results with empirical simulations showing that our proposed active learning strategy based on leverage score sampling outperforms (ordinary) uniform sampling when fitting single neuron models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gajjar23a/gajjar23a.pdf",
        "supp": "",
        "pdf_size": 4133852,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2836566903736750812&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ca364dad5c",
        "title": "Active Membership Inference Attack under Local Differential Privacy in Federated Learning",
        "site": "https://proceedings.mlr.press/v206/nguyen23e.html",
        "author": "Truc Nguyen; Phung Lai; Khang Tran; NhatHai Phan; My T. Thai",
        "abstract": "Federated learning (FL) was originally regarded as a framework for collaborative learning among clients with data privacy protection through a coordinating server. In this paper, we propose a new active membership inference (AMI) attack carried out by a dishonest server in FL. In AMI attacks, the server crafts and embeds malicious parameters into global models to effectively infer whether a target data sample is included in a client\u2019s private training data or not. By exploiting the correlation among data features through a non-linear decision boundary, AMI attacks with a certified guarantee of success can achieve severely high success rates under rigorous local differential privacy (LDP) protection; thereby exposing clients\u2019 training data to significant privacy risk. Theoretical and experimental results on several benchmark datasets show that adding sufficient privacy-preserving noise to prevent our attack would significantly damage FL\u2019s model utility.",
        "bibtex": "@InProceedings{pmlr-v206-nguyen23e,\n  title = \t {Active Membership Inference Attack under Local Differential Privacy in Federated Learning},\n  author =       {Nguyen, Truc and Lai, Phung and Tran, Khang and Phan, NhatHai and Thai, My T.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5714--5730},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nguyen23e/nguyen23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nguyen23e.html},\n  abstract = \t {Federated learning (FL) was originally regarded as a framework for collaborative learning among clients with data privacy protection through a coordinating server. In this paper, we propose a new active membership inference (AMI) attack carried out by a dishonest server in FL. In AMI attacks, the server crafts and embeds malicious parameters into global models to effectively infer whether a target data sample is included in a client\u2019s private training data or not. By exploiting the correlation among data features through a non-linear decision boundary, AMI attacks with a certified guarantee of success can achieve severely high success rates under rigorous local differential privacy (LDP) protection; thereby exposing clients\u2019 training data to significant privacy risk. Theoretical and experimental results on several benchmark datasets show that adding sufficient privacy-preserving noise to prevent our attack would significantly damage FL\u2019s model utility.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nguyen23e/nguyen23e.pdf",
        "supp": "",
        "pdf_size": 9388135,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8123182677536899379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of Florida; New Jersey Institute of Technology; New Jersey Institute of Technology; New Jersey Institute of Technology + University of Florida; New Jersey Institute of Technology + University of Florida",
        "aff_domain": "ufl.edu;njit.edu;njit.edu;njit.edu;cise.ufl.edu",
        "email": "ufl.edu;njit.edu;njit.edu;njit.edu;cise.ufl.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1+0;1+0",
        "aff_unique_norm": "University of Florida;New Jersey Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ufl.edu;https://www.njit.edu",
        "aff_unique_abbr": "UF;NJIT",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e599ba1988",
        "title": "Actually Sparse Variational Gaussian Processes",
        "site": "https://proceedings.mlr.press/v206/cunningham23a.html",
        "author": "Harry Jake Cunningham; Daniel Augusto de Souza; So Takao; Mark van der Wilk; Marc Peter Deisenroth",
        "abstract": "Gaussian processes (GPs) are typically criticised for their unfavourable scaling in both computational and memory requirements. For large datasets, sparse GPs reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. In practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse GPs can become computationally expensive, limited by the number of inducing variables one can use. In this work, we propose a new class of inter-domain variational GP, constructed by projecting a GP onto a set of compactly supported B-spline basis functions. The key benefit of our approach is that the compact support of the B-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. This allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previous approaches failed.",
        "bibtex": "@InProceedings{pmlr-v206-cunningham23a,\n  title = \t {Actually Sparse Variational Gaussian Processes},\n  author =       {Cunningham, Harry Jake and de Souza, Daniel Augusto and Takao, So and van der Wilk, Mark and Deisenroth, Marc Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10395--10408},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cunningham23a/cunningham23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cunningham23a.html},\n  abstract = \t {Gaussian processes (GPs) are typically criticised for their unfavourable scaling in both computational and memory requirements. For large datasets, sparse GPs reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. In practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse GPs can become computationally expensive, limited by the number of inducing variables one can use. In this work, we propose a new class of inter-domain variational GP, constructed by projecting a GP onto a set of compactly supported B-spline basis functions. The key benefit of our approach is that the compact support of the B-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. This allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previous approaches failed.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cunningham23a/cunningham23a.pdf",
        "supp": "",
        "pdf_size": 2774789,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2871816782952466808&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University College London; University College London; University College London; Imperial College London; University College London",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University College London;Imperial College London",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "UCL;ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "c79cf32301",
        "title": "AdaGDA: Faster Adaptive Gradient Descent Ascent Methods for Minimax Optimization",
        "site": "https://proceedings.mlr.press/v206/huang23a.html",
        "author": "Feihu Huang; Xidong Wu; Zhengmian Hu",
        "abstract": "In the paper, we propose a class of faster adaptive Gradient Descent Ascent (GDA) methods for solving the nonconvex-strongly-concave minimax problems by using the unified adaptive matrices, which include almost all existing coordinate-wise and global adaptive learning rates. In particular, we provide an effective convergence analysis framework for our adaptive GDA methods. Specifically, we propose a fast Adaptive Gradient Descent Ascent (AdaGDA) method based on the basic momentum technique, which reaches a lower gradient complexity of $\\tilde{O}(\\kappa^4\\epsilon^{-4})$ for finding an $\\epsilon$-stationary point without large batches, which improves the existing results of the adaptive GDA methods by a factor of $O(\\sqrt{\\kappa})$. Moreover, we propose an accelerated version of AdaGDA (VR-AdaGDA) method based on the momentum-based variance reduced technique, which achieves a lower gradient complexity of $\\tilde{O}(\\kappa^{4.5}\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point without large batches, which improves the existing results of the adaptive GDA methods by a factor of $O(\\epsilon^{-1})$. Moreover, we prove that our VR-AdaGDA method can reach the best known gradient complexity of $\\tilde{O}(\\kappa^{3}\\epsilon^{-3})$ with the mini-batch size $O(\\kappa^3)$. The experiments on policy evaluation and fair classifier learning tasks are conducted to verify the efficiency of our new algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-huang23a,\n  title = \t {AdaGDA: Faster Adaptive Gradient Descent Ascent Methods for Minimax Optimization},\n  author =       {Huang, Feihu and Wu, Xidong and Hu, Zhengmian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2365--2389},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/huang23a/huang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/huang23a.html},\n  abstract = \t {In the paper, we propose a class of faster adaptive Gradient Descent Ascent (GDA) methods for solving the nonconvex-strongly-concave minimax problems by using the unified adaptive matrices, which include almost all existing coordinate-wise and global adaptive learning rates. In particular, we provide an effective convergence analysis framework for our adaptive GDA methods. Specifically, we propose a fast Adaptive Gradient Descent Ascent (AdaGDA) method based on the basic momentum technique, which reaches a lower gradient complexity of $\\tilde{O}(\\kappa^4\\epsilon^{-4})$ for finding an $\\epsilon$-stationary point without large batches, which improves the existing results of the adaptive GDA methods by a factor of $O(\\sqrt{\\kappa})$. Moreover, we propose an accelerated version of AdaGDA (VR-AdaGDA) method based on the momentum-based variance reduced technique, which achieves a lower gradient complexity of $\\tilde{O}(\\kappa^{4.5}\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point without large batches, which improves the existing results of the adaptive GDA methods by a factor of $O(\\epsilon^{-1})$. Moreover, we prove that our VR-AdaGDA method can reach the best known gradient complexity of $\\tilde{O}(\\kappa^{3}\\epsilon^{-3})$ with the mini-batch size $O(\\kappa^3)$. The experiments on policy evaluation and fair classifier learning tasks are conducted to verify the efficiency of our new algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/huang23a/huang23a.pdf",
        "supp": "",
        "pdf_size": 1096279,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10727171850290542166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China + MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, China; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, USA; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, USA",
        "aff_domain": "gmail.com; ; ",
        "email": "gmail.com; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;2",
        "aff_unique_norm": "Nanjing University of Aeronautics and Astronautics;MIIT;University of Pittsburgh",
        "aff_unique_dep": "College of Computer Science and Technology;Key Laboratory of Pattern Analysis and Machine Intelligence;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.nuaa.edu.cn;;https://www.pitt.edu",
        "aff_unique_abbr": "NUAA;MIIT;Pitt",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "Nanjing;;Pittsburgh",
        "aff_country_unique_index": "0+0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "4bcf2fdd00",
        "title": "Adaptation to Misspecified Kernel Regularity in Kernelised Bandits",
        "site": "https://proceedings.mlr.press/v206/liu23c.html",
        "author": "Yusha Liu; Aarti Singh",
        "abstract": "In continuum-armed bandit problems where the underlying function resides in a reproducing kernel Hilbert space (RKHS), namely, the kernelised bandit problems, an important open problem remains of how well learning algorithms can adapt if the regularity of the associated kernel function is unknown. In this work, we study adaptivity to the regularity of translation-invariant kernels, which is characterized by the decay rate of the Fourier transformation of the kernel, in the bandit setting. We derive an adaptivity lower bound, proving that it is impossible to simultaneously achieve optimal cumulative regret in a pair of RKHSs with different regularities. To verify the tightness of this lower bound, we show that an existing bandit model selection algorithm applied with minimax non-adaptive kernelised bandit algorithms matches the lower bound in dependence of T, the total number of steps, except for log factors. By filling in the regret bounds for adaptivity between RKHSs, we connect the statistical difficulty for adaptivity in continuum-armed bandits in three fundamental types of function spaces: RKHS, Sobolev space, and Holder space.",
        "bibtex": "@InProceedings{pmlr-v206-liu23c,\n  title = \t {Adaptation to Misspecified Kernel Regularity in Kernelised Bandits},\n  author =       {Liu, Yusha and Singh, Aarti},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4963--4985},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23c/liu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23c.html},\n  abstract = \t {In continuum-armed bandit problems where the underlying function resides in a reproducing kernel Hilbert space (RKHS), namely, the kernelised bandit problems, an important open problem remains of how well learning algorithms can adapt if the regularity of the associated kernel function is unknown. In this work, we study adaptivity to the regularity of translation-invariant kernels, which is characterized by the decay rate of the Fourier transformation of the kernel, in the bandit setting. We derive an adaptivity lower bound, proving that it is impossible to simultaneously achieve optimal cumulative regret in a pair of RKHSs with different regularities. To verify the tightness of this lower bound, we show that an existing bandit model selection algorithm applied with minimax non-adaptive kernelised bandit algorithms matches the lower bound in dependence of T, the total number of steps, except for log factors. By filling in the regret bounds for adaptivity between RKHSs, we connect the statistical difficulty for adaptivity in continuum-armed bandits in three fundamental types of function spaces: RKHS, Sobolev space, and Holder space.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23c/liu23c.pdf",
        "supp": "",
        "pdf_size": 423995,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1307559249885813858&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "728bb6a463",
        "title": "Adapting to Latent Subgroup Shifts via Concepts and Proxies",
        "site": "https://proceedings.mlr.press/v206/alabdulmohsin23a.html",
        "author": "Ibrahim Alabdulmohsin; Nicole Chiou; Alexander D\u2019Amour; Arthur Gretton; Sanmi Koyejo; Matt J. Kusner; Stephen R. Pfohl; Olawale Salaudeen; Jessica Schrouff; Katherine Tsai",
        "abstract": "We address the problem of unsupervised domain adaptation when the source domain differs from the target domain because of a shift in the distribution of a latent subgroup. When this subgroup confounds all observed data, neither covariate shift nor label shift assumptions apply. We show that the optimal target predictor can be non-parametrically identified with the help of concept and proxy variables available only in the source domain, and unlabeled data from the target. The identification results are constructive, immediately suggesting an algorithm for estimating the optimal predictor in the target. For continuous observations, when this algorithm becomes impractical, we propose a latent variable model specific to the data generation process at hand. We show how the approach degrades as the size of the shift changes, and verify that it outperforms both covariate and label shift adjustment.",
        "bibtex": "@InProceedings{pmlr-v206-alabdulmohsin23a,\n  title = \t {Adapting to Latent Subgroup Shifts via Concepts and Proxies},\n  author =       {Alabdulmohsin, Ibrahim and Chiou, Nicole and D'Amour, Alexander and Gretton, Arthur and Koyejo, Sanmi and Kusner, Matt J. and Pfohl, Stephen R. and Salaudeen, Olawale and Schrouff, Jessica and Tsai, Katherine},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9637--9661},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/alabdulmohsin23a/alabdulmohsin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/alabdulmohsin23a.html},\n  abstract = \t {We address the problem of unsupervised domain adaptation when the source domain differs from the target domain because of a shift in the distribution of a latent subgroup. When this subgroup confounds all observed data, neither covariate shift nor label shift assumptions apply. We show that the optimal target predictor can be non-parametrically identified with the help of concept and proxy variables available only in the source domain, and unlabeled data from the target. The identification results are constructive, immediately suggesting an algorithm for estimating the optimal predictor in the target. For continuous observations, when this algorithm becomes impractical, we propose a latent variable model specific to the data generation process at hand. We show how the approach degrades as the size of the shift changes, and verify that it outperforms both covariate and label shift adjustment.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/alabdulmohsin23a/alabdulmohsin23a.pdf",
        "supp": "",
        "pdf_size": 656469,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15114731970550596263&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;;;;;",
        "aff_domain": ";;;;;;;;;",
        "email": ";;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "56c48779d4",
        "title": "Adaptive Cholesky Gaussian Processes",
        "site": "https://proceedings.mlr.press/v206/bartels23a.html",
        "author": "Simon Bartels; Kristoffer Stensbo-Smidt; Pablo Moreno-Munoz; Wouter Boomsma; Jes Frellsen; Soren Hauberg",
        "abstract": "We present a method to approximate Gaussian process regression models to large datasets by considering only a subset of the data. Our approach is novel in that the size of the subset is selected on the fly during exact inference with little computational overhead. From an empirical observation that the log-marginal likelihood often exhibits a linear trend once a sufficient subset of a dataset has been observed, we conclude that many large datasets contain redundant information that only slightly affects the posterior. Based on this, we provide probabilistic bounds on the full model evidence that can identify such subsets. Remarkably, these bounds are largely composed of terms that appear in intermediate steps of the standard Cholesky decomposition, allowing us to modify the algorithm to adaptively stop the decomposition once enough data have been observed.",
        "bibtex": "@InProceedings{pmlr-v206-bartels23a,\n  title = \t {Adaptive Cholesky Gaussian Processes},\n  author =       {Bartels, Simon and Stensbo-Smidt, Kristoffer and Moreno-Munoz, Pablo and Boomsma, Wouter and Frellsen, Jes and Hauberg, Soren},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {408--452},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bartels23a/bartels23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bartels23a.html},\n  abstract = \t {We present a method to approximate Gaussian process regression models to large datasets by considering only a subset of the data. Our approach is novel in that the size of the subset is selected on the fly during exact inference with little computational overhead. From an empirical observation that the log-marginal likelihood often exhibits a linear trend once a sufficient subset of a dataset has been observed, we conclude that many large datasets contain redundant information that only slightly affects the posterior. Based on this, we provide probabilistic bounds on the full model evidence that can identify such subsets. Remarkably, these bounds are largely composed of terms that appear in intermediate steps of the standard Cholesky decomposition, allowing us to modify the algorithm to adaptively stop the decomposition once enough data have been observed.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bartels23a/bartels23a.pdf",
        "supp": "",
        "pdf_size": 4006787,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=361830342362998686&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b6786b6ea4",
        "title": "Adaptive Dimension Reduction and Variational Inference for Transductive Few-Shot Classification",
        "site": "https://proceedings.mlr.press/v206/hu23c.html",
        "author": "Yuqing Hu; Stephane Pateux; Vincent Gripon",
        "abstract": "Transductive Few-Shot learning has gained increased attention nowadays considering the cost of data annotations along with the increased accuracy provided by unlabelled samples in the domain of few shot. Especially in Few-Shot Classification (FSC), recent works explore the feature distributions aiming at maximizing likelihoods or posteriors with respect to the unknown parameters. Following this vein, and considering the parallel between FSC and clustering, we seek for better taking into account the uncertainty in estimation due to lack of data, as well as better statistical properties of the clusters associated with each class. Therefore in this paper we propose a new clustering method based on Variational Bayesian inference, further improved by Adaptive Dimension Reduction based on Probabilistic Linear Discriminant Analysis. Our proposed method significantly improves accuracy in the realistic unbalanced transductive setting on various Few-Shot benchmarks when applied to features used in previous studies, with a gain of up to $6%$ in accuracy. In addition, when applied to balanced setting, we obtain very competitive results without making use of the class-balance artefact which is disputable for practical use cases.",
        "bibtex": "@InProceedings{pmlr-v206-hu23c,\n  title = \t {Adaptive Dimension Reduction and Variational Inference for Transductive Few-Shot Classification},\n  author =       {Hu, Yuqing and Pateux, Stephane and Gripon, Vincent},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5899--5917},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hu23c/hu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hu23c.html},\n  abstract = \t {Transductive Few-Shot learning has gained increased attention nowadays considering the cost of data annotations along with the increased accuracy provided by unlabelled samples in the domain of few shot. Especially in Few-Shot Classification (FSC), recent works explore the feature distributions aiming at maximizing likelihoods or posteriors with respect to the unknown parameters. Following this vein, and considering the parallel between FSC and clustering, we seek for better taking into account the uncertainty in estimation due to lack of data, as well as better statistical properties of the clusters associated with each class. Therefore in this paper we propose a new clustering method based on Variational Bayesian inference, further improved by Adaptive Dimension Reduction based on Probabilistic Linear Discriminant Analysis. Our proposed method significantly improves accuracy in the realistic unbalanced transductive setting on various Few-Shot benchmarks when applied to features used in previous studies, with a gain of up to $6%$ in accuracy. In addition, when applied to balanced setting, we obtain very competitive results without making use of the class-balance artefact which is disputable for practical use cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hu23c/hu23c.pdf",
        "supp": "",
        "pdf_size": 552480,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15035596737842355836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "IMT Atlantique; Orange; Orange IMT Atlantique",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "IMT Atlantique;Orange",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.imt-atlantique.fr;",
        "aff_unique_abbr": "IMT Atlantique;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France;"
    },
    {
        "id": "cba1275cab",
        "title": "Adaptive Tuning for Metropolis Adjusted Langevin Trajectories",
        "site": "https://proceedings.mlr.press/v206/riou-durand23a.html",
        "author": "Lionel Riou-Durand; Pavel Sountsov; Jure Vogrinc; Charles Margossian; Sam Power",
        "abstract": "Hamiltonian Monte Carlo (HMC) is a widely used sampler for continuous probability distributions. In many cases, the underlying Hamiltonian dynamics exhibit a phenomenon of resonance which decreases the efficiency of the algorithm and makes it very sensitive to hyperparameter values. This issue can be tackled efficiently, either via the use of trajectory length randomization (RHMC) or via partial momentum refreshment. The second approach is connected to the kinetic Langevin diffusion, and has been mostly investigated through the use of Generalized HMC (GHMC). However, GHMC induces momentum flips upon rejections causing the sampler to backtrack and waste computational resources. In this work we focus on a recent algorithm bypassing this issue, named Metropolis Adjusted Langevin Trajectories (MALT). We build upon recent strategies for tuning the hyperparameters of RHMC which target a bound on the Effective Sample Size (ESS) and adapt it to MALT, thereby enabling the first user-friendly deployment of this algorithm. We construct a method to optimize a sharper bound on the ESS and reduce the estimator variance. Easily compatible with parallel implementation, the resultant Adaptive MALT algorithm is competitive in terms of ESS rate and hits useful tradeoffs in memory usage when compared to GHMC, RHMC and NUTS.",
        "bibtex": "@InProceedings{pmlr-v206-riou-durand23a,\n  title = \t {Adaptive Tuning for Metropolis Adjusted Langevin Trajectories},\n  author =       {Riou-Durand, Lionel and Sountsov, Pavel and Vogrinc, Jure and Margossian, Charles and Power, Sam},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8102--8116},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/riou-durand23a/riou-durand23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/riou-durand23a.html},\n  abstract = \t {Hamiltonian Monte Carlo (HMC) is a widely used sampler for continuous probability distributions. In many cases, the underlying Hamiltonian dynamics exhibit a phenomenon of resonance which decreases the efficiency of the algorithm and makes it very sensitive to hyperparameter values. This issue can be tackled efficiently, either via the use of trajectory length randomization (RHMC) or via partial momentum refreshment. The second approach is connected to the kinetic Langevin diffusion, and has been mostly investigated through the use of Generalized HMC (GHMC). However, GHMC induces momentum flips upon rejections causing the sampler to backtrack and waste computational resources. In this work we focus on a recent algorithm bypassing this issue, named Metropolis Adjusted Langevin Trajectories (MALT). We build upon recent strategies for tuning the hyperparameters of RHMC which target a bound on the Effective Sample Size (ESS) and adapt it to MALT, thereby enabling the first user-friendly deployment of this algorithm. We construct a method to optimize a sharper bound on the ESS and reduce the estimator variance. Easily compatible with parallel implementation, the resultant Adaptive MALT algorithm is competitive in terms of ESS rate and hits useful tradeoffs in memory usage when compared to GHMC, RHMC and NUTS.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/riou-durand23a/riou-durand23a.pdf",
        "supp": "",
        "pdf_size": 483271,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5458586379672256031&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Warwick; Google Research; University of Warwick; Flatiron Institute; University of Bristol",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "University of Warwick;Google;Flatiron Institute;University of Bristol",
        "aff_unique_dep": ";Google Research;;",
        "aff_unique_url": "https://www.warwick.ac.uk;https://research.google;https://flatironinstitute.org;https://www.bristol.ac.uk",
        "aff_unique_abbr": "Warwick;Google Research;Flatiron;Bristol",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "8c16985de8",
        "title": "Adversarial De-confounding in Individualised Treatment Effects Estimation",
        "site": "https://proceedings.mlr.press/v206/chauhan23a.html",
        "author": "Vinod K. Chauhan; Soheila Molaei; Marzia Hoque Tania; Anshul Thakur; Tingting Zhu; David A. Clifton",
        "abstract": "Observational studies have recently received significant attention from the machine learning community due to the increasingly available non-experimental observational data and the limitations of the experimental studies, such as considerable cost, impracticality, small and less representative sample sizes, etc. In observational studies, de-confounding is a fundamental problem of individualised treatment effects (ITE) estimation. This paper proposes disentangled representations with adversarial training to selectively balance the confounders in the binary treatment setting for the ITE estimation. The adversarial training of treatment policy selectively encourages treatment-agnostic balanced representations for the confounders and helps to estimate the ITE in the observational studies via counterfactual inference. Empirical results on synthetic and real-world datasets, with varying degrees of confounding, prove that our proposed approach improves the state-of-the-art methods in achieving lower error in the ITE estimation.",
        "bibtex": "@InProceedings{pmlr-v206-chauhan23a,\n  title = \t {Adversarial De-confounding in Individualised Treatment Effects Estimation},\n  author =       {Chauhan, Vinod K. and Molaei, Soheila and Tania, Marzia Hoque and Thakur, Anshul and Zhu, Tingting and Clifton, David A.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {837--849},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chauhan23a/chauhan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chauhan23a.html},\n  abstract = \t {Observational studies have recently received significant attention from the machine learning community due to the increasingly available non-experimental observational data and the limitations of the experimental studies, such as considerable cost, impracticality, small and less representative sample sizes, etc. In observational studies, de-confounding is a fundamental problem of individualised treatment effects (ITE) estimation. This paper proposes disentangled representations with adversarial training to selectively balance the confounders in the binary treatment setting for the ITE estimation. The adversarial training of treatment policy selectively encourages treatment-agnostic balanced representations for the confounders and helps to estimate the ITE in the observational studies via counterfactual inference. Empirical results on synthetic and real-world datasets, with varying degrees of confounding, prove that our proposed approach improves the state-of-the-art methods in achieving lower error in the ITE estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chauhan23a/chauhan23a.pdf",
        "supp": "",
        "pdf_size": 1294226,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13424931128293352881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Institute of Biomedical Engineering, University of Oxford, UK; Institute of Biomedical Engineering, University of Oxford, UK; Institute of Biomedical Engineering, University of Oxford, UK; Institute of Biomedical Engineering, University of Oxford, UK; Institute of Biomedical Engineering, University of Oxford, UK; Institute of Biomedical Engineering, University of Oxford, UK + Oxford-Suzhou Centre for Advanced Research, Suzhou, China",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0+1",
        "aff_unique_norm": "University of Oxford;Oxford-Suzhou Centre for Advanced Research",
        "aff_unique_dep": "Institute of Biomedical Engineering;",
        "aff_unique_url": "https://www.ox.ac.uk;",
        "aff_unique_abbr": "Oxford;",
        "aff_campus_unique_index": "0;0;0;0;0;0+1",
        "aff_campus_unique": "Oxford;Suzhou",
        "aff_country_unique_index": "0;0;0;0;0;0+1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "ce67bdb84b",
        "title": "Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks",
        "site": "https://proceedings.mlr.press/v206/zhang23d.html",
        "author": "Huishuai Zhang; Da Yu; Yiping Lu; Di He",
        "abstract": "Adversarial example, which is usually generated by adding imperceptible adversarial noise to a clean sample, is ubiquitous for neural networks. In this paper we unveil a surprising property of adversarial noises when they are put together, i.e., adversarial noises crafted by one-step gradient methods are linearly separable if equipped with the corresponding labels. We theoretically prove this property for a two-layer network with randomly initialized entries and the neural tangent kernel setup where the parameters are not far from initialization. The proof idea is to show the label information can be efficiently backpropagated to the input while keeping the linear separability. Our theory and experimental evidence further show that the linear classifier trained with the adversarial noises of the training data can well classify the adversarial noises of the test data, indicating that adversarial noises actually inject a distributional perturbation to the original data distribution. Furthermore, we empirically demonstrate that the adversarial noises may become less linearly separable when the above conditions are compromised while they are still much easier to classify than original features.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23d,\n  title = \t {Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks},\n  author =       {Zhang, Huishuai and Yu, Da and Lu, Yiping and He, Di},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2792--2804},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23d/zhang23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23d.html},\n  abstract = \t {Adversarial example, which is usually generated by adding imperceptible adversarial noise to a clean sample, is ubiquitous for neural networks. In this paper we unveil a surprising property of adversarial noises when they are put together, i.e., adversarial noises crafted by one-step gradient methods are linearly separable if equipped with the corresponding labels. We theoretically prove this property for a two-layer network with randomly initialized entries and the neural tangent kernel setup where the parameters are not far from initialization. The proof idea is to show the label information can be efficiently backpropagated to the input while keeping the linear separability. Our theory and experimental evidence further show that the linear classifier trained with the adversarial noises of the training data can well classify the adversarial noises of the test data, indicating that adversarial noises actually inject a distributional perturbation to the original data distribution. Furthermore, we empirically demonstrate that the adversarial noises may become less linearly separable when the above conditions are compromised while they are still much easier to classify than original features.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23d/zhang23d.pdf",
        "supp": "",
        "pdf_size": 1785528,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14021218669521711852&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e6cdb0f994",
        "title": "Adversarial Random Forests for Density Estimation and Generative Modeling",
        "site": "https://proceedings.mlr.press/v206/watson23a.html",
        "author": "David S. Watson; Kristin Blesch; Jan Kapar; Marvin N. Wright",
        "abstract": "We propose methods for density estimation and data synthesis using a novel form of unsupervised random forests. Inspired by generative adversarial networks, we implement a recursive procedure in which trees gradually learn structural properties of the data through alternating rounds of generation and discrimination. The method is provably consistent under minimal assumptions. Unlike classic tree-based alternatives, our approach provides smooth (un)conditional densities and allows for fully synthetic data generation. We achieve comparable or superior performance to state-of-the-art probabilistic circuits and deep learning models on various tabular data benchmarks while executing about two orders of magnitude faster on average. An accompanying $R$ package, $arf$, is available on $CRAN$.",
        "bibtex": "@InProceedings{pmlr-v206-watson23a,\n  title = \t {Adversarial Random Forests for Density Estimation and Generative Modeling},\n  author =       {Watson, David S. and Blesch, Kristin and Kapar, Jan and Wright, Marvin N.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5357--5375},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/watson23a/watson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/watson23a.html},\n  abstract = \t {We propose methods for density estimation and data synthesis using a novel form of unsupervised random forests. Inspired by generative adversarial networks, we implement a recursive procedure in which trees gradually learn structural properties of the data through alternating rounds of generation and discrimination. The method is provably consistent under minimal assumptions. Unlike classic tree-based alternatives, our approach provides smooth (un)conditional densities and allows for fully synthetic data generation. We achieve comparable or superior performance to state-of-the-art probabilistic circuits and deep learning models on various tabular data benchmarks while executing about two orders of magnitude faster on average. An accompanying $R$ package, $arf$, is available on $CRAN$.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/watson23a/watson23a.pdf",
        "supp": "",
        "pdf_size": 1184350,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12545018675887199066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "47ac32a525",
        "title": "Adversarial robustness of VAEs through the lens of local geometry",
        "site": "https://proceedings.mlr.press/v206/khan23b.html",
        "author": "Asif Khan; Amos Storkey",
        "abstract": "In an unsupervised attack on variational autoencoders (VAEs), an adversary finds a small perturbation in an input sample that significantly changes its latent space encoding, thereby compromising the reconstruction for a fixed decoder. A known reason for such vulnerability is the distortions in the latent space resulting from a mismatch between approximated latent posterior and a prior distribution. Consequently, a slight change in an input sample can move its encoding to a low/zero density region in the latent space resulting in an unconstrained generation. This paper demonstrates that an optimal way for an adversary to attack VAEs is to exploit a directional bias of a stochastic pullback metric tensor induced by the encoder and decoder networks. The pullback metric tensor of an encoder measures the change in infinitesimal latent volume from an input to a latent space. Thus, it can be viewed as a lens to analyse the effect of input perturbations leading to latent space distortions. We propose robustness evaluation scores using the eigenspectrum of a pullback metric tensor. Moreover, we empirically show that the scores correlate with the robustness parameter $\\beta$ of the $\\beta-$VAE. Since increasing $\\beta$ also degrades reconstruction quality, we demonstrate a simple alternative using mixup training to fill the empty regions in the latent space, thus improving robustness with improved reconstruction.",
        "bibtex": "@InProceedings{pmlr-v206-khan23b,\n  title = \t {Adversarial robustness of VAEs through the lens of local geometry},\n  author =       {Khan, Asif and Storkey, Amos},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8954--8967},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/khan23b/khan23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/khan23b.html},\n  abstract = \t {In an unsupervised attack on variational autoencoders (VAEs), an adversary finds a small perturbation in an input sample that significantly changes its latent space encoding, thereby compromising the reconstruction for a fixed decoder. A known reason for such vulnerability is the distortions in the latent space resulting from a mismatch between approximated latent posterior and a prior distribution. Consequently, a slight change in an input sample can move its encoding to a low/zero density region in the latent space resulting in an unconstrained generation. This paper demonstrates that an optimal way for an adversary to attack VAEs is to exploit a directional bias of a stochastic pullback metric tensor induced by the encoder and decoder networks. The pullback metric tensor of an encoder measures the change in infinitesimal latent volume from an input to a latent space. Thus, it can be viewed as a lens to analyse the effect of input perturbations leading to latent space distortions. We propose robustness evaluation scores using the eigenspectrum of a pullback metric tensor. Moreover, we empirically show that the scores correlate with the robustness parameter $\\beta$ of the $\\beta-$VAE. Since increasing $\\beta$ also degrades reconstruction quality, we demonstrate a simple alternative using mixup training to fill the empty regions in the latent space, thus improving robustness with improved reconstruction.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/khan23b/khan23b.pdf",
        "supp": "",
        "pdf_size": 4955019,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12899895147606046274&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "School of Informatics, University of Edinburgh, U.K.; School of Informatics, University of Edinburgh, U.K.",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "45a0753598",
        "title": "Agnostic PAC Learning of $k$-juntas Using $L_2$-Polynomial Regression",
        "site": "https://proceedings.mlr.press/v206/heidari23b.html",
        "author": "Mohsen Heidari; Wojciech Szpankowski",
        "abstract": "Many conventional learning algorithms rely on loss functions other than the natural 0-1 loss for computational efficiency and theoretical tractability. Among them are approaches based on absolute loss (L1 regression) and square loss (L2 regression). The first is proved to be an agnostic PAC learner for various important concept classes such as juntas, and half-spaces. On the other hand, the second is preferable because of its computational efficiency which is linear in the sample size. However, PAC learnability is still unknown as guarantees have been proved only under distributional restrictions. The question of whether L2 regression is an agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be answered. This paper resolves this problem for the junta class on the Boolean cube \u2014 proving agnostic PAC learning of k-juntas using L2 polynomial regression. Moreover, we present a new PAC learning algorithm based on the Boolean Fourier expansion with lower computational complexity. Fourier-based algorithms, such as Linial et al. (1993), have been used under distributional restrictions, such as uniform distribution. We show that with an appropriate change one can apply those algorithms in agnostic settings without any distributional assumption. We prove our results by connecting the PAC learning with 0-1 loss to the minimum mean square estimation (MMSE) problem. We derive an elegant upper bound on the 0-1 loss in terms of the MMSE error based on that, we show that the sign of the MMSE is a PAC learner for any concept class containing it.",
        "bibtex": "@InProceedings{pmlr-v206-heidari23b,\n  title = \t {Agnostic PAC Learning of $k$-juntas Using $L_2$-Polynomial Regression},\n  author =       {Heidari, Mohsen and Szpankowski, Wojciech},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2922--2938},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/heidari23b/heidari23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/heidari23b.html},\n  abstract = \t {Many conventional learning algorithms rely on loss functions other than the natural 0-1 loss for computational efficiency and theoretical tractability. Among them are approaches based on absolute loss (L1 regression) and square loss (L2 regression). The first is proved to be an agnostic PAC learner for various important concept classes such as juntas, and half-spaces. On the other hand, the second is preferable because of its computational efficiency which is linear in the sample size. However, PAC learnability is still unknown as guarantees have been proved only under distributional restrictions. The question of whether L2 regression is an agnostic PAC learner for 0-1 loss has been open since 1993 and yet has to be answered. This paper resolves this problem for the junta class on the Boolean cube \u2014 proving agnostic PAC learning of k-juntas using L2 polynomial regression. Moreover, we present a new PAC learning algorithm based on the Boolean Fourier expansion with lower computational complexity. Fourier-based algorithms, such as Linial et al. (1993), have been used under distributional restrictions, such as uniform distribution. We show that with an appropriate change one can apply those algorithms in agnostic settings without any distributional assumption. We prove our results by connecting the PAC learning with 0-1 loss to the minimum mean square estimation (MMSE) problem. We derive an elegant upper bound on the 0-1 loss in terms of the MMSE error based on that, we show that the sign of the MMSE is a PAC learner for any concept class containing it.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/heidari23b/heidari23b.pdf",
        "supp": "",
        "pdf_size": 368194,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3106264418324548210&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Indiana University, Bloomington; Purdue University, West Lafayette",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Indiana University;Purdue University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.indiana.edu;https://www.purdue.edu",
        "aff_unique_abbr": "IU;Purdue",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Bloomington;West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b6060d04fd",
        "title": "Algorithm for Constrained Markov Decision Process with Linear Convergence",
        "site": "https://proceedings.mlr.press/v206/gladin23a.html",
        "author": "Egor Gladin; Maksim Lavrik-Karmazin; Karina Zainullina; Varvara Rudenko; Alexander Gasnikov; Martin Takac",
        "abstract": "The problem of constrained Markov decision process is considered. An agent aims to maximize the expected accumulated discounted reward subject to multiple constraints on its costs (the number of constraints is relatively small). A new dual approach is proposed with the integration of two ingredients: entropy-regularized policy optimizer and Vaidya\u2019s dual optimizer, both of which are critical to achieve faster convergence. The finite-time error bound of the proposed approach is provided. Despite the challenge of the nonconcave objective subject to nonconcave constraints, the proposed approach is shown to converge (with linear rate) to the global optimum. The complexity expressed in terms of the optimality gap and the constraint violation significantly improves upon the existing primal-dual approaches.",
        "bibtex": "@InProceedings{pmlr-v206-gladin23a,\n  title = \t {Algorithm for Constrained Markov Decision Process with Linear Convergence},\n  author =       {Gladin, Egor and Lavrik-Karmazin, Maksim and Zainullina, Karina and Rudenko, Varvara and Gasnikov, Alexander and Takac, Martin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11506--11533},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gladin23a/gladin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gladin23a.html},\n  abstract = \t {The problem of constrained Markov decision process is considered. An agent aims to maximize the expected accumulated discounted reward subject to multiple constraints on its costs (the number of constraints is relatively small). A new dual approach is proposed with the integration of two ingredients: entropy-regularized policy optimizer and Vaidya\u2019s dual optimizer, both of which are critical to achieve faster convergence. The finite-time error bound of the proposed approach is provided. Despite the challenge of the nonconcave objective subject to nonconcave constraints, the proposed approach is shown to converge (with linear rate) to the global optimum. The complexity expressed in terms of the optimality gap and the constraint violation significantly improves upon the existing primal-dual approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gladin23a/gladin23a.pdf",
        "supp": "",
        "pdf_size": 4083563,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2228280980158068186&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Humboldt University of Berlin; Moscow Institute of Physics and Technology; Moscow Institute of Physics and Technology; Moscow Institute of Physics and Technology, HSE University; Moscow Institute of Physics and Technology, ISP RAS Research Center for Trusted Artificial Intelligence; Mohamed bin Zayed University of Artificial Intelligence",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1;2",
        "aff_unique_norm": "Humboldt University of Berlin;Moscow Institute of Physics and Technology;Mohamed bin Zayed University of Artificial Intelligence",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.hu-berlin.de;https://www.mipt.ru/en;https://mbzuai.ac.ae",
        "aff_unique_abbr": "HU Berlin;MIPT;MBZUAI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berlin;",
        "aff_country_unique_index": "0;1;1;1;1;2",
        "aff_country_unique": "Germany;Russian Federation;United Arab Emirates"
    },
    {
        "id": "e3647395fc",
        "title": "Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation",
        "site": "https://proceedings.mlr.press/v206/chen23h.html",
        "author": "Qi Chen; Mario Marchand",
        "abstract": "We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective. Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied. We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data. Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment. Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation. The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency.",
        "bibtex": "@InProceedings{pmlr-v206-chen23h,\n  title = \t {Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation},\n  author =       {Chen, Qi and Marchand, Mario},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10368--10394},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23h/chen23h.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23h.html},\n  abstract = \t {We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective. Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied. We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data. Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment. Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation. The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23h/chen23h.pdf",
        "supp": "",
        "pdf_size": 720851,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15381589270482213626&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Universit\u00e9 Laval; Universit\u00e9 Laval",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "ULaval",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8de29d5497",
        "title": "Alternating Projected SGD for Equality-constrained Bilevel Optimization",
        "site": "https://proceedings.mlr.press/v206/xiao23a.html",
        "author": "Quan Xiao; Han Shen; Wotao Yin; Tianyi Chen",
        "abstract": "Bilevel optimization, which captures the inherent nested structure of machine learning problems, is gaining popularity in many recent applications. Existing works on bilevel optimization mostly consider either the unconstrained problems or the constrained upper-level problems. In this context, this paper considers the stochastic bilevel optimization problems with equality constraints in both upper and lower levels. By leveraging the special structure of the equality constraints problem, the paper first presents an alternating projected SGD approach to tackle this problem and establishes the $\\tilde{\\cal O}(\\epsilon^{-2})$ sample and iteration complexity that matches the state-of-the-art complexity of ALSET Chen et al. (2021) for stochastic unconstrained bilevel problems. To further save the cost of projection, the paper presents an alternating projected SGD approach with lazy projection and establishes the $\\tilde{\\cal O}(\\epsilon^{-2}/T)$ upper-level and $\\tilde{\\cal O}(\\epsilon^{-1.5}/T^{\\frac{3}{4}})$ lower-level projection complexity of this new algorithm, where $T$ is the upper-level projection interval. Application to federated bilevel optimization has been presented to showcase the performance of our algorithms. Our results demonstrate that equality-constrained bilevel optimization with strongly-convex lower-level problems can be solved as efficiently as stochastic single-level optimization problems.",
        "bibtex": "@InProceedings{pmlr-v206-xiao23a,\n  title = \t {Alternating Projected SGD for Equality-constrained Bilevel Optimization},\n  author =       {Xiao, Quan and Shen, Han and Yin, Wotao and Chen, Tianyi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {987--1023},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xiao23a/xiao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xiao23a.html},\n  abstract = \t {Bilevel optimization, which captures the inherent nested structure of machine learning problems, is gaining popularity in many recent applications. Existing works on bilevel optimization mostly consider either the unconstrained problems or the constrained upper-level problems. In this context, this paper considers the stochastic bilevel optimization problems with equality constraints in both upper and lower levels. By leveraging the special structure of the equality constraints problem, the paper first presents an alternating projected SGD approach to tackle this problem and establishes the $\\tilde{\\cal O}(\\epsilon^{-2})$ sample and iteration complexity that matches the state-of-the-art complexity of ALSET Chen et al. (2021) for stochastic unconstrained bilevel problems. To further save the cost of projection, the paper presents an alternating projected SGD approach with lazy projection and establishes the $\\tilde{\\cal O}(\\epsilon^{-2}/T)$ upper-level and $\\tilde{\\cal O}(\\epsilon^{-1.5}/T^{\\frac{3}{4}})$ lower-level projection complexity of this new algorithm, where $T$ is the upper-level projection interval. Application to federated bilevel optimization has been presented to showcase the performance of our algorithms. Our results demonstrate that equality-constrained bilevel optimization with strongly-convex lower-level problems can be solved as efficiently as stochastic single-level optimization problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xiao23a/xiao23a.pdf",
        "supp": "",
        "pdf_size": 736906,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6484010402795450848&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute; Alibaba US, DAMO Academy; Rensselaer Polytechnic Institute",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/hanshen95/AiPOD",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute;Alibaba Group",
        "aff_unique_dep": ";DAMO Academy",
        "aff_unique_url": "https://www.rpi.edu;https://www.alibaba.com",
        "aff_unique_abbr": "RPI;Alibaba",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5d067b77c4",
        "title": "An Efficient and Continuous Voronoi Density Estimator",
        "site": "https://proceedings.mlr.press/v206/marchetti23a.html",
        "author": "Giovanni Luca Marchetti; Vladislav Polianskii; Anastasiia Varava; Florian T. Pokorny; Danica Kragic",
        "abstract": "We introduce a non-parametric density estimator deemed Radial Voronoi Density Estimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and as such benefits from local geometric adaptiveness and broad convergence properties. Due to its radial definition RVDE is continuous and computable in linear time with respect to the dataset size. This amends for the main shortcomings of previously studied VDEs, which are highly discontinuous and computationally expensive. We provide a theoretical study of the modes of RVDE as well as an empirical investigation of its performance on high-dimensional data. Results show that RVDE outperforms other non-parametric density estimators, including recently introduced VDEs.",
        "bibtex": "@InProceedings{pmlr-v206-marchetti23a,\n  title = \t {An Efficient and Continuous Voronoi Density Estimator},\n  author =       {Marchetti, Giovanni Luca and Polianskii, Vladislav and Varava, Anastasiia and Pokorny, Florian T. and Kragic, Danica},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4732--4744},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/marchetti23a/marchetti23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/marchetti23a.html},\n  abstract = \t {We introduce a non-parametric density estimator deemed Radial Voronoi Density Estimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and as such benefits from local geometric adaptiveness and broad convergence properties. Due to its radial definition RVDE is continuous and computable in linear time with respect to the dataset size. This amends for the main shortcomings of previously studied VDEs, which are highly discontinuous and computationally expensive. We provide a theoretical study of the modes of RVDE as well as an empirical investigation of its performance on high-dimensional data. Results show that RVDE outperforms other non-parametric density estimators, including recently introduced VDEs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/marchetti23a/marchetti23a.pdf",
        "supp": "",
        "pdf_size": 2506657,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9945013607517991219&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "35ae5679cd",
        "title": "An Homogeneous Unbalanced Regularized Optimal Transport Model with Applications to Optimal Transport with Boundary",
        "site": "https://proceedings.mlr.press/v206/lacombe23a.html",
        "author": "Theo Lacombe",
        "abstract": "This work studies how the introduction of the entropic regularization term in unbalanced Optimal Transport (OT) models may alter their homogeneity with respect to the input measures. We observe that in common settings (including balanced OT and unbalanced OT with Kullback-Leibler divergence to the marginals), although the optimal transport cost itself is not homogeneous, optimal transport plans and the so-called Sinkhorn divergences are indeed homogeneous. However, homogeneity does not hold in more general Unbalanced Regularized Optimal Transport (UROT) models, for instance those using the Total Variation as divergence to the marginals. We propose to modify the entropic regularization term to retrieve an UROT model that is homogeneous while preserving most properties of the standard UROT model. We showcase the importance of using our Homogeneous UROT (HUROT) model when it comes to regularize Optimal Transport with Boundary, a transportation model involving a spatially varying divergence to the marginals for which the standard (inhomogeneous) UROT model would yield inappropriate behavior.",
        "bibtex": "@InProceedings{pmlr-v206-lacombe23a,\n  title = \t {An Homogeneous Unbalanced Regularized Optimal Transport Model with Applications to Optimal Transport with Boundary},\n  author =       {Lacombe, Theo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7311--7330},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lacombe23a/lacombe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lacombe23a.html},\n  abstract = \t {This work studies how the introduction of the entropic regularization term in unbalanced Optimal Transport (OT) models may alter their homogeneity with respect to the input measures. We observe that in common settings (including balanced OT and unbalanced OT with Kullback-Leibler divergence to the marginals), although the optimal transport cost itself is not homogeneous, optimal transport plans and the so-called Sinkhorn divergences are indeed homogeneous. However, homogeneity does not hold in more general Unbalanced Regularized Optimal Transport (UROT) models, for instance those using the Total Variation as divergence to the marginals. We propose to modify the entropic regularization term to retrieve an UROT model that is homogeneous while preserving most properties of the standard UROT model. We showcase the importance of using our Homogeneous UROT (HUROT) model when it comes to regularize Optimal Transport with Boundary, a transportation model involving a spatially varying divergence to the marginals for which the standard (inhomogeneous) UROT model would yield inappropriate behavior.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lacombe23a/lacombe23a.pdf",
        "supp": "",
        "pdf_size": 843859,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10668601102232647843&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Laboratoire d\u2019Informatique Gaspard Monge, Univ. Gustave Eiffel, CNRS, LIGM, F-77454 Marne-la-Vall\u00e9e, France",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Universit\u00e9 Gustave Eiffel",
        "aff_unique_dep": "Laboratoire d\u2019Informatique Gaspard Monge",
        "aff_unique_url": "https://www.univ-gustave-eiffel.fr",
        "aff_unique_abbr": "Univ. Gustave Eiffel",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Marne-la-Vall\u00e9e",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "a8a647d546",
        "title": "An Online and Unified Algorithm for Projection Matrix Vector Multiplication with Application to Empirical Risk Minimization",
        "site": "https://proceedings.mlr.press/v206/qin23a.html",
        "author": "Lianke Qin; Zhao Song; Lichen Zhang; Danyang Zhuo",
        "abstract": "Online matrix vector multiplication is a fundamental step and bottleneck in many machine learning algorithms. It is defined as follows: given a matrix at the pre-processing phase, at each iteration one receives a query vector and needs to form the matrix-vector product (approximately) before observing the next vector. In this work, we study a particular instance of such problem called the online projection matrix vector multiplication. Via a reduction, we show it suffices to solve the inverse maintenance problem. Additionally, our framework supports dimensionality reduction to speed up the computation that approximates the matrix-vector product with an optimization-friendly error guarantee. Moreover, our unified approach can handle both data-oblivious sketching and data-dependent sampling. Finally, we demonstrate the effectiveness of our framework by speeding up the empirical risk minimization solver.",
        "bibtex": "@InProceedings{pmlr-v206-qin23a,\n  title = \t {An Online and Unified Algorithm for Projection Matrix Vector Multiplication with Application to Empirical Risk Minimization},\n  author =       {Qin, Lianke and Song, Zhao and Zhang, Lichen and Zhuo, Danyang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {101--156},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qin23a/qin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qin23a.html},\n  abstract = \t {Online matrix vector multiplication is a fundamental step and bottleneck in many machine learning algorithms. It is defined as follows: given a matrix at the pre-processing phase, at each iteration one receives a query vector and needs to form the matrix-vector product (approximately) before observing the next vector. In this work, we study a particular instance of such problem called the online projection matrix vector multiplication. Via a reduction, we show it suffices to solve the inverse maintenance problem. Additionally, our framework supports dimensionality reduction to speed up the computation that approximates the matrix-vector product with an optimization-friendly error guarantee. Moreover, our unified approach can handle both data-oblivious sketching and data-dependent sampling. Finally, we demonstrate the effectiveness of our framework by speeding up the empirical risk minimization solver.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qin23a/qin23a.pdf",
        "supp": "",
        "pdf_size": 621002,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13208428989288412137&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1ef80d4139",
        "title": "An Optimization-based Algorithm for Non-stationary Kernel Bandits without Prior Knowledge",
        "site": "https://proceedings.mlr.press/v206/hong23b.html",
        "author": "Kihyuk Hong; Yuhang Li; Ambuj Tewari",
        "abstract": "We propose an algorithm for non-stationary kernel bandits that does not require prior knowledge of the degree of non-stationarity. The algorithm follows randomized strategies obtained by solving optimization problems that balance exploration and exploitation. It adapts to non-stationarity by restarting when a change in the reward function is detected. Our algorithm enjoys a tighter dynamic regret bound than previous work on non- stationary kernel bandits. Moreover, when applied to the non-stationary linear bandits by us- ing a linear kernel, our algorithm is nearly minimax optimal, solving an open problem in the non-stationary linear bandit literature. We extend our algorithm to use a neural network for dynamically adapting the feature mapping to observed data. We prove a dynamic regret bound of the extension using the neural tangent kernel theory. We demonstrate empirically that our algorithm and the extension can adapt to varying degrees of non-stationarity.",
        "bibtex": "@InProceedings{pmlr-v206-hong23b,\n  title = \t {An Optimization-based Algorithm for Non-stationary Kernel Bandits without Prior Knowledge},\n  author =       {Hong, Kihyuk and Li, Yuhang and Tewari, Ambuj},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3048--3085},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hong23b/hong23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hong23b.html},\n  abstract = \t {We propose an algorithm for non-stationary kernel bandits that does not require prior knowledge of the degree of non-stationarity. The algorithm follows randomized strategies obtained by solving optimization problems that balance exploration and exploitation. It adapts to non-stationarity by restarting when a change in the reward function is detected. Our algorithm enjoys a tighter dynamic regret bound than previous work on non- stationary kernel bandits. Moreover, when applied to the non-stationary linear bandits by us- ing a linear kernel, our algorithm is nearly minimax optimal, solving an open problem in the non-stationary linear bandit literature. We extend our algorithm to use a neural network for dynamically adapting the feature mapping to observed data. We prove a dynamic regret bound of the extension using the neural tangent kernel theory. We demonstrate empirically that our algorithm and the extension can adapt to varying degrees of non-stationarity.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hong23b/hong23b.pdf",
        "supp": "",
        "pdf_size": 740773,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3323551364920209810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e7847dec4d",
        "title": "An Unpooling Layer for Graph Generation",
        "site": "https://proceedings.mlr.press/v206/guo23a.html",
        "author": "Yinglong Guo; Dongmian Zou; Gilad Lerman",
        "abstract": "We propose a novel and trainable graph unpooling layer for effective graph generation. The unpooling layer receives an input graph with features and outputs an enlarged graph with desired structure and features. We prove that the output graph of the unpooling layer remains connected and for any connected graph there exists a series of unpooling layers that can produce it from a 3-node graph. We apply the unpooling layer within the generator of a generative adversarial network as well as the decoder of a variational autoencoder. We give extensive experimental evidence demonstrating the competitive performance of our proposed method on synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v206-guo23a,\n  title = \t {An Unpooling Layer for Graph Generation},\n  author =       {Guo, Yinglong and Zou, Dongmian and Lerman, Gilad},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3179--3209},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/guo23a/guo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/guo23a.html},\n  abstract = \t {We propose a novel and trainable graph unpooling layer for effective graph generation. The unpooling layer receives an input graph with features and outputs an enlarged graph with desired structure and features. We prove that the output graph of the unpooling layer remains connected and for any connected graph there exists a series of unpooling layers that can produce it from a 3-node graph. We apply the unpooling layer within the generator of a generative adversarial network as well as the decoder of a variational autoencoder. We give extensive experimental evidence demonstrating the competitive performance of our proposed method on synthetic and real data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/guo23a/guo23a.pdf",
        "supp": "",
        "pdf_size": 2582565,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7148556388587090148&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1080817932",
        "title": "Analysis of Catastrophic Forgetting for Random Orthogonal Transformation Tasks in the Overparameterized Regime",
        "site": "https://proceedings.mlr.press/v206/goldfarb23a.html",
        "author": "Daniel Goldfarb; Paul Hand",
        "abstract": "Overparameterization is known to permit strong generalization performance in neural networks. In this work, we provide an initial theoretical analysis of its effect on catastrophic forgetting in a continual learning setup. We show experimentally that in Permuted MNIST image classification tasks, the generalization performance of multilayer perceptrons trained by vanilla stochastic gradient descent can be improved by overparameterization, and the extent of the performance increase achieved by overparameterization is comparable to that of state-of-the-art continual learning algorithms. We provide a theoretical explanation of this effect by studying a qualitatively similar two-task linear regression problem, where each task is related by a random orthogonal transformation. We show that when a model is trained on the two tasks in sequence without any additional regularization, the risk gain on the first task is small if the model is sufficiently overparameterized.",
        "bibtex": "@InProceedings{pmlr-v206-goldfarb23a,\n  title = \t {Analysis of Catastrophic Forgetting for Random Orthogonal Transformation Tasks in the Overparameterized Regime},\n  author =       {Goldfarb, Daniel and Hand, Paul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2975--2993},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/goldfarb23a/goldfarb23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/goldfarb23a.html},\n  abstract = \t {Overparameterization is known to permit strong generalization performance in neural networks. In this work, we provide an initial theoretical analysis of its effect on catastrophic forgetting in a continual learning setup. We show experimentally that in Permuted MNIST image classification tasks, the generalization performance of multilayer perceptrons trained by vanilla stochastic gradient descent can be improved by overparameterization, and the extent of the performance increase achieved by overparameterization is comparable to that of state-of-the-art continual learning algorithms. We provide a theoretical explanation of this effect by studying a qualitatively similar two-task linear regression problem, where each task is related by a random orthogonal transformation. We show that when a model is trained on the two tasks in sequence without any additional regularization, the risk gain on the first task is small if the model is sufficiently overparameterized.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/goldfarb23a/goldfarb23a.pdf",
        "supp": "",
        "pdf_size": 1443307,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15957175268405735477&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Northeastern University; Northeastern University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5b57e7a6c0",
        "title": "Approximate Regions of Attraction in Learning with Decision-Dependent Distributions",
        "site": "https://proceedings.mlr.press/v206/dong23b.html",
        "author": "Roy Dong; Heling Zhang; Lillian Ratliff",
        "abstract": "As data-driven methods are deployed in real-world settings, the processes that generate the observed data will often react to the decisions of the learner. For example, a data source may have some incentive for the algorithm to provide a particular label (e.g. approve a bank loan), and manipulate their features accordingly. Work in strategic classification and decision-dependent distributions seeks to characterize the closed-loop behavior of deploying learning algorithms by explicitly considering the effect of the classifier on the underlying data distribution. More recently, works in performative prediction seek to classify the closed-loop behavior by considering general properties of the mapping from classifier to data distribution, rather than an explicit form. Building on this notion, we analyze repeated risk minimization as the perturbed trajectories of the gradient flows of performative risk minimization. We consider the case where there may be multiple local minimizers of performative risk, motivated by situations where the initial conditions may have significant impact on the long-term behavior of the system. We provide sufficient conditions to characterize the region of attraction for the various equilibria in this settings. Additionally, we introduce the notion of performative alignment, which provides a geometric condition on the convergence of repeated risk minimization to performative risk minimizers.",
        "bibtex": "@InProceedings{pmlr-v206-dong23b,\n  title = \t {Approximate Regions of Attraction in Learning with Decision-Dependent Distributions},\n  author =       {Dong, Roy and Zhang, Heling and Ratliff, Lillian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11172--11184},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dong23b/dong23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dong23b.html},\n  abstract = \t {As data-driven methods are deployed in real-world settings, the processes that generate the observed data will often react to the decisions of the learner. For example, a data source may have some incentive for the algorithm to provide a particular label (e.g. approve a bank loan), and manipulate their features accordingly. Work in strategic classification and decision-dependent distributions seeks to characterize the closed-loop behavior of deploying learning algorithms by explicitly considering the effect of the classifier on the underlying data distribution. More recently, works in performative prediction seek to classify the closed-loop behavior by considering general properties of the mapping from classifier to data distribution, rather than an explicit form. Building on this notion, we analyze repeated risk minimization as the perturbed trajectories of the gradient flows of performative risk minimization. We consider the case where there may be multiple local minimizers of performative risk, motivated by situations where the initial conditions may have significant impact on the long-term behavior of the system. We provide sufficient conditions to characterize the region of attraction for the various equilibria in this settings. Additionally, we introduce the notion of performative alignment, which provides a geometric condition on the convergence of repeated risk minimization to performative risk minimizers.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dong23b/dong23b.pdf",
        "supp": "",
        "pdf_size": 488683,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14580404343403278214&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "16f4616dcc",
        "title": "Approximating a RUM from Distributions on $k$-Slates",
        "site": "https://proceedings.mlr.press/v206/chierichetti23a.html",
        "author": "Flavio Chierichetti; Mirko Giacchini; Ravi Kumar; Alessandro Panconesi; Andrew Tomkins",
        "abstract": "In this work we consider the problem of fitting Random Utility Models (RUMs) to user choices. Given the winner distributions of the subsets of size $k$ of a universe, we obtain a polynomial-time algorithm that finds the RUM that best approximates the given distribution on average. Our algorithm is based on a linear program that we solve using the ellipsoid method. Given that its separation oracle problem is NP-hard, we devise an approximate separation oracle that can be viewed as a generalization of the weighted Feedback Arc Set problem to hypergraphs. Our theoretical result can also be made practical: we obtain a heuristic that scales to real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v206-chierichetti23a,\n  title = \t {Approximating a RUM from Distributions on $k$-Slates},\n  author =       {Chierichetti, Flavio and Giacchini, Mirko and Kumar, Ravi and Panconesi, Alessandro and Tomkins, Andrew},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4757--4767},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chierichetti23a/chierichetti23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chierichetti23a.html},\n  abstract = \t {In this work we consider the problem of fitting Random Utility Models (RUMs) to user choices. Given the winner distributions of the subsets of size $k$ of a universe, we obtain a polynomial-time algorithm that finds the RUM that best approximates the given distribution on average. Our algorithm is based on a linear program that we solve using the ellipsoid method. Given that its separation oracle problem is NP-hard, we devise an approximate separation oracle that can be viewed as a generalization of the weighted Feedback Arc Set problem to hypergraphs. Our theoretical result can also be made practical: we obtain a heuristic that scales to real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chierichetti23a/chierichetti23a.pdf",
        "supp": "",
        "pdf_size": 1141448,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18358356097427309763&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Sapienza University, Dip. di Informatica; Sapienza University, Dip. di Informatica; Google, Mountain View, CA; Sapienza University, Dip. di Informatica; Google, Mountain View, CA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Sapienza University;Google",
        "aff_unique_dep": "Department of Computer Science;Google",
        "aff_unique_url": "https://www.uniroma1.it;https://www.google.com",
        "aff_unique_abbr": "Sapienza;Google",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "a4ca5cfa11",
        "title": "Asymptotic Bayes risk of semi-supervised multitask learning on Gaussian mixture",
        "site": "https://proceedings.mlr.press/v206/nguyen23c.html",
        "author": "Minh-Toan Nguyen; Romain Couillet",
        "abstract": "The article considers semi-supervised multitask learning on a Gaussian mixture model (GMM). Using methods from statistical physics, we compute the asymptotic Bayes risk of each task in the regime of large datasets in high dimension, from which we analyze the role of task similarity in learning and evaluate the performance gain when tasks are learned together rather than separately. In the supervised case, we derive a simple algorithm that attains the Bayes optimal performance.",
        "bibtex": "@InProceedings{pmlr-v206-nguyen23c,\n  title = \t {Asymptotic Bayes risk of semi-supervised multitask learning on Gaussian mixture},\n  author =       {Nguyen, Minh-Toan and Couillet, Romain},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5063--5078},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nguyen23c/nguyen23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nguyen23c.html},\n  abstract = \t {The article considers semi-supervised multitask learning on a Gaussian mixture model (GMM). Using methods from statistical physics, we compute the asymptotic Bayes risk of each task in the regime of large datasets in high dimension, from which we analyze the role of task similarity in learning and evaluate the performance gain when tasks are learned together rather than separately. In the supervised case, we derive a simple algorithm that attains the Bayes optimal performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nguyen23c/nguyen23c.pdf",
        "supp": "",
        "pdf_size": 485840,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9750039113487755565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "GIPSA-lab, Universit\u00e9 Grenoble Alpes; LIG-lab, Universit\u00e9 Grenoble Alpes",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 Grenoble Alpes",
        "aff_unique_dep": "GIPSA-lab",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "c8ef811071",
        "title": "Asymptotically Unbiased Off-Policy Policy Evaluation when Reusing Old Data in Nonstationary Environments",
        "site": "https://proceedings.mlr.press/v206/liu23d.html",
        "author": "Vincent Liu; Yash Chandak; Philip Thomas; Martha White",
        "abstract": "In this work, we consider the off-policy policy evaluation problem for contextual bandits and finite horizon reinforcement learning in the nonstationary setting. Reusing old data is critical for policy evaluation, but existing estimators that reuse old data introduce large bias such that we can not obtain a valid confidence interval. Inspired from a related field called survey sampling, we introduce a variant of the doubly robust (DR) estimator, called the regression-assisted DR estimator, that can incorporate the past data without introducing a large bias. The estimator unifies several existing off-policy policy evaluation methods and improves on them with the use of auxiliary information and a regression approach. We prove that the new estimator is asymptotically unbiased, and provide a consistent variance estimator to a construct a large sample confidence interval. Finally, we empirically show that the new estimator improves estimation for the current and future policy values, and provides a tight and valid interval estimation in several nonstationary recommendation environments.",
        "bibtex": "@InProceedings{pmlr-v206-liu23d,\n  title = \t {Asymptotically Unbiased Off-Policy Policy Evaluation when Reusing Old Data in Nonstationary Environments},\n  author =       {Liu, Vincent and Chandak, Yash and Thomas, Philip and White, Martha},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5474--5492},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23d/liu23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23d.html},\n  abstract = \t {In this work, we consider the off-policy policy evaluation problem for contextual bandits and finite horizon reinforcement learning in the nonstationary setting. Reusing old data is critical for policy evaluation, but existing estimators that reuse old data introduce large bias such that we can not obtain a valid confidence interval. Inspired from a related field called survey sampling, we introduce a variant of the doubly robust (DR) estimator, called the regression-assisted DR estimator, that can incorporate the past data without introducing a large bias. The estimator unifies several existing off-policy policy evaluation methods and improves on them with the use of auxiliary information and a regression approach. We prove that the new estimator is asymptotically unbiased, and provide a consistent variance estimator to a construct a large sample confidence interval. Finally, we empirically show that the new estimator improves estimation for the current and future policy values, and provides a tight and valid interval estimation in several nonstationary recommendation environments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23d/liu23d.pdf",
        "supp": "",
        "pdf_size": 435903,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5244167474314964458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "556f890384",
        "title": "Autoencoded sparse Bayesian in-IRT factorization, calibration, and amortized inference for the Work Disability Functional Assessment Battery",
        "site": "https://proceedings.mlr.press/v206/chang23a.html",
        "author": "Joshua C. Chang; Carson C. Chow; Julia Porcino",
        "abstract": "The Work Disability Functional Assessment Battery (WD-FAB) is a multidimensional item response theory (IRT) instrument designed for assessing work-related mental and physical function based on responses to an item bank. In prior iterations it was developed using traditional means \u2013 linear factorization and null hypothesis statistical testing for item partitioning/selection, and finally, posthoc calibration of disjoint unidimensional IRT models. As a result, the WD-FAB, like many other IRT instruments, is a posthoc model. Its item partitioning, based on exploratory factor analysis, is blind to the final nonlinear IRT model and is not performed in a manner consistent with goodness of fit to the final model. In this manuscript, we develop a Bayesian hierarchical model for self-consistently performing the following simultaneous tasks: scale factorization, item selection, parameter identification, and response scoring. This method uses sparsity-based shrinkage to obviate the linear factorization and null hypothesis statistical tests that are usually required for developing multidimensional IRT models, so that item partitioning is consistent with the ultimate nonlinear factor model. We also analogize our multidimensional IRT model to probabilistic autoencoders, specifying an encoder function that amortizes the inference of ability parameters from item responses. The encoder function is equivalent to the \u201cVBE\u201d step in a stochastic variational Bayesian expectation maximization (VBEM) procedure that we use for approximate Bayesian inference on the entire model. We use the method on a sample of WD-FAB item responses and compare the resulting item discriminations to those obtained using the traditional posthoc method.",
        "bibtex": "@InProceedings{pmlr-v206-chang23a,\n  title = \t {Autoencoded sparse Bayesian in-IRT factorization, calibration, and amortized inference for the Work Disability Functional Assessment Battery},\n  author =       {Chang, Joshua C. and Chow, Carson C. and Porcino, Julia},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3961--3976},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chang23a/chang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chang23a.html},\n  abstract = \t {The Work Disability Functional Assessment Battery (WD-FAB) is a multidimensional item response theory (IRT) instrument designed for assessing work-related mental and physical function based on responses to an item bank. In prior iterations it was developed using traditional means \u2013 linear factorization and null hypothesis statistical testing for item partitioning/selection, and finally, posthoc calibration of disjoint unidimensional IRT models. As a result, the WD-FAB, like many other IRT instruments, is a posthoc model. Its item partitioning, based on exploratory factor analysis, is blind to the final nonlinear IRT model and is not performed in a manner consistent with goodness of fit to the final model. In this manuscript, we develop a Bayesian hierarchical model for self-consistently performing the following simultaneous tasks: scale factorization, item selection, parameter identification, and response scoring. This method uses sparsity-based shrinkage to obviate the linear factorization and null hypothesis statistical tests that are usually required for developing multidimensional IRT models, so that item partitioning is consistent with the ultimate nonlinear factor model. We also analogize our multidimensional IRT model to probabilistic autoencoders, specifying an encoder function that amortizes the inference of ability parameters from item responses. The encoder function is equivalent to the \u201cVBE\u201d step in a stochastic variational Bayesian expectation maximization (VBEM) procedure that we use for approximate Bayesian inference on the entire model. We use the method on a sample of WD-FAB item responses and compare the resulting item discriminations to those obtained using the traditional posthoc method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chang23a/chang23a.pdf",
        "supp": "",
        "pdf_size": 1616129,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15661053794400435950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a453576134",
        "title": "Automatic Attention Pruning: Improving and Automating Model Pruning using Attentions",
        "site": "https://proceedings.mlr.press/v206/zhao23b.html",
        "author": "Kaiqi Zhao; Animesh Jain; Ming Zhao",
        "abstract": "Pruning is a promising approach to compress deep learning models in order to deploy them on resource-constrained edge devices. However, many existing pruning solutions are based on unstructured pruning, which yields models that cannot efficiently run on commodity hardware; and they often require users to manually explore and tune the pruning process, which is time-consuming and often leads to sub-optimal results. To address these limitations, this paper presents Automatic Attention Pruning (AAP), an adaptive, attention-based, structured pruning approach to automatically generate small, accurate, and hardware-efficient models that meet user objectives. First, it proposes iterative structured pruning using activation-based attention maps to effectively identify and prune unimportant filters. Then, it proposes adaptive pruning policies for automatically meeting the pruning objectives of accuracy-critical, memory-constrained, and latency-sensitive tasks. A comprehensive evaluation shows that AAP substantially outperforms the state-of-the-art structured pruning works for a variety of model architectures. Our code is at: https://github.com/kaiqi123/Automatic-Attention-Pruning.git.",
        "bibtex": "@InProceedings{pmlr-v206-zhao23b,\n  title = \t {Automatic Attention Pruning: Improving and Automating Model Pruning using Attentions},\n  author =       {Zhao, Kaiqi and Jain, Animesh and Zhao, Ming},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10470--10486},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhao23b/zhao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhao23b.html},\n  abstract = \t {Pruning is a promising approach to compress deep learning models in order to deploy them on resource-constrained edge devices. However, many existing pruning solutions are based on unstructured pruning, which yields models that cannot efficiently run on commodity hardware; and they often require users to manually explore and tune the pruning process, which is time-consuming and often leads to sub-optimal results. To address these limitations, this paper presents Automatic Attention Pruning (AAP), an adaptive, attention-based, structured pruning approach to automatically generate small, accurate, and hardware-efficient models that meet user objectives. First, it proposes iterative structured pruning using activation-based attention maps to effectively identify and prune unimportant filters. Then, it proposes adaptive pruning policies for automatically meeting the pruning objectives of accuracy-critical, memory-constrained, and latency-sensitive tasks. A comprehensive evaluation shows that AAP substantially outperforms the state-of-the-art structured pruning works for a variety of model architectures. Our code is at: https://github.com/kaiqi123/Automatic-Attention-Pruning.git.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhao23b/zhao23b.pdf",
        "supp": "",
        "pdf_size": 4495401,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10595361061414396201&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "011e7e2766",
        "title": "Average Adjusted Association: Efficient Estimation with High Dimensional Confounders",
        "site": "https://proceedings.mlr.press/v206/jun23a.html",
        "author": "Sung Jae Jun; Sokbae Lee",
        "abstract": "The log odds ratio is a well-established metric for evaluating the association between binary outcome and exposure variables. Despite its widespread use, there has been limited discussion on how to summarize the log odds ratio as a function of confounders through averaging. To address this issue, we propose the Average Adjusted Association (AAA), which is a summary measure of association in a heterogeneous population, adjusted for observed confounders. To facilitate the use of it, we also develop efficient double/debiased machine learning (DML) estimators of the AAA. Our DML estimators use two equivalent forms of the efficient influence function, and are applicable in various sampling scenarios, including random sampling, outcome-based sampling, and exposure-based sampling. Through real data and simulations, we demonstrate the practicality and effectiveness of our proposed estimators in measuring the AAA.",
        "bibtex": "@InProceedings{pmlr-v206-jun23a,\n  title = \t {Average Adjusted Association: Efficient Estimation with High Dimensional Confounders},\n  author =       {Jun, Sung Jae and Lee, Sokbae},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5980--5996},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jun23a/jun23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jun23a.html},\n  abstract = \t {The log odds ratio is a well-established metric for evaluating the association between binary outcome and exposure variables. Despite its widespread use, there has been limited discussion on how to summarize the log odds ratio as a function of confounders through averaging. To address this issue, we propose the Average Adjusted Association (AAA), which is a summary measure of association in a heterogeneous population, adjusted for observed confounders. To facilitate the use of it, we also develop efficient double/debiased machine learning (DML) estimators of the AAA. Our DML estimators use two equivalent forms of the efficient influence function, and are applicable in various sampling scenarios, including random sampling, outcome-based sampling, and exposure-based sampling. Through real data and simulations, we demonstrate the practicality and effectiveness of our proposed estimators in measuring the AAA.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jun23a/jun23a.pdf",
        "supp": "",
        "pdf_size": 267053,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9289363301050995116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Economics, Pennsylvania State University, University Park, PA 16802, USA; Department of Economics, Columbia University, New York, NY, 10027, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Pennsylvania State University;Columbia University",
        "aff_unique_dep": "Department of Economics;Department of Economics",
        "aff_unique_url": "https://www.psu.edu;https://www.columbia.edu",
        "aff_unique_abbr": "PSU;Columbia",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "University Park;New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "426274cd0b",
        "title": "Average case analysis of Lasso under ultra sparse conditions",
        "site": "https://proceedings.mlr.press/v206/okajima23a.html",
        "author": "Koki Okajima; Xiangming Meng; Takashi Takahashi; Yoshiyuki Kabashima",
        "abstract": "We analyze the performance of the least absolute shrinkage and selection operator (Lasso) for the linear model when the number of regressors $N$ grows larger keeping the true support size $d$ finite, i.e., the ultra-sparse case. The result is based on a novel treatment of the non-rigorous replica method in statistical physics, which has been applied only to problem settings where $N$, $d$ and the number of observations $M$ tend to infinity at the same rate. Our analysis makes it possible to assess the average performance of Lasso with Gaussian sensing matrices without assumptions on the scaling of $N$ and $M$, the noise distribution, and the profile of the true signal. Under mild conditions on the noise distribution, the analysis also offers a lower bound on the sample complexity necessary for partial and perfect support recovery when $M$ diverges as $M = O(\\log N)$. The obtained bound for perfect support recovery is a generalization of that given in previous literature, which only considers the case of Gaussian noise and diverging $d$. Extensive numerical experiments strongly support our analysis.",
        "bibtex": "@InProceedings{pmlr-v206-okajima23a,\n  title = \t {Average case analysis of Lasso under ultra sparse conditions},\n  author =       {Okajima, Koki and Meng, Xiangming and Takahashi, Takashi and Kabashima, Yoshiyuki},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11317--11330},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/okajima23a/okajima23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/okajima23a.html},\n  abstract = \t {We analyze the performance of the least absolute shrinkage and selection operator (Lasso) for the linear model when the number of regressors $N$ grows larger keeping the true support size $d$ finite, i.e., the ultra-sparse case. The result is based on a novel treatment of the non-rigorous replica method in statistical physics, which has been applied only to problem settings where $N$, $d$ and the number of observations $M$ tend to infinity at the same rate. Our analysis makes it possible to assess the average performance of Lasso with Gaussian sensing matrices without assumptions on the scaling of $N$ and $M$, the noise distribution, and the profile of the true signal. Under mild conditions on the noise distribution, the analysis also offers a lower bound on the sample complexity necessary for partial and perfect support recovery when $M$ diverges as $M = O(\\log N)$. The obtained bound for perfect support recovery is a generalization of that given in previous literature, which only considers the case of Gaussian noise and diverging $d$. Extensive numerical experiments strongly support our analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/okajima23a/okajima23a.pdf",
        "supp": "",
        "pdf_size": 309595,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1096760534490936495&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1717443f2a",
        "title": "BaCaDI: Bayesian Causal Discovery with Unknown Interventions",
        "site": "https://proceedings.mlr.press/v206/hagele23a.html",
        "author": "Alexander H\u00e4gele; Jonas Rothfuss; Lars Lorch; Vignesh Ram Somnath; Bernhard Sch\u00f6lkopf; Andreas Krause",
        "abstract": "Inferring causal structures from experimentation is a central task in many domains. For example, in biology, recent advances allow us to obtain single-cell expression data under multiple interventions such as drugs or gene knockouts. However, the targets of the interventions are often uncertain or unknown and the number of observations limited. As a result, standard causal discovery methods can no longer be reliably used. To fill this gap, we propose a Bayesian framework (BaCaDI) for discovering and reasoning about the causal structure that underlies data generated under various unknown experimental or interventional conditions. BaCaDI is fully differentiable, which allows us to infer the complex joint posterior over the intervention targets and the causal structure via efficient gradient-based variational inference. In experiments on synthetic causal discovery tasks and simulated gene-expression data, BaCaDI outperforms related methods in identifying causal structures and intervention targets.",
        "bibtex": "@InProceedings{pmlr-v206-hagele23a,\n  title = \t {BaCaDI: Bayesian Causal Discovery with Unknown Interventions},\n  author =       {H\\\"agele, Alexander and Rothfuss, Jonas and Lorch, Lars and Somnath, Vignesh Ram and Sch\\\"olkopf, Bernhard and Krause, Andreas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1411--1436},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hagele23a/hagele23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hagele23a.html},\n  abstract = \t {Inferring causal structures from experimentation is a central task in many domains. For example, in biology, recent advances allow us to obtain single-cell expression data under multiple interventions such as drugs or gene knockouts. However, the targets of the interventions are often uncertain or unknown and the number of observations limited. As a result, standard causal discovery methods can no longer be reliably used. To fill this gap, we propose a Bayesian framework (BaCaDI) for discovering and reasoning about the causal structure that underlies data generated under various unknown experimental or interventional conditions. BaCaDI is fully differentiable, which allows us to infer the complex joint posterior over the intervention targets and the causal structure via efficient gradient-based variational inference. In experiments on synthetic causal discovery tasks and simulated gene-expression data, BaCaDI outperforms related methods in identifying causal structures and intervention targets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hagele23a/hagele23a.pdf",
        "supp": "",
        "pdf_size": 799769,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12327218189310353013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, ETH Z\u00fcrich, Switzerland; Department of Computer Science, ETH Z\u00fcrich, Switzerland; Department of Computer Science, ETH Z\u00fcrich, Switzerland; Department of Computer Science, ETH Z\u00fcrich, Switzerland + IBM Research Z\u00fcrich, Switzerland; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany + Department of Computer Science, ETH Z\u00fcrich, Switzerland; Department of Computer Science, ETH Z\u00fcrich, Switzerland",
        "aff_domain": "ethz.ch; ; ; ; ; ",
        "email": "ethz.ch; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0+1;2+0;0",
        "aff_unique_norm": "ETH Zurich;IBM;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Department of Computer Science;IBM Research;",
        "aff_unique_url": "https://www.ethz.ch;https://www.ibm.com/research;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "ETHZ;IBM;MPI-IS",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Z\u00fcrich;T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0+0;1+0;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "1c21c21349",
        "title": "Balanced Off-Policy Evaluation for Personalized Pricing",
        "site": "https://proceedings.mlr.press/v206/elmachtoub23a.html",
        "author": "Adam Elmachtoub; Vishal Gupta; Yunfan Zhao",
        "abstract": "We consider a personalized pricing problem in which we have data consisting of feature information, historical pricing decisions, and binary realized demand. The goal is to perform off-policy evaluation for a new personalized pricing policy that maps features to prices. Methods based on inverse propensity weighting (including doubly robust methods) for off-policy evaluation may perform poorly when the logging policy has little exploration or is deterministic, which is common in pricing applications. Building on the balanced policy evaluation framework of Kallus (2018), we propose a new approach tailored to pricing applications. The key idea is to compute an estimate that minimizes the worst-case mean squared error or maximizes a worst-case lower bound on policy performance, where in both cases the worst-case is taken with respect to a set of possible revenue functions. We establish theoretical convergence guarantees and empirically demonstrate the advantage of our approach using a real-world pricing dataset.",
        "bibtex": "@InProceedings{pmlr-v206-elmachtoub23a,\n  title = \t {Balanced Off-Policy Evaluation for Personalized Pricing},\n  author =       {Elmachtoub, Adam and Gupta, Vishal and Zhao, Yunfan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10901--10917},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/elmachtoub23a/elmachtoub23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/elmachtoub23a.html},\n  abstract = \t {We consider a personalized pricing problem in which we have data consisting of feature information, historical pricing decisions, and binary realized demand. The goal is to perform off-policy evaluation for a new personalized pricing policy that maps features to prices. Methods based on inverse propensity weighting (including doubly robust methods) for off-policy evaluation may perform poorly when the logging policy has little exploration or is deterministic, which is common in pricing applications. Building on the balanced policy evaluation framework of Kallus (2018), we propose a new approach tailored to pricing applications. The key idea is to compute an estimate that minimizes the worst-case mean squared error or maximizes a worst-case lower bound on policy performance, where in both cases the worst-case is taken with respect to a set of possible revenue functions. We establish theoretical convergence guarantees and empirically demonstrate the advantage of our approach using a real-world pricing dataset.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/elmachtoub23a/elmachtoub23a.pdf",
        "supp": "",
        "pdf_size": 374673,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15833887965758187812&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "162c682b0e",
        "title": "Barlow Graph Auto-Encoder for Unsupervised Network Embedding",
        "site": "https://proceedings.mlr.press/v206/khan23a.html",
        "author": "Rayyan Ahmad Khan; Martin Kleinsteuber",
        "abstract": "Network embedding has emerged as a promising research field for network analysis. Recently, an approach, named Barlow Twins, has been proposed for self-supervised learning in computer vision by applying the redundancy-reduction principle to the embedding vectors corresponding to two distorted versions of the image samples. Motivated by this, we propose Barlow Graph Auto-Encoder, a simple yet effective architecture for learning network embedding. It aims to maximize the similarity between the embedding vectors of immediate and larger neighborhoods of a node while minimizing the redundancy between the components of these projections. In addition, we also present the variational counterpart named Barlow Variational Graph Auto-Encoder. We demonstrate the effectiveness of our approach in learning multiple graph-related tasks, i.e., link prediction, clustering, and downstream node classification, by providing extensive comparisons with several well-known techniques on eight benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v206-khan23a,\n  title = \t {Barlow Graph Auto-Encoder for Unsupervised Network Embedding},\n  author =       {Khan, Rayyan Ahmad and Kleinsteuber, Martin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {306--322},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/khan23a/khan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/khan23a.html},\n  abstract = \t {Network embedding has emerged as a promising research field for network analysis. Recently, an approach, named Barlow Twins, has been proposed for self-supervised learning in computer vision by applying the redundancy-reduction principle to the embedding vectors corresponding to two distorted versions of the image samples. Motivated by this, we propose Barlow Graph Auto-Encoder, a simple yet effective architecture for learning network embedding. It aims to maximize the similarity between the embedding vectors of immediate and larger neighborhoods of a node while minimizing the redundancy between the components of these projections. In addition, we also present the variational counterpart named Barlow Variational Graph Auto-Encoder. We demonstrate the effectiveness of our approach in learning multiple graph-related tasks, i.e., link prediction, clustering, and downstream node classification, by providing extensive comparisons with several well-known techniques on eight benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/khan23a/khan23a.pdf",
        "supp": "",
        "pdf_size": 686567,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11508597341501078120&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Unite Network SE, Germany + TU Munich, Germany; Unite Network SE, Germany + TU Munich, Germany",
        "aff_domain": "tum.de;unite.eu",
        "email": "tum.de;unite.eu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Unite Network SE;Technical University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.tum.de",
        "aff_unique_abbr": ";TUM",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "7db82ee8b2",
        "title": "Bayesian Convolutional Deep Sets with Task-Dependent Stationary Prior",
        "site": "https://proceedings.mlr.press/v206/jung23a.html",
        "author": "Yohan Jung; Jinkyoo Park",
        "abstract": "Convolutional deep sets is a neural network architecture that can model stationary stochastic processes. This architecture uses the kernel smoother and deep convolutional neural network to construct translation equivariant functional representations. However, the non-parametric nature of the kernel smoother can produce ambiguous representations when the number of data points is not given sufficiently. To address this issue, we introduce bayesian convolutional deep sets, which constructs random translation equivariant functional representations with a stationary prior. Furthermore, we present how to impose the task-dependent prior for each dataset because a wrongly imposed prior can result in an even worse representation than that of the kernel smoother. Empirically, we demonstrate that the proposed architecture alleviates the targeted issue in various experiments with time-series and image datasets.",
        "bibtex": "@InProceedings{pmlr-v206-jung23a,\n  title = \t {Bayesian Convolutional Deep Sets with Task-Dependent Stationary Prior},\n  author =       {Jung, Yohan and Park, Jinkyoo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3795--3824},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jung23a/jung23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jung23a.html},\n  abstract = \t {Convolutional deep sets is a neural network architecture that can model stationary stochastic processes. This architecture uses the kernel smoother and deep convolutional neural network to construct translation equivariant functional representations. However, the non-parametric nature of the kernel smoother can produce ambiguous representations when the number of data points is not given sufficiently. To address this issue, we introduce bayesian convolutional deep sets, which constructs random translation equivariant functional representations with a stationary prior. Furthermore, we present how to impose the task-dependent prior for each dataset because a wrongly imposed prior can result in an even worse representation than that of the kernel smoother. Empirically, we demonstrate that the proposed architecture alleviates the targeted issue in various experiments with time-series and image datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jung23a/jung23a.pdf",
        "supp": "",
        "pdf_size": 3377331,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:gPVMb8B9MdwJ:scholar.google.com/&scioq=Bayesian+Convolutional+Deep+Sets+with+Task-Dependent+Stationary+Prior&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "a00de33e53",
        "title": "Bayesian Hierarchical Models for Counterfactual Estimation",
        "site": "https://proceedings.mlr.press/v206/raman23a.html",
        "author": "Natraj Raman; Daniele Magazzeni; Sameena Shah",
        "abstract": "Counterfactual explanations utilize feature perturbations to analyze the outcome of an original decision and recommend an actionable recourse. We argue that it is beneficial to provide several alternative explanations rather than a single point solution and propose a probabilistic paradigm to estimate a diverse set of counterfactuals. Specifically, we treat the perturbations as random variables endowed with prior distribution functions. This allows sampling multiple counterfactuals from the posterior density, with the added benefit of incorporating inductive biases, preserving domain specific constraints and quantifying uncertainty in estimates. More importantly, we leverage Bayesian hierarchical modeling to share information across different subgroups of a population, which can both improve robustness and measure fairness. A gradient based sampler with superior convergence characteristics efficiently computes the posterior samples. Experiments across several datasets demonstrate that the counterfactuals estimated using our approach are valid, sparse, diverse and feasible.",
        "bibtex": "@InProceedings{pmlr-v206-raman23a,\n  title = \t {Bayesian Hierarchical Models for Counterfactual Estimation},\n  author =       {Raman, Natraj and Magazzeni, Daniele and Shah, Sameena},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1115--1128},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/raman23a/raman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/raman23a.html},\n  abstract = \t {Counterfactual explanations utilize feature perturbations to analyze the outcome of an original decision and recommend an actionable recourse. We argue that it is beneficial to provide several alternative explanations rather than a single point solution and propose a probabilistic paradigm to estimate a diverse set of counterfactuals. Specifically, we treat the perturbations as random variables endowed with prior distribution functions. This allows sampling multiple counterfactuals from the posterior density, with the added benefit of incorporating inductive biases, preserving domain specific constraints and quantifying uncertainty in estimates. More importantly, we leverage Bayesian hierarchical modeling to share information across different subgroups of a population, which can both improve robustness and measure fairness. A gradient based sampler with superior convergence characteristics efficiently computes the posterior samples. Experiments across several datasets demonstrate that the counterfactuals estimated using our approach are valid, sparse, diverse and feasible.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/raman23a/raman23a.pdf",
        "supp": "",
        "pdf_size": 724826,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10510902550774716596&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8c611c85f0",
        "title": "Bayesian Optimization Over Iterative Learners with Structured Responses: A Budget-aware Planning Approach",
        "site": "https://proceedings.mlr.press/v206/belakaria23a.html",
        "author": "Syrine Belakaria; Janardhan Rao Doppa; Nicolo Fusi; Rishit Sheth",
        "abstract": "The rising growth of deep neural networks (DNNs) and datasets in size motivates the need for efficient solutions for simultaneous model selection and training. Many methods for hyperparameter optimization (HPO) of iterative learners, including DNNs, attempt to solve this problem by querying and learning a response surface while searching for the optimum of that surface. However, many of these methods make myopic queries, do not consider prior knowledge about the response structure, and/or perform a biased cost-aware search, all of which exacerbate identifying the best-performing model when a total cost budget is specified. This paper proposes a novel approach referred to as Budget-Aware Planning for Iterative Learners (BAPI) to solve HPO problems under a constrained cost budget. BAPI is an efficient non-myopic Bayesian optimization solution that accounts for the budget and leverages the prior knowledge about the objective function and cost function to select better configurations and to take more informed decisions during the evaluation (training). Experiments on diverse HPO benchmarks for iterative learners show that BAPI performs better than state-of-the-art baselines in most cases.",
        "bibtex": "@InProceedings{pmlr-v206-belakaria23a,\n  title = \t {Bayesian Optimization Over Iterative Learners with Structured Responses: A Budget-aware Planning Approach},\n  author =       {Belakaria, Syrine and Doppa, Janardhan Rao and Fusi, Nicolo and Sheth, Rishit},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9076--9093},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/belakaria23a/belakaria23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/belakaria23a.html},\n  abstract = \t {The rising growth of deep neural networks (DNNs) and datasets in size motivates the need for efficient solutions for simultaneous model selection and training. Many methods for hyperparameter optimization (HPO) of iterative learners, including DNNs, attempt to solve this problem by querying and learning a response surface while searching for the optimum of that surface. However, many of these methods make myopic queries, do not consider prior knowledge about the response structure, and/or perform a biased cost-aware search, all of which exacerbate identifying the best-performing model when a total cost budget is specified. This paper proposes a novel approach referred to as Budget-Aware Planning for Iterative Learners (BAPI) to solve HPO problems under a constrained cost budget. BAPI is an efficient non-myopic Bayesian optimization solution that accounts for the budget and leverages the prior knowledge about the objective function and cost function to select better configurations and to take more informed decisions during the evaluation (training). Experiments on diverse HPO benchmarks for iterative learners show that BAPI performs better than state-of-the-art baselines in most cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/belakaria23a/belakaria23a.pdf",
        "supp": "",
        "pdf_size": 3561178,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7635714177043482814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "854d4d3493",
        "title": "Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings",
        "site": "https://proceedings.mlr.press/v206/deshwal23a.html",
        "author": "Aryan Deshwal; Sebastian Ament; Maximilian Balandat; Eytan Bakshy; Janardhan Rao Doppa; David Eriksson",
        "abstract": "We consider the problem of optimizing expensive black-box functions over high-dimensional combinatorial spaces which arises in many science, engineering, and ML applications. We use Bayesian Optimization (BO) and propose a novel surrogate modeling approach for efficiently handling a large number of binary and categorical parameters. The key idea is to select a number of discrete structures from the input space (the dictionary) and use them to define an ordinal embedding for high-dimensional combinatorial structures. This allows us to use existing Gaussian process models for continuous spaces. We develop a principled approach based on binary wavelets to construct dictionaries for binary spaces, and propose a randomized construction method that generalizes to categorical spaces. We provide theoretical justification to support the effectiveness of the dictionary-based embeddings. Our experiments on diverse real-world benchmarks demonstrate the effectiveness of our proposed surrogate modeling approach over state-of-the-art BO methods.",
        "bibtex": "@InProceedings{pmlr-v206-deshwal23a,\n  title = \t {Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings},\n  author =       {Deshwal, Aryan and Ament, Sebastian and Balandat, Maximilian and Bakshy, Eytan and Doppa, Janardhan Rao and Eriksson, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7021--7039},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/deshwal23a/deshwal23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/deshwal23a.html},\n  abstract = \t {We consider the problem of optimizing expensive black-box functions over high-dimensional combinatorial spaces which arises in many science, engineering, and ML applications. We use Bayesian Optimization (BO) and propose a novel surrogate modeling approach for efficiently handling a large number of binary and categorical parameters. The key idea is to select a number of discrete structures from the input space (the dictionary) and use them to define an ordinal embedding for high-dimensional combinatorial structures. This allows us to use existing Gaussian process models for continuous spaces. We develop a principled approach based on binary wavelets to construct dictionaries for binary spaces, and propose a randomized construction method that generalizes to categorical spaces. We provide theoretical justification to support the effectiveness of the dictionary-based embeddings. Our experiments on diverse real-world benchmarks demonstrate the effectiveness of our proposed surrogate modeling approach over state-of-the-art BO methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/deshwal23a/deshwal23a.pdf",
        "supp": "",
        "pdf_size": 1468102,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3009529588623744223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Washington State University; Meta; Meta; Meta; Washington State University; Meta",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "Washington State University;Meta",
        "aff_unique_dep": ";Meta Platforms, Inc.",
        "aff_unique_url": "https://wsu.edu;https://meta.com",
        "aff_unique_abbr": "WSU;Meta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6e6d80e8c6",
        "title": "Bayesian Optimization with Conformal Prediction Sets",
        "site": "https://proceedings.mlr.press/v206/stanton23a.html",
        "author": "Samuel Stanton; Wesley Maddox; Andrew Gordon Wilson",
        "abstract": "Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we find that query coverage can be significantly improved without harming sample-efficiency.",
        "bibtex": "@InProceedings{pmlr-v206-stanton23a,\n  title = \t {Bayesian Optimization with Conformal Prediction Sets},\n  author =       {Stanton, Samuel and Maddox, Wesley and Wilson, Andrew Gordon},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {959--986},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/stanton23a/stanton23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/stanton23a.html},\n  abstract = \t {Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we find that query coverage can be significantly improved without harming sample-efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/stanton23a/stanton23a.pdf",
        "supp": "",
        "pdf_size": 1976514,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11277357743222910055&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Prescient Design, Genentech+New York University; New York University; New York University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1",
        "aff_unique_norm": "Genentech;New York University",
        "aff_unique_dep": "Prescient Design;",
        "aff_unique_url": "https://www.gene.com;https://www.nyu.edu",
        "aff_unique_abbr": "Genentech;NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9ddf19a0fd",
        "title": "Bayesian Strategy-Proof Facility Location via Robust Estimation",
        "site": "https://proceedings.mlr.press/v206/zampetakis23a.html",
        "author": "Emmanouil Zampetakis; Fred Zhang",
        "abstract": "A seminal work by Moulin (1980) shows that the median voting scheme fully characterizes (deterministic) strategy-proof facility location mechanism for single-peaked preferences. In this simple setting, median also achieves the optimal social cost. In $d$ dimensions, strategy-proof mechanism is characterized by coordinate-wise median, which is known to have a large $\\sqrt{d}$ approximation ratio of the social cost in the Euclidean space, whereas the socially optimal mechanism fails at being strategy-proof. In light of the negative results in the classic, worst-case setting, we initiate the study of Bayesian mechanism design for strategy-proof facility location for multi-dimensional Euclidean preferences, where the agents\u2019 preferences are drawn from a distribution. We approach the problem via connections to algorithmic high-dimensional robust statistics. Specially, our contributions are the following: * We provide a general reduction from any robust estimation scheme to Bayesian approximately strategy-proof mechanism. This leads to new strategy-proof mechanisms for Gaussian and bounded moment distributions, by leveraging recent advances in robust statistics. * We show that the Lugosi-Mendelson median arising from heavy-tailed statistics can be used to obtain Bayesian approximately strategy-proof single-facility mechanism with asymptotically optimal social cost, under mild distributional assumptions. * We provide Bayesian approximately strategy-proof multi-facility mechanisms for Gaussian mixture distributions with nearly optimal social cost.",
        "bibtex": "@InProceedings{pmlr-v206-zampetakis23a,\n  title = \t {Bayesian Strategy-Proof Facility Location via Robust Estimation},\n  author =       {Zampetakis, Emmanouil and Zhang, Fred},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4196--4208},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zampetakis23a/zampetakis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zampetakis23a.html},\n  abstract = \t {A seminal work by Moulin (1980) shows that the median voting scheme fully characterizes (deterministic) strategy-proof facility location mechanism for single-peaked preferences. In this simple setting, median also achieves the optimal social cost. In $d$ dimensions, strategy-proof mechanism is characterized by coordinate-wise median, which is known to have a large $\\sqrt{d}$ approximation ratio of the social cost in the Euclidean space, whereas the socially optimal mechanism fails at being strategy-proof. In light of the negative results in the classic, worst-case setting, we initiate the study of Bayesian mechanism design for strategy-proof facility location for multi-dimensional Euclidean preferences, where the agents\u2019 preferences are drawn from a distribution. We approach the problem via connections to algorithmic high-dimensional robust statistics. Specially, our contributions are the following: * We provide a general reduction from any robust estimation scheme to Bayesian approximately strategy-proof mechanism. This leads to new strategy-proof mechanisms for Gaussian and bounded moment distributions, by leveraging recent advances in robust statistics. * We show that the Lugosi-Mendelson median arising from heavy-tailed statistics can be used to obtain Bayesian approximately strategy-proof single-facility mechanism with asymptotically optimal social cost, under mild distributional assumptions. * We provide Bayesian approximately strategy-proof multi-facility mechanisms for Gaussian mixture distributions with nearly optimal social cost.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zampetakis23a/zampetakis23a.pdf",
        "supp": "",
        "pdf_size": 296159,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8094122989688319853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "UC Berkeley; UC Berkeley",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b76a60c838",
        "title": "Bayesian Structure Scores for Probabilistic Circuits",
        "site": "https://proceedings.mlr.press/v206/yang23a.html",
        "author": "Yang Yang; Gennaro Gala; Robert Peharz",
        "abstract": "Probabilistic circuits (PCs) are a prominent representation of probability distributions with tractable inference. While parameter learning in PCs is rigorously studied, structure learning is often more based on heuristics than on principled objectives. In this paper, we develop Bayesian structure scores for deterministic PCs, i.e., the structure likelihood with parameters marginalized out, which are well known as rigorous objectives for structure learning in probabilistic graphical models. When used within a greedy cutset algorithm, our scores effectively protect against overfitting and yield a fast and almost hyper-parameter-free structure learner, distinguishing it from previous approaches. In experiments, we achieve good trade-offs between training time and model fit in terms of log-likelihood. Moreover, the principled nature of Bayesian scores unlocks PCs for accommodating frameworks such as structural expectation-maximization.",
        "bibtex": "@InProceedings{pmlr-v206-yang23a,\n  title = \t {Bayesian Structure Scores for Probabilistic Circuits},\n  author =       {Yang, Yang and Gala, Gennaro and Peharz, Robert},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {563--575},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23a/yang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23a.html},\n  abstract = \t {Probabilistic circuits (PCs) are a prominent representation of probability distributions with tractable inference. While parameter learning in PCs is rigorously studied, structure learning is often more based on heuristics than on principled objectives. In this paper, we develop Bayesian structure scores for deterministic PCs, i.e., the structure likelihood with parameters marginalized out, which are well known as rigorous objectives for structure learning in probabilistic graphical models. When used within a greedy cutset algorithm, our scores effectively protect against overfitting and yield a fast and almost hyper-parameter-free structure learner, distinguishing it from previous approaches. In experiments, we achieve good trade-offs between training time and model fit in terms of log-likelihood. Moreover, the principled nature of Bayesian scores unlocks PCs for accommodating frameworks such as structural expectation-maximization.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23a/yang23a.pdf",
        "supp": "",
        "pdf_size": 489972,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14710181705885159379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3a0fead8e5",
        "title": "Bayesian Variable Selection in a Million Dimensions",
        "site": "https://proceedings.mlr.press/v206/jankowiak23a.html",
        "author": "Martin Jankowiak",
        "abstract": "Bayesian variable selection is a powerful tool for data analysis, as it offers a principled method for variable selection that accounts for prior information and uncertainty. However, wider adoption of Bayesian variable selection has been hampered by computational challenges, especially in difficult regimes with a large number of covariates P or non-conjugate likelihoods. To scale to the large P regime we introduce an efficient Markov Chain Monte Carlo scheme whose cost per iteration is sublinear in P (though linear in the number of data points). In addition we show how this scheme can be extended to generalized linear models for count data, which are prevalent in biology, ecology, economics, and beyond. In particular we design efficient algorithms for variable selection in binomial and negative binomial regression, which includes logistic regression as a special case. In experiments we demonstrate the effectiveness of our methods, including on cancer and maize genomic data.",
        "bibtex": "@InProceedings{pmlr-v206-jankowiak23a,\n  title = \t {Bayesian Variable Selection in a Million Dimensions},\n  author =       {Jankowiak, Martin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {253--282},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jankowiak23a/jankowiak23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jankowiak23a.html},\n  abstract = \t {Bayesian variable selection is a powerful tool for data analysis, as it offers a principled method for variable selection that accounts for prior information and uncertainty. However, wider adoption of Bayesian variable selection has been hampered by computational challenges, especially in difficult regimes with a large number of covariates P or non-conjugate likelihoods. To scale to the large P regime we introduce an efficient Markov Chain Monte Carlo scheme whose cost per iteration is sublinear in P (though linear in the number of data points). In addition we show how this scheme can be extended to generalized linear models for count data, which are prevalent in biology, ecology, economics, and beyond. In particular we design efficient algorithms for variable selection in binomial and negative binomial regression, which includes logistic regression as a special case. In experiments we demonstrate the effectiveness of our methods, including on cancer and maize genomic data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jankowiak23a/jankowiak23a.pdf",
        "supp": "",
        "pdf_size": 8768013,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12303417779796219517&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "https://github.com/BasisResearch/millipede",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "53ececfd7b",
        "title": "Benign overfitting of non-smooth neural networks beyond lazy training",
        "site": "https://proceedings.mlr.press/v206/xu23k.html",
        "author": "Xingyu Xu; Yuantao Gu",
        "abstract": "Benign overfitting refers to a recently discovered intriguing phenomenon that over-parameterized neural networks, in many cases, can fit the training data perfectly but still generalize well, surprisingly contrary to the traditional belief that overfitting is harmful for generalization. In spite of its surging popularity in recent years, little has been known in the theoretical aspect of benign overfitting of neural networks. In this work, we provide a theoretical analysis of benign overfitting for two-layer neural networks with possibly non-smooth activation function. Without resorting to the popular Neural Tangent Kernel (NTK) approximation, we prove that neural networks can be trained with gradient descent to classify binary-labeled training data perfectly (achieving zero training loss) even in presence of polluted labels, but still generalize well. Our result removes the smoothness assumption in previous literature and goes beyond the NTK regime; this enables a better theoretical understanding of benign overfitting within a practically more meaningful setting, e.g., with (leaky-)ReLU activation function, small random initialization, and finite network width.",
        "bibtex": "@InProceedings{pmlr-v206-xu23k,\n  title = \t {Benign overfitting of non-smooth neural networks beyond lazy training},\n  author =       {Xu, Xingyu and Gu, Yuantao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11094--11117},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23k/xu23k.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23k.html},\n  abstract = \t {Benign overfitting refers to a recently discovered intriguing phenomenon that over-parameterized neural networks, in many cases, can fit the training data perfectly but still generalize well, surprisingly contrary to the traditional belief that overfitting is harmful for generalization. In spite of its surging popularity in recent years, little has been known in the theoretical aspect of benign overfitting of neural networks. In this work, we provide a theoretical analysis of benign overfitting for two-layer neural networks with possibly non-smooth activation function. Without resorting to the popular Neural Tangent Kernel (NTK) approximation, we prove that neural networks can be trained with gradient descent to classify binary-labeled training data perfectly (achieving zero training loss) even in presence of polluted labels, but still generalize well. Our result removes the smoothness assumption in previous literature and goes beyond the NTK regime; this enables a better theoretical understanding of benign overfitting within a practically more meaningful setting, e.g., with (leaky-)ReLU activation function, small random initialization, and finite network width.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23k/xu23k.pdf",
        "supp": "",
        "pdf_size": 409891,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11648803460350517517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Tsinghua University; Tsinghua University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "a985dbe8b6",
        "title": "Beyond Performative Prediction: Open-environment Learning with Presence of Corruptions",
        "site": "https://proceedings.mlr.press/v206/shan23a.html",
        "author": "Jia-Wei Shan; Peng Zhao; Zhi-Hua Zhou",
        "abstract": "Performative prediction is a framework to capture the endogenous distribution changes resulting from the reactions of deployed environments to the learner\u2019s decision. Existing results require that the collected data are sampled from the clean observed distribution. However, this is often not the case in real-world applications, and even worse, data collected in open environments may include corruption due to various undesirable factors. In this paper, we study the entanglement of endogenous distribution change and corruption in open environments, where data are obtained from a corrupted decision-dependent distribution. The central challenge in this problem is the entangling effects between changing distributions and corruptions, which impede the use of effective gradient-based updates. To overcome this difficulty, we propose a novel recursive formula that decouples the two sources of effects, which allows us to further exploit suitable techniques for handling two decoupled effects and obtaining favorable guarantees. Theoretically, we prove that our proposed algorithm converges to the desired solution under corrupted observations, and simultaneously it can retain a competitive rate in the uncorrupted case. Experimental results also support our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v206-shan23a,\n  title = \t {Beyond Performative Prediction: Open-environment Learning with Presence of Corruptions},\n  author =       {Shan, Jia-Wei and Zhao, Peng and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7981--7998},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shan23a/shan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shan23a.html},\n  abstract = \t {Performative prediction is a framework to capture the endogenous distribution changes resulting from the reactions of deployed environments to the learner\u2019s decision. Existing results require that the collected data are sampled from the clean observed distribution. However, this is often not the case in real-world applications, and even worse, data collected in open environments may include corruption due to various undesirable factors. In this paper, we study the entanglement of endogenous distribution change and corruption in open environments, where data are obtained from a corrupted decision-dependent distribution. The central challenge in this problem is the entangling effects between changing distributions and corruptions, which impede the use of effective gradient-based updates. To overcome this difficulty, we propose a novel recursive formula that decouples the two sources of effects, which allows us to further exploit suitable techniques for handling two decoupled effects and obtaining favorable guarantees. Theoretically, we prove that our proposed algorithm converges to the desired solution under corrupted observations, and simultaneously it can retain a competitive rate in the uncorrupted case. Experimental results also support our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shan23a/shan23a.pdf",
        "supp": "",
        "pdf_size": 1012547,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3923593265442046306&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "aff_domain": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "email": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "712426ea5a",
        "title": "Blessing of Class Diversity in Pre-training",
        "site": "https://proceedings.mlr.press/v206/zhao23a.html",
        "author": "Yulai Zhao; Jianshu Chen; Simon Du",
        "abstract": "This paper presents a new statistical analysis aiming to explain the recent superior achievements of the pre-training techniques in natural language processing (NLP). We prove that when the classes of the pre-training task (e.g., different words in the masked language model task) are sufficiently diverse, in the sense that the least singular value of the last linear layer in pre-training (denoted as $\\tilde{\\nu}$) is large, then pre-training can significantly improve the sample efficiency of downstream tasks. Specially, we show the transfer learning excess risk enjoys an $O\\left(\\frac{1}{\\tilde{\\nu} \\sqrt{n}}\\right)$ rate, in contrast to the $O\\left(\\frac{1}{\\sqrt{m}}\\right)$ rate in the standard supervised learning. Here, $n$ is the number of pre-training data and $m$ is the number of data in the downstream task, and typically $n \\gg m$. Our proof relies on a vector-form Rademacher complexity chain rule for disassembling composite function classes and a modified self-concordance condition. These techniques can be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v206-zhao23a,\n  title = \t {Blessing of Class Diversity in Pre-training},\n  author =       {Zhao, Yulai and Chen, Jianshu and Du, Simon},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {283--305},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhao23a/zhao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhao23a.html},\n  abstract = \t {This paper presents a new statistical analysis aiming to explain the recent superior achievements of the pre-training techniques in natural language processing (NLP). We prove that when the classes of the pre-training task (e.g., different words in the masked language model task) are sufficiently diverse, in the sense that the least singular value of the last linear layer in pre-training (denoted as $\\tilde{\\nu}$) is large, then pre-training can significantly improve the sample efficiency of downstream tasks. Specially, we show the transfer learning excess risk enjoys an $O\\left(\\frac{1}{\\tilde{\\nu} \\sqrt{n}}\\right)$ rate, in contrast to the $O\\left(\\frac{1}{\\sqrt{m}}\\right)$ rate in the standard supervised learning. Here, $n$ is the number of pre-training data and $m$ is the number of data in the downstream task, and typically $n \\gg m$. Our proof relies on a vector-form Rademacher complexity chain rule for disassembling composite function classes and a modified self-concordance condition. These techniques can be of independent interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhao23a/zhao23a.pdf",
        "supp": "",
        "pdf_size": 395607,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5036162941136586381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Princeton University; Tencent AI Lab; University of Washington",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Tencent;University of Washington",
        "aff_unique_dep": ";Tencent AI Lab;",
        "aff_unique_url": "https://www.princeton.edu;https://ai.tencent.com;https://www.washington.edu",
        "aff_unique_abbr": "Princeton;Tencent AI Lab;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "1b8e61ecc2",
        "title": "BlitzMask: Real-Time Instance Segmentation Approach for Mobile Devices",
        "site": "https://proceedings.mlr.press/v206/bulygin23a.html",
        "author": "Vitalii Bulygin; Dmytro Mykheievskyi; Kyrylo Kuchynskyi",
        "abstract": "We propose a fast and low complexity anchor-free instance segmentation approach BlitzMask. For the first time, the approach achieves competitive results for real-time inference on mobile devices. The model architecture modifies CenterNet by adding a new lite head to the CenterNet architecture. The model contains only layers optimized for inference on mobile devices, e.g. batch normalization, standard convolution, depthwise convolution, and can be easily embedded into a mobile device. The instance segmentation task requires finding an arbitrary (not a priori fixed) number of instance masks. The proposed method predicts the number of instance masks separately for each image using a predicted heatmap. Then, it decomposes each instance mask over a predicted spanning set, which is an output of the lite head. The approach uses training from scratch with a new optimization process and a new loss function. A model with EfficientNet-Lite B4 backbone and 320x320 input resolution achieves 28.9 mask AP at 29.2 fps on Samsung S21 GPU and 28.0 mask AP at 39.4 fps on Samsung S21 DSP. This sets a new speed benchmark for inference for instance segmentation on mobile devices.",
        "bibtex": "@InProceedings{pmlr-v206-bulygin23a,\n  title = \t {BlitzMask: Real-Time Instance Segmentation Approach for Mobile Devices},\n  author =       {Bulygin, Vitalii and Mykheievskyi, Dmytro and Kuchynskyi, Kyrylo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1799--1811},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bulygin23a/bulygin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bulygin23a.html},\n  abstract = \t {We propose a fast and low complexity anchor-free instance segmentation approach BlitzMask. For the first time, the approach achieves competitive results for real-time inference on mobile devices. The model architecture modifies CenterNet by adding a new lite head to the CenterNet architecture. The model contains only layers optimized for inference on mobile devices, e.g. batch normalization, standard convolution, depthwise convolution, and can be easily embedded into a mobile device. The instance segmentation task requires finding an arbitrary (not a priori fixed) number of instance masks. The proposed method predicts the number of instance masks separately for each image using a predicted heatmap. Then, it decomposes each instance mask over a predicted spanning set, which is an output of the lite head. The approach uses training from scratch with a new optimization process and a new loss function. A model with EfficientNet-Lite B4 backbone and 320x320 input resolution achieves 28.9 mask AP at 29.2 fps on Samsung S21 GPU and 28.0 mask AP at 39.4 fps on Samsung S21 DSP. This sets a new speed benchmark for inference for instance segmentation on mobile devices.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bulygin23a/bulygin23a.pdf",
        "supp": "",
        "pdf_size": 3546903,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5089528525966206798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1577ee169d",
        "title": "Boosted Off-Policy Learning",
        "site": "https://proceedings.mlr.press/v206/london23a.html",
        "author": "Ben London; Levi Lu; Ted Sandler; Thorsten Joachims",
        "abstract": "We propose the first boosting algorithm for off-policy learning from logged bandit feedback. Unlike existing boosting methods for supervised learning, our algorithm directly optimizes an estimate of the policy\u2019s expected reward. We analyze this algorithm and prove that the excess empirical risk decreases (possibly exponentially fast) with each round of boosting, provided a \u201cweak\u201d learning condition is satisfied by the base learner. We further show how to reduce the base learner to supervised learning, which opens up a broad range of readily available base learners with practical benefits, such as decision trees. Experiments indicate that our algorithm inherits many desirable properties of tree-based boosting algorithms (e.g., robustness to feature scaling and hyperparameter tuning), and that it can outperform off-policy learning with deep neural networks as well as methods that simply regress on the observed rewards.",
        "bibtex": "@InProceedings{pmlr-v206-london23a,\n  title = \t {Boosted Off-Policy Learning},\n  author =       {London, Ben and Lu, Levi and Sandler, Ted and Joachims, Thorsten},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5614--5640},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/london23a/london23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/london23a.html},\n  abstract = \t {We propose the first boosting algorithm for off-policy learning from logged bandit feedback. Unlike existing boosting methods for supervised learning, our algorithm directly optimizes an estimate of the policy\u2019s expected reward. We analyze this algorithm and prove that the excess empirical risk decreases (possibly exponentially fast) with each round of boosting, provided a \u201cweak\u201d learning condition is satisfied by the base learner. We further show how to reduce the base learner to supervised learning, which opens up a broad range of readily available base learners with practical benefits, such as decision trees. Experiments indicate that our algorithm inherits many desirable properties of tree-based boosting algorithms (e.g., robustness to feature scaling and hyperparameter tuning), and that it can outperform off-policy learning with deep neural networks as well as methods that simply regress on the observed rewards.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/london23a/london23a.pdf",
        "supp": "",
        "pdf_size": 827659,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2653892758244477437&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "497a367b57",
        "title": "Bounding Evidence and Estimating Log-Likelihood in VAE",
        "site": "https://proceedings.mlr.press/v206/struski23a.html",
        "author": "\u0141ukasz Struski; Marcin Mazur; Pawe\u0142 Batorski; Przemys\u0142aw Spurek; Jacek Tabor",
        "abstract": "Many crucial problems in deep learning and statistical inference are caused by a variational gap, i.e., a difference between model evidence (log-likelihood) and evidence lower bound (ELBO). In particular, in a classical VAE setting that involves training via an ELBO cost function, it is difficult to provide a robust comparison of the effects of training between models, since we do not know a log-likelihood of data (but only its lower bound). In this paper, to deal with this problem, we introduce a general and effective upper bound, which allows us to efficiently approximate the evidence of data. We provide extensive theoretical and experimental studies of our approach, including its comparison to the other state-of-the-art upper bounds, as well as its application as a tool for the evaluation of models that were trained on various lower bounds.",
        "bibtex": "@InProceedings{pmlr-v206-struski23a,\n  title = \t {Bounding Evidence and Estimating Log-Likelihood in VAE},\n  author =       {Struski, {\\L}ukasz and Mazur, Marcin and Batorski, Pawe{\\l} and Spurek, Przemys{\\l}aw and Tabor, Jacek},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5036--5051},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/struski23a/struski23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/struski23a.html},\n  abstract = \t {Many crucial problems in deep learning and statistical inference are caused by a variational gap, i.e., a difference between model evidence (log-likelihood) and evidence lower bound (ELBO). In particular, in a classical VAE setting that involves training via an ELBO cost function, it is difficult to provide a robust comparison of the effects of training between models, since we do not know a log-likelihood of data (but only its lower bound). In this paper, to deal with this problem, we introduce a general and effective upper bound, which allows us to efficiently approximate the evidence of data. We provide extensive theoretical and experimental studies of our approach, including its comparison to the other state-of-the-art upper bounds, as well as its application as a tool for the evaluation of models that were trained on various lower bounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/struski23a/struski23a.pdf",
        "supp": "",
        "pdf_size": 8406769,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=934334184970240362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Jagiellonian University, Faculty of Mathematics and Computer Science, Krak \u00b4ow, Poland; Jagiellonian University, Faculty of Mathematics and Computer Science, Krak \u00b4ow, Poland; Jagiellonian University, Faculty of Mathematics and Computer Science, Krak \u00b4ow, Poland; Jagiellonian University, Faculty of Mathematics and Computer Science, Krak \u00b4ow, Poland; Jagiellonian University, Faculty of Mathematics and Computer Science, Krak \u00b4ow, Poland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Jagiellonian University",
        "aff_unique_dep": "Faculty of Mathematics and Computer Science",
        "aff_unique_url": "https://www.uj.edu.pl",
        "aff_unique_abbr": "UJ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Krak\u00f3w",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "9049644949",
        "title": "Breaking a Classical Barrier for Classifying Arbitrary Test Examples in the Quantum Model",
        "site": "https://proceedings.mlr.press/v206/gluch23a.html",
        "author": "Grzegorz Gluch; Khashayar Barooti; R\u00fcdiger Urbanke",
        "abstract": "A new model for adversarial robustness was introduced by Goldwasser et al. in [GKKM20]. In this model the authors present a selective and transductive learning algorithm which guarantees a low test error and low rejection rate wrt to the original distribution. Moreover, a lower bound in terms of the VC-dimension, the standard risk and the number of samples is derived. We show that this lower bound can be broken in the quantum world. We consider a new model, influenced by the quantum PAC-learning model introduced by [BJ95], and similar in spirit to the one in [GKKM20]. In this model we give an interactive protocol between the learner and the adversary (at test-time) that guarantees robustness. This protocol, when applied, breaks the lower bound from [GKKM20]. From the technical perspective, our protocol is inspired by recent advances in delegation of quantum computation, e.g. [Mah18]. But in order to be applicable to our task, we extend the delegation protocol to enable a new feature, e.g. by extending delegation of decision problems, i.e. BQP, to sampling problems with adversarially chosen inputs.",
        "bibtex": "@InProceedings{pmlr-v206-gluch23a,\n  title = \t {Breaking a Classical Barrier for Classifying Arbitrary Test Examples in the Quantum Model},\n  author =       {Gluch, Grzegorz and Barooti, Khashayar and Urbanke, R\\\"udiger},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11457--11488},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gluch23a/gluch23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gluch23a.html},\n  abstract = \t {A new model for adversarial robustness was introduced by Goldwasser et al. in [GKKM20]. In this model the authors present a selective and transductive learning algorithm which guarantees a low test error and low rejection rate wrt to the original distribution. Moreover, a lower bound in terms of the VC-dimension, the standard risk and the number of samples is derived. We show that this lower bound can be broken in the quantum world. We consider a new model, influenced by the quantum PAC-learning model introduced by [BJ95], and similar in spirit to the one in [GKKM20]. In this model we give an interactive protocol between the learner and the adversary (at test-time) that guarantees robustness. This protocol, when applied, breaks the lower bound from [GKKM20]. From the technical perspective, our protocol is inspired by recent advances in delegation of quantum computation, e.g. [Mah18]. But in order to be applicable to our task, we extend the delegation protocol to enable a new feature, e.g. by extending delegation of decision problems, i.e. BQP, to sampling problems with adversarially chosen inputs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gluch23a/gluch23a.pdf",
        "supp": "",
        "pdf_size": 2685090,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14776587860896218689&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "EPFL; EPFL; EPFL",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch",
        "email": "epfl.ch;epfl.ch;epfl.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "e4901b0622",
        "title": "Bures-Wasserstein Barycenters and Low-Rank Matrix Recovery",
        "site": "https://proceedings.mlr.press/v206/maunu23a.html",
        "author": "Tyler Maunu; Thibaut Le Gouic; Philippe Rigollet",
        "abstract": "We revisit the problem of recovering a low-rank positive semidefinite matrix from rank-one projections using tools from optimal transport. More specifically, we show that a variational formulation of this problem is equivalent to computing a Wasserstein barycenter. In turn, this new perspective enables the development of new geometric first-order methods with strong convergence guarantees in Bures-Wasserstein distance. Experiments on simulated data demonstrate the advantages of our new methodology over existing methods.",
        "bibtex": "@InProceedings{pmlr-v206-maunu23a,\n  title = \t {Bures-Wasserstein Barycenters and Low-Rank Matrix Recovery},\n  author =       {Maunu, Tyler and Le Gouic, Thibaut and Rigollet, Philippe},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8183--8210},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/maunu23a/maunu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/maunu23a.html},\n  abstract = \t {We revisit the problem of recovering a low-rank positive semidefinite matrix from rank-one projections using tools from optimal transport. More specifically, we show that a variational formulation of this problem is equivalent to computing a Wasserstein barycenter. In turn, this new perspective enables the development of new geometric first-order methods with strong convergence guarantees in Bures-Wasserstein distance. Experiments on simulated data demonstrate the advantages of our new methodology over existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/maunu23a/maunu23a.pdf",
        "supp": "",
        "pdf_size": 2689059,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9145382761268738276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3c0e861484",
        "title": "But Are You Sure? An Uncertainty-Aware Perspective on Explainable AI",
        "site": "https://proceedings.mlr.press/v206/marx23a.html",
        "author": "Charles Marx; Youngsuk Park; Hilaf Hasson; Yuyang Wang; Stefano Ermon; Luke Huan",
        "abstract": "Although black-box models can accurately predict outcomes such as weather patterns, they often lack transparency, making it challenging to extract meaningful insights (such as which atmospheric conditions signal future rainfall). Model explanations attempt to identify the essential features of a model, but these explanations can be inconsistent: two near-optimal models may admit vastly different explanations. In this paper, we propose a solution to this problem by constructing uncertainty sets for explanations of the optimal model(s) in both frequentist and Bayesian settings. Our uncertainty sets are guaranteed to include the explanation of the optimal model with high probability, even though this model is unknown. We demonstrate the effectiveness of our approach in both synthetic and real-world experiments, illustrating how our uncertainty sets can be used to calibrate trust in model explanations.",
        "bibtex": "@InProceedings{pmlr-v206-marx23a,\n  title = \t {But Are You Sure? An Uncertainty-Aware Perspective on Explainable AI},\n  author =       {Marx, Charles and Park, Youngsuk and Hasson, Hilaf and Wang, Yuyang and Ermon, Stefano and Huan, Luke},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7375--7391},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/marx23a/marx23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/marx23a.html},\n  abstract = \t {Although black-box models can accurately predict outcomes such as weather patterns, they often lack transparency, making it challenging to extract meaningful insights (such as which atmospheric conditions signal future rainfall). Model explanations attempt to identify the essential features of a model, but these explanations can be inconsistent: two near-optimal models may admit vastly different explanations. In this paper, we propose a solution to this problem by constructing uncertainty sets for explanations of the optimal model(s) in both frequentist and Bayesian settings. Our uncertainty sets are guaranteed to include the explanation of the optimal model with high probability, even though this model is unknown. We demonstrate the effectiveness of our approach in both synthetic and real-world experiments, illustrating how our uncertainty sets can be used to calibrate trust in model explanations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/marx23a/marx23a.pdf",
        "supp": "",
        "pdf_size": 5120892,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6793142599115366181&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3c5ff00ade",
        "title": "Byzantine-Robust Federated Learning with Optimal Statistical Rates",
        "site": "https://proceedings.mlr.press/v206/zhu23b.html",
        "author": "Banghua Zhu; Lun Wang; Qi Pang; Shuai Wang; Jiantao Jiao; Dawn Song; Michael I. Jordan",
        "abstract": "We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates based on recent progress in high dimensional robust statistics. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a near-optimal statistical rate for strongly convex losses. We also provide statistical lower bound for the problem. For experiments, we benchmark against competing protocols and show the empirical superiority of the proposed protocols.",
        "bibtex": "@InProceedings{pmlr-v206-zhu23b,\n  title = \t {Byzantine-Robust Federated Learning with Optimal Statistical Rates},\n  author =       {Zhu, Banghua and Wang, Lun and Pang, Qi and Wang, Shuai and Jiao, Jiantao and Song, Dawn and Jordan, Michael I.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3151--3178},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhu23b/zhu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhu23b.html},\n  abstract = \t {We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates based on recent progress in high dimensional robust statistics. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a near-optimal statistical rate for strongly convex losses. We also provide statistical lower bound for the problem. For experiments, we benchmark against competing protocols and show the empirical superiority of the proposed protocols.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhu23b/zhu23b.pdf",
        "supp": "",
        "pdf_size": 801203,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8498390870506213397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "UC Berkeley; UC Berkeley+Google; UC Berkeley+HKUST; HKUST; UC Berkeley; UC Berkeley; UC Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;berkeley.edu;hkust.edu.hk;berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;berkeley.edu;hkust.edu.hk;berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0+2;2;0;0;0",
        "aff_unique_norm": "University of California, Berkeley;Google;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Google;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.google.com;https://www.ust.hk",
        "aff_unique_abbr": "UC Berkeley;Google;HKUST",
        "aff_campus_unique_index": "0;0+1;0+2;2;0;0;0",
        "aff_campus_unique": "Berkeley;Mountain View;Hong Kong SAR",
        "aff_country_unique_index": "0;0+0;0+1;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "1c46307e26",
        "title": "Byzantine-Robust Online and Offline Distributed Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/chen23b.html",
        "author": "Yiding Chen; Xuezhou Zhang; Kaiqing Zhang; Mengdi Wang; Xiaojin Zhu",
        "abstract": "We consider a distributed reinforcement learning setting where multiple agents separately explore the environment and communicate their experiences through a central server. However, $\\alpha$-fraction of agents are adversarial and can report arbitrary fake information. Critically, these adversarial agents can collude and their fake data can be of any sizes. We desire to robustly identify a near-optimal policy for the underlying Markov decision process in the presence of these adversarial agents. Our main technical contribution is COW, a novel algorithm for the robust mean estimation from batches problem, that can handle arbitrary batch sizes. Building upon this new estimator, in the offline setting, we design a Byzantine-robust distributed pessimistic value iteration algorithm; in the online setting, we design a Byzantine-robust distributed optimistic value iteration algorithm. Both algorithms obtain near-optimal sample complexities and achieve superior robustness guarantee than prior works.",
        "bibtex": "@InProceedings{pmlr-v206-chen23b,\n  title = \t {Byzantine-Robust Online and Offline Distributed Reinforcement Learning},\n  author =       {Chen, Yiding and Zhang, Xuezhou and Zhang, Kaiqing and Wang, Mengdi and Zhu, Xiaojin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3230--3269},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23b/chen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23b.html},\n  abstract = \t {We consider a distributed reinforcement learning setting where multiple agents separately explore the environment and communicate their experiences through a central server. However, $\\alpha$-fraction of agents are adversarial and can report arbitrary fake information. Critically, these adversarial agents can collude and their fake data can be of any sizes. We desire to robustly identify a near-optimal policy for the underlying Markov decision process in the presence of these adversarial agents. Our main technical contribution is COW, a novel algorithm for the robust mean estimation from batches problem, that can handle arbitrary batch sizes. Building upon this new estimator, in the offline setting, we design a Byzantine-robust distributed pessimistic value iteration algorithm; in the online setting, we design a Byzantine-robust distributed optimistic value iteration algorithm. Both algorithms obtain near-optimal sample complexities and achieve superior robustness guarantee than prior works.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23b/chen23b.pdf",
        "supp": "",
        "pdf_size": 493049,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9122947942893947170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Wisconsin-Madison; Princeton University; University of Maryland, College Park; Princeton University; University of Wisconsin-Madison",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "University of Wisconsin-Madison;Princeton University;University of Maryland",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.wisc.edu;https://www.princeton.edu;https://www/umd.edu",
        "aff_unique_abbr": "UW-Madison;Princeton;UMD",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Madison;;College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3dd94a7811",
        "title": "CLIP-Lite: Information Efficient Visual Representation Learning with Language Supervision",
        "site": "https://proceedings.mlr.press/v206/shrivastava23a.html",
        "author": "Aman Shrivastava; Ramprasaath R. Selvaraju; Nikhil Naik; Vicente Ordonez",
        "abstract": "We propose CLIP-Lite, an information efficient method for visual representation learning by feature alignment with textual annotations. Compared to the previously proposed CLIP model, CLIP-Lite requires only one negative image-text sample pair for every positive image-text sample during the optimization of its contrastive learning objective. We accomplish this by taking advantage of an information efficient lower-bound to maximize the mutual information between the two input modalities. This allows CLIP-Lite to be trained with significantly reduced amounts of data and batch sizes while obtaining better performance than CLIP at the same scale. We evaluate CLIP-Lite by pretraining on the COCO-Captions dataset and testing transfer learning to other datasets. CLIP-Lite obtains a +14.0$%$ mAP absolute gain in performance on Pascal VOC classification, and a +22.1$%$ top-1 accuracy gain on ImageNet, while being comparable or superior to other, more complex, text-supervised models. CLIP-Lite is also superior to CLIP on image and text retrieval, zero-shot classification, and visual grounding. Finally, we show that CLIP-Lite can leverage language semantics to encourage bias-free visual representations that can be used in downstream tasks. Implementation: https://github.com/4m4n5/CLIP-Lite",
        "bibtex": "@InProceedings{pmlr-v206-shrivastava23a,\n  title = \t {CLIP-Lite: Information Efficient Visual Representation Learning with Language Supervision},\n  author =       {Shrivastava, Aman and Selvaraju, Ramprasaath R. and Naik, Nikhil and Ordonez, Vicente},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8433--8447},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shrivastava23a/shrivastava23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shrivastava23a.html},\n  abstract = \t {We propose CLIP-Lite, an information efficient method for visual representation learning by feature alignment with textual annotations. Compared to the previously proposed CLIP model, CLIP-Lite requires only one negative image-text sample pair for every positive image-text sample during the optimization of its contrastive learning objective. We accomplish this by taking advantage of an information efficient lower-bound to maximize the mutual information between the two input modalities. This allows CLIP-Lite to be trained with significantly reduced amounts of data and batch sizes while obtaining better performance than CLIP at the same scale. We evaluate CLIP-Lite by pretraining on the COCO-Captions dataset and testing transfer learning to other datasets. CLIP-Lite obtains a +14.0$%$ mAP absolute gain in performance on Pascal VOC classification, and a +22.1$%$ top-1 accuracy gain on ImageNet, while being comparable or superior to other, more complex, text-supervised models. CLIP-Lite is also superior to CLIP on image and text retrieval, zero-shot classification, and visual grounding. Finally, we show that CLIP-Lite can leverage language semantics to encourage bias-free visual representations that can be used in downstream tasks. Implementation: https://github.com/4m4n5/CLIP-Lite}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shrivastava23a/shrivastava23a.pdf",
        "supp": "",
        "pdf_size": 1361311,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8125970351891616527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cefbe1b41f",
        "title": "Can 5th Generation Local Training Methods Support Client Sampling? Yes!",
        "site": "https://proceedings.mlr.press/v206/grudzien23a.html",
        "author": "Micha\u0142 Grudzie\u0144; Grigory Malinovsky; Peter Richtarik",
        "abstract": "The celebrated FedAvg algorithm of McMahan et al. (2017) is based on three components: client sampling (CS), data sampling (DS) and local training (LT). While the first two are reasonably well understood, the third component, whose role is to reduce the number of communication rounds needed to train the model, resisted all attempts at a satisfactory theoretical explanation. Malinovsky et al. (2022) identified four distinct generations of LT methods based on the quality of the provided theoretical communication complexity guarantees. Despite a lot of progress in this area, none of the existing works were able to show that it is theoretically better to employ multiple local gradient-type steps (i.e., to engage in LT) than to rely on a single local gradient-type step only in the important heterogeneous data regime. In a recent breakthrough embodied in their ProxSkip method and its theoretical analysis, Mishchenko et al. (2022) showed that LT indeed leads to provable communication acceleration for arbitrarily heterogeneous data, thus jump-starting the 5th generation of LT methods. However, while these latest generation LT methods are compatible with DS, none of them support CS. We resolve this open problem in the affirmative. In order to do so, we had to base our algorithmic development on new algorithmic and theoretical foundations.",
        "bibtex": "@InProceedings{pmlr-v206-grudzien23a,\n  title = \t {Can 5th Generation Local Training Methods Support Client Sampling? Yes!},\n  author =       {Grudzie\\'n, Micha{\\l} and Malinovsky, Grigory and Richtarik, Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1055--1092},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/grudzien23a/grudzien23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/grudzien23a.html},\n  abstract = \t {The celebrated FedAvg algorithm of McMahan et al. (2017) is based on three components: client sampling (CS), data sampling (DS) and local training (LT). While the first two are reasonably well understood, the third component, whose role is to reduce the number of communication rounds needed to train the model, resisted all attempts at a satisfactory theoretical explanation. Malinovsky et al. (2022) identified four distinct generations of LT methods based on the quality of the provided theoretical communication complexity guarantees. Despite a lot of progress in this area, none of the existing works were able to show that it is theoretically better to employ multiple local gradient-type steps (i.e., to engage in LT) than to rely on a single local gradient-type step only in the important heterogeneous data regime. In a recent breakthrough embodied in their ProxSkip method and its theoretical analysis, Mishchenko et al. (2022) showed that LT indeed leads to provable communication acceleration for arbitrarily heterogeneous data, thus jump-starting the 5th generation of LT methods. However, while these latest generation LT methods are compatible with DS, none of them support CS. We resolve this open problem in the affirmative. In order to do so, we had to base our algorithmic development on new algorithmic and theoretical foundations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/grudzien23a/grudzien23a.pdf",
        "supp": "",
        "pdf_size": 1534879,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3633954198966920348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "KAUST & University of Oxford; KAUST; KAUST",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaust.edu.sa",
        "aff_unique_abbr": "KAUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Saudi Arabia"
    },
    {
        "id": "dab11200cc",
        "title": "Catalyst Acceleration of Error Compensated Methods Leads to Better Communication Complexity",
        "site": "https://proceedings.mlr.press/v206/qian23a.html",
        "author": "Xun Qian; Hanze Dong; Tong Zhang; Peter Richtarik",
        "abstract": "Communication overhead is well known to be a key bottleneck in large scale distributed learning, and a particularly successful class of methods which help to overcome this bottleneck is based on the idea of communication compression. Some of the most practically effective gradient compressors, such as TopK, are biased, which causes convergence issues unless one employs a well designed error compensation/feedback mechanism. Error compensation is therefore a fundamental technique in the distributed learning literature. In a recent development, Qian et al (NeurIPS 2021) showed that the error-compensation mechanism can be combined with acceleration/momentum, which is another key and highly successful optimization technique. In particular, they developed the error-compensated loop-less Katyusha (ECLK) method, and proved an accelerated linear rate in the strongly convex case. However, the dependence of their rate on the compressor parameter does not match the best dependence obtainable in the non-accelerated error-compensated methods. Our work addresses this problem. We propose several new accelerated error-compensated methods using the catalyst acceleration technique, and obtain results that match the best dependence on the compressor parameter in non-accelerated error-compensated methods up to logarithmic terms.",
        "bibtex": "@InProceedings{pmlr-v206-qian23a,\n  title = \t {Catalyst Acceleration of Error Compensated Methods Leads to Better Communication Complexity},\n  author =       {Qian, Xun and Dong, Hanze and Zhang, Tong and Richtarik, Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {615--649},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qian23a/qian23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qian23a.html},\n  abstract = \t {Communication overhead is well known to be a key bottleneck in large scale distributed learning, and a particularly successful class of methods which help to overcome this bottleneck is based on the idea of communication compression. Some of the most practically effective gradient compressors, such as TopK, are biased, which causes convergence issues unless one employs a well designed error compensation/feedback mechanism. Error compensation is therefore a fundamental technique in the distributed learning literature. In a recent development, Qian et al (NeurIPS 2021) showed that the error-compensation mechanism can be combined with acceleration/momentum, which is another key and highly successful optimization technique. In particular, they developed the error-compensated loop-less Katyusha (ECLK) method, and proved an accelerated linear rate in the strongly convex case. However, the dependence of their rate on the compressor parameter does not match the best dependence obtainable in the non-accelerated error-compensated methods. Our work addresses this problem. We propose several new accelerated error-compensated methods using the catalyst acceleration technique, and obtain results that match the best dependence on the compressor parameter in non-accelerated error-compensated methods up to logarithmic terms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qian23a/qian23a.pdf",
        "supp": "",
        "pdf_size": 948951,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7650770876696711723&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0364b2235f",
        "title": "Causal Entropy Optimization",
        "site": "https://proceedings.mlr.press/v206/branchini23a.html",
        "author": "Nicola Branchini; Virginia Aglietti; Neil Dhir; Theodoros Damoulas",
        "abstract": "We study the problem of globally optimizing the causal effect on a target variable of an unknown causal graph in which interventions can be performed. This problem arises in many areas of science including biology, operations research and healthcare. We propose Causal Entropy Optimization (CEO), a framework that generalizes Causal Bayesian Optimization (CBO) to account for all sources of uncertainty, including the one arising from the causal graph structure. CEO incorporates the causal structure uncertainty both in the surrogate models for the causal effects and in the mechanism used to select interventions via an information-theoretic acquisition function. The resulting algorithm automatically trades-off structure learning and causal effect optimization, while naturally accounting for observation noise. For various synthetic and real-world structural causal models, CEO achieves faster convergence to the global optimum compared with CBO while also learning the graph. Furthermore, our joint approach to structure learning and causal optimization improves upon sequential, structure-learning-first approaches.",
        "bibtex": "@InProceedings{pmlr-v206-branchini23a,\n  title = \t {Causal Entropy Optimization},\n  author =       {Branchini, Nicola and Aglietti, Virginia and Dhir, Neil and Damoulas, Theodoros},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8586--8605},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/branchini23a/branchini23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/branchini23a.html},\n  abstract = \t {We study the problem of globally optimizing the causal effect on a target variable of an unknown causal graph in which interventions can be performed. This problem arises in many areas of science including biology, operations research and healthcare. We propose Causal Entropy Optimization (CEO), a framework that generalizes Causal Bayesian Optimization (CBO) to account for all sources of uncertainty, including the one arising from the causal graph structure. CEO incorporates the causal structure uncertainty both in the surrogate models for the causal effects and in the mechanism used to select interventions via an information-theoretic acquisition function. The resulting algorithm automatically trades-off structure learning and causal effect optimization, while naturally accounting for observation noise. For various synthetic and real-world structural causal models, CEO achieves faster convergence to the global optimum compared with CBO while also learning the graph. Furthermore, our joint approach to structure learning and causal optimization improves upon sequential, structure-learning-first approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/branchini23a/branchini23a.pdf",
        "supp": "",
        "pdf_size": 3746127,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16084111042524524051&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "11ee009fc6",
        "title": "Characterizing Internal Evasion Attacks in Federated Learning",
        "site": "https://proceedings.mlr.press/v206/kim23a.html",
        "author": "Taejin Kim; Shubhranshu Singh; Nikhil Madaan; Carlee Joe-Wong",
        "abstract": "Federated learning allows for clients in a distributed system to jointly train a machine learning model. However, clients\u2019 models are vulnerable to attacks during the training and testing phases. In this paper, we address the issue of adversarial clients performing \u201cinternal evasion attacks\u201d: crafting evasion attacks at test time to deceive other clients. For example, adversaries may aim to deceive spam filters and recommendation systems trained with federated learning for monetary gain. The adversarial clients have extensive information about the victim model in a federated learning setting, as weight information is shared amongst clients. We are the first to characterize the transferability of such internal evasion attacks for different learning methods and analyze the trade-off between model accuracy and robustness depending on the degree of similarities in client data. We show that adversarial training defenses in the federated learning setting only display limited improvements against internal attacks. However, combining adversarial training with personalized federated learning frameworks increases relative internal attack robustness by 60$%$ compared to federated adversarial training and performs well under limited system resources.",
        "bibtex": "@InProceedings{pmlr-v206-kim23a,\n  title = \t {Characterizing Internal Evasion Attacks in Federated Learning},\n  author =       {Kim, Taejin and Singh, Shubhranshu and Madaan, Nikhil and Joe-Wong, Carlee},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {907--921},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kim23a/kim23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kim23a.html},\n  abstract = \t {Federated learning allows for clients in a distributed system to jointly train a machine learning model. However, clients\u2019 models are vulnerable to attacks during the training and testing phases. In this paper, we address the issue of adversarial clients performing \u201cinternal evasion attacks\u201d: crafting evasion attacks at test time to deceive other clients. For example, adversaries may aim to deceive spam filters and recommendation systems trained with federated learning for monetary gain. The adversarial clients have extensive information about the victim model in a federated learning setting, as weight information is shared amongst clients. We are the first to characterize the transferability of such internal evasion attacks for different learning methods and analyze the trade-off between model accuracy and robustness depending on the degree of similarities in client data. We show that adversarial training defenses in the federated learning setting only display limited improvements against internal attacks. However, combining adversarial training with personalized federated learning frameworks increases relative internal attack robustness by 60$%$ compared to federated adversarial training and performs well under limited system resources.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kim23a/kim23a.pdf",
        "supp": "",
        "pdf_size": 1826546,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17811940725838272950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4fca099bd2",
        "title": "Characterizing Polarization in Social Networks using the Signed Relational Latent Distance Model",
        "site": "https://proceedings.mlr.press/v206/nakis23a.html",
        "author": "Nikolaos Nakis; Abdulkadir Celikkanat; Louis Boucherie; Christian Djurhuus; Felix Burmester; Daniel Mathias Holmelund; Monika Frolcov\u00e1; Morten M\u00f8rup",
        "abstract": "Graph representation learning has become a prominent tool for the characterization and understanding of the structure of networks in general and social networks in particular. Typically, these representation learning approaches embed the networks into a low-dimensional space in which the role of each individual can be characterized in terms of their latent position. A major current concern in social networks is the emergence of polarization and filter bubbles promoting a mindset of \u201dus-versus-them\u201d that may be defined by extreme positions believed to ultimately lead to political violence and the erosion of democracy. Such polarized networks are typically characterized in terms of signed links reflecting likes and dislikes. We propose the Signed Latent Distance Model (SLDM) utilizing for the first time the Skellam distribution as a likelihood function for signed networks. We further extend the modeling to the characterization of distinct extreme positions by constraining the embedding space to polytopes, forming the Signed Latent Relational Distance Model (SLIM). On four real social signed networks of polarization, we demonstrate that the models extract low-dimensional characterizations that well predict friendships and animosity while SLIM provides interpretable visualizations defined by extreme positions when restricting the embedding space to polytopes.",
        "bibtex": "@InProceedings{pmlr-v206-nakis23a,\n  title = \t {Characterizing Polarization in Social Networks using the Signed Relational Latent Distance Model},\n  author =       {Nakis, Nikolaos and Celikkanat, Abdulkadir and Boucherie, Louis and Djurhuus, Christian and Burmester, Felix and Holmelund, Daniel Mathias and Frolcov\\'a, Monika and M{\\o}rup, Morten},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11489--11505},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nakis23a/nakis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nakis23a.html},\n  abstract = \t {Graph representation learning has become a prominent tool for the characterization and understanding of the structure of networks in general and social networks in particular. Typically, these representation learning approaches embed the networks into a low-dimensional space in which the role of each individual can be characterized in terms of their latent position. A major current concern in social networks is the emergence of polarization and filter bubbles promoting a mindset of \u201dus-versus-them\u201d that may be defined by extreme positions believed to ultimately lead to political violence and the erosion of democracy. Such polarized networks are typically characterized in terms of signed links reflecting likes and dislikes. We propose the Signed Latent Distance Model (SLDM) utilizing for the first time the Skellam distribution as a likelihood function for signed networks. We further extend the modeling to the characterization of distinct extreme positions by constraining the embedding space to polytopes, forming the Signed Latent Relational Distance Model (SLIM). On four real social signed networks of polarization, we demonstrate that the models extract low-dimensional characterizations that well predict friendships and animosity while SLIM provides interpretable visualizations defined by extreme positions when restricting the embedding space to polytopes. }\n}",
        "pdf": "https://proceedings.mlr.press/v206/nakis23a/nakis23a.pdf",
        "supp": "",
        "pdf_size": 9913624,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6860314478123865811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "82cf784917",
        "title": "Classification of Adolescents\u2019 Risky Behavior in Instant Messaging Conversations",
        "site": "https://proceedings.mlr.press/v206/plhak23a.html",
        "author": "Jarom\u0131\u0301r Plh\u00e1k; Ond\u0159ej Sotol\u00e1\u0159; Michaela Lebed\u0131\u0301kov\u00e1; David \u0160mahel",
        "abstract": "Previous research on detecting risky online behavior has been rather scattered, typically identifying single risks in online samples. To our knowledge, the presented research is the first that presents a process of building models that can efficiently detect the following four online risky behavior: (1) aggression, harassment, hate; (2) mental health; (3) use of alcohol, and drugs; and (4) sexting. Furthermore, the corpora in this research are unique because of the usage of private instant messaging conversations in the Czech language provided by adolescents. The combination of publicly unavailable and unique data with high-quality annotations of specific psychological phenomena allowed us for precise detection using transformer machine learning models that can handle sequential data and involve the context of utterances. The impact of the context length and text augmentation on model efficiency is discussed in detail. The final model provides promising results with an acceptable F1 score. Therefore, we believe that the model could be used in various applications, e.g., parental applications, chatbots, or services provided by Internet providers. Future research could investigate the usage of the model in other languages.",
        "bibtex": "@InProceedings{pmlr-v206-plhak23a,\n  title = \t {Classification of Adolescents\u2019 Risky Behavior in Instant Messaging Conversations},\n  author =       {Plh\\'ak, Jarom{\\'\\i}r and Sotol\\'a\\v{r}, Ond\\v{r}ej and Lebed{\\'\\i}kov\\'a, Michaela and \\v{S}mahel, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2390--2404},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/plhak23a/plhak23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/plhak23a.html},\n  abstract = \t {Previous research on detecting risky online behavior has been rather scattered, typically identifying single risks in online samples. To our knowledge, the presented research is the first that presents a process of building models that can efficiently detect the following four online risky behavior: (1) aggression, harassment, hate; (2) mental health; (3) use of alcohol, and drugs; and (4) sexting. Furthermore, the corpora in this research are unique because of the usage of private instant messaging conversations in the Czech language provided by adolescents. The combination of publicly unavailable and unique data with high-quality annotations of specific psychological phenomena allowed us for precise detection using transformer machine learning models that can handle sequential data and involve the context of utterances. The impact of the context length and text augmentation on model efficiency is discussed in detail. The final model provides promising results with an acceptable F1 score. Therefore, we believe that the model could be used in various applications, e.g., parental applications, chatbots, or services provided by Internet providers. Future research could investigate the usage of the model in other languages.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/plhak23a/plhak23a.pdf",
        "supp": "",
        "pdf_size": 534193,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15007847701203846978&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0f71d4bc5f",
        "title": "Clustering High-dimensional Data with Ordered Weighted $\\ell_1$ Regularization",
        "site": "https://proceedings.mlr.press/v206/chakraborty23a.html",
        "author": "Chandramauli Chakraborty; Sayan Paul; Saptarshi Chakraborty; Swagatam Das",
        "abstract": "Clustering complex high-dimensional data is particularly challenging as the signal-to-noise ratio in such data is significantly lower than their classical counterparts. This is mainly because most of the features describing a data point have little to no information about the natural grouping of the data. Filtering such features is, thus, critical in harnessing meaningful information from such large-scale data. Many recent methods have attempted to find feature importance in a centroid-based clustering setting. Though empirically successful in classical low-dimensional settings, most perform poorly, especially on microarray and single-cell RNA-seq data. This paper extends the merits of weighted center-based clustering through the Ordered Weighted $\\ell_1$ (OWL) norm for better feature selection. Appealing to the elegant properties of block coordinate-descent and Frank-Wolf algorithms, we are not only able to maintain computational efficiency but also able to outperform the state-of-the-art in high-dimensional settings. The proposal also comes with finite sample theoretical guarantees, including a rate of $\\mathcal{O}\\left(\\sqrt{k \\log p/n}\\right)$, under model-sparsity, bridging the gap between theory and practice of weighted clustering.",
        "bibtex": "@InProceedings{pmlr-v206-chakraborty23a,\n  title = \t {Clustering High-dimensional Data with Ordered Weighted $\\ell_1$ Regularization},\n  author =       {Chakraborty, Chandramauli and Paul, Sayan and Chakraborty, Saptarshi and Das, Swagatam},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7176--7189},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chakraborty23a/chakraborty23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chakraborty23a.html},\n  abstract = \t {Clustering complex high-dimensional data is particularly challenging as the signal-to-noise ratio in such data is significantly lower than their classical counterparts. This is mainly because most of the features describing a data point have little to no information about the natural grouping of the data. Filtering such features is, thus, critical in harnessing meaningful information from such large-scale data. Many recent methods have attempted to find feature importance in a centroid-based clustering setting. Though empirically successful in classical low-dimensional settings, most perform poorly, especially on microarray and single-cell RNA-seq data. This paper extends the merits of weighted center-based clustering through the Ordered Weighted $\\ell_1$ (OWL) norm for better feature selection. Appealing to the elegant properties of block coordinate-descent and Frank-Wolf algorithms, we are not only able to maintain computational efficiency but also able to outperform the state-of-the-art in high-dimensional settings. The proposal also comes with finite sample theoretical guarantees, including a rate of $\\mathcal{O}\\left(\\sqrt{k \\log p/n}\\right)$, under model-sparsity, bridging the gap between theory and practice of weighted clustering.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chakraborty23a/chakraborty23a.pdf",
        "supp": "",
        "pdf_size": 2672089,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13342059797769255699&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Indian Statistical Institute, Kolkata, India; Indian Statistical Institute, Kolkata, India; Department of Statistics UC Berkeley + Electronics and Communication Sciences Unit, Indian Statistical Institute; Indian Statistical Institute, Kolkata, India",
        "aff_domain": "isical.ac.in;isical.ac.in;isical.ac.in;isical.ac.in",
        "email": "isical.ac.in;isical.ac.in;isical.ac.in;isical.ac.in",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+0;0",
        "aff_unique_norm": "Indian Statistical Institute;University of California, Berkeley",
        "aff_unique_dep": ";Department of Statistics",
        "aff_unique_url": "https://www.isical.ac.in;https://www.berkeley.edu",
        "aff_unique_abbr": "ISI;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Kolkata;Berkeley;",
        "aff_country_unique_index": "0;0;1+0;0",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "549183feff",
        "title": "Clustering above Exponential Families with Tempered Exponential Measures",
        "site": "https://proceedings.mlr.press/v206/amid23a.html",
        "author": "Ehsan Amid; Richard Nock; Manfred K. Warmuth",
        "abstract": "The link with exponential families has allowed k-means clustering to be generalized to a wide variety of data-generating distributions in exponential families and clustering distortions among Bregman divergences. Getting the framework to go beyond exponential families is important to lift roadblocks like the lack of robustness of some population minimizers, which is carved into their axiomatization. Current generalizations of exponential families like the q-exponential families or even the deformed exponential families fail at achieving the goal. In this paper, we provide a new attempt at getting a complete framework, grounded in a new generalization of exponential families that we introduce, called tempered exponential measures (TEMs). TEMs keep the maximum entropy axiomatization framework of q-exponential families, but instead of normalizing the measure, normalize a dual called a co-distribution. Numerous interesting properties arise for clustering, such as improved and controllable robustness for population minimizers, that keep a simple analytic form.",
        "bibtex": "@InProceedings{pmlr-v206-amid23a,\n  title = \t {Clustering above Exponential Families with Tempered Exponential Measures},\n  author =       {Amid, Ehsan and Nock, Richard and Warmuth, Manfred K.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2994--3017},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/amid23a/amid23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/amid23a.html},\n  abstract = \t {The link with exponential families has allowed k-means clustering to be generalized to a wide variety of data-generating distributions in exponential families and clustering distortions among Bregman divergences. Getting the framework to go beyond exponential families is important to lift roadblocks like the lack of robustness of some population minimizers, which is carved into their axiomatization. Current generalizations of exponential families like the q-exponential families or even the deformed exponential families fail at achieving the goal. In this paper, we provide a new attempt at getting a complete framework, grounded in a new generalization of exponential families that we introduce, called tempered exponential measures (TEMs). TEMs keep the maximum entropy axiomatization framework of q-exponential families, but instead of normalizing the measure, normalize a dual called a co-distribution. Numerous interesting properties arise for clustering, such as improved and controllable robustness for population minimizers, that keep a simple analytic form.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/amid23a/amid23a.pdf",
        "supp": "",
        "pdf_size": 908881,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17761191289785806543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6485e40ab5",
        "title": "Coarse-Grained Smoothness for Reinforcement Learning in Metric Spaces",
        "site": "https://proceedings.mlr.press/v206/gottesman23a.html",
        "author": "Omer Gottesman; Kavosh Asadi; Cameron S. Allen; Samuel Lobel; George Konidaris; Michael Littman",
        "abstract": "Principled decision-making in continuous state\u2013action spaces is impossible without some assumptions. A common approach is to assume Lipschitz continuity of the Q-function. We show that, unfortunately, this property fails to hold in many typical domains. We propose a new coarse-grained smoothness definition that generalizes the notion of Lipschitz continuity, is more widely applicable, and allows us to compute significantly tighter bounds on Q-functions, leading to improved learning. We provide a theoretical analysis of our new smoothness definition, and discuss its implications and impact on control and exploration in continuous domains.",
        "bibtex": "@InProceedings{pmlr-v206-gottesman23a,\n  title = \t {Coarse-Grained Smoothness for Reinforcement Learning in Metric Spaces},\n  author =       {Gottesman, Omer and Asadi, Kavosh and Allen, Cameron S. and Lobel, Samuel and Konidaris, George and Littman, Michael},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1390--1410},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gottesman23a/gottesman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gottesman23a.html},\n  abstract = \t {Principled decision-making in continuous state\u2013action spaces is impossible without some assumptions. A common approach is to assume Lipschitz continuity of the Q-function. We show that, unfortunately, this property fails to hold in many typical domains. We propose a new coarse-grained smoothness definition that generalizes the notion of Lipschitz continuity, is more widely applicable, and allows us to compute significantly tighter bounds on Q-functions, leading to improved learning. We provide a theoretical analysis of our new smoothness definition, and discuss its implications and impact on control and exploration in continuous domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gottesman23a/gottesman23a.pdf",
        "supp": "",
        "pdf_size": 938263,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11604839270250726419&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Brown University; Amazon Web Services + Brown University; Brown University; Brown University; Brown University; Brown University",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;0;0;0",
        "aff_unique_norm": "Brown University;Amazon",
        "aff_unique_dep": ";Amazon Web Services",
        "aff_unique_url": "https://www.brown.edu;https://aws.amazon.com",
        "aff_unique_abbr": "Brown;AWS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4d41b7de23",
        "title": "Coherent Probabilistic Forecasting of Temporal Hierarchies",
        "site": "https://proceedings.mlr.press/v206/rangapuram23a.html",
        "author": "Syama Sundar Rangapuram; Shubham Kapoor; Rajbir Singh Nirwan; Pedro Mercado; Tim Januschowski; Yuyang Wang; Michael Bohlke-Schneider",
        "abstract": "Forecasts at different time granularities are required in practice for addressing various business problems starting from short-term operational to medium-term tactical and to long-term strategic planning. These forecasting problems are usually treated independently by learning different ML models which results in forecasts that are not consistent with the temporal aggregation structure, leading to inefficient decision making. Some of the recent work addressed this problem, however, it uses a post-hoc reconciliation strategy, which results in sub-optimal results and cannot produce probabilistic forecasts. In this paper, we present a global model that produces coherent, probabilistic forecasts for different time granularities by learning joint embeddings for the different aggregation levels with graph neural networks and temporal reconciliation. Temporal reconciliation not only enables consistent decisions for business problems across different planning horizons but also improves the quality of forecasts at finer time granularities. A thorough empirical evaluation illustrates the benefits of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v206-rangapuram23a,\n  title = \t {Coherent Probabilistic Forecasting of Temporal Hierarchies},\n  author =       {Rangapuram, Syama Sundar and Kapoor, Shubham and Nirwan, Rajbir Singh and Mercado, Pedro and Januschowski, Tim and Wang, Yuyang and Bohlke-Schneider, Michael},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9362--9376},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/rangapuram23a/rangapuram23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/rangapuram23a.html},\n  abstract = \t {Forecasts at different time granularities are required in practice for addressing various business problems starting from short-term operational to medium-term tactical and to long-term strategic planning. These forecasting problems are usually treated independently by learning different ML models which results in forecasts that are not consistent with the temporal aggregation structure, leading to inefficient decision making. Some of the recent work addressed this problem, however, it uses a post-hoc reconciliation strategy, which results in sub-optimal results and cannot produce probabilistic forecasts. In this paper, we present a global model that produces coherent, probabilistic forecasts for different time granularities by learning joint embeddings for the different aggregation levels with graph neural networks and temporal reconciliation. Temporal reconciliation not only enables consistent decisions for business problems across different planning horizons but also improves the quality of forecasts at finer time granularities. A thorough empirical evaluation illustrates the benefits of the proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/rangapuram23a/rangapuram23a.pdf",
        "supp": "",
        "pdf_size": 1132804,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10654690165249953663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "AWS AI Labs; AWS AI Labs; D2S, Inc. + Zalando; AWS AI Labs; Zalando; AWS AI Labs; AWS AI Labs",
        "aff_domain": "amazon.de; ; ; ; ; ; ",
        "email": "amazon.de; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;0;2;0;0",
        "aff_unique_norm": "Amazon;D2S, Inc.;Zalando SE",
        "aff_unique_dep": "AWS AI Labs;;",
        "aff_unique_url": "https://aws.amazon.com;;https://www.zalando.de",
        "aff_unique_abbr": "AWS;;Zalando",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1;0;1;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "cc0ce2a0e3",
        "title": "Collision Probability Matching Loss for Disentangling Epistemic Uncertainty from Aleatoric Uncertainty",
        "site": "https://proceedings.mlr.press/v206/narimatsu23a.html",
        "author": "Hiromi Narimatsu; Mayuko Ozawa; Shiro Kumano",
        "abstract": "Two important aspects of machine learning, uncertainty and calibration, have previously been studied separately. The first aspect involves knowing whether inaccuracy is due to the epistemic uncertainty of the model, which is theoretically reducible, or to the aleatoric uncertainty in the data per se, which thus becomes the upper bound of model performance. As for the second aspect, numerous calibration methods have been proposed to correct predictive probabilities to better reflect the true probabilities of being correct. In this paper, we aim to obtain the squared error of predictive distribution from the true distribution as epistemic uncertainty. Our formulation, based on second-order R\u00e9nyi entropy, integrates the two problems into a unified framework and obtains the epistemic (un)certainty as the difference between the aleatoric and predictive (un)certainties. As an auxiliary loss to ordinary losses, such as cross-entropy loss, the proposed collision probability matching (CPM) loss matches the cross-collision probability between the true and predictive distributions to the collision probability of the predictive distribution, where these probabilities correspond to accuracy and confidence, respectively. Unlike previous Shannon-entropy-based uncertainty methods, the proposed method makes the aleatoric uncertainty directly measurable as test-retest reliability, which is a summary statistic of the true distribution frequently used in scientific research on humans. We provide mathematical proof and strong experimental evidence for our formulation using both a real dataset consisting of real human ratings toward emotional faces and simulation.",
        "bibtex": "@InProceedings{pmlr-v206-narimatsu23a,\n  title = \t {Collision Probability Matching Loss for Disentangling Epistemic Uncertainty from Aleatoric Uncertainty},\n  author =       {Narimatsu, Hiromi and Ozawa, Mayuko and Kumano, Shiro},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11355--11370},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/narimatsu23a/narimatsu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/narimatsu23a.html},\n  abstract = \t {Two important aspects of machine learning, uncertainty and calibration, have previously been studied separately. The first aspect involves knowing whether inaccuracy is due to the epistemic uncertainty of the model, which is theoretically reducible, or to the aleatoric uncertainty in the data per se, which thus becomes the upper bound of model performance. As for the second aspect, numerous calibration methods have been proposed to correct predictive probabilities to better reflect the true probabilities of being correct. In this paper, we aim to obtain the squared error of predictive distribution from the true distribution as epistemic uncertainty. Our formulation, based on second-order R\u00e9nyi entropy, integrates the two problems into a unified framework and obtains the epistemic (un)certainty as the difference between the aleatoric and predictive (un)certainties. As an auxiliary loss to ordinary losses, such as cross-entropy loss, the proposed collision probability matching (CPM) loss matches the cross-collision probability between the true and predictive distributions to the collision probability of the predictive distribution, where these probabilities correspond to accuracy and confidence, respectively. Unlike previous Shannon-entropy-based uncertainty methods, the proposed method makes the aleatoric uncertainty directly measurable as test-retest reliability, which is a summary statistic of the true distribution frequently used in scientific research on humans. We provide mathematical proof and strong experimental evidence for our formulation using both a real dataset consisting of real human ratings toward emotional faces and simulation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/narimatsu23a/narimatsu23a.pdf",
        "supp": "",
        "pdf_size": 824685,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18392812963254043262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "53320b1fef",
        "title": "Combining Graphical and Algebraic Approaches for Parameter Identification in Latent Variable Structural Equation Models",
        "site": "https://proceedings.mlr.press/v206/ankan23a.html",
        "author": "Ankur Ankan; Inge Wortel; Kenneth Bollen; Johannes Textor",
        "abstract": "Measurement error is ubiquitous in many variables \u201clatent-to-observed\u201d (L2O) transformation from the MIIV approach and develop an equivalent graphical L2O transformation that allows applying existing graphical criteria to latent parameters in SEMs. We combine L2O transformation with graphical instrumental variable criteria to obtain an efficient algorithm for non-iterative parameter identification in SEMs with latent variables. We prove that this graphical L2O transformation with the instrumental set criterion is equivalent to the state-of-the-art MIIV approach for SEMs, and show that it can lead to novel identification strategies when combined with other graphical criteria.",
        "bibtex": "@InProceedings{pmlr-v206-ankan23a,\n  title = \t {Combining Graphical and Algebraic Approaches for Parameter Identification in Latent Variable Structural Equation Models},\n  author =       {Ankan, Ankur and Wortel, Inge and Bollen, Kenneth and Textor, Johannes},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7252--7264},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ankan23a/ankan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ankan23a.html},\n  abstract = \t {Measurement error is ubiquitous in many variables \u201clatent-to-observed\u201d (L2O) transformation from the MIIV approach and develop an equivalent graphical L2O transformation that allows applying existing graphical criteria to latent parameters in SEMs. We combine L2O transformation with graphical instrumental variable criteria to obtain an efficient algorithm for non-iterative parameter identification in SEMs with latent variables. We prove that this graphical L2O transformation with the instrumental set criterion is equivalent to the state-of-the-art MIIV approach for SEMs, and show that it can lead to novel identification strategies when combined with other graphical criteria.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ankan23a/ankan23a.pdf",
        "supp": "",
        "pdf_size": 308132,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4016400592476826157&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9cb293f092",
        "title": "Competing against Adaptive Strategies in Online Learning via Hints",
        "site": "https://proceedings.mlr.press/v206/bhaskara23a.html",
        "author": "Aditya Bhaskara; Kamesh Munagala",
        "abstract": "For many of the classic online learning settings, it is known that having a \u201chint\u201d about the loss function before making a prediction yields significantly better regret guarantees. In this work we study the question, do hints allow us to go beyond the standard notion of regret (which competes against the best fixed strategy) and compete against adaptive or dynamic strategies? After all, if hints were perfect, we can clearly compete against a fully dynamic strategy. For some common online learning settings, we provide upper and lower bounds for the switching regret, i.e., the difference between the loss incurred by the algorithm and the optimal strategy in hindsight that switches state at most $L$ times, where $L$ is some parameter. We show positive results for online linear optimization and the classic experts problem. Interestingly, such results turn out to be impossible for the classic bandit setting.",
        "bibtex": "@InProceedings{pmlr-v206-bhaskara23a,\n  title = \t {Competing against Adaptive Strategies in Online Learning via Hints},\n  author =       {Bhaskara, Aditya and Munagala, Kamesh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10409--10424},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bhaskara23a/bhaskara23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bhaskara23a.html},\n  abstract = \t {For many of the classic online learning settings, it is known that having a \u201chint\u201d about the loss function before making a prediction yields significantly better regret guarantees. In this work we study the question, do hints allow us to go beyond the standard notion of regret (which competes against the best fixed strategy) and compete against adaptive or dynamic strategies? After all, if hints were perfect, we can clearly compete against a fully dynamic strategy. For some common online learning settings, we provide upper and lower bounds for the switching regret, i.e., the difference between the loss incurred by the algorithm and the optimal strategy in hindsight that switches state at most $L$ times, where $L$ is some parameter. We show positive results for online linear optimization and the classic experts problem. Interestingly, such results turn out to be impossible for the classic bandit setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bhaskara23a/bhaskara23a.pdf",
        "supp": "",
        "pdf_size": 292179,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8121511741116038313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "University of Utah; Duke University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Utah;Duke University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utah.edu;https://www.duke.edu",
        "aff_unique_abbr": "Utah;Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5247c201fa",
        "title": "Complex-to-Real Sketches for Tensor Products with Applications to the Polynomial Kernel",
        "site": "https://proceedings.mlr.press/v206/wacker23a.html",
        "author": "Jonas Wacker; Ruben Ohana; Maurizio Filippone",
        "abstract": "Randomized sketches of a tensor product of $p$ vectors follow a tradeoff between statistical efficiency and computational acceleration. Commonly used approaches avoid computing the high-dimensional tensor product explicitly, resulting in a suboptimal dependence of $O(3^p)$ in the embedding dimension. We propose a simple Complex-to-Real (CtR) modification of well-known sketches that replaces real random projections by complex ones, incurring a lower $O(2^p)$ factor in the embedding dimension. The output of our sketches is real-valued, which renders their downstream use straightforward. In particular, we apply our sketches to $p$-fold self-tensored inputs corresponding to the feature maps of the polynomial kernel. We show that our method achieves state-of-the-art performance in terms of accuracy and speed compared to other randomized approximations from the literature.",
        "bibtex": "@InProceedings{pmlr-v206-wacker23a,\n  title = \t {Complex-to-Real Sketches for Tensor Products with Applications to the Polynomial Kernel},\n  author =       {Wacker, Jonas and Ohana, Ruben and Filippone, Maurizio},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5181--5212},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wacker23a/wacker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wacker23a.html},\n  abstract = \t {Randomized sketches of a tensor product of $p$ vectors follow a tradeoff between statistical efficiency and computational acceleration. Commonly used approaches avoid computing the high-dimensional tensor product explicitly, resulting in a suboptimal dependence of $O(3^p)$ in the embedding dimension. We propose a simple Complex-to-Real (CtR) modification of well-known sketches that replaces real random projections by complex ones, incurring a lower $O(2^p)$ factor in the embedding dimension. The output of our sketches is real-valued, which renders their downstream use straightforward. In particular, we apply our sketches to $p$-fold self-tensored inputs corresponding to the feature maps of the polynomial kernel. We show that our method achieves state-of-the-art performance in terms of accuracy and speed compared to other randomized approximations from the literature.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wacker23a/wacker23a.pdf",
        "supp": "",
        "pdf_size": 1291982,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8411913396649864569&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "EURECOM, France; CCM, Flatiron Institute, USA + EURECOM, France; EURECOM, France",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "EURECOM;Flatiron Institute",
        "aff_unique_dep": ";CCM",
        "aff_unique_url": "https://www.eurecom.fr;https://flatironinstitute.org",
        "aff_unique_abbr": "EURECOM;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "f464de6b75",
        "title": "Compositional Probabilistic and Causal Inference using Tractable Circuit Models",
        "site": "https://proceedings.mlr.press/v206/wang23o.html",
        "author": "Benjie Wang; Marta Kwiatkowska",
        "abstract": "Probabilistic circuits (PCs) are a class of tractable probabilistic models, which admit efficient inference routines depending on their structural properties. In this paper, we introduce md-vtrees, a novel structural formulation of (marginal) determinism in structured decomposable PCs, which generalizes previously proposed classes such as probabilistic sentential decision diagrams. Crucially, we show how md-vtrees can be used to derive tractability conditions and efficient algorithms for advanced inference queries expressed as arbitrary compositions of basic probabilistic operations, such as marginalization, multiplication and reciprocals, in a sound and generalizable manner. In particular, we derive the first polytime algorithms for causal inference queries such as backdoor adjustment on PCs. As a practical instantiation of the framework, we propose MDNets, a novel PC architecture using md-vtrees, and empirically demonstrate their application to causal inference.",
        "bibtex": "@InProceedings{pmlr-v206-wang23o,\n  title = \t {Compositional Probabilistic and Causal Inference using Tractable Circuit Models},\n  author =       {Wang, Benjie and Kwiatkowska, Marta},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9488--9498},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23o/wang23o.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23o.html},\n  abstract = \t {Probabilistic circuits (PCs) are a class of tractable probabilistic models, which admit efficient inference routines depending on their structural properties. In this paper, we introduce md-vtrees, a novel structural formulation of (marginal) determinism in structured decomposable PCs, which generalizes previously proposed classes such as probabilistic sentential decision diagrams. Crucially, we show how md-vtrees can be used to derive tractability conditions and efficient algorithms for advanced inference queries expressed as arbitrary compositions of basic probabilistic operations, such as marginalization, multiplication and reciprocals, in a sound and generalizable manner. In particular, we derive the first polytime algorithms for causal inference queries such as backdoor adjustment on PCs. As a practical instantiation of the framework, we propose MDNets, a novel PC architecture using md-vtrees, and empirically demonstrate their application to causal inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23o/wang23o.pdf",
        "supp": "",
        "pdf_size": 328893,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18041324818583159707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Oxford; Department of Computer Science, University of Oxford",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "a8ea7435a0",
        "title": "Compress Then Test: Powerful Kernel Testing in Near-linear Time",
        "site": "https://proceedings.mlr.press/v206/domingo-enrich23a.html",
        "author": "Carles Domingo-Enrich; Raaz Dwivedi; Lester Mackey",
        "abstract": "Kernel two-sample testing provides a powerful framework for distinguishing any pair of distributions based on n sample points. However, existing kernel tests either run in $n^2$ time or sacrifice undue power to improve runtime. To address these shortcomings, we introduce Compress Then Test (CTT), a new framework for high-powered kernel testing based on sample compression. CTT cheaply approximates an expensive test by compressing each n point sample into a small but provably high-fidelity coreset. For standard kernels and subexponential distributions, CTT inherits the statistical behavior of a quadratic-time test\u2014recovering the same optimal detection boundary\u2014while running in near-linear time. We couple these advances with cheaper permutation testing, justified by new power analyses; improved time-vs.-quality guarantees for low-rank approximation; and a fast aggregation procedure for identifying especially discriminating kernels. In our experiments with real and simulated data, CTT and its extensions provide 20\u2013200x speed-ups over state-of-the-art approximate MMD tests with no loss of power.",
        "bibtex": "@InProceedings{pmlr-v206-domingo-enrich23a,\n  title = \t {Compress Then Test: Powerful Kernel Testing in Near-linear Time},\n  author =       {Domingo-Enrich, Carles and Dwivedi, Raaz and Mackey, Lester},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1174--1218},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/domingo-enrich23a/domingo-enrich23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/domingo-enrich23a.html},\n  abstract = \t {Kernel two-sample testing provides a powerful framework for distinguishing any pair of distributions based on n sample points. However, existing kernel tests either run in $n^2$ time or sacrifice undue power to improve runtime. To address these shortcomings, we introduce Compress Then Test (CTT), a new framework for high-powered kernel testing based on sample compression. CTT cheaply approximates an expensive test by compressing each n point sample into a small but provably high-fidelity coreset. For standard kernels and subexponential distributions, CTT inherits the statistical behavior of a quadratic-time test\u2014recovering the same optimal detection boundary\u2014while running in near-linear time. We couple these advances with cheaper permutation testing, justified by new power analyses; improved time-vs.-quality guarantees for low-rank approximation; and a fast aggregation procedure for identifying especially discriminating kernels. In our experiments with real and simulated data, CTT and its extensions provide 20\u2013200x speed-ups over state-of-the-art approximate MMD tests with no loss of power.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/domingo-enrich23a/domingo-enrich23a.pdf",
        "supp": "",
        "pdf_size": 21970605,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6237209558347108893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Courant Institute of Mathematical Sciences, NYU; Harvard University; MIT + Microsoft Research New England",
        "aff_domain": "nyu.edu;mit.edu;microsoft.com",
        "email": "nyu.edu;mit.edu;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3",
        "aff_unique_norm": "New York University;Harvard University;Massachusetts Institute of Technology;Microsoft",
        "aff_unique_dep": "Courant Institute of Mathematical Sciences;;;Microsoft Research",
        "aff_unique_url": "https://www.courant.nyu.edu;https://www.harvard.edu;https://web.mit.edu;https://www.microsoft.com/en-us/research/group/microsoft-research-new-england",
        "aff_unique_abbr": "NYU;Harvard;MIT;MSR NE",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "New York;;New England",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f09c782ca7",
        "title": "Computing Abductive Explanations for Boosted Trees",
        "site": "https://proceedings.mlr.press/v206/audemard23a.html",
        "author": "Gilles Audemard; Jean-Marie Lagniez; Pierre Marquis; Nicolas Szczepanski",
        "abstract": "Boosted trees is a dominant ML model, exhibiting high accuracy. However, boosted trees are hardly intelligible, and this is a problem whenever they are used in safety-critical applications. Indeed, in such a context, provably sound explanations for the predictions made are expected. Recent work have shown how subset-minimal abductive explanations can be derived for boosted trees, using automated reasoning techniques. However, the generation of such well-founded explanations is intractable in the general case. To improve the scalability of their generation, we introduce the notion of tree-specific explanation for a boosted tree. We show that tree-specific explanations are provably sound abductive explanations that can be computed in polynomial time. We also explain how to derive a subset-minimal abductive explanation from a tree-specific explanation. Experiments on various datasets show the computational benefits of leveraging tree-specific explanations for deriving subset-minimal abductive explanations.",
        "bibtex": "@InProceedings{pmlr-v206-audemard23a,\n  title = \t {Computing Abductive Explanations for Boosted Trees},\n  author =       {Audemard, Gilles and Lagniez, Jean-Marie and Marquis, Pierre and Szczepanski, Nicolas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4699--4711},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/audemard23a/audemard23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/audemard23a.html},\n  abstract = \t {Boosted trees is a dominant ML model, exhibiting high accuracy. However, boosted trees are hardly intelligible, and this is a problem whenever they are used in safety-critical applications. Indeed, in such a context, provably sound explanations for the predictions made are expected. Recent work have shown how subset-minimal abductive explanations can be derived for boosted trees, using automated reasoning techniques. However, the generation of such well-founded explanations is intractable in the general case. To improve the scalability of their generation, we introduce the notion of tree-specific explanation for a boosted tree. We show that tree-specific explanations are provably sound abductive explanations that can be computed in polynomial time. We also explain how to derive a subset-minimal abductive explanation from a tree-specific explanation. Experiments on various datasets show the computational benefits of leveraging tree-specific explanations for deriving subset-minimal abductive explanations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/audemard23a/audemard23a.pdf",
        "supp": "",
        "pdf_size": 713645,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11257497659757989775&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ccf57ed002",
        "title": "Conformal Off-Policy Prediction",
        "site": "https://proceedings.mlr.press/v206/zhang23c.html",
        "author": "Yingying Zhang; Chengchun Shi; Shikai Luo",
        "abstract": "Off-policy evaluation is critical in a number of applications where new policies need to be evaluated offline before online deployment. Most existing methods focus on the expected return, define the target parameter through averaging and provide a point estimator only. In this paper, we develop a novel procedure to produce reliable interval estimators for a target policy\u2019s return starting from any initial state. Our proposal accounts for the variability of the return around its expectation, focuses on the individual effect and offers valid uncertainty quantification. Our main idea lies in designing a pseudo policy that generates subsamples as if they were sampled from the target policy so that existing conformal prediction algorithms are applicable to prediction interval construction. Our methods are justified by theories, synthetic data and real data from short-video platforms.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23c,\n  title = \t {Conformal Off-Policy Prediction},\n  author =       {Zhang, Yingying and Shi, Chengchun and Luo, Shikai},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2751--2768},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23c/zhang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23c.html},\n  abstract = \t {Off-policy evaluation is critical in a number of applications where new policies need to be evaluated offline before online deployment. Most existing methods focus on the expected return, define the target parameter through averaging and provide a point estimator only. In this paper, we develop a novel procedure to produce reliable interval estimators for a target policy\u2019s return starting from any initial state. Our proposal accounts for the variability of the return around its expectation, focuses on the individual effect and offers valid uncertainty quantification. Our main idea lies in designing a pseudo policy that generates subsamples as if they were sampled from the target policy so that existing conformal prediction algorithms are applicable to prediction interval construction. Our methods are justified by theories, synthetic data and real data from short-video platforms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23c/zhang23c.pdf",
        "supp": "",
        "pdf_size": 512119,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17145093134072104769&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "227695e357",
        "title": "Conformalized Unconditional Quantile Regression",
        "site": "https://proceedings.mlr.press/v206/alaa23a.html",
        "author": "Ahmed M. Alaa; Zeshan Hussain; David Sontag",
        "abstract": "We develop a predictive inference procedure that combines conformal prediction (CP) with unconditional quantile regression (QR)-a commonly used tool in econometrics that involves regressing the recentered influence function (RIF) of the quantile functional over input covariates. Unlike the more widely known conditional QR, unconditional QR explicitly captures the impact of changes in covariate distribution on the quantiles of the marginal distribution of outcomes. Leveraging this property, our procedure issues adaptive predictive intervals with localized frequentist coverage guarantees. It operates by fitting a machine learning model for the RIFs using training data, and then applying the CP procedure for any test covariate with respect to a \u201chypothetical\u201d covariate distribution localized around the new instance. Experiments show that our procedure is adaptive to heteroscedasticity, provides transparent coverage guarantees that are relevant to the test instance at hand, and performs competitively with existing methods in terms of efficiency.",
        "bibtex": "@InProceedings{pmlr-v206-alaa23a,\n  title = \t {Conformalized Unconditional Quantile Regression},\n  author =       {Alaa, Ahmed M. and Hussain, Zeshan and Sontag, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10690--10702},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/alaa23a/alaa23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/alaa23a.html},\n  abstract = \t {We develop a predictive inference procedure that combines conformal prediction (CP) with unconditional quantile regression (QR)-a commonly used tool in econometrics that involves regressing the recentered influence function (RIF) of the quantile functional over input covariates. Unlike the more widely known conditional QR, unconditional QR explicitly captures the impact of changes in covariate distribution on the quantiles of the marginal distribution of outcomes. Leveraging this property, our procedure issues adaptive predictive intervals with localized frequentist coverage guarantees. It operates by fitting a machine learning model for the RIFs using training data, and then applying the CP procedure for any test covariate with respect to a \u201chypothetical\u201d covariate distribution localized around the new instance. Experiments show that our procedure is adaptive to heteroscedasticity, provides transparent coverage guarantees that are relevant to the test instance at hand, and performs competitively with existing methods in terms of efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/alaa23a/alaa23a.pdf",
        "supp": "",
        "pdf_size": 1125125,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=818974483343372710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "UC Berkeley; MIT; MIT",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Berkeley;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://web.mit.edu",
        "aff_unique_abbr": "UC Berkeley;MIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "74e8c38989",
        "title": "Conjugate Gradient Method for Generative Adversarial Networks",
        "site": "https://proceedings.mlr.press/v206/naganuma23a.html",
        "author": "Hiroki Naganuma; Hideaki Iiduka",
        "abstract": "One of the training strategies of generative models is to minimize the Jensen\u2013Shannon divergence between the model distribution and the data distribution. Since data distribution is unknown, generative adversarial networks (GANs) formulate this problem as a game between two models, a generator and a discriminator. The training can be formulated in the context of game theory and the local Nash equilibrium (LNE). It does not seem feasible to derive guarantees of stability or optimality for the existing methods. This optimization problem is far more challenging than the single objective setting. Here, we use the conjugate gradient method to reliably and efficiently solve the LNE problem in GANs. We give a proof and convergence analysis under mild assumptions showing that the proposed method converges to a LNE with three different learning rate update rules, including a constant learning rate. Finally, we demonstrate that the proposed method outperforms stochastic gradient descent (SGD) and momentum SGD in terms of best Frechet inception distance (FID) score and outperforms Adam on average.",
        "bibtex": "@InProceedings{pmlr-v206-naganuma23a,\n  title = \t {Conjugate Gradient Method for Generative Adversarial Networks},\n  author =       {Naganuma, Hiroki and Iiduka, Hideaki},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4381--4408},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/naganuma23a/naganuma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/naganuma23a.html},\n  abstract = \t {One of the training strategies of generative models is to minimize the Jensen\u2013Shannon divergence between the model distribution and the data distribution. Since data distribution is unknown, generative adversarial networks (GANs) formulate this problem as a game between two models, a generator and a discriminator. The training can be formulated in the context of game theory and the local Nash equilibrium (LNE). It does not seem feasible to derive guarantees of stability or optimality for the existing methods. This optimization problem is far more challenging than the single objective setting. Here, we use the conjugate gradient method to reliably and efficiently solve the LNE problem in GANs. We give a proof and convergence analysis under mild assumptions showing that the proposed method converges to a LNE with three different learning rate update rules, including a constant learning rate. Finally, we demonstrate that the proposed method outperforms stochastic gradient descent (SGD) and momentum SGD in terms of best Frechet inception distance (FID) score and outperforms Adam on average.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/naganuma23a/naganuma23a.pdf",
        "supp": "",
        "pdf_size": 1245530,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:2YMdhjmP6oMJ:scholar.google.com/&scioq=Conjugate+Gradient+Method+for+Generative+Adversarial+Networks&hl=en&as_sdt=0,14",
        "gs_version_total": 6,
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Meiji University",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/Hiroki11x/ConjugateGradient_GAN",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;Meiji University",
        "aff_unique_dep": "Mila;",
        "aff_unique_url": "https://umontreal.ca;https://www.meiji.ac.jp",
        "aff_unique_abbr": "UdeM;Meiji",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Montr\u00e9al;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Canada;Japan"
    },
    {
        "id": "3271827c77",
        "title": "Connectivity-contrastive learning: Combining causal discovery and representation learning for multimodal data",
        "site": "https://proceedings.mlr.press/v206/morioka23a.html",
        "author": "Hiroshi Morioka; Aapo Hyvarinen",
        "abstract": "Causal discovery methods typically extract causal relations between multiple nodes (variables) based on univariate observations of each node. However, one frequently encounters situations where each node is multivariate, i.e. has multiple observational modalities. Furthermore, the observed modalities may be generated through an unknown mixing process, so that some original latent variables are entangled inside the nodes. In such a multimodal case, the existing frameworks cannot be applied. To analyze such data, we propose a new causal representation learning framework called connectivity-contrastive learning (CCL). CCL disentangles the observational mixing and extracts a set of mutually independent latent components, each having a separate causal structure between the nodes. The actual learning proceeds by a novel self-supervised learning method in which the pretext task is to predict the label of a pair of nodes from the observations of the node pairs. We present theorems which show that CCL can indeed identify both the latent components and the multimodal causal structure under weak technical assumptions, up to some indeterminacy. Finally, we experimentally show its superior causal discovery performance compared to state-of-the-art baselines, in particular demonstrating robustness against latent confounders.",
        "bibtex": "@InProceedings{pmlr-v206-morioka23a,\n  title = \t {Connectivity-contrastive learning: Combining causal discovery and representation learning for multimodal data},\n  author =       {Morioka, Hiroshi and Hyvarinen, Aapo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3399--3426},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/morioka23a/morioka23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/morioka23a.html},\n  abstract = \t {Causal discovery methods typically extract causal relations between multiple nodes (variables) based on univariate observations of each node. However, one frequently encounters situations where each node is multivariate, i.e. has multiple observational modalities. Furthermore, the observed modalities may be generated through an unknown mixing process, so that some original latent variables are entangled inside the nodes. In such a multimodal case, the existing frameworks cannot be applied. To analyze such data, we propose a new causal representation learning framework called connectivity-contrastive learning (CCL). CCL disentangles the observational mixing and extracts a set of mutually independent latent components, each having a separate causal structure between the nodes. The actual learning proceeds by a novel self-supervised learning method in which the pretext task is to predict the label of a pair of nodes from the observations of the node pairs. We present theorems which show that CCL can indeed identify both the latent components and the multimodal causal structure under weak technical assumptions, up to some indeterminacy. Finally, we experimentally show its superior causal discovery performance compared to state-of-the-art baselines, in particular demonstrating robustness against latent confounders.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/morioka23a/morioka23a.pdf",
        "supp": "",
        "pdf_size": 3690909,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=751740941890445820&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "RIKEN AIP; University of Helsinki + Universit\u00e9 Paris-Saclay, Inria",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "RIKEN;University of Helsinki;Universit\u00e9 Paris-Saclay",
        "aff_unique_dep": "Advanced Institute for Computational Science;;",
        "aff_unique_url": "https://www.aip.riken.jp;https://www.helsinki.fi;https://www.universite-paris-saclay.fr",
        "aff_unique_abbr": "RIKEN AIP;UH;UPS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+2",
        "aff_country_unique": "Japan;Finland;France"
    },
    {
        "id": "6783cdb43e",
        "title": "Consistent Complementary-Label Learning via Order-Preserving Losses",
        "site": "https://proceedings.mlr.press/v206/liu23g.html",
        "author": "Shuqi Liu; Yuzhou Cao; Qiaozhen Zhang; Lei Feng; Bo An",
        "abstract": "In contrast to ordinary supervised classification tasks that require massive data with high-quality labels, complementary-label learning (CLL) deals with the weakly-supervised learning scenario where each instance is equipped with a complementary label, which specifies a class the instance does not belong to. However, most of the existing statistically consistent CLL methods suffer from overfitting intrinsically, due to the negative empirical risk issue. In this paper, we aim to propose overfitting-resistant and theoretically grounded methods for CLL. Considering the unique property of the distribution of complementarily labeled samples, we provide a risk estimator via order-preserving losses, which are naturally non-negative and thus can avoid overfitting caused by negative terms in risk estimators. Moreover, we provide classifier-consistency analysis and statistical guarantee for this estimator. Furthermore, we provide a weighed version of the proposed risk estimator to further enhance its generalization ability and prove its statistical consistency. Experiments on benchmark datasets demonstrate the effectiveness of our proposed methods.",
        "bibtex": "@InProceedings{pmlr-v206-liu23g,\n  title = \t {Consistent Complementary-Label Learning via Order-Preserving Losses},\n  author =       {Liu, Shuqi and Cao, Yuzhou and Zhang, Qiaozhen and Feng, Lei and An, Bo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8734--8748},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23g/liu23g.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23g.html},\n  abstract = \t {In contrast to ordinary supervised classification tasks that require massive data with high-quality labels, complementary-label learning (CLL) deals with the weakly-supervised learning scenario where each instance is equipped with a complementary label, which specifies a class the instance does not belong to. However, most of the existing statistically consistent CLL methods suffer from overfitting intrinsically, due to the negative empirical risk issue. In this paper, we aim to propose overfitting-resistant and theoretically grounded methods for CLL. Considering the unique property of the distribution of complementarily labeled samples, we provide a risk estimator via order-preserving losses, which are naturally non-negative and thus can avoid overfitting caused by negative terms in risk estimators. Moreover, we provide classifier-consistency analysis and statistical guarantee for this estimator. Furthermore, we provide a weighed version of the proposed risk estimator to further enhance its generalization ability and prove its statistical consistency. Experiments on benchmark datasets demonstrate the effectiveness of our proposed methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23g/liu23g.pdf",
        "supp": "",
        "pdf_size": 2600528,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15309639403445552397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Statistics and Data Science, Nankai University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Statistics and Data Science, Nankai University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "aff_domain": "nankai.edu.cn; ; ; ; ",
        "email": "nankai.edu.cn; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Nankai University;Nanyang Technological University",
        "aff_unique_dep": "School of Statistics and Data Science;School of Computer Science and Engineering",
        "aff_unique_url": "http://www.nankai.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "Nankai;NTU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "c515f5ccbf",
        "title": "Context-Specific Causal Discovery for Categorical Data Using Staged Trees",
        "site": "https://proceedings.mlr.press/v206/leonelli23a.html",
        "author": "Manuele Leonelli; Gherardo Varando",
        "abstract": "Causal discovery algorithms aim at untangling complex causal relationships from data. Here, we study causal discovery and inference methods based on staged tree models, which can represent complex and asymmetric causal relationships between categorical variables. We provide a first graphical representation of the equivalence class of a staged tree, by looking only at a specific subset of its underlying independences. We further define a new pre-metric, inspired by the widely used structural intervention distance, to quantify the closeness between two staged trees in terms of their corresponding causal inference statements. A simulation study highlights the efficacy of staged trees in uncovering complexes, asymmetric causal relationships from data, and real-world data applications illustrate their use in practical causal analysis.",
        "bibtex": "@InProceedings{pmlr-v206-leonelli23a,\n  title = \t {Context-Specific Causal Discovery for Categorical Data Using Staged Trees},\n  author =       {Leonelli, Manuele and Varando, Gherardo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8871--8888},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/leonelli23a/leonelli23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/leonelli23a.html},\n  abstract = \t {Causal discovery algorithms aim at untangling complex causal relationships from data. Here, we study causal discovery and inference methods based on staged tree models, which can represent complex and asymmetric causal relationships between categorical variables. We provide a first graphical representation of the equivalence class of a staged tree, by looking only at a specific subset of its underlying independences. We further define a new pre-metric, inspired by the widely used structural intervention distance, to quantify the closeness between two staged trees in terms of their corresponding causal inference statements. A simulation study highlights the efficacy of staged trees in uncovering complexes, asymmetric causal relationships from data, and real-world data applications illustrate their use in practical causal analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/leonelli23a/leonelli23a.pdf",
        "supp": "",
        "pdf_size": 493398,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8853166232623554347&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Science and Technology, IE University, Madrid, Spain; Image Processing Laboratory, Universitat de Val\u00e8ncia, Val\u00e8ncia, Spain",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "IE University;Universitat de Val\u00e8ncia",
        "aff_unique_dep": "School of Science and Technology;Image Processing Laboratory",
        "aff_unique_url": "https://www.ie.edu;https://www.uv.es",
        "aff_unique_abbr": "IEU;",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Madrid;Val\u00e8ncia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "db0fe499c6",
        "title": "Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles",
        "site": "https://proceedings.mlr.press/v206/kim23b.html",
        "author": "Jung-Hun Kim; Se-Young Yun; Minchan Jeong; Junhyun Nam; Jinwoo Shin; Richard Combes",
        "abstract": "We study contextual linear bandit problems under feature uncertainty; they are noisy with missing entries. To address the challenges of the noise, we analyze Bayesian oracles given observed noisy features. Our Bayesian analysis finds that the optimal hypothesis can be far from the underlying realizability function, depending on the noise characteristics, which are highly non-intuitive and do not occur for classical noiseless setups. This implies that classical approaches cannot guarantee a non-trivial regret bound. Therefore, we propose an algorithm that aims at the Bayesian oracle from observed information under this model, achieving $\\tilde{O}(d\\sqrt{T})$ regret bound when there is a large number of arms. We demonstrate the proposed algorithm using synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v206-kim23b,\n  title = \t {Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles},\n  author =       {Kim, Jung-Hun and Yun, Se-Young and Jeong, Minchan and Nam, Junhyun and Shin, Jinwoo and Combes, Richard},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1624--1645},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kim23b/kim23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kim23b.html},\n  abstract = \t {We study contextual linear bandit problems under feature uncertainty; they are noisy with missing entries. To address the challenges of the noise, we analyze Bayesian oracles given observed noisy features. Our Bayesian analysis finds that the optimal hypothesis can be far from the underlying realizability function, depending on the noise characteristics, which are highly non-intuitive and do not occur for classical noiseless setups. This implies that classical approaches cannot guarantee a non-trivial regret bound. Therefore, we propose an algorithm that aims at the Bayesian oracle from observed information under this model, achieving $\\tilde{O}(d\\sqrt{T})$ regret bound when there is a large number of arms. We demonstrate the proposed algorithm using synthetic and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kim23b/kim23b.pdf",
        "supp": "",
        "pdf_size": 654244,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9890570718210146587&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Korea Advanced Institute of Science & Technology (KAIST), South Korea; Korea Advanced Institute of Science & Technology (KAIST), South Korea; Korea Advanced Institute of Science & Technology (KAIST), South Korea; Korea Advanced Institute of Science & Technology (KAIST), South Korea; Korea Advanced Institute of Science & Technology (KAIST), South Korea; Universit \u00b4e Paris-Saclay, CNRS, CentraleSup \u00b4elec, Laboratoire des signaux et syst `emes, France",
        "aff_domain": "kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;centralesupelec.fr",
        "email": "kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;centralesupelec.fr",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Universit\u00e9 Paris-Saclay",
        "aff_unique_dep": ";Laboratoire des signaux et syst\u00e8mes",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.universite-paris-saclay.fr",
        "aff_unique_abbr": "KAIST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "South Korea;France"
    },
    {
        "id": "878d428e97",
        "title": "Continuous-Time Decision Transformer for Healthcare Applications",
        "site": "https://proceedings.mlr.press/v206/zhang23i.html",
        "author": "Zhiyue Zhang; Hongyuan Mei; Yanxun Xu",
        "abstract": "Offline reinforcement learning (RL) is a promising approach for training intelligent medical agents to learn treatment policies and assist decision making in many healthcare applications, such as scheduling clinical visits and assigning dosages for patients with chronic conditions. In this paper, we investigate the potential usefulness of Decision Transformer (Chen et al., 2021)\u2013a new offline RL paradign\u2013  in medical domains where decision making in continuous time is desired. As Decision Transformer only handles discrete-time (or turn-based) sequential decision making scenarios, we generalize it to Continuous-Time Decision Transformer that not only considers the past clinical measurements and treatments but also the timings of previous visits, and learns to suggest the timings of future visits as well as the treatment plan at each visit. Extensive experiments on synthetic datasets and simulators motivated by real-world medical applications demonstrate that Continuous-Time Decision Transformer is able to outperform competitors and has clinical utility in terms of improving patients\u2019 health and prolonging their survival by learning high-performance policies from logged data generated using policies of different levels of quality.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23i,\n  title = \t {Continuous-Time Decision Transformer for Healthcare Applications},\n  author =       {Zhang, Zhiyue and Mei, Hongyuan and Xu, Yanxun},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6245--6262},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23i/zhang23i.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23i.html},\n  abstract = \t {Offline reinforcement learning (RL) is a promising approach for training intelligent medical agents to learn treatment policies and assist decision making in many healthcare applications, such as scheduling clinical visits and assigning dosages for patients with chronic conditions. In this paper, we investigate the potential usefulness of Decision Transformer (Chen et al., 2021)\u2013a new offline RL paradign\u2013  in medical domains where decision making in continuous time is desired. As Decision Transformer only handles discrete-time (or turn-based) sequential decision making scenarios, we generalize it to Continuous-Time Decision Transformer that not only considers the past clinical measurements and treatments but also the timings of previous visits, and learns to suggest the timings of future visits as well as the treatment plan at each visit. Extensive experiments on synthetic datasets and simulators motivated by real-world medical applications demonstrate that Continuous-Time Decision Transformer is able to outperform competitors and has clinical utility in terms of improving patients\u2019 health and prolonging their survival by learning high-performance policies from logged data generated using policies of different levels of quality.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23i/zhang23i.pdf",
        "supp": "",
        "pdf_size": 477045,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11614890334192599723&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f77f30778f",
        "title": "Convergence of Stein Variational Gradient Descent under a Weaker Smoothness Condition",
        "site": "https://proceedings.mlr.press/v206/sun23d.html",
        "author": "Lukang Sun; Avetik Karagulyan; Peter Richtarik",
        "abstract": "Stein Variational Gradient Descent (SVGD) is an important alternative to the Langevin-type algorithms for sampling from probability distributions of the form $\\pi(x) \\propto \\exp(-V(x))$. In the existing theory of Langevin-type algorithms and SVGD, the potential function $V$ is often assumed to be $L$-smooth. However, this restrictive condition excludes a large class of potential functions such as polynomials of degree greater than $2$. Our paper studies the convergence of the SVGD algorithm for distributions with $(L_0,L_1)$-smooth potentials. This relaxed smoothness assumption was introduced by Zhang et al. [2019a] for the analysis of gradient clipping algorithms. With the help of trajectory-independent auxiliary conditions, we provide a descent lemma establishing that the algorithm decreases the KL divergence at each iteration and prove a complexity bound for SVGD in the population limit in terms of the Stein Fisher information.",
        "bibtex": "@InProceedings{pmlr-v206-sun23d,\n  title = \t {Convergence of Stein Variational Gradient Descent under a Weaker Smoothness Condition},\n  author =       {Sun, Lukang and Karagulyan, Avetik and Richtarik, Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3693--3717},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sun23d/sun23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sun23d.html},\n  abstract = \t {Stein Variational Gradient Descent (SVGD) is an important alternative to the Langevin-type algorithms for sampling from probability distributions of the form $\\pi(x) \\propto \\exp(-V(x))$. In the existing theory of Langevin-type algorithms and SVGD, the potential function $V$ is often assumed to be $L$-smooth. However, this restrictive condition excludes a large class of potential functions such as polynomials of degree greater than $2$. Our paper studies the convergence of the SVGD algorithm for distributions with $(L_0,L_1)$-smooth potentials. This relaxed smoothness assumption was introduced by Zhang et al. [2019a] for the analysis of gradient clipping algorithms. With the help of trajectory-independent auxiliary conditions, we provide a descent lemma establishing that the algorithm decreases the KL divergence at each iteration and prove a complexity bound for SVGD in the population limit in terms of the Stein Fisher information.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sun23d/sun23d.pdf",
        "supp": "",
        "pdf_size": 1332403,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12056539209830748841&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5473cb1467",
        "title": "Convex Bounds on the Softmax Function with Applications to Robustness Verification",
        "site": "https://proceedings.mlr.press/v206/wei23c.html",
        "author": "Dennis Wei; Haoze Wu; Min Wu; Pin-Yu Chen; Clark Barrett; Eitan Farchi",
        "abstract": "The softmax function is a ubiquitous component at the output of neural networks and increasingly in intermediate layers as well. This paper provides convex lower bounds and concave upper bounds on the softmax function, which are compatible with convex optimization formulations for characterizing neural networks and other ML models. We derive bounds using both a natural exponential-reciprocal decomposition of the softmax as well as an alternative decomposition in terms of the log-sum-exp function. The new bounds are provably and/or numerically tighter than linear bounds obtained in previous work on robustness verification of transformers. As illustrations of the utility of the bounds, we apply them to verification of transformers as well as of the robustness of predictive uncertainty estimates of deep ensembles.",
        "bibtex": "@InProceedings{pmlr-v206-wei23c,\n  title = \t {Convex Bounds on the Softmax Function with Applications to Robustness Verification},\n  author =       {Wei, Dennis and Wu, Haoze and Wu, Min and Chen, Pin-Yu and Barrett, Clark and Farchi, Eitan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6853--6878},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wei23c/wei23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wei23c.html},\n  abstract = \t {The softmax function is a ubiquitous component at the output of neural networks and increasingly in intermediate layers as well. This paper provides convex lower bounds and concave upper bounds on the softmax function, which are compatible with convex optimization formulations for characterizing neural networks and other ML models. We derive bounds using both a natural exponential-reciprocal decomposition of the softmax as well as an alternative decomposition in terms of the log-sum-exp function. The new bounds are provably and/or numerically tighter than linear bounds obtained in previous work on robustness verification of transformers. As illustrations of the utility of the bounds, we apply them to verification of transformers as well as of the robustness of predictive uncertainty estimates of deep ensembles.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wei23c/wei23c.pdf",
        "supp": "",
        "pdf_size": 1126354,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1274588695046399573&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "474c42406a",
        "title": "Convolutional Persistence as a Remedy to Neural Model Analysis",
        "site": "https://proceedings.mlr.press/v206/khramtsova23a.html",
        "author": "Ekaterina Khramtsova; Guido Zuccon; Xi Wang; Mahsa Baktashmotlagh",
        "abstract": "While deep neural networks are proven to be effective learning systems, their analysis is complex due to the high-dimensionality of their weight space. Persistent topological properties can be used as an additional descriptor, providing insights on how the network weights evolve during training. In this paper, we focus on convolutional neural networks, and define the topology of the space, populated by convolutional filters (i.e., kernels). We perform an extensive analysis of topological properties of the convolutional filters. Specifically, we define a metric based on persistent homology, namely, Convolutional Topology Representation, to determine an important factor in neural networks training: the generalizability of the model to the test set. We further analyse how various training methods affect the topology of convolutional layers.",
        "bibtex": "@InProceedings{pmlr-v206-khramtsova23a,\n  title = \t {Convolutional Persistence as a Remedy to Neural Model Analysis},\n  author =       {Khramtsova, Ekaterina and Zuccon, Guido and Wang, Xi and Baktashmotlagh, Mahsa},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10839--10855},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/khramtsova23a/khramtsova23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/khramtsova23a.html},\n  abstract = \t {While deep neural networks are proven to be effective learning systems, their analysis is complex due to the high-dimensionality of their weight space. Persistent topological properties can be used as an additional descriptor, providing insights on how the network weights evolve during training. In this paper, we focus on convolutional neural networks, and define the topology of the space, populated by convolutional filters (i.e., kernels). We perform an extensive analysis of topological properties of the convolutional filters. Specifically, we define a metric based on persistent homology, namely, Convolutional Topology Representation, to determine an important factor in neural networks training: the generalizability of the model to the test set. We further analyse how various training methods affect the topology of convolutional layers.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/khramtsova23a/khramtsova23a.pdf",
        "supp": "",
        "pdf_size": 1508579,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8899643774529246652&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1b2f319f2c",
        "title": "Cooperative Inverse Decision Theory for Uncertain Preferences",
        "site": "https://proceedings.mlr.press/v206/robertson23a.html",
        "author": "Zachary Robertson; Hantao Zhang; Sanmi Koyejo",
        "abstract": "Inverse decision theory (IDT) aims to learn a performance metric for classification by eliciting expert classifications on examples. However, elicitation in practical settings may require many classifications of potentially ambiguous examples. To improve the efficiency of elicitation, we propose the cooperative inverse decision theory (CIDT) framework as a formalization of the performance metric elicitation problem. In cooperative inverse decision theory, the expert and a machine play a game where both are rewarded according to the expert\u2019s performance metric, but the machine does not initially know what this function is. We show that optimal policies in this framework produce active learning that leads to an exponential improvement in sample complexity over previous work. One of our key findings is that a broad class of sub-optimal experts can be represented as having uncertain preferences. We use this finding to show such experts naturally fit into our proposed framework extending inverse decision theory to efficiently deal with decision data that is sub-optimal due to noise, conflicting experts, or systematic error.",
        "bibtex": "@InProceedings{pmlr-v206-robertson23a,\n  title = \t {Cooperative Inverse Decision Theory for Uncertain Preferences},\n  author =       {Robertson, Zachary and Zhang, Hantao and Koyejo, Sanmi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5854--5868},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/robertson23a/robertson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/robertson23a.html},\n  abstract = \t {Inverse decision theory (IDT) aims to learn a performance metric for classification by eliciting expert classifications on examples. However, elicitation in practical settings may require many classifications of potentially ambiguous examples. To improve the efficiency of elicitation, we propose the cooperative inverse decision theory (CIDT) framework as a formalization of the performance metric elicitation problem. In cooperative inverse decision theory, the expert and a machine play a game where both are rewarded according to the expert\u2019s performance metric, but the machine does not initially know what this function is. We show that optimal policies in this framework produce active learning that leads to an exponential improvement in sample complexity over previous work. One of our key findings is that a broad class of sub-optimal experts can be represented as having uncertain preferences. We use this finding to show such experts naturally fit into our proposed framework extending inverse decision theory to efficiently deal with decision data that is sub-optimal due to noise, conflicting experts, or systematic error.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/robertson23a/robertson23a.pdf",
        "supp": "",
        "pdf_size": 1957895,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Zrgj0hE6MicJ:scholar.google.com/&scioq=Cooperative+Inverse+Decision+Theory+for+Uncertain+Preferences&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c538c53569",
        "title": "Coordinate Ascent for Off-Policy RL with Global Convergence Guarantees",
        "site": "https://proceedings.mlr.press/v206/su23a.html",
        "author": "Hsin-En Su; Yen-Ju Chen; Ping-Chun Hsieh; Xi Liu",
        "abstract": "We revisit the domain of off-policy policy optimization in RL from the perspective of coordinate ascent. One commonly-used approach is to leverage the off-policy policy gradient to optimize a surrogate objective \u2013 the total discounted in expectation return of the target policy with respect to the state distribution of the behavior policy. However, this approach has been shown to suffer from the distribution mismatch issue, and therefore significant efforts are needed for correcting this mismatch either via state distribution correction or a counterfactual method. In this paper, we rethink off-policy learning via Coordinate Ascent Policy Optimization (CAPO), an off-policy actor-critic algorithm that decouples policy improvement from the state distribution of the behavior policy without using the policy gradient. This design obviates the need for distribution correction or importance sampling in the policy improvement step of off-policy policy gradient. We establish the global convergence of CAPO with general coordinate selection and then further quantify the convergence rates of several instances of CAPO with popular coordinate selection rules, including the cyclic and the randomized variants of CAPO. We then extend CAPO to neural policies for a more practical implementation. Through experiments, we demonstrate that CAPO provides a competitive approach to RL in practice.",
        "bibtex": "@InProceedings{pmlr-v206-su23a,\n  title = \t {Coordinate Ascent for Off-Policy RL with Global Convergence Guarantees},\n  author =       {Su, Hsin-En and Chen, Yen-Ju and Hsieh, Ping-Chun and Liu, Xi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1331--1378},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/su23a/su23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/su23a.html},\n  abstract = \t {We revisit the domain of off-policy policy optimization in RL from the perspective of coordinate ascent. One commonly-used approach is to leverage the off-policy policy gradient to optimize a surrogate objective \u2013 the total discounted in expectation return of the target policy with respect to the state distribution of the behavior policy. However, this approach has been shown to suffer from the distribution mismatch issue, and therefore significant efforts are needed for correcting this mismatch either via state distribution correction or a counterfactual method. In this paper, we rethink off-policy learning via Coordinate Ascent Policy Optimization (CAPO), an off-policy actor-critic algorithm that decouples policy improvement from the state distribution of the behavior policy without using the policy gradient. This design obviates the need for distribution correction or importance sampling in the policy improvement step of off-policy policy gradient. We establish the global convergence of CAPO with general coordinate selection and then further quantify the convergence rates of several instances of CAPO with popular coordinate selection rules, including the cyclic and the randomized variants of CAPO. We then extend CAPO to neural policies for a more practical implementation. Through experiments, we demonstrate that CAPO provides a competitive approach to RL in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/su23a/su23a.pdf",
        "supp": "",
        "pdf_size": 2587068,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:WIqOgqQdWJ8J:scholar.google.com/&scioq=Coordinate+Ascent+for+Off-Policy+RL+with+Global+Convergence+Guarantees&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Applied Machine Learning, Meta AI, Menlo Park, CA, USA",
        "aff_domain": "nycu.edu.tw;nycu.edu.tw;nycu.edu.tw;gmail.com",
        "email": "nycu.edu.tw;nycu.edu.tw;nycu.edu.tw;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "National Yang Ming Chiao Tung University;Meta",
        "aff_unique_dep": "Department of Computer Science;Applied Machine Learning",
        "aff_unique_url": "https://www.nctu.edu.tw;https://ai.facebook.com",
        "aff_unique_abbr": "NYCU;Meta AI",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Taiwan;Menlo Park",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "43d7a119d9",
        "title": "Coordinate Descent for SLOPE",
        "site": "https://proceedings.mlr.press/v206/larsson23a.html",
        "author": "Johan Larsson; Quentin Klopfenstein; Mathurin Massias; Jonas Wallin",
        "abstract": "The lasso is the most famous sparse regression and feature selection method. One reason for its popularity is the speed at which the underlying optimization problem can be solved. Sorted L-One Penalized Estimation (SLOPE) is a generalization of the lasso with appealing statistical properties. In spite of this, the method has not yet reached widespread interest. A major reason for this is that current software packages that fit SLOPE rely on algorithms that perform poorly in high dimensions. To tackle this issue, we propose a new fast algorithm to solve the SLOPE optimization problem, which combines proximal gradient descent and proximal coordinate descent steps. We provide new results on the directional derivative of the SLOPE penalty and its related SLOPE thresholding operator, as well as provide convergence guarantees for our proposed solver. In extensive benchmarks on simulated and real data, we demonstrate our method\u2019s performance against a long list of competing algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-larsson23a,\n  title = \t {Coordinate Descent for SLOPE},\n  author =       {Larsson, Johan and Klopfenstein, Quentin and Massias, Mathurin and Wallin, Jonas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4802--4821},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/larsson23a/larsson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/larsson23a.html},\n  abstract = \t {The lasso is the most famous sparse regression and feature selection method. One reason for its popularity is the speed at which the underlying optimization problem can be solved. Sorted L-One Penalized Estimation (SLOPE) is a generalization of the lasso with appealing statistical properties. In spite of this, the method has not yet reached widespread interest. A major reason for this is that current software packages that fit SLOPE rely on algorithms that perform poorly in high dimensions. To tackle this issue, we propose a new fast algorithm to solve the SLOPE optimization problem, which combines proximal gradient descent and proximal coordinate descent steps. We provide new results on the directional derivative of the SLOPE penalty and its related SLOPE thresholding operator, as well as provide convergence guarantees for our proposed solver. In extensive benchmarks on simulated and real data, we demonstrate our method\u2019s performance against a long list of competing algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/larsson23a/larsson23a.pdf",
        "supp": "",
        "pdf_size": 2597629,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13052809431030703098&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Statistics, Lund University, Sweden; Luxembourg Centre for Systems Biomedicine, University of Luxembourg, Luxembourg; Univ. Lyon, Inria, CNRS, ENS de Lyon, UCB Lyon 1, LIP UMR 5668, F-69342 Lyon, France + Department of Statistics, Lund University, Sweden; Department of Statistics, Lund University, Sweden",
        "aff_domain": "stat.lu.se;uni.lu;inria.fr;stat.lu.se",
        "email": "stat.lu.se;uni.lu;inria.fr;stat.lu.se",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+0;0",
        "aff_unique_norm": "Lund University;University of Luxembourg;University of Lyon",
        "aff_unique_dep": "Department of Statistics;Luxembourg Centre for Systems Biomedicine;",
        "aff_unique_url": "https://www.lunduniversity.lu.se;https://wwwen.unil.lu;https://www.universite-lyon.fr",
        "aff_unique_abbr": "LU;UniLu;Univ. Lyon",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Lyon",
        "aff_country_unique_index": "0;1;2+0;0",
        "aff_country_unique": "Sweden;Luxembourg;France"
    },
    {
        "id": "8472ed01be",
        "title": "Covariate-informed Representation Learning to Prevent Posterior Collapse of iVAE",
        "site": "https://proceedings.mlr.press/v206/kim23c.html",
        "author": "Young-Geun Kim; Ying Liu; Xue-Xin Wei",
        "abstract": "The recently proposed identifiable variational autoencoder (iVAE) framework provides a promising approach for learning latent independent components (ICs). iVAEs use auxiliary covariates to build an identifiable generation structure from covariates to ICs to observations, and the posterior network approximates ICs given observations and covariates. Though the identifiability is appealing, we show that iVAEs could have local minimum solution where observations and the approximated ICs are independent given covariates.\u2013 a phenomenon we referred to as the posterior collapse problem of iVAEs. To overcome this problem, we develop a new approach, covariate-informed iVAE (CI-iVAE) by considering a mixture of encoder and posterior distributions in the objective function. In doing so, the objective function prevents the posterior collapse, resulting latent representations that contain more information of the observations. Furthermore, CI-iVAE extends the original iVAE objective function to a larger class and finds the optimal one among them, thus having tighter evidence lower bounds than the original iVAE. Experiments on simulation datasets, EMNIST, Fashion-MNIST, and a large-scale brain imaging dataset demonstrate the effectiveness of our new method.",
        "bibtex": "@InProceedings{pmlr-v206-kim23c,\n  title = \t {Covariate-informed Representation Learning to Prevent Posterior Collapse of iVAE},\n  author =       {Kim, Young-Geun and Liu, Ying and Wei, Xue-Xin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2641--2660},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kim23c/kim23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kim23c.html},\n  abstract = \t {The recently proposed identifiable variational autoencoder (iVAE) framework provides a promising approach for learning latent independent components (ICs). iVAEs use auxiliary covariates to build an identifiable generation structure from covariates to ICs to observations, and the posterior network approximates ICs given observations and covariates. Though the identifiability is appealing, we show that iVAEs could have local minimum solution where observations and the approximated ICs are independent given covariates.\u2013 a phenomenon we referred to as the posterior collapse problem of iVAEs. To overcome this problem, we develop a new approach, covariate-informed iVAE (CI-iVAE) by considering a mixture of encoder and posterior distributions in the objective function. In doing so, the objective function prevents the posterior collapse, resulting latent representations that contain more information of the observations. Furthermore, CI-iVAE extends the original iVAE objective function to a larger class and finds the optimal one among them, thus having tighter evidence lower bounds than the original iVAE. Experiments on simulation datasets, EMNIST, Fashion-MNIST, and a large-scale brain imaging dataset demonstrate the effectiveness of our new method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kim23c/kim23c.pdf",
        "supp": "",
        "pdf_size": 2206288,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3121854412151864543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Psychiatry and Department of Biostatistics, Columbia University; Department of Psychiatry and Department of Biostatistics, Columbia University; Department of Neuroscience and Department of Psychology, The University of Texas at Austin",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Columbia University;University of Texas at Austin",
        "aff_unique_dep": "Department of Psychiatry;Department of Neuroscience",
        "aff_unique_url": "https://www.columbia.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Columbia;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "dcb07cc97f",
        "title": "DIET: Conditional independence testing with marginal dependence measures of residual information",
        "site": "https://proceedings.mlr.press/v206/sudarshan23a.html",
        "author": "Mukund Sudarshan; Aahlad Puli; Wesley Tansey; Rajesh Ranganath",
        "abstract": "Conditional randomization tests (CRTs) assess whether a variable $x$ is predictive of another variable $y$, having observed covariates $z$. CRTs require fitting a large number of predictive models, which is often computationally intractable. Existing solutions to reduce the cost of CRTs typically split the dataset into a train and test portion, or rely on heuristics for interactions, both of which lead to a loss in power. We propose the decoupled independence test (DIET), an algorithm that avoids both of these issues by leveraging marginal independence statistics to test conditional independence relationships. DIET tests the marginal independence of two random variables: $F_{x\\vert z}(x \\vert z)$ and $F_{y\\vert z}(y \\vert z)$ where $F_{\\cdot \\vert z}(\\cdot \\vert z)$ is a conditional cumulative distribution function (CDF) for the distribution $p(\\cdot \\vert z)$. These variables are termed \u201cinformation residuals.\u201d We give sufficient conditions for DIET to achieve finite sample type-1 error control and power greater than the type-1 error rate. We then prove that when using the mutual information between the information residuals as a test statistic, DIET yields the most powerful conditionally valid test. Finally, we show DIET achieves higher power than other tractable CRTs on several synthetic and real benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-sudarshan23a,\n  title = \t {DIET: Conditional independence testing with marginal dependence measures of residual information},\n  author =       {Sudarshan, Mukund and Puli, Aahlad and Tansey, Wesley and Ranganath, Rajesh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10343--10367},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sudarshan23a/sudarshan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sudarshan23a.html},\n  abstract = \t {Conditional randomization tests (CRTs) assess whether a variable $x$ is predictive of another variable $y$, having observed covariates $z$. CRTs require fitting a large number of predictive models, which is often computationally intractable. Existing solutions to reduce the cost of CRTs typically split the dataset into a train and test portion, or rely on heuristics for interactions, both of which lead to a loss in power. We propose the decoupled independence test (DIET), an algorithm that avoids both of these issues by leveraging marginal independence statistics to test conditional independence relationships. DIET tests the marginal independence of two random variables: $F_{x\\vert z}(x \\vert z)$ and $F_{y\\vert z}(y \\vert z)$ where $F_{\\cdot \\vert z}(\\cdot \\vert z)$ is a conditional cumulative distribution function (CDF) for the distribution $p(\\cdot \\vert z)$. These variables are termed \u201cinformation residuals.\u201d We give sufficient conditions for DIET to achieve finite sample type-1 error control and power greater than the type-1 error rate. We then prove that when using the mutual information between the information residuals as a test statistic, DIET yields the most powerful conditionally valid test. Finally, we show DIET achieves higher power than other tractable CRTs on several synthetic and real benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sudarshan23a/sudarshan23a.pdf",
        "supp": "",
        "pdf_size": 1657366,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16816234739018636750&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Computer Science, New York University; Computer Science, New York University; Computational Oncology, Memorial Sloan Kettering Cancer Center; Computer Science, Data Science, and Population Health at Langone Health, New York University",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "New York University;Memorial Sloan Kettering Cancer Center",
        "aff_unique_dep": "Computer Science;Computational Oncology",
        "aff_unique_url": "https://www.nyu.edu;https://www.mskcc.org",
        "aff_unique_abbr": "NYU;MSKCC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "77951faa71",
        "title": "Data Augmentation for Imbalanced Regression",
        "site": "https://proceedings.mlr.press/v206/stocksieker23a.html",
        "author": "Samuel Stocksieker; Denys Pommeret; Arthur Charpentier",
        "abstract": "In this work, we consider the problem of imbalanced data in a regression framework when the imbalanced phenomenon concerns continuous or discrete covariates. Such a situation can lead to biases in the estimates. In this case, we propose a data augmentation algorithm that combines a weighted resampling (WR) and a data augmentation (DA) procedure. In a first step, the DA procedure permits exploring a wider support than the initial one. In a second step, the WR method drives the exogenous distribution to a target one. We discuss the choice of the DA procedure through a numerical study that illustrates the advantages of this approach. Finally, an actuarial application is studied.",
        "bibtex": "@InProceedings{pmlr-v206-stocksieker23a,\n  title = \t {Data Augmentation for Imbalanced Regression},\n  author =       {Stocksieker, Samuel and Pommeret, Denys and Charpentier, Arthur},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7774--7799},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/stocksieker23a/stocksieker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/stocksieker23a.html},\n  abstract = \t {In this work, we consider the problem of imbalanced data in a regression framework when the imbalanced phenomenon concerns continuous or discrete covariates. Such a situation can lead to biases in the estimates. In this case, we propose a data augmentation algorithm that combines a weighted resampling (WR) and a data augmentation (DA) procedure. In a first step, the DA procedure permits exploring a wider support than the initial one. In a second step, the WR method drives the exogenous distribution to a target one. We discuss the choice of the DA procedure through a numerical study that illustrates the advantages of this approach. Finally, an actuarial application is studied.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/stocksieker23a/stocksieker23a.pdf",
        "supp": "",
        "pdf_size": 10672968,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13410391843849627497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b277f05be0",
        "title": "Data Banzhaf: A Robust Data Valuation Framework for Machine Learning",
        "site": "https://proceedings.mlr.press/v206/wang23e.html",
        "author": "Jiachen T. Wang; Ruoxi Jia",
        "abstract": "Data valuation has wide use cases in machine learning, including improving data quality and creating economic incentives for data sharing. This paper studies the robustness of data valuation to noisy model performance scores. Particularly, we find that the inherent randomness of the widely used stochastic gradient descent can cause existing data value notions (e.g., the Shapley value and the Leave-one-out error) to produce inconsistent data value rankings across different runs. To address this challenge, we introduce the concept of safety margin, which measures the robustness of a data value notion. We show that the Banzhaf value, a famous value notion that originated from cooperative game theory literature, achieves the largest safety margin among all semivalues (a class of value notions that satisfy crucial properties entailed by ML applications and include the famous Shapley value and Leave-one-out error). We propose an algorithm to efficiently estimate the Banzhaf value based on the Maximum Sample Reuse (MSR) principle. Our evaluation demonstrates that the Banzhaf value outperforms the existing semivalue-based data value notions on several ML tasks such as learning with weighted samples and noisy label detection. Overall, our study suggests that when the underlying ML algorithm is stochastic, the Banzhaf value is a promising alternative to the other semivalue-based data value schemes given its computational advantage and ability to robustly differentiate data quality.",
        "bibtex": "@InProceedings{pmlr-v206-wang23e,\n  title = \t {Data Banzhaf: A Robust Data Valuation Framework for Machine Learning},\n  author =       {Wang, Jiachen T. and Jia, Ruoxi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6388--6421},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23e/wang23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23e.html},\n  abstract = \t {Data valuation has wide use cases in machine learning, including improving data quality and creating economic incentives for data sharing. This paper studies the robustness of data valuation to noisy model performance scores. Particularly, we find that the inherent randomness of the widely used stochastic gradient descent can cause existing data value notions (e.g., the Shapley value and the Leave-one-out error) to produce inconsistent data value rankings across different runs. To address this challenge, we introduce the concept of safety margin, which measures the robustness of a data value notion. We show that the Banzhaf value, a famous value notion that originated from cooperative game theory literature, achieves the largest safety margin among all semivalues (a class of value notions that satisfy crucial properties entailed by ML applications and include the famous Shapley value and Leave-one-out error). We propose an algorithm to efficiently estimate the Banzhaf value based on the Maximum Sample Reuse (MSR) principle. Our evaluation demonstrates that the Banzhaf value outperforms the existing semivalue-based data value notions on several ML tasks such as learning with weighted samples and noisy label detection. Overall, our study suggests that when the underlying ML algorithm is stochastic, the Banzhaf value is a promising alternative to the other semivalue-based data value schemes given its computational advantage and ability to robustly differentiate data quality.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23e/wang23e.pdf",
        "supp": "",
        "pdf_size": 2226048,
        "gs_citation": 128,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7268999199134278169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Princeton University; Virginia Tech",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Princeton University;Virginia Tech",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.princeton.edu;https://www.vt.edu",
        "aff_unique_abbr": "Princeton;VT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "423c10e0f6",
        "title": "Deep Grey-Box Modeling With Adaptive Data-Driven Models Toward Trustworthy Estimation of Theory-Driven Models",
        "site": "https://proceedings.mlr.press/v206/takeishi23a.html",
        "author": "Naoya Takeishi; Alexandros Kalousis",
        "abstract": "The combination of deep neural nets and theory-driven models (deep grey-box models) can be advantageous due to the inherent robustness and interpretability of the theory-driven part. Deep grey-box models are usually learned with a regularized risk minimization to prevent a theory-driven part from being overwritten and ignored by a deep neural net. However, an estimation of the theory-driven part obtained by uncritically optimizing a regularizer can hardly be trustworthy if we are not sure which regularizer is suitable for the given data, which may affect the interpretability. Toward a trustworthy estimation of the theory-driven part, we should analyze the behavior of regularizers to compare different candidates and to justify a specific choice. In this paper, we present a framework that allows us to empirically analyze the behavior of a regularizer with a slight change in the architecture of the neural net and the training objective.",
        "bibtex": "@InProceedings{pmlr-v206-takeishi23a,\n  title = \t {Deep Grey-Box Modeling With Adaptive Data-Driven Models Toward Trustworthy Estimation of Theory-Driven Models},\n  author =       {Takeishi, Naoya and Kalousis, Alexandros},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4089--4100},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/takeishi23a/takeishi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/takeishi23a.html},\n  abstract = \t {The combination of deep neural nets and theory-driven models (deep grey-box models) can be advantageous due to the inherent robustness and interpretability of the theory-driven part. Deep grey-box models are usually learned with a regularized risk minimization to prevent a theory-driven part from being overwritten and ignored by a deep neural net. However, an estimation of the theory-driven part obtained by uncritically optimizing a regularizer can hardly be trustworthy if we are not sure which regularizer is suitable for the given data, which may affect the interpretability. Toward a trustworthy estimation of the theory-driven part, we should analyze the behavior of regularizers to compare different candidates and to justify a specific choice. In this paper, we present a framework that allows us to empirically analyze the behavior of a regularizer with a slight change in the architecture of the neural net and the training objective.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/takeishi23a/takeishi23a.pdf",
        "supp": "",
        "pdf_size": 534921,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14509201046555312048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Applied Sciences and Arts Western Switzerland (HES-SO), Geneva, Switzerland; University of Applied Sciences and Arts Western Switzerland (HES-SO), Geneva, Switzerland",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Applied Sciences and Arts Western Switzerland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.hes-so.ch",
        "aff_unique_abbr": "HES-SO",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Geneva",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "71797bcb01",
        "title": "Deep Joint Source-Channel Coding with Iterative Source Error Correction",
        "site": "https://proceedings.mlr.press/v206/lee23c.html",
        "author": "Changwoo Lee; Xiao Hu; Hun-Seok Kim",
        "abstract": "In this paper, we propose an iterative source error correction (ISEC) decoding scheme for deep-learning-based joint source-channel coding (Deep JSCC). Given a noisy codeword received through the channel, we use a Deep JSCC encoder and decoder pair to update the codeword iteratively to find a (modified) maximum a-posteriori (MAP) solution. For efficient MAP decoding, we utilize a neural network-based denoiser to approximate the gradient of the log-prior density of the codeword space. Albeit the non-convexity of the optimization problem, our proposed scheme improves various distortion and perceptual quality metrics from the conventional one-shot (non-iterative) Deep JSCC decoding baseline. Furthermore, the proposed scheme produces more reliable source reconstruction results compared to the baseline when the channel noise characteristics do not match the ones used during training.",
        "bibtex": "@InProceedings{pmlr-v206-lee23c,\n  title = \t {Deep Joint Source-Channel Coding with Iterative Source Error Correction},\n  author =       {Lee, Changwoo and Hu, Xiao and Kim, Hun-Seok},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3879--3902},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lee23c/lee23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lee23c.html},\n  abstract = \t {In this paper, we propose an iterative source error correction (ISEC) decoding scheme for deep-learning-based joint source-channel coding (Deep JSCC). Given a noisy codeword received through the channel, we use a Deep JSCC encoder and decoder pair to update the codeword iteratively to find a (modified) maximum a-posteriori (MAP) solution. For efficient MAP decoding, we utilize a neural network-based denoiser to approximate the gradient of the log-prior density of the codeword space. Albeit the non-convexity of the optimization problem, our proposed scheme improves various distortion and perceptual quality metrics from the conventional one-shot (non-iterative) Deep JSCC decoding baseline. Furthermore, the proposed scheme produces more reliable source reconstruction results compared to the baseline when the channel noise characteristics do not match the ones used during training.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lee23c/lee23c.pdf",
        "supp": "",
        "pdf_size": 4023908,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17037320188596356385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ecab273c09",
        "title": "Deep Neural Networks with Efficient Guaranteed Invariances",
        "site": "https://proceedings.mlr.press/v206/rath23a.html",
        "author": "Matthias Rath; Alexandru Paul Condurache",
        "abstract": "We address the problem of improving the performance and in particular the sample complexity of deep neural networks by enforcing and guaranteeing invariances to symmetry transformations rather than learning them from data. Group-equivariant convolutions are a popular approach to obtain equivariant representations. The desired corresponding invariance is then imposed using pooling operations. For rotations, it has been shown that using invariant integration instead of pooling further improves the sample complexity. In this contribution, we first expand invariant integration beyond rotations to flips and scale transformations. We then address the problem of incorporating multiple desired invariances into a single network. For this purpose, we propose a multi-stream architecture, where each stream is invariant to a different transformation such that the network can simultaneously benefit from multiple invariances. We demonstrate our approach with successful experiments on Scaled-MNIST, SVHN, CIFAR-10 and STL-10.",
        "bibtex": "@InProceedings{pmlr-v206-rath23a,\n  title = \t {Deep Neural Networks with Efficient Guaranteed Invariances},\n  author =       {Rath, Matthias and Condurache, Alexandru Paul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2460--2480},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/rath23a/rath23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/rath23a.html},\n  abstract = \t {We address the problem of improving the performance and in particular the sample complexity of deep neural networks by enforcing and guaranteeing invariances to symmetry transformations rather than learning them from data. Group-equivariant convolutions are a popular approach to obtain equivariant representations. The desired corresponding invariance is then imposed using pooling operations. For rotations, it has been shown that using invariant integration instead of pooling further improves the sample complexity. In this contribution, we first expand invariant integration beyond rotations to flips and scale transformations. We then address the problem of incorporating multiple desired invariances into a single network. For this purpose, we propose a multi-stream architecture, where each stream is invariant to a different transformation such that the network can simultaneously benefit from multiple invariances. We demonstrate our approach with successful experiments on Scaled-MNIST, SVHN, CIFAR-10 and STL-10.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/rath23a/rath23a.pdf",
        "supp": "",
        "pdf_size": 1280453,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7965017076279057791&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Cross-Domain Computing Solutions, Robert Bosch GmbH, Stuttgart, Germany+Institute for Signal Processing, University of L \u00a8ubeck, L\u00a8ubeck, Germany; Cross-Domain Computing Solutions, Robert Bosch GmbH, Stuttgart, Germany+Institute for Signal Processing, University of L \u00a8ubeck, L\u00a8ubeck, Germany",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Robert Bosch GmbH;University of L\u00fcbeck",
        "aff_unique_dep": "Cross-Domain Computing Solutions;Institute for Signal Processing",
        "aff_unique_url": "https://www.bosch.com;https://www.uni-luebeck.de",
        "aff_unique_abbr": "Bosch;",
        "aff_campus_unique_index": "0+1;0+1",
        "aff_campus_unique": "Stuttgart;L\u00fcbeck",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "f8c439e55c",
        "title": "Deep Value Function Networks for Large-Scale Multistage Stochastic Programs",
        "site": "https://proceedings.mlr.press/v206/bae23a.html",
        "author": "Hyunglip Bae; Jinkyu Lee; Woo Chang Kim; Yongjae Lee",
        "abstract": "A neural networks-based stagewise decomposition algorithm called Deep Value Function Networks (DVFN) is proposed for large-scale multistage stochastic programming (MSP) problems. Traditional approaches such as nested Benders decomposition and its stochastic variant, stochastic dual dynamic programming (SDDP) approximates value functions as piecewise linear convex functions by gradually accumulating subgradient cuts from dual solutions of stagewise subproblems. Although they have been proven effective for linear problems, nonlinear problems may suffer from the increasing number of subgradient cuts as they proceed. A recently developed algorithm called Value Function Gradient Learning (VFGL) replaced the piecewise linear approximation with parametric function approximation, but its performance heavily depends upon the choice of parametric forms like most of traditional parametric machine learning algorithms did. On the other hand, DVFN approximates value functions using neural networks, which are known to have huge capacity in terms of their functional representations. The art of choosing appropriate parametric form becomes a simple labor of hyperparameter search for neural networks. However, neural networks are non-convex in general, and it would make the learning process unstable. We resolve this issue by using input convex neural networks that guarantee convexity with respect to inputs. We compare DVFN with SDDP and VFGL for solving large-scale linear and nonlinear MSP problems: production optimization and energy planning. Numerical examples clearly indicate that DVFN provide accurate and computationally efficient solutions.",
        "bibtex": "@InProceedings{pmlr-v206-bae23a,\n  title = \t {Deep Value Function Networks for Large-Scale Multistage Stochastic Programs},\n  author =       {Bae, Hyunglip and Lee, Jinkyu and Chang Kim, Woo and Lee, Yongjae},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11267--11287},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bae23a/bae23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bae23a.html},\n  abstract = \t {A neural networks-based stagewise decomposition algorithm called Deep Value Function Networks (DVFN) is proposed for large-scale multistage stochastic programming (MSP) problems. Traditional approaches such as nested Benders decomposition and its stochastic variant, stochastic dual dynamic programming (SDDP) approximates value functions as piecewise linear convex functions by gradually accumulating subgradient cuts from dual solutions of stagewise subproblems. Although they have been proven effective for linear problems, nonlinear problems may suffer from the increasing number of subgradient cuts as they proceed. A recently developed algorithm called Value Function Gradient Learning (VFGL) replaced the piecewise linear approximation with parametric function approximation, but its performance heavily depends upon the choice of parametric forms like most of traditional parametric machine learning algorithms did. On the other hand, DVFN approximates value functions using neural networks, which are known to have huge capacity in terms of their functional representations. The art of choosing appropriate parametric form becomes a simple labor of hyperparameter search for neural networks. However, neural networks are non-convex in general, and it would make the learning process unstable. We resolve this issue by using input convex neural networks that guarantee convexity with respect to inputs. We compare DVFN with SDDP and VFGL for solving large-scale linear and nonlinear MSP problems: production optimization and energy planning. Numerical examples clearly indicate that DVFN provide accurate and computationally efficient solutions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bae23a/bae23a.pdf",
        "supp": "",
        "pdf_size": 3427965,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4736238341020409459&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "KAIST; Hugraph; KAIST; UNIST",
        "aff_domain": "kaist.ac.kr;hugraph.com;kaist.ac.kr;unist.ac.kr",
        "email": "kaist.ac.kr;hugraph.com;kaist.ac.kr;unist.ac.kr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Hugraph;Ulsan National Institute of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.kaist.ac.kr;;https://www.unist.ac.kr",
        "aff_unique_abbr": "KAIST;;UNIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea;"
    },
    {
        "id": "5ccf6cddd4",
        "title": "Deep equilibrium models as estimators for continuous latent variables",
        "site": "https://proceedings.mlr.press/v206/tsuchida23a.html",
        "author": "Russell Tsuchida; Cheng Soon Ong",
        "abstract": "Principal Component Analysis (PCA) and its exponential family extensions have three components: observations, latents and parameters of a linear transformation. We consider a generalised setting where the canonical parameters of the exponential family are a nonlinear transformation of the latents. We show explicit relationships between particular neural network architectures and the corresponding statistical models. We find that deep equilibrium models \u2014 a recently introduced class of implicit neural networks \u2014 solve maximum a-posteriori (MAP) estimates for the latents and parameters of the transformation. Our analysis provides a systematic way to relate activation functions, dropout, and layer structure, to statistical assumptions about the observations, thus providing foundational principles for unsupervised DEQs. For hierarchical latents, individual neurons can be interpreted as nodes in a deep graphical model. Our DEQ feature maps are end-to-end differentiable, enabling fine-tuning for downstream tasks.",
        "bibtex": "@InProceedings{pmlr-v206-tsuchida23a,\n  title = \t {Deep equilibrium models as estimators for continuous latent variables},\n  author =       {Tsuchida, Russell and Ong, Cheng Soon},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1646--1671},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tsuchida23a/tsuchida23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tsuchida23a.html},\n  abstract = \t {Principal Component Analysis (PCA) and its exponential family extensions have three components: observations, latents and parameters of a linear transformation. We consider a generalised setting where the canonical parameters of the exponential family are a nonlinear transformation of the latents. We show explicit relationships between particular neural network architectures and the corresponding statistical models. We find that deep equilibrium models \u2014 a recently introduced class of implicit neural networks \u2014 solve maximum a-posteriori (MAP) estimates for the latents and parameters of the transformation. Our analysis provides a systematic way to relate activation functions, dropout, and layer structure, to statistical assumptions about the observations, thus providing foundational principles for unsupervised DEQs. For hierarchical latents, individual neurons can be interpreted as nodes in a deep graphical model. Our DEQ feature maps are end-to-end differentiable, enabling fine-tuning for downstream tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tsuchida23a/tsuchida23a.pdf",
        "supp": "",
        "pdf_size": 3786860,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12235034479475624859&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Data61, CSIRO, Australia; Data61, CSIRO and Australian National University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "CSIRO;Data61",
        "aff_unique_dep": "Data61;",
        "aff_unique_url": "https://www.csiro.au;https://www.data61.csiro.au",
        "aff_unique_abbr": "CSIRO;Data61",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "ed0fcab323",
        "title": "Delayed Feedback in Generalised Linear Bandits Revisited",
        "site": "https://proceedings.mlr.press/v206/howson23b.html",
        "author": "Benjamin Howson; Ciara Pike-Burke; Sarah Filippi",
        "abstract": "The stochastic generalised linear bandit is a well-understood model for sequential decision-making problems, with many algorithms achieving near-optimal regret guarantees under immediate feedback. However, the stringent requirement for immediate rewards is unmet in many real-world applications where the reward is almost always delayed. We study the phenomenon of delayed rewards in generalised linear bandits in a theoretical manner. We show that a natural adaptation of an optimistic algorithm to the delayed feedback setting can achieve regret of $\\widetilde{\\mathcal{O}}(d\\sqrt{T} + d^{3/2}\\mathbb{E}[\\tau]\\,)$, where $\\mathbb{E}[\\tau]$ denotes the expected delay, $d$ is the dimension and $T$ is the time horizon. This significantly improves upon existing approaches for this setting where the best known regret bound was $ \\widetilde{\\mathcal{O}}(\\sqrt{dT}\\sqrt{d + \\mathbb{E}[\\tau]}\\,)$. We verify our theoretical results through experiments on simulated data.",
        "bibtex": "@InProceedings{pmlr-v206-howson23b,\n  title = \t {Delayed Feedback in Generalised Linear Bandits Revisited},\n  author =       {Howson, Benjamin and Pike-Burke, Ciara and Filippi, Sarah},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6095--6119},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/howson23b/howson23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/howson23b.html},\n  abstract = \t {The stochastic generalised linear bandit is a well-understood model for sequential decision-making problems, with many algorithms achieving near-optimal regret guarantees under immediate feedback. However, the stringent requirement for immediate rewards is unmet in many real-world applications where the reward is almost always delayed. We study the phenomenon of delayed rewards in generalised linear bandits in a theoretical manner. We show that a natural adaptation of an optimistic algorithm to the delayed feedback setting can achieve regret of $\\widetilde{\\mathcal{O}}(d\\sqrt{T} + d^{3/2}\\mathbb{E}[\\tau]\\,)$, where $\\mathbb{E}[\\tau]$ denotes the expected delay, $d$ is the dimension and $T$ is the time horizon. This significantly improves upon existing approaches for this setting where the best known regret bound was $ \\widetilde{\\mathcal{O}}(\\sqrt{dT}\\sqrt{d + \\mathbb{E}[\\tau]}\\,)$. We verify our theoretical results through experiments on simulated data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/howson23b/howson23b.pdf",
        "supp": "",
        "pdf_size": 1454513,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16127631316742764097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c973ea64cf",
        "title": "Density Ratio Estimation and Neyman Pearson Classification with Missing Data",
        "site": "https://proceedings.mlr.press/v206/givens23a.html",
        "author": "Josh Givens; Song Liu; Henry W. J. Reeve",
        "abstract": "Density Ratio Estimation (DRE) is an important machine learning technique with many downstream applications. We consider the challenge of DRE with missing not at random (MNAR) data. In this setting, we show that using standard DRE methods leads to biased results while our proposal (M-KLIEP), an adaptation of the popular DRE procedure KLIEP, restores consistency. Moreover, we provide finite sample estimation error bounds for M-KLIEP, which demonstrate minimax optimality with respect to both sample size and worst-case missingness. We then adapt an important downstream application of DRE, Neyman-Pearson (NP) classification, to this MNAR setting. Our procedure both controls Type I error and achieves high power, with high probability. Finally, we demonstrate promising empirical performance both synthetic data and real-world data with simulated missingness.",
        "bibtex": "@InProceedings{pmlr-v206-givens23a,\n  title = \t {Density Ratio Estimation and Neyman Pearson Classification with Missing Data},\n  author =       {Givens, Josh and Liu, Song and Reeve, Henry W. J.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8645--8681},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/givens23a/givens23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/givens23a.html},\n  abstract = \t {Density Ratio Estimation (DRE) is an important machine learning technique with many downstream applications. We consider the challenge of DRE with missing not at random (MNAR) data. In this setting, we show that using standard DRE methods leads to biased results while our proposal (M-KLIEP), an adaptation of the popular DRE procedure KLIEP, restores consistency. Moreover, we provide finite sample estimation error bounds for M-KLIEP, which demonstrate minimax optimality with respect to both sample size and worst-case missingness. We then adapt an important downstream application of DRE, Neyman-Pearson (NP) classification, to this MNAR setting. Our procedure both controls Type I error and achieves high power, with high probability. Finally, we demonstrate promising empirical performance both synthetic data and real-world data with simulated missingness.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/givens23a/givens23a.pdf",
        "supp": "",
        "pdf_size": 952061,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=488543755958463971&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ff6f7c0534",
        "title": "Differentiable Change-point Detection With Temporal Point Processes",
        "site": "https://proceedings.mlr.press/v206/koley23a.html",
        "author": "Paramita Koley; Harshavardhan Alimi; Shrey Singla; Sourangshu Bhattacharya; Niloy Ganguly; Abir De",
        "abstract": "In this paper, we consider the problem of global change-point detection in event sequence data, where both the event distributions and change-points are assumed to be unknown. For this problem, we propose a Log-likelihood Ratio based Global Change-point Detector, which observes the entire sequence and detects a prespecified number of change-points. Based on the Transformer Hawkes Process (THP), a well-known neural TPP framework, we develop DCPD, a differentiable change-point detector, along with maintaining distinct intensity and mark predictor for each partition. Further, we propose a sliding-window-based extension of DCPD to improve its scalability in terms of the number of events or change-points with minor sacrifices in performance. Experiments on synthetic datasets explore the effects of run-time, relative complexity, and other aspects of distributions on various properties of our changepoint detectors, namely robustness, detection accuracy, scalability, etc. under controlled environments. Finally, we perform experiments on six real-world temporal event sequences collected from diverse domains like health, geographical regions, etc., and show that our methods either outperform or perform comparably with the baselines.",
        "bibtex": "@InProceedings{pmlr-v206-koley23a,\n  title = \t {Differentiable Change-point Detection With Temporal Point Processes},\n  author =       {Koley, Paramita and Alimi, Harshavardhan and Singla, Shrey and Bhattacharya, Sourangshu and Ganguly, Niloy and De, Abir},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6940--6955},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/koley23a/koley23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/koley23a.html},\n  abstract = \t {In this paper, we consider the problem of global change-point detection in event sequence data, where both the event distributions and change-points are assumed to be unknown. For this problem, we propose a Log-likelihood Ratio based Global Change-point Detector, which observes the entire sequence and detects a prespecified number of change-points. Based on the Transformer Hawkes Process (THP), a well-known neural TPP framework, we develop DCPD, a differentiable change-point detector, along with maintaining distinct intensity and mark predictor for each partition. Further, we propose a sliding-window-based extension of DCPD to improve its scalability in terms of the number of events or change-points with minor sacrifices in performance. Experiments on synthetic datasets explore the effects of run-time, relative complexity, and other aspects of distributions on various properties of our changepoint detectors, namely robustness, detection accuracy, scalability, etc. under controlled environments. Finally, we perform experiments on six real-world temporal event sequences collected from diverse domains like health, geographical regions, etc., and show that our methods either outperform or perform comparably with the baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/koley23a/koley23a.pdf",
        "supp": "",
        "pdf_size": 6067669,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:lcAH9LprYxMJ:scholar.google.com/&scioq=Differentiable+Change-point+Detection+With+Temporal+Point+Processes&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6f16b1fe42",
        "title": "Differentially Private Matrix Completion through Low-rank Matrix Factorization",
        "site": "https://proceedings.mlr.press/v206/wang23d.html",
        "author": "Lingxiao Wang; Boxin Zhao; Mladen Kolar",
        "abstract": "We study the matrix completion problem under joint differential privacy and develop a non-convex low-rank matrix factorization-based method for solving it. Our method comes with strong privacy and utility guarantees, has a linear convergence rate, and is more scalable than the best-known alternative (Chien et al., 2021). Our method achieves the (near) optimal sample complexity for matrix completion required by the non-private baseline and is much better than the best known result under joint differential privacy. Furthermore, we prove a tight utility guarantee that improves existing approaches and removes the impractical resampling assumption used in the literature. Numerical experiments further demonstrate the superiority of our method.",
        "bibtex": "@InProceedings{pmlr-v206-wang23d,\n  title = \t {Differentially Private Matrix Completion through Low-rank Matrix Factorization},\n  author =       {Wang, Lingxiao and Zhao, Boxin and Kolar, Mladen},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5731--5748},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23d/wang23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23d.html},\n  abstract = \t {We study the matrix completion problem under joint differential privacy and develop a non-convex low-rank matrix factorization-based method for solving it. Our method comes with strong privacy and utility guarantees, has a linear convergence rate, and is more scalable than the best-known alternative (Chien et al., 2021). Our method achieves the (near) optimal sample complexity for matrix completion required by the non-private baseline and is much better than the best known result under joint differential privacy. Furthermore, we prove a tight utility guarantee that improves existing approaches and removes the impractical resampling assumption used in the literature. Numerical experiments further demonstrate the superiority of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23d/wang23d.pdf",
        "supp": "",
        "pdf_size": 565439,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17199226724860048615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b7cf45aaef",
        "title": "Differentially Private Synthetic Control",
        "site": "https://proceedings.mlr.press/v206/rho23a.html",
        "author": "Saeyoung Rho; Rachel Cummings; Vishal Misra",
        "abstract": "Synthetic control is a causal inference tool used to estimate the treatment effects of an intervention by creating synthetic counterfactual data. This approach combines measurements from other similar observations (i.e., donor pool) to predict a counterfactual time series of interest (i.e., target unit) by analyzing the relationship between the target and the donor pool before the intervention. As synthetic control tools are increasingly applied to sensitive or proprietary data, formal privacy protections are often required. In this work, we suggest the first algorithms for differentially private synthetic control with explicit error bounds based on the analysis of the sensitivity of the synthetic control query. Our approach builds upon tools from non-private synthetic control and differentially private empirical risk minimization. We empirically evaluate the performance of our algorithms and show favorable results in a variety of parameter regimes.",
        "bibtex": "@InProceedings{pmlr-v206-rho23a,\n  title = \t {Differentially Private Synthetic Control},\n  author =       {Rho, Saeyoung and Cummings, Rachel and Misra, Vishal},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1457--1491},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/rho23a/rho23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/rho23a.html},\n  abstract = \t {Synthetic control is a causal inference tool used to estimate the treatment effects of an intervention by creating synthetic counterfactual data. This approach combines measurements from other similar observations (i.e., donor pool) to predict a counterfactual time series of interest (i.e., target unit) by analyzing the relationship between the target and the donor pool before the intervention. As synthetic control tools are increasingly applied to sensitive or proprietary data, formal privacy protections are often required. In this work, we suggest the first algorithms for differentially private synthetic control with explicit error bounds based on the analysis of the sensitivity of the synthetic control query. Our approach builds upon tools from non-private synthetic control and differentially private empirical risk minimization. We empirically evaluate the performance of our algorithms and show favorable results in a variety of parameter regimes.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/rho23a/rho23a.pdf",
        "supp": "",
        "pdf_size": 1177173,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8861916073675336672&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "790aeed7a0",
        "title": "Diffusion Generative Models in Infinite Dimensions",
        "site": "https://proceedings.mlr.press/v206/kerrigan23a.html",
        "author": "Gavin Kerrigan; Justin Ley; Padhraic Smyth",
        "abstract": "Diffusion generative models have recently been applied to domains where the available data can be seen as a discretization of an underlying function, such as audio signals or time series. However, these models operate directly on the discretized data, and there are no semantics in the modeling process that relate the observed data to the underlying functional forms. We generalize diffusion models to operate directly in function space by developing the foundational theory for such models in terms of Gaussian measures on Hilbert spaces. A significant benefit of our function space point of view is that it allows us to explicitly specify the space of functions we are working in, leading us to develop methods for diffusion generative modeling in Sobolev spaces. Our approach allows us to perform both unconditional and conditional generation of function-valued data. We demonstrate our methods on several synthetic and real-world benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-kerrigan23a,\n  title = \t {Diffusion Generative Models in Infinite Dimensions},\n  author =       {Kerrigan, Gavin and Ley, Justin and Smyth, Padhraic},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9538--9563},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kerrigan23a/kerrigan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kerrigan23a.html},\n  abstract = \t {Diffusion generative models have recently been applied to domains where the available data can be seen as a discretization of an underlying function, such as audio signals or time series. However, these models operate directly on the discretized data, and there are no semantics in the modeling process that relate the observed data to the underlying functional forms. We generalize diffusion models to operate directly in function space by developing the foundational theory for such models in terms of Gaussian measures on Hilbert spaces. A significant benefit of our function space point of view is that it allows us to explicitly specify the space of functions we are working in, leading us to develop methods for diffusion generative modeling in Sobolev spaces. Our approach allows us to perform both unconditional and conditional generation of function-valued data. We demonstrate our methods on several synthetic and real-world benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kerrigan23a/kerrigan23a.pdf",
        "supp": "",
        "pdf_size": 26263255,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1258351634450031562&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of California, Irvine; University of California, Irvine; University of California, Irvine",
        "aff_domain": "uci.edu;uci.edu;ics.uci.edu",
        "email": "uci.edu;uci.edu;ics.uci.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Irvine",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uci.edu",
        "aff_unique_abbr": "UCI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Irvine",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6dcdcc7734",
        "title": "Dimensionality Collapse: Optimal Measurement Selection for Low-Error Infinite-Horizon Forecasting",
        "site": "https://proceedings.mlr.press/v206/naumer23a.html",
        "author": "Helmuth Naumer; Farzad Kamalabadi",
        "abstract": "This work introduces a method to select linear functional measurements of a vector-valued time series optimized for forecasting distant time-horizons. By formulating and solving the problem of sequential linear measurement design as an infinite-horizon problem with the time-averaged trace of the Cram\u00e9r-Rao lower bound (CRLB) for forecasting as the cost, the most informative data can be collected irrespective of the eventual forecasting algorithm. By introducing theoretical results regarding measurements under additive noise from natural exponential families, we construct an equivalent problem from which a local dimensionality reduction can be derived. This alternative formulation is based on the future collapse of dimensionality inherent in the limiting behavior of many differential equations and can be directly observed in the low-rank structure of the CRLB for forecasting. Implementations of both an approximate dynamic programming formulation and the proposed alternative are illustrated using an extended Kalman filter for state estimation, with results on simulated systems with limit cycles and chaotic behavior demonstrating a linear improvement in the CRLB as a function of the number of collapsing dimensions of the system.",
        "bibtex": "@InProceedings{pmlr-v206-naumer23a,\n  title = \t {Dimensionality Collapse: Optimal Measurement Selection for Low-Error Infinite-Horizon Forecasting},\n  author =       {Naumer, Helmuth and Kamalabadi, Farzad},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6166--6198},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/naumer23a/naumer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/naumer23a.html},\n  abstract = \t {This work introduces a method to select linear functional measurements of a vector-valued time series optimized for forecasting distant time-horizons. By formulating and solving the problem of sequential linear measurement design as an infinite-horizon problem with the time-averaged trace of the Cram\u00e9r-Rao lower bound (CRLB) for forecasting as the cost, the most informative data can be collected irrespective of the eventual forecasting algorithm. By introducing theoretical results regarding measurements under additive noise from natural exponential families, we construct an equivalent problem from which a local dimensionality reduction can be derived. This alternative formulation is based on the future collapse of dimensionality inherent in the limiting behavior of many differential equations and can be directly observed in the low-rank structure of the CRLB for forecasting. Implementations of both an approximate dynamic programming formulation and the proposed alternative are illustrated using an extended Kalman filter for state estimation, with results on simulated systems with limit cycles and chaotic behavior demonstrating a linear improvement in the CRLB as a function of the number of collapsing dimensions of the system.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/naumer23a/naumer23a.pdf",
        "supp": "",
        "pdf_size": 3679567,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:qQyqkXZCB8wJ:scholar.google.com/&scioq=Dimensionality+Collapse:+Optimal+Measurement+Selection+for+Low-Error+Infinite-Horizon+Forecasting&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2e09a2f87c",
        "title": "Direct Inference of Effect of Treatment (DIET) for a Cookieless World",
        "site": "https://proceedings.mlr.press/v206/shankar23a.html",
        "author": "Shiv Shankar; Ritwik Sinha; Saayan Mitra; Moumita Sinha; Madalina Fiterau",
        "abstract": "Brands use cookies and device identifiers to link different web visits to the same consumer. However, with increasing demands for privacy, these identifiers are about to be phased out, making identity fragmentation a permanent feature of the online world. Assessing treatment effects via randomized experiments (A/B testing) in such a scenario is challenging because identity fragmentation causes a) users to receive hybrid/mixed treatments, and b) hides the causal link between the historical treatments and the outcome. In this work, we address the problem of estimating treatment effects when a lack of identification leads to incomplete knowledge of historical treatments. This is a challenging problem which has not been addressed in literature yet. We develop a new method called DIET, which can adjust for users being exposed to mixed treatments without the entire history of treatments being available. Our method takes inspiration from the Cox model, and uses a proportional outcome approach under which we prove that one can obtain consistent estimates of treatment effects even under identity fragmentation. Our experiments, on one simulated and two real datasets, show that our method leads to up to 20% reduction in error and 25% reduction in bias over the naive estimate.",
        "bibtex": "@InProceedings{pmlr-v206-shankar23a,\n  title = \t {Direct Inference of Effect of Treatment (DIET) for a Cookieless World},\n  author =       {Shankar, Shiv and Sinha, Ritwik and Mitra, Saayan and Sinha, Moumita and Fiterau, Madalina},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1869--1887},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shankar23a/shankar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shankar23a.html},\n  abstract = \t {Brands use cookies and device identifiers to link different web visits to the same consumer. However, with increasing demands for privacy, these identifiers are about to be phased out, making identity fragmentation a permanent feature of the online world. Assessing treatment effects via randomized experiments (A/B testing) in such a scenario is challenging because identity fragmentation causes a) users to receive hybrid/mixed treatments, and b) hides the causal link between the historical treatments and the outcome. In this work, we address the problem of estimating treatment effects when a lack of identification leads to incomplete knowledge of historical treatments. This is a challenging problem which has not been addressed in literature yet. We develop a new method called DIET, which can adjust for users being exposed to mixed treatments without the entire history of treatments being available. Our method takes inspiration from the Cox model, and uses a proportional outcome approach under which we prove that one can obtain consistent estimates of treatment effects even under identity fragmentation. Our experiments, on one simulated and two real datasets, show that our method leads to up to 20% reduction in error and 25% reduction in bias over the naive estimate.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shankar23a/shankar23a.pdf",
        "supp": "",
        "pdf_size": 839904,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7679013443111619021&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "UMass; Adobe Research; Adobe Research; Adobe Inc; UMass",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Massachusetts;Adobe",
        "aff_unique_dep": ";Adobe Research",
        "aff_unique_url": "https://www.umass.edu;https://research.adobe.com",
        "aff_unique_abbr": "UMass;Adobe",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "204ac288cb",
        "title": "Discovering Many Diverse Solutions with Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v206/maus23a.html",
        "author": "Natalie Maus; Kaiwen Wu; David Eriksson; Jacob Gardner",
        "abstract": "Bayesian optimization (BO) is a popular approach for sample-efficient optimization of black-box objective functions. While BO has been successfully applied to a wide range of scientific applications, traditional approaches to single-objective BO only seek to find a single best solution. This can be a significant limitation in situations where solutions may later turn out to be intractable, for example, a designed molecule may turn out to later violate constraints that can only be evaluated after the optimization process has concluded. To address this issue, we propose rank-ordered Bayesian Optimization with trustregions (ROBOT) which aims to find a portfolio of high-performing solutions that are diverse according to a user-specified diversity measure. We evaluate ROBOT on several real-world applications and show that it can discover large sets of high-performing diverse solutions while requiring few additional function evaluations compared to finding a single best solution.",
        "bibtex": "@InProceedings{pmlr-v206-maus23a,\n  title = \t {Discovering Many Diverse Solutions with Bayesian Optimization},\n  author =       {Maus, Natalie and Wu, Kaiwen and Eriksson, David and Gardner, Jacob},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1779--1798},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/maus23a/maus23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/maus23a.html},\n  abstract = \t {Bayesian optimization (BO) is a popular approach for sample-efficient optimization of black-box objective functions. While BO has been successfully applied to a wide range of scientific applications, traditional approaches to single-objective BO only seek to find a single best solution. This can be a significant limitation in situations where solutions may later turn out to be intractable, for example, a designed molecule may turn out to later violate constraints that can only be evaluated after the optimization process has concluded. To address this issue, we propose rank-ordered Bayesian Optimization with trustregions (ROBOT) which aims to find a portfolio of high-performing solutions that are diverse according to a user-specified diversity measure. We evaluate ROBOT on several real-world applications and show that it can discover large sets of high-performing diverse solutions while requiring few additional function evaluations compared to finding a single best solution.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/maus23a/maus23a.pdf",
        "supp": "",
        "pdf_size": 13776150,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6864824217515497156&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "01d97b62ef",
        "title": "Discrete Distribution Estimation under User-level Local Differential Privacy",
        "site": "https://proceedings.mlr.press/v206/acharya23a.html",
        "author": "Jayadev Acharya; Yuhan Liu; Ziteng Sun",
        "abstract": "We study discrete distribution estimation under user-level local differential privacy (LDP). In user-level $\\varepsilon$-LDP, each user has a $m\\ge1$ samples and the privacy of all $m$ samples must be preserved simultaneously. We resolve the following dilemma: While on the one hand having more samples per user should provide more information about the underlying distribution, on the other hand, guaranteeing privacy of all $m$ samples should make estimation task more difficult. We obtain tight bounds for this problem under almost all parameter regimes. Perhaps surprisingly, we show that in suitable parameter regimes, having $m$ samples per user is equivalent to having $m$ times more users, each with only one sample. Our results demonstrate interesting phase transitions for $m$ and the privacy parameter $\\varepsilon$ in the estimation risk. Finally, connecting with recent results on shuffled DP, we show that combined with random shuffling, our algorithm leads to optimal error guarantees (up to logarithmic factors) under the central model of user-level DP in certain parameter regimes. We provide several simulations to verify our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v206-acharya23a,\n  title = \t {Discrete Distribution Estimation under User-level Local Differential Privacy},\n  author =       {Acharya, Jayadev and Liu, Yuhan and Sun, Ziteng},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8561--8585},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/acharya23a/acharya23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/acharya23a.html},\n  abstract = \t {We study discrete distribution estimation under user-level local differential privacy (LDP). In user-level $\\varepsilon$-LDP, each user has a $m\\ge1$ samples and the privacy of all $m$ samples must be preserved simultaneously. We resolve the following dilemma: While on the one hand having more samples per user should provide more information about the underlying distribution, on the other hand, guaranteeing privacy of all $m$ samples should make estimation task more difficult. We obtain tight bounds for this problem under almost all parameter regimes. Perhaps surprisingly, we show that in suitable parameter regimes, having $m$ samples per user is equivalent to having $m$ times more users, each with only one sample. Our results demonstrate interesting phase transitions for $m$ and the privacy parameter $\\varepsilon$ in the estimation risk. Finally, connecting with recent results on shuffled DP, we show that combined with random shuffling, our algorithm leads to optimal error guarantees (up to logarithmic factors) under the central model of user-level DP in certain parameter regimes. We provide several simulations to verify our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/acharya23a/acharya23a.pdf",
        "supp": "",
        "pdf_size": 733318,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6984299971823946853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8748f7b06e",
        "title": "Discrete Langevin Samplers via Wasserstein Gradient Flow",
        "site": "https://proceedings.mlr.press/v206/sun23f.html",
        "author": "Haoran Sun; Hanjun Dai; Bo Dai; Haomin Zhou; Dale Schuurmans",
        "abstract": "It is known that gradient based MCMC samplers for continuous spaces, such as Langevin Monte Carlo (LMC), can be derived as particle versions of a gradient flow that minimizes KL divergence on a Wasserstein manifold. The superior efficiency of such samplers has motivated several recent attempts to generalize LMC to discrete spaces. However, a fully principled extension of Langevin dynamics to discrete has yet to be achieved, due to the lack of well-defined gradients in the sample space. In this work, we show how the Wasserstein gradient flow can be generalized naturally to discrete spaces. Given the proposed formulation, we demonstrate how a discrete analogue of Langevin dynamics can subsequently be developed. With this new understanding, we reveal how recent gradient-based samplers in discrete space can be obtained as special cases by choosing particular discretizations. More importantly, the framework also allows for the derivation of novel algorithms, one of which, discrete Langevin Monte Carlo (DLMC), is obtained by a factorized estimate of the transition matrix. The DLMC method admits a convenient parallel implementation and time-uniform sampling that achieves larger jump distances. We demonstrate the advantages of DLMC for sampling and learning in various binary and categorical distributions.",
        "bibtex": "@InProceedings{pmlr-v206-sun23f,\n  title = \t {Discrete Langevin Samplers via Wasserstein Gradient Flow},\n  author =       {Sun, Haoran and Dai, Hanjun and Dai, Bo and Zhou, Haomin and Schuurmans, Dale},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6290--6313},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sun23f/sun23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sun23f.html},\n  abstract = \t {It is known that gradient based MCMC samplers for continuous spaces, such as Langevin Monte Carlo (LMC), can be derived as particle versions of a gradient flow that minimizes KL divergence on a Wasserstein manifold. The superior efficiency of such samplers has motivated several recent attempts to generalize LMC to discrete spaces. However, a fully principled extension of Langevin dynamics to discrete has yet to be achieved, due to the lack of well-defined gradients in the sample space. In this work, we show how the Wasserstein gradient flow can be generalized naturally to discrete spaces. Given the proposed formulation, we demonstrate how a discrete analogue of Langevin dynamics can subsequently be developed. With this new understanding, we reveal how recent gradient-based samplers in discrete space can be obtained as special cases by choosing particular discretizations. More importantly, the framework also allows for the derivation of novel algorithms, one of which, discrete Langevin Monte Carlo (DLMC), is obtained by a factorized estimate of the transition matrix. The DLMC method admits a convenient parallel implementation and time-uniform sampling that achieves larger jump distances. We demonstrate the advantages of DLMC for sampling and learning in various binary and categorical distributions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sun23f/sun23f.pdf",
        "supp": "",
        "pdf_size": 852650,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2127049226881792179&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Georgia Tech; Google Research; Google Research + Georgia Tech; Georgia Tech; Google Research + University of Alberta",
        "aff_domain": "gatech.edu;google.com;google.com;math.gatech.edu;google.com",
        "email": "gatech.edu;google.com;google.com;math.gatech.edu;google.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1+0;0;1+2",
        "aff_unique_norm": "Georgia Institute of Technology;Google;University of Alberta",
        "aff_unique_dep": ";Google Research;",
        "aff_unique_url": "https://www.gatech.edu;https://research.google;https://www.ualberta.ca",
        "aff_unique_abbr": "Georgia Tech;Google Research;UAlberta",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0+0;0;0+1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "0467de290f",
        "title": "Distance-to-Set Priors and Constrained Bayesian Inference",
        "site": "https://proceedings.mlr.press/v206/presman23a.html",
        "author": "Rick Presman; Jason Xu",
        "abstract": "Constrained learning is prevalent in many statistical tasks. Recent work proposes distance-to-set penalties to derive estimators under general constraints that can be specified as sets, but focuses on obtaining point estimates that do not come with corresponding measures of uncertainty. To remedy this, we approach distance-to-set regularization from a Bayesian lens. We consider a class of smooth distance-to-set priors, showing that they yield well-defined posteriors toward quantifying uncertainty for constrained learning problems. We discuss relationships and advantages over prior work on Bayesian constraint relaxation. Moreover, we prove that our approach is optimal in an information geometric-sense for finite penalty parameters $\\rho$, and enjoys favorable statistical properties when $\\rho \\rightarrow \\infty$. The method is designed to perform effectively within gradient based MCMC samplers, as illustrated on a suite of simulated and real data applications.",
        "bibtex": "@InProceedings{pmlr-v206-presman23a,\n  title = \t {Distance-to-Set Priors and Constrained Bayesian Inference},\n  author =       {Presman, Rick and Xu, Jason},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2310--2326},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/presman23a/presman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/presman23a.html},\n  abstract = \t {Constrained learning is prevalent in many statistical tasks. Recent work proposes distance-to-set penalties to derive estimators under general constraints that can be specified as sets, but focuses on obtaining point estimates that do not come with corresponding measures of uncertainty. To remedy this, we approach distance-to-set regularization from a Bayesian lens. We consider a class of smooth distance-to-set priors, showing that they yield well-defined posteriors toward quantifying uncertainty for constrained learning problems. We discuss relationships and advantages over prior work on Bayesian constraint relaxation. Moreover, we prove that our approach is optimal in an information geometric-sense for finite penalty parameters $\\rho$, and enjoys favorable statistical properties when $\\rho \\rightarrow \\infty$. The method is designed to perform effectively within gradient based MCMC samplers, as illustrated on a suite of simulated and real data applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/presman23a/presman23a.pdf",
        "supp": "",
        "pdf_size": 808807,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9799338126744563402&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Duke University; Duke University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f1100a0b4d",
        "title": "Distill n\u2019 Explain: explaining graph neural networks using simple surrogates",
        "site": "https://proceedings.mlr.press/v206/pereira23a.html",
        "author": "Tamara Pereira; Erik Nascimento; Lucas E. Resck; Diego Mesquita; Amauri Souza",
        "abstract": "Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n\u2019 Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faithfulness of explanations.",
        "bibtex": "@InProceedings{pmlr-v206-pereira23a,\n  title = \t {Distill n\u2019 Explain: explaining graph neural networks using simple surrogates},\n  author =       {Pereira, Tamara and Nascimento, Erik and Resck, Lucas E. and Mesquita, Diego and Souza, Amauri},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6199--6214},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/pereira23a/pereira23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/pereira23a.html},\n  abstract = \t {Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n\u2019 Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faithfulness of explanations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/pereira23a/pereira23a.pdf",
        "supp": "",
        "pdf_size": 504586,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6143926391967780486&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Federal Institute of Ceara; Federal Institute of Ceara; Getulio Vargas Foundation; Getulio Vargas Foundation; Federal Institute of Ceara+Getulio Vargas Foundation+Aalto university",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0+1+2",
        "aff_unique_norm": "Federal Institute of Cear\u00e1;Getulio Vargas Foundation;Aalto University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.ifce.edu.br;https://fgv.br;https://www.aalto.fi",
        "aff_unique_abbr": "IFCE;FGV;Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0+0+1",
        "aff_country_unique": "Brazil;Finland"
    },
    {
        "id": "0c37fd5bf9",
        "title": "Distributed Offline Policy Optimization Over Batch Data",
        "site": "https://proceedings.mlr.press/v206/shen23b.html",
        "author": "Han Shen; Songtao Lu; Xiaodong Cui; Tianyi Chen",
        "abstract": "Federated learning (FL) has received increasing interests during the past years, However, most of the existing works focus on supervised learning, and federated learning for sequential decision making has not been fully explored. Part of the reason is that learning a policy for sequential decision making typically requires repeated interaction with the environments, which is costly in many FL applications.To overcome this issue, this work proposes a federated offline policy optimization method abbreviated as FedOPO that allows clients to jointly learn the optimal policy without interacting with environments during training. Albeit the nonconcave-convex-strongly concave nature of the resultant max-min-max problem, we establish both the local and global convergence of our FedOPO algorithm. Experiments on the OpenAI gym demonstrate that our algorithm is able to find a near-optimal policy while enjoying various merits brought by FL, including training speedup and improved asymptotic performance.",
        "bibtex": "@InProceedings{pmlr-v206-shen23b,\n  title = \t {Distributed Offline Policy Optimization Over Batch Data},\n  author =       {Shen, Han and Lu, Songtao and Cui, Xiaodong and Chen, Tianyi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4443--4472},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shen23b/shen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shen23b.html},\n  abstract = \t {Federated learning (FL) has received increasing interests during the past years, However, most of the existing works focus on supervised learning, and federated learning for sequential decision making has not been fully explored. Part of the reason is that learning a policy for sequential decision making typically requires repeated interaction with the environments, which is costly in many FL applications.To overcome this issue, this work proposes a federated offline policy optimization method abbreviated as FedOPO that allows clients to jointly learn the optimal policy without interacting with environments during training. Albeit the nonconcave-convex-strongly concave nature of the resultant max-min-max problem, we establish both the local and global convergence of our FedOPO algorithm. Experiments on the OpenAI gym demonstrate that our algorithm is able to find a near-optimal policy while enjoying various merits brought by FL, including training speedup and improved asymptotic performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shen23b/shen23b.pdf",
        "supp": "",
        "pdf_size": 2168191,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=669655099737330295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d1a4148082",
        "title": "Distributionally Robust Policy Gradient for Offline Contextual Bandits",
        "site": "https://proceedings.mlr.press/v206/yang23f.html",
        "author": "Zhouhao Yang; Yihong Guo; Pan Xu; Anqi Liu; Animashree Anandkumar",
        "abstract": "Learning an optimal policy from offline data is notoriously challenging, which requires the evaluation of the learning policy using data pre-collected from a static logging policy. We study the policy optimization problem in offline contextual bandits using policy gradient methods. We employ a distributionally robust policy gradient method, DROPO, to account for the distributional shift between the static logging policy and the learning policy in policy gradient. Our approach conservatively estimates the conditional reward distributional and updates the policy accordingly. We show that our algorithm converges to a stationary point with rate $O(1/T)$, where $T$ is the number of time steps. We conduct experiments on real-world datasets under various scenarios of logging policies to compare our proposed algorithm with baseline methods in offline contextual bandits. We also propose a variant of our algorithm, DROPO-exp, to further improve the performance when a limited amount of online interaction is allowed. Our results demonstrate the effectiveness and robustness of the proposed algorithms, especially under heavily biased offline data.",
        "bibtex": "@InProceedings{pmlr-v206-yang23f,\n  title = \t {Distributionally Robust Policy Gradient for Offline Contextual Bandits},\n  author =       {Yang, Zhouhao and Guo, Yihong and Xu, Pan and Liu, Anqi and Anandkumar, Animashree},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6443--6462},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23f/yang23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23f.html},\n  abstract = \t {Learning an optimal policy from offline data is notoriously challenging, which requires the evaluation of the learning policy using data pre-collected from a static logging policy. We study the policy optimization problem in offline contextual bandits using policy gradient methods. We employ a distributionally robust policy gradient method, DROPO, to account for the distributional shift between the static logging policy and the learning policy in policy gradient. Our approach conservatively estimates the conditional reward distributional and updates the policy accordingly. We show that our algorithm converges to a stationary point with rate $O(1/T)$, where $T$ is the number of time steps. We conduct experiments on real-world datasets under various scenarios of logging policies to compare our proposed algorithm with baseline methods in offline contextual bandits. We also propose a variant of our algorithm, DROPO-exp, to further improve the performance when a limited amount of online interaction is allowed. Our results demonstrate the effectiveness and robustness of the proposed algorithms, especially under heavily biased offline data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23f/yang23f.pdf",
        "supp": "",
        "pdf_size": 4384543,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10302088154697673593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Shanghai Jiao Tong University; Johns Hopkins University; Duke University; Johns Hopkins University; California Institute of Technology",
        "aff_domain": "sjtu.edu.cn;jhu.edu;duke.edu;cs.jhu.edu;caltech.edu",
        "email": "sjtu.edu.cn;jhu.edu;duke.edu;cs.jhu.edu;caltech.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;3",
        "aff_unique_norm": "Shanghai Jiao Tong University;Johns Hopkins University;Duke University;California Institute of Technology",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.jhu.edu;https://www.duke.edu;https://www.caltech.edu",
        "aff_unique_abbr": "SJTU;JHU;Duke;Caltech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "84d2883979",
        "title": "Do Bayesian Neural Networks Need To Be Fully Stochastic?",
        "site": "https://proceedings.mlr.press/v206/sharma23a.html",
        "author": "Mrinank Sharma; Sebastian Farquhar; Eric Nalisnick; Tom Rainforth",
        "abstract": "We investigate the benefit of treating all the parameters in a Bayesian neural network stochastically and find compelling theoretical and empirical evidence that this standard construction may be unnecessary. To this end, we prove that expressive predictive distributions require only small amounts of stochasticity. In particular, partially stochastic networks with only n stochastic biases are universal probabilistic predictors for n-dimensional predictive problems. In empirical investigations, we find no systematic benefit of full stochasticity across four different inference modalities and eight datasets; partially stochastic networks can match and sometimes even outperform fully stochastic networks, despite their reduced memory costs.",
        "bibtex": "@InProceedings{pmlr-v206-sharma23a,\n  title = \t {Do Bayesian Neural Networks Need To Be Fully Stochastic?},\n  author =       {Sharma, Mrinank and Farquhar, Sebastian and Nalisnick, Eric and Rainforth, Tom},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7694--7722},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sharma23a/sharma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sharma23a.html},\n  abstract = \t {We investigate the benefit of treating all the parameters in a Bayesian neural network stochastically and find compelling theoretical and empirical evidence that this standard construction may be unnecessary. To this end, we prove that expressive predictive distributions require only small amounts of stochasticity. In particular, partially stochastic networks with only n stochastic biases are universal probabilistic predictors for n-dimensional predictive problems. In empirical investigations, we find no systematic benefit of full stochasticity across four different inference modalities and eight datasets; partially stochastic networks can match and sometimes even outperform fully stochastic networks, despite their reduced memory costs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sharma23a/sharma23a.pdf",
        "supp": "",
        "pdf_size": 2483956,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2172887208858790784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Oxford; University of Oxford; University of Amsterdam; University of Oxford",
        "aff_domain": "robots.ox.ac.uk; ; ; ",
        "email": "robots.ox.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Oxford;University of Amsterdam",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.uva.nl",
        "aff_unique_abbr": "Oxford;UvA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Netherlands"
    },
    {
        "id": "1cd60fbf5a",
        "title": "Does Label Differential Privacy Prevent Label Inference Attacks?",
        "site": "https://proceedings.mlr.press/v206/wu23a.html",
        "author": "Ruihan Wu; Jin Peng Zhou; Kilian Q. Weinberger; Chuan Guo",
        "abstract": "Label differential privacy (label-DP) is a popular framework for training private ML models on datasets with public features and sensitive private labels. Despite its rigorous privacy guarantee, it has been observed that in practice label-DP does not preclude label inference attacks (LIAs): Models trained with label-DP can be evaluated on the public training features to recover, with high accuracy, the very private labels that it was designed to protect. In this work, we argue that this phenomenon is not paradoxical and that label-DP is designed to limit the advantage of an LIA adversary compared to predicting training labels using the Bayes classifier. At label-DP $\\epsilon=0$ this advantage is zero, hence the optimal attack is to predict according to the Bayes classifier and is independent of the training labels. Our bound shows the semantic protection conferred by label-DP and gives guidelines on how to choose $\\epsilon$ to limit the threat of LIAs below a certain level. Finally, we empirically demonstrate that our result closely captures the behavior of simulated attacks on both synthetic and real world datasets.",
        "bibtex": "@InProceedings{pmlr-v206-wu23a,\n  title = \t {Does Label Differential Privacy Prevent Label Inference Attacks?},\n  author =       {Wu, Ruihan and Zhou, Jin Peng and Weinberger, Kilian Q. and Guo, Chuan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4336--4347},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wu23a/wu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wu23a.html},\n  abstract = \t {Label differential privacy (label-DP) is a popular framework for training private ML models on datasets with public features and sensitive private labels. Despite its rigorous privacy guarantee, it has been observed that in practice label-DP does not preclude label inference attacks (LIAs): Models trained with label-DP can be evaluated on the public training features to recover, with high accuracy, the very private labels that it was designed to protect. In this work, we argue that this phenomenon is not paradoxical and that label-DP is designed to limit the advantage of an LIA adversary compared to predicting training labels using the Bayes classifier. At label-DP $\\epsilon=0$ this advantage is zero, hence the optimal attack is to predict according to the Bayes classifier and is independent of the training labels. Our bound shows the semantic protection conferred by label-DP and gives guidelines on how to choose $\\epsilon$ to limit the threat of LIAs below a certain level. Finally, we empirically demonstrate that our result closely captures the behavior of simulated attacks on both synthetic and real world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wu23a/wu23a.pdf",
        "supp": "",
        "pdf_size": 10029584,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3966750204471985327&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "22e4634994",
        "title": "Domain Adaptation under Missingness Shift",
        "site": "https://proceedings.mlr.press/v206/zhou23b.html",
        "author": "Helen Zhou; Sivaraman Balakrishnan; Zachary Lipton",
        "abstract": "Rates of missing data often depend on record-keeping policies and thus may change across times and locations, even when the underlying features are comparatively stable. In this paper, we introduce the problem of Domain Adaptation under Missingness Shift (DAMS). Here, (labeled) source data and (unlabeled) target data would be exchangeable but for different missing data mechanisms. We show that if missing data indicators are available, DAMS reduces to covariate shift. Addressing cases where such indicators are absent, we establish the following theoretical results for underreporting completely at random: (i) covariate shift is violated (adaptation is required); (ii) the optimal linear source predictor can perform arbitrarily worse on the target domain than always predicting the mean; (iii) the optimal target predictor can be identified, even when the missingness rates themselves are not; and (iv) for linear models, a simple analytic adjustment yields consistent estimates of the optimal target parameters. In experiments on synthetic and semi-synthetic data, we demonstrate the promise of our methods when assumptions hold. Finally, we discuss a rich family of future extensions.",
        "bibtex": "@InProceedings{pmlr-v206-zhou23b,\n  title = \t {Domain Adaptation under Missingness Shift},\n  author =       {Zhou, Helen and Balakrishnan, Sivaraman and Lipton, Zachary},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9577--9606},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhou23b/zhou23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhou23b.html},\n  abstract = \t {Rates of missing data often depend on record-keeping policies and thus may change across times and locations, even when the underlying features are comparatively stable. In this paper, we introduce the problem of Domain Adaptation under Missingness Shift (DAMS). Here, (labeled) source data and (unlabeled) target data would be exchangeable but for different missing data mechanisms. We show that if missing data indicators are available, DAMS reduces to covariate shift. Addressing cases where such indicators are absent, we establish the following theoretical results for underreporting completely at random: (i) covariate shift is violated (adaptation is required); (ii) the optimal linear source predictor can perform arbitrarily worse on the target domain than always predicting the mean; (iii) the optimal target predictor can be identified, even when the missingness rates themselves are not; and (iv) for linear models, a simple analytic adjustment yields consistent estimates of the optimal target parameters. In experiments on synthetic and semi-synthetic data, we demonstrate the promise of our methods when assumptions hold. Finally, we discuss a rich family of future extensions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhou23b/zhou23b.pdf",
        "supp": "",
        "pdf_size": 830787,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10318340365314344542&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "36b0eeb96c",
        "title": "Don\u2019t be fooled: label leakage in explanation methods and the importance of their quantitative evaluation",
        "site": "https://proceedings.mlr.press/v206/jethani23a.html",
        "author": "Neil Jethani; Adriel Saporta; Rajesh Ranganath",
        "abstract": "Feature attribution methods identify which features of an input most influence a model\u2019s output. Most widely-used feature attribution methods (such as SHAP, LIME, and Grad-CAM) are \u201cclass-dependent\u201d methods in that they generate a feature attribution vector as a function of class. In this work, we demonstrate that class-dependent methods can \u201cleak\u201d information about the selected class, making that class appear more likely than it is. Thus, an end user runs the risk of drawing false conclusions when interpreting an explanation generated by a class-dependent method. In contrast, we introduce \u201cdistribution-aware\u201d methods, which favor explanations that keep the label\u2019s distribution close to its distribution given all features of the input. We introduce SHAP-KL and FastSHAP-KL, two baseline distribution-aware methods that compute Shapley values. Finally, we perform a comprehensive evaluation of seven class-dependent and three distribution-aware methods on three clinical datasets of different high-dimensional data types: images, biosignals, and text.",
        "bibtex": "@InProceedings{pmlr-v206-jethani23a,\n  title = \t {Don\u2019t be fooled: label leakage in explanation methods and the importance of their quantitative evaluation},\n  author =       {Jethani, Neil and Saporta, Adriel and Ranganath, Rajesh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8925--8953},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jethani23a/jethani23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jethani23a.html},\n  abstract = \t {Feature attribution methods identify which features of an input most influence a model\u2019s output. Most widely-used feature attribution methods (such as SHAP, LIME, and Grad-CAM) are \u201cclass-dependent\u201d methods in that they generate a feature attribution vector as a function of class. In this work, we demonstrate that class-dependent methods can \u201cleak\u201d information about the selected class, making that class appear more likely than it is. Thus, an end user runs the risk of drawing false conclusions when interpreting an explanation generated by a class-dependent method. In contrast, we introduce \u201cdistribution-aware\u201d methods, which favor explanations that keep the label\u2019s distribution close to its distribution given all features of the input. We introduce SHAP-KL and FastSHAP-KL, two baseline distribution-aware methods that compute Shapley values. Finally, we perform a comprehensive evaluation of seven class-dependent and three distribution-aware methods on three clinical datasets of different high-dimensional data types: images, biosignals, and text.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jethani23a/jethani23a.pdf",
        "supp": "",
        "pdf_size": 2325832,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18109623017668541660&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Grossman School of Medicine, Courant Institute New York University; Courant Institute New York University; Courant Institute, Center for Data Science New York University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Grossman School of Medicine",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "de1ceaa8ab",
        "title": "Doubly Fair Dynamic Pricing",
        "site": "https://proceedings.mlr.press/v206/xu23i.html",
        "author": "Jianyu Xu; Dan Qiao; Yu-Xiang Wang",
        "abstract": "We study the problem of online dynamic pricing with two types of fairness constraints: a \u201cprocedural fairness\u201d which requires the \u201cproposed\u201d prices to be equal in expectation among different groups, and a \u201csubstantive fairness\u201d which requires the \u201caccepted\u201d prices to be equal in expectation among different groups. A policy that is simultaneously procedural and substantive fair is referred to as \u201cdoubly fair\u201d. We show that a doubly fair policy must be random to have higher revenue than the best trivial policy that assigns the same price to different groups. In a two-group setting, we propose an online learning algorithm for the 2-group pricing problems that achieves $\\tilde{O}(\\sqrt{T})$ regret, zero procedural unfairness and $\\tilde{O}(\\sqrt{T})$ substantive unfairness over $T$ rounds of learning. We also prove two lower bounds showing that these results on regret and unfairness are both information-theoretically optimal up to iterated logarithmic factors. To the best of our knowledge, this is the first dynamic pricing algorithm that learns to price while satisfying two fairness constraints at the same time.",
        "bibtex": "@InProceedings{pmlr-v206-xu23i,\n  title = \t {Doubly Fair Dynamic Pricing},\n  author =       {Xu, Jianyu and Qiao, Dan and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9941--9975},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23i/xu23i.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23i.html},\n  abstract = \t {We study the problem of online dynamic pricing with two types of fairness constraints: a \u201cprocedural fairness\u201d which requires the \u201cproposed\u201d prices to be equal in expectation among different groups, and a \u201csubstantive fairness\u201d which requires the \u201caccepted\u201d prices to be equal in expectation among different groups. A policy that is simultaneously procedural and substantive fair is referred to as \u201cdoubly fair\u201d. We show that a doubly fair policy must be random to have higher revenue than the best trivial policy that assigns the same price to different groups. In a two-group setting, we propose an online learning algorithm for the 2-group pricing problems that achieves $\\tilde{O}(\\sqrt{T})$ regret, zero procedural unfairness and $\\tilde{O}(\\sqrt{T})$ substantive unfairness over $T$ rounds of learning. We also prove two lower bounds showing that these results on regret and unfairness are both information-theoretically optimal up to iterated logarithmic factors. To the best of our knowledge, this is the first dynamic pricing algorithm that learns to price while satisfying two fairness constraints at the same time.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23i/xu23i.pdf",
        "supp": "",
        "pdf_size": 698030,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3479892500166050723&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Computer Science Department, University of California, Santa Barbara; Computer Science Department, University of California, Santa Barbara; Computer Science Department, University of California, Santa Barbara",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "535a0a3d00",
        "title": "Dropout-Resilient Secure Multi-Party Collaborative Learning with Linear Communication Complexity",
        "site": "https://proceedings.mlr.press/v206/lu23a.html",
        "author": "Xingyu Lu; Hasin Us Sami; Ba\u015fak G\u00fcler",
        "abstract": "Collaborative machine learning enables privacy-preserving training of machine learning models without collecting sensitive client data. Despite recent breakthroughs, communication bottleneck is still a major challenge against its scalability to larger networks. To address this challenge, we propose PICO, the first collaborative learning framework with linear communication complexity, significantly improving over the quadratic state-of-the-art, under formal information-theoretic privacy guarantees. Theoretical analysis demonstrates that PICO slashes the communication cost while achieving equal computational complexity, adversary resilience, robustness to client dropouts, and model accuracy to the state-of-the-art. Extensive experiments demonstrate up to 91x reduction in the communication overhead, and up to 7x speed-up in the wall-clock training time compared to the state-of-the-art. As such, PICO addresses a key technical challenge in multi-party collaborative learning, paving the way for future large-scale privacy-preserving learning frameworks.",
        "bibtex": "@InProceedings{pmlr-v206-lu23a,\n  title = \t {Dropout-Resilient Secure Multi-Party Collaborative Learning with Linear Communication Complexity},\n  author =       {Lu, Xingyu and Sami, Hasin Us and G\\\"uler, Ba\\c{s}ak},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10566--10593},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lu23a/lu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lu23a.html},\n  abstract = \t {Collaborative machine learning enables privacy-preserving training of machine learning models without collecting sensitive client data. Despite recent breakthroughs, communication bottleneck is still a major challenge against its scalability to larger networks. To address this challenge, we propose PICO, the first collaborative learning framework with linear communication complexity, significantly improving over the quadratic state-of-the-art, under formal information-theoretic privacy guarantees. Theoretical analysis demonstrates that PICO slashes the communication cost while achieving equal computational complexity, adversary resilience, robustness to client dropouts, and model accuracy to the state-of-the-art. Extensive experiments demonstrate up to 91x reduction in the communication overhead, and up to 7x speed-up in the wall-clock training time compared to the state-of-the-art. As such, PICO addresses a key technical challenge in multi-party collaborative learning, paving the way for future large-scale privacy-preserving learning frameworks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lu23a/lu23a.pdf",
        "supp": "",
        "pdf_size": 7398984,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7012793067174480927&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Electrical and Computer Engineering, University of California, Riverside; Department of Electrical and Computer Engineering, University of California, Riverside; Department of Electrical and Computer Engineering, University of California, Riverside",
        "aff_domain": "ucr.edu;ucr.edu;ece.ucr.edu",
        "email": "ucr.edu;ucr.edu;ece.ucr.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e844e0f03f",
        "title": "Dueling RL: Reinforcement Learning with Trajectory Preferences",
        "site": "https://proceedings.mlr.press/v206/saha23a.html",
        "author": "Aadirupa Saha; Aldo Pacchiano; Jonathan Lee",
        "abstract": "We consider the problem of preference-based reinforcement learning (PbRL), where, unlike traditional reinforcement learning (RL), an agent receives feedback only in terms of 1 bit (0/1) preferences over a trajectory pair instead of absolute rewards for it. The success of the traditional reward-based RL framework crucially depends on how accurately a system designer can express an appropriate reward function, which is often a non-trivial task. The main novelty of the our framework is the ability to learn from preference-based trajectory feedback that eliminates the need to hand-craft numeric reward models. This paper sets up a formal framework for the PbRL problem with non-markovian rewards, where the trajectory preferences are encoded by a generalized linear model of dimension $d$. Assuming the transition model is known, we propose an algorithm with a regret guarantee of $\\tilde {\\mathcal{O}}\\left( SH d \\log (T / \\delta) \\sqrt{T} \\right)$. We further extend the above algorithm to the case of unknown transition dynamics and provide an algorithm with regret $\\widetilde{\\mathcal{O}}((\\sqrt{d} + H^2 + |\\mathcal{S}|)\\sqrt{dT} +\\sqrt{|\\mathcal{S}||\\mathcal{A}|TH} )$. To the best of our knowledge, our work is one of the first to give tight regret guarantees for preference-based RL problem with trajectory preferences.",
        "bibtex": "@InProceedings{pmlr-v206-saha23a,\n  title = \t {Dueling RL: Reinforcement Learning with Trajectory Preferences},\n  author =       {Saha, Aadirupa and Pacchiano, Aldo and Lee, Jonathan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6263--6289},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/saha23a/saha23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/saha23a.html},\n  abstract = \t {We consider the problem of preference-based reinforcement learning (PbRL), where, unlike traditional reinforcement learning (RL), an agent receives feedback only in terms of 1 bit (0/1) preferences over a trajectory pair instead of absolute rewards for it. The success of the traditional reward-based RL framework crucially depends on how accurately a system designer can express an appropriate reward function, which is often a non-trivial task. The main novelty of the our framework is the ability to learn from preference-based trajectory feedback that eliminates the need to hand-craft numeric reward models. This paper sets up a formal framework for the PbRL problem with non-markovian rewards, where the trajectory preferences are encoded by a generalized linear model of dimension $d$. Assuming the transition model is known, we propose an algorithm with a regret guarantee of $\\tilde {\\mathcal{O}}\\left( SH d \\log (T / \\delta) \\sqrt{T} \\right)$. We further extend the above algorithm to the case of unknown transition dynamics and provide an algorithm with regret $\\widetilde{\\mathcal{O}}((\\sqrt{d} + H^2 + |\\mathcal{S}|)\\sqrt{dT} +\\sqrt{|\\mathcal{S}||\\mathcal{A}|TH} )$. To the best of our knowledge, our work is one of the first to give tight regret guarantees for preference-based RL problem with trajectory preferences.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/saha23a/saha23a.pdf",
        "supp": "",
        "pdf_size": 637428,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11068216206164654162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Microsoft Research, New York City; TTI, Chicago + Stanford University; Apple ML Research, US",
        "aff_domain": "ttic.edu; ; ",
        "email": "ttic.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;3",
        "aff_unique_norm": "Microsoft;Toyota Technological Institute at Chicago;Stanford University;Apple",
        "aff_unique_dep": "Microsoft Research;;;Apple ML Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.tti-chicago.org;https://www.stanford.edu;https://www.apple.com",
        "aff_unique_abbr": "MSR;TTI;Stanford;Apple",
        "aff_campus_unique_index": "0;1+2",
        "aff_campus_unique": "New York City;Chicago;Stanford;",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1b5abb30fe",
        "title": "EEGNN: Edge Enhanced Graph Neural Network with a Bayesian Nonparametric Graph Model",
        "site": "https://proceedings.mlr.press/v206/liu23a.html",
        "author": "Yirui Liu; Xinghao Qiao; Liying Wang; Jessica Lam",
        "abstract": "Training deep graph neural networks (GNNs) poses a challenging task, as the performance of GNNs may suffer from the number of hidden message-passing layers. The literature has focused on the proposals of over-smoothing and under-reaching to explain the performance deterioration of deep GNNs. In this paper, we propose a new explanation for such deteriorated performance phenomenon, mis-simplification, that is, mistakenly simplifying graphs by preventing self-loops and forcing edges to be unweighted. We show that such simplifying can reduce the potential of message-passing layers to capture the structural information of graphs. In view of this, we propose a new framework, edge enhanced graph neural network (EEGNN). EEGNN uses the structural information extracted from the proposed Dirichlet mixture Poisson graph model (DMPGM), a Bayesian nonparametric model for graphs, to improve the performance of various deep message-passing GNNs. We propose a Markov chain Monte Carlo inference framework for DMPGM. Experiments over different datasets show that our method achieves considerable performance increase compared to baselines.",
        "bibtex": "@InProceedings{pmlr-v206-liu23a,\n  title = \t {EEGNN: Edge Enhanced Graph Neural Network with a Bayesian Nonparametric Graph Model},\n  author =       {Liu, Yirui and Qiao, Xinghao and Wang, Liying and Lam, Jessica},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2132--2146},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23a/liu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23a.html},\n  abstract = \t {Training deep graph neural networks (GNNs) poses a challenging task, as the performance of GNNs may suffer from the number of hidden message-passing layers. The literature has focused on the proposals of over-smoothing and under-reaching to explain the performance deterioration of deep GNNs. In this paper, we propose a new explanation for such deteriorated performance phenomenon, mis-simplification, that is, mistakenly simplifying graphs by preventing self-loops and forcing edges to be unweighted. We show that such simplifying can reduce the potential of message-passing layers to capture the structural information of graphs. In view of this, we propose a new framework, edge enhanced graph neural network (EEGNN). EEGNN uses the structural information extracted from the proposed Dirichlet mixture Poisson graph model (DMPGM), a Bayesian nonparametric model for graphs, to improve the performance of various deep message-passing GNNs. We propose a Markov chain Monte Carlo inference framework for DMPGM. Experiments over different datasets show that our method achieves considerable performance increase compared to baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23a/liu23a.pdf",
        "supp": "",
        "pdf_size": 883559,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1546224297267658641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c1e90ce551",
        "title": "EGG-GAE: scalable graph neural networks for tabular data imputation",
        "site": "https://proceedings.mlr.press/v206/telyatnikov23a.html",
        "author": "Lev Telyatnikov; Simone Scardapane",
        "abstract": "Missing data imputation (MDI) is crucial when dealing with tabular datasets across various domains. Autoencoders can be trained to reconstruct missing values, and graph autoencoders (GAE) can additionally consider similar patterns in the dataset when imputing new values for a given instance. However, previously proposed GAEs suffer from scalability issues, requiring the user to define a similarity metric among patterns to build the graph connectivity beforehand. In this paper, we leverage recent progress in latent graph learning to propose a novel EdGe Generation Graph AutoEncoder (EGG-GAE) for missing data imputation that overcomes these two drawbacks. EGG-GAE works on randomly sampled mini-batches of the input data (hence scaling to larger datasets), and it automatically infers the best connectivity across the mini-batch for each architecture layer. We also experiment with several extensions, including an ensemble strategy for inference and the inclusion of what we call prototype nodes, obtaining significant improvements, both in terms of imputation error and final downstream accuracy, across multiple benchmarks and baselines.",
        "bibtex": "@InProceedings{pmlr-v206-telyatnikov23a,\n  title = \t {EGG-GAE: scalable graph neural networks for tabular data imputation},\n  author =       {Telyatnikov, Lev and Scardapane, Simone},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2661--2676},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/telyatnikov23a/telyatnikov23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/telyatnikov23a.html},\n  abstract = \t {Missing data imputation (MDI) is crucial when dealing with tabular datasets across various domains. Autoencoders can be trained to reconstruct missing values, and graph autoencoders (GAE) can additionally consider similar patterns in the dataset when imputing new values for a given instance. However, previously proposed GAEs suffer from scalability issues, requiring the user to define a similarity metric among patterns to build the graph connectivity beforehand. In this paper, we leverage recent progress in latent graph learning to propose a novel EdGe Generation Graph AutoEncoder (EGG-GAE) for missing data imputation that overcomes these two drawbacks. EGG-GAE works on randomly sampled mini-batches of the input data (hence scaling to larger datasets), and it automatically infers the best connectivity across the mini-batch for each architecture layer. We also experiment with several extensions, including an ensemble strategy for inference and the inclusion of what we call prototype nodes, obtaining significant improvements, both in terms of imputation error and final downstream accuracy, across multiple benchmarks and baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/telyatnikov23a/telyatnikov23a.pdf",
        "supp": "",
        "pdf_size": 3759106,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11569142581084457910&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Sapienza University of Rome; Sapienza University of Rome",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Sapienza University of Rome",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uniroma1.it",
        "aff_unique_abbr": "Sapienza",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Rome",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "ae337abd0f",
        "title": "Efficient Informed Proposals for Discrete Distributions via Newton\u2019s Series Approximation",
        "site": "https://proceedings.mlr.press/v206/xiang23a.html",
        "author": "Yue Xiang; Dongyao Zhu; Bowen Lei; Dongkuan Xu; Ruqi Zhang",
        "abstract": "Gradients have been exploited in proposal distributions to accelerate the convergence of Markov chain Monte Carlo algorithms on discrete distributions. However, these methods require a natural differentiable extension of the target discrete distribution, which often does not exist or does not provide effective guidance. In this paper, we develop a gradient-like proposal for any discrete distribution without this strong requirement. Built upon a locally-balanced proposal, our method efficiently approximates the discrete likelihood ratio via Newton\u2019s series expansion to enable a large and efficient exploration in discrete spaces. We show that our method can also be viewed as a multilinear extension, thus inheriting the desired properties. We prove that our method has a guaranteed convergence rate with or without the Metropolis-Hastings step. Furthermore, our method outperforms a number of popular alternatives in several different experiments, including the facility location problem, extractive text summarization, and image retrieval.",
        "bibtex": "@InProceedings{pmlr-v206-xiang23a,\n  title = \t {Efficient Informed Proposals for Discrete Distributions via Newton\u2019s Series Approximation},\n  author =       {Xiang, Yue and Zhu, Dongyao and Lei, Bowen and Xu, Dongkuan and Zhang, Ruqi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7288--7310},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xiang23a/xiang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xiang23a.html},\n  abstract = \t {Gradients have been exploited in proposal distributions to accelerate the convergence of Markov chain Monte Carlo algorithms on discrete distributions. However, these methods require a natural differentiable extension of the target discrete distribution, which often does not exist or does not provide effective guidance. In this paper, we develop a gradient-like proposal for any discrete distribution without this strong requirement. Built upon a locally-balanced proposal, our method efficiently approximates the discrete likelihood ratio via Newton\u2019s series expansion to enable a large and efficient exploration in discrete spaces. We show that our method can also be viewed as a multilinear extension, thus inheriting the desired properties. We prove that our method has a guaranteed convergence rate with or without the Metropolis-Hastings step. Furthermore, our method outperforms a number of popular alternatives in several different experiments, including the facility location problem, extractive text summarization, and image retrieval.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xiang23a/xiang23a.pdf",
        "supp": "",
        "pdf_size": 1432813,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13042945713690827800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Renmin University of China; Independent Researcher; Texas A&M University; North Carolina State University; Purdue University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Renmin University of China;Independent Researcher;Texas A&M University;North Carolina State University;Purdue University",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "http://www.ruc.edu.cn;;https://www.tamu.edu;https://www.ncsu.edu;https://www.purdue.edu",
        "aff_unique_abbr": "RUC;;TAMU;NCSU;Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;2;2;2",
        "aff_country_unique": "China;;United States"
    },
    {
        "id": "eca374a6c6",
        "title": "Efficient Planning in Combinatorial Action Spaces with Applications to Cooperative Multi-Agent Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/tkachuk23a.html",
        "author": "Volodymyr Tkachuk; Seyed Alireza Bakhtiari; Johannes Kirschner; Matej Jusup; Ilija Bogunovic; Csaba Szepesv\u00e1ri",
        "abstract": "A practical challenge in reinforcement learning are combinatorial action spaces that make planning computationally demanding. For example, in cooperative multi-agent reinforcement learning, a potentially large number of agents jointly optimize a global reward function, which leads to a combinatorial blow-up in the action space by the number of agents. As a minimal requirement, we assume access to an argmax oracle that allows to efficiently compute the greedy policy for any Q-function in the model class. Building on recent work in planning with local access to a simulator and linear function approximation, we propose efficient algorithms for this setting that lead to polynomial compute and query complexity in all relevant problem parameters. For the special case where the feature decomposition is additive, we further improve the bounds and extend the results to the kernelized setting with an efficient algorithm.",
        "bibtex": "@InProceedings{pmlr-v206-tkachuk23a,\n  title = \t {Efficient Planning in Combinatorial Action Spaces with Applications to Cooperative Multi-Agent Reinforcement Learning},\n  author =       {Tkachuk, Volodymyr and Bakhtiari, Seyed Alireza and Kirschner, Johannes and Jusup, Matej and Bogunovic, Ilija and Szepesv\\'ari, Csaba},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6342--6370},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tkachuk23a/tkachuk23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tkachuk23a.html},\n  abstract = \t {A practical challenge in reinforcement learning are combinatorial action spaces that make planning computationally demanding. For example, in cooperative multi-agent reinforcement learning, a potentially large number of agents jointly optimize a global reward function, which leads to a combinatorial blow-up in the action space by the number of agents. As a minimal requirement, we assume access to an argmax oracle that allows to efficiently compute the greedy policy for any Q-function in the model class. Building on recent work in planning with local access to a simulator and linear function approximation, we propose efficient algorithms for this setting that lead to polynomial compute and query complexity in all relevant problem parameters. For the special case where the feature decomposition is additive, we further improve the bounds and extend the results to the kernelized setting with an efficient algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tkachuk23a/tkachuk23a.pdf",
        "supp": "",
        "pdf_size": 570763,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17078377445384171335&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Alberta; University of Alberta; University of Alberta; ETH Zurich; University College London; University of Alberta/DeepMind",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "University of Alberta;ETH Zurich;University College London",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ualberta.ca;https://www.ethz.ch;https://www.ucl.ac.uk",
        "aff_unique_abbr": "UAlberta;ETHZ;UCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;2;0",
        "aff_country_unique": "Canada;Switzerland;United Kingdom"
    },
    {
        "id": "b16097509d",
        "title": "Efficient SAGE Estimation via Causal Structure Learning",
        "site": "https://proceedings.mlr.press/v206/luther23a.html",
        "author": "Christoph Luther; Gunnar K\u00f6nig; Moritz Grosse-Wentrup",
        "abstract": "The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model\u2019s surplus performance contributions over an exponential number of feature sets. This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions. Thus, SAGE approximation algorithms only take a fraction of the feature sets into account. We propose d-SAGE, a method that accelerates SAGE approximation. d-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped. To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as d-separations. This is computationally more efficient because the expense of the one-time graph inference and the d-separation queries is negligible compared to the expense of surplus contribution evaluations. Empirically we demonstrate that d-SAGE enables the efficient and accurate estimation of SAGE values.",
        "bibtex": "@InProceedings{pmlr-v206-luther23a,\n  title = \t {Efficient SAGE Estimation via Causal Structure Learning},\n  author =       {Luther, Christoph and K\\\"onig, Gunnar and Grosse-Wentrup, Moritz},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11650--11670},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/luther23a/luther23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/luther23a.html},\n  abstract = \t {The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model\u2019s surplus performance contributions over an exponential number of feature sets. This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions. Thus, SAGE approximation algorithms only take a fraction of the feature sets into account. We propose d-SAGE, a method that accelerates SAGE approximation. d-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped. To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as d-separations. This is computationally more efficient because the expense of the one-time graph inference and the d-separation queries is negligible compared to the expense of surplus contribution evaluations. Empirically we demonstrate that d-SAGE enables the efficient and accurate estimation of SAGE values.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/luther23a/luther23a.pdf",
        "supp": "",
        "pdf_size": 6196055,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1666533468295251571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of Vienna; UniVie Doctoral School CSLMU Munich + University of Vienna; Munich Center for ML (MCML)University of Vienna + Data Science @ Uni Vienna + Vienna CogSciHub",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+0;1+0+2",
        "aff_unique_norm": "University of Vienna;University of Munich;Vienna CogSciHub",
        "aff_unique_dep": ";Munich Center for Machine Learning;",
        "aff_unique_url": "https://univie.ac.at;https://www.munich-center-for-ml.de;",
        "aff_unique_abbr": "UV;MCML;",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0+0;1+0+0",
        "aff_country_unique": "Austria;Germany"
    },
    {
        "id": "d6bfed4be0",
        "title": "Efficient and Light-Weight Federated Learning via Asynchronous Distributed Dropout",
        "site": "https://proceedings.mlr.press/v206/dun23a.html",
        "author": "Chen Dun; Mirian Hipolito; Chris Jermaine; Dimitrios Dimitriadis; Anastasios Kyrillidis",
        "abstract": "Asynchronous learning protocols have regained attention lately, especially in the Federated Learning (FL) setup, where slower clients can severely impede the learning process. Herein, we propose AsyncDrop, a novel asynchronous FL framework that utilizes dropout regularization to handle device heterogeneity in distributed settings. Overall, AsyncDrop achieves better performance compared to state of the art asynchronous methodologies, while resulting in less communication and training time overheads. The key idea revolves around creating \u201csubmodels\u201d out of the global model, and distributing their training to workers, based on device heterogeneity. We rigorously justify that such an approach can be theoretically characterized. We implement our approach and compare it against other asynchronous baselines, both by design and by adapting existing synchronous FL algorithms to asynchronous scenarios. Empirically, AsyncDrop reduces the communication cost and training time, while matching or improving the final test accuracy in diverse non-i.i.d. FL scenarios.",
        "bibtex": "@InProceedings{pmlr-v206-dun23a,\n  title = \t {Efficient and Light-Weight Federated Learning via Asynchronous Distributed Dropout},\n  author =       {Dun, Chen and Hipolito, Mirian and Jermaine, Chris and Dimitriadis, Dimitrios and Kyrillidis, Anastasios},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6630--6660},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dun23a/dun23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dun23a.html},\n  abstract = \t {Asynchronous learning protocols have regained attention lately, especially in the Federated Learning (FL) setup, where slower clients can severely impede the learning process. Herein, we propose AsyncDrop, a novel asynchronous FL framework that utilizes dropout regularization to handle device heterogeneity in distributed settings. Overall, AsyncDrop achieves better performance compared to state of the art asynchronous methodologies, while resulting in less communication and training time overheads. The key idea revolves around creating \u201csubmodels\u201d out of the global model, and distributing their training to workers, based on device heterogeneity. We rigorously justify that such an approach can be theoretically characterized. We implement our approach and compare it against other asynchronous baselines, both by design and by adapting existing synchronous FL algorithms to asynchronous scenarios. Empirically, AsyncDrop reduces the communication cost and training time, while matching or improving the final test accuracy in diverse non-i.i.d. FL scenarios.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dun23a/dun23a.pdf",
        "supp": "",
        "pdf_size": 1837294,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17292180526571559856&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Rice University; Microsoft Research; Rice University; Microsoft Research; Rice University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Rice University;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.rice.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "Rice;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "822d8bacff",
        "title": "Efficient fair PCA for fair representation learning",
        "site": "https://proceedings.mlr.press/v206/kleindessner23a.html",
        "author": "Matth\u00e4us Kleindessner; Michele Donini; Chris Russell; Muhammad Bilal Zafar",
        "abstract": "We revisit the problem of fair principal component analysis (PCA), where the goal is to learn the best low-rank linear approximation of the data that obfuscates demographic information. We propose a conceptually simple approach that allows for an analytic solution similar to standard PCA and can be kernelized. Our methods have the same complexity as standard PCA, or kernel PCA, and run much faster than existing methods for fair PCA based on semidefinite programming or manifold optimization, while achieving similar results.",
        "bibtex": "@InProceedings{pmlr-v206-kleindessner23a,\n  title = \t {Efficient fair PCA for fair representation learning},\n  author =       {Kleindessner, Matth\\\"aus and Donini, Michele and Russell, Chris and Zafar, Muhammad Bilal},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5250--5270},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kleindessner23a/kleindessner23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kleindessner23a.html},\n  abstract = \t {We revisit the problem of fair principal component analysis (PCA), where the goal is to learn the best low-rank linear approximation of the data that obfuscates demographic information. We propose a conceptually simple approach that allows for an analytic solution similar to standard PCA and can be kernelized. Our methods have the same complexity as standard PCA, or kernel PCA, and run much faster than existing methods for fair PCA based on semidefinite programming or manifold optimization, while achieving similar results.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kleindessner23a/kleindessner23a.pdf",
        "supp": "",
        "pdf_size": 1331733,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9779177823510707762&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3b5c810479",
        "title": "Efficiently Forgetting What You Have Learned in Graph Representation Learning via Projection",
        "site": "https://proceedings.mlr.press/v206/cong23a.html",
        "author": "Weilin Cong; Mehrdad Mahdavi",
        "abstract": "As privacy protection receives much attention, unlearning the effect of a specific node from a pre-trained graph learning model has become equally important. However, due to the node dependency in the graph-structured data, representation unlearning in Graph Neural Networks (GNNs) is challenging and less well explored. In this paper, we fill in this gap by first studying the unlearning problem in linear-GNNs, and then introducing its extension to non-linear structures. Given a set of nodes to unlearn, we propose Projector that unlearns by projecting the weight parameters of the pre-trained model onto a subspace that is irrelevant to features of the nodes to be forgotten. Projector could overcome the challenges caused by node dependency and enjoys perfect data removal, i.e., the unlearned model parameters do not contain any information about the unlearned node features which is guaranteed by algorithmic construction. Empirical results on real-world datasets illustrate the effectiveness and efficiency of Projector.",
        "bibtex": "@InProceedings{pmlr-v206-cong23a,\n  title = \t {Efficiently Forgetting What You Have Learned in Graph Representation Learning via Projection},\n  author =       {Cong, Weilin and Mahdavi, Mehrdad},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6674--6703},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cong23a/cong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cong23a.html},\n  abstract = \t {As privacy protection receives much attention, unlearning the effect of a specific node from a pre-trained graph learning model has become equally important. However, due to the node dependency in the graph-structured data, representation unlearning in Graph Neural Networks (GNNs) is challenging and less well explored. In this paper, we fill in this gap by first studying the unlearning problem in linear-GNNs, and then introducing its extension to non-linear structures. Given a set of nodes to unlearn, we propose Projector that unlearns by projecting the weight parameters of the pre-trained model onto a subspace that is irrelevant to features of the nodes to be forgotten. Projector could overcome the challenges caused by node dependency and enjoys perfect data removal, i.e., the unlearned model parameters do not contain any information about the unlearned node features which is guaranteed by algorithmic construction. Empirical results on real-world datasets illustrate the effectiveness and efficiency of Projector.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cong23a/cong23a.pdf",
        "supp": "",
        "pdf_size": 1720593,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10937506803852279515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "The Pennsylvania State University; The Pennsylvania State University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pennsylvania State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fa109a164e",
        "title": "Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity",
        "site": "https://proceedings.mlr.press/v206/qoku23a.html",
        "author": "Arber Qoku; Florian Buettner",
        "abstract": "Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, patients can be characterized by data from different molecular layers. Latent variable models with structured sparsity are a commonly used tool for disentangling variation within and across data views. However, their interpretability is cumbersome since it requires a direct inspection and interpretation of each factor from domain experts. Here, we propose MuVI, a novel multi-view latent variable model based on a modified horseshoe prior for modeling structured sparsity. This facilitates the incorporation of limited and noisy domain knowledge, thereby allowing for an analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) outperforms state-of-the-art approaches for modeling structured sparsity in terms of the reconstruction error and the precision/recall, (ii) robustly integrates noisy domain expertise in the form of feature sets, (iii) promotes the identifiability of factors and (iv) infers interpretable and biologically meaningful axes of variation in a real-world multi-view dataset of cancer patients.",
        "bibtex": "@InProceedings{pmlr-v206-qoku23a,\n  title = \t {Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity},\n  author =       {Qoku, Arber and Buettner, Florian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11545--11562},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qoku23a/qoku23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qoku23a.html},\n  abstract = \t {Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, patients can be characterized by data from different molecular layers. Latent variable models with structured sparsity are a commonly used tool for disentangling variation within and across data views. However, their interpretability is cumbersome since it requires a direct inspection and interpretation of each factor from domain experts. Here, we propose MuVI, a novel multi-view latent variable model based on a modified horseshoe prior for modeling structured sparsity. This facilitates the incorporation of limited and noisy domain knowledge, thereby allowing for an analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) outperforms state-of-the-art approaches for modeling structured sparsity in terms of the reconstruction error and the precision/recall, (ii) robustly integrates noisy domain expertise in the form of feature sets, (iii) promotes the identifiability of factors and (iv) infers interpretable and biologically meaningful axes of variation in a real-world multi-view dataset of cancer patients.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qoku23a/qoku23a.pdf",
        "supp": "",
        "pdf_size": 2803034,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17049109507822657213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "German Cancer Research Center (DKFZ) + German Cancer Consortium (DKTK) + Goethe University Frankfurt, Germany; German Cancer Research Center (DKFZ) + German Cancer Consortium (DKTK) + Frankfurt Cancer Institute, Germany + Goethe University Frankfurt, Germany",
        "aff_domain": "dkfz.de;dkfz.de",
        "email": "dkfz.de;dkfz.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;0+1+3+2",
        "aff_unique_norm": "German Cancer Research Center;German Cancer Consortium;Goethe University Frankfurt;Frankfurt Cancer Institute",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.dkfz.de;https://www.dktk.org;https://www.uni-frankfurt.de;",
        "aff_unique_abbr": "DKFZ;DKTK;GU Frankfurt;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0+0;0+0+0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "2cc58d267a",
        "title": "Energy-Based Models for Functional Data using Path Measure Tilting",
        "site": "https://proceedings.mlr.press/v206/lim23a.html",
        "author": "Jen Ning Lim; Sebastian Vollmer; Lorenz Wolf; Andrew Duncan",
        "abstract": "Energy-Based Models (EBMs) have proven to be a highly effective approach for modelling densities on finite-dimensional spaces. Their ability to incorporate domain-specific choices and constraints into the structure of the model through composition make EBMs an appealing candidate for applications in physics, biology and computer vision and various other fields. Recently, Energy-Based Processes (EBP) for modelling stochastic processes was proposed for unconditional exchangeable data (e.g., point clouds). In this work, we present a novel subclass of EBPs, called $\\mathcal{F}$-EBM for conditional exchangeable data, which is able to learn distributions of functions (such as curves or surfaces) from functional samples evaluated at finitely many points. Two unique challenges arise in the functional context. Firstly, training data is often not evaluated along a fixed set of points. Secondly, steps must be taken to control the behaviour of the model between evaluation points, to mitigate overfitting. The proposed model is an energy based model on function space that is decomposed spectrally, where a Gaussian Process path measure is used to reweight the distribution to capture smoothness properties of the underlying process being modelled. The resulting model has the ability to utilize irregularly sampled training data and can output predictions at any resolution, providing an effective approach to up-scaling functional data. We demonstrate the efficacy of our proposed approach for modelling a range of datasets, including data collected from Standard and Poor\u2019s 500 (S$&$P) and UK National grid.",
        "bibtex": "@InProceedings{pmlr-v206-lim23a,\n  title = \t {Energy-Based Models for Functional Data using Path Measure Tilting},\n  author =       {Lim, Jen Ning and Vollmer, Sebastian and Wolf, Lorenz and Duncan, Andrew},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1904--1923},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lim23a/lim23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lim23a.html},\n  abstract = \t {Energy-Based Models (EBMs) have proven to be a highly effective approach for modelling densities on finite-dimensional spaces. Their ability to incorporate domain-specific choices and constraints into the structure of the model through composition make EBMs an appealing candidate for applications in physics, biology and computer vision and various other fields. Recently, Energy-Based Processes (EBP) for modelling stochastic processes was proposed for unconditional exchangeable data (e.g., point clouds). In this work, we present a novel subclass of EBPs, called $\\mathcal{F}$-EBM for conditional exchangeable data, which is able to learn distributions of functions (such as curves or surfaces) from functional samples evaluated at finitely many points. Two unique challenges arise in the functional context. Firstly, training data is often not evaluated along a fixed set of points. Secondly, steps must be taken to control the behaviour of the model between evaluation points, to mitigate overfitting. The proposed model is an energy based model on function space that is decomposed spectrally, where a Gaussian Process path measure is used to reweight the distribution to capture smoothness properties of the underlying process being modelled. The resulting model has the ability to utilize irregularly sampled training data and can output predictions at any resolution, providing an effective approach to up-scaling functional data. We demonstrate the efficacy of our proposed approach for modelling a range of datasets, including data collected from Standard and Poor\u2019s 500 (S$&$P) and UK National grid.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lim23a/lim23a.pdf",
        "supp": "",
        "pdf_size": 22398629,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5470731186186287869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3a48c6959a",
        "title": "Entropic Risk Optimization in Discounted MDPs",
        "site": "https://proceedings.mlr.press/v206/lin-hau23a.html",
        "author": "Jia Lin Hau; Marek Petrik; Mohammad Ghavamzadeh",
        "abstract": "Risk-averse Markov Decision Processes (MDPs) have optimal policies that achieve high returns with low variability, but these MDPs are often difficult to solve. Only a few practical risk-averse objectives admit a dynamic programming (DP) formulation, which is the mainstay of most MDP and RL algorithms. We derive a new DP formulation for discounted risk-averse MDPs with Entropic Risk Measure (ERM) and Entropic Value at Risk (EVaR) objectives. Our DP formulation for ERM, which is possible because of our novel definition of value function with time-dependent risk levels, can approximate optimal policies in a time that is polynomial in the approximation error. We then use the ERM algorithm to optimize the EVaR objective in polynomial time using an optimized discretization scheme. Our numerical results show the viability of our formulations and algorithms in discounted MDPs.",
        "bibtex": "@InProceedings{pmlr-v206-lin-hau23a,\n  title = \t {Entropic Risk Optimization in Discounted MDPs},\n  author =       {Lin Hau, Jia and Petrik, Marek and Ghavamzadeh, Mohammad},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {47--76},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lin-hau23a/lin-hau23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lin-hau23a.html},\n  abstract = \t {Risk-averse Markov Decision Processes (MDPs) have optimal policies that achieve high returns with low variability, but these MDPs are often difficult to solve. Only a few practical risk-averse objectives admit a dynamic programming (DP) formulation, which is the mainstay of most MDP and RL algorithms. We derive a new DP formulation for discounted risk-averse MDPs with Entropic Risk Measure (ERM) and Entropic Value at Risk (EVaR) objectives. Our DP formulation for ERM, which is possible because of our novel definition of value function with time-dependent risk levels, can approximate optimal policies in a time that is polynomial in the approximation error. We then use the ERM algorithm to optimize the EVaR objective in polynomial time using an optimized discretization scheme. Our numerical results show the viability of our formulations and algorithms in discounted MDPs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lin-hau23a/lin-hau23a.pdf",
        "supp": "",
        "pdf_size": 432240,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10429647909919626024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "35bd0e6751",
        "title": "Equivariant Representation Learning via Class-Pose Decomposition",
        "site": "https://proceedings.mlr.press/v206/marchetti23b.html",
        "author": "Giovanni Luca Marchetti; Gustaf Tegn\u00e9r; Anastasiia Varava; Danica Kragic",
        "abstract": "We introduce a general method for learning representations that are equivariant to symmetries of data. Our central idea is to decompose the latent space into an invariant factor and the symmetry group itself. The components semantically correspond to intrinsic data classes and poses respectively. The learner is trained on a loss encouraging equivariance based on supervision from relative symmetry information. The approach is motivated by theoretical results from group theory and guarantees representations that are lossless, interpretable and disentangled. We provide an empirical investigation via experiments involving datasets with a variety of symmetries. Results show that our representations capture the geometry of data and outperform other equivariant representation learning frameworks.",
        "bibtex": "@InProceedings{pmlr-v206-marchetti23b,\n  title = \t {Equivariant Representation Learning via Class-Pose Decomposition},\n  author =       {Marchetti, Giovanni Luca and Tegn\\'er, Gustaf and Varava, Anastasiia and Kragic, Danica},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4745--4756},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/marchetti23b/marchetti23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/marchetti23b.html},\n  abstract = \t {We introduce a general method for learning representations that are equivariant to symmetries of data. Our central idea is to decompose the latent space into an invariant factor and the symmetry group itself. The components semantically correspond to intrinsic data classes and poses respectively. The learner is trained on a loss encouraging equivariance based on supervision from relative symmetry information. The approach is motivated by theoretical results from group theory and guarantees representations that are lossless, interpretable and disentangled. We provide an empirical investigation via experiments involving datasets with a variety of symmetries. Results show that our representations capture the geometry of data and outperform other equivariant representation learning frameworks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/marchetti23b/marchetti23b.pdf",
        "supp": "",
        "pdf_size": 2003129,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16174163000090989062&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8d02f61fbd",
        "title": "Error Estimation for Random Fourier Features",
        "site": "https://proceedings.mlr.press/v206/yao23a.html",
        "author": "Junwen Yao; N. Benjamin Erichson; Miles E. Lopes",
        "abstract": "Random Fourier Features (RFF) is among the most popular and broadly applicable approaches for scaling up kernel methods. In essence, RFF allows the user to avoid costly computations with a large kernel matrix via a fast randomized approximation. However, a pervasive difficulty in applying RFF is that the user does not know the actual error of the approximation, or how this error will propagate into downstream learning tasks. Up to now, the RFF literature has primarily dealt with these uncertainties using theoretical error bounds, but from a user\u2019s standpoint, such results are typically impractical\u2014either because they are highly conservative or involve unknown quantities. To tackle these general issues in a data-driven way, this paper develops a bootstrap approach to numerically estimate the errors of RFF approximations. Three key advantages of this approach are: (1) The error estimates are specific to the problem at hand, avoiding the pessimism of worst-case bounds. (2) The approach is flexible with respect to different uses of RFF, and can even estimate errors in downstream learning tasks. (3) The approach enables adaptive computation, in the sense that the user can quickly inspect the error of a rough initial kernel approximation and then predict how much extra work is needed. Furthermore, in exchange for all of these benefits, the error estimates can be obtained at a modest computational cost.",
        "bibtex": "@InProceedings{pmlr-v206-yao23a,\n  title = \t {Error Estimation for Random Fourier Features},\n  author =       {Yao, Junwen and Erichson, N. Benjamin and Lopes, Miles E.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2348--2364},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yao23a/yao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yao23a.html},\n  abstract = \t {Random Fourier Features (RFF) is among the most popular and broadly applicable approaches for scaling up kernel methods. In essence, RFF allows the user to avoid costly computations with a large kernel matrix via a fast randomized approximation. However, a pervasive difficulty in applying RFF is that the user does not know the actual error of the approximation, or how this error will propagate into downstream learning tasks. Up to now, the RFF literature has primarily dealt with these uncertainties using theoretical error bounds, but from a user\u2019s standpoint, such results are typically impractical\u2014either because they are highly conservative or involve unknown quantities. To tackle these general issues in a data-driven way, this paper develops a bootstrap approach to numerically estimate the errors of RFF approximations. Three key advantages of this approach are: (1) The error estimates are specific to the problem at hand, avoiding the pessimism of worst-case bounds. (2) The approach is flexible with respect to different uses of RFF, and can even estimate errors in downstream learning tasks. (3) The approach enables adaptive computation, in the sense that the user can quickly inspect the error of a rough initial kernel approximation and then predict how much extra work is needed. Furthermore, in exchange for all of these benefits, the error estimates can be obtained at a modest computational cost.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yao23a/yao23a.pdf",
        "supp": "",
        "pdf_size": 4447212,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2135855186062019955&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, Davis; Lawrence Berkeley National Laboratory; University of California, Davis",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Davis;Lawrence Berkeley National Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucdavis.edu;https://www.lbl.gov",
        "aff_unique_abbr": "UC Davis;LBNL",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Davis;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e6a0a9c231",
        "title": "Estimating Conditional Average Treatment Effects with Missing Treatment Information",
        "site": "https://proceedings.mlr.press/v206/kuzmanovic23a.html",
        "author": "Milan Kuzmanovic; Tobias Hatt; Stefan Feuerriegel",
        "abstract": "Estimating conditional average treatment effects (CATE) is challenging, especially when treatment information is missing. Although this is a widespread problem in practice, CATE estimation with missing treatments has received little attention. In this paper, we analyze CATE estimation in the setting with missing treatments where unique challenges arise in the form of covariate shifts. We identify two covariate shifts in our setting: (i) a covariate shift between the treated and control population; and (ii) a covariate shift between the observed and missing treatment population. We first theoretically show the effect of these covariate shifts by deriving a generalization bound for estimating CATE in our setting with missing treatments. Then, motivated by our bound, we develop the missing treatment representation network (MTRNet), a novel CATE estimation algorithm that learns a balanced representation of covariates using domain adaptation. By using balanced representations, MTRNet provides more reliable CATE estimates in the covariate domains where the data are not fully observed. In various experiments with semi-synthetic and real-world data, we show that our algorithm improves over the state-of-the-art by a substantial margin.",
        "bibtex": "@InProceedings{pmlr-v206-kuzmanovic23a,\n  title = \t {Estimating Conditional Average Treatment Effects with Missing Treatment Information},\n  author =       {Kuzmanovic, Milan and Hatt, Tobias and Feuerriegel, Stefan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {746--766},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kuzmanovic23a/kuzmanovic23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kuzmanovic23a.html},\n  abstract = \t {Estimating conditional average treatment effects (CATE) is challenging, especially when treatment information is missing. Although this is a widespread problem in practice, CATE estimation with missing treatments has received little attention. In this paper, we analyze CATE estimation in the setting with missing treatments where unique challenges arise in the form of covariate shifts. We identify two covariate shifts in our setting: (i) a covariate shift between the treated and control population; and (ii) a covariate shift between the observed and missing treatment population. We first theoretically show the effect of these covariate shifts by deriving a generalization bound for estimating CATE in our setting with missing treatments. Then, motivated by our bound, we develop the missing treatment representation network (MTRNet), a novel CATE estimation algorithm that learns a balanced representation of covariates using domain adaptation. By using balanced representations, MTRNet provides more reliable CATE estimates in the covariate domains where the data are not fully observed. In various experiments with semi-synthetic and real-world data, we show that our algorithm improves over the state-of-the-art by a substantial margin.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kuzmanovic23a/kuzmanovic23a.pdf",
        "supp": "",
        "pdf_size": 542936,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16814623385157372920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b5c3621392",
        "title": "Estimating Total Correlation with Mutual Information Estimators",
        "site": "https://proceedings.mlr.press/v206/bai23a.html",
        "author": "Ke Bai; Pengyu Cheng; Weituo Hao; Ricardo Henao; Larry Carin",
        "abstract": "Total correlation (TC) is a fundamental concept in information theory that measures statistical dependency among multiple random variables. Recently, TC has shown noticeable effectiveness as a regularizer in many learning tasks, where the correlation among multiple latent embeddings requires to be jointly minimized or maximized. However, calculating precise TC values is challenging, especially when the closed-form distributions of embedding variables are unknown. In this paper, we introduce a unified framework to estimate total correlation values with sample-based mutual information (MI) estimators. More specifically, we discover a relation between TC and MI and propose two types of calculation paths (tree-like and line-like) to decompose TC into MI terms. With each MI term being bounded, the TC values can be successfully estimated. Further, we provide theoretical analyses concerning the statistical consistency of the proposed TC estimators. Experiments are presented on both synthetic and real-world scenarios, where our estimators demonstrate effectiveness in all TC estimation, minimization, and maximization tasks.",
        "bibtex": "@InProceedings{pmlr-v206-bai23a,\n  title = \t {Estimating Total Correlation with Mutual Information Estimators},\n  author =       {Bai, Ke and Cheng, Pengyu and Hao, Weituo and Henao, Ricardo and Carin, Larry},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2147--2164},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bai23a/bai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bai23a.html},\n  abstract = \t {Total correlation (TC) is a fundamental concept in information theory that measures statistical dependency among multiple random variables. Recently, TC has shown noticeable effectiveness as a regularizer in many learning tasks, where the correlation among multiple latent embeddings requires to be jointly minimized or maximized. However, calculating precise TC values is challenging, especially when the closed-form distributions of embedding variables are unknown. In this paper, we introduce a unified framework to estimate total correlation values with sample-based mutual information (MI) estimators. More specifically, we discover a relation between TC and MI and propose two types of calculation paths (tree-like and line-like) to decompose TC into MI terms. With each MI term being bounded, the TC values can be successfully estimated. Further, we provide theoretical analyses concerning the statistical consistency of the proposed TC estimators. Experiments are presented on both synthetic and real-world scenarios, where our estimators demonstrate effectiveness in all TC estimation, minimization, and maximization tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bai23a/bai23a.pdf",
        "supp": "",
        "pdf_size": 1925368,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5022914881829913476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Duke University; Tencent AI Lab; ByteDance; KAUST; KAUST",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/Linear95/TC-estimation",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;3",
        "aff_unique_norm": "Duke University;Tencent;ByteDance;King Abdullah University of Science and Technology",
        "aff_unique_dep": ";Tencent AI Lab;;",
        "aff_unique_url": "https://www.duke.edu;https://ai.tencent.com;https://www.bytedance.com;https://www.kaust.edu.sa",
        "aff_unique_abbr": "Duke;Tencent AI Lab;ByteDance;KAUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;2",
        "aff_country_unique": "United States;China;Saudi Arabia"
    },
    {
        "id": "7b33c59526",
        "title": "Exact Gradient Computation for Spiking Neural Networks via Forward Propagation",
        "site": "https://proceedings.mlr.press/v206/lee23b.html",
        "author": "Jane H. Lee; Saeid Haghighatshoar; Amin Karbasi",
        "abstract": "Spiking neural networks (SNN) have recently emerged as alternatives to traditional neural networks, owing to its energy efficiency benefits and capacity to capture biological neuronal mechanisms. However, the classic backpropagation algorithm for training traditional networks has been notoriously difficult to apply to SNN due to the hard-thresholding and discontinuities at spike times. Therefore, a large majority of prior work believes exact gradients for SNN w.r.t. their weights do not exist and has focused on approximation methods to produce surrogate gradients. In this paper, (1) by applying the implicit function theorem to SNN at the discrete spike times, we prove that, albeit being non-differentiable in time, SNNs have well-defined gradients w.r.t. their weights, and (2) we propose a novel training algorithm, called forward propagation (FP), that computes exact gradients for SNN. FP exploits the causality structure between the spikes and allows us to parallelize computation forward in time. It can be used with other algorithms that simulate the forward pass, and it also provides insights on why other related algorithms such as Hebbian learning and also recently-proposed surrogate gradient methods may perform well.",
        "bibtex": "@InProceedings{pmlr-v206-lee23b,\n  title = \t {Exact Gradient Computation for Spiking Neural Networks via Forward Propagation},\n  author =       {Lee, Jane H. and Haghighatshoar, Saeid and Karbasi, Amin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1812--1831},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lee23b/lee23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lee23b.html},\n  abstract = \t {Spiking neural networks (SNN) have recently emerged as alternatives to traditional neural networks, owing to its energy efficiency benefits and capacity to capture biological neuronal mechanisms. However, the classic backpropagation algorithm for training traditional networks has been notoriously difficult to apply to SNN due to the hard-thresholding and discontinuities at spike times. Therefore, a large majority of prior work believes exact gradients for SNN w.r.t. their weights do not exist and has focused on approximation methods to produce surrogate gradients. In this paper, (1) by applying the implicit function theorem to SNN at the discrete spike times, we prove that, albeit being non-differentiable in time, SNNs have well-defined gradients w.r.t. their weights, and (2) we propose a novel training algorithm, called forward propagation (FP), that computes exact gradients for SNN. FP exploits the causality structure between the spikes and allows us to parallelize computation forward in time. It can be used with other algorithms that simulate the forward pass, and it also provides insights on why other related algorithms such as Hebbian learning and also recently-proposed surrogate gradient methods may perform well.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lee23b/lee23b.pdf",
        "supp": "",
        "pdf_size": 1930764,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11250749440555885382&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9f0ce94b36",
        "title": "Explicit Regularization in Overparametrized Models via Noise Injection",
        "site": "https://proceedings.mlr.press/v206/orvieto23a.html",
        "author": "Antonio Orvieto; Anant Raj; Hans Kersting; Francis Bach",
        "abstract": "Injecting noise within gradient descent has several desirable features, such as smoothing and regularizing properties. In this paper, we investigate the effects of injecting noise before computing a gradient step. We demonstrate that small perturbations can induce explicit regularization for simple models based on the L1-norm, group L1-norms, or nuclear norms. However, when applied to overparametrized neural networks with large widths, we show that the same perturbations can cause variance explosion. To overcome this, we propose using independent layer-wise perturbations, which provably allow for explicit regularization without variance explosion. Our empirical results show that these small perturbations lead to improved generalization performance compared to vanilla gradient descent.",
        "bibtex": "@InProceedings{pmlr-v206-orvieto23a,\n  title = \t {Explicit Regularization in Overparametrized Models via Noise Injection},\n  author =       {Orvieto, Antonio and Raj, Anant and Kersting, Hans and Bach, Francis},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7265--7287},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/orvieto23a/orvieto23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/orvieto23a.html},\n  abstract = \t {Injecting noise within gradient descent has several desirable features, such as smoothing and regularizing properties. In this paper, we investigate the effects of injecting noise before computing a gradient step. We demonstrate that small perturbations can induce explicit regularization for simple models based on the L1-norm, group L1-norms, or nuclear norms. However, when applied to overparametrized neural networks with large widths, we show that the same perturbations can cause variance explosion. To overcome this, we propose using independent layer-wise perturbations, which provably allow for explicit regularization without variance explosion. Our empirical results show that these small perturbations lead to improved generalization performance compared to vanilla gradient descent.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/orvieto23a/orvieto23a.pdf",
        "supp": "",
        "pdf_size": 2639603,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17168878924085774552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5b455605f1",
        "title": "Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference",
        "site": "https://proceedings.mlr.press/v206/banerjee23b.html",
        "author": "Debangshu Banerjee; Avishek Ghosh; Sayak Ray Chowdhury; Aditya Gopalan",
        "abstract": "We present a non-asymptotic lower bound on the spectrum of the design matrix generated by any linear bandit algorithm with sub-linear regret when the action set has well-behaved curvature. Specifically, we show that the minimum eigenvalue of the expected design matrix grows as $\\Omega(\\sqrt{n})$ whenever the expected cumulative regret of the algorithm is $O(\\sqrt{n})$, where $n$ is the learning horizon, and the action-space has a constant Hessian around the optimal arm. This shows that such action-spaces force a polynomial lower bound on the least eigenvalue, rather than a logarithmic lower bound as shown by Lattimore et al. (2017) for discrete (i.e., well-separated) action spaces. Furthermore, while the latter holds only in the asymptotic regime ($n \\to \\infty$), our result for these \u201clocally rich\u201d action spaces is any-time. Additionally, under a mild technical assumption, we obtain a similar lower bound on the minimum eigen value holding with high probability. We apply our result to two practical scenarios \u2013 model selection and clustering in linear bandits. For model selection, we show that an epoch-based linear bandit algorithm adapts to the true model complexity at a rate exponential in the number of epochs, by virtue of our novel spectral bound. For clustering, we consider a multi agent framework where we show, by leveraging the spectral result, that no forced exploration is necessary\u2014the agents can run a linear bandit algorithm and estimate their underlying parameters at once, and hence incur a low regret.",
        "bibtex": "@InProceedings{pmlr-v206-banerjee23b,\n  title = \t {Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference},\n  author =       {Banerjee, Debangshu and Ghosh, Avishek and Ray Chowdhury, Sayak and Gopalan, Aditya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8233--8262},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/banerjee23b/banerjee23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/banerjee23b.html},\n  abstract = \t {We present a non-asymptotic lower bound on the spectrum of the design matrix generated by any linear bandit algorithm with sub-linear regret when the action set has well-behaved curvature. Specifically, we show that the minimum eigenvalue of the expected design matrix grows as $\\Omega(\\sqrt{n})$ whenever the expected cumulative regret of the algorithm is $O(\\sqrt{n})$, where $n$ is the learning horizon, and the action-space has a constant Hessian around the optimal arm. This shows that such action-spaces force a polynomial lower bound on the least eigenvalue, rather than a logarithmic lower bound as shown by Lattimore et al. (2017) for discrete (i.e., well-separated) action spaces. Furthermore, while the latter holds only in the asymptotic regime ($n \\to \\infty$), our result for these \u201clocally rich\u201d action spaces is any-time. Additionally, under a mild technical assumption, we obtain a similar lower bound on the minimum eigen value holding with high probability. We apply our result to two practical scenarios \u2013 model selection and clustering in linear bandits. For model selection, we show that an epoch-based linear bandit algorithm adapts to the true model complexity at a rate exponential in the number of epochs, by virtue of our novel spectral bound. For clustering, we consider a multi agent framework where we show, by leveraging the spectral result, that no forced exploration is necessary\u2014the agents can run a linear bandit algorithm and estimate their underlying parameters at once, and hence incur a low regret.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/banerjee23b/banerjee23b.pdf",
        "supp": "",
        "pdf_size": 914461,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18426448063337184230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6538dd1ee0",
        "title": "Exploration in Reward Machines with Low Regret",
        "site": "https://proceedings.mlr.press/v206/bourel23a.html",
        "author": "Hippolyte Bourel; Anders Jonsson; Odalric-Ambrym Maillard; Mohammad Sadegh Talebi",
        "abstract": "We study reinforcement learning (RL) for decision processes with non-Markovian reward, in which high-level knowledge in the form of reward machines is available to the learner. Specifically, we investigate the efficiency of RL under the average-reward criterion, in the regret minimization setting. We propose two model-based RL algorithms that each exploits the structure of the reward machines, and show that our algorithms achieve regret bounds that improve over those of baselines by a multiplicative factor proportional to the number of states in the underlying reward machine. To the best of our knowledge, the proposed algorithms and associated regret bounds are the first to tailor the analysis specifically to reward machines, either in the episodic or average-reward settings. We also present a regret lower bound for the studied setting, which indicates that the proposed algorithms achieve a near-optimal regret. Finally, we report numerical experiments that demonstrate the superiority of the proposed algorithms over existing baselines in practice.",
        "bibtex": "@InProceedings{pmlr-v206-bourel23a,\n  title = \t {Exploration in Reward Machines with Low Regret},\n  author =       {Bourel, Hippolyte and Jonsson, Anders and Maillard, Odalric-Ambrym and Talebi, Mohammad Sadegh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4114--4146},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bourel23a/bourel23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bourel23a.html},\n  abstract = \t {We study reinforcement learning (RL) for decision processes with non-Markovian reward, in which high-level knowledge in the form of reward machines is available to the learner. Specifically, we investigate the efficiency of RL under the average-reward criterion, in the regret minimization setting. We propose two model-based RL algorithms that each exploits the structure of the reward machines, and show that our algorithms achieve regret bounds that improve over those of baselines by a multiplicative factor proportional to the number of states in the underlying reward machine. To the best of our knowledge, the proposed algorithms and associated regret bounds are the first to tailor the analysis specifically to reward machines, either in the episodic or average-reward settings. We also present a regret lower bound for the studied setting, which indicates that the proposed algorithms achieve a near-optimal regret. Finally, we report numerical experiments that demonstrate the superiority of the proposed algorithms over existing baselines in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bourel23a/bourel23a.pdf",
        "supp": "",
        "pdf_size": 1407358,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13078842927196818557&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "20a8e22f76",
        "title": "FAIR: Fair Collaborative Active Learning with Individual Rationality for Scientific Discovery",
        "site": "https://proceedings.mlr.press/v206/xu23e.html",
        "author": "Xinyi Xu; Zhaoxuan Wu; Arun Verma; Chuan Sheng Foo; Bryan Kian Hsiang Low",
        "abstract": "Scientific discovery aims to find new patterns and test specific hypotheses by analysing large-scale experimental data. However, various practical limitations (e.g., high experimental costs or the inability to perform some experiments) make it challenging for researchers to collect sufficient experimental data for successful scientific discovery. To this end, we propose a collaborative active learning (CAL) framework that enables researchers to share their experimental data for mutual benefit. Specifically, our proposed coordinated acquisition function sets out to achieve individual rationality and fairness so that everyone can equitably benefit from collaboration. We empirically demonstrate that our method outperforms existing batch active learning ones (adapted to the CAL setting) in terms of both learning performance and fairness on various real-world scientific discovery datasets (biochemistry, material science, and physics).",
        "bibtex": "@InProceedings{pmlr-v206-xu23e,\n  title = \t {FAIR: Fair Collaborative Active Learning with Individual Rationality for Scientific Discovery},\n  author =       {Xu, Xinyi and Wu, Zhaoxuan and Verma, Arun and Foo, Chuan Sheng and Low, Bryan Kian Hsiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4033--4057},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23e/xu23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23e.html},\n  abstract = \t {Scientific discovery aims to find new patterns and test specific hypotheses by analysing large-scale experimental data. However, various practical limitations (e.g., high experimental costs or the inability to perform some experiments) make it challenging for researchers to collect sufficient experimental data for successful scientific discovery. To this end, we propose a collaborative active learning (CAL) framework that enables researchers to share their experimental data for mutual benefit. Specifically, our proposed coordinated acquisition function sets out to achieve individual rationality and fairness so that everyone can equitably benefit from collaboration. We empirically demonstrate that our method outperforms existing batch active learning ones (adapted to the CAL setting) in terms of both learning performance and fairness on various real-world scientific discovery datasets (biochemistry, material science, and physics).}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23e/xu23e.pdf",
        "supp": "",
        "pdf_size": 2183578,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2967995501823432004&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, National University of Singapore + Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore; Institute of Data Science & ISEP NUSGS, National University of Singapore + Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore; Department of Computer Science, National University of Singapore; Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore + Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research (A*STAR), Singapore; Department of Computer Science, National University of Singapore",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0;1+1;0",
        "aff_unique_norm": "National University of Singapore;Agency for Science, Technology and Research",
        "aff_unique_dep": "Department of Computer Science;Institute for Infocomm Research",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.a-star.edu.sg",
        "aff_unique_abbr": "NUS;A*STAR",
        "aff_campus_unique_index": ";1;",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0+0;0+0;0;0+0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "b786acc5e0",
        "title": "Factorial SDE for Multi-Output Gaussian Process Regression",
        "site": "https://proceedings.mlr.press/v206/jeong23a.html",
        "author": "Daniel P. Jeong; Seyoung Kim",
        "abstract": "Multi-output Gaussian process (GP) regression has been widely used as a flexible nonparametric Bayesian model for predicting multiple correlated outputs given inputs. However, the cubic complexity in the sample size and the output dimensions for inverting the kernel matrix has limited their use in the large-data regime. In this paper, we introduce the factorial stochastic differential equation as a representation of multi-output GP regression, which is a factored state-space representation as in factorial hidden Markov models. We propose a structured mean-field variational inference approach that achieves a time complexity linear in the number of samples, along with its sparse variational inference counterpart with complexity linear in the number of inducing points. On simulated and real-world data, we show that our approach significantly improves upon the scalability of previous methods, while achieving competitive prediction accuracy.",
        "bibtex": "@InProceedings{pmlr-v206-jeong23a,\n  title = \t {Factorial SDE for Multi-Output Gaussian Process Regression},\n  author =       {Jeong, Daniel P. and Kim, Seyoung},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9755--9772},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jeong23a/jeong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jeong23a.html},\n  abstract = \t {Multi-output Gaussian process (GP) regression has been widely used as a flexible nonparametric Bayesian model for predicting multiple correlated outputs given inputs. However, the cubic complexity in the sample size and the output dimensions for inverting the kernel matrix has limited their use in the large-data regime. In this paper, we introduce the factorial stochastic differential equation as a representation of multi-output GP regression, which is a factored state-space representation as in factorial hidden Markov models. We propose a structured mean-field variational inference approach that achieves a time complexity linear in the number of samples, along with its sparse variational inference counterpart with complexity linear in the number of inducing points. On simulated and real-world data, we show that our approach significantly improves upon the scalability of previous methods, while achieving competitive prediction accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jeong23a/jeong23a.pdf",
        "supp": "",
        "pdf_size": 5245026,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:pkYzvoZTTr4J:scholar.google.com/&scioq=Factorial+SDE+for+Multi-Output+Gaussian+Process+Regression&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "aff": "Machine Learning Department, School of Computer Science, Carnegie Mellon University; Computational Biology Department, School of Computer Science, Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0c3b59751a",
        "title": "Fair Representation Learning with Unreliable Labels",
        "site": "https://proceedings.mlr.press/v206/zhang23g.html",
        "author": "Yixuan Zhang; Feng Zhou; Zhidong Li; Yang Wang; Fang Chen",
        "abstract": "In learning with fairness, for every instance, its label can be randomly flipped to another class due to the practitioner\u2019s prejudice, namely, label bias. The existing well-studied fair representation learning methods focus on removing the dependency between the sensitive factors and the input data, but do not address how the representations retain useful information when the labels are unreliable. In fact, we find that the learned representations become random or degenerated when the instance is contaminated by label bias. To alleviate this issue, we investigate the problem of learning fair representations that are independent of the sensitive factors while retaining the task-relevant information given only access to unreliable labels. Our model disentangles the dependency between fair representations and sensitive factors in the latent space. To remove the reliance between the labels and sensitive factors, we incorporate an additional penalty based on mutual information. The learned purged fair representations can then be used in any downstream processing. We demonstrate the superiority of our method over previous works through multiple experiments on both synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23g,\n  title = \t {Fair Representation Learning with Unreliable Labels},\n  author =       {Zhang, Yixuan and Zhou, Feng and Li, Zhidong and Wang, Yang and Chen, Fang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4655--4667},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23g/zhang23g.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23g.html},\n  abstract = \t {In learning with fairness, for every instance, its label can be randomly flipped to another class due to the practitioner\u2019s prejudice, namely, label bias. The existing well-studied fair representation learning methods focus on removing the dependency between the sensitive factors and the input data, but do not address how the representations retain useful information when the labels are unreliable. In fact, we find that the learned representations become random or degenerated when the instance is contaminated by label bias. To alleviate this issue, we investigate the problem of learning fair representations that are independent of the sensitive factors while retaining the task-relevant information given only access to unreliable labels. Our model disentangles the dependency between fair representations and sensitive factors in the latent space. To remove the reliance between the labels and sensitive factors, we incorporate an additional penalty based on mutual information. The learned purged fair representations can then be used in any downstream processing. We demonstrate the superiority of our method over previous works through multiple experiments on both synthetic and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23g/zhang23g.pdf",
        "supp": "",
        "pdf_size": 2997668,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11203335639141390224&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fa6749005d",
        "title": "Fair learning with Wasserstein barycenters for non-decomposable performance measures",
        "site": "https://proceedings.mlr.press/v206/gaucher23a.html",
        "author": "Solenne Gaucher; Nicolas Schreuder; Evgenii Chzhen",
        "abstract": "This work provides several fundamental characterizations of the optimal classification function under the demographic parity constraint. In the awareness framework, akin to the classical unconstrained classification case, we show that maximizing accuracy under this fairness constraint is equivalent to solving a fair regression problem followed by thresholding at level $1/2$. We extend this result to linear-fractional classification measures (e.g., $F$-score, AM measure, balanced accuracy, etc.), highlighting the fundamental role played by regression in this framework. Our results leverage recently developed connection between the demographic parity constraint and the multi-marginal optimal transport formulation. Informally, our result shows that the transition between the unconstrained problem and the fair one is achieved by replacing the conditional expectation of the label by the solution of the fair regression problem. Finally, leveraging our analysis, we demonstrate an equivalence between the awareness and the unawareness setups for two sensitive groups.",
        "bibtex": "@InProceedings{pmlr-v206-gaucher23a,\n  title = \t {Fair learning with Wasserstein barycenters for non-decomposable performance measures},\n  author =       {Gaucher, Solenne and Schreuder, Nicolas and Chzhen, Evgenii},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2436--2459},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gaucher23a/gaucher23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gaucher23a.html},\n  abstract = \t {This work provides several fundamental characterizations of the optimal classification function under the demographic parity constraint. In the awareness framework, akin to the classical unconstrained classification case, we show that maximizing accuracy under this fairness constraint is equivalent to solving a fair regression problem followed by thresholding at level $1/2$. We extend this result to linear-fractional classification measures (e.g., $F$-score, AM measure, balanced accuracy, etc.), highlighting the fundamental role played by regression in this framework. Our results leverage recently developed connection between the demographic parity constraint and the multi-marginal optimal transport formulation. Informally, our result shows that the transition between the unconstrained problem and the fair one is achieved by replacing the conditional expectation of the label by the solution of the fair regression problem. Finally, leveraging our analysis, we demonstrate an equivalence between the awareness and the unawareness setups for two sensitive groups.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gaucher23a/gaucher23a.pdf",
        "supp": "",
        "pdf_size": 945128,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3882533328667569704&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "253b5f61b8",
        "title": "Faithful Heteroscedastic Regression with Neural Networks",
        "site": "https://proceedings.mlr.press/v206/stirn23a.html",
        "author": "Andrew Stirn; Harm Wessels; Megan Schertzer; Laura Pereira; Neville Sanjana; David Knowles",
        "abstract": "Heteroscedastic regression models a Gaussian variable\u2019s mean and variance as a function of covariates. Parametric methods that employ neural networks for these parameter maps can capture complex relationships in the data. Yet, optimizing network parameters via log likelihood gradients can yield suboptimal mean and uncalibrated variance estimates. Current solutions side-step this optimization problem with surrogate objectives or Bayesian treatments. Instead, we make two simple modifications to optimization. Notably, their combination produces a heteroscedastic model with mean estimates that are provably as accurate as those from its homoscedastic counterpart (i.e.\u00a0fitting the mean under squared error loss). For a wide variety of network and task complexities, we find that mean estimates from existing heteroscedastic solutions can be significantly less accurate than those from an equivalently expressive mean-only model. Our approach provably retains the accuracy of an equally flexible mean-only model while also offering best-in-class variance calibration. Lastly, we show how to leverage our method to recover the underlying heteroscedastic noise variance.",
        "bibtex": "@InProceedings{pmlr-v206-stirn23a,\n  title = \t {Faithful Heteroscedastic Regression with Neural Networks},\n  author =       {Stirn, Andrew and Wessels, Harm and Schertzer, Megan and Pereira, Laura and Sanjana, Neville and Knowles, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5593--5613},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/stirn23a/stirn23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/stirn23a.html},\n  abstract = \t {Heteroscedastic regression models a Gaussian variable\u2019s mean and variance as a function of covariates. Parametric methods that employ neural networks for these parameter maps can capture complex relationships in the data. Yet, optimizing network parameters via log likelihood gradients can yield suboptimal mean and uncalibrated variance estimates. Current solutions side-step this optimization problem with surrogate objectives or Bayesian treatments. Instead, we make two simple modifications to optimization. Notably, their combination produces a heteroscedastic model with mean estimates that are provably as accurate as those from its homoscedastic counterpart (i.e.\u00a0fitting the mean under squared error loss). For a wide variety of network and task complexities, we find that mean estimates from existing heteroscedastic solutions can be significantly less accurate than those from an equivalently expressive mean-only model. Our approach provably retains the accuracy of an equally flexible mean-only model while also offering best-in-class variance calibration. Lastly, we show how to leverage our method to recover the underlying heteroscedastic noise variance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/stirn23a/stirn23a.pdf",
        "supp": "",
        "pdf_size": 6376816,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15380659930397325765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b50c33344f",
        "title": "Falsification of Internal and External Validity in Observational Studies via Conditional Moment Restrictions",
        "site": "https://proceedings.mlr.press/v206/hussain23a.html",
        "author": "Zeshan Hussain; Ming-Chieh Shih; Michael Oberst; Ilker Demirel; David Sontag",
        "abstract": "Randomized Controlled Trials (RCT)s are relied upon to assess new treatments, but suffer from limited power to guide personalized treatment decisions. On the other hand, observational (i.e., non-experimental) studies have large and diverse populations, but are prone to various biases (e.g. residual confounding). To safely leverage the strengths of observational studies, we focus on the problem of falsification, whereby RCTs are used to validate causal effect estimates learned from observational data. In particular, we show that, given data from both an RCT and an observational study, assumptions on internal and external validity have an observable, testable implication in the form of a set of Conditional Moment Restrictions (CMRs). Further, we show that expressing these CMRs with respect to the causal effect, or \u201ccausal contrast\u201d, as opposed to individual counterfactual means, provides a more reliable falsification test. In addition to giving guarantees on the asymptotic properties of our test, we demonstrate superior power and type I error of our approach on semi-synthetic and real world datasets. Our approach is interpretable, allowing a practitioner to visualize which subgroups in the population lead to falsification of an observational study.",
        "bibtex": "@InProceedings{pmlr-v206-hussain23a,\n  title = \t {Falsification of Internal and External Validity in Observational Studies via Conditional Moment Restrictions},\n  author =       {Hussain, Zeshan and Shih, Ming-Chieh and Oberst, Michael and Demirel, Ilker and Sontag, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5869--5898},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hussain23a/hussain23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hussain23a.html},\n  abstract = \t {Randomized Controlled Trials (RCT)s are relied upon to assess new treatments, but suffer from limited power to guide personalized treatment decisions. On the other hand, observational (i.e., non-experimental) studies have large and diverse populations, but are prone to various biases (e.g. residual confounding). To safely leverage the strengths of observational studies, we focus on the problem of falsification, whereby RCTs are used to validate causal effect estimates learned from observational data. In particular, we show that, given data from both an RCT and an observational study, assumptions on internal and external validity have an observable, testable implication in the form of a set of Conditional Moment Restrictions (CMRs). Further, we show that expressing these CMRs with respect to the causal effect, or \u201ccausal contrast\u201d, as opposed to individual counterfactual means, provides a more reliable falsification test. In addition to giving guarantees on the asymptotic properties of our test, we demonstrate superior power and type I error of our approach on semi-synthetic and real world datasets. Our approach is interpretable, allowing a practitioner to visualize which subgroups in the population lead to falsification of an observational study.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hussain23a/hussain23a.pdf",
        "supp": "",
        "pdf_size": 908225,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13254049313675289847&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "MIT; National Dong Hwa University; MIT; MIT; MIT",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;National Dong Hwa University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.ndhu.edu.tw",
        "aff_unique_abbr": "MIT;NDHU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Taiwan",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "b16c42aca2",
        "title": "Fast Block Coordinate Descent for Non-Convex Group Regularizations",
        "site": "https://proceedings.mlr.press/v206/ida23a.html",
        "author": "Yasutoshi Ida; Sekitoshi Kanai; Atsutoshi Kumagai",
        "abstract": "Non-convex sparse regularizations with group structures are useful tools for selecting important feature groups. For optimization with these regularizations, block coordinate descent (BCD) is a standard solver that iteratively updates each parameter group. However, it suffers from high computation costs for a large number of parameter groups. The state-of-the-art method prunes unnecessary updates in BCD by utilizing bounds on the norms of the parameter groups. Unfortunately, since it computes the bound for each iteration, the computation cost still tends to be high when the updates are not sufficiently pruned. This paper proposes a fast BCD for non-convex group regularizations. Specifically, it selects a small subset of the parameter groups from all the parameter groups on the basis of the bounds and performs BCD on the subset. The subset grows step by step in accordance with the bounds during optimization. Since it computes the bounds only when selecting and growing the subsets, the total cost for computing the bounds is smaller than in the previous method. In addition, we theoretically guarantee the convergence of our method. Experiments show that our method is up to four times faster than the state-of-the-art method and 68 times faster than the original BCD without any loss of accuracy.",
        "bibtex": "@InProceedings{pmlr-v206-ida23a,\n  title = \t {Fast Block Coordinate Descent for Non-Convex Group Regularizations},\n  author =       {Ida, Yasutoshi and Kanai, Sekitoshi and Kumagai, Atsutoshi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2481--2493},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ida23a/ida23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ida23a.html},\n  abstract = \t {Non-convex sparse regularizations with group structures are useful tools for selecting important feature groups. For optimization with these regularizations, block coordinate descent (BCD) is a standard solver that iteratively updates each parameter group. However, it suffers from high computation costs for a large number of parameter groups. The state-of-the-art method prunes unnecessary updates in BCD by utilizing bounds on the norms of the parameter groups. Unfortunately, since it computes the bound for each iteration, the computation cost still tends to be high when the updates are not sufficiently pruned. This paper proposes a fast BCD for non-convex group regularizations. Specifically, it selects a small subset of the parameter groups from all the parameter groups on the basis of the bounds and performs BCD on the subset. The subset grows step by step in accordance with the bounds during optimization. Since it computes the bounds only when selecting and growing the subsets, the total cost for computing the bounds is smaller than in the previous method. In addition, we theoretically guarantee the convergence of our method. Experiments show that our method is up to four times faster than the state-of-the-art method and 68 times faster than the original BCD without any loss of accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ida23a/ida23a.pdf",
        "supp": "",
        "pdf_size": 493558,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=584543796267603839&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8a0ad97b43",
        "title": "Fast Computation of Branching Process Transition Probabilities via ADMM",
        "site": "https://proceedings.mlr.press/v206/awasthi23a.html",
        "author": "Achal Awasthi; Jason Xu",
        "abstract": "Branching processes are a class of continuous-time Markov chains (CTMCs) prevalent for modeling stochastic population dynamics in ecology, biology, epidemiology, and many other fields. The transient or finite-time behavior of these systems is fully characterized by their transition probabilities. However, computing them requires marginalizing over all paths between endpoint-conditioned values, which often poses a computational bottleneck. Leveraging recent results that connect generating function methods to a compressed sensing framework, we recast this task from the lens of sparse optimization. We propose a new solution method using variable splitting; in particular, we derive closed form updates in a highly efficient ADMM algorithm. Notably, no matrix products\u2014let alone inversions\u2014are required at any step. This reduces computational cost by orders of magnitude over existing methods, and the algorithm is easily parallelizable and fairly insensitive to tuning parameters. A comparison to prior work is carried out in two applications to models of blood cell production and transposon evolution, showing that the proposed method is orders of magnitudes more scalable than existing work.",
        "bibtex": "@InProceedings{pmlr-v206-awasthi23a,\n  title = \t {Fast Computation of Branching Process Transition Probabilities via ADMM},\n  author =       {Awasthi, Achal and Xu, Jason},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2327--2347},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/awasthi23a/awasthi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/awasthi23a.html},\n  abstract = \t {Branching processes are a class of continuous-time Markov chains (CTMCs) prevalent for modeling stochastic population dynamics in ecology, biology, epidemiology, and many other fields. The transient or finite-time behavior of these systems is fully characterized by their transition probabilities. However, computing them requires marginalizing over all paths between endpoint-conditioned values, which often poses a computational bottleneck. Leveraging recent results that connect generating function methods to a compressed sensing framework, we recast this task from the lens of sparse optimization. We propose a new solution method using variable splitting; in particular, we derive closed form updates in a highly efficient ADMM algorithm. Notably, no matrix products\u2014let alone inversions\u2014are required at any step. This reduces computational cost by orders of magnitude over existing methods, and the algorithm is easily parallelizable and fairly insensitive to tuning parameters. A comparison to prior work is carried out in two applications to models of blood cell production and transposon evolution, showing that the proposed method is orders of magnitudes more scalable than existing work.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/awasthi23a/awasthi23a.pdf",
        "supp": "",
        "pdf_size": 523486,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:DFW9wQnk17cJ:scholar.google.com/&scioq=Fast+Computation+of+Branching+Process+Transition+Probabilities+via+ADMM&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "Duke University; Duke University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8cf66f8dd6",
        "title": "Fast Distributed k-Means with a Small Number of Rounds",
        "site": "https://proceedings.mlr.press/v206/hess23a.html",
        "author": "Tom Hess; Ron Visbord; Sivan Sabato",
        "abstract": "We propose a new algorithm for k-means clustering in a distributed setting, where the data is distributed across many machines, and a coordinator communicates with these machines to calculate the output clustering. Our algorithm guarantees a cost approximation factor and a number of communication rounds that depend only on the computational capacity of the coordinator. Moreover, the algorithm includes a built-in stopping mechanism, which allows it to use fewer communication rounds whenever possible. We show both theoretically and empirically that in many natural cases, indeed 1-4 rounds suffice. In comparison with the popular k-means$||$ algorithm, our approach allows exploiting a larger coordinator capacity to obtain a smaller number of rounds. Our experiments show that the k-means cost obtained by the proposed algorithm is usually better than the cost obtained by k-means$||$, even when the latter is allowed a larger number of rounds. Moreover, the machine running time in our approach is considerably smaller than that of k-means$||$.",
        "bibtex": "@InProceedings{pmlr-v206-hess23a,\n  title = \t {Fast Distributed k-Means with a Small Number of Rounds},\n  author =       {Hess, Tom and Visbord, Ron and Sabato, Sivan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {850--874},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hess23a/hess23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hess23a.html},\n  abstract = \t {We propose a new algorithm for k-means clustering in a distributed setting, where the data is distributed across many machines, and a coordinator communicates with these machines to calculate the output clustering. Our algorithm guarantees a cost approximation factor and a number of communication rounds that depend only on the computational capacity of the coordinator. Moreover, the algorithm includes a built-in stopping mechanism, which allows it to use fewer communication rounds whenever possible. We show both theoretically and empirically that in many natural cases, indeed 1-4 rounds suffice. In comparison with the popular k-means$||$ algorithm, our approach allows exploiting a larger coordinator capacity to obtain a smaller number of rounds. Our experiments show that the k-means cost obtained by the proposed algorithm is usually better than the cost obtained by k-means$||$, even when the latter is allowed a larger number of rounds. Moreover, the machine running time in our approach is considerably smaller than that of k-means$||$.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hess23a/hess23a.pdf",
        "supp": "",
        "pdf_size": 410865,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=307334781015269356&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel; Independent researcher; Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel",
        "aff_domain": ";;",
        "email": ";;",
        "github": "https://github.com/selotape/distributed_k_means",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev;Independent Researcher",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.bgu.ac.il;",
        "aff_unique_abbr": "BGU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beer Sheva;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel;"
    },
    {
        "id": "69368447eb",
        "title": "Fast Feature Selection with Fairness Constraints",
        "site": "https://proceedings.mlr.press/v206/quinzan23a.html",
        "author": "Francesco Quinzan; Rajiv Khanna; Moshik Hershcovitch; Sarel Cohen; Daniel Waddington; Tobias Friedrich; Michael W. Mahoney",
        "abstract": "We study the fundamental problem of selecting optimal features for model construction. This problem is computationally challenging on large datasets, even with the use of greedy algorithm variants. To address this challenge, we extend the adaptive query model, recently proposed for the greedy forward selection for submodular functions, to the faster paradigm of Orthogonal Matching Pursuit for non-submodular functions. The proposed algorithm achieves exponentially fast parallel run time in the adaptive query model, scaling much better than prior work. Furthermore, our extension allows the use of downward-closed constraints, which can be used to encode certain fairness criteria into the feature selection process. We prove strong approximation guarantees for the algorithm based on standard assumptions. These guarantees are applicable to many parametric models, including Generalized Linear Models. Finally, we demonstrate empirically that the proposed algorithm competes favorably with state-of-the-art techniques for feature selection, on real-world and synthetic datasets.",
        "bibtex": "@InProceedings{pmlr-v206-quinzan23a,\n  title = \t {Fast Feature Selection with Fairness Constraints},\n  author =       {Quinzan, Francesco and Khanna, Rajiv and Hershcovitch, Moshik and Cohen, Sarel and Waddington, Daniel and Friedrich, Tobias and Mahoney, Michael W.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7800--7823},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/quinzan23a/quinzan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/quinzan23a.html},\n  abstract = \t {We study the fundamental problem of selecting optimal features for model construction. This problem is computationally challenging on large datasets, even with the use of greedy algorithm variants. To address this challenge, we extend the adaptive query model, recently proposed for the greedy forward selection for submodular functions, to the faster paradigm of Orthogonal Matching Pursuit for non-submodular functions. The proposed algorithm achieves exponentially fast parallel run time in the adaptive query model, scaling much better than prior work. Furthermore, our extension allows the use of downward-closed constraints, which can be used to encode certain fairness criteria into the feature selection process. We prove strong approximation guarantees for the algorithm based on standard assumptions. These guarantees are applicable to many parametric models, including Generalized Linear Models. Finally, we demonstrate empirically that the proposed algorithm competes favorably with state-of-the-art techniques for feature selection, on real-world and synthetic datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/quinzan23a/quinzan23a.pdf",
        "supp": "",
        "pdf_size": 8498763,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6144558457194124773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "KTH; Purdue; IBM Research; HPI; IBM Research; HPI; ICSI and UC Berkeley",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;2;3;4",
        "aff_unique_norm": "KTH Royal Institute of Technology;Purdue University;IBM;Hasso Plattner Institute;University of California, Berkeley",
        "aff_unique_dep": ";;IBM Research;;ICSI",
        "aff_unique_url": "https://www.kth.se;https://www.purdue.edu;https://www.ibm.com/research;https://www.hpi.de;https://www.berkeley.edu",
        "aff_unique_abbr": "KTH;Purdue;IBM;HPI;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;1;2;1;2;1",
        "aff_country_unique": "Sweden;United States;Germany"
    },
    {
        "id": "f72c784f68",
        "title": "Fast Variational Estimation of Mutual Information for Implicit and Explicit Likelihood Models",
        "site": "https://proceedings.mlr.press/v206/dahlke23a.html",
        "author": "Caleb Dahlke; Sue Zheng; Jason Pacheco",
        "abstract": "Computing mutual information (MI) of random variables lacks a closed-form in nontrivial models. Variational MI approximations are widely used as flexible estimators for this purpose, but computing them typically requires solving a costly nonconvex optimization. We prove that a widely used class of variational MI estimators can be solved via moment matching operations in place of the numerical optimization methods that are typically required. We show that the same moment matching solution yields variational estimates for so-called \u201cimplicit\u201d models that lack a closed form likelihood function. Furthermore, we demonstrate that this moment matching solution has multiple orders of magnitude computational speed up compared to the standard optimization based solutions. We show that theoretical results are supported by numerical evaluation in fully parameterized Gaussian mixture models and a generalized linear model with implicit likelihood due to nuisance variables. We also demonstrate on the implicit simulation-based likelihood SIR epidemiology model, where we avoid costly likelihood free inference and observe many orders of magnitude speedup.",
        "bibtex": "@InProceedings{pmlr-v206-dahlke23a,\n  title = \t {Fast Variational Estimation of Mutual Information for Implicit and Explicit Likelihood Models},\n  author =       {Dahlke, Caleb and Zheng, Sue and Pacheco, Jason},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10262--10278},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dahlke23a/dahlke23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dahlke23a.html},\n  abstract = \t {Computing mutual information (MI) of random variables lacks a closed-form in nontrivial models. Variational MI approximations are widely used as flexible estimators for this purpose, but computing them typically requires solving a costly nonconvex optimization. We prove that a widely used class of variational MI estimators can be solved via moment matching operations in place of the numerical optimization methods that are typically required. We show that the same moment matching solution yields variational estimates for so-called \u201cimplicit\u201d models that lack a closed form likelihood function. Furthermore, we demonstrate that this moment matching solution has multiple orders of magnitude computational speed up compared to the standard optimization based solutions. We show that theoretical results are supported by numerical evaluation in fully parameterized Gaussian mixture models and a generalized linear model with implicit likelihood due to nuisance variables. We also demonstrate on the implicit simulation-based likelihood SIR epidemiology model, where we avoid costly likelihood free inference and observe many orders of magnitude speedup.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dahlke23a/dahlke23a.pdf",
        "supp": "",
        "pdf_size": 1219903,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1891904346086265297&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "805736650f",
        "title": "Faster Projection-Free Augmented Lagrangian Methods via Weak Proximal Oracle",
        "site": "https://proceedings.mlr.press/v206/garber23a.html",
        "author": "Dan Garber; Tsur Livney; Shoham Sabach",
        "abstract": "This paper considers a convex composite optimization problem with affine constraints, which includes problems that take the form of minimizing a smooth convex objective function over the intersection of (simple) convex sets, or regularized with multiple (simple) functions. Motivated by high-dimensional applications in which exact projection/proximal computations are not tractable, we propose a projection-free augmented Lagrangian-based method, in which primal updates are carried out using a weak proximal oracle (WPO). In an earlier work, WPO was shown to be more powerful than the standard linear minimization oracle (LMO) that underlies conditional gradient-based methods (aka Frank-Wolfe methods). Moreover, WPO is computationally tractable for many high-dimensional problems of interest, including those motivated by recovery of low-rank matrices and tensors, and optimization over polytopes which admit efficient LMOs. The main result of this paper shows that under a certain curvature assumption (which is weaker than strong convexity), our WPO-based algorithm achieves an ergodic rate of convergence of $O(1/T)$ for both the objective residual and feasibility gap. This result, to the best of our knowledge, improves upon the $O(1/\\sqrt{T})$ rate for existing LMO-based projection-free methods for this class of problems. Empirical experiments on a low-rank and sparse covariance matrix estimation task and the Max Cut semidefinite relaxation demonstrate that of our method can outperform state-of-the-art LMO-based Lagrangian-based methods.",
        "bibtex": "@InProceedings{pmlr-v206-garber23a,\n  title = \t {Faster Projection-Free Augmented Lagrangian Methods via Weak Proximal Oracle},\n  author =       {Garber, Dan and Livney, Tsur and Sabach, Shoham},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7213--7238},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/garber23a/garber23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/garber23a.html},\n  abstract = \t {This paper considers a convex composite optimization problem with affine constraints, which includes problems that take the form of minimizing a smooth convex objective function over the intersection of (simple) convex sets, or regularized with multiple (simple) functions. Motivated by high-dimensional applications in which exact projection/proximal computations are not tractable, we propose a projection-free augmented Lagrangian-based method, in which primal updates are carried out using a weak proximal oracle (WPO). In an earlier work, WPO was shown to be more powerful than the standard linear minimization oracle (LMO) that underlies conditional gradient-based methods (aka Frank-Wolfe methods). Moreover, WPO is computationally tractable for many high-dimensional problems of interest, including those motivated by recovery of low-rank matrices and tensors, and optimization over polytopes which admit efficient LMOs. The main result of this paper shows that under a certain curvature assumption (which is weaker than strong convexity), our WPO-based algorithm achieves an ergodic rate of convergence of $O(1/T)$ for both the objective residual and feasibility gap. This result, to the best of our knowledge, improves upon the $O(1/\\sqrt{T})$ rate for existing LMO-based projection-free methods for this class of problems. Empirical experiments on a low-rank and sparse covariance matrix estimation task and the Max Cut semidefinite relaxation demonstrate that of our method can outperform state-of-the-art LMO-based Lagrangian-based methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/garber23a/garber23a.pdf",
        "supp": "",
        "pdf_size": 1024013,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=97926015573254045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b396ea0984",
        "title": "Feasible Recourse Plan via Diverse Interpolation",
        "site": "https://proceedings.mlr.press/v206/nguyen23b.html",
        "author": "Duy Nguyen; Ngoc Bui; Viet Anh Nguyen",
        "abstract": "Explaining algorithmic decisions and recommending actionable feedback is increasingly important for machine learning applications. Recently, significant efforts have been invested in finding a diverse set of recourses to cover the wide spectrum of users\u2019 preferences. However, existing works often neglect the requirement that the recourses should be close to the data manifold; hence, the constructed recourses might be implausible and unsatisfying to users. To address these issues, we propose a novel approach that explicitly directs the diverse set of actionable recourses towards the data manifold. We first find a diverse set of prototypes in the favorable class that balances the trade-off between diversity and proximity. We demonstrate two specific methods to find these prototypes: either by finding the maximum a posteriori estimate of a determinantal point process or by solving a quadratic binary program. To ensure the actionability constraints, we construct an actionability graph in which the nodes represent the training samples and the edges indicate the feasible action between two instances. We then find a feasible path to each prototype, and this path demonstrates the feasible actions for each recourse in the plan. The experimental results show that our method produces a set of recourses that are close to the data manifold while delivering a better cost-diversity trade-off than existing approaches.",
        "bibtex": "@InProceedings{pmlr-v206-nguyen23b,\n  title = \t {Feasible Recourse Plan via Diverse Interpolation},\n  author =       {Nguyen, Duy and Bui, Ngoc and Nguyen, Viet Anh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4679--4698},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nguyen23b/nguyen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nguyen23b.html},\n  abstract = \t {Explaining algorithmic decisions and recommending actionable feedback is increasingly important for machine learning applications. Recently, significant efforts have been invested in finding a diverse set of recourses to cover the wide spectrum of users\u2019 preferences. However, existing works often neglect the requirement that the recourses should be close to the data manifold; hence, the constructed recourses might be implausible and unsatisfying to users. To address these issues, we propose a novel approach that explicitly directs the diverse set of actionable recourses towards the data manifold. We first find a diverse set of prototypes in the favorable class that balances the trade-off between diversity and proximity. We demonstrate two specific methods to find these prototypes: either by finding the maximum a posteriori estimate of a determinantal point process or by solving a quadratic binary program. To ensure the actionability constraints, we construct an actionability graph in which the nodes represent the training samples and the edges indicate the feasible action between two instances. We then find a feasible path to each prototype, and this path demonstrates the feasible actions for each recourse in the plan. The experimental results show that our method produces a set of recourses that are close to the data manifold while delivering a better cost-diversity trade-off than existing approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nguyen23b/nguyen23b.pdf",
        "supp": "",
        "pdf_size": 1300745,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13619028580478559498&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1bb1de0a73",
        "title": "Federated Asymptotics: a model to compare federated learning algorithms",
        "site": "https://proceedings.mlr.press/v206/cheng23b.html",
        "author": "Gary Cheng; Karan Chadha; John Duchi",
        "abstract": "We develop an asymptotic framework to compare the test performance of (personalized) federated learning algorithms whose purpose is to move beyond algorithmic convergence arguments. To that end, we study a high-dimensional linear regression model to elucidate the statistical properties (per client test error) of loss minimizers. Our techniques and model allow precise predictions about the benefits of personalization and information sharing in federated scenarios, including that Federated Averaging with simple client fine-tuning achieves identical asymptotic risk to more intricate meta-learning approaches and outperforms naive Federated Averaging. We evaluate and corroborate these theoretical predictions on federated versions of the EMNIST, CIFAR-100, Shakespeare, and Stack Overflow datasets.",
        "bibtex": "@InProceedings{pmlr-v206-cheng23b,\n  title = \t {Federated Asymptotics: a model to compare federated learning algorithms},\n  author =       {Cheng, Gary and Chadha, Karan and Duchi, John},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10650--10689},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cheng23b/cheng23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cheng23b.html},\n  abstract = \t {We develop an asymptotic framework to compare the test performance of (personalized) federated learning algorithms whose purpose is to move beyond algorithmic convergence arguments. To that end, we study a high-dimensional linear regression model to elucidate the statistical properties (per client test error) of loss minimizers. Our techniques and model allow precise predictions about the benefits of personalization and information sharing in federated scenarios, including that Federated Averaging with simple client fine-tuning achieves identical asymptotic risk to more intricate meta-learning approaches and outperforms naive Federated Averaging. We evaluate and corroborate these theoretical predictions on federated versions of the EMNIST, CIFAR-100, Shakespeare, and Stack Overflow datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cheng23b/cheng23b.pdf",
        "supp": "",
        "pdf_size": 631802,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10257226143260848453&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9f4002caa7",
        "title": "Federated Averaging Langevin Dynamics: Toward a unified theory and new algorithms",
        "site": "https://proceedings.mlr.press/v206/plassier23a.html",
        "author": "Vincent Plassier; Eric Moulines; Alain Durmus",
        "abstract": "This paper focuses on Bayesian inference in a federated learning context (FL). While several distributed MCMC algorithms have been proposed, few consider the specific limitations of FL such as communication bottlenecks and statistical heterogeneity. Recently, Federated Averaging Langevin Dynamics (FALD) was introduced, which extends the Federated Averaging algorithm to Bayesian inference. We obtain a novel tight non-asymptotic upper bound on the Wasserstein distance to the global posterior for FALD. This bound highlights the effects of statistical heterogeneity, which causes a drift in the local updates that negatively impacts convergence. We propose a new algorithm VR-FALD* that uses control variates to correct the client drift. We establish non-asymptotic bounds showing that VR-FALD* is not affected by statistical heterogeneity. Finally, we illustrate our results on several FL benchmarks for Bayesian inference.",
        "bibtex": "@InProceedings{pmlr-v206-plassier23a,\n  title = \t {Federated Averaging Langevin Dynamics: Toward a unified theory and new algorithms},\n  author =       {Plassier, Vincent and Moulines, Eric and Durmus, Alain},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5299--5356},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/plassier23a/plassier23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/plassier23a.html},\n  abstract = \t {This paper focuses on Bayesian inference in a federated learning context (FL). While several distributed MCMC algorithms have been proposed, few consider the specific limitations of FL such as communication bottlenecks and statistical heterogeneity. Recently, Federated Averaging Langevin Dynamics (FALD) was introduced, which extends the Federated Averaging algorithm to Bayesian inference. We obtain a novel tight non-asymptotic upper bound on the Wasserstein distance to the global posterior for FALD. This bound highlights the effects of statistical heterogeneity, which causes a drift in the local updates that negatively impacts convergence. We propose a new algorithm VR-FALD* that uses control variates to correct the client drift. We establish non-asymptotic bounds showing that VR-FALD* is not affected by statistical heterogeneity. Finally, we illustrate our results on several FL benchmarks for Bayesian inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/plassier23a/plassier23a.pdf",
        "supp": "",
        "pdf_size": 1355164,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15134080025470224490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c89aedd3c7",
        "title": "Federated Learning for Data Streams",
        "site": "https://proceedings.mlr.press/v206/marfoq23a.html",
        "author": "Othmane Marfoq; Giovanni Neglia; Laetitia Kameni; Richard Vidal",
        "abstract": "Federated learning (FL) is an effective solution to train machine learning models on the increasing amount of data generated by IoT devices and smartphones while keeping such data localized. Most previous work on federated learning assumes that clients operate on static datasets collected before training starts. This approach may be inefficient because 1) it ignores new samples clients collect during training, and 2) it may require a potentially long preparatory phase for clients to collect enough data. Moreover, learning on static datasets may be simply impossible in scenarios with small aggregate storage across devices. It is, therefore, necessary to design federated algorithms able to learn from data streams. In this work, we formulate and study the problem of federated learning for data streams. We propose a general FL algorithm to learn from data streams through an opportune weighted empirical risk minimization. Our theoretical analysis provides insights to configure such an algorithm, and we evaluate its performance on a wide range of machine learning tasks.",
        "bibtex": "@InProceedings{pmlr-v206-marfoq23a,\n  title = \t {Federated Learning for Data Streams},\n  author =       {Marfoq, Othmane and Neglia, Giovanni and Kameni, Laetitia and Vidal, Richard},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8889--8924},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/marfoq23a/marfoq23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/marfoq23a.html},\n  abstract = \t {Federated learning (FL) is an effective solution to train machine learning models on the increasing amount of data generated by IoT devices and smartphones while keeping such data localized. Most previous work on federated learning assumes that clients operate on static datasets collected before training starts. This approach may be inefficient because 1) it ignores new samples clients collect during training, and 2) it may require a potentially long preparatory phase for clients to collect enough data. Moreover, learning on static datasets may be simply impossible in scenarios with small aggregate storage across devices. It is, therefore, necessary to design federated algorithms able to learn from data streams. In this work, we formulate and study the problem of federated learning for data streams. We propose a general FL algorithm to learn from data streams through an opportune weighted empirical risk minimization. Our theoretical analysis provides insights to configure such an algorithm, and we evaluate its performance on a wide range of machine learning tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/marfoq23a/marfoq23a.pdf",
        "supp": "",
        "pdf_size": 1370718,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7232116939503829966&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0abd70fa89",
        "title": "Federated Learning under Distributed Concept Drift",
        "site": "https://proceedings.mlr.press/v206/jothimurugesan23a.html",
        "author": "Ellango Jothimurugesan; Kevin Hsieh; Jianyu Wang; Gauri Joshi; Phillip B. Gibbons",
        "abstract": "Federated Learning (FL) under distributed concept drift is a largely unexplored area. Although concept drift is itself a well-studied phenomenon, it poses particular challenges for FL, because drifts arise staggered in time and space (across clients). Our work is the first to explicitly study data heterogeneity in both dimensions. We first demonstrate that prior solutions to drift adaptation, with their single global model, are ill-suited to staggered drifts, necessitating multiple-model solutions. We identify the problem of drift adaptation as a time-varying clustering problem, and we propose two new clustering algorithms for reacting to drifts based on local drift detection and hierarchical clustering. Empirical evaluation shows that our solutions achieve significantly higher accuracy than existing baselines, and are comparable to an idealized algorithm with oracle knowledge of the ground-truth clustering of clients to concepts at each time step.",
        "bibtex": "@InProceedings{pmlr-v206-jothimurugesan23a,\n  title = \t {Federated Learning under Distributed Concept Drift},\n  author =       {Jothimurugesan, Ellango and Hsieh, Kevin and Wang, Jianyu and Joshi, Gauri and Gibbons, Phillip B.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5834--5853},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jothimurugesan23a/jothimurugesan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jothimurugesan23a.html},\n  abstract = \t {Federated Learning (FL) under distributed concept drift is a largely unexplored area. Although concept drift is itself a well-studied phenomenon, it poses particular challenges for FL, because drifts arise staggered in time and space (across clients). Our work is the first to explicitly study data heterogeneity in both dimensions. We first demonstrate that prior solutions to drift adaptation, with their single global model, are ill-suited to staggered drifts, necessitating multiple-model solutions. We identify the problem of drift adaptation as a time-varying clustering problem, and we propose two new clustering algorithms for reacting to drifts based on local drift detection and hierarchical clustering. Empirical evaluation shows that our solutions achieve significantly higher accuracy than existing baselines, and are comparable to an idealized algorithm with oracle knowledge of the ground-truth clustering of clients to concepts at each time step.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jothimurugesan23a/jothimurugesan23a.pdf",
        "supp": "",
        "pdf_size": 2058718,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6913692799698863516&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Carnegie Mellon University; Microsoft Research; Carnegie Mellon University + Apple; Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Microsoft;Apple",
        "aff_unique_dep": ";Microsoft Research;Apple Inc.",
        "aff_unique_url": "https://www.cmu.edu;https://www.microsoft.com/en-us/research;https://www.apple.com",
        "aff_unique_abbr": "CMU;MSR;Apple",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "420c9860a4",
        "title": "Finding Regularized Competitive Equilibria of Heterogeneous Agent Macroeconomic Models via Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/xu23a.html",
        "author": "Ruitu Xu; Yifei Min; Tianhao Wang; Michael I. Jordan; Zhaoran Wang; Zhuoran Yang",
        "abstract": "We study a heterogeneous agent macroeconomic model with an infinite number of households and firms competing in a labor market. Each household earns income and engages in consumption at each time step while aiming to maximize a concave utility subject to the underlying market conditions. The households aim to find the optimal saving strategy that maximizes their discounted cumulative utility given the market condition, while the firms determine the market conditions through maximizing corporate profit based on the household population behavior. The model captures a wide range of applications in macroeconomic studies, and we propose a data-driven reinforcement learning framework that finds the regularized competitive equilibrium of the model. The proposed algorithm enjoys theoretical guarantees in converging to the equilibrium of the market at a sub-linear rate.",
        "bibtex": "@InProceedings{pmlr-v206-xu23a,\n  title = \t {Finding Regularized Competitive Equilibria of Heterogeneous Agent Macroeconomic Models via Reinforcement Learning},\n  author =       {Xu, Ruitu and Min, Yifei and Wang, Tianhao and Jordan, Michael I. and Wang, Zhaoran and Yang, Zhuoran},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {375--407},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23a/xu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23a.html},\n  abstract = \t {We study a heterogeneous agent macroeconomic model with an infinite number of households and firms competing in a labor market. Each household earns income and engages in consumption at each time step while aiming to maximize a concave utility subject to the underlying market conditions. The households aim to find the optimal saving strategy that maximizes their discounted cumulative utility given the market condition, while the firms determine the market conditions through maximizing corporate profit based on the household population behavior. The model captures a wide range of applications in macroeconomic studies, and we propose a data-driven reinforcement learning framework that finds the regularized competitive equilibrium of the model. The proposed algorithm enjoys theoretical guarantees in converging to the equilibrium of the market at a sub-linear rate.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23a/xu23a.pdf",
        "supp": "",
        "pdf_size": 1644226,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4041843026906874955&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d694c77670",
        "title": "Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation",
        "site": "https://proceedings.mlr.press/v206/patil23a.html",
        "author": "Gandharv Patil; Prashanth L.A.; Dheeraj Nagaraj; Doina Precup",
        "abstract": "We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm, when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal O (1/t) rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation, and show that this variant fares favourably in problems with ill-conditioned features.",
        "bibtex": "@InProceedings{pmlr-v206-patil23a,\n  title = \t {Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation},\n  author =       {Patil, Gandharv and L.A., Prashanth and Nagaraj, Dheeraj and Precup, Doina},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5438--5448},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/patil23a/patil23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/patil23a.html},\n  abstract = \t {We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm, when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal O (1/t) rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation, and show that this variant fares favourably in problems with ill-conditioned features.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/patil23a/patil23a.pdf",
        "supp": "",
        "pdf_size": 326470,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9553865142009490713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9dd0663e68",
        "title": "Fitting low-rank models on egocentrically sampled partial networks",
        "site": "https://proceedings.mlr.press/v206/angus-chan23a.html",
        "author": "Ga Ming Angus Chan; Tianxi Li",
        "abstract": "The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of \u201cuniformly missing at random\u201d, egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric sampling for sparse networks. To our knowledge, this method offers the first theoretical guarantee for egocentric partial network estimation in the scope of low-rank models. We evaluate the technique on several synthetic and real-world networks and show that it delivers competitive performance in link prediction tasks.",
        "bibtex": "@InProceedings{pmlr-v206-angus-chan23a,\n  title = \t {Fitting low-rank models on egocentrically sampled partial networks},\n  author =       {Angus Chan, Ga Ming and Li, Tianxi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10635--10649},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/angus-chan23a/angus-chan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/angus-chan23a.html},\n  abstract = \t {The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of \u201cuniformly missing at random\u201d, egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric sampling for sparse networks. To our knowledge, this method offers the first theoretical guarantee for egocentric partial network estimation in the scope of low-rank models. We evaluate the technique on several synthetic and real-world networks and show that it delivers competitive performance in link prediction tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/angus-chan23a/angus-chan23a.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11760652276452280899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e9f4075f39",
        "title": "Fix-A-Step: Semi-supervised Learning From Uncurated Unlabeled Data",
        "site": "https://proceedings.mlr.press/v206/huang23c.html",
        "author": "Zhe Huang; Mary-Joy Sidhom; Benjamin Wessler; Michael C. Hughes",
        "abstract": "Semi-supervised learning (SSL) promises improved accuracy compared to training classifiers on small labeled datasets by also training on many unlabeled images. In real applications like medical imaging, unlabeled data will be collected for expediency and thus uncurated: possibly different from the labeled set in classes or features. Unfortunately, modern deep SSL often makes accuracy worse when given uncurated unlabeled data. Recent complex remedies try to detect out-of-distribution unlabeled images and then discard or downweight them. Instead, we introduce Fix-A-Step, a simpler procedure that views all uncurated unlabeled images as potentially helpful. Our first insight is that even uncurated images can yield useful augmentations of labeled data. Second, we modify gradient descent updates to prevent optimizing a multi-task SSL loss from hurting labeled-set accuracy. Fix-A-Step can \u201crepair\u201d many common deep SSL methods, improving accuracy on CIFAR benchmarks across all tested methods and levels of artificial class mismatch. On a new medical SSL benchmark called Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated ultrasound images to deliver gains that generalize across hospitals.",
        "bibtex": "@InProceedings{pmlr-v206-huang23c,\n  title = \t {Fix-A-Step: Semi-supervised Learning From Uncurated Unlabeled Data},\n  author =       {Huang, Zhe and Sidhom, Mary-Joy and Wessler, Benjamin and Hughes, Michael C.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8373--8394},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/huang23c/huang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/huang23c.html},\n  abstract = \t {Semi-supervised learning (SSL) promises improved accuracy compared to training classifiers on small labeled datasets by also training on many unlabeled images. In real applications like medical imaging, unlabeled data will be collected for expediency and thus uncurated: possibly different from the labeled set in classes or features. Unfortunately, modern deep SSL often makes accuracy worse when given uncurated unlabeled data. Recent complex remedies try to detect out-of-distribution unlabeled images and then discard or downweight them. Instead, we introduce Fix-A-Step, a simpler procedure that views all uncurated unlabeled images as potentially helpful. Our first insight is that even uncurated images can yield useful augmentations of labeled data. Second, we modify gradient descent updates to prevent optimizing a multi-task SSL loss from hurting labeled-set accuracy. Fix-A-Step can \u201crepair\u201d many common deep SSL methods, improving accuracy on CIFAR benchmarks across all tested methods and levels of artificial class mismatch. On a new medical SSL benchmark called Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated ultrasound images to deliver gains that generalize across hospitals.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/huang23c/huang23c.pdf",
        "supp": "",
        "pdf_size": 8090318,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5123490025940306145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6dc12678fe",
        "title": "Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity",
        "site": "https://proceedings.mlr.press/v206/allouah23a.html",
        "author": "Youssef Allouah; Sadegh Farhadkhani; Rachid Guerraoui; Nirupam Gupta; Rafael Pinot; John Stephan",
        "abstract": "Byzantine machine learning (ML) aims to ensure the resilience of distributed learning algorithms to misbehaving (or Byzantine) machines. Although this problem received significant attention, prior works often assume the data held by the machines to be homogeneous, which is seldom true in practical settings. Data heterogeneity makes Byzantine ML considerably more challenging, since a Byzantine machine can hardly be distinguished from a non-Byzantine outlier. A few solutions have been proposed to tackle this issue, but these provide suboptimal probabilistic guarantees and fare poorly in practice. This paper closes the theoretical gap, achieving optimality and inducing good empirical results. In fact, we show how to automatically adapt existing solutions for (homogeneous) Byzantine ML to the heterogeneous setting through a powerful mechanism, we call nearest neighbor mixing (NNM), which boosts any standard robust distributed gradient descent variant to yield optimal Byzantine resilience under heterogeneity. We obtain similar guarantees (in expectation) by plugging NNM in the distributed stochastic heavy ball method, a practical substitute to distributed gradient descent. We obtain empirical results that significantly outperform state-of-the-art Byzantine ML solutions.",
        "bibtex": "@InProceedings{pmlr-v206-allouah23a,\n  title = \t {Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity},\n  author =       {Allouah, Youssef and Farhadkhani, Sadegh and Guerraoui, Rachid and Gupta, Nirupam and Pinot, Rafael and Stephan, John},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1232--1300},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/allouah23a/allouah23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/allouah23a.html},\n  abstract = \t {Byzantine machine learning (ML) aims to ensure the resilience of distributed learning algorithms to misbehaving (or Byzantine) machines. Although this problem received significant attention, prior works often assume the data held by the machines to be homogeneous, which is seldom true in practical settings. Data heterogeneity makes Byzantine ML considerably more challenging, since a Byzantine machine can hardly be distinguished from a non-Byzantine outlier. A few solutions have been proposed to tackle this issue, but these provide suboptimal probabilistic guarantees and fare poorly in practice. This paper closes the theoretical gap, achieving optimality and inducing good empirical results. In fact, we show how to automatically adapt existing solutions for (homogeneous) Byzantine ML to the heterogeneous setting through a powerful mechanism, we call nearest neighbor mixing (NNM), which boosts any standard robust distributed gradient descent variant to yield optimal Byzantine resilience under heterogeneity. We obtain similar guarantees (in expectation) by plugging NNM in the distributed stochastic heavy ball method, a practical substitute to distributed gradient descent. We obtain empirical results that significantly outperform state-of-the-art Byzantine ML solutions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/allouah23a/allouah23a.pdf",
        "supp": "",
        "pdf_size": 5014693,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14688449440230896564&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL); Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL); Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL); Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL); Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL); Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL)",
        "aff_domain": "epfl.ch; ; ; ; ; ",
        "email": "epfl.ch; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "da49dfde8b",
        "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment Effect Oracles",
        "site": "https://proceedings.mlr.press/v206/carranza23a.html",
        "author": "Aldo Gael Carranza; Sanath Kumar Krishnamurthy; Susan Athey",
        "abstract": "Contextual bandit algorithms often estimate reward models to inform decision-making. However, true rewards can contain action-independent redundancies that are not relevant for decision-making. We show it is more data-efficient to estimate any function that explains the reward differences between actions, that is, the treatment effects. Motivated by this observation, building on recent work on oracle-based bandit algorithms, we provide the first reduction of contextual bandits to general-purpose heterogeneous treatment effect estimation, and we design a simple and computationally efficient algorithm based on this reduction. Our theoretical and experimental results demonstrate that heterogeneous treatment effect estimation in contextual bandits offers practical advantages over reward estimation including more efficient model estimation and greater flexibility to model misspecification.",
        "bibtex": "@InProceedings{pmlr-v206-carranza23a,\n  title = \t {Flexible and Efficient Contextual Bandits with Heterogeneous Treatment Effect Oracles},\n  author =       {Carranza, Aldo Gael and Krishnamurthy, Sanath Kumar and Athey, Susan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7190--7212},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/carranza23a/carranza23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/carranza23a.html},\n  abstract = \t {Contextual bandit algorithms often estimate reward models to inform decision-making. However, true rewards can contain action-independent redundancies that are not relevant for decision-making. We show it is more data-efficient to estimate any function that explains the reward differences between actions, that is, the treatment effects. Motivated by this observation, building on recent work on oracle-based bandit algorithms, we provide the first reduction of contextual bandits to general-purpose heterogeneous treatment effect estimation, and we design a simple and computationally efficient algorithm based on this reduction. Our theoretical and experimental results demonstrate that heterogeneous treatment effect estimation in contextual bandits offers practical advantages over reward estimation including more efficient model estimation and greater flexibility to model misspecification.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/carranza23a/carranza23a.pdf",
        "supp": "",
        "pdf_size": 1354643,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13783690950205610452&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c584ba1cf",
        "title": "Flexible risk design using bi-directional dispersion",
        "site": "https://proceedings.mlr.press/v206/holland23a.html",
        "author": "Matthew J. Holland",
        "abstract": "Many novel notions of \u201crisk\u201d (e.g., CVaR, tilted risk, DRO risk) have been proposed and studied, but these risks are all at least as sensitive as the mean to loss tails on the upside, and tend to ignore deviations on the downside. We study a complementary new risk class that penalizes loss deviations in a bi-directional manner, while having more flexibility in terms of tail sensitivity than is offered by mean-variance. This class lets us derive high-probability learning guarantees without explicit gradient clipping, and empirical tests using both simulated and real data illustrate a high degree of control over key properties of the test loss distribution of gradient-based learners.",
        "bibtex": "@InProceedings{pmlr-v206-holland23a,\n  title = \t {Flexible risk design using bi-directional dispersion},\n  author =       {Holland, Matthew J.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1586--1623},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/holland23a/holland23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/holland23a.html},\n  abstract = \t {Many novel notions of \u201crisk\u201d (e.g., CVaR, tilted risk, DRO risk) have been proposed and studied, but these risks are all at least as sensitive as the mean to loss tails on the upside, and tend to ignore deviations on the downside. We study a complementary new risk class that penalizes loss deviations in a bi-directional manner, while having more flexibility in terms of tail sensitivity than is offered by mean-variance. This class lets us derive high-probability learning guarantees without explicit gradient clipping, and empirical tests using both simulated and real data illustrate a high degree of control over key properties of the test loss distribution of gradient-based learners.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/holland23a/holland23a.pdf",
        "supp": "",
        "pdf_size": 926595,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6256393935982750223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Osaka University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "332bf745fe",
        "title": "ForestPrune: Compact Depth-Pruned Tree Ensembles",
        "site": "https://proceedings.mlr.press/v206/liu23h.html",
        "author": "Brian Liu; Rahul Mazumder",
        "abstract": "Tree ensembles are powerful models that achieve excellent predictive performances, but can grow to unwieldy sizes. These ensembles are often post-processed (pruned) to reduce memory footprint and improve interpretability. We present ForestPrune, a novel optimization framework to post-process tree ensembles by pruning depth layers from individual trees. Since the number of nodes in a decision tree increases exponentially with tree depth, pruning deep trees drastically compactifies ensembles. We develop a specialized optimization algorithm to efficiently obtain high-quality solutions to problems under ForestPrune. Our algorithm typically reaches good solutions in seconds for medium-size datasets and ensembles, with 10000s of rows and 100s of trees, resulting in significant speedups over existing approaches. Our experiments demonstrate that ForestPrune produces parsimonious models that outperform models extracted by existing post-processing algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-liu23h,\n  title = \t {ForestPrune: Compact Depth-Pruned Tree Ensembles},\n  author =       {Liu, Brian and Mazumder, Rahul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9417--9428},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23h/liu23h.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23h.html},\n  abstract = \t {Tree ensembles are powerful models that achieve excellent predictive performances, but can grow to unwieldy sizes. These ensembles are often post-processed (pruned) to reduce memory footprint and improve interpretability. We present ForestPrune, a novel optimization framework to post-process tree ensembles by pruning depth layers from individual trees. Since the number of nodes in a decision tree increases exponentially with tree depth, pruning deep trees drastically compactifies ensembles. We develop a specialized optimization algorithm to efficiently obtain high-quality solutions to problems under ForestPrune. Our algorithm typically reaches good solutions in seconds for medium-size datasets and ensembles, with 10000s of rows and 100s of trees, resulting in significant speedups over existing approaches. Our experiments demonstrate that ForestPrune produces parsimonious models that outperform models extracted by existing post-processing algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23h/liu23h.pdf",
        "supp": "",
        "pdf_size": 701632,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14139263435992931347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Operations Research Center, MITSloan School of Management & Operations Research Center, MIT; Operations Research Center, MITSloan School of Management & Operations Research Center, MIT",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/brianliu12437/ForestPruneAISTATS2023",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Operations Research Center, Sloan School of Management",
        "aff_unique_url": "https://web.mit.edu/",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "38035149f1",
        "title": "Freeze then Train: Towards Provable Representation Learning under Spurious Correlations and Feature Noise",
        "site": "https://proceedings.mlr.press/v206/ye23a.html",
        "author": "Haotian Ye; James Zou; Linjun Zhang",
        "abstract": "The existence of spurious correlations such as image backgrounds in the training environment can make empirical risk minimization (ERM) perform badly in the test environment. To address this problem, Kirichenko et al. (2022) empirically found that the core features that are related to the outcome can still be learned well even with the presence of spurious correlations. This opens a promising strategy to first train a feature learner rather than a classifier, and then perform linear probing (last layer retraining) in the test environment. However, a theoretical understanding of when and why this approach works is lacking. In this paper, we find that core features are only learned well when their associated non-realizable noise is smaller than that of spurious features, which is not necessarily true in practice. We provide both theories and experiments to support this finding and to illustrate the importance of non-realizable noise. Moreover, we propose an algorithm called Freeze then Train (FTT), that first freezes certain salient features and then trains the rest of the features using ERM. We theoretically show that FTT preserves features that are more beneficial to test time probing. Across two commonly used spurious correlation datasets, FTT outperforms ERM, IRM, JTT and CVaR-DRO, with substantial improvement in accuracy (by 4.5$%$) when the feature noise is large. FTT also performs better on general distribution shift benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-ye23a,\n  title = \t {Freeze then Train: Towards Provable Representation Learning under Spurious Correlations and Feature Noise},\n  author =       {Ye, Haotian and Zou, James and Zhang, Linjun},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8968--8990},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ye23a/ye23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ye23a.html},\n  abstract = \t {The existence of spurious correlations such as image backgrounds in the training environment can make empirical risk minimization (ERM) perform badly in the test environment. To address this problem, Kirichenko et al. (2022) empirically found that the core features that are related to the outcome can still be learned well even with the presence of spurious correlations. This opens a promising strategy to first train a feature learner rather than a classifier, and then perform linear probing (last layer retraining) in the test environment. However, a theoretical understanding of when and why this approach works is lacking. In this paper, we find that core features are only learned well when their associated non-realizable noise is smaller than that of spurious features, which is not necessarily true in practice. We provide both theories and experiments to support this finding and to illustrate the importance of non-realizable noise. Moreover, we propose an algorithm called Freeze then Train (FTT), that first freezes certain salient features and then trains the rest of the features using ERM. We theoretically show that FTT preserves features that are more beneficial to test time probing. Across two commonly used spurious correlation datasets, FTT outperforms ERM, IRM, JTT and CVaR-DRO, with substantial improvement in accuracy (by 4.5$%$) when the feature noise is large. FTT also performs better on general distribution shift benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ye23a/ye23a.pdf",
        "supp": "",
        "pdf_size": 1043884,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=487799980057591544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Peking University; Stanford University; Rutgers University",
        "aff_domain": "pku.edu.cn;stanford.edu;rutgers.edu",
        "email": "pku.edu.cn;stanford.edu;rutgers.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Peking University;Stanford University;Rutgers University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.stanford.edu;https://www.rutgers.edu",
        "aff_unique_abbr": "Peking U;Stanford;Rutgers",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "e5db3446be",
        "title": "Frequentist Uncertainty Quantification in Semi-Structured Neural Networks",
        "site": "https://proceedings.mlr.press/v206/dorigatti23a.html",
        "author": "Emilio Dorigatti; Benjamin Schubert; Bernd Bischl; David Ruegamer",
        "abstract": "Semi-structured regression (SSR) models jointly learn the effect of structured (tabular) and unstructured (non-tabular) data through additive predictors and deep neural networks (DNNs), respectively. Inference in SSR models aims at deriving confidence intervals for the structured predictor, although current approaches ignore the variance of the DNN estimation of the unstructured effects. This results in an underestimation of the variance of the structured coefficients and, thus, an increase of Type-I error rates. To address this shortcoming, we present here a theoretical framework for structured inference in SSR models that incorporates the variance of the DNN estimate into confidence intervals for the structured predictor. By treating this estimate as a random offset with known variance, our formulation is agnostic to the specific deep uncertainty quantification method employed. Through numerical experiments and a practical application on a medical dataset, we show that our approach results in increased coverage of the true structured coefficients and thus a reduction in Type-I error rate compared to ignoring the variance of the neural network, naive ensembling of SSR models, and a variational inference baseline.",
        "bibtex": "@InProceedings{pmlr-v206-dorigatti23a,\n  title = \t {Frequentist Uncertainty Quantification in Semi-Structured Neural Networks},\n  author =       {Dorigatti, Emilio and Schubert, Benjamin and Bischl, Bernd and Ruegamer, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1924--1941},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dorigatti23a/dorigatti23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dorigatti23a.html},\n  abstract = \t {Semi-structured regression (SSR) models jointly learn the effect of structured (tabular) and unstructured (non-tabular) data through additive predictors and deep neural networks (DNNs), respectively. Inference in SSR models aims at deriving confidence intervals for the structured predictor, although current approaches ignore the variance of the DNN estimation of the unstructured effects. This results in an underestimation of the variance of the structured coefficients and, thus, an increase of Type-I error rates. To address this shortcoming, we present here a theoretical framework for structured inference in SSR models that incorporates the variance of the DNN estimate into confidence intervals for the structured predictor. By treating this estimate as a random offset with known variance, our formulation is agnostic to the specific deep uncertainty quantification method employed. Through numerical experiments and a practical application on a medical dataset, we show that our approach results in increased coverage of the true structured coefficients and thus a reduction in Type-I error rate compared to ignoring the variance of the neural network, naive ensembling of SSR models, and a variational inference baseline.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dorigatti23a/dorigatti23a.pdf",
        "supp": "",
        "pdf_size": 500038,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3955672962147246571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1b5ea12d49",
        "title": "From Shapley Values to Generalized Additive Models and back",
        "site": "https://proceedings.mlr.press/v206/bordt23a.html",
        "author": "Sebastian Bordt; Ulrike von Luxburg",
        "abstract": "In explainable machine learning, local post-hoc explanation algorithms and inherently interpretable models are often seen as competing approaches. This work offers a partial reconciliation between the two by establishing a correspondence between Shapley Values and Generalized Additive Models (GAMs). We introduce $n$-Shapley Values, a parametric family of local post-hoc explanation algorithms that explain individual predictions with interaction terms up to order $n$. By varying the parameter $n$, we obtain a sequence of explanations that covers the entire range from Shapley Values up to a uniquely determined decomposition of the function we want to explain. The relationship between $n$-Shapley Values and this decomposition offers a functionally-grounded characterization of Shapley Values, which highlights their limitations. We then show that $n$-Shapley Values, as well as the Shapley Taylor- and Faith-Shap interaction indices, recover GAMs with interaction terms up to order $n$. This implies that the original Shapely Values recover GAMs without variable interactions. Taken together, our results provide a precise characterization of Shapley Values as they are being used in explainable machine learning. They also offer a principled interpretation of partial dependence plots of Shapley Values in terms of the underlying functional decomposition. A package for the estimation of different interaction indices is available at https://github.com/tml-tuebingen/nshap.",
        "bibtex": "@InProceedings{pmlr-v206-bordt23a,\n  title = \t {From Shapley Values to Generalized Additive Models and back},\n  author =       {Bordt, Sebastian and von Luxburg, Ulrike},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {709--745},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bordt23a/bordt23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bordt23a.html},\n  abstract = \t {In explainable machine learning, local post-hoc explanation algorithms and inherently interpretable models are often seen as competing approaches. This work offers a partial reconciliation between the two by establishing a correspondence between Shapley Values and Generalized Additive Models (GAMs). We introduce $n$-Shapley Values, a parametric family of local post-hoc explanation algorithms that explain individual predictions with interaction terms up to order $n$. By varying the parameter $n$, we obtain a sequence of explanations that covers the entire range from Shapley Values up to a uniquely determined decomposition of the function we want to explain. The relationship between $n$-Shapley Values and this decomposition offers a functionally-grounded characterization of Shapley Values, which highlights their limitations. We then show that $n$-Shapley Values, as well as the Shapley Taylor- and Faith-Shap interaction indices, recover GAMs with interaction terms up to order $n$. This implies that the original Shapely Values recover GAMs without variable interactions. Taken together, our results provide a precise characterization of Shapley Values as they are being used in explainable machine learning. They also offer a principled interpretation of partial dependence plots of Shapley Values in terms of the underlying functional decomposition. A package for the estimation of different interaction indices is available at https://github.com/tml-tuebingen/nshap.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bordt23a/bordt23a.pdf",
        "supp": "",
        "pdf_size": 6386173,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3896353546669996591&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of T\u00fcbingen; Department of Computer Science and T\u00fcbingen AI Center, University of T\u00fcbingen",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/tml-tuebingen/nshap",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "dff04beb24",
        "title": "Further Adaptive Best-of-Both-Worlds Algorithm for Combinatorial Semi-Bandits",
        "site": "https://proceedings.mlr.press/v206/tsuchiya23a.html",
        "author": "Taira Tsuchiya; Shinji Ito; Junya Honda",
        "abstract": "We consider the combinatorial semi-bandit problem and present a new algorithm with a best-of-both-worlds regret guarantee; the regrets are bounded near-optimally in the stochastic and adversarial regimes. In the stochastic regime, we prove a variance-dependent regret bound depending on the tight suboptimality gap introduced by Kveton et al. (2015) with a good leading constant. In the adversarial regime, we show that the same algorithm simultaneously obtains various data-dependent regret bounds. Our algorithm is based on the follow-the-regularized-leader framework with a refined regularizer and adaptive learning rate. Finally, we numerically test the proposed algorithm and confirm its superior or competitive performance over existing algorithms, including Thompson sampling under most settings.",
        "bibtex": "@InProceedings{pmlr-v206-tsuchiya23a,\n  title = \t {Further Adaptive Best-of-Both-Worlds Algorithm for Combinatorial Semi-Bandits},\n  author =       {Tsuchiya, Taira and Ito, Shinji and Honda, Junya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8117--8144},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tsuchiya23a/tsuchiya23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tsuchiya23a.html},\n  abstract = \t {We consider the combinatorial semi-bandit problem and present a new algorithm with a best-of-both-worlds regret guarantee; the regrets are bounded near-optimally in the stochastic and adversarial regimes. In the stochastic regime, we prove a variance-dependent regret bound depending on the tight suboptimality gap introduced by Kveton et al. (2015) with a good leading constant. In the adversarial regime, we show that the same algorithm simultaneously obtains various data-dependent regret bounds. Our algorithm is based on the follow-the-regularized-leader framework with a refined regularizer and adaptive learning rate. Finally, we numerically test the proposed algorithm and confirm its superior or competitive performance over existing algorithms, including Thompson sampling under most settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tsuchiya23a/tsuchiya23a.pdf",
        "supp": "",
        "pdf_size": 1242617,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9975210363728426480&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a70c468c8b",
        "title": "Gaussian Processes on Distributions based on Regularized Optimal Transport",
        "site": "https://proceedings.mlr.press/v206/bachoc23a.html",
        "author": "Fran\u00e7ois Bachoc; Louis B\u00e9thune; Alberto Gonzalez-Sanz; Jean-Michel Loubes",
        "abstract": "We present a novel kernel over the space of probability measures based on the dual formulation of optimal regularized transport. We propose an Hilbertian embedding of the space of probabilities using their Sinkhorn potentials, which are solutions of the dual entropic relaxed optimal transport between the probabilities and a reference measure $\\mathcal{U}$. We prove that this construction enables to obtain a valid kernel, by using the Hilbert norms. We prove that the kernel enjoys theoretical properties such as universality and some invariances, while still being computationally feasible. Moreover we provide theoretical guarantees on the behaviour of a Gaussian process based on this kernel. The empirical performances are compared with other traditional choices of kernels for processes indexed on distributions.",
        "bibtex": "@InProceedings{pmlr-v206-bachoc23a,\n  title = \t {Gaussian Processes on Distributions based on Regularized Optimal Transport},\n  author =       {Bachoc, Fran\\c{c}ois and B\\'ethune, Louis and Gonzalez-Sanz, Alberto and Loubes, Jean-Michel},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4986--5010},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bachoc23a/bachoc23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bachoc23a.html},\n  abstract = \t {We present a novel kernel over the space of probability measures based on the dual formulation of optimal regularized transport. We propose an Hilbertian embedding of the space of probabilities using their Sinkhorn potentials, which are solutions of the dual entropic relaxed optimal transport between the probabilities and a reference measure $\\mathcal{U}$. We prove that this construction enables to obtain a valid kernel, by using the Hilbert norms. We prove that the kernel enjoys theoretical properties such as universality and some invariances, while still being computationally feasible. Moreover we provide theoretical guarantees on the behaviour of a Gaussian process based on this kernel. The empirical performances are compared with other traditional choices of kernels for processes indexed on distributions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bachoc23a/bachoc23a.pdf",
        "supp": "",
        "pdf_size": 1488351,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11802007471416411146&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c313263340",
        "title": "Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion",
        "site": "https://proceedings.mlr.press/v206/ju23a.html",
        "author": "Haotian Ju; Dongyue Li; Aneesh Sharma; Hongyang R. Zhang",
        "abstract": "Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network\u2019s feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works\u2019 settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with observed generalization gaps of graph neural networks accurately; Optimizing noise stability properties for fine-tuning pretrained graph neural networks also improves the test performance on several graph-level classification tasks.",
        "bibtex": "@InProceedings{pmlr-v206-ju23a,\n  title = \t {Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion},\n  author =       {Ju, Haotian and Li, Dongyue and Sharma, Aneesh and Zhang, Hongyang R.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6314--6341},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ju23a/ju23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ju23a.html},\n  abstract = \t {Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network\u2019s feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works\u2019 settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with observed generalization gaps of graph neural networks accurately; Optimizing noise stability properties for fine-tuning pretrained graph neural networks also improves the test performance on several graph-level classification tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ju23a/ju23a.pdf",
        "supp": "",
        "pdf_size": 679845,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8383412820362043029&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Northeastern University; Northeastern University; Google; Northeastern University",
        "aff_domain": "northeastern.edu;northeastern.edu;google.com;northeastern.edu",
        "email": "northeastern.edu;northeastern.edu;google.com;northeastern.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Northeastern University;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.northeastern.edu;https://www.google.com",
        "aff_unique_abbr": "NEU;Google",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bc4ecd714e",
        "title": "Generalized PTR: User-Friendly Recipes for Data-Adaptive Algorithms with Differential Privacy",
        "site": "https://proceedings.mlr.press/v206/redberg23a.html",
        "author": "Rachel Redberg; Yuqing Zhu; Yu-Xiang Wang",
        "abstract": "The \u201cPropose-Test-Release\u201d (PTR) framework [Dwork and Lei, 2009] is a classic recipe for designing differentially private (DP) algorithms that are data-adaptive, i.e. those that add less noise when the input dataset is \u201cnice\u201d. We extend PTR to a more general setting by privately testing data-dependent privacy losses rather than local sensitivity, hence making it applicable beyond the standard noise-adding mechanisms, e.g. to queries with unbounded or undefined sensitivity. We demonstrate the versatility of generalized PTR using private linear regression as a case study. Additionally, we apply our algorithm to solve an open problem from \u201cPrivate Aggregation of Teacher Ensembles (PATE)\u201d [Papernot et al., 2017, 2018] - privately releasing the entire model with a delicate data-dependent analysis.",
        "bibtex": "@InProceedings{pmlr-v206-redberg23a,\n  title = \t {Generalized PTR: User-Friendly Recipes for Data-Adaptive Algorithms with Differential Privacy},\n  author =       {Redberg, Rachel and Zhu, Yuqing and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3977--4005},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/redberg23a/redberg23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/redberg23a.html},\n  abstract = \t {The \u201cPropose-Test-Release\u201d (PTR) framework [Dwork and Lei, 2009] is a classic recipe for designing differentially private (DP) algorithms that are data-adaptive, i.e. those that add less noise when the input dataset is \u201cnice\u201d. We extend PTR to a more general setting by privately testing data-dependent privacy losses rather than local sensitivity, hence making it applicable beyond the standard noise-adding mechanisms, e.g. to queries with unbounded or undefined sensitivity. We demonstrate the versatility of generalized PTR using private linear regression as a case study. Additionally, we apply our algorithm to solve an open problem from \u201cPrivate Aggregation of Teacher Ensembles (PATE)\u201d [Papernot et al., 2017, 2018] - privately releasing the entire model with a delicate data-dependent analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/redberg23a/redberg23a.pdf",
        "supp": "",
        "pdf_size": 631561,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13529535022622450262&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c680b5b9fd",
        "title": "Generative Oversampling for Imbalanced Data via Majority-Guided VAE",
        "site": "https://proceedings.mlr.press/v206/ai23a.html",
        "author": "Qingzhong Ai; Pengyun Wang; Lirong He; Liangjian Wen; Lujia Pan; Zenglin Xu",
        "abstract": "Learning with imbalanced data is a challenging problem in deep learning. Over-sampling is a widely used technique to re-balance the sampling distribution of training data. However, most existing over-sampling methods only use intra-class information of minority classes to augment the data but ignore the inter-class relationships with the majority ones, which is prone to overfitting, especially when the imbalance ratio is large. To address this issue, we propose a novel over-sampling model, called Majority-Guided VAE(MGVAE), which generates new minority samples under the guidance of a majority-based prior. In this way, the newly generated minority samples can inherit the diversity and richness of the majority ones, thus mitigating overfitting in downstream tasks. Furthermore, to prevent model collapse under limited data, we first pre-train MGVAE on sufficient majority samples and then fine-tune based on minority samples with Elastic Weight Consolidation(EWC) regularization. Experimental results on benchmark image datasets and real-world tabular data show that MGVAE achieves competitive improvements over other over-sampling methods in downstream classification tasks, demonstrating the effectiveness of our method.",
        "bibtex": "@InProceedings{pmlr-v206-ai23a,\n  title = \t {Generative Oversampling for Imbalanced Data via Majority-Guided VAE},\n  author =       {Ai, Qingzhong and Wang, Pengyun and He, Lirong and Wen, Liangjian and Pan, Lujia and Xu, Zenglin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3315--3330},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ai23a/ai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ai23a.html},\n  abstract = \t {Learning with imbalanced data is a challenging problem in deep learning. Over-sampling is a widely used technique to re-balance the sampling distribution of training data. However, most existing over-sampling methods only use intra-class information of minority classes to augment the data but ignore the inter-class relationships with the majority ones, which is prone to overfitting, especially when the imbalance ratio is large. To address this issue, we propose a novel over-sampling model, called Majority-Guided VAE(MGVAE), which generates new minority samples under the guidance of a majority-based prior. In this way, the newly generated minority samples can inherit the diversity and richness of the majority ones, thus mitigating overfitting in downstream tasks. Furthermore, to prevent model collapse under limited data, we first pre-train MGVAE on sufficient majority samples and then fine-tune based on minority samples with Elastic Weight Consolidation(EWC) regularization. Experimental results on benchmark image datasets and real-world tabular data show that MGVAE achieves competitive improvements over other over-sampling methods in downstream classification tasks, demonstrating the effectiveness of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ai23a/ai23a.pdf",
        "supp": "",
        "pdf_size": 863984,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17634447489964571929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Electronic Science and Technology of China; Noah\u2019s Ark Lab, Huawei Technologies; University of Electronic Science and Technology of China; Noah\u2019s Ark Lab, Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies; Harbin Institute of Technology, Shenzhen+Peng Cheng Lab",
        "aff_domain": "std.uestc.edu.cn;gmail.com;std.uestc.edu.cn;huawei.com;huawei.com;hit.edu.cn",
        "email": "std.uestc.edu.cn;gmail.com;std.uestc.edu.cn;huawei.com;huawei.com;hit.edu.cn",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;1;2+3",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Huawei;Harbin Institute of Technology;Pengcheng Laboratory",
        "aff_unique_dep": ";Noah\u2019s Ark Lab;;Peng Cheng Lab",
        "aff_unique_url": "https://www.uestc.edu.cn;https://www.huawei.com;http://en.hhit.edu.cn/;",
        "aff_unique_abbr": "UESTC;Huawei;HIT;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "ab71c9f9a4",
        "title": "Geometric Random Walk Graph Neural Networks via Implicit Layers",
        "site": "https://proceedings.mlr.press/v206/nikolentzos23c.html",
        "author": "Giannis Nikolentzos; Michalis Vazirgiannis",
        "abstract": "Graph neural networks have recently attracted a lot of attention and have been applied with great success to several important graph problems. The Random Walk Graph Neural Network model was recently proposed as a more intuitive alternative to the well-studied family of message passing neural networks. This model compares each input graph against a set of latent \u201chidden graphs\u201d using a kernel that counts common random walks up to some length. In this paper, we propose a new architecture, called Geometric Random Walk Graph Neural Network (GRWNN), that generalizes the above model such that it can count common walks of infinite length in two graphs. The proposed model retains the transparency of Random Walk Graph Neural Networks since its first layer also consists of a number of trainable \u201chidden graphs\u201d which are compared against the input graphs using the geometric random walk kernel. To compute the kernel, we employ a fixed-point iteration approach involving implicitly defined operations. Then, we capitalize on implicit differentiation to derive an efficient training scheme which requires only constant memory, regardless of the number of fixed-point iterations. Experiments on graph classification datasets demonstrate the effectiveness of the proposed approach in comparison with state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v206-nikolentzos23c,\n  title = \t {Geometric Random Walk Graph Neural Networks via Implicit Layers},\n  author =       {Nikolentzos, Giannis and Vazirgiannis, Michalis},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2035--2053},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nikolentzos23c/nikolentzos23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nikolentzos23c.html},\n  abstract = \t {Graph neural networks have recently attracted a lot of attention and have been applied with great success to several important graph problems. The Random Walk Graph Neural Network model was recently proposed as a more intuitive alternative to the well-studied family of message passing neural networks. This model compares each input graph against a set of latent \u201chidden graphs\u201d using a kernel that counts common random walks up to some length. In this paper, we propose a new architecture, called Geometric Random Walk Graph Neural Network (GRWNN), that generalizes the above model such that it can count common walks of infinite length in two graphs. The proposed model retains the transparency of Random Walk Graph Neural Networks since its first layer also consists of a number of trainable \u201chidden graphs\u201d which are compared against the input graphs using the geometric random walk kernel. To compute the kernel, we employ a fixed-point iteration approach involving implicitly defined operations. Then, we capitalize on implicit differentiation to derive an efficient training scheme which requires only constant memory, regardless of the number of fixed-point iterations. Experiments on graph classification datasets demonstrate the effectiveness of the proposed approach in comparison with state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nikolentzos23c/nikolentzos23c.pdf",
        "supp": "",
        "pdf_size": 385705,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8685010607544929401&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "LIX, \u00b4Ecole Polytechnique; LIX, \u00b4Ecole Polytechnique",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ecole Polytechnique",
        "aff_unique_dep": "LIX",
        "aff_unique_url": "https://www.polytechnique.edu",
        "aff_unique_abbr": "X",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "818eded8e2",
        "title": "Global Convergence of Over-parameterized Deep Equilibrium Models",
        "site": "https://proceedings.mlr.press/v206/ling23a.html",
        "author": "Zenan Ling; Xingyu Xie; Qiuhao Wang; Zongpeng Zhang; Zhouchen Lin",
        "abstract": "A deep equilibrium model (DEQ) is implicitly defined through an equilibrium point of an infinite-depth weight-tied model with an input-injection. Instead of infinite computations, it solves an equilibrium point directly with root-finding and computes gradients with implicit differentiation. In this paper, the training dynamics of over-parameterized DEQs are investigated, and we propose a novel probabilistic framework to overcome the challenge arising from the weight-sharing and the infinite depth. By supposing a condition on the initial equilibrium point, we prove that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. We further perform a fine-grained non-asymptotic analysis about random DEQs and the corresponding weight-untied models, and show that the required initial condition is satisfied via mild over-parameterization. Moreover, we show that the unique equilibrium point always exists during the training.",
        "bibtex": "@InProceedings{pmlr-v206-ling23a,\n  title = \t {Global Convergence of Over-parameterized Deep Equilibrium Models},\n  author =       {Ling, Zenan and Xie, Xingyu and Wang, Qiuhao and Zhang, Zongpeng and Lin, Zhouchen},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {767--787},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ling23a/ling23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ling23a.html},\n  abstract = \t {A deep equilibrium model (DEQ) is implicitly defined through an equilibrium point of an infinite-depth weight-tied model with an input-injection. Instead of infinite computations, it solves an equilibrium point directly with root-finding and computes gradients with implicit differentiation. In this paper, the training dynamics of over-parameterized DEQs are investigated, and we propose a novel probabilistic framework to overcome the challenge arising from the weight-sharing and the infinite depth. By supposing a condition on the initial equilibrium point, we prove that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. We further perform a fine-grained non-asymptotic analysis about random DEQs and the corresponding weight-untied models, and show that the required initial condition is satisfied via mild over-parameterization. Moreover, we show that the unique equilibrium point always exists during the training.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ling23a/ling23a.pdf",
        "supp": "",
        "pdf_size": 924603,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16079176760938515888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "National Key Lab. of General Artificial Intelligence, School of Intelligence Science and Technology, Peking University + EIC, Huazhong University of Science and Technology; National Key Lab. of General Artificial Intelligence, School of Intelligence Science and Technology, Peking University; Center for Data Science, Academy for Advanced Interdisciplinary Studies, Peking University; Center for Data Science, Academy for Advanced Interdisciplinary Studies, Peking University + Institute for Artificial Intelligence, Peking University + Peng Cheng Laboratory; National Key Lab. of General Artificial Intelligence, School of Intelligence Science and Technology, Peking University + Institute for Artificial Intelligence, Peking University + Peng Cheng Laboratory",
        "aff_domain": "pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn",
        "email": "pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;0+0+2;0+0+2",
        "aff_unique_norm": "Peking University;Huazhong University of Science and Technology;Pengcheng Laboratory",
        "aff_unique_dep": "School of Intelligence Science and Technology;EIC;Peng Cheng Laboratory",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.hust.edu.cn;http://www.pcl.ac.cn",
        "aff_unique_abbr": "Peking University;HUST;PCL",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0;0+0+0;0+0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "de504fc1d7",
        "title": "Global-Local Regularization Via Distributional Robustness",
        "site": "https://proceedings.mlr.press/v206/phan23a.html",
        "author": "Hoang Phan; Trung Le; Trung Phung; Anh Tuan Bui; Nhat Ho; Dinh Phung",
        "abstract": "Despite superior performance in many situations, deep neural networks are often vulnerable to adversarial examples and distribution shifts, limiting model generalization ability in real-world applications. To alleviate these problems, recent approaches leverage distributional robustness optimization (DRO) to find the most challenging distribution, and then minimize loss function over this most challenging distribution. Regardless of having achieved some improvements, these DRO approaches have some obvious limitations. First, they purely focus on local regularization to strengthen model robustness, missing a global regularization effect that is useful in many real-world applications (e.g., domain adaptation, domain generalization, and adversarial machine learning). Second, the loss functions in the existing DRO approaches operate in only the most challenging distribution, hence decouple with the original distribution, leading to a restrictive modeling capability. In this paper, we propose a novel regularization technique, following the veins of Wasserstein-based DRO framework. Specifically, we define a particular joint distribution and Wasserstein-based uncertainty, allowing us to couple the original and most challenging distributions for enhancing modeling capability and applying both local and global regularizations. Empirical studies on different learning problems demonstrate that our proposed approach significantly outperforms the existing regularization approaches in various domains.",
        "bibtex": "@InProceedings{pmlr-v206-phan23a,\n  title = \t {Global-Local Regularization Via Distributional Robustness},\n  author =       {Phan, Hoang and Le, Trung and Phung, Trung and Tuan Bui, Anh and Ho, Nhat and Phung, Dinh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7644--7664},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/phan23a/phan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/phan23a.html},\n  abstract = \t {Despite superior performance in many situations, deep neural networks are often vulnerable to adversarial examples and distribution shifts, limiting model generalization ability in real-world applications. To alleviate these problems, recent approaches leverage distributional robustness optimization (DRO) to find the most challenging distribution, and then minimize loss function over this most challenging distribution. Regardless of having achieved some improvements, these DRO approaches have some obvious limitations. First, they purely focus on local regularization to strengthen model robustness, missing a global regularization effect that is useful in many real-world applications (e.g., domain adaptation, domain generalization, and adversarial machine learning). Second, the loss functions in the existing DRO approaches operate in only the most challenging distribution, hence decouple with the original distribution, leading to a restrictive modeling capability. In this paper, we propose a novel regularization technique, following the veins of Wasserstein-based DRO framework. Specifically, we define a particular joint distribution and Wasserstein-based uncertainty, allowing us to couple the original and most challenging distributions for enhancing modeling capability and applying both local and global regularizations. Empirical studies on different learning problems demonstrate that our proposed approach significantly outperforms the existing regularization approaches in various domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/phan23a/phan23a.pdf",
        "supp": "",
        "pdf_size": 3199303,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3810594846149203013&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "VinAI Research; Monash University, Australia; Johns Hopkins University+University of Texas, Austin; Monash University, Australia; Johns Hopkins University+University of Texas, Austin; VinAI Research",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3;1;2+3;0",
        "aff_unique_norm": "VinAI Research;Monash University;Johns Hopkins University;University of Texas at Austin",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.vinai.io/;https://www.monash.edu;https://www.jhu.edu;https://www.utexas.edu",
        "aff_unique_abbr": "VinAI;Monash;JHU;UT Austin",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;1;2+2;1;2+2;0",
        "aff_country_unique": "Vietnam;Australia;United States"
    },
    {
        "id": "2e1c444576",
        "title": "Gradient-Informed Neural Network Statistical Robustness Estimation",
        "site": "https://proceedings.mlr.press/v206/tit23a.html",
        "author": "Karim TIT; Teddy Furon; Mathias Rousset",
        "abstract": "Deep neural networks are robust against random corruptions of the inputs to some extent. This global sense of safety is not sufficient in critical applications where probabilities of failure must be assessed with accuracy. Some previous works applied known statistical methods from the field of rare event analysis to classification. Yet, they use classifiers as black-box models without taking into account gradient information, readily available for deep learning models via auto-differentiation. We propose a new and highly efficient estimator of probabilities of failure dedicated to neural networks as it leverages the fast computation of gradients of the model through back-propagation.",
        "bibtex": "@InProceedings{pmlr-v206-tit23a,\n  title = \t {Gradient-Informed Neural Network Statistical Robustness Estimation},\n  author =       {TIT, Karim and Furon, Teddy and Rousset, Mathias},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {323--334},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tit23a/tit23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tit23a.html},\n  abstract = \t {Deep neural networks are robust against random corruptions of the inputs to some extent. This global sense of safety is not sufficient in critical applications where probabilities of failure must be assessed with accuracy. Some previous works applied known statistical methods from the field of rare event analysis to classification. Yet, they use classifiers as black-box models without taking into account gradient information, readily available for deep learning models via auto-differentiation. We propose a new and highly efficient estimator of probabilities of failure dedicated to neural networks as it leverages the fast computation of gradients of the model through back-propagation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tit23a/tit23a.pdf",
        "supp": "",
        "pdf_size": 6005206,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1036713363573555363&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e90780d863",
        "title": "Graph Alignment Kernels using Weisfeiler and Leman Hierarchies",
        "site": "https://proceedings.mlr.press/v206/nikolentzos23b.html",
        "author": "Giannis Nikolentzos; Michalis Vazirgiannis",
        "abstract": "Graph kernels have become a standard approach for tackling the graph similarity and learning tasks at the same time. Most graph kernels proposed so far are instances of the R-convolution framework. These kernels decompose graphs into their substructures and sum over all pairs of these substructures. However, considerably less attention has been paid to other types of kernels. In this paper, we propose a new kernel between graphs which reorders the adjacency matrix of each graph based on soft permutation matrices, and then compares those aligned adjacency matrices to each other using a linear kernel. To compute the permutation matrices, the kernel finds corresponding vertices in different graphs. Two vertices match with each other if the Weisfeiler-Leman test of isomorphism assigns the same label to both of them. The proposed kernel is evaluated on several graph classification and graph regression datasets. Our results indicate that the kernel is competitive with traditional and state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v206-nikolentzos23b,\n  title = \t {Graph Alignment Kernels using Weisfeiler and Leman Hierarchies},\n  author =       {Nikolentzos, Giannis and Vazirgiannis, Michalis},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2019--2034},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nikolentzos23b/nikolentzos23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nikolentzos23b.html},\n  abstract = \t {Graph kernels have become a standard approach for tackling the graph similarity and learning tasks at the same time. Most graph kernels proposed so far are instances of the R-convolution framework. These kernels decompose graphs into their substructures and sum over all pairs of these substructures. However, considerably less attention has been paid to other types of kernels. In this paper, we propose a new kernel between graphs which reorders the adjacency matrix of each graph based on soft permutation matrices, and then compares those aligned adjacency matrices to each other using a linear kernel. To compute the permutation matrices, the kernel finds corresponding vertices in different graphs. Two vertices match with each other if the Weisfeiler-Leman test of isomorphism assigns the same label to both of them. The proposed kernel is evaluated on several graph classification and graph regression datasets. Our results indicate that the kernel is competitive with traditional and state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nikolentzos23b/nikolentzos23b.pdf",
        "supp": "",
        "pdf_size": 375983,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6643059544832637071&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "LIX, \u00b4Ecole Polytechnique; LIX, \u00b4Ecole Polytechnique",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/giannisnik/gawl",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ecole Polytechnique",
        "aff_unique_dep": "LIX",
        "aff_unique_url": "https://www.polytechnique.edu",
        "aff_unique_abbr": "X",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "f38a6b0ff9",
        "title": "Graph Spectral Embedding using the Geodesic Betweenness Centrality",
        "site": "https://proceedings.mlr.press/v206/deutsch23a.html",
        "author": "Shay Deutsch; Stefano Soatto",
        "abstract": "We introduce the Graph Sylvester Embedding (GSE), an unsupervised graph representation of local similarity, connectivity, and global structure. GSE uses the solution of the Sylvester equation to capture both network structure and neighborhood proximity in a single representation. Unlike embeddings based on the eigenvectors of the Laplacian, GSE incorporates two or more basis functions, for instance using the Laplacian and the affinity matrix. Such basis functions are constructed not from the original graph, but from one whose weights measure the centrality of an edge (the fraction of the number of shortest paths that pass through that edge) in the original graph. This allows more flexibility and control to represent complex network structure and shows significant improvements over the state of the art when used for data analysis tasks such as predicting failed edges in material science and network alignment in the human-SARS CoV-2 protein-protein interactome.",
        "bibtex": "@InProceedings{pmlr-v206-deutsch23a,\n  title = \t {Graph Spectral Embedding using the Geodesic Betweenness Centrality},\n  author =       {Deutsch, Shay and Soatto, Stefano},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10505--10519},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/deutsch23a/deutsch23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/deutsch23a.html},\n  abstract = \t {We introduce the Graph Sylvester Embedding (GSE), an unsupervised graph representation of local similarity, connectivity, and global structure. GSE uses the solution of the Sylvester equation to capture both network structure and neighborhood proximity in a single representation. Unlike embeddings based on the eigenvectors of the Laplacian, GSE incorporates two or more basis functions, for instance using the Laplacian and the affinity matrix. Such basis functions are constructed not from the original graph, but from one whose weights measure the centrality of an edge (the fraction of the number of shortest paths that pass through that edge) in the original graph. This allows more flexibility and control to represent complex network structure and shows significant improvements over the state of the art when used for data analysis tasks such as predicting failed edges in material science and network alignment in the human-SARS CoV-2 protein-protein interactome.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/deutsch23a/deutsch23a.pdf",
        "supp": "",
        "pdf_size": 2484357,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:bEYYuFFjLkcJ:scholar.google.com/&scioq=Graph+Spectral+Embedding+using+the+Geodesic+Betweenness+Centrality&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "aff": "Discover + University of California, Los Angeles; University of California, Los Angeles",
        "aff_domain": "discover.com;ucla.edu",
        "email": "discover.com;ucla.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "Discover;University of California, Los Angeles",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.discover.com;https://www.ucla.edu",
        "aff_unique_abbr": ";UCLA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "1;1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "079071ae0e",
        "title": "Group Distributionally Robust Reinforcement Learning with Hierarchical Latent Variables",
        "site": "https://proceedings.mlr.press/v206/xu23d.html",
        "author": "Mengdi Xu; Peide Huang; Yaru Niu; Visak Kumar; Jielin Qiu; Chao Fang; Kuan-Hui Lee; Xuewei Qi; Henry Lam; Bo Li; Ding Zhao",
        "abstract": "One key challenge for multi-task Reinforcement learning (RL) in practice is the absence of task specifications. Robust RL has been applied to deal with task ambiguity but may result in over-conservative policies. To balance the worst-case (robustness) and average performance, we propose Group Distributionally Robust Markov Decision Process (GDR-MDP), a flexible hierarchical MDP formulation that encodes task groups via a latent mixture model. GDR-MDP identifies the optimal policy that maximizes the expected return under the worst-possible qualified belief over task groups within an ambiguity set. We rigorously show that GDR-MDP\u2019s hierarchical structure improves distributional robustness by adding regularization to the worst possible outcomes. We then develop deep RL algorithms for GDR-MDP for both value-based and policy-based RL methods. Extensive experiments on Box2D control tasks, MuJoCo benchmarks, and Google football platforms show that our algorithms outperform classic robust training algorithms across diverse environments in terms of robustness under belief uncertainties. Demos are available on our project page (https://sites.google.com/view/gdr-rl/home).",
        "bibtex": "@InProceedings{pmlr-v206-xu23d,\n  title = \t {Group Distributionally Robust Reinforcement Learning with Hierarchical Latent Variables},\n  author =       {Xu, Mengdi and Huang, Peide and Niu, Yaru and Kumar, Visak and Qiu, Jielin and Fang, Chao and Lee, Kuan-Hui and Qi, Xuewei and Lam, Henry and Li, Bo and Zhao, Ding},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2677--2703},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23d/xu23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23d.html},\n  abstract = \t {One key challenge for multi-task Reinforcement learning (RL) in practice is the absence of task specifications. Robust RL has been applied to deal with task ambiguity but may result in over-conservative policies. To balance the worst-case (robustness) and average performance, we propose Group Distributionally Robust Markov Decision Process (GDR-MDP), a flexible hierarchical MDP formulation that encodes task groups via a latent mixture model. GDR-MDP identifies the optimal policy that maximizes the expected return under the worst-possible qualified belief over task groups within an ambiguity set. We rigorously show that GDR-MDP\u2019s hierarchical structure improves distributional robustness by adding regularization to the worst possible outcomes. We then develop deep RL algorithms for GDR-MDP for both value-based and policy-based RL methods. Extensive experiments on Box2D control tasks, MuJoCo benchmarks, and Google football platforms show that our algorithms outperform classic robust training algorithms across diverse environments in terms of robustness under belief uncertainties. Demos are available on our project page (https://sites.google.com/view/gdr-rl/home).}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23d/xu23d.pdf",
        "supp": "",
        "pdf_size": 3446784,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17387418029647366630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;;;;;",
        "aff_domain": ";;;;;;;;;;",
        "email": ";;;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 11,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a0cba41c87",
        "title": "Heavy Sets with Applications to Interpretable Machine Learning Diagnostics",
        "site": "https://proceedings.mlr.press/v206/malioutov23a.html",
        "author": "Dmitry Malioutov; Sanjeeb Dash; Dennis Wei",
        "abstract": "ML models take on a new life after deployment and raise a host of new challenges: data drift, model recalibration and monitoring. If performance erodes over time, engineers in charge may ask what changed \u2013 did the data distribution change, did the model get worse after retraining? We propose a flexible paradigm for answering a variety of model diagnosis questions by finding heaviest-weight interpretable regions, which we call heavy sets. We associate a local weight describing model mismatch at each datapoint, and find a simple region maximizing the sum (or average) of these weights. Specific choices of weights can find regions where two models differ the most, where a single model makes unusually many errors, or where two datasets have large differences in densities. The premise is that a region with overall elevated errors (weights) may discover statistically significant effects despite individual errors not standing out in the noise. We focus on interpretable regions defined by sparse AND-rules (conjunctive rule using a small subset of available features). We first describe an exact integer programming (IP) formulation applicable to smaller data-sets. As the exact IP is NP-hard, we develop a greedy coordinate-wise dynamic-programming based formulation. For smaller datasets the heuristic often comes close in accuracy to the IP in objective, but it can scale to datasets with millions of examples and thousands of features. We also address statistical significance of the detected regions, taking care of multiple hypothesis testing and spatial dependence challenges that arise in model diagnostics. We evaluate our proposed approach both on synthetic data (with known ground-truth), and on well-known public ML datasets.",
        "bibtex": "@InProceedings{pmlr-v206-malioutov23a,\n  title = \t {Heavy Sets with Applications to Interpretable Machine Learning Diagnostics},\n  author =       {Malioutov, Dmitry and Dash, Sanjeeb and Wei, Dennis},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5918--5930},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/malioutov23a/malioutov23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/malioutov23a.html},\n  abstract = \t {ML models take on a new life after deployment and raise a host of new challenges: data drift, model recalibration and monitoring. If performance erodes over time, engineers in charge may ask what changed \u2013 did the data distribution change, did the model get worse after retraining? We propose a flexible paradigm for answering a variety of model diagnosis questions by finding heaviest-weight interpretable regions, which we call heavy sets. We associate a local weight describing model mismatch at each datapoint, and find a simple region maximizing the sum (or average) of these weights. Specific choices of weights can find regions where two models differ the most, where a single model makes unusually many errors, or where two datasets have large differences in densities. The premise is that a region with overall elevated errors (weights) may discover statistically significant effects despite individual errors not standing out in the noise. We focus on interpretable regions defined by sparse AND-rules (conjunctive rule using a small subset of available features). We first describe an exact integer programming (IP) formulation applicable to smaller data-sets. As the exact IP is NP-hard, we develop a greedy coordinate-wise dynamic-programming based formulation. For smaller datasets the heuristic often comes close in accuracy to the IP in objective, but it can scale to datasets with millions of examples and thousands of features. We also address statistical significance of the detected regions, taking care of multiple hypothesis testing and spatial dependence challenges that arise in model diagnostics. We evaluate our proposed approach both on synthetic data (with known ground-truth), and on well-known public ML datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/malioutov23a/malioutov23a.pdf",
        "supp": "",
        "pdf_size": 3722887,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18341220692372184819&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "31e8e0e72b",
        "title": "Hedging against Complexity: Distributionally Robust Optimization with Parametric Approximation",
        "site": "https://proceedings.mlr.press/v206/iyengar23a.html",
        "author": "Garud Iyengar; Henry Lam; Tianyu Wang",
        "abstract": "Empirical risk minimization (ERM) and distributionally robust optimization (DRO) are popular approaches for solving stochastic optimization problems that appear in operations management and machine learning. Existing generalization error bounds for these methods depend on either the complexity of the cost function or dimension of the uncertain parameters; consequently, the performance of these methods is poor for high-dimensional problems with objective functions under high complexity. We propose a simple approach in which the distribution of uncertain parameters is approximated using a parametric family of distributions. This mitigates both sources of complexity; however, it introduces a model misspecification error. We show that this new source of error can be controlled by suitable DRO formulations. Our proposed parametric DRO approach has significantly improved generalization bounds over existing ERM / DRO methods and parametric ERM for a wide variety of settings. Our method is particularly effective under distribution shifts. We also illustrate the superior performance of our approach on both synthetic and real-data portfolio optimization and regression tasks.",
        "bibtex": "@InProceedings{pmlr-v206-iyengar23a,\n  title = \t {Hedging against Complexity: Distributionally Robust Optimization with Parametric Approximation},\n  author =       {Iyengar, Garud and Lam, Henry and Wang, Tianyu},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9976--10011},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/iyengar23a/iyengar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/iyengar23a.html},\n  abstract = \t {Empirical risk minimization (ERM) and distributionally robust optimization (DRO) are popular approaches for solving stochastic optimization problems that appear in operations management and machine learning. Existing generalization error bounds for these methods depend on either the complexity of the cost function or dimension of the uncertain parameters; consequently, the performance of these methods is poor for high-dimensional problems with objective functions under high complexity. We propose a simple approach in which the distribution of uncertain parameters is approximated using a parametric family of distributions. This mitigates both sources of complexity; however, it introduces a model misspecification error. We show that this new source of error can be controlled by suitable DRO formulations. Our proposed parametric DRO approach has significantly improved generalization bounds over existing ERM / DRO methods and parametric ERM for a wide variety of settings. Our method is particularly effective under distribution shifts. We also illustrate the superior performance of our approach on both synthetic and real-data portfolio optimization and regression tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/iyengar23a/iyengar23a.pdf",
        "supp": "",
        "pdf_size": 1665158,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8376980826180169165&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "950f814536",
        "title": "HeteRSGD: Tackling Heterogeneous Sampling Costs via Optimal Reweighted Stochastic Gradient Descent",
        "site": "https://proceedings.mlr.press/v206/chen23i.html",
        "author": "Ziang Chen; Jianfeng Lu; Huajie Qian; Xinshang Wang; Wotao Yin",
        "abstract": "One implicit assumption in current stochastic gradient descent (SGD) algorithms is the identical cost for sampling each component function of the finite-sum objective. However, there are applications where the costs differ substantially, for which SGD schemes with uniform sampling invoke a high sampling load. We investigate the use of importance sampling (IS) as a cost saver in this setting, in contrast to its traditional use for variance reduction. The key ingredient is a novel efficiency metric for IS that advocates low sampling costs while penalizing high gradient variances. We then propose HeteRSGD, an SGD scheme that performs gradient sampling according to optimal probability weights stipulated by the metric, and establish theories on its optimal asymptotic and finite-time convergence rates among all possible IS-based SGD schemes. We show that the relative efficiency gain of HeteRSGD can be arbitrarily large regardless of the problem dimension and number of components. Our theoretical results are validated numerically for both convex and nonconvex problems.",
        "bibtex": "@InProceedings{pmlr-v206-chen23i,\n  title = \t {HeteRSGD: Tackling Heterogeneous Sampling Costs via Optimal Reweighted Stochastic Gradient Descent},\n  author =       {Chen, Ziang and Lu, Jianfeng and Qian, Huajie and Wang, Xinshang and Yin, Wotao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10732--10781},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23i/chen23i.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23i.html},\n  abstract = \t {One implicit assumption in current stochastic gradient descent (SGD) algorithms is the identical cost for sampling each component function of the finite-sum objective. However, there are applications where the costs differ substantially, for which SGD schemes with uniform sampling invoke a high sampling load. We investigate the use of importance sampling (IS) as a cost saver in this setting, in contrast to its traditional use for variance reduction. The key ingredient is a novel efficiency metric for IS that advocates low sampling costs while penalizing high gradient variances. We then propose HeteRSGD, an SGD scheme that performs gradient sampling according to optimal probability weights stipulated by the metric, and establish theories on its optimal asymptotic and finite-time convergence rates among all possible IS-based SGD schemes. We show that the relative efficiency gain of HeteRSGD can be arbitrarily large regardless of the problem dimension and number of components. Our theoretical results are validated numerically for both convex and nonconvex problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23i/chen23i.pdf",
        "supp": "",
        "pdf_size": 1419248,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:62XeWM8Hjr4J:scholar.google.com/&scioq=HeteRSGD:+Tackling+Heterogeneous+Sampling+Costs+via+Optimal+Reweighted+Stochastic+Gradient+Descent&hl=en&as_sdt=0,5",
        "gs_version_total": 0,
        "aff": "Duke University; Duke University; Alibaba Group; Alibaba Group; Alibaba Group",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "Duke University;Alibaba Group",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.duke.edu;https://www.alibaba.com",
        "aff_unique_abbr": "Duke;Alibaba",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "a46dac2fa4",
        "title": "Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems",
        "site": "https://proceedings.mlr.press/v206/bitzer23a.html",
        "author": "Matthias Bitzer; Mona Meister; Christoph Zimmer",
        "abstract": "Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using active learning and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in active learning for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible than previous ones, while still being applicable in the low data regime. Thus, it provides a good prior for active learning procedures. We empirically demonstrate excellent performance on various active learning tasks.",
        "bibtex": "@InProceedings{pmlr-v206-bitzer23a,\n  title = \t {Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems},\n  author =       {Bitzer, Matthias and Meister, Mona and Zimmer, Christoph},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7897--7912},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bitzer23a/bitzer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bitzer23a.html},\n  abstract = \t {Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using active learning and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in active learning for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible than previous ones, while still being applicable in the low data regime. Thus, it provides a good prior for active learning procedures. We empirically demonstrate excellent performance on various active learning tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bitzer23a/bitzer23a.pdf",
        "supp": "",
        "pdf_size": 4305683,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17077947794810931225&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "998a382f2d",
        "title": "High Probability Bounds for Stochastic Continuous Submodular Maximization",
        "site": "https://proceedings.mlr.press/v206/becker23a.html",
        "author": "Evan Becker; Jingdong Gao; Ted Zadouri; Baharan Mirzasoleiman",
        "abstract": "We consider maximization of stochastic monotone continuous submodular functions (CSF) with a diminishing return property. Existing algorithms only guarantee the performance in expectation, and do not bound the probability of getting a bad solution. This implies that for a particular run of the algorithms, the solution may be much worse than the provided guarantee in expectation. In this paper, we first empirically verify that this is indeed the case. Then, we provide the first high-probability analysis of the existing methods for stochastic CSF maximization, namely PGA, boosted PGA, SCG, and SCG++. Finally, we provide an improved high-probability bound for SCG, under slightly stronger assumptions, with a better convergence rate than that of the expected solution. Through extensive experiments on non-concave quadratic programming (NQP) and optimal budget allocation, we confirm the validity of our bounds and show that even in the worst-case, PGA converges to $OPT/2$, and boosted PGA, SCG, SCG++ converge to $(1 - 1/e)OPT$, but at a slower rate than that of the expected solution.",
        "bibtex": "@InProceedings{pmlr-v206-becker23a,\n  title = \t {High Probability Bounds for Stochastic Continuous Submodular Maximization},\n  author =       {Becker, Evan and Gao, Jingdong and Zadouri, Ted and Mirzasoleiman, Baharan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5958--5979},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/becker23a/becker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/becker23a.html},\n  abstract = \t {We consider maximization of stochastic monotone continuous submodular functions (CSF) with a diminishing return property. Existing algorithms only guarantee the performance in expectation, and do not bound the probability of getting a bad solution. This implies that for a particular run of the algorithms, the solution may be much worse than the provided guarantee in expectation. In this paper, we first empirically verify that this is indeed the case. Then, we provide the first high-probability analysis of the existing methods for stochastic CSF maximization, namely PGA, boosted PGA, SCG, and SCG++. Finally, we provide an improved high-probability bound for SCG, under slightly stronger assumptions, with a better convergence rate than that of the expected solution. Through extensive experiments on non-concave quadratic programming (NQP) and optimal budget allocation, we confirm the validity of our bounds and show that even in the worst-case, PGA converges to $OPT/2$, and boosted PGA, SCG, SCG++ converge to $(1 - 1/e)OPT$, but at a slower rate than that of the expected solution.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/becker23a/becker23a.pdf",
        "supp": "",
        "pdf_size": 1230052,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:87ohiQuafm4J:scholar.google.com/&scioq=High+Probability+Bounds+for+Stochastic+Continuous+Submodular+Maximization&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9b4f7675ba",
        "title": "High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent",
        "site": "https://proceedings.mlr.press/v206/mangold23a.html",
        "author": "Paul Mangold; Aur\u00e9lien Bellet; Joseph Salmon; Marc Tommasi",
        "abstract": "In this paper, we study differentially private empirical risk minimization (DP-ERM). It has been shown that the worst-case utility of DP-ERM reduces polynomially as the dimension increases. This is a major obstacle to privately learning large machine learning models. In high dimension, it is common for some model\u2019s parameters to carry more information than others. To exploit this, we propose a differentially private greedy coordinate descent (DP-GCD) algorithm. At each iteration, DP-GCD privately performs a coordinate-wise gradient step along the gradients\u2019 (approximately) greatest entry. We show theoretically that DP-GCD can achieve a logarithmic dependence on the dimension for a wide range of problems by naturally exploiting their structural properties (such as quasi-sparse solutions). We illustrate this behavior numerically, both on synthetic and real datasets.",
        "bibtex": "@InProceedings{pmlr-v206-mangold23a,\n  title = \t {High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent},\n  author =       {Mangold, Paul and Bellet, Aur\\'elien and Salmon, Joseph and Tommasi, Marc},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4894--4916},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mangold23a/mangold23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mangold23a.html},\n  abstract = \t {In this paper, we study differentially private empirical risk minimization (DP-ERM). It has been shown that the worst-case utility of DP-ERM reduces polynomially as the dimension increases. This is a major obstacle to privately learning large machine learning models. In high dimension, it is common for some model\u2019s parameters to carry more information than others. To exploit this, we propose a differentially private greedy coordinate descent (DP-GCD) algorithm. At each iteration, DP-GCD privately performs a coordinate-wise gradient step along the gradients\u2019 (approximately) greatest entry. We show theoretically that DP-GCD can achieve a logarithmic dependence on the dimension for a wide range of problems by naturally exploiting their structural properties (such as quasi-sparse solutions). We illustrate this behavior numerically, both on synthetic and real datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mangold23a/mangold23a.pdf",
        "supp": "",
        "pdf_size": 586217,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17912762505210125343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 23,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "01d3179dab",
        "title": "How Does Pseudo-Labeling Affect the Generalization Error of the Semi-Supervised Gibbs Algorithm?",
        "site": "https://proceedings.mlr.press/v206/he23b.html",
        "author": "Haiyun He; Gholamali Aminian; Yuheng Bu; Miguel Rodrigues; Vincent Y. F. Tan",
        "abstract": "We provide an exact characterization of the expected generalization error (gen-error) for semi-supervised learning (SSL) with pseudo-labeling via the Gibbs algorithm. The gen-error is expressed in terms of the symmetrized KL information between the output hypothesis, the pseudo-labeled dataset, and the labeled dataset. Distribution-free upper and lower bounds on the gen-error can also be obtained. Our findings offer new insights that the generalization performance of SSL with pseudo-labeling is affected not only by the information between the output hypothesis and input training data but also by the information shared between the labeled and pseudo-labeled data samples. This serves as a guideline to choose an appropriate pseudo-labeling method from a given family of methods. To deepen our understanding, we further explore two examples\u2014mean estimation and logistic regression. In particular, we analyze how the ratio of the number of unlabeled to labeled data $\\lambda$ affects the gen-error under both scenarios. As $\\lambda$ increases, the gen-error for mean estimation decreases and then saturates at a value larger than when all the samples are labeled, and the gap can be quantified exactly with our analysis, and is dependent on the cross-covariance between the labeled and pseudo-labeled data samples. For logistic regression, the gen-error and the variance component of the excess risk also decrease as $\\lambda$ increases.",
        "bibtex": "@InProceedings{pmlr-v206-he23b,\n  title = \t {How Does Pseudo-Labeling Affect the Generalization Error of the Semi-Supervised Gibbs Algorithm?},\n  author =       {He, Haiyun and Aminian, Gholamali and Bu, Yuheng and Rodrigues, Miguel and Tan, Vincent Y. F.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8494--8520},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/he23b/he23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/he23b.html},\n  abstract = \t {We provide an exact characterization of the expected generalization error (gen-error) for semi-supervised learning (SSL) with pseudo-labeling via the Gibbs algorithm. The gen-error is expressed in terms of the symmetrized KL information between the output hypothesis, the pseudo-labeled dataset, and the labeled dataset. Distribution-free upper and lower bounds on the gen-error can also be obtained. Our findings offer new insights that the generalization performance of SSL with pseudo-labeling is affected not only by the information between the output hypothesis and input training data but also by the information shared between the labeled and pseudo-labeled data samples. This serves as a guideline to choose an appropriate pseudo-labeling method from a given family of methods. To deepen our understanding, we further explore two examples\u2014mean estimation and logistic regression. In particular, we analyze how the ratio of the number of unlabeled to labeled data $\\lambda$ affects the gen-error under both scenarios. As $\\lambda$ increases, the gen-error for mean estimation decreases and then saturates at a value larger than when all the samples are labeled, and the gap can be quantified exactly with our analysis, and is dependent on the cross-covariance between the labeled and pseudo-labeled data samples. For logistic regression, the gen-error and the variance component of the excess risk also decrease as $\\lambda$ increases.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/he23b/he23b.pdf",
        "supp": "",
        "pdf_size": 734855,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6616284865780772872&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Cornell University; The Alan Turing Institute; Univ. of Florida; Univ. College London; Nat. Univ. of Singapore",
        "aff_domain": "u.nus.edu; ; ; ; ",
        "email": "u.nus.edu; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Cornell University;Alan Turing Institute;University of Florida;University College London;National University of Singapore",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.cornell.edu;https://www.turing.ac.uk;https://www.ufl.edu;https://www.ucl.ac.uk;https://www.nus.edu.sg",
        "aff_unique_abbr": "Cornell;ATI;UF;UCL;NUS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;1;0;1;2",
        "aff_country_unique": "United States;United Kingdom;Singapore"
    },
    {
        "id": "6b320ef978",
        "title": "Huber-robust confidence sequences",
        "site": "https://proceedings.mlr.press/v206/wang23p.html",
        "author": "Hongjian Wang; Aaditya Ramdas",
        "abstract": "Confidence sequences are confidence intervals that can be sequentially tracked, and are valid at arbitrary data-dependent stopping times. This paper presents confidence sequences for a univariate mean of an unknown distribution with a known upper bound on the p-th central moment (p $>$ 1), but allowing for (at most) $\\varepsilon$ fraction of arbitrary distribution corruption, as in Huber\u2019s contamination model. We do this by designing new robust exponential supermartingales, and show that the resulting confidence sequences attain the optimal width achieved in the nonsequential setting. Perhaps surprisingly, the constant margin between our sequential result and the lower bound is smaller than even fixed-time robust confidence intervals based on the trimmed mean, for example. Since confidence sequences are a common tool used within A/B/n testing and bandits, these results open the door to sequential experimentation that is robust to outliers and adversarial corruptions.",
        "bibtex": "@InProceedings{pmlr-v206-wang23p,\n  title = \t {Huber-robust confidence sequences},\n  author =       {Wang, Hongjian and Ramdas, Aaditya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9662--9679},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23p/wang23p.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23p.html},\n  abstract = \t {Confidence sequences are confidence intervals that can be sequentially tracked, and are valid at arbitrary data-dependent stopping times. This paper presents confidence sequences for a univariate mean of an unknown distribution with a known upper bound on the p-th central moment (p $>$ 1), but allowing for (at most) $\\varepsilon$ fraction of arbitrary distribution corruption, as in Huber\u2019s contamination model. We do this by designing new robust exponential supermartingales, and show that the resulting confidence sequences attain the optimal width achieved in the nonsequential setting. Perhaps surprisingly, the constant margin between our sequential result and the lower bound is smaller than even fixed-time robust confidence intervals based on the trimmed mean, for example. Since confidence sequences are a common tool used within A/B/n testing and bandits, these results open the door to sequential experimentation that is robust to outliers and adversarial corruptions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23p/wang23p.pdf",
        "supp": "",
        "pdf_size": 571358,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13164448060034633826&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Machine Learning Department, Carnegie Mellon University; Department of Statistics and Data Science, Machine Learning Department, Carnegie Mellon University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "afc56893b9",
        "title": "INO: Invariant Neural Operators for Learning Complex Physical Systems with Momentum Conservation",
        "site": "https://proceedings.mlr.press/v206/liu23f.html",
        "author": "Ning Liu; Yue Yu; Huaiqian You; Neeraj Tatikola",
        "abstract": "Neural operators, which emerge as implicit solution operators of hidden governing equations, have recently become popular tools for learning responses of complex real-world physical systems. Nevertheless, the majority of neural operator applications has thus far been data-driven, which neglects the intrinsic preservation of fundamental physical laws in data. In this paper, we introduce a novel integral neural operator architecture, to learn physical models with fundamental conservation laws automatically guaranteed. In particular, by replacing the frame-dependent position information with its invariant counterpart in the kernel space, the proposed neural operator is designed to be translation- and rotation-invariant, and consequently abides by the conservation laws of linear and angular momentums. As applications, we demonstrate the expressivity and efficacy of our model in learning complex material behaviors from both synthetic and experimental datasets, and show that, by automatically satisfying these essential physical laws, our learned neural operator is not only generalizable in handling translated and rotated datasets, but also achieves improved accuracy and efficiency from the baseline neural operator models.",
        "bibtex": "@InProceedings{pmlr-v206-liu23f,\n  title = \t {INO: Invariant Neural Operators for Learning Complex Physical Systems with Momentum Conservation},\n  author =       {Liu, Ning and Yu, Yue and You, Huaiqian and Tatikola, Neeraj},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6822--6838},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23f/liu23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23f.html},\n  abstract = \t {Neural operators, which emerge as implicit solution operators of hidden governing equations, have recently become popular tools for learning responses of complex real-world physical systems. Nevertheless, the majority of neural operator applications has thus far been data-driven, which neglects the intrinsic preservation of fundamental physical laws in data. In this paper, we introduce a novel integral neural operator architecture, to learn physical models with fundamental conservation laws automatically guaranteed. In particular, by replacing the frame-dependent position information with its invariant counterpart in the kernel space, the proposed neural operator is designed to be translation- and rotation-invariant, and consequently abides by the conservation laws of linear and angular momentums. As applications, we demonstrate the expressivity and efficacy of our model in learning complex material behaviors from both synthetic and experimental datasets, and show that, by automatically satisfying these essential physical laws, our learned neural operator is not only generalizable in handling translated and rotated datasets, but also achieves improved accuracy and efficiency from the baseline neural operator models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23f/liu23f.pdf",
        "supp": "",
        "pdf_size": 1533111,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=842481683833611347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "60d8c75e30",
        "title": "Ideal Abstractions for Decision-Focused Learning",
        "site": "https://proceedings.mlr.press/v206/poli23a.html",
        "author": "Michael Poli; Stefano Massaroli; Stefano Ermon; Bryan Wilder; Eric Horvitz",
        "abstract": "We present a methodology for formulating simplifying abstractions in machine learning systems by identifying and harnessing the utility structure of decisions. Machine learning tasks commonly involve high-dimensional output spaces (e.g., predictions for every pixel in an image or node in a graph), even though a coarser output would often suffice for downstream decision-making (e.g., regions of an image instead of pixels). Developers often hand-engineer abstractions of the output space, but numerous abstractions are possible and it is unclear how the choice of output space for a model impacts its usefulness in downstream decision-making. We propose a method that configures the output space automatically in order to minimize the loss of decision-relevant information. Taking a geometric perspective, we formulate a step of the algorithm as a projection of the probability simplex, termed fold, that minimizes the total loss of decision-related information in the H-entropy sense. Crucially, learning in the abstracted outcome space requires significantly less data, leading to a net improvement in decision quality. We demonstrate the method in two domains: data acquisition for deep neural network training and a closed-loop wildfire management task.",
        "bibtex": "@InProceedings{pmlr-v206-poli23a,\n  title = \t {Ideal Abstractions for Decision-Focused Learning},\n  author =       {Poli, Michael and Massaroli, Stefano and Ermon, Stefano and Wilder, Bryan and Horvitz, Eric},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10223--10234},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/poli23a/poli23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/poli23a.html},\n  abstract = \t {We present a methodology for formulating simplifying abstractions in machine learning systems by identifying and harnessing the utility structure of decisions. Machine learning tasks commonly involve high-dimensional output spaces (e.g., predictions for every pixel in an image or node in a graph), even though a coarser output would often suffice for downstream decision-making (e.g., regions of an image instead of pixels). Developers often hand-engineer abstractions of the output space, but numerous abstractions are possible and it is unclear how the choice of output space for a model impacts its usefulness in downstream decision-making. We propose a method that configures the output space automatically in order to minimize the loss of decision-relevant information. Taking a geometric perspective, we formulate a step of the algorithm as a projection of the probability simplex, termed fold, that minimizes the total loss of decision-related information in the H-entropy sense. Crucially, learning in the abstracted outcome space requires significantly less data, leading to a net improvement in decision quality. We demonstrate the method in two domains: data acquisition for deep neural network training and a closed-loop wildfire management task.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/poli23a/poli23a.pdf",
        "supp": "",
        "pdf_size": 4581037,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1217026702915324124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Microsoft; Mila; Stanford; Carnegie Mellon; Microsoft",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "Microsoft;Mila;Stanford University;Carnegie Mellon University",
        "aff_unique_dep": "Microsoft Corporation;Quebec Artificial Intelligence Institute;;",
        "aff_unique_url": "https://www.microsoft.com;https://mila.quebec;https://www.stanford.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Microsoft;Mila;Stanford;CMU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "a71b458ed0",
        "title": "Identification of Blackwell Optimal Policies for Deterministic MDPs",
        "site": "https://proceedings.mlr.press/v206/boone23a.html",
        "author": "Victor Boone; Bruno Gaujal",
        "abstract": "This paper investigates a new learning problem, the identification of Blackwell optimal policies on deterministic MDPs (DMDPs): A learner has to return a Blackwell optimal policy with fixed confidence using a minimal number of queries. First, we characterize the maximal set of DMDPs for which the identification is possible. Then, we focus on the analysis of algorithms based on product-form confidence regions. We minimize the number of queries by efficiently visiting the state-action pairs with respect to the shape of confidence sets. Furthermore, these confidence sets are themselves optimized to achieve better performances. The performances of our methods compare to the lower bounds up to a factor $n^2$ in the worst case \u2013 where $n$ is the number of states, and constant in certain classes of DMDPs.",
        "bibtex": "@InProceedings{pmlr-v206-boone23a,\n  title = \t {Identification of Blackwell Optimal Policies for Deterministic MDPs},\n  author =       {Boone, Victor and Gaujal, Bruno},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7392--7424},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/boone23a/boone23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/boone23a.html},\n  abstract = \t {This paper investigates a new learning problem, the identification of Blackwell optimal policies on deterministic MDPs (DMDPs): A learner has to return a Blackwell optimal policy with fixed confidence using a minimal number of queries. First, we characterize the maximal set of DMDPs for which the identification is possible. Then, we focus on the analysis of algorithms based on product-form confidence regions. We minimize the number of queries by efficiently visiting the state-action pairs with respect to the shape of confidence sets. Furthermore, these confidence sets are themselves optimized to achieve better performances. The performances of our methods compare to the lower bounds up to a factor $n^2$ in the worst case \u2013 where $n$ is the number of states, and constant in certain classes of DMDPs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/boone23a/boone23a.pdf",
        "supp": "",
        "pdf_size": 507880,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16546401650215660899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, 38000 Grenoble, France; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, 38000 Grenoble, France",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universite Grenoble Alpes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Grenoble",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "3ecbdf4c33",
        "title": "Implications of sparsity and high triangle density for graph representation learning",
        "site": "https://proceedings.mlr.press/v206/sansford23a.html",
        "author": "Hannah Sansford; Alexander Modell; Nick Whiteley; Patrick Rubin-Delanchy",
        "abstract": "Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure.",
        "bibtex": "@InProceedings{pmlr-v206-sansford23a,\n  title = \t {Implications of sparsity and high triangle density for graph representation learning},\n  author =       {Sansford, Hannah and Modell, Alexander and Whiteley, Nick and Rubin-Delanchy, Patrick},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5449--5473},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sansford23a/sansford23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sansford23a.html},\n  abstract = \t {Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sansford23a/sansford23a.pdf",
        "supp": "",
        "pdf_size": 6504979,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6117194568531396909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8e9be6fd04",
        "title": "Implicit Graphon Neural Representation",
        "site": "https://proceedings.mlr.press/v206/xia23b.html",
        "author": "Xinyue Xia; Gal Mishne; Yusu Wang",
        "abstract": "Graphons are general and powerful models for generating graphs of varying size. In this paper, we propose to directly model graphons using neural networks, obtaining Implicit Graphon Neural Representation (IGNR). Existing work in modeling and reconstructing graphons often approximates a target graphon by a fixed resolution piece-wise constant representation. Our IGNR has the benefit that it can represent graphons up to arbitrary resolutions, and enables natural and efficient generation of arbitrary sized graphs with desired structure once the model is learned. Furthermore, we allow the input graph data to be unaligned and have different sizes by leveraging the Gromov-Wasserstein distance. We first demonstrate the effectiveness of our model by showing its superior performance on a graphon learning task. We then propose an extension of IGNR that can be incorporated into an auto-encoder framework, and demonstrate its good performance under a more general setting of graphon learning. We also show that our model is suitable for graph representation learning and graph generation.",
        "bibtex": "@InProceedings{pmlr-v206-xia23b,\n  title = \t {Implicit Graphon Neural Representation},\n  author =       {Xia, Xinyue and Mishne, Gal and Wang, Yusu},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10619--10634},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xia23b/xia23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xia23b.html},\n  abstract = \t {Graphons are general and powerful models for generating graphs of varying size. In this paper, we propose to directly model graphons using neural networks, obtaining Implicit Graphon Neural Representation (IGNR). Existing work in modeling and reconstructing graphons often approximates a target graphon by a fixed resolution piece-wise constant representation. Our IGNR has the benefit that it can represent graphons up to arbitrary resolutions, and enables natural and efficient generation of arbitrary sized graphs with desired structure once the model is learned. Furthermore, we allow the input graph data to be unaligned and have different sizes by leveraging the Gromov-Wasserstein distance. We first demonstrate the effectiveness of our model by showing its superior performance on a graphon learning task. We then propose an extension of IGNR that can be incorporated into an auto-encoder framework, and demonstrate its good performance under a more general setting of graphon learning. We also show that our model is suitable for graph representation learning and graph generation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xia23b/xia23b.pdf",
        "supp": "",
        "pdf_size": 2582236,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1888590106640809944&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "29314e4baa",
        "title": "Improved Approximation for Fair Correlation Clustering",
        "site": "https://proceedings.mlr.press/v206/ahmadian23a.html",
        "author": "Sara Ahmadian; Maryam Negahbani",
        "abstract": "Correlation clustering is a ubiquitous paradigm in unsupervised machine learning where addressing unfairness is a major challenge. Motivated by this, we study fair correlation clustering where the data points may belong to different protected groups and the goal is to ensure fair representation of all groups across clusters. Our paper significantly generalizes and improves on the quality guarantees of previous work of Ahmadian et al. as follows. * We allow the user to specify an arbitrary upper bound on the representation of each group in a cluster. * Our algorithm allows individuals to have multiple protected features and ensure fairness simultaneously across them all. * We prove guarantees for clustering quality and fairness in this general setting. Furthermore, this improves on the results for the special cases studied in previous work. Our experiments on real-world data demonstrate that our clustering quality compared to the optimal solution is much better than what our theoretical result suggests.",
        "bibtex": "@InProceedings{pmlr-v206-ahmadian23a,\n  title = \t {Improved Approximation for Fair Correlation Clustering},\n  author =       {Ahmadian, Sara and Negahbani, Maryam},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9499--9516},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ahmadian23a/ahmadian23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ahmadian23a.html},\n  abstract = \t {Correlation clustering is a ubiquitous paradigm in unsupervised machine learning where addressing unfairness is a major challenge. Motivated by this, we study fair correlation clustering where the data points may belong to different protected groups and the goal is to ensure fair representation of all groups across clusters. Our paper significantly generalizes and improves on the quality guarantees of previous work of Ahmadian et al. as follows. * We allow the user to specify an arbitrary upper bound on the representation of each group in a cluster. * Our algorithm allows individuals to have multiple protected features and ensure fairness simultaneously across them all. * We prove guarantees for clustering quality and fairness in this general setting. Furthermore, this improves on the results for the special cases studied in previous work. Our experiments on real-world data demonstrate that our clustering quality compared to the optimal solution is much better than what our theoretical result suggests.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ahmadian23a/ahmadian23a.pdf",
        "supp": "",
        "pdf_size": 853815,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17604292890152468585&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; KatanaGraph",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Google;KatanaGraph",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;",
        "aff_unique_abbr": "Google Research;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "4206167602",
        "title": "Improved Bound on Generalization Error of Compressed KNN Estimator",
        "site": "https://proceedings.mlr.press/v206/zhang23j.html",
        "author": "Hang Zhang; Ping Li",
        "abstract": "This paper studies the generalization capability of the compressed $k$-nearest neighbor (KNN) estimator, where randomly-projected low-dimensional data are put into the KNN estimator rather than the high-dimensional raw data. Considering both regression and classification, we give improved bounds on its generalization errors, to put more specific, $\\ell_2$ error for regression and mis-classification rate for classification. As a byproduct of our analysis, we prove that ordered distance is almost preserved with random projections, which we believe is for the first time. In addition, we provide numerical experiments on various public datasets to verify our theorems.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23j,\n  title = \t {Improved Bound on Generalization Error of Compressed KNN Estimator},\n  author =       {Zhang, Hang and Li, Ping},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7578--7593},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23j/zhang23j.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23j.html},\n  abstract = \t {This paper studies the generalization capability of the compressed $k$-nearest neighbor (KNN) estimator, where randomly-projected low-dimensional data are put into the KNN estimator rather than the high-dimensional raw data. Considering both regression and classification, we give improved bounds on its generalization errors, to put more specific, $\\ell_2$ error for regression and mis-classification rate for classification. As a byproduct of our analysis, we prove that ordered distance is almost preserved with random projections, which we believe is for the first time. In addition, we provide numerical experiments on various public datasets to verify our theorems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23j/zhang23j.pdf",
        "supp": "",
        "pdf_size": 1102065,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:u83rxMavs7AJ:scholar.google.com/&scioq=Improved+Bound+on+Generalization+Error+of+Compressed+KNN+Estimator&hl=en&as_sdt=0,33",
        "gs_version_total": 0,
        "aff": "Amazon; LinkedIn Ads",
        "aff_domain": "amazon.com;linkedin.com",
        "email": "amazon.com;linkedin.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Amazon;LinkedIn",
        "aff_unique_dep": "Amazon.com, Inc.;LinkedIn Ads",
        "aff_unique_url": "https://www.amazon.com;https://www.linkedin.com",
        "aff_unique_abbr": "Amazon;LinkedIn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "46a479e693",
        "title": "Improved Generalization Bound and Learning of Sparsity Patterns for Data-Driven Low-Rank Approximation",
        "site": "https://proceedings.mlr.press/v206/sakaue23a.html",
        "author": "Shinsaku Sakaue; Taihei Oki",
        "abstract": "Learning sketching matrices for fast and accurate low-rank approximation (LRA) has gained increasing attention. Recently, Bartlett, Indyk, and Wagner (COLT 2022) presented a generalization bound for the learning-based LRA. Specifically, for rank-$k$ approximation using an $m \\times n$ learned sketching matrix with $s$ non-zeros in each column, they proved an $\\tilde O(nsm)$ bound on the fat shattering dimension ($\\tilde O$ hides logarithmic factors). We build on their work and make two contributions. (1) We present a better $\\tilde O(nsk)$ bound ($k \\le m$). En route to obtaining this result, we give a low-complexity Goldberg\u2013Jerrum algorithm for computing pseudo-inverse matrices, which would be of independent interest. (2) We alleviate an assumption of the previous study that sketching matrices have a fixed sparsity pattern. We prove that learning positions of non-zeros increases the fat shattering dimension only by $O(ns\\log n)$. In addition, experiments confirm the practical benefit of learning sparsity patterns.",
        "bibtex": "@InProceedings{pmlr-v206-sakaue23a,\n  title = \t {Improved Generalization Bound and Learning of Sparsity Patterns for Data-Driven Low-Rank Approximation},\n  author =       {Sakaue, Shinsaku and Oki, Taihei},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1--10},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sakaue23a/sakaue23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sakaue23a.html},\n  abstract = \t {Learning sketching matrices for fast and accurate low-rank approximation (LRA) has gained increasing attention. Recently, Bartlett, Indyk, and Wagner (COLT 2022) presented a generalization bound for the learning-based LRA. Specifically, for rank-$k$ approximation using an $m \\times n$ learned sketching matrix with $s$ non-zeros in each column, they proved an $\\tilde O(nsm)$ bound on the fat shattering dimension ($\\tilde O$ hides logarithmic factors). We build on their work and make two contributions. (1) We present a better $\\tilde O(nsk)$ bound ($k \\le m$). En route to obtaining this result, we give a low-complexity Goldberg\u2013Jerrum algorithm for computing pseudo-inverse matrices, which would be of independent interest. (2) We alleviate an assumption of the previous study that sketching matrices have a fixed sparsity pattern. We prove that learning positions of non-zeros increases the fat shattering dimension only by $O(ns\\log n)$. In addition, experiments confirm the practical benefit of learning sparsity patterns.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sakaue23a/sakaue23a.pdf",
        "supp": "",
        "pdf_size": 519800,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18290706203727160558&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "The University of Tokyo; The University of Tokyo",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "a24b829f9f",
        "title": "Improved Rate of First Order Algorithms for Entropic Optimal Transport",
        "site": "https://proceedings.mlr.press/v206/luo23a.html",
        "author": "Yiling Luo; Yiling Xie; Xiaoming Huo",
        "abstract": "This paper improves the state-of-the-art rate of a first-order algorithm for solving entropy regularized optimal transport. The resulting rate for approximating the optimal transport (OT) has been improved from $\\widetilde{\\mathcal{O}}({n^{2.5}}/{\\epsilon})$ to $\\widetilde{\\mathcal{O}}({n^2}/{\\epsilon})$, where $n$ is the problem size and $\\epsilon$ is the accuracy level. In particular, we propose an accelerated primal-dual stochastic mirror descent algorithm with variance reduction. Such special design helps us improve the rate compared to other accelerated primal-dual algorithms. We further propose a batch version of our stochastic algorithm, which improves the computational performance through parallel computing. To compare, we prove that the computational complexity of the Stochastic Sinkhorn algorithm is $\\widetilde{\\mathcal{O}}({n^2}/{\\epsilon^2})$, which is slower than our accelerated primal-dual stochastic mirror algorithm. Experiments are done using synthetic and real data, and the results match our theoretical rates. Our algorithm may inspire more research to develop accelerated primal-dual algorithms that have rate $\\widetilde{\\mathcal{O}}({n^2}/{\\epsilon})$ for solving OT.",
        "bibtex": "@InProceedings{pmlr-v206-luo23a,\n  title = \t {Improved Rate of First Order Algorithms for Entropic Optimal Transport},\n  author =       {Luo, Yiling and Xie, Yiling and Huo, Xiaoming},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2723--2750},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/luo23a/luo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/luo23a.html},\n  abstract = \t {This paper improves the state-of-the-art rate of a first-order algorithm for solving entropy regularized optimal transport. The resulting rate for approximating the optimal transport (OT) has been improved from $\\widetilde{\\mathcal{O}}({n^{2.5}}/{\\epsilon})$ to $\\widetilde{\\mathcal{O}}({n^2}/{\\epsilon})$, where $n$ is the problem size and $\\epsilon$ is the accuracy level. In particular, we propose an accelerated primal-dual stochastic mirror descent algorithm with variance reduction. Such special design helps us improve the rate compared to other accelerated primal-dual algorithms. We further propose a batch version of our stochastic algorithm, which improves the computational performance through parallel computing. To compare, we prove that the computational complexity of the Stochastic Sinkhorn algorithm is $\\widetilde{\\mathcal{O}}({n^2}/{\\epsilon^2})$, which is slower than our accelerated primal-dual stochastic mirror algorithm. Experiments are done using synthetic and real data, and the results match our theoretical rates. Our algorithm may inspire more research to develop accelerated primal-dual algorithms that have rate $\\widetilde{\\mathcal{O}}({n^2}/{\\epsilon})$ for solving OT.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/luo23a/luo23a.pdf",
        "supp": "",
        "pdf_size": 1021406,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14349603975042696670&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d3855202fb",
        "title": "Improved Representation Learning Through Tensorized Autoencoders",
        "site": "https://proceedings.mlr.press/v206/esser23a.html",
        "author": "Pascal Esser; Satyaki Mukherjee; Mahalakshmi Sabanayagam; Debarghya Ghoshdastidar",
        "abstract": "The central question in representation learning is what constitutes a good or meaningful representation. In this work we argue that if we consider data with inherent cluster structures, where clusters can be characterized through different means and covariances, those data structures should be represented in the embedding as well. While Autoencoders (AE) are widely used in practice for unsupervised representation learning, they do not fulfil the above condition on the embedding as they obtain a single representation of the data. To overcome this we propose a meta-algorithm that can be used to extend an arbitrary AE architecture to a tensorized version (TAE) that allows for learning cluster-specific embeddings while simultaneously learning the cluster assignment. For the linear setting we prove that TAE can recover the principle components of the different clusters in contrast to principle component of the entire data recovered by a standard AE. We validate this on planted models and for general, non-linear and convolutional AEs we empirically illustrate that tensorizing the AE is beneficial in clustering and de-noising tasks.",
        "bibtex": "@InProceedings{pmlr-v206-esser23a,\n  title = \t {Improved Representation Learning Through Tensorized Autoencoders},\n  author =       {Esser, Pascal and Mukherjee, Satyaki and Sabanayagam, Mahalakshmi and Ghoshdastidar, Debarghya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8294--8307},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/esser23a/esser23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/esser23a.html},\n  abstract = \t {The central question in representation learning is what constitutes a good or meaningful representation. In this work we argue that if we consider data with inherent cluster structures, where clusters can be characterized through different means and covariances, those data structures should be represented in the embedding as well. While Autoencoders (AE) are widely used in practice for unsupervised representation learning, they do not fulfil the above condition on the embedding as they obtain a single representation of the data. To overcome this we propose a meta-algorithm that can be used to extend an arbitrary AE architecture to a tensorized version (TAE) that allows for learning cluster-specific embeddings while simultaneously learning the cluster assignment. For the linear setting we prove that TAE can recover the principle components of the different clusters in contrast to principle component of the entire data recovered by a standard AE. We validate this on planted models and for general, non-linear and convolutional AEs we empirically illustrate that tensorizing the AE is beneficial in clustering and de-noising tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/esser23a/esser23a.pdf",
        "supp": "",
        "pdf_size": 3303887,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=246170582366922407&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "634031c1ab",
        "title": "Improved Robust Algorithms for Learning with Discriminative Feature Feedback",
        "site": "https://proceedings.mlr.press/v206/sabato23a.html",
        "author": "Sivan Sabato",
        "abstract": "Discriminative Feature Feedback is a setting first introduced by Dasgupta et al. (2018), which provides a protocol for interactive learning based on feature explanations that are provided by a human teacher. The features distinguish between the labels of pairs of possibly similar instances. That work has shown that learning in this model can have considerable statistical and computational advantages over learning in standard label-based interactive learning models. In this work, we provide new robust interactive learning algorithms for the Discriminative Feature Feedback model, with mistake bounds that are significantly lower than those of previous robust algorithms for this setting. In the adversarial setting, we reduce the dependence on the number of protocol exceptions from quadratic to linear. In addition, we provide an algorithm for a slightly more restricted model, which obtains an even smaller mistake bound for large models with many exceptions. In the stochastic setting, we provide the first algorithm that converges to the exception rate with a polynomial sample complexity. Our algorithm and analysis for the stochastic setting involve a new construction that we call Feature Influence, which may be of wider applicability.",
        "bibtex": "@InProceedings{pmlr-v206-sabato23a,\n  title = \t {Improved Robust Algorithms for Learning with Discriminative Feature Feedback},\n  author =       {Sabato, Sivan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1024--1036},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sabato23a/sabato23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sabato23a.html},\n  abstract = \t {Discriminative Feature Feedback is a setting first introduced by Dasgupta et al. (2018), which provides a protocol for interactive learning based on feature explanations that are provided by a human teacher. The features distinguish between the labels of pairs of possibly similar instances. That work has shown that learning in this model can have considerable statistical and computational advantages over learning in standard label-based interactive learning models. In this work, we provide new robust interactive learning algorithms for the Discriminative Feature Feedback model, with mistake bounds that are significantly lower than those of previous robust algorithms for this setting. In the adversarial setting, we reduce the dependence on the number of protocol exceptions from quadratic to linear. In addition, we provide an algorithm for a slightly more restricted model, which obtains an even smaller mistake bound for large models with many exceptions. In the stochastic setting, we provide the first algorithm that converges to the exception rate with a polynomial sample complexity. Our algorithm and analysis for the stochastic setting involve a new construction that we call Feature Influence, which may be of wider applicability.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sabato23a/sabato23a.pdf",
        "supp": "",
        "pdf_size": 295672,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:6DcT1v16b44J:scholar.google.com/&scioq=Improved+Robust+Algorithms+for+Learning+with+Discriminative+Feature+Feedback&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "51f5072b62",
        "title": "Improved Sample Complexity Bounds for Distributionally Robust Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/xu23h.html",
        "author": "Zaiyan Xu; Kishan Panaganti; Dileep Kalathil",
        "abstract": "We consider the problem of learning a control policy that is robust against the parameter mismatches between the training environment and testing environment. We formulate this as a distributionally robust reinforcement learning (DR-RL) problem where the objective is to learn the policy which maximizes the value function against the worst possible stochastic model of the environment in an uncertainty set. We focus on the tabular episodic learning setting where the algorithm has access to a generative model of the nominal (training) environment around which the uncertainty set is defined. We propose the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the uncertainty sets specified by four different divergences: total variation, chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm achieves $\\tilde{\\mathcal{O}}(|\\mathcal{S}||\\mathcal{A}| H^{5})$ sample complexity, which is uniformly better than the existing results by a factor of $|\\mathcal{S}|$, where $|\\mathcal{S}|$ is number of states, $|\\mathcal{A}|$ is the number of actions, and $H$ is the horizon length. We also provide the first-ever sample complexity result for the Wasserstein uncertainty set. Finally, we demonstrate the performance of our algorithm using simulation experiments.",
        "bibtex": "@InProceedings{pmlr-v206-xu23h,\n  title = \t {Improved Sample Complexity Bounds for Distributionally Robust Reinforcement Learning},\n  author =       {Xu, Zaiyan and Panaganti, Kishan and Kalathil, Dileep},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9728--9754},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23h/xu23h.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23h.html},\n  abstract = \t {We consider the problem of learning a control policy that is robust against the parameter mismatches between the training environment and testing environment. We formulate this as a distributionally robust reinforcement learning (DR-RL) problem where the objective is to learn the policy which maximizes the value function against the worst possible stochastic model of the environment in an uncertainty set. We focus on the tabular episodic learning setting where the algorithm has access to a generative model of the nominal (training) environment around which the uncertainty set is defined. We propose the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the uncertainty sets specified by four different divergences: total variation, chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm achieves $\\tilde{\\mathcal{O}}(|\\mathcal{S}||\\mathcal{A}| H^{5})$ sample complexity, which is uniformly better than the existing results by a factor of $|\\mathcal{S}|$, where $|\\mathcal{S}|$ is number of states, $|\\mathcal{A}|$ is the number of actions, and $H$ is the horizon length. We also provide the first-ever sample complexity result for the Wasserstein uncertainty set. Finally, we demonstrate the performance of our algorithm using simulation experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23h/xu23h.pdf",
        "supp": "",
        "pdf_size": 532032,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13048277111267959183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Texas A&M University; Texas A&M University; Texas A&M University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "acd281a5c4",
        "title": "Improving Adaptive Conformal Prediction Using Self-Supervised Learning",
        "site": "https://proceedings.mlr.press/v206/seedat23a.html",
        "author": "Nabeel Seedat; Alan Jeffares; Fergus Imrie; Mihaela van der Schaar",
        "abstract": "Conformal prediction is a powerful distribution-free tool for uncertainty quantification, establishing valid prediction intervals with finite-sample guarantees. To produce valid intervals which are also adaptive to the difficulty of each instance, a common approach is to compute normalized nonconformity scores on a separate calibration set. Self-supervised learning has been effectively utilized in many domains to learn general representations for downstream predictors. However, the use of self-supervision beyond model pretraining and representation learning has been largely unexplored. In this work, we investigate how self-supervised pretext tasks can improve the quality of the conformal regressors, specifically by improving the adaptability of conformal intervals. We train an auxiliary model with a self-supervised pretext task on top of an existing predictive model and use the self-supervised error as an additional feature to estimate nonconformity scores. We empirically demonstrate the benefit of the additional information using both synthetic and real data on the efficiency (width), deficit, and excess of conformal prediction intervals.",
        "bibtex": "@InProceedings{pmlr-v206-seedat23a,\n  title = \t {Improving Adaptive Conformal Prediction Using Self-Supervised Learning},\n  author =       {Seedat, Nabeel and Jeffares, Alan and Imrie, Fergus and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10160--10177},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/seedat23a/seedat23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/seedat23a.html},\n  abstract = \t {Conformal prediction is a powerful distribution-free tool for uncertainty quantification, establishing valid prediction intervals with finite-sample guarantees. To produce valid intervals which are also adaptive to the difficulty of each instance, a common approach is to compute normalized nonconformity scores on a separate calibration set. Self-supervised learning has been effectively utilized in many domains to learn general representations for downstream predictors. However, the use of self-supervision beyond model pretraining and representation learning has been largely unexplored. In this work, we investigate how self-supervised pretext tasks can improve the quality of the conformal regressors, specifically by improving the adaptability of conformal intervals. We train an auxiliary model with a self-supervised pretext task on top of an existing predictive model and use the self-supervised error as an additional feature to estimate nonconformity scores. We empirically demonstrate the benefit of the additional information using both synthetic and real data on the efficiency (width), deficit, and excess of conformal prediction intervals.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/seedat23a/seedat23a.pdf",
        "supp": "",
        "pdf_size": 1120134,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14544277347507000606&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d16c9dab11",
        "title": "Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes",
        "site": "https://proceedings.mlr.press/v206/baharlouei23a.html",
        "author": "Sina Baharlouei; Fatemeh Sheikholeslami; Meisam Razaviyayn; Zico Kolter",
        "abstract": "This work concerns the development of deep networks that are certifiably robust to adversarial attacks. Joint robust classification-detection was recently introduced as a certified defense mechanism, where adversarial examples are either correctly classified or assigned to the \u201cabstain\u201d class. In this work, we show that such a provable framework can benefit by extension to networks with multiple explicit abstain classes, where the adversarial examples are adaptively assigned to those. We show that na\u00efvely adding multiple abstain classes can lead to \u201cmodel degeneracy\u201d, then we propose a regularization approach and a training method to counter this degeneracy by promoting full use of the multiple abstain classes. Our experiments demonstrate that the proposed approach consistently achieves favorable standard vs. robust verified accuracy tradeoffs, outperforming state-of-the-art algorithms for various choices of number of abstain classes.",
        "bibtex": "@InProceedings{pmlr-v206-baharlouei23a,\n  title = \t {Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes},\n  author =       {Baharlouei, Sina and Sheikholeslami, Fatemeh and Razaviyayn, Meisam and Kolter, Zico},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11059--11078},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/baharlouei23a/baharlouei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/baharlouei23a.html},\n  abstract = \t {This work concerns the development of deep networks that are certifiably robust to adversarial attacks. Joint robust classification-detection was recently introduced as a certified defense mechanism, where adversarial examples are either correctly classified or assigned to the \u201cabstain\u201d class. In this work, we show that such a provable framework can benefit by extension to networks with multiple explicit abstain classes, where the adversarial examples are adaptively assigned to those. We show that na\u00efvely adding multiple abstain classes can lead to \u201cmodel degeneracy\u201d, then we propose a regularization approach and a training method to counter this degeneracy by promoting full use of the multiple abstain classes. Our experiments demonstrate that the proposed approach consistently achieves favorable standard vs. robust verified accuracy tradeoffs, outperforming state-of-the-art algorithms for various choices of number of abstain classes.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/baharlouei23a/baharlouei23a.pdf",
        "supp": "",
        "pdf_size": 2886528,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3255334277269394795&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "USC; USC + Amazon Alexa AI; USC; Bosch Center for AI, CMU",
        "aff_domain": "usc.edu;amazon.com;usc.edu;cs.cmu.edu",
        "email": "usc.edu;amazon.com;usc.edu;cs.cmu.edu",
        "github": "https://github.com/sinaBaharlouei/MultipleAbstainDetection",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;2",
        "aff_unique_norm": "University of Southern California;Amazon;Carnegie Mellon University",
        "aff_unique_dep": ";Amazon Alexa AI;Bosch Center for AI",
        "aff_unique_url": "https://www.usc.edu;https://www.amazon.com;https://www.cmu.edu",
        "aff_unique_abbr": "USC;Amazon;CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0ba2e4ed32",
        "title": "Improving Dual-Encoder Training through Dynamic Indexes for Negative Mining",
        "site": "https://proceedings.mlr.press/v206/monath23a.html",
        "author": "Nicholas Monath; Manzil Zaheer; Kelsey Allen; Andrew Mccallum",
        "abstract": "Dual encoder models are ubiquitous in modern classification and retrieval. Crucial for training such dual encoders is an accurate estimation of gradients from the partition function of the softmax over the large output space; this requires finding negative targets that contribute most significantly (\u2018hard negatives). Since dual encoder model parameters change during training, the use of traditional static nearest neighbor indexes can be sub-optimal. These static indexes (1) periodically require expensive re-building of the index, which in turn requires (2) expensive re-encoding of all targets using updated model parameters. This paper addresses both of these challenges. First, we introduce an algorithm that uses a tree structure to approximate the softmax with provable bounds and that dynamically maintains the tree. Second, we approximate the effect of a gradient update on target encodings with an efficient Nystrom low-rank approximation. In our empirical study on datasets with over twenty million targets, our approach cuts error by half in relation to oracle brute-force negative mining. Furthermore, our method surpasses prior state-of-the-art while using 150x less accelerator memory.",
        "bibtex": "@InProceedings{pmlr-v206-monath23a,\n  title = \t {Improving Dual-Encoder Training through Dynamic Indexes for Negative Mining},\n  author =       {Monath, Nicholas and Zaheer, Manzil and Allen, Kelsey and Mccallum, Andrew},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9308--9330},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/monath23a/monath23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/monath23a.html},\n  abstract = \t {Dual encoder models are ubiquitous in modern classification and retrieval. Crucial for training such dual encoders is an accurate estimation of gradients from the partition function of the softmax over the large output space; this requires finding negative targets that contribute most significantly (\u2018hard negatives). Since dual encoder model parameters change during training, the use of traditional static nearest neighbor indexes can be sub-optimal. These static indexes (1) periodically require expensive re-building of the index, which in turn requires (2) expensive re-encoding of all targets using updated model parameters. This paper addresses both of these challenges. First, we introduce an algorithm that uses a tree structure to approximate the softmax with provable bounds and that dynamically maintains the tree. Second, we approximate the effect of a gradient update on target encodings with an efficient Nystrom low-rank approximation. In our empirical study on datasets with over twenty million targets, our approach cuts error by half in relation to oracle brute-force negative mining. Furthermore, our method surpasses prior state-of-the-art while using 150x less accelerator memory.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/monath23a/monath23a.pdf",
        "supp": "",
        "pdf_size": 433008,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13296311488112906775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "40ddc3860d",
        "title": "Incentive-aware Contextual Pricing with Non-parametric Market Noise",
        "site": "https://proceedings.mlr.press/v206/golrezaei23b.html",
        "author": "Negin Golrezaei; Patrick Jaillet; Jason Cheuk Nam Liang",
        "abstract": "We consider a dynamic pricing problem for repeated contextual second-price auctions with multiple strategic buyers who aim to maximize their long-term time discounted utility. The seller has limited information on buyers\u2019 overall demand curves which depends on a non-parametric market-noise distribution, and buyers may potentially submit corrupted bids (relative to true valuations) to manipulate the seller\u2019s pricing policy for more favorable reserve prices in the future. We focus on designing the seller\u2019s learning policy to set contextual reserve prices where the seller\u2019s goal is to minimize regret compared to the revenue of a benchmark clairvoyant policy that has full information of buyers\u2019 demand. We propose a policy with a phased-structure that incorporates randomized \u201cisolation\u201d periods, during which a buyer is randomly chosen to solely participate in the auction. We show that this design allows the seller to control the number of periods in which buyers significantly corrupt their bids. We then prove that our policy enjoys a T-period regret of $O(\\sqrt{T})$ facing strategic buyers. Finally, we conduct numerical simulations to compare our proposed algorithm to standard pricing policies. Our numerical results show that our algorithm outperforms these policies under various buyer bidding behavior.",
        "bibtex": "@InProceedings{pmlr-v206-golrezaei23b,\n  title = \t {Incentive-aware Contextual Pricing with Non-parametric Market Noise},\n  author =       {Golrezaei, Negin and Jaillet, Patrick and Cheuk Nam Liang, Jason},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9331--9361},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/golrezaei23b/golrezaei23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/golrezaei23b.html},\n  abstract = \t {We consider a dynamic pricing problem for repeated contextual second-price auctions with multiple strategic buyers who aim to maximize their long-term time discounted utility. The seller has limited information on buyers\u2019 overall demand curves which depends on a non-parametric market-noise distribution, and buyers may potentially submit corrupted bids (relative to true valuations) to manipulate the seller\u2019s pricing policy for more favorable reserve prices in the future. We focus on designing the seller\u2019s learning policy to set contextual reserve prices where the seller\u2019s goal is to minimize regret compared to the revenue of a benchmark clairvoyant policy that has full information of buyers\u2019 demand. We propose a policy with a phased-structure that incorporates randomized \u201cisolation\u201d periods, during which a buyer is randomly chosen to solely participate in the auction. We show that this design allows the seller to control the number of periods in which buyers significantly corrupt their bids. We then prove that our policy enjoys a T-period regret of $O(\\sqrt{T})$ facing strategic buyers. Finally, we conduct numerical simulations to compare our proposed algorithm to standard pricing policies. Our numerical results show that our algorithm outperforms these policies under various buyer bidding behavior.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/golrezaei23b/golrezaei23b.pdf",
        "supp": "",
        "pdf_size": 508684,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11081836720443690040&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "MIT Sloan; MIT EECS; MIT Operations Research Center",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Sloan School of Management",
        "aff_unique_url": "https://mitsloan.mit.edu/",
        "aff_unique_abbr": "MIT Sloan",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "40f4169fd5",
        "title": "Incorporating functional summary information in Bayesian neural networks using a Dirichlet process likelihood approach",
        "site": "https://proceedings.mlr.press/v206/raj23a.html",
        "author": "Vishnu Raj; Tianyu Cui; Markus Heinonen; Pekka Marttinen",
        "abstract": "Bayesian neural networks (BNNs) can account for both aleatoric and epistemic uncertainty. However, in BNNs the priors are often specified over the weights which rarely reflects true prior knowledge in large and complex neural network architectures. We present a simple approach to incorporate prior knowledge in BNNs based on external summary information about the predicted classification probabilities for a given dataset. The available summary information is incorporated as augmented data and modeled with a Dirichlet process, and we derive the corresponding Summary Evidence Lower BOund. The approach is founded on Bayesian principles, and all hyperparameters have a proper probabilistic interpretation. We show how the method can inform the model about task difficulty and class imbalance. Extensive experiments show that, with negligible computational overhead, our method parallels and in many cases outperforms popular alternatives in accuracy, uncertainty calibration, and robustness against corruptions with both balanced and imbalanced data.",
        "bibtex": "@InProceedings{pmlr-v206-raj23a,\n  title = \t {Incorporating functional summary information in Bayesian neural networks using a Dirichlet process likelihood approach},\n  author =       {Raj, Vishnu and Cui, Tianyu and Heinonen, Markus and Marttinen, Pekka},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6741--6763},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/raj23a/raj23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/raj23a.html},\n  abstract = \t {Bayesian neural networks (BNNs) can account for both aleatoric and epistemic uncertainty. However, in BNNs the priors are often specified over the weights which rarely reflects true prior knowledge in large and complex neural network architectures. We present a simple approach to incorporate prior knowledge in BNNs based on external summary information about the predicted classification probabilities for a given dataset. The available summary information is incorporated as augmented data and modeled with a Dirichlet process, and we derive the corresponding Summary Evidence Lower BOund. The approach is founded on Bayesian principles, and all hyperparameters have a proper probabilistic interpretation. We show how the method can inform the model about task difficulty and class imbalance. Extensive experiments show that, with negligible computational overhead, our method parallels and in many cases outperforms popular alternatives in accuracy, uncertainty calibration, and robustness against corruptions with both balanced and imbalanced data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/raj23a/raj23a.pdf",
        "supp": "",
        "pdf_size": 1128979,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5115830430496287487&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1f02835dd2",
        "title": "Incremental Aggregated Riemannian Gradient Method for Distributed PCA",
        "site": "https://proceedings.mlr.press/v206/wang23j.html",
        "author": "Xiaolu Wang; Yuchen Jiao; Hoi-To Wai; Yuantao Gu",
        "abstract": "We consider the problem of distributed principal component analysis (PCA) where the data samples are dispersed across different agents. Despite the rich literature on this problem under various specific settings, there is still a lack of efficient algorithms that are amenable to decentralized and asynchronous implementations. In this paper, we extend the incremental aggregated gradient (IAG) method in convex optimization to the nonconvex PCA problems based on an Riemannian gradient-type method named IARG-PCA. The IARG-PCA method admits low per-iteration computational and communication cost and can be readily implemented in a decentralized and asynchronous manner. Moreover, we show that the IARG-PCA method converges linearly to the leading eigenvector of the sample covariance of the whole dataset with a constant step size. The iteration complexity coincides with the best-known result of the IAG method in terms of the linear dependence on the number of agents. Meanwhile, the communication complexity is much lower than the state-of-the-art decentralized PCA algorithms if the eigengap of the sample covariance is moderate. Numerical experiments on synthetic and real datasets show that our IARG-PCA method exhibits substantially lower communication cost and comparable computational cost compared with other existing algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-wang23j,\n  title = \t {Incremental Aggregated Riemannian Gradient Method for Distributed PCA},\n  author =       {Wang, Xiaolu and Jiao, Yuchen and Wai, Hoi-To and Gu, Yuantao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7492--7510},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23j/wang23j.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23j.html},\n  abstract = \t {We consider the problem of distributed principal component analysis (PCA) where the data samples are dispersed across different agents. Despite the rich literature on this problem under various specific settings, there is still a lack of efficient algorithms that are amenable to decentralized and asynchronous implementations. In this paper, we extend the incremental aggregated gradient (IAG) method in convex optimization to the nonconvex PCA problems based on an Riemannian gradient-type method named IARG-PCA. The IARG-PCA method admits low per-iteration computational and communication cost and can be readily implemented in a decentralized and asynchronous manner. Moreover, we show that the IARG-PCA method converges linearly to the leading eigenvector of the sample covariance of the whole dataset with a constant step size. The iteration complexity coincides with the best-known result of the IAG method in terms of the linear dependence on the number of agents. Meanwhile, the communication complexity is much lower than the state-of-the-art decentralized PCA algorithms if the eigengap of the sample covariance is moderate. Numerical experiments on synthetic and real datasets show that our IARG-PCA method exhibits substantially lower communication cost and comparable computational cost compared with other existing algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23j/wang23j.pdf",
        "supp": "",
        "pdf_size": 1030105,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8837675681327982098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9149808ad3",
        "title": "Indeterminacy in Generative Models: Characterization and Strong Identifiability",
        "site": "https://proceedings.mlr.press/v206/xi23a.html",
        "author": "Quanhan Xi; Benjamin Bloem-Reddy",
        "abstract": "Most modern probabilistic generative models, such as the variational autoencoder (VAE), have certain indeterminacies that are unresolvable even with an infinite amount of data. Different tasks tolerate different indeterminacies, however recent applications have indicated the need for strongly identifiable models, in which an observation corresponds to a unique latent code. Progress has been made towards reducing model indeterminacies while maintaining flexibility, and recent work excludes many\u2014but not all\u2014indeterminacies. In this work, we motivate model-identifiability in terms of task-identifiability, then construct a theoretical framework for analyzing the indeterminacies of latent variable models, which enables their precise characterization in terms of the generator function and prior distribution spaces. We reveal that strong identifiability is possible even with highly flexible nonlinear generators, and give two such examples. One is a straightforward modification of iVAE (Khemakhem et al., 2020); the other uses triangular monotonic maps, leading to novel connections between optimal transport and identifiability.",
        "bibtex": "@InProceedings{pmlr-v206-xi23a,\n  title = \t {Indeterminacy in Generative Models: Characterization and Strong Identifiability},\n  author =       {Xi, Quanhan and Bloem-Reddy, Benjamin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6912--6939},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xi23a/xi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xi23a.html},\n  abstract = \t {Most modern probabilistic generative models, such as the variational autoencoder (VAE), have certain indeterminacies that are unresolvable even with an infinite amount of data. Different tasks tolerate different indeterminacies, however recent applications have indicated the need for strongly identifiable models, in which an observation corresponds to a unique latent code. Progress has been made towards reducing model indeterminacies while maintaining flexibility, and recent work excludes many\u2014but not all\u2014indeterminacies. In this work, we motivate model-identifiability in terms of task-identifiability, then construct a theoretical framework for analyzing the indeterminacies of latent variable models, which enables their precise characterization in terms of the generator function and prior distribution spaces. We reveal that strong identifiability is possible even with highly flexible nonlinear generators, and give two such examples. One is a straightforward modification of iVAE (Khemakhem et al., 2020); the other uses triangular monotonic maps, leading to novel connections between optimal transport and identifiability.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xi23a/xi23a.pdf",
        "supp": "",
        "pdf_size": 477662,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14642710230418020361&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of British Columbia; University of British Columbia",
        "aff_domain": "stat.ubc.ca;stat.ubc.ca",
        "email": "stat.ubc.ca;stat.ubc.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "7445bd7788",
        "title": "Inducing Neural Collapse in Deep Long-tailed Learning",
        "site": "https://proceedings.mlr.press/v206/liu23i.html",
        "author": "Xuantong Liu; Jianfeng Zhang; Tianyang Hu; He Cao; Yuan Yao; Lujia Pan",
        "abstract": "Although deep neural networks achieve tremendous success on various classification tasks, the generalization ability drops sheer when training datasets exhibit long-tailed distributions. One of the reasons is that the learned representations (i.e. features) from the imbalanced datasets are less effective than those from balanced datasets. Specifically, the learned representation under class-balanced distribution will present the Neural Collapse (NC) phenomena. NC indicates the features from the same category are close to each other and from different categories are maximally distant, showing an optimal linear separable state of classification. However, the pattern differs on imbalanced datasets and is partially responsible for the reduced performance of the model. In this work, we propose two explicit feature regularization terms to learn high-quality representation for class-imbalanced data. With the proposed regularization, NC phenomena will appear under the class-imbalanced distribution, and the generalization ability can be significantly improved. Our method is easily implemented, highly effective, and can be plugged into most existing methods. The extensive experimental results on widely-used benchmarks show the effectiveness of our method",
        "bibtex": "@InProceedings{pmlr-v206-liu23i,\n  title = \t {Inducing Neural Collapse in Deep Long-tailed Learning},\n  author =       {Liu, Xuantong and Zhang, Jianfeng and Hu, Tianyang and Cao, He and Yao, Yuan and Pan, Lujia},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11534--11544},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23i/liu23i.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23i.html},\n  abstract = \t {Although deep neural networks achieve tremendous success on various classification tasks, the generalization ability drops sheer when training datasets exhibit long-tailed distributions. One of the reasons is that the learned representations (i.e. features) from the imbalanced datasets are less effective than those from balanced datasets. Specifically, the learned representation under class-balanced distribution will present the Neural Collapse (NC) phenomena. NC indicates the features from the same category are close to each other and from different categories are maximally distant, showing an optimal linear separable state of classification. However, the pattern differs on imbalanced datasets and is partially responsible for the reduced performance of the model. In this work, we propose two explicit feature regularization terms to learn high-quality representation for class-imbalanced data. With the proposed regularization, NC phenomena will appear under the class-imbalanced distribution, and the generalization ability can be significantly improved. Our method is easily implemented, highly effective, and can be plugged into most existing methods. The extensive experimental results on widely-used benchmarks show the effectiveness of our method}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23i/liu23i.pdf",
        "supp": "",
        "pdf_size": 902343,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17454983115365702141&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "The Hong Kong University of Science and Technology; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab; The Hong Kong University of Science and Technology; Huawei Noah\u2019s Ark Lab; The Hong Kong University of Science and Technology",
        "aff_domain": "ust.hk;huawei.com;huawei.com;ust.hk;huawei.com;ust.hk",
        "email": "ust.hk;huawei.com;huawei.com;ust.hk;huawei.com;ust.hk",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Huawei",
        "aff_unique_dep": ";Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.ust.hk;https://www.huawei.com",
        "aff_unique_abbr": "HKUST;Huawei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "4c6ddaf577",
        "title": "Inducing Point Allocation for Sparse Gaussian Processes in High-Throughput Bayesian Optimisation",
        "site": "https://proceedings.mlr.press/v206/moss23a.html",
        "author": "Henry B. Moss; Sebastian W. Ober; Victor Picheny",
        "abstract": "Sparse Gaussian processes are a key component of high-throughput Bayesian optimisation (BO) loops; however, we show that existing methods for allocating their inducing points severely hamper optimisation performance. By exploiting the quality-diversity decomposition of determinantal point processes, we propose the first inducing point allocation strategy designed specifically for use in BO. Unlike existing methods which seek only to reduce global uncertainty in the objective function, our approach provides the local high-fidelity modelling of promising regions required for precise optimisation. More generally, we demonstrate that our proposed framework provides a flexible way to allocate modelling capacity in sparse models and so is suitable for a broad range of downstream sequential decision making tasks.",
        "bibtex": "@InProceedings{pmlr-v206-moss23a,\n  title = \t {Inducing Point Allocation for Sparse Gaussian Processes in High-Throughput Bayesian Optimisation},\n  author =       {Moss, Henry B. and Ober, Sebastian W. and Picheny, Victor},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5213--5230},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/moss23a/moss23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/moss23a.html},\n  abstract = \t {Sparse Gaussian processes are a key component of high-throughput Bayesian optimisation (BO) loops; however, we show that existing methods for allocating their inducing points severely hamper optimisation performance. By exploiting the quality-diversity decomposition of determinantal point processes, we propose the first inducing point allocation strategy designed specifically for use in BO. Unlike existing methods which seek only to reduce global uncertainty in the objective function, our approach provides the local high-fidelity modelling of promising regions required for precise optimisation. More generally, we demonstrate that our proposed framework provides a flexible way to allocate modelling capacity in sparse models and so is suitable for a broad range of downstream sequential decision making tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/moss23a/moss23a.pdf",
        "supp": "",
        "pdf_size": 1668275,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17750913345762254807&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8da68bbb20",
        "title": "Influence Diagnostics under Self-concordance",
        "site": "https://proceedings.mlr.press/v206/fisher23a.html",
        "author": "Jillian Fisher; Lang Liu; Krishna Pillutla; Yejin Choi; Zaid Harchaoui",
        "abstract": "Influence diagnostics such as influence functions and approximate maximum influence perturbations are popular in machine learning and in AI domain applications. Influence diagnostics are powerful statistical tools to identify influential datapoints or subsets of datapoints. We establish finite-sample statistical bounds, as well as computational complexity bounds, for influence functions and approximate maximum influence perturbations using efficient inverse-Hessian-vector product implementations. We illustrate our results with generalized linear models and large attention based models on synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v206-fisher23a,\n  title = \t {Influence Diagnostics under Self-concordance},\n  author =       {Fisher, Jillian and Liu, Lang and Pillutla, Krishna and Choi, Yejin and Harchaoui, Zaid},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10028--10076},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/fisher23a/fisher23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/fisher23a.html},\n  abstract = \t {Influence diagnostics such as influence functions and approximate maximum influence perturbations are popular in machine learning and in AI domain applications. Influence diagnostics are powerful statistical tools to identify influential datapoints or subsets of datapoints. We establish finite-sample statistical bounds, as well as computational complexity bounds, for influence functions and approximate maximum influence perturbations using efficient inverse-Hessian-vector product implementations. We illustrate our results with generalized linear models and large attention based models on synthetic and real data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/fisher23a/fisher23a.pdf",
        "supp": "",
        "pdf_size": 1478068,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9015086078167361861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Washington; University of Washington; University of Washington; University of Washington + Allen Institute for Artificial Intelligence; University of Washington",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0+1;0",
        "aff_unique_norm": "University of Washington;Allen Institute for Artificial Intelligence",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.washington.edu;https://allenai.org",
        "aff_unique_abbr": "UW;AI2",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "78ff6c10be",
        "title": "Instance-dependent Sample Complexity Bounds for Zero-sum Matrix Games",
        "site": "https://proceedings.mlr.press/v206/maiti23a.html",
        "author": "Arnab Maiti; Kevin Jamieson; Lillian Ratliff",
        "abstract": "We study the sample complexity of identifying an approximate equilibrium for two-player zero-sum $n\\times 2$ matrix games. That is, in a sequence of repeated game plays, how many rounds must the two players play before reaching an approximate equilibrium (e.g., Nash)? We derive instance-dependent bounds that define an ordering over game matrices that captures the intuition that the dynamics of some games converge faster than others. Specifically, we consider a stochastic observation model such that when the two players choose actions $i$ and $j$, respectively, they both observe each other\u2019s played actions and a stochastic observation $X_{ij}$ such that $\\mathbb{E}[X_{ij}] = A_{ij}$. To our knowledge, our work is the first case of instance-dependent lower bounds on the number of rounds the players must play before reaching an approximate equilibrium in the sense that the number of rounds depends on the specific properties of the game matrix $A$ as well as the desired accuracy. We also prove a converse statement: there exist player strategies that achieve this lower bound.",
        "bibtex": "@InProceedings{pmlr-v206-maiti23a,\n  title = \t {Instance-dependent Sample Complexity Bounds for Zero-sum Matrix Games},\n  author =       {Maiti, Arnab and Jamieson, Kevin and Ratliff, Lillian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9429--9469},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/maiti23a/maiti23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/maiti23a.html},\n  abstract = \t {We study the sample complexity of identifying an approximate equilibrium for two-player zero-sum $n\\times 2$ matrix games. That is, in a sequence of repeated game plays, how many rounds must the two players play before reaching an approximate equilibrium (e.g., Nash)? We derive instance-dependent bounds that define an ordering over game matrices that captures the intuition that the dynamics of some games converge faster than others. Specifically, we consider a stochastic observation model such that when the two players choose actions $i$ and $j$, respectively, they both observe each other\u2019s played actions and a stochastic observation $X_{ij}$ such that $\\mathbb{E}[X_{ij}] = A_{ij}$. To our knowledge, our work is the first case of instance-dependent lower bounds on the number of rounds the players must play before reaching an approximate equilibrium in the sense that the number of rounds depends on the specific properties of the game matrix $A$ as well as the desired accuracy. We also prove a converse statement: there exist player strategies that achieve this lower bound.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/maiti23a/maiti23a.pdf",
        "supp": "",
        "pdf_size": 500376,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9600817368213382304&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Washington; University of Washington; University of Washington",
        "aff_domain": "uw.edu;cs.washington.edu;uw.edu",
        "email": "uw.edu;cs.washington.edu;uw.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2b06f68d44",
        "title": "Interactive Learning with Pricing for Optimal and Stable Allocations in Markets",
        "site": "https://proceedings.mlr.press/v206/erginbas23a.html",
        "author": "Yigit Efe Erginbas; Soham Phade; Kannan Ramchandran",
        "abstract": "Large-scale online recommendation systems must facilitate the allocation of a limited number of items among competing users while learning their preferences from user feedback. As a principled way of incorporating market constraints and user incentives in the design, we consider our objectives to be two-fold: maximal social welfare with minimal instability. To maximize social welfare, our proposed framework enhances the quality of recommendations by exploring allocations that optimistically maximize the rewards. To minimize instability, a measure of users\u2019 incentives to deviate from recommended allocations, the algorithm prices the items based on a scheme derived from the Walrasian equilibria. Though it is known that these equilibria yield stable prices for markets with known user preferences, our approach accounts for the inherent uncertainty in the preferences and further ensures that the users accept most of their recommendations under offered prices. To the best of our knowledge, our approach is the first to integrate techniques from combinatorial bandits, optimal resource allocation, and collaborative filtering to obtain an algorithm that achieves sub-linear social welfare regret as well as sub-linear instability. Empirical studies on synthetic and real-world data also demonstrate the efficacy of our strategy compared to approaches that do not fully incorporate all these aspects.",
        "bibtex": "@InProceedings{pmlr-v206-erginbas23a,\n  title = \t {Interactive Learning with Pricing for Optimal and Stable Allocations in Markets},\n  author =       {Erginbas, Yigit Efe and Phade, Soham and Ramchandran, Kannan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9773--9806},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/erginbas23a/erginbas23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/erginbas23a.html},\n  abstract = \t {Large-scale online recommendation systems must facilitate the allocation of a limited number of items among competing users while learning their preferences from user feedback. As a principled way of incorporating market constraints and user incentives in the design, we consider our objectives to be two-fold: maximal social welfare with minimal instability. To maximize social welfare, our proposed framework enhances the quality of recommendations by exploring allocations that optimistically maximize the rewards. To minimize instability, a measure of users\u2019 incentives to deviate from recommended allocations, the algorithm prices the items based on a scheme derived from the Walrasian equilibria. Though it is known that these equilibria yield stable prices for markets with known user preferences, our approach accounts for the inherent uncertainty in the preferences and further ensures that the users accept most of their recommendations under offered prices. To the best of our knowledge, our approach is the first to integrate techniques from combinatorial bandits, optimal resource allocation, and collaborative filtering to obtain an algorithm that achieves sub-linear social welfare regret as well as sub-linear instability. Empirical studies on synthetic and real-world data also demonstrate the efficacy of our strategy compared to approaches that do not fully incorporate all these aspects.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/erginbas23a/erginbas23a.pdf",
        "supp": "",
        "pdf_size": 3399368,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17647389550569928174&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2bf3be800a",
        "title": "Is interpolation benign for random forest regression?",
        "site": "https://proceedings.mlr.press/v206/arnould23a.html",
        "author": "Ludovic Arnould; Claire Boyer; Erwan Scornet",
        "abstract": "Statistical wisdom suggests that very complex models, interpolating training data, will be poor at predicting unseen examples. Yet, this aphorism has been recently challenged by the identification of benign overfitting regimes, specially studied in the case of parametric models: generalization capabilities may be preserved despite model high complexity. While it is widely known that fully-grown decision trees interpolate and, in turn, have bad predictive performances, the same behavior is yet to be analyzed for Random Forests (RF). In this paper, we study the trade-off between interpolation and consistency for several types of RF algorithms. Theoretically, we prove that interpolation regimes and consistency cannot be achieved simultaneously for several non-adaptive RF. Since adaptivity seems to be the cornerstone to bring together interpolation and consistency, we study interpolating Median RF which are proved to be consistent in the interpolating regime. This is the first result conciliating interpolation and consistency for RF, highlighting that the averaging effect introduced by feature randomization is a key mechanism, sufficient to ensure the consistency in the interpolation regime and beyond. Numerical experiments show that Breiman\u2019s RF are consistent while exactly interpolating, when no bootstrap step is involved. We theoretically control the size of the interpolation area, which converges fast enough to zero, giving a necessary condition for exact interpolation and consistency to occur in conjunction.",
        "bibtex": "@InProceedings{pmlr-v206-arnould23a,\n  title = \t {Is interpolation benign for random forest regression?},\n  author =       {Arnould, Ludovic and Boyer, Claire and Scornet, Erwan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5493--5548},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/arnould23a/arnould23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/arnould23a.html},\n  abstract = \t {Statistical wisdom suggests that very complex models, interpolating training data, will be poor at predicting unseen examples. Yet, this aphorism has been recently challenged by the identification of benign overfitting regimes, specially studied in the case of parametric models: generalization capabilities may be preserved despite model high complexity. While it is widely known that fully-grown decision trees interpolate and, in turn, have bad predictive performances, the same behavior is yet to be analyzed for Random Forests (RF). In this paper, we study the trade-off between interpolation and consistency for several types of RF algorithms. Theoretically, we prove that interpolation regimes and consistency cannot be achieved simultaneously for several non-adaptive RF. Since adaptivity seems to be the cornerstone to bring together interpolation and consistency, we study interpolating Median RF which are proved to be consistent in the interpolating regime. This is the first result conciliating interpolation and consistency for RF, highlighting that the averaging effect introduced by feature randomization is a key mechanism, sufficient to ensure the consistency in the interpolation regime and beyond. Numerical experiments show that Breiman\u2019s RF are consistent while exactly interpolating, when no bootstrap step is involved. We theoretically control the size of the interpolation area, which converges fast enough to zero, giving a necessary condition for exact interpolation and consistency to occur in conjunction.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/arnould23a/arnould23a.pdf",
        "supp": "",
        "pdf_size": 4521737,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4210903912228866065&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "af6548d8aa",
        "title": "Isotropic Gaussian Processes on Finite Spaces of Graphs",
        "site": "https://proceedings.mlr.press/v206/borovitskiy23a.html",
        "author": "Viacheslav Borovitskiy; Mohammad Reza Karimi; Vignesh Ram Somnath; Andreas Krause",
        "abstract": "We propose a principled way to define Gaussian process priors on various sets of unweighted graphs: directed or undirected, with or without loops. We endow each of these sets with a geometric structure, inducing the notions of closeness and symmetries, by turning them into a vertex set of an appropriate metagraph. Building on this, we describe the class of priors that respect this structure and are analogous to the Euclidean isotropic processes, like squared exponential or Mat\u00e9rn. We propose an efficient computational technique for the ostensibly intractable problem of evaluating these priors\u2019 kernels, making such Gaussian processes usable within the usual toolboxes and downstream applications. We go further to consider sets of equivalence classes of unweighted graphs and define the appropriate versions of priors thereon. We prove a hardness result, showing that in this case, exact kernel computation cannot be performed efficiently. However, we propose a simple Monte Carlo approximation for handling moderately sized cases. Inspired by applications in chemistry, we illustrate the proposed techniques on a real molecular property prediction task in the small data regime.",
        "bibtex": "@InProceedings{pmlr-v206-borovitskiy23a,\n  title = \t {Isotropic Gaussian Processes on Finite Spaces of Graphs},\n  author =       {Borovitskiy, Viacheslav and Karimi, Mohammad Reza and Somnath, Vignesh Ram and Krause, Andreas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4556--4574},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/borovitskiy23a/borovitskiy23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/borovitskiy23a.html},\n  abstract = \t {We propose a principled way to define Gaussian process priors on various sets of unweighted graphs: directed or undirected, with or without loops. We endow each of these sets with a geometric structure, inducing the notions of closeness and symmetries, by turning them into a vertex set of an appropriate metagraph. Building on this, we describe the class of priors that respect this structure and are analogous to the Euclidean isotropic processes, like squared exponential or Mat\u00e9rn. We propose an efficient computational technique for the ostensibly intractable problem of evaluating these priors\u2019 kernels, making such Gaussian processes usable within the usual toolboxes and downstream applications. We go further to consider sets of equivalence classes of unweighted graphs and define the appropriate versions of priors thereon. We prove a hardness result, showing that in this case, exact kernel computation cannot be performed efficiently. However, we propose a simple Monte Carlo approximation for handling moderately sized cases. Inspired by applications in chemistry, we illustrate the proposed techniques on a real molecular property prediction task in the small data regime.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/borovitskiy23a/borovitskiy23a.pdf",
        "supp": "",
        "pdf_size": 727002,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2907362985813757257&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Learning & Adaptive Systems Group, Department of Computer Science, ETH Z\u00fcrich, Switzerland; Learning & Adaptive Systems Group, Department of Computer Science, ETH Z\u00fcrich, Switzerland; Learning & Adaptive Systems Group, Department of Computer Science, ETH Z\u00fcrich, Switzerland + IBM Research Z\u00fcrich, Switzerland; Learning & Adaptive Systems Group, Department of Computer Science, ETH Z\u00fcrich, Switzerland",
        "aff_domain": "gmail.com; ; ; ",
        "email": "gmail.com; ; ; ",
        "github": "https://github.com/vsomnath/graph_space_gps",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0",
        "aff_unique_norm": "ETH Zurich;IBM",
        "aff_unique_dep": "Department of Computer Science;IBM Research",
        "aff_unique_url": "https://www.ethz.ch;https://www.ibm.com/research",
        "aff_unique_abbr": "ETH;IBM",
        "aff_campus_unique_index": "0;0;0+0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "5b0e44a40b",
        "title": "Iterative Teaching by Data Hallucination",
        "site": "https://proceedings.mlr.press/v206/qiu23a.html",
        "author": "Zeju Qiu; Weiyang Liu; Tim Z. Xiao; Zhen Liu; Umang Bhatt; Yucen Luo; Adrian Weller; Bernhard Sch\u00f6lkopf",
        "abstract": "We consider the problem of iterative machine teaching, where a teacher sequentially provides examples based on the status of a learner under a discrete input space (i.e., a pool of finite samples), which greatly limits the teacher\u2019s capability. To address this issue, we study iterative teaching under a continuous input space where the input example (i.e., image) can be either generated by solving an optimization problem or drawn directly from a continuous distribution. Specifically, we propose data hallucination teaching (DHT) where the teacher can generate input data intelligently based on labels, the learner\u2019s status and the target concept. We study a number of challenging teaching setups (e.g., linear/neural learners in omniscient and black-box settings). Extensive empirical results verify the effectiveness of DHT.",
        "bibtex": "@InProceedings{pmlr-v206-qiu23a,\n  title = \t {Iterative Teaching by Data Hallucination},\n  author =       {Qiu, Zeju and Liu, Weiyang and Xiao, Tim Z. and Liu, Zhen and Bhatt, Umang and Luo, Yucen and Weller, Adrian and Sch\\\"olkopf, Bernhard},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9892--9913},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qiu23a/qiu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qiu23a.html},\n  abstract = \t {We consider the problem of iterative machine teaching, where a teacher sequentially provides examples based on the status of a learner under a discrete input space (i.e., a pool of finite samples), which greatly limits the teacher\u2019s capability. To address this issue, we study iterative teaching under a continuous input space where the input example (i.e., image) can be either generated by solving an optimization problem or drawn directly from a continuous distribution. Specifically, we propose data hallucination teaching (DHT) where the teacher can generate input data intelligently based on labels, the learner\u2019s status and the target concept. We study a number of challenging teaching setups (e.g., linear/neural learners in omniscient and black-box settings). Extensive empirical results verify the effectiveness of DHT.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qiu23a/qiu23a.pdf",
        "supp": "",
        "pdf_size": 24991349,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17009049207117602118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Max Planck Institute for Intelligent Systems; University of Cambridge + Technical University of Munich; University of T\u00fcbingen; Mila, Universit\u00e9 de Montr\u00e9al; The Alan Turing Institute + University of Cambridge; Max Planck Institute for Intelligent Systems; University of Cambridge + The Alan Turing Institute; Max Planck Institute for Intelligent Systems",
        "aff_domain": "cam.ac.uk; ; ; ; ; ; ; ",
        "email": "cam.ac.uk; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;3;4;5+1;0;1+5;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;University of Cambridge;Technical University of Munich;University of T\u00fcbingen;Universit\u00e9 de Montr\u00e9al;Alan Turing Institute",
        "aff_unique_dep": "Intelligent Systems;;;;Mila;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.cam.ac.uk;https://www.tum.de;https://www.uni-tuebingen.de/;https://umontreal.ca;https://www.turing.ac.uk",
        "aff_unique_abbr": "MPI-IS;Cambridge;TUM;Uni T\u00fcbingen;UdeM;ATI",
        "aff_campus_unique_index": "1;2;1;1",
        "aff_campus_unique": ";Cambridge;Montr\u00e9al",
        "aff_country_unique_index": "0;1+0;0;2;1+1;0;1+1;0",
        "aff_country_unique": "Germany;United Kingdom;Canada"
    },
    {
        "id": "84b881ac80",
        "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference",
        "site": "https://proceedings.mlr.press/v206/ishikawa23a.html",
        "author": "Kei Ishikawa; Niao He",
        "abstract": "We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value. It can be shown that our estimator contains the recently proposed sharp estimator by Dorn and Guo (2022) as a special case, and our method enables a novel extension of the classical marginal sensitivity model using f-divergence. To construct our estimator, we leverage the kernel method to obtain a tractable approximation to the conditional moment constraints, which traditional non-sharp estimators failed to take into account. In the theoretical analysis, we provide a condition for the choice of the kernel which guarantees no specification error that biases the lower bound estimation. Furthermore, we provide consistency guarantees of policy evaluation and learning. In the experiments with synthetic and real-world data, we demonstrate the effectiveness of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v206-ishikawa23a,\n  title = \t {Kernel Conditional Moment Constraints for Confounding Robust Inference},\n  author =       {Ishikawa, Kei and He, Niao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {650--674},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ishikawa23a/ishikawa23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ishikawa23a.html},\n  abstract = \t {We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value. It can be shown that our estimator contains the recently proposed sharp estimator by Dorn and Guo (2022) as a special case, and our method enables a novel extension of the classical marginal sensitivity model using f-divergence. To construct our estimator, we leverage the kernel method to obtain a tractable approximation to the conditional moment constraints, which traditional non-sharp estimators failed to take into account. In the theoretical analysis, we provide a condition for the choice of the kernel which guarantees no specification error that biases the lower bound estimation. Furthermore, we provide consistency guarantees of policy evaluation and learning. In the experiments with synthetic and real-world data, we demonstrate the effectiveness of the proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ishikawa23a/ishikawa23a.pdf",
        "supp": "",
        "pdf_size": 976506,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2218687676630037673&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich",
        "aff_domain": "student.ethz.ch;inf.ethz.ch",
        "email": "student.ethz.ch;inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "884e918ddf",
        "title": "Knowledge Acquisition for Human-In-The-Loop Image Captioning",
        "site": "https://proceedings.mlr.press/v206/zheng23a.html",
        "author": "Ervine Zheng; Qi Yu; Rui Li; Pengcheng Shi; Anne Haake",
        "abstract": "Image captioning offers a computational process to understand the semantics of images and convey them using descriptive language. However, automated captioning models may not always generate satisfactory captions due to the complex nature of the images and the quality/size of the training data. We propose an interactive captioning framework to improve machine-generated captions by keeping humans in the loop and performing an online-offline knowledge acquisition (KA) process. In particular, online KA accepts a list of keywords specified by human users and fuses them with the image features to generate a readable sentence that captures the semantics of the image. It leverages a multimodal conditioned caption completion mechanism to ensure the appearance of all user-input keywords in the generated caption. Offline KA further learns from the user inputs to update the model and benefits caption generation for unseen images in the future. It is built upon a Bayesian transformer architecture that dynamically allocates neural resources and supports uncertainty-aware model updates to mitigate overfitting. Our theoretical analysis also proves that Offline KA automatically selects the best model capacity to accommodate the newly acquired knowledge. Experiments on real-world data demonstrate the effectiveness of the proposed framework.",
        "bibtex": "@InProceedings{pmlr-v206-zheng23a,\n  title = \t {Knowledge Acquisition for Human-In-The-Loop Image Captioning},\n  author =       {Zheng, Ervine and Yu, Qi and Li, Rui and Shi, Pengcheng and Haake, Anne},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2191--2206},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zheng23a/zheng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zheng23a.html},\n  abstract = \t {Image captioning offers a computational process to understand the semantics of images and convey them using descriptive language. However, automated captioning models may not always generate satisfactory captions due to the complex nature of the images and the quality/size of the training data. We propose an interactive captioning framework to improve machine-generated captions by keeping humans in the loop and performing an online-offline knowledge acquisition (KA) process. In particular, online KA accepts a list of keywords specified by human users and fuses them with the image features to generate a readable sentence that captures the semantics of the image. It leverages a multimodal conditioned caption completion mechanism to ensure the appearance of all user-input keywords in the generated caption. Offline KA further learns from the user inputs to update the model and benefits caption generation for unseen images in the future. It is built upon a Bayesian transformer architecture that dynamically allocates neural resources and supports uncertainty-aware model updates to mitigate overfitting. Our theoretical analysis also proves that Offline KA automatically selects the best model capacity to accommodate the newly acquired knowledge. Experiments on real-world data demonstrate the effectiveness of the proposed framework.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zheng23a/zheng23a.pdf",
        "supp": "",
        "pdf_size": 3417600,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15469460089841386121&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rochester Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.rit.edu",
        "aff_unique_abbr": "RIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6bf3b2e7dc",
        "title": "Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph Embedding",
        "site": "https://proceedings.mlr.press/v206/gebhart23a.html",
        "author": "Thomas Gebhart; Jakob Hansen; Paul Schrater",
        "abstract": "Knowledge graph embedding involves learning representations of entities\u2014the vertices of the graph\u2014and relations\u2014the edges of the graph\u2014such that the resulting representations encode the known factual information represented by the knowledge graph and can be used in the inference of new relations. We show that knowledge graph embedding is naturally expressed in the topological and categorical language of cellular sheaves: a knowledge graph embedding can be described as an approximate global section of an appropriate knowledge sheaf over the graph, with consistency constraints induced by the knowledge graph\u2019s schema. This approach provides a generalized framework for reasoning about knowledge graph embedding models and allows for the expression of a wide range of prior constraints on embeddings. Further, the resulting embeddings can be easily adapted for reasoning over composite relations without special training. We implement these ideas to highlight the benefits of the extensions inspired by this new perspective.",
        "bibtex": "@InProceedings{pmlr-v206-gebhart23a,\n  title = \t {Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph Embedding},\n  author =       {Gebhart, Thomas and Hansen, Jakob and Schrater, Paul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9094--9116},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gebhart23a/gebhart23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gebhart23a.html},\n  abstract = \t {Knowledge graph embedding involves learning representations of entities\u2014the vertices of the graph\u2014and relations\u2014the edges of the graph\u2014such that the resulting representations encode the known factual information represented by the knowledge graph and can be used in the inference of new relations. We show that knowledge graph embedding is naturally expressed in the topological and categorical language of cellular sheaves: a knowledge graph embedding can be described as an approximate global section of an appropriate knowledge sheaf over the graph, with consistency constraints induced by the knowledge graph\u2019s schema. This approach provides a generalized framework for reasoning about knowledge graph embedding models and allows for the expression of a wide range of prior constraints on embeddings. Further, the resulting embeddings can be easily adapted for reasoning over composite relations without special training. We implement these ideas to highlight the benefits of the extensions inspired by this new perspective.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gebhart23a/gebhart23a.pdf",
        "supp": "",
        "pdf_size": 1047204,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1253794452743991566&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Minnesota, Department of Computer Science; BlueLightAI, Inc. + University of Minnesota, Department of Computer Science; University of Minnesota, Department of Computer Science",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "University of Minnesota;BlueLightAI",
        "aff_unique_dep": "Department of Computer Science;Inc.",
        "aff_unique_url": "https://www.minnesota.edu;",
        "aff_unique_abbr": "UMN;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "73fd4db6aa",
        "title": "Krylov\u2013Bellman boosting: Super-linear policy evaluation in general state spaces",
        "site": "https://proceedings.mlr.press/v206/xia23a.html",
        "author": "Eric Xia; Martin Wainwright",
        "abstract": "We present and analyze the Krylov\u2013Bellman Boosting algorithm for policy evaluation in general state spaces. It alternates between fitting the Bellman residual using non-parametric regression (as in boosting), and estimating the value function via the least-squares temporal difference (LSTD) procedure applied with a feature set that grows adaptively over time. By exploiting the connection to Krylov methods, we equip this method with two attractive guarantees. First, we provide a general convergence bound that allows for separate estimation errors in residual fitting and LSTD computation. Consistent with our numerical experiments, this bound shows that convergence rates depend on the restricted spectral structure, and are typically super-linear. Second, by combining this meta-result with sample-size dependent guarantees for residual fitting and LTSD computation, we obtain concrete statistical guarantees that depend on the sample size along with the complexity of the function class used to fit the residuals. We illustrate the behavior of the KBB algorithm for various types of policy evaluation problems, and typically find large reductions in sample complexity relative to the standard approach of fitted value iteration.",
        "bibtex": "@InProceedings{pmlr-v206-xia23a,\n  title = \t {Krylov\u2013Bellman boosting: Super-linear policy evaluation in general state spaces},\n  author =       {Xia, Eric and Wainwright, Martin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9137--9166},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xia23a/xia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xia23a.html},\n  abstract = \t {We present and analyze the Krylov\u2013Bellman Boosting algorithm for policy evaluation in general state spaces. It alternates between fitting the Bellman residual using non-parametric regression (as in boosting), and estimating the value function via the least-squares temporal difference (LSTD) procedure applied with a feature set that grows adaptively over time. By exploiting the connection to Krylov methods, we equip this method with two attractive guarantees. First, we provide a general convergence bound that allows for separate estimation errors in residual fitting and LSTD computation. Consistent with our numerical experiments, this bound shows that convergence rates depend on the restricted spectral structure, and are typically super-linear. Second, by combining this meta-result with sample-size dependent guarantees for residual fitting and LTSD computation, we obtain concrete statistical guarantees that depend on the sample size along with the complexity of the function class used to fit the residuals. We illustrate the behavior of the KBB algorithm for various types of policy evaluation problems, and typically find large reductions in sample complexity relative to the standard approach of fitted value iteration.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xia23a/xia23a.pdf",
        "supp": "",
        "pdf_size": 649028,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10020647696832439622&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of California, Berkeley; Massachusetts Institute of Technology",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Berkeley;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://web.mit.edu",
        "aff_unique_abbr": "UC Berkeley;MIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3246b02081",
        "title": "LOFT: Finding Lottery Tickets through Filter-wise Training",
        "site": "https://proceedings.mlr.press/v206/wang23f.html",
        "author": "Qihan Wang; Chen Dun; Fangshuo Liao; Chris Jermaine; Anastasios Kyrillidis",
        "abstract": "Recent work on the Lottery Ticket Hypothesis (LTH) shows that there exist \u201cwinning tickets\u201d in large neural networks. These tickets represent \u201csparse\u201d versions of the full model that can be trained independently to achieve comparable accuracy with respect to the full model. However, finding the winning tickets requires one to pretrain the large model for at least a number of epochs, which can be a burdensome task, especially when the original neural network gets larger. In this paper, we explore how one can efficiently identify the emergence of such winning tickets, and use this observation to design efficient pretraining algorithms. For clarity of exposition, our focus is on convolutional neural networks (CNNs). To identify good filters, we propose a novel filter distance metric that well-represents the model convergence. As our theory dictates, our filter analysis behaves consistently with recent findings of neural network learning dynamics. Motivated by these observations, we present the LOttery ticket through Filter-wise Training algorithm, dubbed as LoFT. LoFT is a model-parallel pretraining algorithm that partitions convolutional layers by filters to train them independently in a distributed setting, resulting in reduced memory and communication costs during pretraining. Experiments show that LoFT i) preserves and finds good lottery tickets, while ii) it achieves non-trivial computation and communication savings, and maintains comparable or even better accuracy than other pretraining methods.",
        "bibtex": "@InProceedings{pmlr-v206-wang23f,\n  title = \t {LOFT: Finding Lottery Tickets through Filter-wise Training},\n  author =       {Wang, Qihan and Dun, Chen and Liao, Fangshuo and Jermaine, Chris and Kyrillidis, Anastasios},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6498--6526},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23f/wang23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23f.html},\n  abstract = \t {Recent work on the Lottery Ticket Hypothesis (LTH) shows that there exist \u201cwinning tickets\u201d in large neural networks. These tickets represent \u201csparse\u201d versions of the full model that can be trained independently to achieve comparable accuracy with respect to the full model. However, finding the winning tickets requires one to pretrain the large model for at least a number of epochs, which can be a burdensome task, especially when the original neural network gets larger. In this paper, we explore how one can efficiently identify the emergence of such winning tickets, and use this observation to design efficient pretraining algorithms. For clarity of exposition, our focus is on convolutional neural networks (CNNs). To identify good filters, we propose a novel filter distance metric that well-represents the model convergence. As our theory dictates, our filter analysis behaves consistently with recent findings of neural network learning dynamics. Motivated by these observations, we present the LOttery ticket through Filter-wise Training algorithm, dubbed as LoFT. LoFT is a model-parallel pretraining algorithm that partitions convolutional layers by filters to train them independently in a distributed setting, resulting in reduced memory and communication costs during pretraining. Experiments show that LoFT i) preserves and finds good lottery tickets, while ii) it achieves non-trivial computation and communication savings, and maintains comparable or even better accuracy than other pretraining methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23f/wang23f.pdf",
        "supp": "",
        "pdf_size": 2481227,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3922025742594880979&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Rice University; Rice University; Rice University; Rice University; Rice University",
        "aff_domain": "gmail.com;rice.edu;rice.edu;rice.edu;rice.edu",
        "email": "gmail.com;rice.edu;rice.edu;rice.edu;rice.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "196d03d626",
        "title": "Langevin Diffusion Variational Inference",
        "site": "https://proceedings.mlr.press/v206/geffner23a.html",
        "author": "Tomas Geffner; Justin Domke",
        "abstract": "Many methods that build powerful variational distributions based on unadjusted Langevin transitions exist. Most of these were developed using a wide range of different approaches and techniques. Unfortunately, the lack of a unified analysis and derivation makes developing new methods and reasoning about existing ones a challenging task. We address this giving a single analysis that unifies and generalizes these existing techniques. The main idea is to augment the target and variational by numerically simulating the underdamped Langevin diffusion process and its time reversal. The benefits of this approach are twofold: it provides a unified formulation for many existing methods, and it simplifies the development of new ones. In fact, using our formulation we propose a new method that combines the strengths of previously existing algorithms; it uses underdamped Langevin transitions and powerful augmentations parameterized by a score network. Our empirical evaluation shows that our proposed method consistently outperforms relevant baselines in a wide range of tasks.",
        "bibtex": "@InProceedings{pmlr-v206-geffner23a,\n  title = \t {Langevin Diffusion Variational Inference},\n  author =       {Geffner, Tomas and Domke, Justin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {576--593},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/geffner23a/geffner23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/geffner23a.html},\n  abstract = \t {Many methods that build powerful variational distributions based on unadjusted Langevin transitions exist. Most of these were developed using a wide range of different approaches and techniques. Unfortunately, the lack of a unified analysis and derivation makes developing new methods and reasoning about existing ones a challenging task. We address this giving a single analysis that unifies and generalizes these existing techniques. The main idea is to augment the target and variational by numerically simulating the underdamped Langevin diffusion process and its time reversal. The benefits of this approach are twofold: it provides a unified formulation for many existing methods, and it simplifies the development of new ones. In fact, using our formulation we propose a new method that combines the strengths of previously existing algorithms; it uses underdamped Langevin transitions and powerful augmentations parameterized by a score network. Our empirical evaluation shows that our proposed method consistently outperforms relevant baselines in a wide range of tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/geffner23a/geffner23a.pdf",
        "supp": "",
        "pdf_size": 362176,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10454324568593839476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Massachusetts, Amherst; University of Massachusetts, Amherst",
        "aff_domain": "cs.umass.edu;cs.umass.edu",
        "email": "cs.umass.edu;cs.umass.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9bd9335f30",
        "title": "Large deviations rates for stochastic gradient descent with strongly convex functions",
        "site": "https://proceedings.mlr.press/v206/bajovic23a.html",
        "author": "Dragana Bajovic; Dusan Jakovetic; Soummya Kar",
        "abstract": "Recent works have shown that high probability metrics with stochastic gradient descent (SGD) exhibit informativeness and in some cases advantage over the commonly adopted mean-square error-based ones. In this work we provide a formal framework for the study of general high probability bounds with SGD, based on the theory of large deviations. The framework allows for a generic (not-necessarily bounded) gradient noise satisfying mild technical assumptions, allowing for the dependence of the noise distribution on the current iterate. Under the preceding assumptions, we find an upper large deviations bound for SGD with strongly convex functions. The corresponding rate function captures analytical dependence on the noise distribution and other problem parameters. This is in contrast with conventional mean-square error analysis that captures only the noise dependence through the variance and does not capture the effect of higher order moments nor interplay between the noise geometry and the shape of the cost function. We also derive exact large deviation rates for the case when the objective function is quadratic and show that the obtained function matches the one from the general upper bound hence showing the tightness of the general upper bound. Numerical examples illustrate and corroborate theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v206-bajovic23a,\n  title = \t {Large deviations rates for stochastic gradient descent with strongly convex functions},\n  author =       {Bajovic, Dragana and Jakovetic, Dusan and Kar, Soummya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10095--10111},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bajovic23a/bajovic23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bajovic23a.html},\n  abstract = \t {Recent works have shown that high probability metrics with stochastic gradient descent (SGD) exhibit informativeness and in some cases advantage over the commonly adopted mean-square error-based ones. In this work we provide a formal framework for the study of general high probability bounds with SGD, based on the theory of large deviations. The framework allows for a generic (not-necessarily bounded) gradient noise satisfying mild technical assumptions, allowing for the dependence of the noise distribution on the current iterate. Under the preceding assumptions, we find an upper large deviations bound for SGD with strongly convex functions. The corresponding rate function captures analytical dependence on the noise distribution and other problem parameters. This is in contrast with conventional mean-square error analysis that captures only the noise dependence through the variance and does not capture the effect of higher order moments nor interplay between the noise geometry and the shape of the cost function. We also derive exact large deviation rates for the case when the objective function is quadratic and show that the obtained function matches the one from the general upper bound hence showing the tightness of the general upper bound. Numerical examples illustrate and corroborate theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bajovic23a/bajovic23a.pdf",
        "supp": "",
        "pdf_size": 559587,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4128473679795571774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Faculty of Technical Sciences, University of Novi Sad, Serbia; Faculty of Sciences, University of Novi Sad, Serbia; Carnegie Mellon University, USA",
        "aff_domain": "uns.ac.rs;dmi.uns.ac.rs;andrew.cmu.edu",
        "email": "uns.ac.rs;dmi.uns.ac.rs;andrew.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Novi Sad;Carnegie Mellon University",
        "aff_unique_dep": "Faculty of Technical Sciences;",
        "aff_unique_url": "https://www.uns.ac.rs;https://www.cmu.edu",
        "aff_unique_abbr": ";CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Serbia;United States"
    },
    {
        "id": "f24c220841",
        "title": "Last-Iterate Convergence with Full and Noisy Feedback in Two-Player Zero-Sum Games",
        "site": "https://proceedings.mlr.press/v206/abe23a.html",
        "author": "Kenshi Abe; Kaito Ariu; Mitsuki Sakamoto; Kentaro Toyoshima; Atsushi Iwasaki",
        "abstract": "This paper proposes Mutation-Driven Multiplicative Weights Update (M2WU) for learning an equilibrium in two-player zero-sum normal-form games and proves that it exhibits the last-iterate convergence property in both full and noisy feedback settings. In the former, players observe their exact gradient vectors of the utility functions. In the latter, they only observe the noisy gradient vectors. Even the celebrated Multiplicative Weights Update (MWU) and Optimistic MWU (OMWU) algorithms may not converge to a Nash equilibrium with noisy feedback. On the contrary, M2WU exhibits the last-iterate convergence to a stationary point near a Nash equilibrium in both feedback settings. We then prove that it converges to an exact Nash equilibrium by iteratively adapting the mutation term. We empirically confirm that M2WU outperforms MWU and OMWU in exploitability and convergence rates.",
        "bibtex": "@InProceedings{pmlr-v206-abe23a,\n  title = \t {Last-Iterate Convergence with Full and Noisy Feedback in Two-Player Zero-Sum Games},\n  author =       {Abe, Kenshi and Ariu, Kaito and Sakamoto, Mitsuki and Toyoshima, Kentaro and Iwasaki, Atsushi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7999--8028},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/abe23a/abe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/abe23a.html},\n  abstract = \t {This paper proposes Mutation-Driven Multiplicative Weights Update (M2WU) for learning an equilibrium in two-player zero-sum normal-form games and proves that it exhibits the last-iterate convergence property in both full and noisy feedback settings. In the former, players observe their exact gradient vectors of the utility functions. In the latter, they only observe the noisy gradient vectors. Even the celebrated Multiplicative Weights Update (MWU) and Optimistic MWU (OMWU) algorithms may not converge to a Nash equilibrium with noisy feedback. On the contrary, M2WU exhibits the last-iterate convergence to a stationary point near a Nash equilibrium in both feedback settings. We then prove that it converges to an exact Nash equilibrium by iteratively adapting the mutation term. We empirically confirm that M2WU outperforms MWU and OMWU in exploitability and convergence rates.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/abe23a/abe23a.pdf",
        "supp": "",
        "pdf_size": 9556247,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7671609696471222754&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "CyberAgent, Inc.; CyberAgent, Inc. + KTH Royal Institute of Technology; University of Electro-Communications; University of Electro-Communications; University of Electro-Communications",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;2;2;2",
        "aff_unique_norm": "CyberAgent;KTH Royal Institute of Technology;University of Electro-Communications",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cyberagent.co.jp;https://www.kth.se;https://www.uec.ac.jp",
        "aff_unique_abbr": "CyberAgent;KTH;UEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+1;0;0;0",
        "aff_country_unique": "Japan;Sweden"
    },
    {
        "id": "d969b5677a",
        "title": "Learning Constrained Structured Spaces with Application to Multi-Graph Matching",
        "site": "https://proceedings.mlr.press/v206/indelman23a.html",
        "author": "Hedda Cohen Indelman; Tamir Hazan",
        "abstract": "Multi-graph matching is a prominent structured prediction task, in which the predicted label is constrained to the space of cycle-consistent matchings. While direct loss minimization is an effective method for learning predictors over structured label spaces, it cannot be applied efficiently to the problem at hand, since executing a specialized solver across sets of matching predictions is computationally prohibitive. Moreover, there\u2019s no supervision on the ground-truth matchings over cycle-consistent prediction sets. Our key insight is to strictly enforce the matching constraints in pairwise matching predictions and softly enforce the cycle-consistency constraints by casting them as weighted loss terms, such that the severity of inconsistency with global predictions is tuned by a penalty parameter. Inspired by the classic penalty method, we prove that our method theoretically recovers the optimal multi-graph matching constrained solution. Our method\u2019s advantages are brought to light in experimental results on the popular keypoint matching task on the Pascal VOC and the Willow ObjectClass datasets.",
        "bibtex": "@InProceedings{pmlr-v206-indelman23a,\n  title = \t {Learning Constrained Structured Spaces with Application to Multi-Graph Matching},\n  author =       {Indelman, Hedda Cohen and Hazan, Tamir},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2589--2602},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/indelman23a/indelman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/indelman23a.html},\n  abstract = \t {Multi-graph matching is a prominent structured prediction task, in which the predicted label is constrained to the space of cycle-consistent matchings. While direct loss minimization is an effective method for learning predictors over structured label spaces, it cannot be applied efficiently to the problem at hand, since executing a specialized solver across sets of matching predictions is computationally prohibitive. Moreover, there\u2019s no supervision on the ground-truth matchings over cycle-consistent prediction sets. Our key insight is to strictly enforce the matching constraints in pairwise matching predictions and softly enforce the cycle-consistency constraints by casting them as weighted loss terms, such that the severity of inconsistency with global predictions is tuned by a penalty parameter. Inspired by the classic penalty method, we prove that our method theoretically recovers the optimal multi-graph matching constrained solution. Our method\u2019s advantages are brought to light in experimental results on the popular keypoint matching task on the Pascal VOC and the Willow ObjectClass datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/indelman23a/indelman23a.pdf",
        "supp": "",
        "pdf_size": 1450668,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17636231890070932911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Technion - Israel Institute of Technology; Technion - Israel Institute of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "06980c6c28",
        "title": "Learning Physics-Informed Neural Networks without Stacked Back-propagation",
        "site": "https://proceedings.mlr.press/v206/he23a.html",
        "author": "Di He; Shanda Li; Wenlei Shi; Xiaotian Gao; Jia Zhang; Jiang Bian; Liwei Wang; Tie-Yan Liu",
        "abstract": "Physics-Informed Neural Network (PINN) has become a commonly used machine learning approach to solve partial differential equations (PDE). But, facing high-dimensional secondorder PDE problems, PINN will suffer from severe scalability issues since its loss includes second-order derivatives, the computational cost of which will grow along with the dimension during stacked back-propagation. In this work, we develop a novel approach that can significantly accelerate the training of Physics-Informed Neural Networks. In particular, we parameterize the PDE solution by the Gaussian smoothed model and show that, derived from Stein\u2019s Identity, the second-order derivatives can be efficiently calculated without back-propagation. We further discuss the model capacity and provide variance reduction methods to address key limitations in the derivative estimation. Experimental results show that our proposed method can achieve competitive error compared to standard PINN training but is significantly faster.",
        "bibtex": "@InProceedings{pmlr-v206-he23a,\n  title = \t {Learning Physics-Informed Neural Networks without Stacked Back-propagation},\n  author =       {He, Di and Li, Shanda and Shi, Wenlei and Gao, Xiaotian and Zhang, Jia and Bian, Jiang and Wang, Liwei and Liu, Tie-Yan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3034--3047},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/he23a/he23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/he23a.html},\n  abstract = \t {Physics-Informed Neural Network (PINN) has become a commonly used machine learning approach to solve partial differential equations (PDE). But, facing high-dimensional secondorder PDE problems, PINN will suffer from severe scalability issues since its loss includes second-order derivatives, the computational cost of which will grow along with the dimension during stacked back-propagation. In this work, we develop a novel approach that can significantly accelerate the training of Physics-Informed Neural Networks. In particular, we parameterize the PDE solution by the Gaussian smoothed model and show that, derived from Stein\u2019s Identity, the second-order derivatives can be efficiently calculated without back-propagation. We further discuss the model capacity and provide variance reduction methods to address key limitations in the derivative estimation. Experimental results show that our proposed method can achieve competitive error compared to standard PINN training but is significantly faster.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/he23a/he23a.pdf",
        "supp": "",
        "pdf_size": 1162890,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11026790489007743122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a909aa2a06",
        "title": "Learning Robust Graph Neural Networks with Limited Supervision",
        "site": "https://proceedings.mlr.press/v206/alchihabi23a.html",
        "author": "Abdullah Alchihabi; Yuhong Guo",
        "abstract": "Graph Neural Networks (GNNs) require a relatively large number of labeled nodes and a reliable/uncorrupted graph connectivity structure to obtain good performance on the semi-supervised node classification task. The performance of GNNs can degrade significantly as the number of labeled nodes decreases or the graph connectivity structure is corrupted by adversarial attacks or noise in data measurement/collection. Therefore, it is important to develop GNN models that are able to achieve good performance when there is limited supervision knowledge\u2013a few labeled nodes and a noisy graph structure. In this paper, we propose a novel Dual GNN learning framework to address this challenging task. The proposed framework has two GNN based node prediction modules. The primary module uses the input graph structure to induce typical node embeddings and predictions with a regular GNN baseline, while the auxiliary module constructs a new graph structure through fine-grained spectral clustering and learns new node embeddings and predictions. By integrating the two modules in a dual GNN learning framework, we perform joint learning in an end-to-end fashion. This general framework can be applied on many GNN baseline models. The experimental results show that the proposed dual GNN framework can greatly outperform the GNN baseline methods and yield superior performance over many state-of-the-art methods when the labeled nodes are scarce and the graph connectivity structure is noisy.",
        "bibtex": "@InProceedings{pmlr-v206-alchihabi23a,\n  title = \t {Learning Robust Graph Neural Networks with Limited Supervision},\n  author =       {Alchihabi, Abdullah and Guo, Yuhong},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8723--8733},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/alchihabi23a/alchihabi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/alchihabi23a.html},\n  abstract = \t {Graph Neural Networks (GNNs) require a relatively large number of labeled nodes and a reliable/uncorrupted graph connectivity structure to obtain good performance on the semi-supervised node classification task. The performance of GNNs can degrade significantly as the number of labeled nodes decreases or the graph connectivity structure is corrupted by adversarial attacks or noise in data measurement/collection. Therefore, it is important to develop GNN models that are able to achieve good performance when there is limited supervision knowledge\u2013a few labeled nodes and a noisy graph structure. In this paper, we propose a novel Dual GNN learning framework to address this challenging task. The proposed framework has two GNN based node prediction modules. The primary module uses the input graph structure to induce typical node embeddings and predictions with a regular GNN baseline, while the auxiliary module constructs a new graph structure through fine-grained spectral clustering and learns new node embeddings and predictions. By integrating the two modules in a dual GNN learning framework, we perform joint learning in an end-to-end fashion. This general framework can be applied on many GNN baseline models. The experimental results show that the proposed dual GNN framework can greatly outperform the GNN baseline methods and yield superior performance over many state-of-the-art methods when the labeled nodes are scarce and the graph connectivity structure is noisy.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/alchihabi23a/alchihabi23a.pdf",
        "supp": "",
        "pdf_size": 5543691,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2404048908129576094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "School of Computer Science, Carleton University, Ottawa, Canada+Canada CIFAR AI Chair, Amii, Canada; School of Computer Science, Carleton University, Ottawa, Canada+Canada CIFAR AI Chair, Amii, Canada",
        "aff_domain": "cmail.carleton.ca;carleton.ca",
        "email": "cmail.carleton.ca;carleton.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Carleton University;Amii",
        "aff_unique_dep": "School of Computer Science;Canada CIFAR AI Chair",
        "aff_unique_url": "https://carleton.ca;",
        "aff_unique_abbr": "Carleton;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ottawa;",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "1557809f71",
        "title": "Learning Sparse Graphon Mean Field Games",
        "site": "https://proceedings.mlr.press/v206/fabian23a.html",
        "author": "Christian Fabian; Kai Cui; Heinz Koeppl",
        "abstract": "Although the field of multi-agent reinforcement learning (MARL) has made considerable progress in the last years, solving systems with a large number of agents remains a hard challenge. Graphon mean field games (GMFGs) enable the scalable analysis of MARL problems that are otherwise intractable. By the mathematical structure of graphons, this approach is limited to dense graphs which are insufficient to describe many real-world networks such as power law graphs. Our paper introduces a novel formulation of GMFGs, called LPGMFGs, which leverages the graph theoretical concept of $L^p$ graphons and provides a machine learning tool to efficiently and accurately approximate solutions for sparse network problems. This especially includes power law networks which are empirically observed in various application areas and cannot be captured by standard graphons. We derive theoretical existence and convergence guarantees and give empirical examples that demonstrate the accuracy of our learning approach for systems with many agents. Furthermore, we extend the Online Mirror Descent (OMD) learning algorithm to our setup to accelerate learning speed, empirically show its capabilities, and conduct a theoretical analysis using the novel concept of smoothed step graphons. In general, we provide a scalable, mathematically well-founded machine learning approach to a large class of otherwise intractable problems of great relevance in numerous research fields.",
        "bibtex": "@InProceedings{pmlr-v206-fabian23a,\n  title = \t {Learning Sparse Graphon Mean Field Games},\n  author =       {Fabian, Christian and Cui, Kai and Koeppl, Heinz},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4486--4514},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/fabian23a/fabian23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/fabian23a.html},\n  abstract = \t {Although the field of multi-agent reinforcement learning (MARL) has made considerable progress in the last years, solving systems with a large number of agents remains a hard challenge. Graphon mean field games (GMFGs) enable the scalable analysis of MARL problems that are otherwise intractable. By the mathematical structure of graphons, this approach is limited to dense graphs which are insufficient to describe many real-world networks such as power law graphs. Our paper introduces a novel formulation of GMFGs, called LPGMFGs, which leverages the graph theoretical concept of $L^p$ graphons and provides a machine learning tool to efficiently and accurately approximate solutions for sparse network problems. This especially includes power law networks which are empirically observed in various application areas and cannot be captured by standard graphons. We derive theoretical existence and convergence guarantees and give empirical examples that demonstrate the accuracy of our learning approach for systems with many agents. Furthermore, we extend the Online Mirror Descent (OMD) learning algorithm to our setup to accelerate learning speed, empirically show its capabilities, and conduct a theoretical analysis using the novel concept of smoothed step graphons. In general, we provide a scalable, mathematically well-founded machine learning approach to a large class of otherwise intractable problems of great relevance in numerous research fields.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/fabian23a/fabian23a.pdf",
        "supp": "",
        "pdf_size": 2302306,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3979285570805651534&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "317c85d802",
        "title": "Learning Treatment Effects from Observational and Experimental Data",
        "site": "https://proceedings.mlr.press/v206/triantafillou23a.html",
        "author": "Sofia Triantafillou; Fattaneh Jabbari; Gregory F. Cooper",
        "abstract": "Decision making often depends on causal effect estimation. For example, clinical decisions are often based on estimates of the probability of post-treatment outcomes. Experimental data from randomized controlled trials allow for unbiased estimation of these probabilities. However, such data are usually limited in the number of samples and the set of measured covariates. Observational data, such as electronic medical records, contain many more samples and a richer set of measured covariates, which can be used to estimate more personalized treatment effects; however, these estimates may be biased due to latent confounding. In this work, we propose a Bayesian method for combining observational and experimental data for unbiased conditional treatment effect estimation. Our method addresses the following question: Given observational data $D_o$ measuring a set of covariates $\\mathbf V$, and experimental data $D_e$ measuring a possibly smaller set of covariates $\\mathbf{V_b}\\subseteq \\mathbf{V}$, which set of covariates $\\mathbf{Z}$ leads to the optimal, unbiased prediction of the post-intervention outcome $P(Y |do(X), \\mathbf{Z})$, and when can we use observational data for this estimation? In simulated data, we show that our method improves the prediction of post-intervention outcomes.",
        "bibtex": "@InProceedings{pmlr-v206-triantafillou23a,\n  title = \t {Learning Treatment Effects from Observational and Experimental Data},\n  author =       {Triantafillou, Sofia and Jabbari, Fattaneh and Cooper, Gregory F.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7126--7146},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/triantafillou23a/triantafillou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/triantafillou23a.html},\n  abstract = \t {Decision making often depends on causal effect estimation. For example, clinical decisions are often based on estimates of the probability of post-treatment outcomes. Experimental data from randomized controlled trials allow for unbiased estimation of these probabilities. However, such data are usually limited in the number of samples and the set of measured covariates. Observational data, such as electronic medical records, contain many more samples and a richer set of measured covariates, which can be used to estimate more personalized treatment effects; however, these estimates may be biased due to latent confounding. In this work, we propose a Bayesian method for combining observational and experimental data for unbiased conditional treatment effect estimation. Our method addresses the following question: Given observational data $D_o$ measuring a set of covariates $\\mathbf V$, and experimental data $D_e$ measuring a possibly smaller set of covariates $\\mathbf{V_b}\\subseteq \\mathbf{V}$, which set of covariates $\\mathbf{Z}$ leads to the optimal, unbiased prediction of the post-intervention outcome $P(Y |do(X), \\mathbf{Z})$, and when can we use observational data for this estimation? In simulated data, we show that our method improves the prediction of post-intervention outcomes.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/triantafillou23a/triantafillou23a.pdf",
        "supp": "",
        "pdf_size": 752465,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3897534873550719553&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a5a47c6e3d",
        "title": "Learning While Scheduling in Multi-Server Systems With Unknown Statistics: MaxWeight with Discounted UCB",
        "site": "https://proceedings.mlr.press/v206/yang23d.html",
        "author": "Zixian Yang; R. Srikant; Lei Ying",
        "abstract": "Multi-server queueing systems are widely used models for job scheduling in machine learning, wireless networks, and crowdsourcing. This paper considers a multi-server system with multiple servers and multiple types of jobs, where different job types require different amounts of processing time at different servers. The goal is to schedule jobs on servers without knowing the statistics of the processing times. To fully utilize the processing power of the servers, it is known that one has to at least learn the service rates of different job types on different servers. Prior works on this topic decouple the learning and scheduling phases which leads to either excessive exploration or extremely large job delays. We propose a new algorithm, which combines the MaxWeight scheduling policy with discounted upper confidence bound (UCB), to simultaneously learn the statistics and schedule jobs to servers. We obtain performance bounds for our algorithm that hold for both stationary and nonstationary service rates. Simulations confirm that the delay performance of our algorithm is several orders of magnitude better than previously proposed algorithms. Our algorithm also has the added benefit that it can handle non-stationarity in the service processes.",
        "bibtex": "@InProceedings{pmlr-v206-yang23d,\n  title = \t {Learning While Scheduling in Multi-Server Systems With Unknown Statistics: MaxWeight with Discounted UCB},\n  author =       {Yang, Zixian and Srikant, R. and Ying, Lei},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4275--4312},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23d/yang23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23d.html},\n  abstract = \t {Multi-server queueing systems are widely used models for job scheduling in machine learning, wireless networks, and crowdsourcing. This paper considers a multi-server system with multiple servers and multiple types of jobs, where different job types require different amounts of processing time at different servers. The goal is to schedule jobs on servers without knowing the statistics of the processing times. To fully utilize the processing power of the servers, it is known that one has to at least learn the service rates of different job types on different servers. Prior works on this topic decouple the learning and scheduling phases which leads to either excessive exploration or extremely large job delays. We propose a new algorithm, which combines the MaxWeight scheduling policy with discounted upper confidence bound (UCB), to simultaneously learn the statistics and schedule jobs to servers. We obtain performance bounds for our algorithm that hold for both stationary and nonstationary service rates. Simulations confirm that the delay performance of our algorithm is several orders of magnitude better than previously proposed algorithms. Our algorithm also has the added benefit that it can handle non-stationarity in the service processes.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23d/yang23d.pdf",
        "supp": "",
        "pdf_size": 6434102,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16589693161726194354&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9a92534640",
        "title": "Learning from Multiple Sources for Data-to-Text and Text-to-Data",
        "site": "https://proceedings.mlr.press/v206/duong23a.html",
        "author": "Song Duong; Alberto Lumbreras; Mike Gartrell; Patrick Gallinari",
        "abstract": "Data-to-text (D2T) and text-to-data (T2D) are dual tasks that convert structured data, such as graphs or tables into fluent text, and vice versa. These tasks are usually handled separately and use corpora extracted from a single source. Current systems leverage pre-trained language models fine-tuned on D2T or T2D tasks. This approach has two main limitations: first, a separate system has to be tuned for each task and source; second, learning is limited by the scarcity of available corpora. This paper considers a more general scenario where data are available from multiple heterogeneous sources. Each source, with its specific data format and semantic domain, provides a non-parallel corpus of text and structured data. We introduce a variational auto-encoder model with disentangled style and content variables that allows us to represent the diversity that stems from multiple sources of text and data. Our model is designed to handle the tasks of D2T and T2D jointly. We evaluate our model on several datasets, and show that by learning from multiple sources, our model closes the performance gap with its supervised single-source counterpart and outperforms it in some cases.",
        "bibtex": "@InProceedings{pmlr-v206-duong23a,\n  title = \t {Learning from Multiple Sources for Data-to-Text and Text-to-Data},\n  author =       {Duong, Song and Lumbreras, Alberto and Gartrell, Mike and Gallinari, Patrick},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3733--3753},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/duong23a/duong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/duong23a.html},\n  abstract = \t {Data-to-text (D2T) and text-to-data (T2D) are dual tasks that convert structured data, such as graphs or tables into fluent text, and vice versa. These tasks are usually handled separately and use corpora extracted from a single source. Current systems leverage pre-trained language models fine-tuned on D2T or T2D tasks. This approach has two main limitations: first, a separate system has to be tuned for each task and source; second, learning is limited by the scarcity of available corpora. This paper considers a more general scenario where data are available from multiple heterogeneous sources. Each source, with its specific data format and semantic domain, provides a non-parallel corpus of text and structured data. We introduce a variational auto-encoder model with disentangled style and content variables that allows us to represent the diversity that stems from multiple sources of text and data. Our model is designed to handle the tasks of D2T and T2D jointly. We evaluate our model on several datasets, and show that by learning from multiple sources, our model closes the performance gap with its supervised single-source counterpart and outperforms it in some cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/duong23a/duong23a.pdf",
        "supp": "",
        "pdf_size": 1047736,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16568294791845640340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3829c7295e",
        "title": "Learning in RKHM: a C*-Algebraic Twist for Kernel Machines",
        "site": "https://proceedings.mlr.press/v206/hashimoto23a.html",
        "author": "Yuka Hashimoto; Masahiro Ikeda; Hachem Kadri",
        "abstract": "Supervised learning in reproducing kernel Hilbert space (RKHS) and vector-valued RKHS (vvRKHS) has been investigated for more than 30 years. In this paper, we provide a new twist to this rich literature by generalizing supervised learning in RKHS and vvRKHS to reproducing kernel Hilbert C*-module (RKHM), and show how to construct effective positive-definite kernels by considering the perspective of C*-algebra. Unlike the cases of RKHS and vvRKHS, we can use C*-algebras to enlarge representation spaces. This enables us to construct RKHMs whose representation power goes beyond RKHSs, vvRKHSs, and existing methods such as convolutional neural networks. Our framework is suitable, for example, for effectively analyzing image data by allowing the interaction of Fourier components.",
        "bibtex": "@InProceedings{pmlr-v206-hashimoto23a,\n  title = \t {Learning in RKHM: a C*-Algebraic Twist for Kernel Machines},\n  author =       {Hashimoto, Yuka and Ikeda, Masahiro and Kadri, Hachem},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {692--708},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hashimoto23a/hashimoto23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hashimoto23a.html},\n  abstract = \t {Supervised learning in reproducing kernel Hilbert space (RKHS) and vector-valued RKHS (vvRKHS) has been investigated for more than 30 years. In this paper, we provide a new twist to this rich literature by generalizing supervised learning in RKHS and vvRKHS to reproducing kernel Hilbert C*-module (RKHM), and show how to construct effective positive-definite kernels by considering the perspective of C*-algebra. Unlike the cases of RKHS and vvRKHS, we can use C*-algebras to enlarge representation spaces. This enables us to construct RKHMs whose representation power goes beyond RKHSs, vvRKHSs, and existing methods such as convolutional neural networks. Our framework is suitable, for example, for effectively analyzing image data by allowing the interaction of Fourier components.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hashimoto23a/hashimoto23a.pdf",
        "supp": "",
        "pdf_size": 798951,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9288583655021028647&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fb114ddf47",
        "title": "Learning k-qubit Quantum Operators via Pauli Decomposition",
        "site": "https://proceedings.mlr.press/v206/heidari23a.html",
        "author": "Mohsen Heidari; Wojciech Szpankowski",
        "abstract": "Motivated by the limited qubit capacity of current quantum systems, we study the quantum sample complexity of k-qubit quantum operators, i.e., operations applicable on only k out of d qubits. The problem is studied according to the quantum probably approximately correct (QPAC) model abiding by quantum mechanical laws such as no-cloning, state collapse, and measurement incompatibility. With the delicacy of quantum samples and the richness of quantum operations, one expects a significantly larger quantum sample complexity. This paper proves the contrary. We show that the quantum sample complexity of k-qubit quantum operations is comparable to the classical sample complexity of their counterparts (juntas), at least when $\\frac{k}{d}\\ll 1$. This is surprising, especially since sample duplication is prohibited, and measurement incompatibility would lead to an exponentially larger sample complexity with standard methods. Our approach is based on the Pauli decomposition of quantum operators and a technique called Quantum Shadow Sampling (QSS) to reduce the sample complexity exponentially. The results are proved by developing (i) a connection between the learning loss and the Pauli decomposition; (ii) a scalable QSS circuit for estimating the Pauli coefficients; and (iii) a quantum algorithm for learning $k$-qubit operators with sample complexity $O(\\frac{k4^k}{\\epsilon^2}\\log d)$.",
        "bibtex": "@InProceedings{pmlr-v206-heidari23a,\n  title = \t {Learning k-qubit Quantum Operators via Pauli Decomposition},\n  author =       {Heidari, Mohsen and Szpankowski, Wojciech},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {490--504},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/heidari23a/heidari23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/heidari23a.html},\n  abstract = \t {Motivated by the limited qubit capacity of current quantum systems, we study the quantum sample complexity of k-qubit quantum operators, i.e., operations applicable on only k out of d qubits. The problem is studied according to the quantum probably approximately correct (QPAC) model abiding by quantum mechanical laws such as no-cloning, state collapse, and measurement incompatibility. With the delicacy of quantum samples and the richness of quantum operations, one expects a significantly larger quantum sample complexity. This paper proves the contrary. We show that the quantum sample complexity of k-qubit quantum operations is comparable to the classical sample complexity of their counterparts (juntas), at least when $\\frac{k}{d}\\ll 1$. This is surprising, especially since sample duplication is prohibited, and measurement incompatibility would lead to an exponentially larger sample complexity with standard methods. Our approach is based on the Pauli decomposition of quantum operators and a technique called Quantum Shadow Sampling (QSS) to reduce the sample complexity exponentially. The results are proved by developing (i) a connection between the learning loss and the Pauli decomposition; (ii) a scalable QSS circuit for estimating the Pauli coefficients; and (iii) a quantum algorithm for learning $k$-qubit operators with sample complexity $O(\\frac{k4^k}{\\epsilon^2}\\log d)$.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/heidari23a/heidari23a.pdf",
        "supp": "",
        "pdf_size": 540068,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3148347314589953085&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Indiana University, Bloomington; Purdue University, West Lafayette",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Indiana University;Purdue University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.indiana.edu;https://www.purdue.edu",
        "aff_unique_abbr": "IU;Purdue",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Bloomington;West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d40ca97519",
        "title": "Learning to Defer to Multiple Experts: Consistent Surrogate Losses, Confidence Calibration, and Conformal Ensembles",
        "site": "https://proceedings.mlr.press/v206/verma23a.html",
        "author": "Rajeev Verma; Daniel Barrejon; Eric Nalisnick",
        "abstract": "We study the statistical properties of learning to defer (L2D) to multiple experts. In particular, we address the open problems of deriving a consistent surrogate loss, confidence calibration, and principled ensembling of experts. Firstly, we derive two consistent surrogates\u2014one based on a softmax parameterization, the other on a one-vs-all (OvA) parameterization\u2014that are analogous to the single expert losses proposed by Mozannar and Sontag (2020) and Verma and Nalisnick (2022), respectively. We then study the frameworks\u2019 ability to estimate $P( m_j = y | x )$, the probability that the $j$th expert will correctly predict the label for $x$. Theory shows the softmax-based loss causes mis-calibration to propagate between the estimates while the OvA-based loss does not (though in practice, we find there are trade offs). Lastly, we propose a conformal inference technique that chooses a subset of experts to query when the system defers. We perform empirical validation on tasks for galaxy, skin lesion, and hate speech classification.",
        "bibtex": "@InProceedings{pmlr-v206-verma23a,\n  title = \t {Learning to Defer to Multiple Experts: Consistent Surrogate Losses, Confidence Calibration, and Conformal Ensembles},\n  author =       {Verma, Rajeev and Barrejon, Daniel and Nalisnick, Eric},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11415--11434},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/verma23a/verma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/verma23a.html},\n  abstract = \t {We study the statistical properties of learning to defer (L2D) to multiple experts. In particular, we address the open problems of deriving a consistent surrogate loss, confidence calibration, and principled ensembling of experts. Firstly, we derive two consistent surrogates\u2014one based on a softmax parameterization, the other on a one-vs-all (OvA) parameterization\u2014that are analogous to the single expert losses proposed by Mozannar and Sontag (2020) and Verma and Nalisnick (2022), respectively. We then study the frameworks\u2019 ability to estimate $P( m_j = y | x )$, the probability that the $j$th expert will correctly predict the label for $x$. Theory shows the softmax-based loss causes mis-calibration to propagate between the estimates while the OvA-based loss does not (though in practice, we find there are trade offs). Lastly, we propose a conformal inference technique that chooses a subset of experts to query when the system defers. We perform empirical validation on tasks for galaxy, skin lesion, and hate speech classification.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/verma23a/verma23a.pdf",
        "supp": "",
        "pdf_size": 563957,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10635637207864033919&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Amsterdam; Universidad Carlos III de Madrid; University of Amsterdam",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Amsterdam;Universidad Carlos III de Madrid",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uva.nl;https://www.uc3m.es",
        "aff_unique_abbr": "UvA;UC3M",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Netherlands;Spain"
    },
    {
        "id": "4ccb60869f",
        "title": "Learning to Generalize Provably in Learning to Optimize",
        "site": "https://proceedings.mlr.press/v206/yang23h.html",
        "author": "Junjie Yang; Tianlong Chen; Mingkang Zhu; Fengxiang He; Dacheng Tao; Yingbin Liang; Zhangyang Wang",
        "abstract": "Learning to optimize (L2O) has gained increasing popularity, which automates the design of optimizers by data-driven approaches. However, current L2O methods often suffer from poor generalization performance in at least two folds: (i) applying the L2O-learned optimizer to unseen optimizees, in terms of lowering their loss function values (optimizer generalization, or \u201cgeneralizable learning of optimizers\u201d); and (ii) the test performance of an optimizee (itself as a machine learning model), trained by the optimizer, in terms of the accuracy over unseen data (optimizee generalization, or \u201clearning to generalize\u201d). While the optimizer generalization has been recently studied, the optimizee generalization (or learning to generalize) has not been rigorously studied in the L2O context, which is the aim of this paper. We first theoretically establish an implicit connection between the local entropy and the Hessian, and hence unify their roles in the handcrafted design of generalizable optimizers as equivalent metrics of the landscape flatness of loss functions. We then propose to incorporate these two metrics as flatness-aware regularizers into the L2O framework in order to meta-train optimizers to learn to generalize, and theoretically show that such generalization ability can be learned during the L2O meta-training process and then transformed to the optimizee loss function. Extensive experiments consistently validate the effectiveness of our proposals with substantially improved generalization on multiple sophisticated L2O models and diverse optimizees.",
        "bibtex": "@InProceedings{pmlr-v206-yang23h,\n  title = \t {Learning to Generalize Provably in Learning to Optimize},\n  author =       {Yang, Junjie and Chen, Tianlong and Zhu, Mingkang and He, Fengxiang and Tao, Dacheng and Liang, Yingbin and Wang, Zhangyang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9807--9825},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23h/yang23h.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23h.html},\n  abstract = \t {Learning to optimize (L2O) has gained increasing popularity, which automates the design of optimizers by data-driven approaches. However, current L2O methods often suffer from poor generalization performance in at least two folds: (i) applying the L2O-learned optimizer to unseen optimizees, in terms of lowering their loss function values (optimizer generalization, or \u201cgeneralizable learning of optimizers\u201d); and (ii) the test performance of an optimizee (itself as a machine learning model), trained by the optimizer, in terms of the accuracy over unseen data (optimizee generalization, or \u201clearning to generalize\u201d). While the optimizer generalization has been recently studied, the optimizee generalization (or learning to generalize) has not been rigorously studied in the L2O context, which is the aim of this paper. We first theoretically establish an implicit connection between the local entropy and the Hessian, and hence unify their roles in the handcrafted design of generalizable optimizers as equivalent metrics of the landscape flatness of loss functions. We then propose to incorporate these two metrics as flatness-aware regularizers into the L2O framework in order to meta-train optimizers to learn to generalize, and theoretically show that such generalization ability can be learned during the L2O meta-training process and then transformed to the optimizee loss function. Extensive experiments consistently validate the effectiveness of our proposals with substantially improved generalization on multiple sophisticated L2O models and diverse optimizees.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23h/yang23h.pdf",
        "supp": "",
        "pdf_size": 5534735,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9414656890693011556&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "The Ohio State University; UT Austin; UT Austin; JD Explore Academy; JD Explore Academy; The Ohio State University; UT Austin",
        "aff_domain": "; ; ; ; ; ; ",
        "email": "; ; ; ; ; ; ",
        "github": "https://github.com/VITA-Group/Open-L2O/tree/main/Model_Free_L2O/L2O-Entropy",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2;2;0;1",
        "aff_unique_norm": "Ohio State University;University of Texas at Austin;JD",
        "aff_unique_dep": ";;JD Explore Academy",
        "aff_unique_url": "https://www.osu.edu;https://www.utexas.edu;",
        "aff_unique_abbr": "OSU;UT Austin;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "779093a51e",
        "title": "Learning to Optimize with Stochastic Dominance Constraints",
        "site": "https://proceedings.mlr.press/v206/dai23b.html",
        "author": "Hanjun Dai; Yuan Xue; Niao He; Yixin Wang; Na Li; Dale Schuurmans; Bo Dai",
        "abstract": "In real-world decision-making, uncertainty is important yet difficult to handle. Stochastic dominance provides a theoretically sound approach to comparing uncertain quantities, but optimization with stochastic dominance constraints is often computationally expensive, which limits practical applicability. In this paper, we develop a simple yet efficient approach for the problem, Light Stochastic Dominance Solver (light-SD), by leveraging properties of the Lagrangian. We recast the inner optimization in the Lagrangian as a learning problem for surrogate approximation, which bypasses the intractability and leads to tractable updates or even closed-form solutions for gradient calculations. We prove convergence of the algorithm and test it empirically. The proposed light-SD demonstrates superior performance on several representative problems ranging from finance to supply chain management.",
        "bibtex": "@InProceedings{pmlr-v206-dai23b,\n  title = \t {Learning to Optimize with Stochastic Dominance Constraints},\n  author =       {Dai, Hanjun and Xue, Yuan and He, Niao and Wang, Yixin and Li, Na and Schuurmans, Dale and Dai, Bo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8991--9009},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dai23b/dai23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dai23b.html},\n  abstract = \t {In real-world decision-making, uncertainty is important yet difficult to handle. Stochastic dominance provides a theoretically sound approach to comparing uncertain quantities, but optimization with stochastic dominance constraints is often computationally expensive, which limits practical applicability. In this paper, we develop a simple yet efficient approach for the problem, Light Stochastic Dominance Solver (light-SD), by leveraging properties of the Lagrangian. We recast the inner optimization in the Lagrangian as a learning problem for surrogate approximation, which bypasses the intractability and leads to tractable updates or even closed-form solutions for gradient calculations. We prove convergence of the algorithm and test it empirically. The proposed light-SD demonstrates superior performance on several representative problems ranging from finance to supply chain management.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dai23b/dai23b.pdf",
        "supp": "",
        "pdf_size": 1210981,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18060744210269185379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f3b7cb86fe",
        "title": "Learning with Partial Forgetting in Modern Hopfield Networks",
        "site": "https://proceedings.mlr.press/v206/ota23a.html",
        "author": "Toshihiro Ota; Ikuro Sato; Rei Kawakami; Masayuki Tanaka; Nakamasa Inoue",
        "abstract": "It has been known by neuroscience studies that partial and transient forgetting of memory often plays an important role in the brain to improve performance for certain intellectual activities. In machine learning, associative memory models such as classical and modern Hopfield networks have been proposed to express memories as attractors in the feature space of a closed recurrent network. In this work, we propose learning with partial forgetting (LwPF), where a partial forgetting functionality is designed by element-wise non-bijective projections, for memory neurons in modern Hopfield networks to improve model performance. We incorporate LwPF into the attention mechanism also, whose process has been shown to be identical to the update rule of a certain modern Hopfield network, by modifying the corresponding Lagrangian. We evaluated the effectiveness of LwPF on three diverse tasks such as bit-pattern classification, immune repertoire classification for computational biology, and image classification for computer vision, and confirmed that LwPF consistently improves the performance of existing neural networks including DeepRC and vision transformers.",
        "bibtex": "@InProceedings{pmlr-v206-ota23a,\n  title = \t {Learning with Partial Forgetting in Modern Hopfield Networks},\n  author =       {Ota, Toshihiro and Sato, Ikuro and Kawakami, Rei and Tanaka, Masayuki and Inoue, Nakamasa},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6661--6673},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ota23a/ota23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ota23a.html},\n  abstract = \t {It has been known by neuroscience studies that partial and transient forgetting of memory often plays an important role in the brain to improve performance for certain intellectual activities. In machine learning, associative memory models such as classical and modern Hopfield networks have been proposed to express memories as attractors in the feature space of a closed recurrent network. In this work, we propose learning with partial forgetting (LwPF), where a partial forgetting functionality is designed by element-wise non-bijective projections, for memory neurons in modern Hopfield networks to improve model performance. We incorporate LwPF into the attention mechanism also, whose process has been shown to be identical to the update rule of a certain modern Hopfield network, by modifying the corresponding Lagrangian. We evaluated the effectiveness of LwPF on three diverse tasks such as bit-pattern classification, immune repertoire classification for computational biology, and image classification for computer vision, and confirmed that LwPF consistently improves the performance of existing neural networks including DeepRC and vision transformers.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ota23a/ota23a.pdf",
        "supp": "",
        "pdf_size": 997744,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7363005398623500219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Tokyo Institute of Technology; Tokyo Institute of Technology+Denso IT Lab, Inc.; Tokyo Institute of Technology; Tokyo Institute of Technology; Tokyo Institute of Technology",
        "aff_domain": "tokyo-tech.ac.jp;tokyo-tech.ac.jp;tokyo-tech.ac.jp;tokyo-tech.ac.jp;tokyo-tech.ac.jp",
        "email": "tokyo-tech.ac.jp;tokyo-tech.ac.jp;tokyo-tech.ac.jp;tokyo-tech.ac.jp;tokyo-tech.ac.jp",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Denso IT Lab, Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.denso.com",
        "aff_unique_abbr": "Titech;Denso IT Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "df0eb023f4",
        "title": "Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision",
        "site": "https://proceedings.mlr.press/v206/zhang23a.html",
        "author": "Jieyu Zhang; Linxin Song; Alex Ratner",
        "abstract": "Programmatic Weak Supervision (PWS) has emerged as a widespread paradigm to synthesize training labels efficiently. The core component of PWS is the label model, which infers true labels by aggregating the outputs of multiple noisy supervision sources abstracted as labeling functions (LFs). Existing statistical label models typically rely only on the outputs of LF, ignoring the instance features when modeling the underlying generative process. In this paper, we attempt to incorporate the instance features into a statistical label model via the proposed FABLE. In particular, it is built on a mixture of Bayesian label models, each corresponding to a global pattern of correlation, and the coefficients of the mixture components are predicted by a Gaussian Process classifier based on instance features. We adopt an auxiliary variable-based variational inference algorithm to tackle the non-conjugate issue between the Gaussian Process and Bayesian label models. Extensive empirical comparison on eleven benchmark datasets sees FABLE achieving the highest averaged performance across nine baselines. Our implementation of FABLE can be found in https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/fable.py.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23a,\n  title = \t {Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision},\n  author =       {Zhang, Jieyu and Song, Linxin and Ratner, Alex},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {157--171},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23a/zhang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23a.html},\n  abstract = \t {Programmatic Weak Supervision (PWS) has emerged as a widespread paradigm to synthesize training labels efficiently. The core component of PWS is the label model, which infers true labels by aggregating the outputs of multiple noisy supervision sources abstracted as labeling functions (LFs). Existing statistical label models typically rely only on the outputs of LF, ignoring the instance features when modeling the underlying generative process. In this paper, we attempt to incorporate the instance features into a statistical label model via the proposed FABLE. In particular, it is built on a mixture of Bayesian label models, each corresponding to a global pattern of correlation, and the coefficients of the mixture components are predicted by a Gaussian Process classifier based on instance features. We adopt an auxiliary variable-based variational inference algorithm to tackle the non-conjugate issue between the Gaussian Process and Bayesian label models. Extensive empirical comparison on eleven benchmark datasets sees FABLE achieving the highest averaged performance across nine baselines. Our implementation of FABLE can be found in https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/fable.py.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23a/zhang23a.pdf",
        "supp": "",
        "pdf_size": 1135634,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3650403724227990603&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Washington; Waseda University; University of Washington",
        "aff_domain": ";;",
        "email": ";;",
        "github": "https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/fable.py",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Washington;Waseda University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.washington.edu;https://www.waseda.jp/top",
        "aff_unique_abbr": "UW;Waseda",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "3faf25e15a",
        "title": "Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation",
        "site": "https://proceedings.mlr.press/v206/zhu23d.html",
        "author": "Yaxuan Zhu; Jianwen Xie; Ping Li",
        "abstract": "We propose the NeRF-LEBM, a likelihoodbased top-down 3D-aware 2D image generative model that incorporates 3D representation via Neural Radiance Fields (NeRF) and 2D imaging process via differentiable volume rendering. The model represents an image as a rendering process from 3D object to 2D image and is conditioned on some latent variables that account for object characteristics and are assumed to follow informative trainable energy-based prior models. We propose two likelihood-based learning frameworks to train the NeRF-LEBM: (i) maximum likelihood estimation with Markov chain Monte Carlo-based inference and (ii) variational inference with the reparameterization trick. We study our models in the scenarios with both known and unknown camera poses. Experiments on several benchmark datasets demonstrate that the NeRF-LEBM can infer 3D object structures from 2D images, generate 2D images with novel views and objects, learn from incomplete 2D images, and learn from 2D images with known or unknown camera poses.",
        "bibtex": "@InProceedings{pmlr-v206-zhu23d,\n  title = \t {Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation},\n  author =       {Zhu, Yaxuan and Xie, Jianwen and Li, Ping},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4164--4180},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhu23d/zhu23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhu23d.html},\n  abstract = \t {We propose the NeRF-LEBM, a likelihoodbased top-down 3D-aware 2D image generative model that incorporates 3D representation via Neural Radiance Fields (NeRF) and 2D imaging process via differentiable volume rendering. The model represents an image as a rendering process from 3D object to 2D image and is conditioned on some latent variables that account for object characteristics and are assumed to follow informative trainable energy-based prior models. We propose two likelihood-based learning frameworks to train the NeRF-LEBM: (i) maximum likelihood estimation with Markov chain Monte Carlo-based inference and (ii) variational inference with the reparameterization trick. We study our models in the scenarios with both known and unknown camera poses. Experiments on several benchmark datasets demonstrate that the NeRF-LEBM can infer 3D object structures from 2D images, generate 2D images with novel views and objects, learn from incomplete 2D images, and learn from 2D images with known or unknown camera poses.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhu23d/zhu23d.pdf",
        "supp": "",
        "pdf_size": 8888260,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8312333401492025425&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Statistics, University of California - UCLA; Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research",
        "aff_domain": "ucla.edu;gmail.com;gmail.com",
        "email": "ucla.edu;gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Los Angeles;Baidu",
        "aff_unique_dep": "Department of Statistics;Cognitive Computing Lab",
        "aff_unique_url": "https://www.ucla.edu;https://baidu.com",
        "aff_unique_abbr": "UCLA;Baidu",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "de5e41493a",
        "title": "Linear Convergence of Gradient Descent For Finite Width Over-parametrized Linear Networks With General Initialization",
        "site": "https://proceedings.mlr.press/v206/xu23c.html",
        "author": "Ziqing Xu; Hancheng Min; Salma Tarmoun; Enrique Mallada; Rene Vidal",
        "abstract": "Recent theoretical analyses of the convergence of gradient descent (GD) to a global minimum for over-parametrized neural networks make strong assumptions on the step size (infinitesimal), the hidden-layer width (infinite), or the initialization (spectral, balanced). In this work, we relax these assumptions and derive a linear convergence rate for two-layer linear networks trained using GD on the squared loss in the case of finite step size, finite width and general initialization. Despite the generality of our analysis, our rate estimates are significantly tighter than those of prior work. Moreover, we provide a time-varying step size rule that monotonically improves the convergence rate as the loss function decreases to zero. Numerical experiments validate our findings.",
        "bibtex": "@InProceedings{pmlr-v206-xu23c,\n  title = \t {Linear Convergence of Gradient Descent For Finite Width Over-parametrized Linear Networks With General Initialization},\n  author =       {Xu, Ziqing and Min, Hancheng and Tarmoun, Salma and Mallada, Enrique and Vidal, Rene},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2262--2284},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23c/xu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23c.html},\n  abstract = \t {Recent theoretical analyses of the convergence of gradient descent (GD) to a global minimum for over-parametrized neural networks make strong assumptions on the step size (infinitesimal), the hidden-layer width (infinite), or the initialization (spectral, balanced). In this work, we relax these assumptions and derive a linear convergence rate for two-layer linear networks trained using GD on the squared loss in the case of finite step size, finite width and general initialization. Despite the generality of our analysis, our rate estimates are significantly tighter than those of prior work. Moreover, we provide a time-varying step size rule that monotonically improves the convergence rate as the loss function decreases to zero. Numerical experiments validate our findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23c/xu23c.pdf",
        "supp": "",
        "pdf_size": 633039,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7404214242696383494&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; University of Pennsylvania",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Johns Hopkins University;University of Pennsylvania",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.jhu.edu;https://www.upenn.edu",
        "aff_unique_abbr": "JHU;UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bede1246a1",
        "title": "Loss-Curvature Matching for Dataset Selection and Condensation",
        "site": "https://proceedings.mlr.press/v206/shin23a.html",
        "author": "Seungjae Shin; Heesun Bae; Donghyeok Shin; Weonyoung Joo; Il-Chul Moon",
        "abstract": "Training neural networks on a large dataset requires substantial computational costs. Dataset reduction selects or synthesizes data instances based on the large dataset, while minimizing the degradation in generalization performance from the full dataset. Existing methods utilize the neural network during the dataset reduction procedure, so the model parameter becomes important factor in preserving the performance after reduction. By depending upon the importance of parameters, this paper introduces a new reduction objective, coined LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point. This new objective induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching. Particularly, we identify the worst case of the loss curvature gap from the local parameter region, and we derive the implementable upper bound of such worst-case with theoretical analyses. Our experiments on both coreset selection and condensation benchmarks illustrate that LCMat shows better generalization performances than existing baselines.",
        "bibtex": "@InProceedings{pmlr-v206-shin23a,\n  title = \t {Loss-Curvature Matching for Dataset Selection and Condensation},\n  author =       {Shin, Seungjae and Bae, Heesun and Shin, Donghyeok and Joo, Weonyoung and Moon, Il-Chul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8606--8628},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shin23a/shin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shin23a.html},\n  abstract = \t {Training neural networks on a large dataset requires substantial computational costs. Dataset reduction selects or synthesizes data instances based on the large dataset, while minimizing the degradation in generalization performance from the full dataset. Existing methods utilize the neural network during the dataset reduction procedure, so the model parameter becomes important factor in preserving the performance after reduction. By depending upon the importance of parameters, this paper introduces a new reduction objective, coined LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point. This new objective induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching. Particularly, we identify the worst case of the loss curvature gap from the local parameter region, and we derive the implementable upper bound of such worst-case with theoretical analyses. Our experiments on both coreset selection and condensation benchmarks illustrate that LCMat shows better generalization performances than existing baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shin23a/shin23a.pdf",
        "supp": "",
        "pdf_size": 3247859,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11099718331728238892&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "KAIST; KAIST; KAIST; Ewha Womans University; KAIST",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Ewha Womans University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.ewha.ac.kr",
        "aff_unique_abbr": "KAIST;Ewha",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "3ae9f658b0",
        "title": "MARS: Masked Automatic Ranks Selection in Tensor Decompositions",
        "site": "https://proceedings.mlr.press/v206/kodryan23a.html",
        "author": "Maxim Kodryan; Dmitry Kropotov; Dmitry Vetrov",
        "abstract": "Tensor decomposition methods have proven effective in various applications, including compression and acceleration of neural networks. At the same time, the problem of determining optimal decomposition ranks, which present the crucial parameter controlling the compressionaccuracy trade-off, is still acute. In this paper, we introduce MARS - a new efficient method for the automatic selection of ranks in general tensor decompositions. During training, the procedure learns binary masks over decomposition cores that \u201cselect\u201d the optimal tensor structure. The learning is performed via relaxed maximum a posteriori (MAP) estimation in a specific Bayesian model and can be naturally embedded into the standard neural network training routine. Diverse experiments demonstrate that MARS achieves better results compared to previous works in various tasks.",
        "bibtex": "@InProceedings{pmlr-v206-kodryan23a,\n  title = \t {MARS: Masked Automatic Ranks Selection in Tensor Decompositions},\n  author =       {Kodryan, Maxim and Kropotov, Dmitry and Vetrov, Dmitry},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3718--3732},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kodryan23a/kodryan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kodryan23a.html},\n  abstract = \t {Tensor decomposition methods have proven effective in various applications, including compression and acceleration of neural networks. At the same time, the problem of determining optimal decomposition ranks, which present the crucial parameter controlling the compressionaccuracy trade-off, is still acute. In this paper, we introduce MARS - a new efficient method for the automatic selection of ranks in general tensor decompositions. During training, the procedure learns binary masks over decomposition cores that \u201cselect\u201d the optimal tensor structure. The learning is performed via relaxed maximum a posteriori (MAP) estimation in a specific Bayesian model and can be naturally embedded into the standard neural network training routine. Diverse experiments demonstrate that MARS achieves better results compared to previous works in various tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kodryan23a/kodryan23a.pdf",
        "supp": "",
        "pdf_size": 1102460,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10073880872241400589&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "HSE University; Lomonosov Moscow State University; HSE University+AIRI",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2",
        "aff_unique_norm": "Higher School of Economics;Lomonosov Moscow State University;Artificial Intelligence Research Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://hse.ru;https://www.msu.ru;https://www.airi.jp",
        "aff_unique_abbr": "HSE;MSU;AIRI",
        "aff_campus_unique_index": "1;",
        "aff_campus_unique": ";Moscow",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "Russian Federation;Japan"
    },
    {
        "id": "32e47f19bd",
        "title": "MMD-B-Fair: Learning Fair Representations with Statistical Testing",
        "site": "https://proceedings.mlr.press/v206/deka23a.html",
        "author": "Namrata Deka; Danica J. Sutherland",
        "abstract": "We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between different values of sensitive attributes, while preserving information about the target. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold\u2019s complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring the complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to hide information about sensitive attributes, and its effectiveness in downstream transfer tasks.",
        "bibtex": "@InProceedings{pmlr-v206-deka23a,\n  title = \t {MMD-B-Fair: Learning Fair Representations with Statistical Testing},\n  author =       {Deka, Namrata and Sutherland, Danica J.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9564--9576},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/deka23a/deka23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/deka23a.html},\n  abstract = \t {We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between different values of sensitive attributes, while preserving information about the target. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold\u2019s complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring the complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to hide information about sensitive attributes, and its effectiveness in downstream transfer tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/deka23a/deka23a.pdf",
        "supp": "",
        "pdf_size": 1546754,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7310171816056904535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of British Columbia; University of British Columbia & Amii",
        "aff_domain": "cs.ubc.ca;cs.ubc.ca",
        "email": "cs.ubc.ca;cs.ubc.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Vancouver",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "8c014515b2",
        "title": "Manifold Restricted Interventional Shapley Values",
        "site": "https://proceedings.mlr.press/v206/taufiq23a.html",
        "author": "Muhammad Faaiz Taufiq; Patrick Bl\u00f6baum; Lenon Minorics",
        "abstract": "Shapley values are model-agnostic methods for explaining model predictions. Many commonly used methods of computing Shapley values, known as off-manifold methods, rely on model evaluations on out-of-distribution input samples. Consequently, explanations obtained are sensitive to model behaviour outside the data distribution, which may be irrelevant for all practical purposes. While on-manifold methods have been proposed which do not suffer from this problem, we show that such methods are overly dependent on the input data distribution, and therefore result in unintuitive and misleading explanations. To circumvent these problems, we propose ManifoldShap, which respects the model\u2019s domain of validity by restricting model evaluations to the data manifold. We show, theoretically and empirically, that ManifoldShap is robust to off-manifold perturbations of the model and leads to more accurate and intuitive explanations than existing state-of-the-art Shapley methods.",
        "bibtex": "@InProceedings{pmlr-v206-taufiq23a,\n  title = \t {Manifold Restricted Interventional Shapley Values},\n  author =       {Taufiq, Muhammad Faaiz and Bl\\\"obaum, Patrick and Minorics, Lenon},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5079--5106},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/taufiq23a/taufiq23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/taufiq23a.html},\n  abstract = \t {Shapley values are model-agnostic methods for explaining model predictions. Many commonly used methods of computing Shapley values, known as off-manifold methods, rely on model evaluations on out-of-distribution input samples. Consequently, explanations obtained are sensitive to model behaviour outside the data distribution, which may be irrelevant for all practical purposes. While on-manifold methods have been proposed which do not suffer from this problem, we show that such methods are overly dependent on the input data distribution, and therefore result in unintuitive and misleading explanations. To circumvent these problems, we propose ManifoldShap, which respects the model\u2019s domain of validity by restricting model evaluations to the data manifold. We show, theoretically and empirically, that ManifoldShap is robust to off-manifold perturbations of the model and leads to more accurate and intuitive explanations than existing state-of-the-art Shapley methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/taufiq23a/taufiq23a.pdf",
        "supp": "",
        "pdf_size": 2754472,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13493958606625017923&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": "University of Oxford; Amazon Research; Amazon Research",
        "aff_domain": "stats.ox.ac.uk; ; ",
        "email": "stats.ox.ac.uk; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Oxford;Amazon",
        "aff_unique_dep": ";Amazon Research",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.amazon.science",
        "aff_unique_abbr": "Oxford;Amazon",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "8d380e9f3b",
        "title": "Matching Map Recovery with an Unknown Number of Outliers",
        "site": "https://proceedings.mlr.press/v206/minasyan23a.html",
        "author": "Arshak Minasyan; Tigran Galstyan; Sona Hunanyan; Arnak Dalalyan",
        "abstract": "We consider the problem of finding the matching map between two sets of $d$-dimensional noisy feature-vectors. The distinctive feature of our setting is that we do not assume that all the vectors of the first set have their corresponding vector in the second set. If $n$ and $m$ are the sizes of these two sets, we assume that the matching map that should be recovered is defined on a subset of unknown cardinality $k^*\\le \\min(n,m)$. We show that, in the high-dimensional setting, if the signal-to-noise ratio is larger than $5(d\\log(4nm/\\alpha))^{1/4}$, then the true matching map can be recovered with probability $1-\\alpha$. Interestingly, this threshold does not depend on $k^*$ and is the same as the one obtained in prior work in the case of $k = \\min(n,m)$. The procedure for which the aforementioned property is proved is obtained by a data-driven selection among candidate mappings $\\{\\hat\\pi_k:k\\in[\\min(n,m)]\\}$. Each $\\hat\\pi_k$ minimizes the sum of squares of distances between two sets of size $k$. The resulting optimization problem can be formulated as a minimum-cost flow problem, and thus solved efficiently. Finally, we report the results of numerical experiments on both synthetic and real-world data that illustrate our theoretical results and provide further insight into the properties of the algorithms studied in this work.",
        "bibtex": "@InProceedings{pmlr-v206-minasyan23a,\n  title = \t {Matching Map Recovery with an Unknown Number of Outliers},\n  author =       {Minasyan, Arshak and Galstyan, Tigran and Hunanyan, Sona and Dalalyan, Arnak},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {891--906},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/minasyan23a/minasyan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/minasyan23a.html},\n  abstract = \t {We consider the problem of finding the matching map between two sets of $d$-dimensional noisy feature-vectors. The distinctive feature of our setting is that we do not assume that all the vectors of the first set have their corresponding vector in the second set. If $n$ and $m$ are the sizes of these two sets, we assume that the matching map that should be recovered is defined on a subset of unknown cardinality $k^*\\le \\min(n,m)$. We show that, in the high-dimensional setting, if the signal-to-noise ratio is larger than $5(d\\log(4nm/\\alpha))^{1/4}$, then the true matching map can be recovered with probability $1-\\alpha$. Interestingly, this threshold does not depend on $k^*$ and is the same as the one obtained in prior work in the case of $k = \\min(n,m)$. The procedure for which the aforementioned property is proved is obtained by a data-driven selection among candidate mappings $\\{\\hat\\pi_k:k\\in[\\min(n,m)]\\}$. Each $\\hat\\pi_k$ minimizes the sum of squares of distances between two sets of size $k$. The resulting optimization problem can be formulated as a minimum-cost flow problem, and thus solved efficiently. Finally, we report the results of numerical experiments on both synthetic and real-world data that illustrate our theoretical results and provide further insight into the properties of the algorithms studied in this work.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/minasyan23a/minasyan23a.pdf",
        "supp": "",
        "pdf_size": 3325117,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=432014030096618497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "CREST, ENSAE, IP Paris; RAU, YerevaNN + Yerevan State University; Yerevan State University; CREST, ENSAE, IP Paris",
        "aff_domain": "ensae.fr;yerevann.com;gmail.com;ensae.fr",
        "email": "ensae.fr;yerevann.com;gmail.com;ensae.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;2;0",
        "aff_unique_norm": "CREST;Russian-Armenian University;Yerevan State University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.crest.fr;http://www.rau.am;https://www.yerevanstateuniversity.am",
        "aff_unique_abbr": "CREST;RAU;YSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+1;1;0",
        "aff_country_unique": "France;Armenia"
    },
    {
        "id": "759b9f0e78",
        "title": "Mean Parity Fair Regression in RKHS",
        "site": "https://proceedings.mlr.press/v206/wei23a.html",
        "author": "Shaokui Wei; Jiayin Liu; Bing Li; Hongyuan Zha",
        "abstract": "We study the fair regression problem under the notion of Mean Parity (MP) fairness, which requires the conditional mean of the learned function output to be constant with respect to the sensitive attributes. We address this problem by leveraging reproducing kernel Hilbert space (RKHS) to construct the functional space whose members are guaranteed to satisfy the fairness constraints. The proposed functional space suggests a closed-form solution for the fair regression problem that is naturally compatible with multiple sensitive attributes. Furthermore, by formulating the fairness-accuracy tradeoff as a relaxed fair regression problem, we derive a corresponding regression function that can be implemented efficiently and provides interpretable tradeoffs. More importantly, under some mild assumptions, the proposed method can be applied to regression problems with a covariance-based notion of fairness. Experimental results on benchmark datasets show the proposed methods achieve competitive and even superior performance compared with several state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v206-wei23a,\n  title = \t {Mean Parity Fair Regression in RKHS},\n  author =       {Wei, Shaokui and Liu, Jiayin and Li, Bing and Zha, Hongyuan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4602--4628},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wei23a/wei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wei23a.html},\n  abstract = \t {We study the fair regression problem under the notion of Mean Parity (MP) fairness, which requires the conditional mean of the learned function output to be constant with respect to the sensitive attributes. We address this problem by leveraging reproducing kernel Hilbert space (RKHS) to construct the functional space whose members are guaranteed to satisfy the fairness constraints. The proposed functional space suggests a closed-form solution for the fair regression problem that is naturally compatible with multiple sensitive attributes. Furthermore, by formulating the fairness-accuracy tradeoff as a relaxed fair regression problem, we derive a corresponding regression function that can be implemented efficiently and provides interpretable tradeoffs. More importantly, under some mild assumptions, the proposed method can be applied to regression problems with a covariance-based notion of fairness. Experimental results on benchmark datasets show the proposed methods achieve competitive and even superior performance compared with several state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wei23a/wei23a.pdf",
        "supp": "",
        "pdf_size": 2278663,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17328270146434238629&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c8b14219d6",
        "title": "Mediated Uncoupled Learning and Validation with Bregman Divergences: Loss Family with Maximal Generality",
        "site": "https://proceedings.mlr.press/v206/yamane23a.html",
        "author": "Ikko Yamane; Yann Chevaleyre; Takashi Ishida; Florian Yger",
        "abstract": "In mediated uncoupled learning (MU-learning), the goal is to predict an output variable $Y$ given an input variable $X$ as in ordinary supervised learning while the training dataset has no joint samples of $(X, Y)$ but only independent samples of $(X, U)$ and $(U, Y)$ each observed with a mediating variable $U$. The existing MU-learning methods can only handle the squared loss, which prohibited the use of other popular loss functions such as the cross-entropy loss. We propose a general MU-learning framework that allows for the problems with Bregman divergences, which cover a wide range of loss functions useful for various types of tasks, in a unified manner. This loss family has maximal generality among those whose minimizers characterize the conditional expectation. We prove that the proposed objective function is a tighter approximation to the oracle loss that one would minimize if ordinary supervised samples of $(X, Y)$ were available. We also propose an estimator of an interval containing the expected test loss of predictions of a trained model only using $(X, U)$- and $(U, Y)$-data. We provide a theoretical analysis on the excess risk for the proposed method and confirm its practical usefulness with regression experiments with synthetic data and low-quality image classification experiments with benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v206-yamane23a,\n  title = \t {Mediated Uncoupled Learning and Validation with Bregman Divergences: Loss Family with Maximal Generality},\n  author =       {Yamane, Ikko and Chevaleyre, Yann and Ishida, Takashi and Yger, Florian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4768--4801},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yamane23a/yamane23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yamane23a.html},\n  abstract = \t {In mediated uncoupled learning (MU-learning), the goal is to predict an output variable $Y$ given an input variable $X$ as in ordinary supervised learning while the training dataset has no joint samples of $(X, Y)$ but only independent samples of $(X, U)$ and $(U, Y)$ each observed with a mediating variable $U$. The existing MU-learning methods can only handle the squared loss, which prohibited the use of other popular loss functions such as the cross-entropy loss. We propose a general MU-learning framework that allows for the problems with Bregman divergences, which cover a wide range of loss functions useful for various types of tasks, in a unified manner. This loss family has maximal generality among those whose minimizers characterize the conditional expectation. We prove that the proposed objective function is a tighter approximation to the oracle loss that one would minimize if ordinary supervised samples of $(X, Y)$ were available. We also propose an estimator of an interval containing the expected test loss of predictions of a trained model only using $(X, U)$- and $(U, Y)$-data. We provide a theoretical analysis on the excess risk for the proposed method and confirm its practical usefulness with regression experiments with synthetic data and low-quality image classification experiments with benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yamane23a/yamane23a.pdf",
        "supp": "",
        "pdf_size": 2411195,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7628273894079086591&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dd29307220",
        "title": "Membership Inference Attacks against Synthetic Data through Overfitting Detection",
        "site": "https://proceedings.mlr.press/v206/breugel23a.html",
        "author": "Boris van Breugel; Hao Sun; Zhaozhi Qian; Mihaela van der Schaar",
        "abstract": "Data is the foundation of most science. Unfortunately, sharing data can be obstructed by the risk of violating data privacy, impeding research in fields like healthcare. Synthetic data is a potential solution. It aims to generate data that has the same distribution as the original data, but that does not disclose information about individuals. Membership Inference Attacks (MIAs) are a common privacy attack, in which the attacker attempts to determine whether a particular real sample was used for training of the model. Previous works that propose MIAs against generative models either display low performance\u2014giving the false impression that data is highly private\u2014or need to assume access to internal generative model parameters\u2014a relatively low-risk scenario, as the data publisher often only releases synthetic data, not the model. In this work we argue for a realistic MIA setting that assumes the attacker has some knowledge of the underlying data distribution. We propose DOMIAS, a density-based MIA model that aims to infer membership by targeting local overfitting of the generative model. Experimentally we show that DOMIAS is significantly more successful at MIA than previous work, especially at attacking uncommon samples. The latter is disconcerting since these samples may correspond to underrepresented groups. We also demonstrate how DOMIAS\u2019 MIA performance score provides an interpretable metric for privacy, giving data publishers a new tool for achieving the desired privacy-utility trade-off in their synthetic data.",
        "bibtex": "@InProceedings{pmlr-v206-breugel23a,\n  title = \t {Membership Inference Attacks against Synthetic Data through Overfitting Detection},\n  author =       {van Breugel, Boris and Sun, Hao and Qian, Zhaozhi and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3493--3514},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/breugel23a/breugel23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/breugel23a.html},\n  abstract = \t {Data is the foundation of most science. Unfortunately, sharing data can be obstructed by the risk of violating data privacy, impeding research in fields like healthcare. Synthetic data is a potential solution. It aims to generate data that has the same distribution as the original data, but that does not disclose information about individuals. Membership Inference Attacks (MIAs) are a common privacy attack, in which the attacker attempts to determine whether a particular real sample was used for training of the model. Previous works that propose MIAs against generative models either display low performance\u2014giving the false impression that data is highly private\u2014or need to assume access to internal generative model parameters\u2014a relatively low-risk scenario, as the data publisher often only releases synthetic data, not the model. In this work we argue for a realistic MIA setting that assumes the attacker has some knowledge of the underlying data distribution. We propose DOMIAS, a density-based MIA model that aims to infer membership by targeting local overfitting of the generative model. Experimentally we show that DOMIAS is significantly more successful at MIA than previous work, especially at attacking uncommon samples. The latter is disconcerting since these samples may correspond to underrepresented groups. We also demonstrate how DOMIAS\u2019 MIA performance score provides an interpretable metric for privacy, giving data publishers a new tool for achieving the desired privacy-utility trade-off in their synthetic data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/breugel23a/breugel23a.pdf",
        "supp": "",
        "pdf_size": 8564222,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9794598535251452303&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8d58f10608",
        "title": "Meta-Learning with Adjoint Methods",
        "site": "https://proceedings.mlr.press/v206/li23c.html",
        "author": "Shibo Li; Zheng Wang; Akil Narayan; Robert Kirby; Shandian Zhe",
        "abstract": "Model Agnostic Meta-Learning (MAML) is widely used to find a good initialization for a family of tasks. Despite its success, a critical challenge in MAML is to calculate the gradient w.r.t. the initialization of a long training trajectory for the sampled tasks, because the computation graph can rapidly explode and the computational cost is very expensive. To address this problem, we propose Adjoint MAML (A-MAML). We view gradient descent in the inner optimization as the evolution of an Ordinary Differential Equation (ODE). To efficiently compute the gradient of the validation loss w.r.t. the initialization, we use the adjoint method to construct a companion, backward ODE. To obtain the gradient w.r.t. the initialization, we only need to run the standard ODE solver twice \u2014 one is forward in time that evolves a long trajectory of gradient flow for the sampled task; the other is backward and solves the adjoint ODE. We need not create or expand any intermediate computational graphs, adopt aggressive approximations, or impose proximal regularizers in the training loss. Our approach is cheap, accurate, and adaptable to different trajectory lengths. We demonstrate the advantage of our approach in both synthetic and real-world meta-learning tasks. The code is available at https://github.com/shib0li/Adjoint-MAML.",
        "bibtex": "@InProceedings{pmlr-v206-li23c,\n  title = \t {Meta-Learning with Adjoint Methods},\n  author =       {Li, Shibo and Wang, Zheng and Narayan, Akil and Kirby, Robert and Zhe, Shandian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7239--7251},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/li23c/li23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/li23c.html},\n  abstract = \t {Model Agnostic Meta-Learning (MAML) is widely used to find a good initialization for a family of tasks. Despite its success, a critical challenge in MAML is to calculate the gradient w.r.t. the initialization of a long training trajectory for the sampled tasks, because the computation graph can rapidly explode and the computational cost is very expensive. To address this problem, we propose Adjoint MAML (A-MAML). We view gradient descent in the inner optimization as the evolution of an Ordinary Differential Equation (ODE). To efficiently compute the gradient of the validation loss w.r.t. the initialization, we use the adjoint method to construct a companion, backward ODE. To obtain the gradient w.r.t. the initialization, we only need to run the standard ODE solver twice \u2014 one is forward in time that evolves a long trajectory of gradient flow for the sampled task; the other is backward and solves the adjoint ODE. We need not create or expand any intermediate computational graphs, adopt aggressive approximations, or impose proximal regularizers in the training loss. Our approach is cheap, accurate, and adaptable to different trajectory lengths. We demonstrate the advantage of our approach in both synthetic and real-world meta-learning tasks. The code is available at https://github.com/shib0li/Adjoint-MAML.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/li23c/li23c.pdf",
        "supp": "",
        "pdf_size": 1537446,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=361106762920529036&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Kahlert School of Computing, University of Utah; Kahlert School of Computing, University of Utah; Scientific Computing and Imaging (SCI) Institute, University of Utah + Department of Mathematics, University of Utah; Kahlert School of Computing, University of Utah + Scientific Computing and Imaging (SCI) Institute, University of Utah; Kahlert School of Computing, University of Utah",
        "aff_domain": "cs.utah.edu;cs.utah.edu;sci.utah.edu;cs.utah.edu;cs.utah.edu",
        "email": "cs.utah.edu;cs.utah.edu;sci.utah.edu;cs.utah.edu;cs.utah.edu",
        "github": "https://github.com/shib0li/Adjoint-MAML",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+0;0+0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "Kahlert School of Computing",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0;0;0+0;0",
        "aff_campus_unique": "Salt Lake City;",
        "aff_country_unique_index": "0;0;0+0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "360571e186",
        "title": "Meta-Uncertainty in Bayesian Model Comparison",
        "site": "https://proceedings.mlr.press/v206/schmitt23a.html",
        "author": "Marvin Schmitt; Stefan T. Radev; Paul-Christian B\u00fcrkner",
        "abstract": "Bayesian model comparison (BMC) offers a principled probabilistic approach to study and rank competing models. In standard BMC, we construct a discrete probability distribution over the set of possible models, conditional on the observed data of interest. These posterior model probabilities (PMPs) are measures of uncertainty, but\u2014when derived from a finite number of observations\u2014are also uncertain themselves. In this paper, we conceptualize distinct levels of uncertainty which arise in BMC. We explore a fully probabilistic framework for quantifying meta-uncertainty, resulting in an applied method to enhance any BMC workflow. Drawing on both Bayesian and frequentist techniques, we represent the uncertainty over the uncertain PMPs via meta-models which combine simulated and observed data into a predictive distribution for PMPs on new data. We demonstrate the utility of the proposed method in the context of conjugate Bayesian regression, likelihood-based inference with Markov chain Monte Carlo, and simulation-based inference with neural networks.",
        "bibtex": "@InProceedings{pmlr-v206-schmitt23a,\n  title = \t {Meta-Uncertainty in Bayesian Model Comparison},\n  author =       {Schmitt, Marvin and Radev, Stefan T. and B\\\"urkner, Paul-Christian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11--29},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/schmitt23a/schmitt23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/schmitt23a.html},\n  abstract = \t {Bayesian model comparison (BMC) offers a principled probabilistic approach to study and rank competing models. In standard BMC, we construct a discrete probability distribution over the set of possible models, conditional on the observed data of interest. These posterior model probabilities (PMPs) are measures of uncertainty, but\u2014when derived from a finite number of observations\u2014are also uncertain themselves. In this paper, we conceptualize distinct levels of uncertainty which arise in BMC. We explore a fully probabilistic framework for quantifying meta-uncertainty, resulting in an applied method to enhance any BMC workflow. Drawing on both Bayesian and frequentist techniques, we represent the uncertainty over the uncertain PMPs via meta-models which combine simulated and observed data into a predictive distribution for PMPs on new data. We demonstrate the utility of the proposed method in the context of conjugate Bayesian regression, likelihood-based inference with Markov chain Monte Carlo, and simulation-based inference with neural networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/schmitt23a/schmitt23a.pdf",
        "supp": "",
        "pdf_size": 1989225,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3004670144286795765&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "57ed205e94",
        "title": "Meta-learning for Robust Anomaly Detection",
        "site": "https://proceedings.mlr.press/v206/kumagai23a.html",
        "author": "Atsutoshi Kumagai; Tomoharu Iwata; Hiroshi Takahashi; Yasuhiro Fujiwara",
        "abstract": "We propose a meta-learning method to improve the anomaly detection performance on unseen target tasks that have only unlabeled data. Existing meta-learning methods for anomaly detection have shown remarkable performance but require labeled data in target tasks. Although they can treat unlabeled data as normal assuming anomalies in the unlabeled data are negligible, this assumption is often violated in practice. As a result, the methods have low performance. Our method meta-learns with related tasks that have labeled and unlabeled data such that the expected test anomaly detection performance is directly improved when the anomaly detector is adapted to given unlabeled data. Our method is based on autoencoders (AEs), which are widely used neural network-based anomaly detectors. We model anomalous attributes for each unlabeled instance in the reconstruction loss of the AE, which are used to prevent the anomalies from being reconstructed; they can remove the effect of the anomalies. We formulate adaptation to the unlabeled data as a learning problem of the last layer of the AE and the anomalous attributes. This formulation enables the optimum solution to be obtained with a closed-form alternate update formula, which is preferable to efficiently maximize the expected test anomaly detection performance. The effectiveness of our method is experimentally shown with four real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v206-kumagai23a,\n  title = \t {Meta-learning for Robust Anomaly Detection},\n  author =       {Kumagai, Atsutoshi and Iwata, Tomoharu and Takahashi, Hiroshi and Fujiwara, Yasuhiro},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {675--691},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kumagai23a/kumagai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kumagai23a.html},\n  abstract = \t {We propose a meta-learning method to improve the anomaly detection performance on unseen target tasks that have only unlabeled data. Existing meta-learning methods for anomaly detection have shown remarkable performance but require labeled data in target tasks. Although they can treat unlabeled data as normal assuming anomalies in the unlabeled data are negligible, this assumption is often violated in practice. As a result, the methods have low performance. Our method meta-learns with related tasks that have labeled and unlabeled data such that the expected test anomaly detection performance is directly improved when the anomaly detector is adapted to given unlabeled data. Our method is based on autoencoders (AEs), which are widely used neural network-based anomaly detectors. We model anomalous attributes for each unlabeled instance in the reconstruction loss of the AE, which are used to prevent the anomalies from being reconstructed; they can remove the effect of the anomalies. We formulate adaptation to the unlabeled data as a learning problem of the last layer of the AE and the anomalous attributes. This formulation enables the optimum solution to be obtained with a closed-form alternate update formula, which is preferable to efficiently maximize the expected test anomaly detection performance. The effectiveness of our method is experimentally shown with four real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kumagai23a/kumagai23a.pdf",
        "supp": "",
        "pdf_size": 8010441,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17403885595972289722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "818ec15582",
        "title": "Mind the (optimality) Gap: A Gap-Aware Learning Rate Scheduler for Adversarial Nets",
        "site": "https://proceedings.mlr.press/v206/hazimeh23a.html",
        "author": "Hussein Hazimeh; Natalia Ponomareva",
        "abstract": "Adversarial nets have proved to be powerful in various domains including generative modeling (GANs), transfer learning, and fairness. However, successfully training adversarial nets using first-order methods remains a major challenge. Typically, careful choices of the learning rates are needed to maintain the delicate balance between the competing networks. In this paper, we design a novel learning rate scheduler that dynamically adapts the learning rate of the adversary to maintain the right balance. The scheduler is driven by the fact that the loss of an ideal adversarial net is a constant known a priori. The scheduler is thus designed to keep the loss of the optimized adversarial net close to that of an ideal network. We run large-scale experiments to study the effectiveness of the scheduler on two popular applications: GANs for image generation and adversarial nets for domain adaptation. Our experiments indicate that adversarial nets trained with the scheduler are less likely to diverge and require significantly less tuning. For example, on CelebA, a GAN with the scheduler requires only one-tenth of the tuning budget needed without a scheduler. Moreover, the scheduler leads to statistically significant improvements in model quality, reaching up to 27$%$ in Frechet Inception Distance for image generation and 3$%$ in test accuracy for domain adaptation.",
        "bibtex": "@InProceedings{pmlr-v206-hazimeh23a,\n  title = \t {Mind the (optimality) Gap: A Gap-Aware Learning Rate Scheduler for Adversarial Nets},\n  author =       {Hazimeh, Hussein and Ponomareva, Natalia},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3018--3033},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hazimeh23a/hazimeh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hazimeh23a.html},\n  abstract = \t {Adversarial nets have proved to be powerful in various domains including generative modeling (GANs), transfer learning, and fairness. However, successfully training adversarial nets using first-order methods remains a major challenge. Typically, careful choices of the learning rates are needed to maintain the delicate balance between the competing networks. In this paper, we design a novel learning rate scheduler that dynamically adapts the learning rate of the adversary to maintain the right balance. The scheduler is driven by the fact that the loss of an ideal adversarial net is a constant known a priori. The scheduler is thus designed to keep the loss of the optimized adversarial net close to that of an ideal network. We run large-scale experiments to study the effectiveness of the scheduler on two popular applications: GANs for image generation and adversarial nets for domain adaptation. Our experiments indicate that adversarial nets trained with the scheduler are less likely to diverge and require significantly less tuning. For example, on CelebA, a GAN with the scheduler requires only one-tenth of the tuning budget needed without a scheduler. Moreover, the scheduler leads to statistically significant improvements in model quality, reaching up to 27$%$ in Frechet Inception Distance for image generation and 3$%$ in test accuracy for domain adaptation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hazimeh23a/hazimeh23a.pdf",
        "supp": "",
        "pdf_size": 3709092,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=498471747154196182&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Google Research; Google Research",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ef5414f4e2",
        "title": "Minimax Nonparametric Two-Sample Test under Adversarial Losses",
        "site": "https://proceedings.mlr.press/v206/tang23a.html",
        "author": "Rong Tang; Yun Yang",
        "abstract": "In this paper, we consider the problem of two-sample hypothesis testing that aims at detecting the difference between two probability densities based on finite samples. The proposed test statistic is constructed by first truncating a sample version of a negative Besov norm and then normalizing it. Here, the negative Besov norm is the norm associated with a Besov space with negative exponent, and is shown to be closely related to a class of commonly used adversarial losses (or integral probability metrics) with smooth discriminators. Theoretically, we characterize the optimal detection boundary of two-sample testing in terms of the dimensionalities and smoothness levels of the underlying densities and the discriminator class defining the adversarial loss. We also show that the proposed approach can simultaneously attain the optimal detection boundary under many common adversarial losses, including those induced by the $\\ell_1$, $\\ell_2$ distances and Wasserstein distances. Our numerical experiments show that the proposed test procedure tends to exhibit higher power and robustness in difference detection than existing state-of-the-art competitors.",
        "bibtex": "@InProceedings{pmlr-v206-tang23a,\n  title = \t {Minimax Nonparametric Two-Sample Test under Adversarial Losses},\n  author =       {Tang, Rong and Yang, Yun},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6132--6165},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tang23a/tang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tang23a.html},\n  abstract = \t {In this paper, we consider the problem of two-sample hypothesis testing that aims at detecting the difference between two probability densities based on finite samples. The proposed test statistic is constructed by first truncating a sample version of a negative Besov norm and then normalizing it. Here, the negative Besov norm is the norm associated with a Besov space with negative exponent, and is shown to be closely related to a class of commonly used adversarial losses (or integral probability metrics) with smooth discriminators. Theoretically, we characterize the optimal detection boundary of two-sample testing in terms of the dimensionalities and smoothness levels of the underlying densities and the discriminator class defining the adversarial loss. We also show that the proposed approach can simultaneously attain the optimal detection boundary under many common adversarial losses, including those induced by the $\\ell_1$, $\\ell_2$ distances and Wasserstein distances. Our numerical experiments show that the proposed test procedure tends to exhibit higher power and robustness in difference detection than existing state-of-the-art competitors.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tang23a/tang23a.pdf",
        "supp": "",
        "pdf_size": 1678219,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13679749125111126137&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a91df3e19f",
        "title": "Minimax-Bayes Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/buening23a.html",
        "author": "Thomas Kleine Buening; Christos Dimitrakakis; Hannes Eriksson; Divya Grover; Emilio Jorge",
        "abstract": "While the Bayesian decision-theoretic framework offers an elegant solution to the problem of decision making under uncertainty, one question is how to appropriately select the prior distribution. One idea is to employ a worst-case prior. However, this is not as easy to specify in sequential decision making as in simple statistical estimation problems. This paper studies (sometimes approximate) minimax-Bayes solutions for various reinforcement learning problems to gain insights into the properties of the corresponding priors and policies. We find that while the worst-case prior depends on the setting, the corresponding minimax policies are more robust than those that assume a standard (i.e. uniform) prior.",
        "bibtex": "@InProceedings{pmlr-v206-buening23a,\n  title = \t {Minimax-Bayes Reinforcement Learning},\n  author =       {Buening, Thomas Kleine and Dimitrakakis, Christos and Eriksson, Hannes and Grover, Divya and Jorge, Emilio},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7511--7527},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/buening23a/buening23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/buening23a.html},\n  abstract = \t {While the Bayesian decision-theoretic framework offers an elegant solution to the problem of decision making under uncertainty, one question is how to appropriately select the prior distribution. One idea is to employ a worst-case prior. However, this is not as easy to specify in sequential decision making as in simple statistical estimation problems. This paper studies (sometimes approximate) minimax-Bayes solutions for various reinforcement learning problems to gain insights into the properties of the corresponding priors and policies. We find that while the worst-case prior depends on the setting, the corresponding minimax policies are more robust than those that assume a standard (i.e. uniform) prior.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/buening23a/buening23a.pdf",
        "supp": "",
        "pdf_size": 1168211,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3854870602186302616&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of Oslo; University of Neuchatel; Zenseact; Chalmers University of Technology+Chalmers University of Technology; Chalmers University of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3+3;3",
        "aff_unique_norm": "University of Oslo;University of Neuchatel;Zenseact;Chalmers University of Technology",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.uio.no;https://www.unine.ch;https://www.zenseact.se;https://www.chalmers.se",
        "aff_unique_abbr": "UiO;UNINE;;Chalmers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;2+2;2",
        "aff_country_unique": "Norway;Switzerland;Sweden"
    },
    {
        "id": "2705680118",
        "title": "Minimum-Entropy Coupling Approximation Guarantees Beyond the Majorization Barrier",
        "site": "https://proceedings.mlr.press/v206/compton23a.html",
        "author": "Spencer Compton; Dmitriy Katz; Benjamin Qi; Kristjan Greenewald; Murat Kocaoglu",
        "abstract": "Given a set of discrete probability distributions, the minimum entropy coupling is the minimum entropy joint distribution that has the input distributions as its marginals. This has immediate relevance to tasks such as entropic causal inference for causal graph discovery and bounding mutual information between variables that we observe separately. Since finding the minimum entropy coupling is NP-Hard, various works have studied approximation algorithms. The work of [Compton, 2022] shows that the greedy coupling algorithm of [Kocaoglu et al., 2017a] is always within $\\log_2(e)$ $\\approx$ 1.44 bits of the optimal coupling. Moreover, they show that it is impossible to obtain a better approximation guarantee using the majorization lower-bound that all prior works have used: thus establishing a majorization barrier. In this work, we break the majorization barrier by designing a stronger lower-bound that we call the profile method. Using this profile method, we are able to show that the greedy algorithm is always within $\\log_2(e)/e$ $\\approx$ 0.53 bits of optimal for coupling two distributions (previous best-known bound is within 1 bit), and within $(1 + \\log_2(e))/2$ $\\approx$ 1.22 bits for coupling any number of distributions (previous best-known bound is within 1.44 bits). We also examine a generalization of the minimum entropy coupling problem: Concave Minimum-Cost Couplings. We are able to obtain similar guarantees for this generalization in terms of the concave cost function. Additionally, we make progress on the open problem of [Kova\u010devi\u0107 et al., 2015] regarding NP membership of the minimum entropy coupling problem by showing that any hardness of minimum entropy coupling beyond NP comes from the difficulty of computing arithmetic in the complexity class NP. Finally, we present exponential-time algorithms for computing the exactly optimal solution. We experimentally observe that our new profile method lower bound is not only helpful for analyzing the greedy approximation algorithm, but also for improving the speed of our new backtracking-based exact algorithm.",
        "bibtex": "@InProceedings{pmlr-v206-compton23a,\n  title = \t {Minimum-Entropy Coupling Approximation Guarantees Beyond the Majorization Barrier},\n  author =       {Compton, Spencer and Katz, Dmitriy and Qi, Benjamin and Greenewald, Kristjan and Kocaoglu, Murat},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10445--10469},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/compton23a/compton23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/compton23a.html},\n  abstract = \t {Given a set of discrete probability distributions, the minimum entropy coupling is the minimum entropy joint distribution that has the input distributions as its marginals. This has immediate relevance to tasks such as entropic causal inference for causal graph discovery and bounding mutual information between variables that we observe separately. Since finding the minimum entropy coupling is NP-Hard, various works have studied approximation algorithms. The work of [Compton, 2022] shows that the greedy coupling algorithm of [Kocaoglu et al., 2017a] is always within $\\log_2(e)$ $\\approx$ 1.44 bits of the optimal coupling. Moreover, they show that it is impossible to obtain a better approximation guarantee using the majorization lower-bound that all prior works have used: thus establishing a majorization barrier. In this work, we break the majorization barrier by designing a stronger lower-bound that we call the profile method. Using this profile method, we are able to show that the greedy algorithm is always within $\\log_2(e)/e$ $\\approx$ 0.53 bits of optimal for coupling two distributions (previous best-known bound is within 1 bit), and within $(1 + \\log_2(e))/2$ $\\approx$ 1.22 bits for coupling any number of distributions (previous best-known bound is within 1.44 bits). We also examine a generalization of the minimum entropy coupling problem: Concave Minimum-Cost Couplings. We are able to obtain similar guarantees for this generalization in terms of the concave cost function. Additionally, we make progress on the open problem of [Kova\u010devi\u0107 et al., 2015] regarding NP membership of the minimum entropy coupling problem by showing that any hardness of minimum entropy coupling beyond NP comes from the difficulty of computing arithmetic in the complexity class NP. Finally, we present exponential-time algorithms for computing the exactly optimal solution. We experimentally observe that our new profile method lower bound is not only helpful for analyzing the greedy approximation algorithm, but also for improving the speed of our new backtracking-based exact algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/compton23a/compton23a.pdf",
        "supp": "",
        "pdf_size": 867060,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8058419439891366042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Stanford University; MIT-IBM Watson AI Lab+MIT; IBM Research; MIT-IBM Watson AI Lab+Purdue University; IBM Research",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+1;2;1+3;2",
        "aff_unique_norm": "Stanford University;Massachusetts Institute of Technology;IBM;Purdue University",
        "aff_unique_dep": ";IBM Watson AI Lab;IBM Research;",
        "aff_unique_url": "https://www.stanford.edu;https://www.mitibmwatsonailab.org;https://www.ibm.com/research;https://www.purdue.edu",
        "aff_unique_abbr": "Stanford;MIT-IBM AI Lab;IBM;Purdue",
        "aff_campus_unique_index": "0;;",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0+0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "506371f62d",
        "title": "Minority Oversampling for Imbalanced Data via Class-Preserving Regularized Auto-Encoders",
        "site": "https://proceedings.mlr.press/v206/mondal23a.html",
        "author": "Arnab Kumar Mondal; Lakshya Singhal; Piyush Tiwary; Parag Singla; Prathosh AP",
        "abstract": "Class imbalance is a common phenomenon in multiple application domains such as healthcare, where the sample occurrence of one or few class categories is more prevalent in the dataset than the rest. This work addresses the class-imbalance issue by proposing an over-sampling method for the minority classes in the latent space of a Regularized Auto-Encoder (RAE). Specifically, we construct a latent space by maximizing the conditional data likelihood using an Encoder-Decoder structure, such that oversampling through convex combinations of latent samples preserves the class identity. A jointly-trained linear classifier that separates convexly coupled latent vectors from different classes is used to impose this property on the AE\u2019s latent space. Further, the aforesaid linear classifier is used for final classification without retraining. We theoretically show that our method can achieve a low variance risk estimate compared to naive oversampling methods and is robust to overfitting. We conduct several experiments on benchmark datasets and show that our method outperforms the existing oversampling techniques for handling class imbalance. The code of the proposed method is available at: https://github.com/arnabkmondal/oversamplingrae.",
        "bibtex": "@InProceedings{pmlr-v206-mondal23a,\n  title = \t {Minority Oversampling for Imbalanced Data via Class-Preserving Regularized Auto-Encoders},\n  author =       {Mondal, Arnab Kumar and Singhal, Lakshya and Tiwary, Piyush and Singla, Parag and {AP}, Prathosh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3440--3465},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mondal23a/mondal23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mondal23a.html},\n  abstract = \t {Class imbalance is a common phenomenon in multiple application domains such as healthcare, where the sample occurrence of one or few class categories is more prevalent in the dataset than the rest. This work addresses the class-imbalance issue by proposing an over-sampling method for the minority classes in the latent space of a Regularized Auto-Encoder (RAE). Specifically, we construct a latent space by maximizing the conditional data likelihood using an Encoder-Decoder structure, such that oversampling through convex combinations of latent samples preserves the class identity. A jointly-trained linear classifier that separates convexly coupled latent vectors from different classes is used to impose this property on the AE\u2019s latent space. Further, the aforesaid linear classifier is used for final classification without retraining. We theoretically show that our method can achieve a low variance risk estimate compared to naive oversampling methods and is robust to overfitting. We conduct several experiments on benchmark datasets and show that our method outperforms the existing oversampling techniques for handling class imbalance. The code of the proposed method is available at: https://github.com/arnabkmondal/oversamplingrae.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mondal23a/mondal23a.pdf",
        "supp": "",
        "pdf_size": 9798849,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12314238679050467003&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "IIT Delhi; IISc Bengaluru; IISc Bengaluru; IIT Delhi; IISc Bengaluru",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/arnabkmondal/OversamplingRAE",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Indian Institute of Technology Delhi;Indian Institute of Science",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iitd.ac.in;https://www.iisc.ac.in",
        "aff_unique_abbr": "IITD;IISc",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Delhi;Bengaluru",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "7d33832d40",
        "title": "Mixed Linear Regression via Approximate Message Passing",
        "site": "https://proceedings.mlr.press/v206/tan23a.html",
        "author": "Nelvin Tan; Ramji Venkataramanan",
        "abstract": "In mixed linear regression, each observation comes from one of L regression vectors (signals), but we do not know which one. The goal is to estimate the signals from the unlabeled observations. We propose a novel approximate message passing (AMP) algorithm for estimation and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic mean-squared error. This can be used to tailor the AMP algorithm to take advantage of any known structural information about the signals. Using state evolution, we derive an optimal choice of AMP \u2018denoising\u2019 functions that minimizes the estimation error in each iteration. Numerical simulations are provided to validate the theoretical results, and show that AMP significantly outperforms other estimators including spectral methods, expectation maximization, and alternating minimization. Though our numerical results focus on mixed linear regression, the proposed AMP algorithm can be applied to a broader class of models including mixtures of generalized linear models and max-affine regression.",
        "bibtex": "@InProceedings{pmlr-v206-tan23a,\n  title = \t {Mixed Linear Regression via Approximate Message Passing},\n  author =       {Tan, Nelvin and Venkataramanan, Ramji},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2116--2131},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tan23a/tan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tan23a.html},\n  abstract = \t {In mixed linear regression, each observation comes from one of L regression vectors (signals), but we do not know which one. The goal is to estimate the signals from the unlabeled observations. We propose a novel approximate message passing (AMP) algorithm for estimation and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic mean-squared error. This can be used to tailor the AMP algorithm to take advantage of any known structural information about the signals. Using state evolution, we derive an optimal choice of AMP \u2018denoising\u2019 functions that minimizes the estimation error in each iteration. Numerical simulations are provided to validate the theoretical results, and show that AMP significantly outperforms other estimators including spectral methods, expectation maximization, and alternating minimization. Though our numerical results focus on mixed linear regression, the proposed AMP algorithm can be applied to a broader class of models including mixtures of generalized linear models and max-affine regression.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tan23a/tan23a.pdf",
        "supp": "",
        "pdf_size": 551497,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6522211044620847526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "University of Cambridge; University of Cambridge",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "80ae1a55ce",
        "title": "Mixed-Effect Thompson Sampling",
        "site": "https://proceedings.mlr.press/v206/aouali23a.html",
        "author": "Imad Aouali; Branislav Kveton; Sumeet Katariya",
        "abstract": "A contextual bandit is a popular framework for online learning to act under uncertainty. In practice, the number of actions is huge and their expected rewards are correlated. In this work, we introduce a general framework for capturing such correlations through a mixed-effect model where actions are related through multiple shared effect parameters. To explore efficiently using this structure, we propose Mixed-Effect Thompson Sampling (meTS) and bound its Bayes regret. The regret bound has two terms, one for learning the action parameters and the other for learning the shared effect parameters. The terms reflect the structure of our model and the quality of priors. Our theoretical findings are validated empirically using both synthetic and real-world problems. We also propose numerous extensions of practical interest. While they do not come with guarantees, they perform well empirically and show the generality of the proposed framework.",
        "bibtex": "@InProceedings{pmlr-v206-aouali23a,\n  title = \t {Mixed-Effect Thompson Sampling},\n  author =       {Aouali, Imad and Kveton, Branislav and Katariya, Sumeet},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2087--2115},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/aouali23a/aouali23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/aouali23a.html},\n  abstract = \t {A contextual bandit is a popular framework for online learning to act under uncertainty. In practice, the number of actions is huge and their expected rewards are correlated. In this work, we introduce a general framework for capturing such correlations through a mixed-effect model where actions are related through multiple shared effect parameters. To explore efficiently using this structure, we propose Mixed-Effect Thompson Sampling (meTS) and bound its Bayes regret. The regret bound has two terms, one for learning the action parameters and the other for learning the shared effect parameters. The terms reflect the structure of our model and the quality of priors. Our theoretical findings are validated empirically using both synthetic and real-world problems. We also propose numerous extensions of practical interest. While they do not come with guarantees, they perform well empirically and show the generality of the proposed framework.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/aouali23a/aouali23a.pdf",
        "supp": "",
        "pdf_size": 3957724,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2090484668649511349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9e5cb9a231",
        "title": "Mixtures of All Trees",
        "site": "https://proceedings.mlr.press/v206/selvam23a.html",
        "author": "Nikil Roashan Selvam; Honghua Zhang; Guy Van den Broeck",
        "abstract": "Tree-shaped graphical models are widely used for their tractability. However, they unfortunately lack expressive power as they require committing to a particular sparse dependency structure. We propose a novel class of generative models called mixtures of all trees: that is, a mixture over all possible ($n^{n-2}$) tree-shaped graphical models over n variables. We show that it is possible to parameterize this Mixture of All Trees (MoAT) model compactly (using a polynomial-size representation) in a way that allows for tractable likelihood computation and optimization via stochastic gradient descent. Furthermore, by leveraging the tractability of tree-shaped models, we devise fast-converging conditional sampling algorithms for approximate inference, even though our theoretical analysis suggests that exact computation of marginals in the MoAT model is NP-hard. Empirically, MoAT achieves state-of-the-art performance on density estimation benchmarks when compared against powerful probabilistic models including hidden Chow-Liu Trees.",
        "bibtex": "@InProceedings{pmlr-v206-selvam23a,\n  title = \t {Mixtures of All Trees},\n  author =       {Selvam, Nikil Roashan and Zhang, Honghua and Van den Broeck, Guy},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11043--11058},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/selvam23a/selvam23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/selvam23a.html},\n  abstract = \t {Tree-shaped graphical models are widely used for their tractability. However, they unfortunately lack expressive power as they require committing to a particular sparse dependency structure. We propose a novel class of generative models called mixtures of all trees: that is, a mixture over all possible ($n^{n-2}$) tree-shaped graphical models over n variables. We show that it is possible to parameterize this Mixture of All Trees (MoAT) model compactly (using a polynomial-size representation) in a way that allows for tractable likelihood computation and optimization via stochastic gradient descent. Furthermore, by leveraging the tractability of tree-shaped models, we devise fast-converging conditional sampling algorithms for approximate inference, even though our theoretical analysis suggests that exact computation of marginals in the MoAT model is NP-hard. Empirically, MoAT achieves state-of-the-art performance on density estimation benchmarks when compared against powerful probabilistic models including hidden Chow-Liu Trees.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/selvam23a/selvam23a.pdf",
        "supp": "",
        "pdf_size": 1500004,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17213228247868918905&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "UCLA Computer Science; UCLA Computer Science; UCLA Computer Science",
        "aff_domain": "ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "email": "ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Computer Science",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f274db4852",
        "title": "Mode-Seeking Divergences: Theory and Applications to GANs",
        "site": "https://proceedings.mlr.press/v206/ting-li23a.html",
        "author": "Cheuk Ting Li; Farzan Farnia",
        "abstract": "Generative adversarial networks (GANs) represent a game between two neural network machines designed to learn the distribution of data. It is commonly observed that different GAN formulations and divergence/distance measures used could lead to considerably different performance results, especially when the data distribution is multi-modal. In this work, we give a theoretical characterization of the mode-seeking behavior of general f-divergences and Wasserstein distances, and prove a performance guarantee for the setting where the underlying model is a mixture of multiple symmetric quasiconcave distributions. This can help us understand the trade-off between the quality and diversity of the trained GANs\u2019 output samples. Our theoretical results show the mode-seeking nature of the Jensen-Shannon (JS) divergence over standard KL-divergence and Wasserstein distance measures. We subsequently demonstrate that a hybrid of JS-divergence and Wasserstein distance measures minimized by Lipschitz GANs mimics the mode-seeking behavior of the JS-divergence. We present numerical results showing the mode-seeking nature of the JS-divergence and its hybrid with the Wasserstein distance while highlighting the mode-covering properties of KL-divergence and Wasserstein distance measures. Our numerical experiments indicate the different behavior of several standard GAN formulations in application to benchmark Gaussian mixture and image datasets.",
        "bibtex": "@InProceedings{pmlr-v206-ting-li23a,\n  title = \t {Mode-Seeking Divergences: Theory and Applications to GANs},\n  author =       {Li, Cheuk Ting and Farnia, Farzan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8321--8350},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ting-li23a/ting-li23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ting-li23a.html},\n  abstract = \t {Generative adversarial networks (GANs) represent a game between two neural network machines designed to learn the distribution of data. It is commonly observed that different GAN formulations and divergence/distance measures used could lead to considerably different performance results, especially when the data distribution is multi-modal. In this work, we give a theoretical characterization of the mode-seeking behavior of general f-divergences and Wasserstein distances, and prove a performance guarantee for the setting where the underlying model is a mixture of multiple symmetric quasiconcave distributions. This can help us understand the trade-off between the quality and diversity of the trained GANs\u2019 output samples. Our theoretical results show the mode-seeking nature of the Jensen-Shannon (JS) divergence over standard KL-divergence and Wasserstein distance measures. We subsequently demonstrate that a hybrid of JS-divergence and Wasserstein distance measures minimized by Lipschitz GANs mimics the mode-seeking behavior of the JS-divergence. We present numerical results showing the mode-seeking nature of the JS-divergence and its hybrid with the Wasserstein distance while highlighting the mode-covering properties of KL-divergence and Wasserstein distance measures. Our numerical experiments indicate the different behavior of several standard GAN formulations in application to benchmark Gaussian mixture and image datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ting-li23a/ting-li23a.pdf",
        "supp": "",
        "pdf_size": 8234706,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6232053806360567738&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "fbe033cd61",
        "title": "Mode-constrained Model-based Reinforcement Learning via Gaussian Processes",
        "site": "https://proceedings.mlr.press/v206/scannell23a.html",
        "author": "Aidan Scannell; Carl Henrik Ek; Arthur Richards",
        "abstract": "Model-based reinforcement learning (RL) algorithms do not typically consider environments with multiple dynamic modes, where it is beneficial to avoid inoperable or undesirable modes. We present a model-based RL algorithm that constrains training to a single dynamic mode with high probability. This is a difficult problem because the mode constraint is a hidden variable associated with the environment\u2019s dynamics. As such, it is 1) unknown a priori and 2) we do not observe its output from the environment, so cannot learn it with supervised learning. We present a nonparametric dynamic model which learns the mode constraint alongside the dynamic modes. Importantly, it learns latent structure that our planning scheme leverages to 1) enforce the mode constraint with high probability, and 2) escape local optima induced by the mode constraint. We validate our method by showing that it can solve a simulated quadcopter navigation task whilst providing a level of constraint satisfaction both during and after training.",
        "bibtex": "@InProceedings{pmlr-v206-scannell23a,\n  title = \t {Mode-constrained Model-based Reinforcement Learning via Gaussian Processes},\n  author =       {Scannell, Aidan and Ek, Carl Henrik and Richards, Arthur},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3299--3314},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/scannell23a/scannell23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/scannell23a.html},\n  abstract = \t {Model-based reinforcement learning (RL) algorithms do not typically consider environments with multiple dynamic modes, where it is beneficial to avoid inoperable or undesirable modes. We present a model-based RL algorithm that constrains training to a single dynamic mode with high probability. This is a difficult problem because the mode constraint is a hidden variable associated with the environment\u2019s dynamics. As such, it is 1) unknown a priori and 2) we do not observe its output from the environment, so cannot learn it with supervised learning. We present a nonparametric dynamic model which learns the mode constraint alongside the dynamic modes. Importantly, it learns latent structure that our planning scheme leverages to 1) enforce the mode constraint with high probability, and 2) escape local optima induced by the mode constraint. We validate our method by showing that it can solve a simulated quadcopter navigation task whilst providing a level of constraint satisfaction both during and after training.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/scannell23a/scannell23a.pdf",
        "supp": "",
        "pdf_size": 1829432,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1153258103207154227&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "05a524450e",
        "title": "Model-Based Uncertainty in Value Functions",
        "site": "https://proceedings.mlr.press/v206/luis23a.html",
        "author": "Carlos E. Luis; Alessandro G. Bottero; Julia Vinogradska; Felix Berkenkamp; Jan Peters",
        "abstract": "We consider the problem of quantifying uncertainty over expected cumulative rewards in model-based reinforcement learning. In particular, we focus on characterizing the variance over values induced by a distribution over MDPs. Previous work upper bounds the posterior variance over values by solving a so-called uncertainty Bellman equation, but the over-approximation may result in inefficient exploration. We propose a new uncertainty Bellman equation whose solution converges to the true posterior variance over values and explicitly characterizes the gap in previous work. Moreover, our uncertainty quantification technique is easily integrated into common exploration strategies and scales naturally beyond the tabular setting by using standard deep reinforcement learning architectures. Experiments in difficult exploration tasks, both in tabular and continuous control settings, show that our sharper uncertainty estimates improve sample-efficiency.",
        "bibtex": "@InProceedings{pmlr-v206-luis23a,\n  title = \t {Model-Based Uncertainty in Value Functions},\n  author =       {Luis, Carlos E. and Bottero, Alessandro G. and Vinogradska, Julia and Berkenkamp, Felix and Peters, Jan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8029--8052},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/luis23a/luis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/luis23a.html},\n  abstract = \t {We consider the problem of quantifying uncertainty over expected cumulative rewards in model-based reinforcement learning. In particular, we focus on characterizing the variance over values induced by a distribution over MDPs. Previous work upper bounds the posterior variance over values by solving a so-called uncertainty Bellman equation, but the over-approximation may result in inefficient exploration. We propose a new uncertainty Bellman equation whose solution converges to the true posterior variance over values and explicitly characterizes the gap in previous work. Moreover, our uncertainty quantification technique is easily integrated into common exploration strategies and scales naturally beyond the tabular setting by using standard deep reinforcement learning architectures. Experiments in difficult exploration tasks, both in tabular and continuous control settings, show that our sharper uncertainty estimates improve sample-efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/luis23a/luis23a.pdf",
        "supp": "",
        "pdf_size": 2228186,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11717579230914723759&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Bosch Center for Artificial Intelligence+Institute for Intelligent Autonomous Systems, TU Darmstadt; Bosch Center for Artificial Intelligence+Institute for Intelligent Autonomous Systems, TU Darmstadt; Bosch Center for Artificial Intelligence; Bosch Center for Artificial Intelligence; Institute for Intelligent Autonomous Systems, TU Darmstadt+German Research Center for AI (DFKI), Research Department: Systems AI for Robot Learning+Hessian.AI",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0;0;1+2+3",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;Technische Universit\u00e4t Darmstadt;German Research Center for AI (DFKI);Hessian.AI",
        "aff_unique_dep": "Center for Artificial Intelligence;Institute for Intelligent Autonomous Systems;Research Department: Systems AI for Robot Learning;",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.tu-darmstadt.de;https://www.dFKI.de;https://www.hessian.ai",
        "aff_unique_abbr": "BCAI;TU Darmstadt;DFKI;Hessian.AI",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0;0;0+0+1",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "a8539e6fee",
        "title": "Model-X Sequential Testing for Conditional Independence via Testing by Betting",
        "site": "https://proceedings.mlr.press/v206/shaer23a.html",
        "author": "Shalev Shaer; Gal Maman; Yaniv Romano",
        "abstract": "This paper develops a model-free sequential test for conditional independence. The proposed test allows researchers to analyze an incoming i.i.d. data stream with any arbitrary dependency structure, and safely conclude whether a feature is conditionally associated with the response under study. We allow the processing of data points online, as soon as they arrive, and stop data acquisition once significant results are detected, rigorously controlling the type-I error rate. Our test can work with any sophisticated machine learning algorithm to enhance data efficiency to the extent possible. The developed method is inspired by two statistical frameworks. The first is the model-X conditional randomization test, a test for conditional independence that is valid in offline settings where the sample size is fixed in advance. The second is testing by betting, a \u201cgame-theoretic\u201d approach for sequential hypothesis testing. We conduct synthetic experiments to demonstrate the advantage of our test over out-of-the-box sequential tests that account for the multiplicity of tests in the time horizon, and demonstrate the practicality of our proposal by applying it to real-world tasks.",
        "bibtex": "@InProceedings{pmlr-v206-shaer23a,\n  title = \t {Model-X Sequential Testing for Conditional Independence via Testing by Betting},\n  author =       {Shaer, Shalev and Maman, Gal and Romano, Yaniv},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2054--2086},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shaer23a/shaer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shaer23a.html},\n  abstract = \t {This paper develops a model-free sequential test for conditional independence. The proposed test allows researchers to analyze an incoming i.i.d. data stream with any arbitrary dependency structure, and safely conclude whether a feature is conditionally associated with the response under study. We allow the processing of data points online, as soon as they arrive, and stop data acquisition once significant results are detected, rigorously controlling the type-I error rate. Our test can work with any sophisticated machine learning algorithm to enhance data efficiency to the extent possible. The developed method is inspired by two statistical frameworks. The first is the model-X conditional randomization test, a test for conditional independence that is valid in offline settings where the sample size is fixed in advance. The second is testing by betting, a \u201cgame-theoretic\u201d approach for sequential hypothesis testing. We conduct synthetic experiments to demonstrate the advantage of our test over out-of-the-box sequential tests that account for the multiplicity of tests in the time horizon, and demonstrate the practicality of our proposal by applying it to real-world tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shaer23a/shaer23a.pdf",
        "supp": "",
        "pdf_size": 3610249,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7443448173188810735&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Electrical and Computer Engineering, Technion\u2013Israel Institute of Technology; Department of Electrical and Computer Engineering, Technion\u2013Israel Institute of Technology; Department of Electrical and Computer Engineering, Technion\u2013Israel Institute of Technology + Department of Computer Science, Technion\u2013Israel Institute of Technology",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+0",
        "aff_unique_norm": "Technion\u2013Israel Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "29f57b2a6a",
        "title": "Multi-Agent congestion cost minimization with linear function approximations",
        "site": "https://proceedings.mlr.press/v206/trivedi23a.html",
        "author": "Prashant Trivedi; Nandyala Hemachandra",
        "abstract": "This work considers multiple agents traversing a network from a source node to the goal node. The cost to an agent for traveling a link has a private as well as a congestion component. The agent\u2019s objective is to find a path to the goal node with minimum overall cost in a decentralized way. We model this as a fully decentralized multi-agent reinforcement learning problem and propose a novel multi-agent congestion cost minimization (MACCM) algorithm. Our MACCM algorithm uses linear function approximations of transition probabilities and the global cost function. In the absence of a central controller and to preserve privacy, agents communicate the cost function parameters to their neighbors via a time-varying communication network. Moreover, each agent maintains its estimate of the global state-action value, which is updated via a multi-agent extended value iteration (MAEVI) sub-routine. We show that our MACCM algorithm achieves a sub-linear regret. The proof requires the convergence of cost function parameters, the MAEVI algorithm, and analysis of the regret bounds induced by the MAEVI triggering condition for each agent. We implement our algorithm on a two node network with multiple links to validate it. We first identify the optimal policy, the optimal number of agents going to the goal node in each period. We observe that the average regret is close to zero for 2 and 3 agents. The optimal policy captures the trade-off between the minimum cost of staying at a node and the congestion cost of going to the goal node. Our work is a generalization of learning the stochastic shortest path problem.",
        "bibtex": "@InProceedings{pmlr-v206-trivedi23a,\n  title = \t {Multi-Agent congestion cost minimization with linear function approximations},\n  author =       {Trivedi, Prashant and Hemachandra, Nandyala},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7611--7643},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/trivedi23a/trivedi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/trivedi23a.html},\n  abstract = \t {This work considers multiple agents traversing a network from a source node to the goal node. The cost to an agent for traveling a link has a private as well as a congestion component. The agent\u2019s objective is to find a path to the goal node with minimum overall cost in a decentralized way. We model this as a fully decentralized multi-agent reinforcement learning problem and propose a novel multi-agent congestion cost minimization (MACCM) algorithm. Our MACCM algorithm uses linear function approximations of transition probabilities and the global cost function. In the absence of a central controller and to preserve privacy, agents communicate the cost function parameters to their neighbors via a time-varying communication network. Moreover, each agent maintains its estimate of the global state-action value, which is updated via a multi-agent extended value iteration (MAEVI) sub-routine. We show that our MACCM algorithm achieves a sub-linear regret. The proof requires the convergence of cost function parameters, the MAEVI algorithm, and analysis of the regret bounds induced by the MAEVI triggering condition for each agent. We implement our algorithm on a two node network with multiple links to validate it. We first identify the optimal policy, the optimal number of agents going to the goal node in each period. We observe that the average regret is close to zero for 2 and 3 agents. The optimal policy captures the trade-off between the minimum cost of staying at a node and the congestion cost of going to the goal node. Our work is a generalization of learning the stochastic shortest path problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/trivedi23a/trivedi23a.pdf",
        "supp": "",
        "pdf_size": 498486,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6753848753024028069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "IE&OR, IIT Bombay, India; IE&OR, IIT Bombay, India",
        "aff_domain": "iitb.ac.in;iitb.ac.in",
        "email": "iitb.ac.in;iitb.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Bombay",
        "aff_unique_dep": "Industrial Engineering & Operations Research",
        "aff_unique_url": "https://www.iitb.ac.in",
        "aff_unique_abbr": "IIT Bombay",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bombay",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "68d4442510",
        "title": "Multi-Fidelity Bayesian Optimization with Unreliable Information Sources",
        "site": "https://proceedings.mlr.press/v206/mikkola23a.html",
        "author": "Petrus Mikkola; Julien Martinelli; Louis Filstroff; Samuel Kaski",
        "abstract": "Bayesian optimization (BO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions. Over the past decade, many algorithms have been proposed to integrate cheaper, lower-fidelity approximations of the objective function into the optimization process, with the goal of converging towards the global optimum at a reduced cost. This task is generally referred to as multi-fidelity Bayesian optimization (MFBO). However, MFBO algorithms can lead to higher optimization costs than their vanilla BO counterparts, especially when the low-fidelity sources are poor approximations of the objective function, therefore defeating their purpose. To address this issue, we propose rMFBO (robust MFBO), a methodology to make any GP-based MFBO scheme robust to the addition of unreliable information sources. rMFBO comes with a theoretical guarantee that its performance can be bound to its vanilla BO analog, with high controllable probability. We demonstrate the effectiveness of the proposed methodology on a number of numerical benchmarks, outperforming earlier MFBO methods on unreliable sources. We expect rMFBO to be particularly useful to reliably include human experts with varying knowledge within BO processes.",
        "bibtex": "@InProceedings{pmlr-v206-mikkola23a,\n  title = \t {Multi-Fidelity Bayesian Optimization with Unreliable Information Sources},\n  author =       {Mikkola, Petrus and Martinelli, Julien and Filstroff, Louis and Kaski, Samuel},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7425--7454},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mikkola23a/mikkola23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mikkola23a.html},\n  abstract = \t {Bayesian optimization (BO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions. Over the past decade, many algorithms have been proposed to integrate cheaper, lower-fidelity approximations of the objective function into the optimization process, with the goal of converging towards the global optimum at a reduced cost. This task is generally referred to as multi-fidelity Bayesian optimization (MFBO). However, MFBO algorithms can lead to higher optimization costs than their vanilla BO counterparts, especially when the low-fidelity sources are poor approximations of the objective function, therefore defeating their purpose. To address this issue, we propose rMFBO (robust MFBO), a methodology to make any GP-based MFBO scheme robust to the addition of unreliable information sources. rMFBO comes with a theoretical guarantee that its performance can be bound to its vanilla BO analog, with high controllable probability. We demonstrate the effectiveness of the proposed methodology on a number of numerical benchmarks, outperforming earlier MFBO methods on unreliable sources. We expect rMFBO to be particularly useful to reliably include human experts with varying knowledge within BO processes.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mikkola23a/mikkola23a.pdf",
        "supp": "",
        "pdf_size": 2496921,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=159098990570602396&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f82d8c7e0a",
        "title": "Multi-armed Bandit Experimental Design: Online Decision-making and Adaptive Inference",
        "site": "https://proceedings.mlr.press/v206/simchi-levi23a.html",
        "author": "David Simchi-Levi; Chonghuan Wang",
        "abstract": "Multi-armed bandit has been well-known for its efficiency in online decision-making in terms of minimizing the loss of the participants\u2019 welfare during experiments (i.e., the regret). In clinical trials and many other scenarios, the statistical power of inferring the treatment effects (i.e., the gaps between the mean outcomes of different arms) is also crucial. Nevertheless, minimizing the regret entails harming the statistical power of estimating the treatment effect, since the observations from some arms can be limited. In this paper, we investigate the trade-off between efficiency and statistical power by casting the multi-armed bandit experimental design into a minimax multi-objective optimization problem. We introduce the concept of Pareto optimality to mathematically characterize the situation in which neither the statistical power nor the efficiency can be improved without degrading the other. We derive a useful sufficient and necessary condition for the Pareto optimal solutions. Additionally, we design an effective Pareto optimal multi-armed bandit experiment that can be tailored to different levels of the trade-off between the two objectives.",
        "bibtex": "@InProceedings{pmlr-v206-simchi-levi23a,\n  title = \t {Multi-armed Bandit Experimental Design: Online Decision-making and Adaptive Inference},\n  author =       {Simchi-Levi, David and Wang, Chonghuan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3086--3097},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/simchi-levi23a/simchi-levi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/simchi-levi23a.html},\n  abstract = \t {Multi-armed bandit has been well-known for its efficiency in online decision-making in terms of minimizing the loss of the participants\u2019 welfare during experiments (i.e., the regret). In clinical trials and many other scenarios, the statistical power of inferring the treatment effects (i.e., the gaps between the mean outcomes of different arms) is also crucial. Nevertheless, minimizing the regret entails harming the statistical power of estimating the treatment effect, since the observations from some arms can be limited. In this paper, we investigate the trade-off between efficiency and statistical power by casting the multi-armed bandit experimental design into a minimax multi-objective optimization problem. We introduce the concept of Pareto optimality to mathematically characterize the situation in which neither the statistical power nor the efficiency can be improved without degrading the other. We derive a useful sufficient and necessary condition for the Pareto optimal solutions. Additionally, we design an effective Pareto optimal multi-armed bandit experiment that can be tailored to different levels of the trade-off between the two objectives.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/simchi-levi23a/simchi-levi23a.pdf",
        "supp": "",
        "pdf_size": 527778,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18282434965588014447&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Laboratory for Information and Decision Systems, MIT; Laboratory for Information and Decision Systems, MIT",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e5d0496c29",
        "title": "Multi-task Representation Learning with Stochastic Linear Bandits",
        "site": "https://proceedings.mlr.press/v206/cella23a.html",
        "author": "Leonardo Cella; Karim Lounici; Gr\u00e9goire Pacreau; Massimiliano Pontil",
        "abstract": "We study the problem of transfer-learning in the setting of stochastic linear contextual bandit tasks. We consider that a low dimensional linear representation is shared across the tasks, and study the benefit of learning the tasks jointly. Following recent results to design Lasso stochastic bandit policies, we propose an efficient greedy policy based on trace norm regularization. It implicitly learns a low dimensional representation by encouraging the matrix formed by the task regression vectors to be of low rank. Unlike previous work in the literature, our policy does not need to know the rank of the underlying matrix, nor {does} it requires the covariance of the arms distribution to be invertible. We derive an upper bound on the multi-task regret of our policy, which is, up to logarithmic factors, of order $T\\sqrt{rN}+\\sqrt{rNTd}$, where $T$ is the number of tasks, $r$ the rank, $d$ the number of variables and $N$ the number of rounds per task. We show the benefit of our strategy over an independent task learning baseline, which has a worse regret of order $T\\sqrt{dN}$. We also argue that our policy {is minimax optimal} and, when $T\\geq d$, has a multi-task regret which is comparable to the regret of an oracle policy which knows the true underlying representation.",
        "bibtex": "@InProceedings{pmlr-v206-cella23a,\n  title = \t {Multi-task Representation Learning with Stochastic Linear Bandits},\n  author =       {Cella, Leonardo and Lounici, Karim and Pacreau, Gr\\'egoire and Pontil, Massimiliano},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4822--4847},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cella23a/cella23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cella23a.html},\n  abstract = \t {We study the problem of transfer-learning in the setting of stochastic linear contextual bandit tasks. We consider that a low dimensional linear representation is shared across the tasks, and study the benefit of learning the tasks jointly. Following recent results to design Lasso stochastic bandit policies, we propose an efficient greedy policy based on trace norm regularization. It implicitly learns a low dimensional representation by encouraging the matrix formed by the task regression vectors to be of low rank. Unlike previous work in the literature, our policy does not need to know the rank of the underlying matrix, nor {does} it requires the covariance of the arms distribution to be invertible. We derive an upper bound on the multi-task regret of our policy, which is, up to logarithmic factors, of order $T\\sqrt{rN}+\\sqrt{rNTd}$, where $T$ is the number of tasks, $r$ the rank, $d$ the number of variables and $N$ the number of rounds per task. We show the benefit of our strategy over an independent task learning baseline, which has a worse regret of order $T\\sqrt{dN}$. We also argue that our policy {is minimax optimal} and, when $T\\geq d$, has a multi-task regret which is comparable to the regret of an oracle policy which knows the true underlying representation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cella23a/cella23a.pdf",
        "supp": "",
        "pdf_size": 1310605,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16479345391639273513&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "914d4df736",
        "title": "Multilevel Bayesian Quadrature",
        "site": "https://proceedings.mlr.press/v206/li23a.html",
        "author": "Kaiyu Li; Daniel Giles; Toni Karvonen; Serge Guillas; Francois-Xavier Briol",
        "abstract": "Multilevel Monte Carlo is a key tool for approximating integrals involving expensive scientific models. The idea is to use approximations of the integrand to construct an estimator with improved accuracy over classical Monte Carlo. We propose to further enhance multilevel Monte Carlo through Bayesian surrogate models of the integrand, focusing on Gaussian process models and the associated Bayesian quadrature estimators. We show, using both theory and numerical experiments, that our approach can lead to significant improvements in accuracy when the integrand is expensive and smooth, and when the dimensionality is small or moderate. We conclude the paper with a case study illustrating the potential impact of our method in landslide-generated tsunami modelling, where the cost of each integrand evaluation is typically too large for operational settings.",
        "bibtex": "@InProceedings{pmlr-v206-li23a,\n  title = \t {Multilevel Bayesian Quadrature},\n  author =       {Li, Kaiyu and Giles, Daniel and Karvonen, Toni and Guillas, Serge and Briol, Francois-Xavier},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1845--1868},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/li23a/li23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/li23a.html},\n  abstract = \t {Multilevel Monte Carlo is a key tool for approximating integrals involving expensive scientific models. The idea is to use approximations of the integrand to construct an estimator with improved accuracy over classical Monte Carlo. We propose to further enhance multilevel Monte Carlo through Bayesian surrogate models of the integrand, focusing on Gaussian process models and the associated Bayesian quadrature estimators. We show, using both theory and numerical experiments, that our approach can lead to significant improvements in accuracy when the integrand is expensive and smooth, and when the dimensionality is small or moderate. We conclude the paper with a case study illustrating the potential impact of our method in landslide-generated tsunami modelling, where the cost of each integrand evaluation is typically too large for operational settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/li23a/li23a.pdf",
        "supp": "",
        "pdf_size": 3511510,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10062566143447571634&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "University College London; University College London; University of Helsinki; University College London + The Alan Turing Institute; University College London + The Alan Turing Institute",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0+2;0+2",
        "aff_unique_norm": "University College London;University of Helsinki;Alan Turing Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.helsinki.fi;https://www.turing.ac.uk",
        "aff_unique_abbr": "UCL;UH;ATI",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0+0;0+0",
        "aff_country_unique": "United Kingdom;Finland"
    },
    {
        "id": "58eec73ebb",
        "title": "Multiple-policy High-confidence Policy Evaluation",
        "site": "https://proceedings.mlr.press/v206/dann23a.html",
        "author": "Chris Dann; Mohammad Ghavamzadeh; Teodor V. Marinov",
        "abstract": "In reinforcement learning applications, we often want to accurately estimate the return of several policies of interest. We study this problem, multiple-policy high-confidence policy evaluation, where the goal is to estimate the return of all given target policies up to a desired accuracy with as few samples as possible. The natural approaches to this problem, i.e., evaluating each policy separately or estimating a model of the MDP, do not take into account the similarities between target policies and scale with the number of policies to evaluate or the size of the MDP, respectively. We present an alternative approach based on reusing samples from on-policy Monte-Carlo estimators and show that it is more sample-efficient in favorable cases. Specifically, we provide guarantees in terms of a notion of overlap of the set of target policies and shed light on when such an approach is indeed beneficial compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v206-dann23a,\n  title = \t {Multiple-policy High-confidence Policy Evaluation},\n  author =       {Dann, Chris and Ghavamzadeh, Mohammad and Marinov, Teodor V.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9470--9487},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dann23a/dann23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dann23a.html},\n  abstract = \t {In reinforcement learning applications, we often want to accurately estimate the return of several policies of interest. We study this problem, multiple-policy high-confidence policy evaluation, where the goal is to estimate the return of all given target policies up to a desired accuracy with as few samples as possible. The natural approaches to this problem, i.e., evaluating each policy separately or estimating a model of the MDP, do not take into account the similarities between target policies and scale with the number of policies to evaluate or the size of the MDP, respectively. We present an alternative approach based on reusing samples from on-policy Monte-Carlo estimators and show that it is more sample-efficient in favorable cases. Specifically, we provide guarantees in terms of a notion of overlap of the set of target policies and shed light on when such an approach is indeed beneficial compared to existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dann23a/dann23a.pdf",
        "supp": "",
        "pdf_size": 604794,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13199461419770281925&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ce7cae85b4",
        "title": "NODAGS-Flow: Nonlinear Cyclic Causal Structure Learning",
        "site": "https://proceedings.mlr.press/v206/sethuraman23a.html",
        "author": "Muralikrishnna G Sethuraman; Romain Lopez; Rahul Mohan; Faramarz Fekri; Tommaso Biancalani; Jan-Christian Huetter",
        "abstract": "Learning causal relationships between variables is a well-studied problem in statistics, with many important applications in science. However, modeling real-world systems remain challenging, as most existing algorithms assume that the underlying causal graph is acyclic. While this is a convenient framework for developing theoretical developments about causal reasoning and inference, the underlying modeling assumption is likely to be violated in real systems, because feedback loops are common (e.g., in biological systems). Although a few methods search for cyclic causal models, they usually rely on some form of linearity, which is also limiting, or lack a clear underlying probabilistic model. In this work, we propose a novel framework for learning nonlinear cyclic causal graphical models from interventional data, called NODAGS-Flow. We perform inference via direct likelihood optimization, employing techniques from residual normalizing flows for likelihood estimation. Through synthetic experiments and an application to single-cell high-content perturbation screening data, we show significant performance improvements with our approach compared to state-of-the-art methods with respect to structure recovery and predictive performance.",
        "bibtex": "@InProceedings{pmlr-v206-sethuraman23a,\n  title = \t {NODAGS-Flow: Nonlinear Cyclic Causal Structure Learning},\n  author =       {Sethuraman, Muralikrishnna G and Lopez, Romain and Mohan, Rahul and Fekri, Faramarz and Biancalani, Tommaso and Huetter, Jan-Christian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6371--6387},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sethuraman23a/sethuraman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sethuraman23a.html},\n  abstract = \t {Learning causal relationships between variables is a well-studied problem in statistics, with many important applications in science. However, modeling real-world systems remain challenging, as most existing algorithms assume that the underlying causal graph is acyclic. While this is a convenient framework for developing theoretical developments about causal reasoning and inference, the underlying modeling assumption is likely to be violated in real systems, because feedback loops are common (e.g., in biological systems). Although a few methods search for cyclic causal models, they usually rely on some form of linearity, which is also limiting, or lack a clear underlying probabilistic model. In this work, we propose a novel framework for learning nonlinear cyclic causal graphical models from interventional data, called NODAGS-Flow. We perform inference via direct likelihood optimization, employing techniques from residual normalizing flows for likelihood estimation. Through synthetic experiments and an application to single-cell high-content perturbation screening data, we show significant performance improvements with our approach compared to state-of-the-art methods with respect to structure recovery and predictive performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sethuraman23a/sethuraman23a.pdf",
        "supp": "",
        "pdf_size": 777970,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17950072817770624137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Georgia Institute of Technology; Stanford University, Genentech; Genentech; Georgia Institute of Technology; Genentech; Genentech",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;2;2",
        "aff_unique_norm": "Georgia Institute of Technology;Stanford University;Genentech",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.gatech.edu;https://www.stanford.edu;https://www.genentech.com",
        "aff_unique_abbr": "Georgia Tech;Stanford;Genentech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9acd5920ae",
        "title": "NTS-NOTEARS: Learning Nonparametric DBNs With Prior Knowledge",
        "site": "https://proceedings.mlr.press/v206/sun23c.html",
        "author": "Xiangyu Sun; Oliver Schulte; Guiliang Liu; Pascal Poupart",
        "abstract": "We describe NTS-NOTEARS, a score-based structure learning method for time-series data to learn dynamic Bayesian networks (DBNs) that captures nonlinear, lagged (inter-slice) and instantaneous (intra-slice) relations among variables. NTS-NOTEARS utilizes 1D convolutional neural networks (CNNs) to model the dependence of child variables on their parents; 1D CNN is a neural function approximation model well-suited for sequential data. DBN-CNN structure learning is formulated as a continuous optimization problem with an acyclicity constraint, following the NOTEARS DAG learning approach (Zheng et al., 2018, 2020). We show how prior knowledge of dependencies (e.g., forbidden and required edges) can be included as additional optimization constraints. Empirical evaluation on simulated and benchmark data shows that NTS-NOTEARS achieves state-of-the-art DAG structure quality compared to both parametric and nonparametric baseline methods, with improvement in the range of 10-20$%$ on the F1-score. We also evaluate NTS-NOTEARS on complex real-world data acquired from professional ice hockey games that contain a mixture of continuous and discrete variables. The code is available online.",
        "bibtex": "@InProceedings{pmlr-v206-sun23c,\n  title = \t {NTS-NOTEARS: Learning Nonparametric DBNs With Prior Knowledge},\n  author =       {Sun, Xiangyu and Schulte, Oliver and Liu, Guiliang and Poupart, Pascal},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1942--1964},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sun23c/sun23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sun23c.html},\n  abstract = \t {We describe NTS-NOTEARS, a score-based structure learning method for time-series data to learn dynamic Bayesian networks (DBNs) that captures nonlinear, lagged (inter-slice) and instantaneous (intra-slice) relations among variables. NTS-NOTEARS utilizes 1D convolutional neural networks (CNNs) to model the dependence of child variables on their parents; 1D CNN is a neural function approximation model well-suited for sequential data. DBN-CNN structure learning is formulated as a continuous optimization problem with an acyclicity constraint, following the NOTEARS DAG learning approach (Zheng et al., 2018, 2020). We show how prior knowledge of dependencies (e.g., forbidden and required edges) can be included as additional optimization constraints. Empirical evaluation on simulated and benchmark data shows that NTS-NOTEARS achieves state-of-the-art DAG structure quality compared to both parametric and nonparametric baseline methods, with improvement in the range of 10-20$%$ on the F1-score. We also evaluate NTS-NOTEARS on complex real-world data acquired from professional ice hockey games that contain a mixture of continuous and discrete variables. The code is available online.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sun23c/sun23c.pdf",
        "supp": "",
        "pdf_size": 21335399,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10794028244702660779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Simon Fraser University; Simon Fraser University; The Chinese University of Hong Kong, Shenzhen; University of Waterloo",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/xiangyu-sun-789/NTS-NOTEARS",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Simon Fraser University;Chinese University of Hong Kong;University of Waterloo",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.sfu.ca;https://www.cuhk.edu.cn;https://uwaterloo.ca",
        "aff_unique_abbr": "SFU;CUHK;UW",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "32e62b5ae0",
        "title": "Nash Equilibria and Pitfalls of Adversarial Training in Adversarial Robustness Games",
        "site": "https://proceedings.mlr.press/v206/balcan23a.html",
        "author": "Maria-Florina Balcan; Rattana Pukdee; Pradeep Ravikumar; Hongyang Zhang",
        "abstract": "Adversarial training is a standard technique for training adversarially robust models. In this paper, we study adversarial training as an alternating best-response strategy in a 2-player zero-sum game. We prove that even in a simple scenario of a linear classifier and a statistical model that abstracts robust vs. non-robust features, the alternating best response strategy of such game may not converge. On the other hand, a unique pure Nash equilibrium of the game exists and is provably robust. We support our theoretical results with experiments, showing the non-convergence of adversarial training and the robustness of Nash equilibrium.",
        "bibtex": "@InProceedings{pmlr-v206-balcan23a,\n  title = \t {Nash Equilibria and Pitfalls of Adversarial Training in Adversarial Robustness Games},\n  author =       {Balcan, Maria-Florina and Pukdee, Rattana and Ravikumar, Pradeep and Zhang, Hongyang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9607--9636},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/balcan23a/balcan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/balcan23a.html},\n  abstract = \t {Adversarial training is a standard technique for training adversarially robust models. In this paper, we study adversarial training as an alternating best-response strategy in a 2-player zero-sum game. We prove that even in a simple scenario of a linear classifier and a statistical model that abstracts robust vs. non-robust features, the alternating best response strategy of such game may not converge. On the other hand, a unique pure Nash equilibrium of the game exists and is provably robust. We support our theoretical results with experiments, showing the non-convergence of adversarial training and the robustness of Nash equilibrium.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/balcan23a/balcan23a.pdf",
        "supp": "",
        "pdf_size": 2518462,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10991996449130869124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0529f1cfb6",
        "title": "Near-Optimal Differentially Private Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/qiao23a.html",
        "author": "Dan Qiao; Yu-Xiang Wang",
        "abstract": "Motivated by personalized healthcare and other applications involving sensitive data, we study online exploration in reinforcement learning with differential privacy (DP) constraints. Existing work on this problem established that no-regret learning is possible under joint differential privacy (JDP) and local differential privacy (LDP) but did not provide an algorithm with optimal regret. We close this gap for the JDP case by designing an $\\epsilon$-JDP algorithm with a regret of $\\widetilde{O}(\\sqrt{SAH^2T}+S^2AH^3/\\epsilon)$ which matches the information-theoretic lower bound of non-private learning for all choices of $\\epsilon> S^{1.5}A^{0.5} H^2/\\sqrt{T}$. In the above, $S$, $A$ denote the number of states and actions, $H$ denotes the planning horizon, and $T$ is the number of steps. To the best of our knowledge, this is the first private RL algorithm that achieves privacy for free asymptotically as $T\\rightarrow \\infty$. Our techniques \u2014 which could be of independent interest \u2014 include privately releasing Bernstein-type exploration bonuses and an improved method for releasing visitation statistics. The same techniques also imply a slightly improved regret bound for the LDP case.",
        "bibtex": "@InProceedings{pmlr-v206-qiao23a,\n  title = \t {Near-Optimal Differentially Private Reinforcement Learning},\n  author =       {Qiao, Dan and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9914--9940},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qiao23a/qiao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qiao23a.html},\n  abstract = \t {Motivated by personalized healthcare and other applications involving sensitive data, we study online exploration in reinforcement learning with differential privacy (DP) constraints. Existing work on this problem established that no-regret learning is possible under joint differential privacy (JDP) and local differential privacy (LDP) but did not provide an algorithm with optimal regret. We close this gap for the JDP case by designing an $\\epsilon$-JDP algorithm with a regret of $\\widetilde{O}(\\sqrt{SAH^2T}+S^2AH^3/\\epsilon)$ which matches the information-theoretic lower bound of non-private learning for all choices of $\\epsilon> S^{1.5}A^{0.5} H^2/\\sqrt{T}$. In the above, $S$, $A$ denote the number of states and actions, $H$ denotes the planning horizon, and $T$ is the number of steps. To the best of our knowledge, this is the first private RL algorithm that achieves privacy for free asymptotically as $T\\rightarrow \\infty$. Our techniques \u2014 which could be of independent interest \u2014 include privately releasing Bernstein-type exploration bonuses and an improved method for releasing visitation statistics. The same techniques also imply a slightly improved regret bound for the LDP case.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qiao23a/qiao23a.pdf",
        "supp": "",
        "pdf_size": 436940,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2883814642069994106&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, UC Santa Barbara; Department of Computer Science, UC Santa Barbara",
        "aff_domain": "ucsb.edu;cs.ucsb.edu",
        "email": "ucsb.edu;cs.ucsb.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "00bfe1ef86",
        "title": "Nearly Optimal Latent State Decoding in Block MDPs",
        "site": "https://proceedings.mlr.press/v206/jedra23a.html",
        "author": "Yassir Jedra; Junghyun Lee; Alexandre Proutiere; Se-Young Yun",
        "abstract": "We consider the problem of model estimation in episodic Block MDPs. In these MDPs, the decision maker has access to rich observations or contexts generated from a small number of latent states. We are interested in estimating the latent state decoding function (the mapping from the observations to latent states) based on data generated under a fixed behavior policy. We derive an information-theoretical lower bound on the error rate for estimating this function and present an algorithm approaching this fundamental limit. In turn, our algorithm also provides estimates of all the components of the MDP. We apply our results to the problem of learning near-optimal policies in the reward-free setting. Based on our efficient model estimation algorithm, we show that we can infer a policy converging (as the number of collected samples grows large) to the optimal policy at the best possible rate. Our analysis provides necessary and sufficient conditions under which exploiting the block structure yields improvements in the sample complexity for identifying near-optimal policies. When these conditions are met, the sample complexity in the minimax reward-free setting is improved by a multiplicative factor $n$, where $n$ is the number of possible contexts.",
        "bibtex": "@InProceedings{pmlr-v206-jedra23a,\n  title = \t {Nearly Optimal Latent State Decoding in Block MDPs},\n  author =       {Jedra, Yassir and Lee, Junghyun and Proutiere, Alexandre and Yun, Se-Young},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2805--2904},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jedra23a/jedra23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jedra23a.html},\n  abstract = \t {We consider the problem of model estimation in episodic Block MDPs. In these MDPs, the decision maker has access to rich observations or contexts generated from a small number of latent states. We are interested in estimating the latent state decoding function (the mapping from the observations to latent states) based on data generated under a fixed behavior policy. We derive an information-theoretical lower bound on the error rate for estimating this function and present an algorithm approaching this fundamental limit. In turn, our algorithm also provides estimates of all the components of the MDP. We apply our results to the problem of learning near-optimal policies in the reward-free setting. Based on our efficient model estimation algorithm, we show that we can infer a policy converging (as the number of collected samples grows large) to the optimal policy at the best possible rate. Our analysis provides necessary and sufficient conditions under which exploiting the block structure yields improvements in the sample complexity for identifying near-optimal policies. When these conditions are met, the sample complexity in the minimax reward-free setting is improved by a multiplicative factor $n$, where $n$ is the number of possible contexts.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jedra23a/jedra23a.pdf",
        "supp": "",
        "pdf_size": 1497294,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=594238173398817114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Kim Jaechul Graduate School of AI, KAIST, Seoul, Republic of Korea; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Kim Jaechul Graduate School of AI, KAIST, Seoul, Republic of Korea",
        "aff_domain": "kth.se;kaist.ac.kr;kth.se;kaist.ac.kr",
        "email": "kth.se;kaist.ac.kr;kth.se;kaist.ac.kr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "KTH Royal Institute of Technology;KAIST",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;Kim Jaechul Graduate School of AI",
        "aff_unique_url": "https://www.kth.se;https://www.kaist.edu",
        "aff_unique_abbr": "KTH;KAIST",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Stockholm;Seoul",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Sweden;South Korea"
    },
    {
        "id": "d355796326",
        "title": "Neural Discovery of Permutation Subgroups",
        "site": "https://proceedings.mlr.press/v206/karjol23a.html",
        "author": "Pavan Karjol; Rohan Kashyap; Prathosh AP",
        "abstract": "We consider the problem of discovering subgroup $H$ of permutation group $S_n$. Unlike the traditional $H$-invariant networks wherein $H$ is assumed to be known, we present a method to discover the underlying subgroup, given that it satisfies certain conditions. Our results show that one could discover any subgroup of type $S_k (k \\leq n)$ by learning an $S_n$-invariant function and a linear transformation. We also prove similar results for cyclic and dihedral subgroups. Finally, we provide a general theorem that can be extended to discover other subgroups of $S_n$. We also demonstrate the applicability of our results through numerical experiments on image-digit sum and symmetric polynomial regression tasks.",
        "bibtex": "@InProceedings{pmlr-v206-karjol23a,\n  title = \t {Neural Discovery of Permutation Subgroups},\n  author =       {Karjol, Pavan and Kashyap, Rohan and {AP}, Prathosh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4668--4678},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/karjol23a/karjol23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/karjol23a.html},\n  abstract = \t {We consider the problem of discovering subgroup $H$ of permutation group $S_n$. Unlike the traditional $H$-invariant networks wherein $H$ is assumed to be known, we present a method to discover the underlying subgroup, given that it satisfies certain conditions. Our results show that one could discover any subgroup of type $S_k (k \\leq n)$ by learning an $S_n$-invariant function and a linear transformation. We also prove similar results for cyclic and dihedral subgroups. Finally, we provide a general theorem that can be extended to discover other subgroups of $S_n$. We also demonstrate the applicability of our results through numerical experiments on image-digit sum and symmetric polynomial regression tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/karjol23a/karjol23a.pdf",
        "supp": "",
        "pdf_size": 1139819,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16261800278913193672&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b4ede74531",
        "title": "Neural Laplace Control for Continuous-time Delayed Systems",
        "site": "https://proceedings.mlr.press/v206/holt23a.html",
        "author": "Samuel Holt; Alihan H\u00fcy\u00fck; Zhaozhi Qian; Hao Sun; Mihaela van der Schaar",
        "abstract": "Many real-world offline reinforcement learning (RL) problems involve continuous-time environments with delays. Such environments are characterized by two distinctive features: firstly, the state x(t) is observed at irregular time intervals, and secondly, the current action a(t) only affects the future state x(t + g) with an unknown delay g > 0. A prime example of such an environment is satellite control where the communication link between earth and a satellite causes irregular observations and delays. Existing offline RL algorithms have achieved success in environments with irregularly observed states in time or known delays. However, environments involving both irregular observations in time and unknown delays remains an open and challenging problem. To this end, we propose Neural Laplace Control, a continuous-time model-based offline RL method that combines a Neural Laplace dynamics model with a model predictive control (MPC) planner\u2013and is able to learn from an offline dataset sampled with irregular time intervals from an environment that has a inherent unknown constant delay. We show experimentally on continuous-time delayed environments it is able to achieve near expert policy performance.",
        "bibtex": "@InProceedings{pmlr-v206-holt23a,\n  title = \t {Neural Laplace Control for Continuous-time Delayed Systems},\n  author =       {Holt, Samuel and H\\\"uy\\\"uk, Alihan and Qian, Zhaozhi and Sun, Hao and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1747--1778},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/holt23a/holt23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/holt23a.html},\n  abstract = \t {Many real-world offline reinforcement learning (RL) problems involve continuous-time environments with delays. Such environments are characterized by two distinctive features: firstly, the state x(t) is observed at irregular time intervals, and secondly, the current action a(t) only affects the future state x(t + g) with an unknown delay g > 0. A prime example of such an environment is satellite control where the communication link between earth and a satellite causes irregular observations and delays. Existing offline RL algorithms have achieved success in environments with irregularly observed states in time or known delays. However, environments involving both irregular observations in time and unknown delays remains an open and challenging problem. To this end, we propose Neural Laplace Control, a continuous-time model-based offline RL method that combines a Neural Laplace dynamics model with a model predictive control (MPC) planner\u2013and is able to learn from an offline dataset sampled with irregular time intervals from an environment that has a inherent unknown constant delay. We show experimentally on continuous-time delayed environments it is able to achieve near expert policy performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/holt23a/holt23a.pdf",
        "supp": "",
        "pdf_size": 3136146,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16942165788016069037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Cambridge; University of Cambridge; University of Cambridge; University of Cambridge; University of Cambridge + The Alan Turing Institute",
        "aff_domain": "cam.ac.uk;cam.ac.uk;maths.cam.ac.uk;cam.ac.uk;cam.ac.uk",
        "email": "cam.ac.uk;cam.ac.uk;maths.cam.ac.uk;cam.ac.uk;cam.ac.uk",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0+1",
        "aff_unique_norm": "University of Cambridge;Alan Turing Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;ATI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "24c9dfc137",
        "title": "Neural Simulated Annealing",
        "site": "https://proceedings.mlr.press/v206/correia23a.html",
        "author": "Alvaro H.C. Correia; Daniel E. Worrall; Roberto Bondesan",
        "abstract": "Simulated annealing (SA) is a stochastic global optimisation metaheuristic applicable to a wide range of discrete and continuous variable problems. Despite its simplicity, SA hinges on carefully handpicked components, viz. proposal distribution and annealing schedule, that often have to be fine tuned to individual problem instances. In this work, we seek to make SA more effective and easier to use by framing its proposal distribution as a reinforcement learning policy that can be optimised for higher solution quality given a computational budget. The result is Neural SA, a competitive and general machine learning method for combinatorial optimisation that is efficient, and easy to design and train. We show Neural SA with such a learnt proposal distribution, parametrised by small equivariant neural networks, outperforms SA baselines on several problems: Rosenbrock\u2019s function and the Knapsack, Bin Packing and Travelling Salesperson problems. We also show Neural SA scales well to large problems (generalising to much larger instances than those seen during training) while getting comparable performance to popular off-the-shelf solvers and machine learning methods in terms of solution quality and wall-clock time.",
        "bibtex": "@InProceedings{pmlr-v206-correia23a,\n  title = \t {Neural Simulated Annealing},\n  author =       {Correia, Alvaro H.C. and Worrall, Daniel E. and Bondesan, Roberto},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4946--4962},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/correia23a/correia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/correia23a.html},\n  abstract = \t {Simulated annealing (SA) is a stochastic global optimisation metaheuristic applicable to a wide range of discrete and continuous variable problems. Despite its simplicity, SA hinges on carefully handpicked components, viz. proposal distribution and annealing schedule, that often have to be fine tuned to individual problem instances. In this work, we seek to make SA more effective and easier to use by framing its proposal distribution as a reinforcement learning policy that can be optimised for higher solution quality given a computational budget. The result is Neural SA, a competitive and general machine learning method for combinatorial optimisation that is efficient, and easy to design and train. We show Neural SA with such a learnt proposal distribution, parametrised by small equivariant neural networks, outperforms SA baselines on several problems: Rosenbrock\u2019s function and the Knapsack, Bin Packing and Travelling Salesperson problems. We also show Neural SA scales well to large problems (generalising to much larger instances than those seen during training) while getting comparable performance to popular off-the-shelf solvers and machine learning methods in terms of solution quality and wall-clock time.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/correia23a/correia23a.pdf",
        "supp": "",
        "pdf_size": 668052,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8620156498699286178&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "61cdea09d5",
        "title": "No time to waste: practical statistical contact tracing with few low-bit messages",
        "site": "https://proceedings.mlr.press/v206/romijnders23a.html",
        "author": "Rob Romijnders; Yuki M. Asano; Christos Louizos; Max Welling",
        "abstract": "Pandemics have a major impact on society and the economy. In the case of a new virus, such as COVID-19, high-grade tests and vaccines might be slow to develop and scarce in the crucial initial phase. With no time to waste and lock-downs being expensive, contact tracing is thus an essential tool for policymakers. In theory, statistical inference on a virus transmission model can provide an effective method for tracing infections. However, in practice, such algorithms need to run decentralized, rendering existing methods \u2013 that require hundreds or even thousands of daily messages per person \u2013 infeasible. In this paper, we develop an algorithm that (i) requires only a few (2-5) daily messages, (ii) works with extremely low bandwidths (3-5 bits) and (iii) enables quarantining and targeted testing that drastically reduces the peak and length of the pandemic. We compare the effectiveness of our algorithm using two agent-based simulators of realistic contact patterns and pandemic parameters and show that it performs well even with low bandwidth, imprecise tests, and incomplete population coverage.",
        "bibtex": "@InProceedings{pmlr-v206-romijnders23a,\n  title = \t {No time to waste: practical statistical contact tracing with few low-bit messages},\n  author =       {Romijnders, Rob and Asano, Yuki M. and Louizos, Christos and Welling, Max},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7943--7960},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/romijnders23a/romijnders23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/romijnders23a.html},\n  abstract = \t {Pandemics have a major impact on society and the economy. In the case of a new virus, such as COVID-19, high-grade tests and vaccines might be slow to develop and scarce in the crucial initial phase. With no time to waste and lock-downs being expensive, contact tracing is thus an essential tool for policymakers. In theory, statistical inference on a virus transmission model can provide an effective method for tracing infections. However, in practice, such algorithms need to run decentralized, rendering existing methods \u2013 that require hundreds or even thousands of daily messages per person \u2013 infeasible. In this paper, we develop an algorithm that (i) requires only a few (2-5) daily messages, (ii) works with extremely low bandwidths (3-5 bits) and (iii) enables quarantining and targeted testing that drastically reduces the peak and length of the pandemic. We compare the effectiveness of our algorithm using two agent-based simulators of realistic contact patterns and pandemic parameters and show that it performs well even with low bandwidth, imprecise tests, and incomplete population coverage.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/romijnders23a/romijnders23a.pdf",
        "supp": "",
        "pdf_size": 1220079,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5825789172569202022&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ca60937192",
        "title": "No-Regret Learning in Two-Echelon Supply Chain with Unknown Demand Distribution",
        "site": "https://proceedings.mlr.press/v206/zhang23e.html",
        "author": "Mengxiao Zhang; Shi Chen; Haipeng Luo; Yingfei Wang",
        "abstract": "Supply chain management (SCM) has been recognized as an important discipline with applications to many industries, where the two-echelon stochastic inventory model, involving one downstream retailer and one upstream supplier, plays a fundamental role for developing firms\u2019 SCM strategies. In this work, we aim at designing online learning algorithms for this problem with an unknown demand distribution, which brings distinct features as compared to classic online convex optimization problems. Specifically, we consider the two-echelon supply chain model introduced in [Cachon and Zipkin, 1999] under two different settings: the centralized setting, where a planner decides both agents\u2019 strategy simultaneously, and the decentralized setting, where two agents decide their strategy independently and selfishly. We design algorithms that achieve favorable guarantees for both regret and convergence to the optimal inventory decision in both settings, and additionally for individual regret in the decentralized setting. Our algorithms are based on Online Gradient Descent and Online Newton Step, together with several new ingredients specifically designed for our problem. We also implement our algorithms and show their empirical effectiveness.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23e,\n  title = \t {No-Regret Learning in Two-Echelon Supply Chain with Unknown Demand Distribution},\n  author =       {Zhang, Mengxiao and Chen, Shi and Luo, Haipeng and Wang, Yingfei},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3270--3298},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23e/zhang23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23e.html},\n  abstract = \t {Supply chain management (SCM) has been recognized as an important discipline with applications to many industries, where the two-echelon stochastic inventory model, involving one downstream retailer and one upstream supplier, plays a fundamental role for developing firms\u2019 SCM strategies. In this work, we aim at designing online learning algorithms for this problem with an unknown demand distribution, which brings distinct features as compared to classic online convex optimization problems. Specifically, we consider the two-echelon supply chain model introduced in [Cachon and Zipkin, 1999] under two different settings: the centralized setting, where a planner decides both agents\u2019 strategy simultaneously, and the decentralized setting, where two agents decide their strategy independently and selfishly. We design algorithms that achieve favorable guarantees for both regret and convergence to the optimal inventory decision in both settings, and additionally for individual regret in the decentralized setting. Our algorithms are based on Online Gradient Descent and Online Newton Step, together with several new ingredients specifically designed for our problem. We also implement our algorithms and show their empirical effectiveness.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23e/zhang23e.pdf",
        "supp": "",
        "pdf_size": 1338271,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12526961938988782860&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cd3775511a",
        "title": "No-regret Sample-efficient Bayesian Optimization for Finding Nash Equilibria with Unknown Utilities",
        "site": "https://proceedings.mlr.press/v206/tay23a.html",
        "author": "Sebastian Shenghong Tay; Quoc Phong Nguyen; Chuan Sheng Foo; Bryan Kian Hsiang Low",
        "abstract": "The Nash equilibrium (NE) is a classic solution concept for normal-form games that is stable under potential unilateral deviations by self-interested agents. Bayesian optimization (BO) has been used to find NE in continuous general-sum games with unknown costly-to-sample utility functions in a sample-efficient manner. This paper presents the first no-regret BO algorithm that is sample-efficient in finding pure NE by leveraging theory on high probability confidence bounds with Gaussian processes and the maximum information gain of kernel functions. Unlike previous works, our algorithm is theoretically guaranteed to converge to the optimal solution (i.e., NE). We also introduce the novel setting of applying BO to finding mixed NE in unknown discrete general-sum games and show that our theoretical framework is general enough to be extended naturally to this setting by developing a no-regret BO algorithm that is sample-efficient in finding mixed NE. We empirically show that our algorithms are competitive w.r.t. suitable baselines in finding NE.",
        "bibtex": "@InProceedings{pmlr-v206-tay23a,\n  title = \t {No-regret Sample-efficient Bayesian Optimization for Finding Nash Equilibria with Unknown Utilities},\n  author =       {Tay, Sebastian Shenghong and Nguyen, Quoc Phong and Foo, Chuan Sheng and Low, Bryan Kian Hsiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3591--3619},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tay23a/tay23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tay23a.html},\n  abstract = \t {The Nash equilibrium (NE) is a classic solution concept for normal-form games that is stable under potential unilateral deviations by self-interested agents. Bayesian optimization (BO) has been used to find NE in continuous general-sum games with unknown costly-to-sample utility functions in a sample-efficient manner. This paper presents the first no-regret BO algorithm that is sample-efficient in finding pure NE by leveraging theory on high probability confidence bounds with Gaussian processes and the maximum information gain of kernel functions. Unlike previous works, our algorithm is theoretically guaranteed to converge to the optimal solution (i.e., NE). We also introduce the novel setting of applying BO to finding mixed NE in unknown discrete general-sum games and show that our theoretical framework is general enough to be extended naturally to this setting by developing a no-regret BO algorithm that is sample-efficient in finding mixed NE. We empirically show that our algorithms are competitive w.r.t. suitable baselines in finding NE.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tay23a/tay23a.pdf",
        "supp": "",
        "pdf_size": 2706019,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7752413297264126551&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6c9b1cb08a",
        "title": "Noise-Aware Statistical Inference with Differentially Private Synthetic Data",
        "site": "https://proceedings.mlr.press/v206/raisa23a.html",
        "author": "Ossi R\u00e4is\u00e4; Joonas J\u00e4lk\u00f6; Samuel Kaski; Antti Honkela",
        "abstract": "While generation of synthetic data under differential privacy (DP) has received a lot of attention in the data privacy community, analysis of synthetic data has received much less. Existing work has shown that simply analysing DP synthetic data as if it were real does not produce valid inferences of population-level quantities. For example, confidence intervals become too narrow, which we demonstrate with a simple experiment. We tackle this problem by combining synthetic data analysis techniques from the field of multiple imputation (MI), and synthetic data generation using noise-aware (NA) Bayesian modeling into a pipeline NA+MI that allows computing accurate uncertainty estimates for population-level quantities from DP synthetic data. To implement NA+MI for discrete data generation using the values of marginal queries, we develop a novel noise-aware synthetic data generation algorithm NAPSU-MQ using the principle of maximum entropy. Our experiments demonstrate that the pipeline is able to produce accurate confidence intervals from DP synthetic data. The intervals become wider with tighter privacy to accurately capture the additional uncertainty stemming from DP noise.",
        "bibtex": "@InProceedings{pmlr-v206-raisa23a,\n  title = \t {Noise-Aware Statistical Inference with Differentially Private Synthetic Data},\n  author =       {R\\\"ais\\\"a, Ossi and J\\\"alk\\\"o, Joonas and Kaski, Samuel and Honkela, Antti},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3620--3643},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/raisa23a/raisa23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/raisa23a.html},\n  abstract = \t {While generation of synthetic data under differential privacy (DP) has received a lot of attention in the data privacy community, analysis of synthetic data has received much less. Existing work has shown that simply analysing DP synthetic data as if it were real does not produce valid inferences of population-level quantities. For example, confidence intervals become too narrow, which we demonstrate with a simple experiment. We tackle this problem by combining synthetic data analysis techniques from the field of multiple imputation (MI), and synthetic data generation using noise-aware (NA) Bayesian modeling into a pipeline NA+MI that allows computing accurate uncertainty estimates for population-level quantities from DP synthetic data. To implement NA+MI for discrete data generation using the values of marginal queries, we develop a novel noise-aware synthetic data generation algorithm NAPSU-MQ using the principle of maximum entropy. Our experiments demonstrate that the pipeline is able to produce accurate confidence intervals from DP synthetic data. The intervals become wider with tighter privacy to accurately capture the additional uncertainty stemming from DP noise.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/raisa23a/raisa23a.pdf",
        "supp": "",
        "pdf_size": 589922,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1756588967067521827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of Helsinki; University of Helsinki\u2217; Aalto University + University of Manchester; University of Helsinki",
        "aff_domain": "helsinki.fi;helsinki.fi;aalto.fi;helsinki.fi",
        "email": "helsinki.fi;helsinki.fi;aalto.fi;helsinki.fi",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;0",
        "aff_unique_norm": "University of Helsinki;Aalto University;University of Manchester",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.helsinki.fi;https://www.aalto.fi;https://www.manchester.ac.uk",
        "aff_unique_abbr": "UH;Aalto;UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1;0",
        "aff_country_unique": "Finland;United Kingdom"
    },
    {
        "id": "2d92410dbe",
        "title": "Noisy Low-rank Matrix Optimization: Geometry of Local Minima and Convergence Rate",
        "site": "https://proceedings.mlr.press/v206/ma23a.html",
        "author": "Ziye Ma; Somayeh Sojoudi",
        "abstract": "This paper is concerned with low-rank matrix optimization, which has found a wide range of applications in machine learning. This problem in the special case of matrix sensing has been studied extensively through the notion of Restricted Isometry Property (RIP), leading to a wealth of results on the geometric landscape of the problem and the convergence rate of common algorithms. However, the existing results can handle the problem in the case with a general objective function subject to noisy data only when the RIP constant is close to 0. In this paper, we develop a new mathematical framework to solve the above-mentioned problem with a far less restrictive RIP constant. We prove that as long as the RIP constant of the noiseless objective is less than 1/3, any spurious local solution of the noisy optimization problem must be close to the ground truth solution. By working through the strict saddle property, we also show that an approximate solution can be found in polynomial time. We characterize the geometry of the spurious local minima of the problem in a local region around the ground truth in the case when the RIP constant is greater than 1/3. Compared to the existing results in the literature, this paper offers the strongest RIP bound, and provides a complete theoretical analysis on the global and local optimization landscapes of general low-rank optimization problems under random corruptions from any finite-variance family.",
        "bibtex": "@InProceedings{pmlr-v206-ma23a,\n  title = \t {Noisy Low-rank Matrix Optimization: Geometry of Local Minima and Convergence Rate},\n  author =       {Ma, Ziye and Sojoudi, Somayeh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3125--3150},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ma23a/ma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ma23a.html},\n  abstract = \t {This paper is concerned with low-rank matrix optimization, which has found a wide range of applications in machine learning. This problem in the special case of matrix sensing has been studied extensively through the notion of Restricted Isometry Property (RIP), leading to a wealth of results on the geometric landscape of the problem and the convergence rate of common algorithms. However, the existing results can handle the problem in the case with a general objective function subject to noisy data only when the RIP constant is close to 0. In this paper, we develop a new mathematical framework to solve the above-mentioned problem with a far less restrictive RIP constant. We prove that as long as the RIP constant of the noiseless objective is less than 1/3, any spurious local solution of the noisy optimization problem must be close to the ground truth solution. By working through the strict saddle property, we also show that an approximate solution can be found in polynomial time. We characterize the geometry of the spurious local minima of the problem in a local region around the ground truth in the case when the RIP constant is greater than 1/3. Compared to the existing results in the literature, this paper offers the strongest RIP bound, and provides a complete theoretical analysis on the global and local optimization landscapes of general low-rank optimization problems under random corruptions from any finite-variance family.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ma23a/ma23a.pdf",
        "supp": "",
        "pdf_size": 743849,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16730237967145773713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of EECS, University of California, Berkeley + Department of Mechanical Engineering, University of California, Berkeley; Department of EECS, University of California, Berkeley",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0+0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f31bab9eeb",
        "title": "Nonmyopic Multiclass Active Search with Diminishing Returns for Diverse Discovery",
        "site": "https://proceedings.mlr.press/v206/nguyen23d.html",
        "author": "Quan Nguyen; Roman Garnett",
        "abstract": "Active search is a setting in adaptive experimental design where we aim to uncover members of rare, valuable class(es) subject to a budget constraint. An important consideration in this problem is diversity among the discovered targets \u2013 in many applications, diverse discoveries offer more insight and may be preferable in downstream tasks. However, most existing active search policies either assume that all targets belong to a common positive class or encourage diversity via simple heuristics. We present a novel formulation of active search with multiple target classes, characterized by a utility function chosen from a flexible family whose members encourage diversity among discoveries via a diminishing returns mechanism. We then study this problem under the Bayesian lens and prove a hardness result for approximating the optimal policy for arbitrary positive, increasing, and concave utility functions. Finally, we design an efficient, nonmyopic approximation to the optimal policy for this class of utilities and demonstrate its superior empirical performance in a variety of experimental settings, including drug discovery.",
        "bibtex": "@InProceedings{pmlr-v206-nguyen23d,\n  title = \t {Nonmyopic Multiclass Active Search with Diminishing Returns for Diverse Discovery},\n  author =       {Nguyen, Quan and Garnett, Roman},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5231--5249},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nguyen23d/nguyen23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nguyen23d.html},\n  abstract = \t {Active search is a setting in adaptive experimental design where we aim to uncover members of rare, valuable class(es) subject to a budget constraint. An important consideration in this problem is diversity among the discovered targets \u2013 in many applications, diverse discoveries offer more insight and may be preferable in downstream tasks. However, most existing active search policies either assume that all targets belong to a common positive class or encourage diversity via simple heuristics. We present a novel formulation of active search with multiple target classes, characterized by a utility function chosen from a flexible family whose members encourage diversity among discoveries via a diminishing returns mechanism. We then study this problem under the Bayesian lens and prove a hardness result for approximating the optimal policy for arbitrary positive, increasing, and concave utility functions. Finally, we design an efficient, nonmyopic approximation to the optimal policy for this class of utilities and demonstrate its superior empirical performance in a variety of experimental settings, including drug discovery.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nguyen23d/nguyen23d.pdf",
        "supp": "",
        "pdf_size": 451356,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12246443251623358965&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Washington University in St. Louis; Washington University in St. Louis",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Washington University in St. Louis",
        "aff_unique_dep": "",
        "aff_unique_url": "https://wustl.edu",
        "aff_unique_abbr": "WashU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "St. Louis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "08c4447da1",
        "title": "Nonparametric Gaussian Process Covariances via Multidimensional Convolutions",
        "site": "https://proceedings.mlr.press/v206/mcdonald23a.html",
        "author": "Thomas M. Mcdonald; Magnus Ross; Michael T. Smith; Mauricio A. \u00c1lvarez",
        "abstract": "A key challenge in the practical application of Gaussian processes (GPs) is selecting a proper covariance function. The process convolutions construction of GPs allows some additional flexibility, but still requires choosing a proper smoothing kernel, which is non-trivial. Previous approaches have built covariance functions by using GP priors over the smoothing kernel, and by extension the covariance, as a way to bypass the need to specify it in advance. However, these models have been limited in several ways: they are restricted to single dimensional inputs, e.g. time; they only allow modelling of single outputs and they do not scale to large datasets since inference is not straightforward. In this paper, we introduce a nonparametric process convolution formulation for GPs that alleviates these weaknesses. We achieve this using a functional sampling approach based on Matheron\u2019s rule to perform fast sampling using interdomain inducing variables. We test the performance of our model on benchmarks for single output, multi-output and large-scale GP regression, and find that our approach can provide improvements over standard GP models, particularly for larger datasets.",
        "bibtex": "@InProceedings{pmlr-v206-mcdonald23a,\n  title = \t {Nonparametric Gaussian Process Covariances via Multidimensional Convolutions},\n  author =       {Mcdonald, Thomas M. and Ross, Magnus and Smith, Michael T. and \\'Alvarez, Mauricio A.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8279--8293},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mcdonald23a/mcdonald23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mcdonald23a.html},\n  abstract = \t {A key challenge in the practical application of Gaussian processes (GPs) is selecting a proper covariance function. The process convolutions construction of GPs allows some additional flexibility, but still requires choosing a proper smoothing kernel, which is non-trivial. Previous approaches have built covariance functions by using GP priors over the smoothing kernel, and by extension the covariance, as a way to bypass the need to specify it in advance. However, these models have been limited in several ways: they are restricted to single dimensional inputs, e.g. time; they only allow modelling of single outputs and they do not scale to large datasets since inference is not straightforward. In this paper, we introduce a nonparametric process convolution formulation for GPs that alleviates these weaknesses. We achieve this using a functional sampling approach based on Matheron\u2019s rule to perform fast sampling using interdomain inducing variables. We test the performance of our model on benchmarks for single output, multi-output and large-scale GP regression, and find that our approach can provide improvements over standard GP models, particularly for larger datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mcdonald23a/mcdonald23a.pdf",
        "supp": "",
        "pdf_size": 2005033,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17817520963179186568&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2224e0327f",
        "title": "Nonparametric Indirect Active Learning",
        "site": "https://proceedings.mlr.press/v206/singh23a.html",
        "author": "Shashank Singh",
        "abstract": "Typical models of active learning assume a learner can directly manipulate or query a covariate X to study its relationship with a response Y. However, if X is a feature of a complex system, it may be possible only to indirectly influence X by manipulating a control variable Z, a scenario we refer to as Indirect Active Learning. Under a nonparametric fixed-budget model of Indirect Active Learning, we study minimax convergence rates for estimating a local relationship between X and Y, with different rates depending on the complexities and noise levels of the relationships between Z and X and between X and Y. We also derive minimax rates for passive learning under comparable assumptions, finding in many cases that, while there is an asymptotic benefit to active learning, this benefit is fully realized by a simple two-stage learner that runs two passive experiments in sequence.",
        "bibtex": "@InProceedings{pmlr-v206-singh23a,\n  title = \t {Nonparametric Indirect Active Learning},\n  author =       {Singh, Shashank},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2515--2541},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/singh23a/singh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/singh23a.html},\n  abstract = \t {Typical models of active learning assume a learner can directly manipulate or query a covariate X to study its relationship with a response Y. However, if X is a feature of a complex system, it may be possible only to indirectly influence X by manipulating a control variable Z, a scenario we refer to as Indirect Active Learning. Under a nonparametric fixed-budget model of Indirect Active Learning, we study minimax convergence rates for estimating a local relationship between X and Y, with different rates depending on the complexities and noise levels of the relationships between Z and X and between X and Y. We also derive minimax rates for passive learning under comparable assumptions, finding in many cases that, while there is an asymptotic benefit to active learning, this benefit is fully realized by a simple two-stage learner that runs two passive experiments in sequence.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/singh23a/singh23a.pdf",
        "supp": "",
        "pdf_size": 911752,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11923218033768188510&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "812488360d",
        "title": "Nonstationary Bandit Learning via Predictive Sampling",
        "site": "https://proceedings.mlr.press/v206/liu23e.html",
        "author": "Yueyang Liu; Benjamin Van Roy; Kuang Xu",
        "abstract": "Thompson sampling has proven effective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to nonstationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not differentiate actions based on how quickly the information acquired loses its usefulness due to nonstationarity. Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes acquiring information that quickly loses usefulness. Theoretical guarantee on the performance of predictive sampling is established through a Bayesian regret bound. We provide versions of predictive sampling for which computations tractably scale to complex bandit environments of practical interest. Through numerical simulation, we demonstrate that predictive sampling outperforms Thompson sampling in all nonstationary environments examined.",
        "bibtex": "@InProceedings{pmlr-v206-liu23e,\n  title = \t {Nonstationary Bandit Learning via Predictive Sampling},\n  author =       {Liu, Yueyang and Van Roy, Benjamin and Xu, Kuang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6215--6244},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23e/liu23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23e.html},\n  abstract = \t {Thompson sampling has proven effective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to nonstationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not differentiate actions based on how quickly the information acquired loses its usefulness due to nonstationarity. Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes acquiring information that quickly loses usefulness. Theoretical guarantee on the performance of predictive sampling is established through a Bayesian regret bound. We provide versions of predictive sampling for which computations tractably scale to complex bandit environments of practical interest. Through numerical simulation, we demonstrate that predictive sampling outperforms Thompson sampling in all nonstationary environments examined.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23e/liu23e.pdf",
        "supp": "",
        "pdf_size": 3818972,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4553849681873472019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f09fac5c2b",
        "title": "Nonstochastic Contextual Combinatorial Bandits",
        "site": "https://proceedings.mlr.press/v206/zierahn23a.html",
        "author": "Lukas Zierahn; Dirk van der Hoeven; Nicol\u00f2 Cesa-Bianchi; Gergely Neu",
        "abstract": "We study a contextual version of online combinatorial optimisation with full and semi-bandit feedback. In this sequential decision-making problem, an online learner has to select an action from a combinatorial decision space after seeing a vector-valued context in each round. As a result of its action, the learner incurs a loss that is a bilinear function of the context vector and the vector representation of the chosen action. We consider two natural versions of the problem: semi-bandit where the losses are revealed for each component appearing in the learner\u2019s combinatorial action, and full-bandit where only the total loss is observed. We design computationally efficient algorithms based on a new loss estimator that takes advantage of the special structure of the problem, and show regret bounds order $\\sqrt{T}$ with respect to the time horizon. The bounds demonstrate polynomial scaling with the relevant problem parameters which is shown to be nearly optimal. The theoretical results are complemented by a set of experiments on simulated data.",
        "bibtex": "@InProceedings{pmlr-v206-zierahn23a,\n  title = \t {Nonstochastic Contextual Combinatorial Bandits},\n  author =       {Zierahn, Lukas and van der Hoeven, Dirk and Cesa-Bianchi, Nicol\\`o and Neu, Gergely},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8771--8813},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zierahn23a/zierahn23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zierahn23a.html},\n  abstract = \t {We study a contextual version of online combinatorial optimisation with full and semi-bandit feedback. In this sequential decision-making problem, an online learner has to select an action from a combinatorial decision space after seeing a vector-valued context in each round. As a result of its action, the learner incurs a loss that is a bilinear function of the context vector and the vector representation of the chosen action. We consider two natural versions of the problem: semi-bandit where the losses are revealed for each component appearing in the learner\u2019s combinatorial action, and full-bandit where only the total loss is observed. We design computationally efficient algorithms based on a new loss estimator that takes advantage of the special structure of the problem, and show regret bounds order $\\sqrt{T}$ with respect to the time horizon. The bounds demonstrate polynomial scaling with the relevant problem parameters which is shown to be nearly optimal. The theoretical results are complemented by a set of experiments on simulated data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zierahn23a/zierahn23a.pdf",
        "supp": "",
        "pdf_size": 1050652,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13615778373845649819&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "45a1d47021",
        "title": "Nothing but Regrets \u2014 Privacy-Preserving Federated Causal Discovery",
        "site": "https://proceedings.mlr.press/v206/mian23a.html",
        "author": "Osman Mian; David Kaltenpoth; Michael Kamp; Jilles Vreeken",
        "abstract": "In critical applications, causal models are the prime choice for their trustworthiness and explainability. If data is inherently distributed and privacy-sensitive, federated learning allows for collaboratively training a joint model. Existing approaches for federated causal discovery share locally discovered causal model in every iteration, therewith not only revealing local structure but also leading to very high communication costs. Instead, we propose an approach for privacy-preserving federated causal discovery by distributed min-max regret optimization. We prove that max-regret is a consistent scoring criterion that can be used within the well-known Greedy Equivalence Search to discover causal networks in a federated setting and is provably privacy-preserving at the same time. Through extensive experiments, we show that our approach reliably discovers causal networks without ever looking at local data and beats the state of the art both in terms of the quality of discovered causal networks as well as communication efficiency.",
        "bibtex": "@InProceedings{pmlr-v206-mian23a,\n  title = \t {Nothing but Regrets \u2014 Privacy-Preserving Federated Causal Discovery},\n  author =       {Mian, Osman and Kaltenpoth, David and Kamp, Michael and Vreeken, Jilles},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8263--8278},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mian23a/mian23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mian23a.html},\n  abstract = \t {In critical applications, causal models are the prime choice for their trustworthiness and explainability. If data is inherently distributed and privacy-sensitive, federated learning allows for collaboratively training a joint model. Existing approaches for federated causal discovery share locally discovered causal model in every iteration, therewith not only revealing local structure but also leading to very high communication costs. Instead, we propose an approach for privacy-preserving federated causal discovery by distributed min-max regret optimization. We prove that max-regret is a consistent scoring criterion that can be used within the well-known Greedy Equivalence Search to discover causal networks in a federated setting and is provably privacy-preserving at the same time. Through extensive experiments, we show that our approach reliably discovers causal networks without ever looking at local data and beats the state of the art both in terms of the quality of discovered causal networks as well as communication efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mian23a/mian23a.pdf",
        "supp": "",
        "pdf_size": 384004,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6354848620847176716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "647c3f4450",
        "title": "Nystr\u00f6m Method for Accurate and Scalable Implicit Differentiation",
        "site": "https://proceedings.mlr.press/v206/hataya23a.html",
        "author": "Ryuichiro Hataya; Makoto Yamada",
        "abstract": "The essential difficulty of gradient-based bilevel optimization using implicit differentiation is to estimate the inverse Hessian vector product with respect to neural network parameters. This paper proposes to tackle this problem by the Nystr\u00f6m method and the Woodbury matrix identity, exploiting the low-rankness of the Hessian. Compared to existing methods using iterative approximation, such as conjugate gradient and the Neumann series approximation, the proposed method avoids numerical instability and can be efficiently computed in matrix operations without iterations. As a result, the proposed method works stably in various tasks and is faster than iterative approximations. Throughout experiments including large-scale hyperparameter optimization and meta learning, we demonstrate that the Nystr\u00f6m method consistently achieves comparable or even superior performance to other approaches. The source code is available from https://github.com/moskomule/hypergrad.",
        "bibtex": "@InProceedings{pmlr-v206-hataya23a,\n  title = \t {Nystr\u00f6m Method for Accurate and Scalable Implicit Differentiation},\n  author =       {Hataya, Ryuichiro and Yamada, Makoto},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4643--4654},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hataya23a/hataya23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hataya23a.html},\n  abstract = \t {The essential difficulty of gradient-based bilevel optimization using implicit differentiation is to estimate the inverse Hessian vector product with respect to neural network parameters. This paper proposes to tackle this problem by the Nystr\u00f6m method and the Woodbury matrix identity, exploiting the low-rankness of the Hessian. Compared to existing methods using iterative approximation, such as conjugate gradient and the Neumann series approximation, the proposed method avoids numerical instability and can be efficiently computed in matrix operations without iterations. As a result, the proposed method works stably in various tasks and is faster than iterative approximations. Throughout experiments including large-scale hyperparameter optimization and meta learning, we demonstrate that the Nystr\u00f6m method consistently achieves comparable or even superior performance to other approaches. The source code is available from https://github.com/moskomule/hypergrad.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hataya23a/hataya23a.pdf",
        "supp": "",
        "pdf_size": 1381805,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15612484438994680058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "RIKEN ADSP+RIKEN AIP; RIKEN AIP+OIST+Kyoto University",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/moskomule/hypergrad",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+1+2",
        "aff_unique_norm": "RIKEN;Okinawa Institute of Science and Technology;Kyoto University",
        "aff_unique_dep": "Advanced Data Science and Policy Research Center;;",
        "aff_unique_url": "https://www.riken.jp;https://www.oist.jp;https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "RIKEN;OIST;Kyoto U",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "5badb493a7",
        "title": "Oblivious near-optimal sampling for multidimensional signals with Fourier constraints",
        "site": "https://proceedings.mlr.press/v206/xu23f.html",
        "author": "Xingyu Xu; Yuantao Gu",
        "abstract": "We study the problem of reconstructing a continuous multidimensional signal from a small number of samples under Fourier constraints assuming that the Fourier power spectrum of the signal has some desirable properties, e.g. being compactly supported, being sparse. We further assume that the Fourier constraint can be expressed as a prior distribution on the Fourier power spectrum, which subsumes the aforementioned examples. The study of sampling and reconstructing in this vein has attracted much attention with a long history. In this paper, we are interested in finding oblivious sampling strategies, that is, sampling without knowing what specific constraint is put on the Fourier power spectrum. We show that it is possible to obliviously sample a Fourier-constrained multidimensional signal with a near-optimal (up to a logarithmic factor) number of samples that guarantee successful reconstruction, partially answering an open question in Avron et al. (2019) which considered the $1$-dimensional case. Our approach highlights a phenomenon that is unique for dimension $d\\ge 2$ that the sampling strategy should depend on the geometry of the region on which the signal is to be reconstructed, unlike the case $d=1$ where all regions are of the form $[a,b]$ which are all geometrically equivalent. Our proof, using tools from convex geometry, also illuminates an idea obscured in $d=1$, that to reconstruct a signal in a given region, it can be helpful to take some samples outside that region.",
        "bibtex": "@InProceedings{pmlr-v206-xu23f,\n  title = \t {Oblivious near-optimal sampling for multidimensional signals with Fourier constraints},\n  author =       {Xu, Xingyu and Gu, Yuantao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4532--4555},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23f/xu23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23f.html},\n  abstract = \t {We study the problem of reconstructing a continuous multidimensional signal from a small number of samples under Fourier constraints assuming that the Fourier power spectrum of the signal has some desirable properties, e.g. being compactly supported, being sparse. We further assume that the Fourier constraint can be expressed as a prior distribution on the Fourier power spectrum, which subsumes the aforementioned examples. The study of sampling and reconstructing in this vein has attracted much attention with a long history. In this paper, we are interested in finding oblivious sampling strategies, that is, sampling without knowing what specific constraint is put on the Fourier power spectrum. We show that it is possible to obliviously sample a Fourier-constrained multidimensional signal with a near-optimal (up to a logarithmic factor) number of samples that guarantee successful reconstruction, partially answering an open question in Avron et al. (2019) which considered the $1$-dimensional case. Our approach highlights a phenomenon that is unique for dimension $d\\ge 2$ that the sampling strategy should depend on the geometry of the region on which the signal is to be reconstructed, unlike the case $d=1$ where all regions are of the form $[a,b]$ which are all geometrically equivalent. Our proof, using tools from convex geometry, also illuminates an idea obscured in $d=1$, that to reconstruct a signal in a given region, it can be helpful to take some samples outside that region.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23f/xu23f.pdf",
        "supp": "",
        "pdf_size": 589309,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7164661462095111578&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Tsinghua University; Tsinghua University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "45c786a4a7",
        "title": "On Generalization of Decentralized Learning with Separable Data",
        "site": "https://proceedings.mlr.press/v206/taheri23a.html",
        "author": "Hossein Taheri; Christos Thrampoulidis",
        "abstract": "Decentralized learning offers privacy and communication efficiency when data are naturally distributed among agents communicating over an underlying graph. Motivated by overparameterized learning settings, in which models are trained to zero training loss, we study algorithmic and generalization properties of decentralized learning with gradient descent on separable data. Specifically, for decentralized gradient descent (DGD) and a variety of loss functions that asymptote to zero at infinity (including exponential and logistic losses), we derive novel finite-time generalization bounds. This complements a long line of recent work that studies the generalization performance and the implicit bias of gradient descent over separable data, but has thus far been limited to centralized learning scenarios. Notably, our generalization bounds approximately match in order their centralized counterparts. Critical behind this, and of independent interest, is establishing novel bounds on the training loss and the rate-of-consensus of DGD for a class of self-bounded losses. Finally, on the algorithmic front, we design improved gradient-based routines for decentralized learning with separable data and empirically demonstrate orders-of-magnitude of speed-up in terms of both training and generalization performance.",
        "bibtex": "@InProceedings{pmlr-v206-taheri23a,\n  title = \t {On Generalization of Decentralized Learning with Separable Data},\n  author =       {Taheri, Hossein and Thrampoulidis, Christos},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4917--4945},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/taheri23a/taheri23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/taheri23a.html},\n  abstract = \t {Decentralized learning offers privacy and communication efficiency when data are naturally distributed among agents communicating over an underlying graph. Motivated by overparameterized learning settings, in which models are trained to zero training loss, we study algorithmic and generalization properties of decentralized learning with gradient descent on separable data. Specifically, for decentralized gradient descent (DGD) and a variety of loss functions that asymptote to zero at infinity (including exponential and logistic losses), we derive novel finite-time generalization bounds. This complements a long line of recent work that studies the generalization performance and the implicit bias of gradient descent over separable data, but has thus far been limited to centralized learning scenarios. Notably, our generalization bounds approximately match in order their centralized counterparts. Critical behind this, and of independent interest, is establishing novel bounds on the training loss and the rate-of-consensus of DGD for a class of self-bounded losses. Finally, on the algorithmic front, we design improved gradient-based routines for decentralized learning with separable data and empirically demonstrate orders-of-magnitude of speed-up in terms of both training and generalization performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/taheri23a/taheri23a.pdf",
        "supp": "",
        "pdf_size": 1601950,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=729180736427245164&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of California, Santa Barbara; University of British Columbia",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, Santa Barbara;University of British Columbia",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsb.edu;https://www.ubc.ca",
        "aff_unique_abbr": "UCSB;UBC",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Santa Barbara;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "c08370d066",
        "title": "On Model Selection Consistency of Lasso for High-Dimensional Ising Models",
        "site": "https://proceedings.mlr.press/v206/meng23a.html",
        "author": "Xiangming Meng; Tomoyuki Obuchi; Yoshiyuki Kabashima",
        "abstract": "We theoretically analyze the model selection consistency of least absolute shrinkage and selection operator (Lasso), both with and without post-thresholding, for high-dimensional Ising models. For random regular (RR) graphs of size $p$ with regular node degree $d$ and uniform couplings $\\theta_0$, it is rigorously proved that Lasso without post-thresholding is model selection consistent in the whole paramagnetic phase with the same order of sample complexity $n=\\Omega{(d^3\\log{p})}$ as that of $\\ell_1$-regularized logistic regression ($\\ell_1$-LogR). This result is consistent with the conjecture in Meng, Obuchi, and Kabashima 2021 using the non-rigorous replica method from statistical physics and thus complements it with a rigorous proof. For general tree-like graphs, it is demonstrated that the same result as RR graphs can be obtained under mild assumptions of the dependency condition and incoherence condition. Moreover, we provide a rigorous proof of the model selection consistency of Lasso with post-thresholding for general tree-like graphs in the paramagnetic phase without further assumptions on the dependency and incoherence conditions. Experimental results agree well with our theoretical analysis.",
        "bibtex": "@InProceedings{pmlr-v206-meng23a,\n  title = \t {On Model Selection Consistency of Lasso for High-Dimensional Ising Models},\n  author =       {Meng, Xiangming and Obuchi, Tomoyuki and Kabashima, Yoshiyuki},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6783--6805},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/meng23a/meng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/meng23a.html},\n  abstract = \t {We theoretically analyze the model selection consistency of least absolute shrinkage and selection operator (Lasso), both with and without post-thresholding, for high-dimensional Ising models. For random regular (RR) graphs of size $p$ with regular node degree $d$ and uniform couplings $\\theta_0$, it is rigorously proved that Lasso without post-thresholding is model selection consistent in the whole paramagnetic phase with the same order of sample complexity $n=\\Omega{(d^3\\log{p})}$ as that of $\\ell_1$-regularized logistic regression ($\\ell_1$-LogR). This result is consistent with the conjecture in Meng, Obuchi, and Kabashima 2021 using the non-rigorous replica method from statistical physics and thus complements it with a rigorous proof. For general tree-like graphs, it is demonstrated that the same result as RR graphs can be obtained under mild assumptions of the dependency condition and incoherence condition. Moreover, we provide a rigorous proof of the model selection consistency of Lasso with post-thresholding for general tree-like graphs in the paramagnetic phase without further assumptions on the dependency and incoherence conditions. Experimental results agree well with our theoretical analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/meng23a/meng23a.pdf",
        "supp": "",
        "pdf_size": 544603,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18414350860838270782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f1b12af6c4",
        "title": "On The Convergence Of Policy Iteration-Based Reinforcement Learning With Monte Carlo Policy Evaluation",
        "site": "https://proceedings.mlr.press/v206/winnicki23a.html",
        "author": "Anna Winnicki; R. Srikant",
        "abstract": "A common technique in reinforcement learning is to evaluate the value function from Monte Carlo simulations of a given policy, and use the estimated value function to obtain a new policy which is greedy with respect to the estimated value function. A well-known longstanding open problem in this context is to prove the convergence of such a scheme when the value function of a policy is estimated from data collected from a single sample path obtained from implementing the policy (see page 99 of [Sutton and Barto, 2018], page 8 of [Tsitsiklis, 2002]). We present a solution to the open problem by showing that a first-visit version of such a policy iteration scheme indeed converges to the optimal policy provided that the policy improvement step uses lookahead [Silver et al., 2016, Mnih et al., 2016, Silver et al., 2017b] rather than a simple greedy policy improvement. We provide results both for the original open problem in the tabular setting and also present extensions to the function approximation setting, where we show that the policy resulting from the algorithm performs close to the optimal policy within a function approximation error.",
        "bibtex": "@InProceedings{pmlr-v206-winnicki23a,\n  title = \t {On The Convergence Of Policy Iteration-Based Reinforcement Learning With Monte Carlo Policy Evaluation},\n  author =       {Winnicki, Anna and Srikant, R.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9852--9878},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/winnicki23a/winnicki23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/winnicki23a.html},\n  abstract = \t {A common technique in reinforcement learning is to evaluate the value function from Monte Carlo simulations of a given policy, and use the estimated value function to obtain a new policy which is greedy with respect to the estimated value function. A well-known longstanding open problem in this context is to prove the convergence of such a scheme when the value function of a policy is estimated from data collected from a single sample path obtained from implementing the policy (see page 99 of [Sutton and Barto, 2018], page 8 of [Tsitsiklis, 2002]). We present a solution to the open problem by showing that a first-visit version of such a policy iteration scheme indeed converges to the optimal policy provided that the policy improvement step uses lookahead [Silver et al., 2016, Mnih et al., 2016, Silver et al., 2017b] rather than a simple greedy policy improvement. We provide results both for the original open problem in the tabular setting and also present extensions to the function approximation setting, where we show that the policy resulting from the algorithm performs close to the optimal policy within a function approximation error.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/winnicki23a/winnicki23a.pdf",
        "supp": "",
        "pdf_size": 286051,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16551708946579995076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Illinois Urbana-Champaign; University of Illinois Urbana-Champaign",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3ff260f861",
        "title": "On Universal Portfolios with Continuous Side Information",
        "site": "https://proceedings.mlr.press/v206/bhatt23a.html",
        "author": "Alankrita Bhatt; J. Jon Ryu; Young-Han Kim",
        "abstract": "A new portfolio selection strategy that adapts to a continuous side-information sequence is presented, with a universal wealth guarantee against a class of state-constant rebalanced portfolios with respect to a state function that maps each side-information symbol to a finite set of states. In particular, given that a state function belongs to a collection of functions of finite Natarajan dimension, the proposed strategy is shown to achieve, asymptotically to first order in the exponent, the same wealth as the best state-constant rebalanced portfolio with respect to the best state function, chosen in hindsight from observed market. This result can be viewed as an extension of the seminal work of Cover and Ordentlich (1996) that assumes a single-state function.",
        "bibtex": "@InProceedings{pmlr-v206-bhatt23a,\n  title = \t {On Universal Portfolios with Continuous Side Information},\n  author =       {Bhatt, Alankrita and Ryu, J. Jon and Kim, Young-Han},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4147--4163},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bhatt23a/bhatt23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bhatt23a.html},\n  abstract = \t {A new portfolio selection strategy that adapts to a continuous side-information sequence is presented, with a universal wealth guarantee against a class of state-constant rebalanced portfolios with respect to a state function that maps each side-information symbol to a finite set of states. In particular, given that a state function belongs to a collection of functions of finite Natarajan dimension, the proposed strategy is shown to achieve, asymptotically to first order in the exponent, the same wealth as the best state-constant rebalanced portfolio with respect to the best state function, chosen in hindsight from observed market. This result can be viewed as an extension of the seminal work of Cover and Ordentlich (1996) that assumes a single-state function.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bhatt23a/bhatt23a.pdf",
        "supp": "",
        "pdf_size": 409466,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11573174306371994544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ece80daa95",
        "title": "On double-descent in uncertainty quantification in overparametrized models",
        "site": "https://proceedings.mlr.press/v206/clarte23a.html",
        "author": "Lucas Clarte; Bruno Loureiro; Florent Krzakala; Lenka Zdeborova",
        "abstract": "Uncertainty quantification is a central challenge in reliable and trustworthy machine learning. Naive measures such as last-layer scores are well-known to yield overconfident estimates in the context of overparametrized neural networks. Several methods, ranging from temperature scaling to different Bayesian treatments of neural networks, have been proposed to mitigate overconfidence, most often supported by the numerical observation that they yield better calibrated uncertainty measures. In this work, we provide a sharp comparison between popular uncertainty measures for binary classification in a mathematically tractable model for overparametrized neural networks: the random features model. We discuss a trade-off between classification accuracy and calibration, unveiling a double descent behavior in the calibration curve of optimally regularised estimators as a function of overparametrization. This is in contrast with the empirical Bayes method, which we show to be well calibrated in our setting despite the higher generalization error and overparametrization.",
        "bibtex": "@InProceedings{pmlr-v206-clarte23a,\n  title = \t {On double-descent in uncertainty quantification in overparametrized models},\n  author =       {Clarte, Lucas and Loureiro, Bruno and Krzakala, Florent and Zdeborova, Lenka},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7089--7125},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/clarte23a/clarte23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/clarte23a.html},\n  abstract = \t {Uncertainty quantification is a central challenge in reliable and trustworthy machine learning. Naive measures such as last-layer scores are well-known to yield overconfident estimates in the context of overparametrized neural networks. Several methods, ranging from temperature scaling to different Bayesian treatments of neural networks, have been proposed to mitigate overconfidence, most often supported by the numerical observation that they yield better calibrated uncertainty measures. In this work, we provide a sharp comparison between popular uncertainty measures for binary classification in a mathematically tractable model for overparametrized neural networks: the random features model. We discuss a trade-off between classification accuracy and calibration, unveiling a double descent behavior in the calibration curve of optimally regularised estimators as a function of overparametrization. This is in contrast with the empirical Bayes method, which we show to be well calibrated in our setting despite the higher generalization error and overparametrization.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/clarte23a/clarte23a.pdf",
        "supp": "",
        "pdf_size": 732923,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11822062823568620780&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4ae0c3bc0a",
        "title": "On the Accelerated Noise-Tolerant Power Method",
        "site": "https://proceedings.mlr.press/v206/xu23g.html",
        "author": "Zhiqiang Xu",
        "abstract": "We revisit the acceleration of the noise-tolerant power method for which, despite previous studies, the results remain unsatisfactory as they are either wrong or suboptimal, also lacking generality. In this work, we present a simple yet general and optimal analysis via noise-corrupted Chebyshev polynomials, which allows a larger iteration rank $p$ than the target rank $k$, requires less noise conditions in a new form, and achieves the optimal iteration complexity $\\Theta\\left(\\sqrt{\\frac{\\lambda_{k}-\\lambda_{q+1}}{\\lambda_{k}}}\\log\\frac{1}{\\epsilon}\\right)$ for some $q$ satisfying $k\\leq q\\leq p$ in a certain regime of the momentum parameter. Interestingly, it shows dynamic dependence of the noise tolerance on the spectral gap, i.e., from linear at the beginning to square-root near convergence, while remaining commensurate with the previous in terms of overall tolerance. We relate our new form of noise norm conditions to the existing trigonometric one, which enables an improved analysis of generalized eigenspace computation and canonical correlation analysis. We conduct an extensive experimental study to showcase the great performance of the considered algorithm with a larger iteration rank $p>k$ across different applications.",
        "bibtex": "@InProceedings{pmlr-v206-xu23g,\n  title = \t {On the Accelerated Noise-Tolerant Power Method},\n  author =       {Xu, Zhiqiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7147--7175},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23g/xu23g.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23g.html},\n  abstract = \t {We revisit the acceleration of the noise-tolerant power method for which, despite previous studies, the results remain unsatisfactory as they are either wrong or suboptimal, also lacking generality. In this work, we present a simple yet general and optimal analysis via noise-corrupted Chebyshev polynomials, which allows a larger iteration rank $p$ than the target rank $k$, requires less noise conditions in a new form, and achieves the optimal iteration complexity $\\Theta\\left(\\sqrt{\\frac{\\lambda_{k}-\\lambda_{q+1}}{\\lambda_{k}}}\\log\\frac{1}{\\epsilon}\\right)$ for some $q$ satisfying $k\\leq q\\leq p$ in a certain regime of the momentum parameter. Interestingly, it shows dynamic dependence of the noise tolerance on the spectral gap, i.e., from linear at the beginning to square-root near convergence, while remaining commensurate with the previous in terms of overall tolerance. We relate our new form of noise norm conditions to the existing trigonometric one, which enables an improved analysis of generalized eigenspace computation and canonical correlation analysis. We conduct an extensive experimental study to showcase the great performance of the considered algorithm with a larger iteration rank $p>k$ across different applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23g/xu23g.pdf",
        "supp": "",
        "pdf_size": 846377,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11972595289081940707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "MachineLearningDepartment, MohamedbinZayedUniversityofArti\ufb01cialIntelligence, AbuDhabi,UAE",
        "aff_domain": "mbzuai.ac.ae",
        "email": "mbzuai.ac.ae",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Mohamed bin Zayed University of Artificial Intelligence",
        "aff_unique_dep": "Machine Learning Department",
        "aff_unique_url": "https://www.mbru.ac.ae",
        "aff_unique_abbr": "MBZUAI",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Abu Dhabi",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Arab Emirates"
    },
    {
        "id": "16b8d07e8f",
        "title": "On the Calibration of Probabilistic Classifier Sets",
        "site": "https://proceedings.mlr.press/v206/mortier23a.html",
        "author": "Thomas Mortier; Viktor Bengs; Eyke H\u00fcllermeier; Stijn Luca; Willem Waegeman",
        "abstract": "Multi-class classification methods that produce sets of probabilistic classifiers, such as ensemble learning methods, are able to model aleatoric and epistemic uncertainty. Aleatoric uncertainty is then typically quantified via the Bayes error, and epistemic uncertainty via the size of the set. In this paper, we extend the notion of calibration, which is commonly used to evaluate the validity of the aleatoric uncertainty representation of a single probabilistic classifier, to assess the validity of an epistemic uncertainty representation obtained by sets of probabilistic classifiers. Broadly speaking, we call a set of probabilistic classifiers calibrated if one can find a calibrated convex combination of these classifiers. To evaluate this notion of calibration, we propose a novel nonparametric calibration test that generalizes an existing test for single probabilistic classifiers to the case of sets of probabilistic classifiers. Making use of this test, we empirically show that ensembles of deep neural networks are often not well calibrated.",
        "bibtex": "@InProceedings{pmlr-v206-mortier23a,\n  title = \t {On the Calibration of Probabilistic Classifier Sets},\n  author =       {Mortier, Thomas and Bengs, Viktor and H\\\"ullermeier, Eyke and Luca, Stijn and Waegeman, Willem},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8857--8870},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mortier23a/mortier23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mortier23a.html},\n  abstract = \t {Multi-class classification methods that produce sets of probabilistic classifiers, such as ensemble learning methods, are able to model aleatoric and epistemic uncertainty. Aleatoric uncertainty is then typically quantified via the Bayes error, and epistemic uncertainty via the size of the set. In this paper, we extend the notion of calibration, which is commonly used to evaluate the validity of the aleatoric uncertainty representation of a single probabilistic classifier, to assess the validity of an epistemic uncertainty representation obtained by sets of probabilistic classifiers. Broadly speaking, we call a set of probabilistic classifiers calibrated if one can find a calibrated convex combination of these classifiers. To evaluate this notion of calibration, we propose a novel nonparametric calibration test that generalizes an existing test for single probabilistic classifiers to the case of sets of probabilistic classifiers. Making use of this test, we empirically show that ensembles of deep neural networks are often not well calibrated.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mortier23a/mortier23a.pdf",
        "supp": "",
        "pdf_size": 764911,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11155015896214648655&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Ghent University; LMU Munich; LMU Munich; Ghent University; Ghent University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Ghent University;Ludwig Maximilian University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ugent.be/en;https://www.lmu.de",
        "aff_unique_abbr": "UGent;LMU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Belgium;Germany"
    },
    {
        "id": "ded4465de7",
        "title": "On the Capacity Limits of Privileged ERM",
        "site": "https://proceedings.mlr.press/v206/sharoni23a.html",
        "author": "Michal Sharoni; Sivan Sabato",
        "abstract": "We study the supervised learning paradigm called Learning Using Privileged Information, first suggested by Vapnik and Vashist (2009). In this paradigm, in addition to the examples and labels, additional (privileged) information is provided only for training examples. The goal is to use this information to improve the classification accuracy of the resulting classifier, where this classifier can only use the non-privileged information of new example instances to predict their label. We study the theory of privileged learning with the zero-one loss under the natural Privileged ERM algorithm proposed in Peshyony and Vapnik (2010). We provide a counter example to a claim made in that work regarding the VC dimension of the loss class induced by this problem; We conclude that the claim is incorrect. We then provide a correct VC dimension analysis which gives both lower and upper bounds on the capacity of the Privileged ERM loss class. We further show, via a generalization analysis, that worst-case guarantees for Privileged ERM cannot improve over standard non-privileged ERM, unless the capacity of the privileged information is similar or smaller to that of the non-privileged information. This result points to an important limitation of the Privileged ERM approach. In our closing discussion, we suggest another way in which Privileged ERM might still be helpful, even when the capacity of the privileged information is large.",
        "bibtex": "@InProceedings{pmlr-v206-sharoni23a,\n  title = \t {On the Capacity Limits of Privileged ERM},\n  author =       {Sharoni, Michal and Sabato, Sivan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {523--534},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sharoni23a/sharoni23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sharoni23a.html},\n  abstract = \t {We study the supervised learning paradigm called Learning Using Privileged Information, first suggested by Vapnik and Vashist (2009). In this paradigm, in addition to the examples and labels, additional (privileged) information is provided only for training examples. The goal is to use this information to improve the classification accuracy of the resulting classifier, where this classifier can only use the non-privileged information of new example instances to predict their label. We study the theory of privileged learning with the zero-one loss under the natural Privileged ERM algorithm proposed in Peshyony and Vapnik (2010). We provide a counter example to a claim made in that work regarding the VC dimension of the loss class induced by this problem; We conclude that the claim is incorrect. We then provide a correct VC dimension analysis which gives both lower and upper bounds on the capacity of the Privileged ERM loss class. We further show, via a generalization analysis, that worst-case guarantees for Privileged ERM cannot improve over standard non-privileged ERM, unless the capacity of the privileged information is similar or smaller to that of the non-privileged information. This result points to an important limitation of the Privileged ERM approach. In our closing discussion, we suggest another way in which Privileged ERM might still be helpful, even when the capacity of the privileged information is large.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sharoni23a/sharoni23a.pdf",
        "supp": "",
        "pdf_size": 339906,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Hvxj-lgnvrMJ:scholar.google.com/&scioq=On+the+Capacity+Limits+of+Privileged+ERM&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev, Beer-Sheva, Israel; Department of Computer Science, Ben-Gurion University of the Negev, Beer-Sheva, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beer-Sheva",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "67e3e3d0c9",
        "title": "On the Complexity of Representation Learning in Contextual Linear Bandits",
        "site": "https://proceedings.mlr.press/v206/tirinzoni23a.html",
        "author": "Andrea Tirinzoni; Matteo Pirotta; Alessandro Lazaric",
        "abstract": "In contextual linear bandits, the reward function is assumed to be a linear combination of an unknown reward vector and a given embedding of context-arm pairs. In practice, the embedding is often learned at the same time as the reward vector, thus leading to an online representation learning problem. Existing approaches to representation learning in contextual bandits are either very generic (e.g., model-selection techniques or algorithms for learning with arbitrary function classes) or specialized to particular structures (e.g., nested features or representations with certain spectral properties). As a result, the understanding of the cost of representation learning in contextual linear bandit is still limited. In this paper, we take a systematic approach to the problem and provide a comprehensive study through an instance-dependent perspective. We show that representation learning is fundamentally more complex than linear bandits (i.e., learning with a given representation). In particular, learning with a given set of representations is never simpler than learning with the worst realizable representation in the set, while we show cases where it can be arbitrarily harder. We complement this result with an extensive discussion of how it relates to existing literature and we illustrate positive instances where representation learning is as complex as learning with a fixed representation and where sub-logarithmic regret is achievable.",
        "bibtex": "@InProceedings{pmlr-v206-tirinzoni23a,\n  title = \t {On the Complexity of Representation Learning in Contextual Linear Bandits},\n  author =       {Tirinzoni, Andrea and Pirotta, Matteo and Lazaric, Alessandro},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7871--7896},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tirinzoni23a/tirinzoni23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tirinzoni23a.html},\n  abstract = \t {In contextual linear bandits, the reward function is assumed to be a linear combination of an unknown reward vector and a given embedding of context-arm pairs. In practice, the embedding is often learned at the same time as the reward vector, thus leading to an online representation learning problem. Existing approaches to representation learning in contextual bandits are either very generic (e.g., model-selection techniques or algorithms for learning with arbitrary function classes) or specialized to particular structures (e.g., nested features or representations with certain spectral properties). As a result, the understanding of the cost of representation learning in contextual linear bandit is still limited. In this paper, we take a systematic approach to the problem and provide a comprehensive study through an instance-dependent perspective. We show that representation learning is fundamentally more complex than linear bandits (i.e., learning with a given representation). In particular, learning with a given set of representations is never simpler than learning with the worst realizable representation in the set, while we show cases where it can be arbitrarily harder. We complement this result with an extensive discussion of how it relates to existing literature and we illustrate positive instances where representation learning is as complex as learning with a fixed representation and where sub-logarithmic regret is achievable.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tirinzoni23a/tirinzoni23a.pdf",
        "supp": "",
        "pdf_size": 447743,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17634984716291089402&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "653454f7e4",
        "title": "On the Consistency Rate of Decision Tree Learning Algorithms",
        "site": "https://proceedings.mlr.press/v206/zheng23b.html",
        "author": "Qin-Cheng Zheng; Shen-Huan Lyu; Shao-Qun Zhang; Yuan Jiang; Zhi-Hua Zhou",
        "abstract": "Decision tree learning algorithms such as CART are generally based on heuristics that maximizes the purity gain greedily. Though these algorithms are practically successful, theoretical properties such as consistency are far from clear. In this paper, we discover that the most serious obstacle encumbering consistency analysis for decision tree learning algorithms lies in the fact that the worst-case purity gain, i.e., the core heuristics for tree splitting, can be zero. Based on this recognition, we present a new algorithm, named Grid Classification And Regression Tree (GridCART), with a provable consistency rate $\\mathcal{O}(n^{-1 / (d + 2)})$, which is the first consistency rate proved for heuristic tree learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-zheng23b,\n  title = \t {On the Consistency Rate of Decision Tree Learning Algorithms},\n  author =       {Zheng, Qin-Cheng and Lyu, Shen-Huan and Zhang, Shao-Qun and Jiang, Yuan and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7824--7848},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zheng23b/zheng23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zheng23b.html},\n  abstract = \t {Decision tree learning algorithms such as CART are generally based on heuristics that maximizes the purity gain greedily. Though these algorithms are practically successful, theoretical properties such as consistency are far from clear. In this paper, we discover that the most serious obstacle encumbering consistency analysis for decision tree learning algorithms lies in the fact that the worst-case purity gain, i.e., the core heuristics for tree splitting, can be zero. Based on this recognition, we present a new algorithm, named Grid Classification And Regression Tree (GridCART), with a provable consistency rate $\\mathcal{O}(n^{-1 / (d + 2)})$, which is the first consistency rate proved for heuristic tree learning algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zheng23b/zheng23b.pdf",
        "supp": "",
        "pdf_size": 428633,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12019848439400873231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2d22ad67ab",
        "title": "On the Convergence of Distributed Stochastic Bilevel Optimization Algorithms over a Network",
        "site": "https://proceedings.mlr.press/v206/gao23a.html",
        "author": "Hongchang Gao; Bin Gu; My T. Thai",
        "abstract": "Bilevel optimization has been applied to a wide variety of machine learning models and numerous stochastic bilevel optimization algorithms have been developed in recent years. However, most existing algorithms restrict their focus on the single-machine setting so that they are incapable of handling the distributed data. To address this issue, under the setting where all participants compose a network and perform peer-to-peer communication in this network, we developed two novel decentralized stochastic bilevel optimization algorithms based on the gradient tracking communication mechanism and two different gradient estimators. Additionally, we established their convergence rates for nonconvex-strongly-convex problems with novel theoretical analysis strategies. To our knowledge, this is the first work achieving these theoretical results. Finally, we applied our algorithms to practical machine learning models, and the experimental results confirmed the efficacy of our algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-gao23a,\n  title = \t {On the Convergence of Distributed Stochastic Bilevel Optimization Algorithms over a Network},\n  author =       {Gao, Hongchang and Gu, Bin and Thai, My T.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9238--9281},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gao23a/gao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gao23a.html},\n  abstract = \t {Bilevel optimization has been applied to a wide variety of machine learning models and numerous stochastic bilevel optimization algorithms have been developed in recent years. However, most existing algorithms restrict their focus on the single-machine setting so that they are incapable of handling the distributed data. To address this issue, under the setting where all participants compose a network and perform peer-to-peer communication in this network, we developed two novel decentralized stochastic bilevel optimization algorithms based on the gradient tracking communication mechanism and two different gradient estimators. Additionally, we established their convergence rates for nonconvex-strongly-convex problems with novel theoretical analysis strategies. To our knowledge, this is the first work achieving these theoretical results. Finally, we applied our algorithms to practical machine learning models, and the experimental results confirmed the efficacy of our algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gao23a/gao23a.pdf",
        "supp": "",
        "pdf_size": 825869,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1133313314040635042&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "32431da011",
        "title": "On the Implicit Geometry of Cross-Entropy Parameterizations for Label-Imbalanced Data",
        "site": "https://proceedings.mlr.press/v206/behnia23a.html",
        "author": "Tina Behnia; Ganesh Ramachandra Kini; Vala Vakilian; Christos Thrampoulidis",
        "abstract": "Various logit-adjusted parameterizations of the cross-entropy (CE) loss have been proposed as alternatives to weighted CE for training large models on label-imbalanced data far beyond the zero train error regime. The driving force behind those designs has been the theory of implicit bias, which for linear(ized) models, explains why they successfully induce bias on the optimization path towards solutions that favor minorities. Aiming to extend this theory to non-linear models, we investigate the implicit geometry of classifiers and embeddings that are learned by different CE parameterizations. Our main result characterizes the global minimizers of a non-convex cost-sensitive SVM classifier for the unconstrained features model, which serves as an abstraction of deep-nets. We derive closed-form formulas for the angles and norms of classifiers and embeddings as a function of the number of classes, the imbalance and the minority ratios, and the loss hyperparameters. Using these, we show that logit-adjusted parameterizations can be appropriately tuned to learn symmetric geometries irrespective of the imbalance ratio. We complement our analysis with experiments and an empirical study of convergence accuracy in deep-nets.",
        "bibtex": "@InProceedings{pmlr-v206-behnia23a,\n  title = \t {On the Implicit Geometry of Cross-Entropy Parameterizations for Label-Imbalanced Data},\n  author =       {Behnia, Tina and Ramachandra Kini, Ganesh and Vakilian, Vala and Thrampoulidis, Christos},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10815--10838},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/behnia23a/behnia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/behnia23a.html},\n  abstract = \t {Various logit-adjusted parameterizations of the cross-entropy (CE) loss have been proposed as alternatives to weighted CE for training large models on label-imbalanced data far beyond the zero train error regime. The driving force behind those designs has been the theory of implicit bias, which for linear(ized) models, explains why they successfully induce bias on the optimization path towards solutions that favor minorities. Aiming to extend this theory to non-linear models, we investigate the implicit geometry of classifiers and embeddings that are learned by different CE parameterizations. Our main result characterizes the global minimizers of a non-convex cost-sensitive SVM classifier for the unconstrained features model, which serves as an abstraction of deep-nets. We derive closed-form formulas for the angles and norms of classifiers and embeddings as a function of the number of classes, the imbalance and the minority ratios, and the loss hyperparameters. Using these, we show that logit-adjusted parameterizations can be appropriately tuned to learn symmetric geometries irrespective of the imbalance ratio. We complement our analysis with experiments and an empirical study of convergence accuracy in deep-nets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/behnia23a/behnia23a.pdf",
        "supp": "",
        "pdf_size": 1478790,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17880297136863706196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f0d3d979ab",
        "title": "On the Limitations of the Elo, Real-World Games are Transitive, not Additive",
        "site": "https://proceedings.mlr.press/v206/bertrand23a.html",
        "author": "Quentin Bertrand; Wojciech Marian Czarnecki; Gauthier Gidel",
        "abstract": "The Elo score has been extensively used to rank players by their skill or strength in competitive games such as chess, go, or StarCraft II. The Elo score implicitly assumes games have a strong additive\u2014hence transitive\u2014component. In this paper, we investigate the challenge of identifying transitive components in games. As a starting point, we show that the Elo score provably fails to extract the transitive component of some elementary transitive games. Based on this observation, we propose an alternative ranking system which properly extracts the transitive components in these games. Finally, we conduct an in-depth empirical validation on real-world game payoff matrices: it shows significant prediction performance improvements compared to the Elo score.",
        "bibtex": "@InProceedings{pmlr-v206-bertrand23a,\n  title = \t {On the Limitations of the Elo, Real-World Games are Transitive, not Additive},\n  author =       {Bertrand, Quentin and Czarnecki, Wojciech Marian and Gidel, Gauthier},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2905--2921},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bertrand23a/bertrand23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bertrand23a.html},\n  abstract = \t {The Elo score has been extensively used to rank players by their skill or strength in competitive games such as chess, go, or StarCraft II. The Elo score implicitly assumes games have a strong additive\u2014hence transitive\u2014component. In this paper, we investigate the challenge of identifying transitive components in games. As a starting point, we show that the Elo score provably fails to extract the transitive component of some elementary transitive games. Based on this observation, we propose an alternative ranking system which properly extracts the transitive components in these games. Finally, we conduct an in-depth empirical validation on real-world game payoff matrices: it shows significant prediction performance improvements compared to the Elo score.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bertrand23a/bertrand23a.pdf",
        "supp": "",
        "pdf_size": 1435610,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12103195489727286380&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Mila and Universit\u00e9 de Montr\u00e9al; V oyLab; Mila and Universit\u00e9 de Montr\u00e9al",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;VoyLab",
        "aff_unique_dep": "Mila;",
        "aff_unique_url": "https://www.umontreal.ca;",
        "aff_unique_abbr": "UdeM;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montr\u00e9al;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada;"
    },
    {
        "id": "88d8e5b226",
        "title": "On the Neural Tangent Kernel Analysis of Randomly Pruned Neural Networks",
        "site": "https://proceedings.mlr.press/v206/yang23b.html",
        "author": "Hongru Yang; Zhangyang Wang",
        "abstract": "Motivated by both theory and practice, we study how random pruning the weights affects a neural network\u2019s neural tangent kernel (NTK). In particular, this work establishes an equivalence of the NTKs between a fully-connected neural network and its randomly pruned version. The equivalence is established under two cases. The first main result studies the infinite-width asymptotic. It is shown that given a pruning probability, for fully-connected neural networks with the weights randomly pruned at the initialization, as the width of each layer grows to infinity sequentially, the NTK of the pruned neural network converges to the limiting NTK of the original network with some extra scaling. If the network weights are rescaled appropriately after pruning, this extra scaling can be removed. The second main result considers the finite width case. It is shown that to ensure the NTK\u2019s closeness to the limit, the dependence of width on the sparsity parameter is asymptotically linear, as the NTK\u2019s gap to its limit goes down to zero. Moreover, if the pruning probability is set to zero (i.e., no pruning), the bound on the required width matches the bound for fully-connected neural networks in previous works up to logarithmic factors. The proof of this result requires developing novel analysis of a network structure which we called mask-induced pseudo-networks.Experiments are provided to evaluate our results.",
        "bibtex": "@InProceedings{pmlr-v206-yang23b,\n  title = \t {On the Neural Tangent Kernel Analysis of Randomly Pruned Neural Networks},\n  author =       {Yang, Hongru and Wang, Zhangyang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1513--1553},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23b/yang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23b.html},\n  abstract = \t {Motivated by both theory and practice, we study how random pruning the weights affects a neural network\u2019s neural tangent kernel (NTK). In particular, this work establishes an equivalence of the NTKs between a fully-connected neural network and its randomly pruned version. The equivalence is established under two cases. The first main result studies the infinite-width asymptotic. It is shown that given a pruning probability, for fully-connected neural networks with the weights randomly pruned at the initialization, as the width of each layer grows to infinity sequentially, the NTK of the pruned neural network converges to the limiting NTK of the original network with some extra scaling. If the network weights are rescaled appropriately after pruning, this extra scaling can be removed. The second main result considers the finite width case. It is shown that to ensure the NTK\u2019s closeness to the limit, the dependence of width on the sparsity parameter is asymptotically linear, as the NTK\u2019s gap to its limit goes down to zero. Moreover, if the pruning probability is set to zero (i.e., no pruning), the bound on the required width matches the bound for fully-connected neural networks in previous works up to logarithmic factors. The proof of this result requires developing novel analysis of a network structure which we called mask-induced pseudo-networks.Experiments are provided to evaluate our results.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23b/yang23b.pdf",
        "supp": "",
        "pdf_size": 4676717,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3204272201776412761&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "VITA Group, The University of Texas at Austin; VITA Group, The University of Texas at Austin",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "VITA Group",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4055ceda00",
        "title": "On the Privacy Risks of Algorithmic Recourse",
        "site": "https://proceedings.mlr.press/v206/pawelczyk23a.html",
        "author": "Martin Pawelczyk; Himabindu Lakkaraju; Seth Neel",
        "abstract": "As predictive models are increasingly being employed to make consequential decisions, there is a growing emphasis on developing techniques that can provide algorithmic recourse to affected individuals. While such recourses can be immensely beneficial to affected individuals, potential adversaries could also exploit these recourses to compromise privacy. In this work, we make the first attempt at investigating if and how an adversary can leverage recourses to infer private information about the underlying model\u2019s training data. To this end, we propose a series of novel membership inference attacks which leverage algorithmic recourse. More specifically, we extend the prior literature on membership inference attacks to the recourse setting by leveraging the distances between data instances and their corresponding counterfactuals output by state-of-the-art recourse methods. Extensive experimentation with real world and synthetic datasets demonstrates significant privacy leakage through recourses. Our work establishes unintended privacy leakage as an important risk in the widespread adoption of recourse methods.",
        "bibtex": "@InProceedings{pmlr-v206-pawelczyk23a,\n  title = \t {On the Privacy Risks of Algorithmic Recourse},\n  author =       {Pawelczyk, Martin and Lakkaraju, Himabindu and Neel, Seth},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9680--9696},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/pawelczyk23a/pawelczyk23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/pawelczyk23a.html},\n  abstract = \t {As predictive models are increasingly being employed to make consequential decisions, there is a growing emphasis on developing techniques that can provide algorithmic recourse to affected individuals. While such recourses can be immensely beneficial to affected individuals, potential adversaries could also exploit these recourses to compromise privacy. In this work, we make the first attempt at investigating if and how an adversary can leverage recourses to infer private information about the underlying model\u2019s training data. To this end, we propose a series of novel membership inference attacks which leverage algorithmic recourse. More specifically, we extend the prior literature on membership inference attacks to the recourse setting by leveraging the distances between data instances and their corresponding counterfactuals output by state-of-the-art recourse methods. Extensive experimentation with real world and synthetic datasets demonstrates significant privacy leakage through recourses. Our work establishes unintended privacy leakage as an important risk in the widespread adoption of recourse methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/pawelczyk23a/pawelczyk23a.pdf",
        "supp": "",
        "pdf_size": 1532098,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3301841815760564079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of T\u00fcbingen; Harvard University; Harvard University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of T\u00fcbingen;Harvard University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.harvard.edu",
        "aff_unique_abbr": "Uni T\u00fcbingen;Harvard",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "3d734c3ee4",
        "title": "On the Strategyproofness of the Geometric Median",
        "site": "https://proceedings.mlr.press/v206/el-mhamdi23a.html",
        "author": "El-Mahdi El-Mhamdi; Sadegh Farhadkhani; Rachid Guerraoui; L\u00ea-Nguy\u00ean Hoang",
        "abstract": "The geometric median, an instrumental component of the secure machine learning toolbox, is known to be effective when robustly aggregating models (or gradients), gathered from potentially malicious (or strategic) users. What is less known is the extent to which the geometric median incentivizes dishonest behaviors. This paper addresses this fundamental question by quantifying its strategyproofness. While we observe that the geometric median is not even approximately strategyproof, we prove that it is asymptotically $\\alpha$-strategyproof: when the number of users is large enough, a user that misbehaves can gain at most a multiplicative factor $\\alpha$, which we compute as a function of the distribution followed by the users. We then generalize our results to the case where users actually care more about specific dimensions, determining how this impacts $\\alpha$. We also show how the skewed geometric medians can be used to improve strategyproofness.",
        "bibtex": "@InProceedings{pmlr-v206-el-mhamdi23a,\n  title = \t {On the Strategyproofness of the Geometric Median},\n  author =       {El-Mhamdi, El-Mahdi and Farhadkhani, Sadegh and Guerraoui, Rachid and Hoang, L\\^e-Nguy\\^en},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2603--2640},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/el-mhamdi23a/el-mhamdi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/el-mhamdi23a.html},\n  abstract = \t {The geometric median, an instrumental component of the secure machine learning toolbox, is known to be effective when robustly aggregating models (or gradients), gathered from potentially malicious (or strategic) users. What is less known is the extent to which the geometric median incentivizes dishonest behaviors. This paper addresses this fundamental question by quantifying its strategyproofness. While we observe that the geometric median is not even approximately strategyproof, we prove that it is asymptotically $\\alpha$-strategyproof: when the number of users is large enough, a user that misbehaves can gain at most a multiplicative factor $\\alpha$, which we compute as a function of the distribution followed by the users. We then generalize our results to the case where users actually care more about specific dimensions, determining how this impacts $\\alpha$. We also show how the skewed geometric medians can be used to improve strategyproofness.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/el-mhamdi23a/el-mhamdi23a.pdf",
        "supp": "",
        "pdf_size": 1130411,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13256075590652488907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Calicarpa, \u00b4Ecole Polytechnique EPFL; Calicarpa, EPFL; EPFL; Calicarpa, Tournesol",
        "aff_domain": "epfl.ch;epfl.ch;epfl.ch;tournesol.app",
        "email": "epfl.ch;epfl.ch;epfl.ch;tournesol.app",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne;EPFL;Calicarpa",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.epfl.ch;https://www.epfl.ch;",
        "aff_unique_abbr": "EPFL;EPFL;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland;"
    },
    {
        "id": "9c3c8f7f60",
        "title": "On the bias of K-fold cross validation with stable learners",
        "site": "https://proceedings.mlr.press/v206/aghbalou23a.html",
        "author": "Anass Aghbalou; Anne Sabourin; Fran\u00e7ois Portier",
        "abstract": "This paper investigates the efficiency of the K-fold cross-validation (CV) procedure and a debiased version thereof as a means of estimating the generalization risk of a learning algorithm. We work under the general assumption of uniform algorithmic stability. We show that the K-fold risk estimate may not be consistent under such general stability assumptions, by constructing non vanishing lower bounds on the error in realistic contexts such as regularized empirical risk minimisation and stochastic gradient descent. We thus advocate the use of a debiased version of the K-fold and prove an error bound with exponential tail decay regarding this version. Our result is applicable to the large class of uniformly stable algorithms, contrarily to earlier works focusing on specific tasks such as density estimation. We illustrate the relevance of the debiased K-fold CV on a simple model selection problem and demonstrate empirically the usefulness of the promoted approach on real world classification and regression datasets.",
        "bibtex": "@InProceedings{pmlr-v206-aghbalou23a,\n  title = \t {On the bias of K-fold cross validation with stable learners},\n  author =       {Aghbalou, Anass and Sabourin, Anne and Portier, Fran\\c{c}ois},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3775--3794},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/aghbalou23a/aghbalou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/aghbalou23a.html},\n  abstract = \t {This paper investigates the efficiency of the K-fold cross-validation (CV) procedure and a debiased version thereof as a means of estimating the generalization risk of a learning algorithm. We work under the general assumption of uniform algorithmic stability. We show that the K-fold risk estimate may not be consistent under such general stability assumptions, by constructing non vanishing lower bounds on the error in realistic contexts such as regularized empirical risk minimisation and stochastic gradient descent. We thus advocate the use of a debiased version of the K-fold and prove an error bound with exponential tail decay regarding this version. Our result is applicable to the large class of uniformly stable algorithms, contrarily to earlier works focusing on specific tasks such as density estimation. We illustrate the relevance of the debiased K-fold CV on a simple model selection problem and demonstrate empirically the usefulness of the promoted approach on real world classification and regression datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/aghbalou23a/aghbalou23a.pdf",
        "supp": "",
        "pdf_size": 311816,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1852813435389875803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "LTCI, T\u00b4el\u00b4ecom Paris; Universit\u00b4e Paris-SaclayCREST; EnsaiCNRS, MAP5 + Universit\u00b4e Paris Cit\u00b4e",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3",
        "aff_unique_norm": "T\u00e9l\u00e9com Paris;Universit\u00e9 Paris-Saclay;EnsaiCNRS;Universit\u00e9 Paris Cit\u00e9",
        "aff_unique_dep": "LTCI;CREST;MAP5;",
        "aff_unique_url": "https://www.telecom-paris.fr;https://www.universite-paris-saclay.fr;https://www.ensai.fr;https://www.universite-paris.fr",
        "aff_unique_abbr": "T\u00e9l\u00e9com Paris;UPS;;UPC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "France"
    },
    {
        "id": "8b6d692d04",
        "title": "On-Demand Communication for Asynchronous Multi-Agent Bandits",
        "site": "https://proceedings.mlr.press/v206/chen23c.html",
        "author": "Yu-Zhen Janice Chen; Lin Yang; Xuchuang Wang; Xutong Liu; Mohammad Hajiesmaili; John C. S. Lui; Don Towsley",
        "abstract": "This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously \u2013 agent pull times and rates are unknown, irregular, and heterogeneous \u2013 and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.",
        "bibtex": "@InProceedings{pmlr-v206-chen23c,\n  title = \t {On-Demand Communication for Asynchronous Multi-Agent Bandits},\n  author =       {Chen, Yu-Zhen Janice and Yang, Lin and Wang, Xuchuang and Liu, Xutong and Hajiesmaili, Mohammad and Lui, John C. S. and Towsley, Don},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3903--3930},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23c/chen23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23c.html},\n  abstract = \t {This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously \u2013 agent pull times and rates are unknown, irregular, and heterogeneous \u2013 and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23c/chen23c.pdf",
        "supp": "",
        "pdf_size": 2302926,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13595176987299628083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b5a475f417",
        "title": "One Arrow, Two Kills: A Unified Framework for Achieving Optimal Regret Guarantees in Sleeping Bandits",
        "site": "https://proceedings.mlr.press/v206/gaillard23a.html",
        "author": "Pierre Gaillard; Aadirupa Saha; Soham Dan",
        "abstract": "We address the problem of Internal Regret in adversarial Sleeping Bandits and the relationship between different notions of sleeping regrets in multi-armed bandits. We propose a new concept called Internal Regret for sleeping multi-armed bandits (MAB) and present an algorithm that achieves sublinear Internal Regret, even when losses and availabilities are both adversarial. We demonstrate that a low internal regret leads to both low external regret and low policy regret for i.i.d. losses. Our contribution is unifying existing notions of regret in sleeping bandits and exploring their implications for each other. In addition, we extend our results to Dueling Bandits (DB), a preference feedback version of multi-armed bandits, and design a low-regret algorithm for sleeping dueling bandits with stochastic preferences and adversarial availabilities. We validate the effectiveness of our algorithms through empirical evaluations.",
        "bibtex": "@InProceedings{pmlr-v206-gaillard23a,\n  title = \t {One Arrow, Two Kills: A Unified Framework for Achieving Optimal Regret Guarantees in Sleeping Bandits},\n  author =       {Gaillard, Pierre and Saha, Aadirupa and Dan, Soham},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7755--7773},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gaillard23a/gaillard23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gaillard23a.html},\n  abstract = \t {We address the problem of Internal Regret in adversarial Sleeping Bandits and the relationship between different notions of sleeping regrets in multi-armed bandits. We propose a new concept called Internal Regret for sleeping multi-armed bandits (MAB) and present an algorithm that achieves sublinear Internal Regret, even when losses and availabilities are both adversarial. We demonstrate that a low internal regret leads to both low external regret and low policy regret for i.i.d. losses. Our contribution is unifying existing notions of regret in sleeping bandits and exploring their implications for each other. In addition, we extend our results to Dueling Bandits (DB), a preference feedback version of multi-armed bandits, and design a low-regret algorithm for sleeping dueling bandits with stochastic preferences and adversarial availabilities. We validate the effectiveness of our algorithms through empirical evaluations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gaillard23a/gaillard23a.pdf",
        "supp": "",
        "pdf_size": 2819186,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1564879304191435080&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INPTTI; Chicago IBM Research; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INPTTI + University of Pennsylvania",
        "aff_domain": "ttic.edu; ; ",
        "email": "ttic.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2",
        "aff_unique_norm": "Universite Grenoble Alpes;IBM;University of Pennsylvania",
        "aff_unique_dep": ";IBM Research;",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://www.ibm.com/research;https://www.upenn.edu",
        "aff_unique_abbr": "UGA;IBM;UPenn",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Grenoble;Chicago;",
        "aff_country_unique_index": "0;1;0+1",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "5ac0ade0ba",
        "title": "One Policy is Enough: Parallel Exploration with a Single Policy is Near-Optimal for Reward-Free Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/cisneros-velarde23a.html",
        "author": "Pedro Cisneros-Velarde; Boxiang Lyu; Sanmi Koyejo; Mladen Kolar",
        "abstract": "Although parallelism has been extensively used in Reinforcement Learning (RL), the quantitative effects of parallel exploration are not well understood theoretically. We study the benefits of simple parallel exploration for reward-free RL in linear Markov decision processes (MDPs) and two-player zero-sum Markov games (MGs). In contrast to the existing literature, which focuses on approaches that encourage agents to explore over a diverse set of policies, we show that using a single policy to guide exploration across all agents is sufficient to obtain an almost-linear speedup in all cases compared to their fully sequential counterpart. Furthermore, we demonstrate that this simple procedure is near-minimax optimal in the reward-free setting for linear MDPs. From a practical perspective, our paper shows that a single policy is sufficient and provably near-optimal for incorporating parallelism during the exploration phase.",
        "bibtex": "@InProceedings{pmlr-v206-cisneros-velarde23a,\n  title = \t {One Policy is Enough: Parallel Exploration with a Single Policy is Near-Optimal for Reward-Free Reinforcement Learning},\n  author =       {Cisneros-Velarde, Pedro and Lyu, Boxiang and Koyejo, Sanmi and Kolar, Mladen},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1965--2001},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cisneros-velarde23a/cisneros-velarde23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cisneros-velarde23a.html},\n  abstract = \t {Although parallelism has been extensively used in Reinforcement Learning (RL), the quantitative effects of parallel exploration are not well understood theoretically. We study the benefits of simple parallel exploration for reward-free RL in linear Markov decision processes (MDPs) and two-player zero-sum Markov games (MGs). In contrast to the existing literature, which focuses on approaches that encourage agents to explore over a diverse set of policies, we show that using a single policy to guide exploration across all agents is sufficient to obtain an almost-linear speedup in all cases compared to their fully sequential counterpart. Furthermore, we demonstrate that this simple procedure is near-minimax optimal in the reward-free setting for linear MDPs. From a practical perspective, our paper shows that a single policy is sufficient and provably near-optimal for incorporating parallelism during the exploration phase.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cisneros-velarde23a/cisneros-velarde23a.pdf",
        "supp": "",
        "pdf_size": 434146,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2556065484147960177&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Illinois at Urbana-Champaign; The University of Chicago; Stanford University, Google Research; The University of Chicago",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;University of Chicago;Stanford University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://illinois.edu;https://www.uchicago.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UIUC;UChicago;Stanford",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Urbana-Champaign;;Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "08aad26bec",
        "title": "Online Algorithms with Costly Predictions",
        "site": "https://proceedings.mlr.press/v206/drygala23a.html",
        "author": "Marina Drygala; Sai Ganesh Nagarajan; Ola Svensson",
        "abstract": "In recent years there has been a significant research effort on incorporating predictions into online algorithms. However, work in this area often makes the underlying assumption that predictions come for free (e.g., without any computational or monetary costs). In this paper, we consider a cost associated with making predictions. We show that interesting algorithmic subtleties arise for even the most basic online problems, such as ski rental and its generalization, the Bahncard problem. In particular, we show that with costly predictions, care needs to be taken in (i) asking for the prediction at the right time, (ii) deciding if it is worth asking for the prediction, and (iii) how many predictions we ask for, in settings where it is natural to consider making multiple predictions. Specifically, (i) in the basic ski-rental setting, we compute the optimal delay before asking the predictor, (ii) in the same setting, given apriori information about the true number of ski-days through its mean and variance, we provide a simple algorithm that is near-optimal, under some natural parameter settings, in deciding if it is worth asking for the predictor and (iii) in the setting of the Bahncard problem, we provide a $(1+\\varepsilon)$-approximation algorithm and quantify lower bounds on the number of queries required to do so. In addition, we show that solving the problem optimally would require almost complete information of the instance.",
        "bibtex": "@InProceedings{pmlr-v206-drygala23a,\n  title = \t {Online Algorithms with Costly Predictions},\n  author =       {Drygala, Marina and Nagarajan, Sai Ganesh and Svensson, Ola},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8078--8101},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/drygala23a/drygala23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/drygala23a.html},\n  abstract = \t {In recent years there has been a significant research effort on incorporating predictions into online algorithms. However, work in this area often makes the underlying assumption that predictions come for free (e.g., without any computational or monetary costs). In this paper, we consider a cost associated with making predictions. We show that interesting algorithmic subtleties arise for even the most basic online problems, such as ski rental and its generalization, the Bahncard problem. In particular, we show that with costly predictions, care needs to be taken in (i) asking for the prediction at the right time, (ii) deciding if it is worth asking for the prediction, and (iii) how many predictions we ask for, in settings where it is natural to consider making multiple predictions. Specifically, (i) in the basic ski-rental setting, we compute the optimal delay before asking the predictor, (ii) in the same setting, given apriori information about the true number of ski-days through its mean and variance, we provide a simple algorithm that is near-optimal, under some natural parameter settings, in deciding if it is worth asking for the predictor and (iii) in the setting of the Bahncard problem, we provide a $(1+\\varepsilon)$-approximation algorithm and quantify lower bounds on the number of queries required to do so. In addition, we show that solving the problem optimally would require almost complete information of the instance.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/drygala23a/drygala23a.pdf",
        "supp": "",
        "pdf_size": 368117,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4065086442957192765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ece013749b",
        "title": "Online Defense Strategies for Reinforcement Learning Against Adaptive Reward Poisoning",
        "site": "https://proceedings.mlr.press/v206/nika23a.html",
        "author": "Andi Nika; Adish Singla; Goran Radanovic",
        "abstract": "We consider the problem of defense against reward-poisoning attacks in reinforcement learning and formulate it as a game in $T$ rounds between a defender and an adaptive attacker in an adversarial environment. To address this problem, we design two novel defense algorithms. First, we propose Exp3-DARP, a defense algorithm that uses Exp3 as a hyperparameter learning subroutine, and show that it achieves order-optimal $\\tilde{\\Theta}(T^{1/2})$ bounds on our notion of regret with respect to a defense that always picks the optimal parameter in hindsight. We show that the order of $T$ in the bounds cannot be improved when the reward arrival process is adversarial, even if the feedback model of the defense is stronger. However, assuming that the environment is stochastic, we propose OMDUCB-DARP that uses estimates of costs as proxies to update the randomized strategy of the learner and are able to substantially improve the bounds proportional to how smoothly the attacker\u2019s strategy changes. Furthermore, we show that weaker types of defense, that do not take into account the attack structure and the poisoned rewards, suffer linear regret with respect to a defender that always selects the optimal parameter in hindsight when faced with an adaptive attacker that uses a no-regret algorithm to learn the behavior of the defense. Finally, we support our theoretical results with experimental evaluations on three different environments, showcasing the efficiency of our methods.",
        "bibtex": "@InProceedings{pmlr-v206-nika23a,\n  title = \t {Online Defense Strategies for Reinforcement Learning Against Adaptive Reward Poisoning},\n  author =       {Nika, Andi and Singla, Adish and Radanovic, Goran},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {335--358},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nika23a/nika23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nika23a.html},\n  abstract = \t {We consider the problem of defense against reward-poisoning attacks in reinforcement learning and formulate it as a game in $T$ rounds between a defender and an adaptive attacker in an adversarial environment. To address this problem, we design two novel defense algorithms. First, we propose Exp3-DARP, a defense algorithm that uses Exp3 as a hyperparameter learning subroutine, and show that it achieves order-optimal $\\tilde{\\Theta}(T^{1/2})$ bounds on our notion of regret with respect to a defense that always picks the optimal parameter in hindsight. We show that the order of $T$ in the bounds cannot be improved when the reward arrival process is adversarial, even if the feedback model of the defense is stronger. However, assuming that the environment is stochastic, we propose OMDUCB-DARP that uses estimates of costs as proxies to update the randomized strategy of the learner and are able to substantially improve the bounds proportional to how smoothly the attacker\u2019s strategy changes. Furthermore, we show that weaker types of defense, that do not take into account the attack structure and the poisoned rewards, suffer linear regret with respect to a defender that always selects the optimal parameter in hindsight when faced with an adaptive attacker that uses a no-regret algorithm to learn the behavior of the defense. Finally, we support our theoretical results with experimental evaluations on three different environments, showcasing the efficiency of our methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nika23a/nika23a.pdf",
        "supp": "",
        "pdf_size": 10125257,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13576481920046166208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ef17c484c5",
        "title": "Online Learning for Non-monotone DR-Submodular Maximization: From Full Information to Bandit Feedback",
        "site": "https://proceedings.mlr.press/v206/zhang23f.html",
        "author": "Qixin Zhang; Zengde Deng; Zaiyi Chen; Kuangqi Zhou; Haoyuan Hu; Yu Yang",
        "abstract": "In this paper, we revisit the online non-monotone continuous DR-submodular maximization problem over a down-closed convex set, which finds wide real-world applications in the domain of machine learning, economics, and operations research. At first, we present the Meta-MFW algorithm achieving a $1/e$-regret of $O(\\sqrt{T})$ at the cost of $T^{3/2}$ stochastic gradient evaluations per round. As far as we know, Meta-MFW is the first algorithm to obtain $1/e$-regret of $O(\\sqrt{T})$ for the online non-monotone continuous DR-submodular maximization problem over a down-closed convex set. Furthermore, in sharp contrast with ODC algorithm (Thang $&$ Srivastav, 2021), Meta-MFW relies on the simple online linear oracle without discretization, lifting, or rounding operations. Considering the practical restrictions, we then propose the Mono-MFW algorithm, which reduces the per-function stochastic gradient evaluations from $T^{3/2}$ to 1 and achieves a $1/e$-regret bound of $O(T^{4/5})$. Next, we extend Mono-MFW to the bandit setting and propose the Bandit-MFW algorithm which attains a $1/e$-regret bound of $O(T^{8/9})$. To the best of our knowledge, Mono-MFW and Bandit-MFW are the first sublinear-regret algorithms to explore the one-shot and bandit setting for online non-monotone continuous DR-submodular maximization problem over a down-closed convex set, respectively. Finally, we conduct numerical experiments on both synthetic and real-world datasets to verify the effectiveness of our methods.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23f,\n  title = \t {Online Learning for Non-monotone DR-Submodular Maximization: From Full Information to Bandit Feedback},\n  author =       {Zhang, Qixin and Deng, Zengde and Chen, Zaiyi and Zhou, Kuangqi and Hu, Haoyuan and Yang, Yu},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3515--3537},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23f/zhang23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23f.html},\n  abstract = \t {In this paper, we revisit the online non-monotone continuous DR-submodular maximization problem over a down-closed convex set, which finds wide real-world applications in the domain of machine learning, economics, and operations research. At first, we present the Meta-MFW algorithm achieving a $1/e$-regret of $O(\\sqrt{T})$ at the cost of $T^{3/2}$ stochastic gradient evaluations per round. As far as we know, Meta-MFW is the first algorithm to obtain $1/e$-regret of $O(\\sqrt{T})$ for the online non-monotone continuous DR-submodular maximization problem over a down-closed convex set. Furthermore, in sharp contrast with ODC algorithm (Thang $&$ Srivastav, 2021), Meta-MFW relies on the simple online linear oracle without discretization, lifting, or rounding operations. Considering the practical restrictions, we then propose the Mono-MFW algorithm, which reduces the per-function stochastic gradient evaluations from $T^{3/2}$ to 1 and achieves a $1/e$-regret bound of $O(T^{4/5})$. Next, we extend Mono-MFW to the bandit setting and propose the Bandit-MFW algorithm which attains a $1/e$-regret bound of $O(T^{8/9})$. To the best of our knowledge, Mono-MFW and Bandit-MFW are the first sublinear-regret algorithms to explore the one-shot and bandit setting for online non-monotone continuous DR-submodular maximization problem over a down-closed convex set, respectively. Finally, we conduct numerical experiments on both synthetic and real-world datasets to verify the effectiveness of our methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23f/zhang23f.pdf",
        "supp": "",
        "pdf_size": 2717870,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2203137796608136758&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "City University of Hong Kong; Cainiao Network; Cainiao Network; National University of Singapore; Cainiao Network; City University of Hong Kong",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "City University of Hong Kong;Cainiao Network;National University of Singapore",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cityu.edu.hk;https://www.cainiao.com;https://www.nus.edu.sg",
        "aff_unique_abbr": "CityU;Cainiao;NUS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "839e0b29f8",
        "title": "Online Learning for Traffic Routing under Unknown Preferences",
        "site": "https://proceedings.mlr.press/v206/jalota23a.html",
        "author": "Devansh Jalota; Karthik Gopalakrishnan; Navid Azizan; Ramesh Johari; Marco Pavone",
        "abstract": "In transportation networks, road tolling schemes are a method to cope with the efficiency losses due to selfish user routing, wherein users choose routes to minimize individual travel costs. However, the efficacy of tolling schemes often relies on access to complete information on users\u2019 trip attributes, such as their origin-destination (O-D) travel information and their values of time, which may not be available in practice. Motivated by this practical consideration, we propose an online learning approach to set tolls in a traffic network to drive heterogeneous users with different values of time toward a system-efficient traffic pattern. In particular, we develop a simple yet effective algorithm that adjusts tolls at each time period solely based on the observed aggregate flows on the roads of the network without relying on any additional trip attributes of users, thereby preserving user privacy. In the setting where the O-D pairs and values of time of users are drawn i.i.d. at each period, we show that our approach obtains an expected regret and road capacity violation of $O(\\sqrt{T})$, where $T$ is the number of periods over which tolls are updated. Our regret guarantee is relative to an offline oracle with complete information on users\u2019 trip attributes. We further establish a $\\Omega(\\sqrt{T})$ lower bound on the regret of any algorithm, which establishes that our algorithm is optimal up to constants. Finally, we demonstrate the superior performance of our approach relative to several benchmarks on a real-world traffic network, which highlights its practical applicability.",
        "bibtex": "@InProceedings{pmlr-v206-jalota23a,\n  title = \t {Online Learning for Traffic Routing under Unknown Preferences},\n  author =       {Jalota, Devansh and Gopalakrishnan, Karthik and Azizan, Navid and Johari, Ramesh and Pavone, Marco},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3210--3229},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jalota23a/jalota23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jalota23a.html},\n  abstract = \t {In transportation networks, road tolling schemes are a method to cope with the efficiency losses due to selfish user routing, wherein users choose routes to minimize individual travel costs. However, the efficacy of tolling schemes often relies on access to complete information on users\u2019 trip attributes, such as their origin-destination (O-D) travel information and their values of time, which may not be available in practice. Motivated by this practical consideration, we propose an online learning approach to set tolls in a traffic network to drive heterogeneous users with different values of time toward a system-efficient traffic pattern. In particular, we develop a simple yet effective algorithm that adjusts tolls at each time period solely based on the observed aggregate flows on the roads of the network without relying on any additional trip attributes of users, thereby preserving user privacy. In the setting where the O-D pairs and values of time of users are drawn i.i.d. at each period, we show that our approach obtains an expected regret and road capacity violation of $O(\\sqrt{T})$, where $T$ is the number of periods over which tolls are updated. Our regret guarantee is relative to an offline oracle with complete information on users\u2019 trip attributes. We further establish a $\\Omega(\\sqrt{T})$ lower bound on the regret of any algorithm, which establishes that our algorithm is optimal up to constants. Finally, we demonstrate the superior performance of our approach relative to several benchmarks on a real-world traffic network, which highlights its practical applicability.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jalota23a/jalota23a.pdf",
        "supp": "",
        "pdf_size": 15903975,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3779368417328304615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Stanford University; Stanford University; Massachusetts Institute of Technology; Stanford University; Stanford University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Stanford University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://web.mit.edu",
        "aff_unique_abbr": "Stanford;MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "80d1d9ec63",
        "title": "Online Linearized LASSO",
        "site": "https://proceedings.mlr.press/v206/yang23g.html",
        "author": "Shuoguang Yang; Yuhao Yan; Xiuneng Zhu; Qiang Sun",
        "abstract": "Sparse regression has been a popular approach to perform variable selection and enhance the prediction accuracy and interpretability of the resulting statistical model. Existing approaches focus on offline regularized regression, while the online scenario has rarely been studied. In this paper, we propose a novel online sparse linear regression framework for analyzing streaming data when data points arrive sequentially. Our proposed method is memory efficient and requires less stringent restricted strong convexity assumptions. Theoretically, we show that with a properly chosen regularization parameter, the $\\ell_2$-error of our estimator decays to zero at the optimal order of $\\tilde \\mathcal{O}(\\frac{s}{\\sqrt{t}})$, where $s$ is the sparsity level, $t$ is the streaming sample size, and $\\tilde \\mathcal{O}(\\cdot)$ hides logarithmic terms. Numerical experiments demonstrate the practical efficiency of our algorithm.",
        "bibtex": "@InProceedings{pmlr-v206-yang23g,\n  title = \t {Online Linearized LASSO},\n  author =       {Yang, Shuoguang and Yan, Yuhao and Zhu, Xiuneng and Sun, Qiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7594--7610},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23g/yang23g.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23g.html},\n  abstract = \t {Sparse regression has been a popular approach to perform variable selection and enhance the prediction accuracy and interpretability of the resulting statistical model. Existing approaches focus on offline regularized regression, while the online scenario has rarely been studied. In this paper, we propose a novel online sparse linear regression framework for analyzing streaming data when data points arrive sequentially. Our proposed method is memory efficient and requires less stringent restricted strong convexity assumptions. Theoretically, we show that with a properly chosen regularization parameter, the $\\ell_2$-error of our estimator decays to zero at the optimal order of $\\tilde \\mathcal{O}(\\frac{s}{\\sqrt{t}})$, where $s$ is the sparsity level, $t$ is the streaming sample size, and $\\tilde \\mathcal{O}(\\cdot)$ hides logarithmic terms. Numerical experiments demonstrate the practical efficiency of our algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23g/yang23g.pdf",
        "supp": "",
        "pdf_size": 2242910,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16403978059253827745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1b683ffd15",
        "title": "Optimal Algorithms for Latent Bandits with Cluster Structure",
        "site": "https://proceedings.mlr.press/v206/pal23a.html",
        "author": "Soumyabrata Pal; Arun Sai Suggala; Karthikeyan Shanmugam; Prateek Jain",
        "abstract": "We consider the problem of latent bandits with cluster structure where there are multiple users, each with an associated multi-armed bandit problem. These users are grouped into latent clusters such that the mean reward vectors of users within the same cluster are identical. At each round, a user, selected uniformly at random, pulls an arm and observes a corresponding noisy reward. The goal of the users is to maximize their cumulative rewards. This problem is central to practical recommendation systems and has received wide attention of late Gentile et al. (2014), Maillard and Mannor (2014). Now, if each user acts independently, then they would have to explore each arm independently and a regret of $\\Omega(\\sqrt{\\mathrm{MNT}})$ is unavoidable, where M, N are the number of arms and users, respectively. Instead, we propose LATTICE (Latent bAndiTs via maTrIx ComplEtion) which allows exploration of the latent cluster structure to provide the minimax optimal regret of $\\widetilde{O}(\\sqrt{(M+N)T})$ when the number of clusters is $\\tilde O(1)$. This is the first algorithm to guarantee such strong regret bound. LATTICE is based on a careful exploitation of arm information within a cluster while simultaneously clustering users. Furthermore, it is computationally efficient and requires only $O(\\log \\mathrm{T})$ calls to an offline matrix completion oracle across all T rounds.",
        "bibtex": "@InProceedings{pmlr-v206-pal23a,\n  title = \t {Optimal Algorithms for Latent Bandits with Cluster Structure},\n  author =       {Pal, Soumyabrata and Sai Suggala, Arun and Shanmugam, Karthikeyan and Jain, Prateek},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7540--7577},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/pal23a/pal23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/pal23a.html},\n  abstract = \t {We consider the problem of latent bandits with cluster structure where there are multiple users, each with an associated multi-armed bandit problem. These users are grouped into latent clusters such that the mean reward vectors of users within the same cluster are identical. At each round, a user, selected uniformly at random, pulls an arm and observes a corresponding noisy reward. The goal of the users is to maximize their cumulative rewards. This problem is central to practical recommendation systems and has received wide attention of late Gentile et al. (2014), Maillard and Mannor (2014). Now, if each user acts independently, then they would have to explore each arm independently and a regret of $\\Omega(\\sqrt{\\mathrm{MNT}})$ is unavoidable, where M, N are the number of arms and users, respectively. Instead, we propose LATTICE (Latent bAndiTs via maTrIx ComplEtion) which allows exploration of the latent cluster structure to provide the minimax optimal regret of $\\widetilde{O}(\\sqrt{(M+N)T})$ when the number of clusters is $\\tilde O(1)$. This is the first algorithm to guarantee such strong regret bound. LATTICE is based on a careful exploitation of arm information within a cluster while simultaneously clustering users. Furthermore, it is computationally efficient and requires only $O(\\log \\mathrm{T})$ calls to an offline matrix completion oracle across all T rounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/pal23a/pal23a.pdf",
        "supp": "",
        "pdf_size": 686245,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9755051290853975692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0fd97710bf",
        "title": "Optimal Contextual Bandits with Knapsacks under Realizability via Regression Oracles",
        "site": "https://proceedings.mlr.press/v206/han23b.html",
        "author": "Yuxuan Han; Jialin Zeng; Yang Wang; Yang Xiang; Jiheng Zhang",
        "abstract": "We study the stochastic contextual bandit with knapsacks (CBwK) problem, where each action, taken upon a context, not only leads to a random reward but also costs a random resource consumption in a vector form. The challenge is to maximize the total reward without violating the budget for each resource. We study this problem under a general realizability setting where the expected reward and expected cost are functions of contexts and actions in some given general function classes $\\mathcal{F}$ and $\\mathcal{G}$, respectively. Existing works on CBwK are restricted to the linear function class since they use UCB-type algorithms, which heavily rely on the linear form and thus are difficult to extend to general function classes. Motivated by online regression oracles that have been successfully applied to contextual bandits, we propose the first universal and optimal algorithmic framework for CBwK by reducing it to online regression. We also establish the lower regret bound to show the optimality of our algorithm for a variety of function classes.",
        "bibtex": "@InProceedings{pmlr-v206-han23b,\n  title = \t {Optimal Contextual Bandits with Knapsacks under Realizability via Regression Oracles},\n  author =       {Han, Yuxuan and Zeng, Jialin and Wang, Yang and Xiang, Yang and Zhang, Jiheng},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5011--5035},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/han23b/han23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/han23b.html},\n  abstract = \t {We study the stochastic contextual bandit with knapsacks (CBwK) problem, where each action, taken upon a context, not only leads to a random reward but also costs a random resource consumption in a vector form. The challenge is to maximize the total reward without violating the budget for each resource. We study this problem under a general realizability setting where the expected reward and expected cost are functions of contexts and actions in some given general function classes $\\mathcal{F}$ and $\\mathcal{G}$, respectively. Existing works on CBwK are restricted to the linear function class since they use UCB-type algorithms, which heavily rely on the linear form and thus are difficult to extend to general function classes. Motivated by online regression oracles that have been successfully applied to contextual bandits, we propose the first universal and optimal algorithmic framework for CBwK by reducing it to online regression. We also establish the lower regret bound to show the optimality of our algorithm for a variety of function classes.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/han23b/han23b.pdf",
        "supp": "",
        "pdf_size": 650746,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17725206406307180042&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Mathematics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Mathematics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Mathematics, HKUST + Department of Industrial Engineering and Decision Analytics, HKUST; Department of Mathematics, HKUST + HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute; Department of Industrial Engineering and Decision Analytics, HKUST",
        "aff_domain": "ust.hk;ust.hk; ;ust.hk;ust.hk",
        "email": "ust.hk;ust.hk; ;ust.hk;ust.hk",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0;0+0;0+0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.hkust.edu.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0+1;0+1;0+0;0+1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "7f7441ea8b",
        "title": "Optimal Sample Complexity Bounds for Non-convex Optimization under Kurdyka-Lojasiewicz Condition",
        "site": "https://proceedings.mlr.press/v206/yu23a.html",
        "author": "Qian Yu; Yining Wang; Baihe Huang; Qi Lei; Jason D. Lee",
        "abstract": "Optimization of smooth reward functions under bandit feedback is a long-standing problem in online learning. This paper approaches this problem by studying the convergence under smoothness and Kurdyka-Lojasiewicz conditions. We designed a search-based algorithm that achieves an improved rate compared to the standard gradient-based method. In conjunction with a matching lower bound, this algorithm shows optimality in the dependence on precision for the low-dimension regime.",
        "bibtex": "@InProceedings{pmlr-v206-yu23a,\n  title = \t {Optimal Sample Complexity Bounds for Non-convex Optimization under Kurdyka-Lojasiewicz Condition},\n  author =       {Yu, Qian and Wang, Yining and Huang, Baihe and Lei, Qi and Lee, Jason D.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6806--6821},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yu23a/yu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yu23a.html},\n  abstract = \t {Optimization of smooth reward functions under bandit feedback is a long-standing problem in online learning. This paper approaches this problem by studying the convergence under smoothness and Kurdyka-Lojasiewicz conditions. We designed a search-based algorithm that achieves an improved rate compared to the standard gradient-based method. In conjunction with a matching lower bound, this algorithm shows optimality in the dependence on precision for the low-dimension regime.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yu23a/yu23a.pdf",
        "supp": "",
        "pdf_size": 549337,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9727688679436608090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Princeton University; University of Texas at Dallas; University of California, Berkeley; New York University; Princeton University",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "Princeton University;University of Texas at Dallas;University of California, Berkeley;New York University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.princeton.edu;https://www.utdallas.edu;https://www.berkeley.edu;https://www.nyu.edu",
        "aff_unique_abbr": "Princeton;UT Dallas;UC Berkeley;NYU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Dallas;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c15cb14ab2",
        "title": "Optimal Sketching Bounds for Sparse Linear Regression",
        "site": "https://proceedings.mlr.press/v206/mai23a.html",
        "author": "Tung Mai; Alexander Munteanu; Cameron Musco; Anup Rao; Chris Schwiegelshohn; David Woodruff",
        "abstract": "We study oblivious sketching for $k$-sparse linear regression under various loss functions. In particular, we are interested in a distribution over sketching matrices $S\\in\\mathbb{R}^{m\\times n}$ that does not depend on the inputs $A\\in\\mathbb{R}^{n\\times d}$ and $b\\in\\mathbb{R}^n$, such that, given access to $SA$ and $Sb$, we can recover a $k$-sparse $\\tilde x\\in\\mathbb{R}^d$ with $\\|A\\tilde x-b\\|_f\\leq (1+\\varepsilon) \\min\\nolimits_{k{\\mathrm{-sparse}\\,x\\in\\mathbb{R}^d}} \\|Ax-b\\|_f$. Here $\\|\\cdot\\|_f: \\mathbb R^n \\rightarrow \\mathbb R$ is some loss function \u2013 such as an $\\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses. We show that for sparse $\\ell_2$ norm regression, there is a distribution over oblivious sketches with $m=\\Theta(k\\log(d/k)/\\varepsilon^2)$ rows, which is tight up to a constant factor. This extends to $\\ell_p$ loss with an additional additive $O(k\\log(k/\\varepsilon)/\\varepsilon^2)$ term in the upper bound. This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression, where $A$ is the identity matrix. For this problem, under the $\\ell_2$ norm, we observe an upper bound of $m=O(k \\log (d)/\\varepsilon + k\\log(k/\\varepsilon)/\\varepsilon^2)$, showing that sparse recovery is strictly easier to sketch than sparse regression. For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we give the first known sketching bounds that achieve $m = o(d)$ showing that $m=O(\\mu^2 k\\log(\\mu n d/\\varepsilon)/\\varepsilon^2)$ rows suffice, where $\\mu$ is a natural complexity parameter needed to obtain relative error bounds for these loss functions. We again show that this dimension is tight, up to lower order terms and the dependence on $\\mu$. Finally, we show that similar sketching bounds can be achieved for LASSO regression, a popular convex relaxation of sparse regression, where one aims to minimize $\\|Ax-b\\|_2^2+\\lambda\\|x\\|_1$ over $x\\in\\mathbb{R}^d$. We show that sketching dimension $m =O(\\log(d)/(\\lambda \\varepsilon)^2)$ suffices and that the dependence on $d$ and $\\lambda$ is tight.",
        "bibtex": "@InProceedings{pmlr-v206-mai23a,\n  title = \t {Optimal Sketching Bounds for Sparse Linear Regression},\n  author =       {Mai, Tung and Munteanu, Alexander and Musco, Cameron and Rao, Anup and Schwiegelshohn, Chris and Woodruff, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11288--11316},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mai23a/mai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mai23a.html},\n  abstract = \t {We study oblivious sketching for $k$-sparse linear regression under various loss functions. In particular, we are interested in a distribution over sketching matrices $S\\in\\mathbb{R}^{m\\times n}$ that does not depend on the inputs $A\\in\\mathbb{R}^{n\\times d}$ and $b\\in\\mathbb{R}^n$, such that, given access to $SA$ and $Sb$, we can recover a $k$-sparse $\\tilde x\\in\\mathbb{R}^d$ with $\\|A\\tilde x-b\\|_f\\leq (1+\\varepsilon) \\min\\nolimits_{k{\\mathrm{-sparse}\\,x\\in\\mathbb{R}^d}} \\|Ax-b\\|_f$. Here $\\|\\cdot\\|_f: \\mathbb R^n \\rightarrow \\mathbb R$ is some loss function \u2013 such as an $\\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses. We show that for sparse $\\ell_2$ norm regression, there is a distribution over oblivious sketches with $m=\\Theta(k\\log(d/k)/\\varepsilon^2)$ rows, which is tight up to a constant factor. This extends to $\\ell_p$ loss with an additional additive $O(k\\log(k/\\varepsilon)/\\varepsilon^2)$ term in the upper bound. This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression, where $A$ is the identity matrix. For this problem, under the $\\ell_2$ norm, we observe an upper bound of $m=O(k \\log (d)/\\varepsilon + k\\log(k/\\varepsilon)/\\varepsilon^2)$, showing that sparse recovery is strictly easier to sketch than sparse regression. For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we give the first known sketching bounds that achieve $m = o(d)$ showing that $m=O(\\mu^2 k\\log(\\mu n d/\\varepsilon)/\\varepsilon^2)$ rows suffice, where $\\mu$ is a natural complexity parameter needed to obtain relative error bounds for these loss functions. We again show that this dimension is tight, up to lower order terms and the dependence on $\\mu$. Finally, we show that similar sketching bounds can be achieved for LASSO regression, a popular convex relaxation of sparse regression, where one aims to minimize $\\|Ax-b\\|_2^2+\\lambda\\|x\\|_1$ over $x\\in\\mathbb{R}^d$. We show that sketching dimension $m =O(\\log(d)/(\\lambda \\varepsilon)^2)$ suffices and that the dependence on $d$ and $\\lambda$ is tight.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mai23a/mai23a.pdf",
        "supp": "",
        "pdf_size": 445020,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5845820331861829340&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a7d4d46739",
        "title": "Optimal and Private Learning from Human Response Data",
        "site": "https://proceedings.mlr.press/v206/nguyen23a.html",
        "author": "Duc Nguyen; Anderson Ye Zhang",
        "abstract": "Item response theory (IRT) is the study of how people make probabilistic decisions, with diverse applications in education testing, recommendation systems, among others. The Rasch model of binary response data, one of the most fundamental models in IRT, remains an active area of research with important practical significance. Recently, Nguyen and Zhang (2022) proposed a new spectral estimation algorithm that is efficient and accurate. In this work, we extend their results in two important ways. Firstly, we obtain a refined entrywise error bound for the spectral algorithm, complementing the \u2018average error\u2019 $\\ell_2$ bound in their work. Notably, under mild sampling conditions, the spectral algorithm achieves the minimax optimal entrywise error bound (modulo a log factor). Building on the refined analysis, we also show that the spectral algorithm enjoys optimal sample complexity for top-$K$ recovery (e.g., identifying the best $K$ items from approval/disapproval response data), explaining interesting empirical findings in the previous work. Our second contribution addresses an important but understudied topic in IRT: privacy. Despite the human-centric applications of IRT, there has not been any proposed privacy-preserving mechanism in the literature. We develop a private extension of the spectral algorithm, leveraging its unique Markov chain formulation and the discrete Gaussian mechanism (Canonne et al., 2020). Experiments show that our approach is significantly more accurate than the baselines in the low-to-moderate privacy regime.",
        "bibtex": "@InProceedings{pmlr-v206-nguyen23a,\n  title = \t {Optimal and Private Learning from Human Response Data},\n  author =       {Nguyen, Duc and Zhang, Anderson Ye},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {922--958},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nguyen23a/nguyen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nguyen23a.html},\n  abstract = \t {Item response theory (IRT) is the study of how people make probabilistic decisions, with diverse applications in education testing, recommendation systems, among others. The Rasch model of binary response data, one of the most fundamental models in IRT, remains an active area of research with important practical significance. Recently, Nguyen and Zhang (2022) proposed a new spectral estimation algorithm that is efficient and accurate. In this work, we extend their results in two important ways. Firstly, we obtain a refined entrywise error bound for the spectral algorithm, complementing the \u2018average error\u2019 $\\ell_2$ bound in their work. Notably, under mild sampling conditions, the spectral algorithm achieves the minimax optimal entrywise error bound (modulo a log factor). Building on the refined analysis, we also show that the spectral algorithm enjoys optimal sample complexity for top-$K$ recovery (e.g., identifying the best $K$ items from approval/disapproval response data), explaining interesting empirical findings in the previous work. Our second contribution addresses an important but understudied topic in IRT: privacy. Despite the human-centric applications of IRT, there has not been any proposed privacy-preserving mechanism in the literature. We develop a private extension of the spectral algorithm, leveraging its unique Markov chain formulation and the discrete Gaussian mechanism (Canonne et al., 2020). Experiments show that our approach is significantly more accurate than the baselines in the low-to-moderate privacy regime.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nguyen23a/nguyen23a.pdf",
        "supp": "",
        "pdf_size": 1158700,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17955915859712068226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer & Information Science, University of Pennsylvania; Department of Statistics & Data Science, University of Pennsylvania",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Computer & Information Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1c69ef4a4a",
        "title": "Optimal robustness-consistency tradeoffs for learning-augmented metrical task systems",
        "site": "https://proceedings.mlr.press/v206/christianson23a.html",
        "author": "Nicolas Christianson; Junxuan Shen; Adam Wierman",
        "abstract": "We examine the problem of designing learning-augmented algorithms for metrical task systems (MTS) that exploit machine-learned advice while maintaining rigorous, worst-case guarantees on performance. We propose an algorithm, DART, that achieves this dual objective, providing cost within a multiplicative factor $(1+\\epsilon)$ of the machine-learned advice (i.e., consistency) while ensuring cost within a multiplicative factor $2^{O(1/\\epsilon)}$ of a baseline robust algorithm (i.e., robustness) for any $\\epsilon > 0$. We show that this exponential tradeoff between consistency and robustness is unavoidable in general, but that in important subclasses of MTS, such as when the metric space has bounded diameter and in the $k$-server problem, our algorithm achieves improved, polynomial tradeoffs between consistency and robustness.",
        "bibtex": "@InProceedings{pmlr-v206-christianson23a,\n  title = \t {Optimal robustness-consistency tradeoffs for learning-augmented metrical task systems},\n  author =       {Christianson, Nicolas and Shen, Junxuan and Wierman, Adam},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9377--9399},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/christianson23a/christianson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/christianson23a.html},\n  abstract = \t {We examine the problem of designing learning-augmented algorithms for metrical task systems (MTS) that exploit machine-learned advice while maintaining rigorous, worst-case guarantees on performance. We propose an algorithm, DART, that achieves this dual objective, providing cost within a multiplicative factor $(1+\\epsilon)$ of the machine-learned advice (i.e., consistency) while ensuring cost within a multiplicative factor $2^{O(1/\\epsilon)}$ of a baseline robust algorithm (i.e., robustness) for any $\\epsilon > 0$. We show that this exponential tradeoff between consistency and robustness is unavoidable in general, but that in important subclasses of MTS, such as when the metric space has bounded diameter and in the $k$-server problem, our algorithm achieves improved, polynomial tradeoffs between consistency and robustness.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/christianson23a/christianson23a.pdf",
        "supp": "",
        "pdf_size": 818479,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18019195144473956267&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "California Institute of Technology; California Institute of Technology; California Institute of Technology",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9b87b4119a",
        "title": "Optimism and Delays in Episodic Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/howson23a.html",
        "author": "Benjamin Howson; Ciara Pike-Burke; Sarah Filippi",
        "abstract": "There are many algorithms for regret minimisation in episodic reinforcement learning. This problem is well-understood from a theoretical perspective, providing that the sequences of states, actions and rewards associated with each episode are available to the algorithm updating the policy immediately after every interaction with the environment. However, feedback is almost always delayed in practice. In this paper, we study the impact of delayed feedback in episodic reinforcement learning from a theoretical perspective and propose two general-purpose approaches to handling the delays. The first involves updating as soon as new information becomes available, whereas the second waits before using newly observed information to update the policy. For the class of optimistic algorithms and either approach, we show that the regret increases by an additive term involving the number of states, actions, episode length, the expected delay and an algorithm-dependent constant. We empirically investigate the impact of various delay distributions on the regret of optimistic algorithms to validate our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v206-howson23a,\n  title = \t {Optimism and Delays in Episodic Reinforcement Learning},\n  author =       {Howson, Benjamin and Pike-Burke, Ciara and Filippi, Sarah},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6061--6094},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/howson23a/howson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/howson23a.html},\n  abstract = \t {There are many algorithms for regret minimisation in episodic reinforcement learning. This problem is well-understood from a theoretical perspective, providing that the sequences of states, actions and rewards associated with each episode are available to the algorithm updating the policy immediately after every interaction with the environment. However, feedback is almost always delayed in practice. In this paper, we study the impact of delayed feedback in episodic reinforcement learning from a theoretical perspective and propose two general-purpose approaches to handling the delays. The first involves updating as soon as new information becomes available, whereas the second waits before using newly observed information to update the policy. For the class of optimistic algorithms and either approach, we show that the regret increases by an additive term involving the number of states, actions, episode length, the expected delay and an algorithm-dependent constant. We empirically investigate the impact of various delay distributions on the regret of optimistic algorithms to validate our theoretical results.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/howson23a/howson23a.pdf",
        "supp": "",
        "pdf_size": 2285567,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6298402375613180893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "845e986419",
        "title": "Optimizing Pessimism in Dynamic Treatment Regimes: A Bayesian Learning Approach",
        "site": "https://proceedings.mlr.press/v206/zhou23a.html",
        "author": "Yunzhe Zhou; Zhengling Qi; Chengchun Shi; Lexin Li",
        "abstract": "In this article, we propose a novel pessimism-based Bayesian learning method for optimal dynamic treatment regimes in the offline setting. When the coverage condition does not hold, which is common for offline data, the existing solutions would produce sub-optimal policies. The pessimism principle addresses this issue by discouraging recommendation of actions that are less explored conditioning on the state. However, nearly all pessimism-based methods rely on a key hyper-parameter that quantifies the degree of pessimism, and the performance of the methods can be highly sensitive to the choice of this parameter. We propose to integrate the pessimism principle with Thompson sampling and Bayesian machine learning for optimizing the degree of pessimism. We derive a credible set whose boundary uniformly lower bounds the optimal Q-function, and thus we do not require additional tuning of the degree of pessimism. We develop a general Bayesian learning method that works with a range of models, from Bayesian linear basis model to Bayesian neural network model. We develop the computational algorithm based on variational inference, which is highly efficient and scalable. We establish the theoretical guarantees of the proposed method, and show empirically that it outperforms the existing state-of-the-art solutions through both simulations and a real data example.",
        "bibtex": "@InProceedings{pmlr-v206-zhou23a,\n  title = \t {Optimizing Pessimism in Dynamic Treatment Regimes: A Bayesian Learning Approach},\n  author =       {Zhou, Yunzhe and Qi, Zhengling and Shi, Chengchun and Li, Lexin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6704--6721},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhou23a/zhou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhou23a.html},\n  abstract = \t {In this article, we propose a novel pessimism-based Bayesian learning method for optimal dynamic treatment regimes in the offline setting. When the coverage condition does not hold, which is common for offline data, the existing solutions would produce sub-optimal policies. The pessimism principle addresses this issue by discouraging recommendation of actions that are less explored conditioning on the state. However, nearly all pessimism-based methods rely on a key hyper-parameter that quantifies the degree of pessimism, and the performance of the methods can be highly sensitive to the choice of this parameter. We propose to integrate the pessimism principle with Thompson sampling and Bayesian machine learning for optimizing the degree of pessimism. We derive a credible set whose boundary uniformly lower bounds the optimal Q-function, and thus we do not require additional tuning of the degree of pessimism. We develop a general Bayesian learning method that works with a range of models, from Bayesian linear basis model to Bayesian neural network model. We develop the computational algorithm based on variational inference, which is highly efficient and scalable. We establish the theoretical guarantees of the proposed method, and show empirically that it outperforms the existing state-of-the-art solutions through both simulations and a real data example.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhou23a/zhou23a.pdf",
        "supp": "",
        "pdf_size": 1709684,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4657830472286271850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d4192422a5",
        "title": "Oracle-free Reinforcement Learning in Mean-Field Games along a Single Sample Path",
        "site": "https://proceedings.mlr.press/v206/zaman23a.html",
        "author": "Muhammad Aneeq Uz Zaman; Alec Koppel; Sujay Bhatt; Tamer Basar",
        "abstract": "We consider online reinforcement learning in Mean-Field Games (MFGs). Unlike traditional approaches, we alleviate the need for a mean-field oracle by developing an algorithm that approximates the Mean-Field Equilibrium (MFE) using the single sample path of the generic agent. We call this Sandbox Learning, as it can be used as a warm-start for any agent learning in a multi-agent non-cooperative setting. We adopt a two time-scale approach in which an online fixed-point recursion for the mean-field operates on a slower time-scale, in tandem with a control policy update on a faster time-scale for the generic agent. Given that the underlying Markov Decision Process (MDP) of the agent is communicating, we provide finite sample convergence guarantees in terms of convergence of the mean-field and control policy to the mean-field equilibrium. The sample complexity of the Sandbox learning algorithm is $O(\\epsilon^{-4})$ where $\\epsilon$ is the MFE approximation error. This is similar to works which assume access to oracle. Finally, we empirically demonstrate the effectiveness of the sandbox learning algorithm in diverse scenarios, including those where the MDP does not necessarily have a single communicating class.",
        "bibtex": "@InProceedings{pmlr-v206-zaman23a,\n  title = \t {Oracle-free Reinforcement Learning in Mean-Field Games along a Single Sample Path},\n  author =       {Zaman, Muhammad Aneeq Uz and Koppel, Alec and Bhatt, Sujay and Basar, Tamer},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10178--10206},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zaman23a/zaman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zaman23a.html},\n  abstract = \t {We consider online reinforcement learning in Mean-Field Games (MFGs). Unlike traditional approaches, we alleviate the need for a mean-field oracle by developing an algorithm that approximates the Mean-Field Equilibrium (MFE) using the single sample path of the generic agent. We call this Sandbox Learning, as it can be used as a warm-start for any agent learning in a multi-agent non-cooperative setting. We adopt a two time-scale approach in which an online fixed-point recursion for the mean-field operates on a slower time-scale, in tandem with a control policy update on a faster time-scale for the generic agent. Given that the underlying Markov Decision Process (MDP) of the agent is communicating, we provide finite sample convergence guarantees in terms of convergence of the mean-field and control policy to the mean-field equilibrium. The sample complexity of the Sandbox learning algorithm is $O(\\epsilon^{-4})$ where $\\epsilon$ is the MFE approximation error. This is similar to works which assume access to oracle. Finally, we empirically demonstrate the effectiveness of the sandbox learning algorithm in diverse scenarios, including those where the MDP does not necessarily have a single communicating class.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zaman23a/zaman23a.pdf",
        "supp": "",
        "pdf_size": 854098,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10108495226555646343&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "CSL, UIUC; J.P. Morgan, USA+CSL, UIUC; J.P. Morgan, USA; CSL, UIUC",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;J.P. Morgan",
        "aff_unique_dep": "Computer Science Laboratory;",
        "aff_unique_url": "https://www.cs.uiuc.edu;https://www.jpmorganchase.com",
        "aff_unique_abbr": "UIUC;JPM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "49524a5712",
        "title": "Origins of Low-Dimensional Adversarial Perturbations",
        "site": "https://proceedings.mlr.press/v206/dohmatob23a.html",
        "author": "Elvis Dohmatob; Chuan Guo; Morgane Goibert",
        "abstract": "Machine learning models are known to be susceptible to adversarial perturbations. Even more concerning is the fact that these adversarial perturbations can be found by black-box search using surprisingly few queries, which essentially restricts the perturbation to a subspace of dimension $k$\u2014much smaller than the dimension $d$ of the image space. This intriguing phenomenon raises the question: Is the vulnerability to black-box attacks inherent or can we hope to prevent them? In this paper, we initiate a rigorous study of the phenomenon of low-dimensional adversarial perturbations (LDAPs). Our result characterizes precisely the sufficient conditions for the existence of LDAPs, and we show that these conditions hold for neural networks under practical settings, including the so-called lazy regime wherein the parameters of the trained network remain close to their values at initialization. Our theoretical results are confirmed by experiments on both synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v206-dohmatob23a,\n  title = \t {Origins of Low-Dimensional Adversarial Perturbations},\n  author =       {Dohmatob, Elvis and Guo, Chuan and Goibert, Morgane},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9221--9237},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/dohmatob23a/dohmatob23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/dohmatob23a.html},\n  abstract = \t {Machine learning models are known to be susceptible to adversarial perturbations. Even more concerning is the fact that these adversarial perturbations can be found by black-box search using surprisingly few queries, which essentially restricts the perturbation to a subspace of dimension $k$\u2014much smaller than the dimension $d$ of the image space. This intriguing phenomenon raises the question: Is the vulnerability to black-box attacks inherent or can we hope to prevent them? In this paper, we initiate a rigorous study of the phenomenon of low-dimensional adversarial perturbations (LDAPs). Our result characterizes precisely the sufficient conditions for the existence of LDAPs, and we show that these conditions hold for neural networks under practical settings, including the so-called lazy regime wherein the parameters of the trained network remain close to their values at initialization. Our theoretical results are confirmed by experiments on both synthetic and real data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/dohmatob23a/dohmatob23a.pdf",
        "supp": "",
        "pdf_size": 1304223,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13005603462857660885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2e7417d8f8",
        "title": "Overcoming Prior Misspecification in Online Learning to Rank",
        "site": "https://proceedings.mlr.press/v206/azizi23a.html",
        "author": "Javad Azizi; Ofer Meshi; Masrour Zoghi; Maryam Karimzadehgan",
        "abstract": "The recent literature on online learning to rank (LTR) has established the utility of prior knowledge to Bayesian ranking bandit algorithms. However, a major limitation of existing work is the requirement for the prior used by the algorithm to match the true prior. In this paper, we propose and analyze adaptive algorithms that address this issue and additionally extend these results to the linear and generalized linear models. We also consider scalar relevance feedback on top of click feedback. Moreover, we demonstrate the efficacy of our algorithms using both synthetic and real-world experiments.",
        "bibtex": "@InProceedings{pmlr-v206-azizi23a,\n  title = \t {Overcoming Prior Misspecification in Online Learning to Rank},\n  author =       {Azizi, Javad and Meshi, Ofer and Zoghi, Masrour and Karimzadehgan, Maryam},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {594--614},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/azizi23a/azizi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/azizi23a.html},\n  abstract = \t {The recent literature on online learning to rank (LTR) has established the utility of prior knowledge to Bayesian ranking bandit algorithms. However, a major limitation of existing work is the requirement for the prior used by the algorithm to match the true prior. In this paper, we propose and analyze adaptive algorithms that address this issue and additionally extend these results to the linear and generalized linear models. We also consider scalar relevance feedback on top of click feedback. Moreover, we demonstrate the efficacy of our algorithms using both synthetic and real-world experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/azizi23a/azizi23a.pdf",
        "supp": "",
        "pdf_size": 17532135,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7Y0G8LY78uYJ:scholar.google.com/&scioq=Overcoming+Prior+Misspecification+in+Online+Learning+to+Rank&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8fbdb7c650",
        "title": "Overparameterized Random Feature Regression with Nearly Orthogonal Data",
        "site": "https://proceedings.mlr.press/v206/wang23m.html",
        "author": "Zhichao Wang; Yizhe Zhu",
        "abstract": "We investigate the properties of random feature ridge regression (RFRR) given by a two-layer neural network with random Gaussian initialization. We study the non-asymptotic behaviors of the RFRR with nearly orthogonal deterministic unit-length input data vectors in the overparameterized regime, where the width of the first layer is much larger than the sample size. Our analysis shows high-probability non-asymptotic concentration results for the training errors, cross-validations, and generalization errors of RFRR centered around their respective values for a kernel ridge regression (KRR). This KRR is derived from an expected kernel generated by a nonlinear random feature map. We then approximate the performance of the KRR by a polynomial kernel matrix obtained from the Hermite polynomial expansion of the activation function, whose degree only depends on the orthogonality among different data points. This polynomial kernel determines the asymptotic behavior of the RFRR and the KRR. Our results hold for a wide variety of activation functions and input data sets that exhibit nearly orthogonal properties. Based on these approximations, we obtain a lower bound for the generalization error of the RFRR for a nonlinear student-teacher model.",
        "bibtex": "@InProceedings{pmlr-v206-wang23m,\n  title = \t {Overparameterized Random Feature Regression with Nearly Orthogonal Data},\n  author =       {Wang, Zhichao and Zhu, Yizhe},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8463--8493},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23m/wang23m.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23m.html},\n  abstract = \t {We investigate the properties of random feature ridge regression (RFRR) given by a two-layer neural network with random Gaussian initialization. We study the non-asymptotic behaviors of the RFRR with nearly orthogonal deterministic unit-length input data vectors in the overparameterized regime, where the width of the first layer is much larger than the sample size. Our analysis shows high-probability non-asymptotic concentration results for the training errors, cross-validations, and generalization errors of RFRR centered around their respective values for a kernel ridge regression (KRR). This KRR is derived from an expected kernel generated by a nonlinear random feature map. We then approximate the performance of the KRR by a polynomial kernel matrix obtained from the Hermite polynomial expansion of the activation function, whose degree only depends on the orthogonality among different data points. This polynomial kernel determines the asymptotic behavior of the RFRR and the KRR. Our results hold for a wide variety of activation functions and input data sets that exhibit nearly orthogonal properties. Based on these approximations, we obtain a lower bound for the generalization error of the RFRR for a nonlinear student-teacher model.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23m/wang23m.pdf",
        "supp": "",
        "pdf_size": 857501,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4092274277137317304&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, San Diego; University of California, Irvine",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, San Diego;University of California, Irvine",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsd.edu;https://www.uci.edu",
        "aff_unique_abbr": "UCSD;UCI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "San Diego;Irvine",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "81e791f710",
        "title": "PAC Learning of Halfspaces with Malicious Noise in Nearly Linear Time",
        "site": "https://proceedings.mlr.press/v206/shen23a.html",
        "author": "Jie Shen",
        "abstract": "We study the problem of efficient PAC learning of halfspaces in $\\mathbb{R}^d$ in the presence of the malicious noise, where a fraction of the training samples are adversarially corrupted. A series of recent works have developed polynomial-time algorithms that enjoy near-optimal sample complexity and noise tolerance, yet leaving open whether a linear-time algorithm exists and matches these appealing statistical performance guarantees. In this work, we give an affirmative answer by developing an algorithm that runs in time $\\tilde{O}(m d )$, where $m = \\tilde{O}(\\frac{d}{\\epsilon})$ is the sample size and $\\epsilon \\in (0, 1)$ is the target error rate. Notably, the computational complexity of all prior algorithms suffer either a high order dependence on the problem size, or is implicitly proportional to $\\frac{1}{\\epsilon^2}$ through the sample size. Our key idea is to combine localization and an approximate version of matrix multiplicative weights update method to progressively downweight the contribution of the corrupted samples while refining the learned halfspace.",
        "bibtex": "@InProceedings{pmlr-v206-shen23a,\n  title = \t {PAC Learning of Halfspaces with Malicious Noise in Nearly Linear Time},\n  author =       {Shen, Jie},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {30--46},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shen23a/shen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shen23a.html},\n  abstract = \t {We study the problem of efficient PAC learning of halfspaces in $\\mathbb{R}^d$ in the presence of the malicious noise, where a fraction of the training samples are adversarially corrupted. A series of recent works have developed polynomial-time algorithms that enjoy near-optimal sample complexity and noise tolerance, yet leaving open whether a linear-time algorithm exists and matches these appealing statistical performance guarantees. In this work, we give an affirmative answer by developing an algorithm that runs in time $\\tilde{O}(m d )$, where $m = \\tilde{O}(\\frac{d}{\\epsilon})$ is the sample size and $\\epsilon \\in (0, 1)$ is the target error rate. Notably, the computational complexity of all prior algorithms suffer either a high order dependence on the problem size, or is implicitly proportional to $\\frac{1}{\\epsilon^2}$ through the sample size. Our key idea is to combine localization and an approximate version of matrix multiplicative weights update method to progressively downweight the contribution of the corrupted samples while refining the learned halfspace.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shen23a/shen23a.pdf",
        "supp": "",
        "pdf_size": 345473,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9533267846719222355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Stevens Institute of Technology",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7fa00ac764",
        "title": "PAC-Bayesian Learning of Optimization Algorithms",
        "site": "https://proceedings.mlr.press/v206/sucker23a.html",
        "author": "Michael Sucker; Peter Ochs",
        "abstract": "We apply the PAC-Bayes theory to the setting of learning-to-optimize. To the best of our knowledge, we present the first framework to learn optimization algorithms with provable generalization guarantees (PAC-bounds) and explicit trade-off between a high probability of convergence and a high convergence speed. Even in the limit case, where convergence is guaranteed, our learned optimization algorithms provably outperform related algorithms based on a (deterministic) worst-case analysis. Our results rely on PAC-Bayes bounds for general, unbounded loss-functions based on exponential families. By generalizing existing ideas, we reformulate the learning procedure into a one-dimensional minimization problem and study the possibility to find a global minimum, which enables the algorithmic realization of the learning procedure. As a proof-of-concept, we learn hyperparameters of standard optimization algorithms to empirically underline our theory.",
        "bibtex": "@InProceedings{pmlr-v206-sucker23a,\n  title = \t {PAC-Bayesian Learning of Optimization Algorithms},\n  author =       {Sucker, Michael and Ochs, Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8145--8164},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sucker23a/sucker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sucker23a.html},\n  abstract = \t {We apply the PAC-Bayes theory to the setting of learning-to-optimize. To the best of our knowledge, we present the first framework to learn optimization algorithms with provable generalization guarantees (PAC-bounds) and explicit trade-off between a high probability of convergence and a high convergence speed. Even in the limit case, where convergence is guaranteed, our learned optimization algorithms provably outperform related algorithms based on a (deterministic) worst-case analysis. Our results rely on PAC-Bayes bounds for general, unbounded loss-functions based on exponential families. By generalizing existing ideas, we reformulate the learning procedure into a one-dimensional minimization problem and study the possibility to find a global minimum, which enables the algorithmic realization of the learning procedure. As a proof-of-concept, we learn hyperparameters of standard optimization algorithms to empirically underline our theory.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sucker23a/sucker23a.pdf",
        "supp": "",
        "pdf_size": 1141136,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2290709559273979048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Mathematics, University of T\u00fcbingen; Department of Mathematics, University of T\u00fcbingen",
        "aff_domain": "math.uni-tuebingen.de;math.uni-tuebingen.de",
        "email": "math.uni-tuebingen.de;math.uni-tuebingen.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "Uni T\u00fcbingen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "2fa9806bd6",
        "title": "Particle algorithms for maximum likelihood training of latent variable models",
        "site": "https://proceedings.mlr.press/v206/kuntz23a.html",
        "author": "Juan Kuntz; Jen Ning Lim; Adam M. Johansen",
        "abstract": "Neal and Hinton (1998) recast maximum likelihood estimation of any given latent variable model as the minimization of a free energy functional F, and the EM algorithm as coordinate descent applied to F. Here, we explore alternative ways to optimize the functional. In particular, we identify various gradient flows associated with F and show that their limits coincide with F\u2019s stationary points. By discretizing the flows, we obtain practical particle-based algorithms for maximum likelihood estimation in broad classes of latent variable models. The novel algorithms scale to high-dimensional settings and perform well in numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v206-kuntz23a,\n  title = \t {Particle algorithms for maximum likelihood training of latent variable models},\n  author =       {Kuntz, Juan and Lim, Jen Ning and Johansen, Adam M.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5134--5180},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kuntz23a/kuntz23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kuntz23a.html},\n  abstract = \t {Neal and Hinton (1998) recast maximum likelihood estimation of any given latent variable model as the minimization of a free energy functional F, and the EM algorithm as coordinate descent applied to F. Here, we explore alternative ways to optimize the functional. In particular, we identify various gradient flows associated with F and show that their limits coincide with F\u2019s stationary points. By discretizing the flows, we obtain practical particle-based algorithms for maximum likelihood estimation in broad classes of latent variable models. The novel algorithms scale to high-dimensional settings and perform well in numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kuntz23a/kuntz23a.pdf",
        "supp": "",
        "pdf_size": 1331101,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11993510179683943147&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, University of Warwick; Department of Statistics, University of Warwick; Department of Statistics, University of Warwick",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Warwick",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://warwick.ac.uk",
        "aff_unique_abbr": "Warwick",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9e3918a21c",
        "title": "Performative Prediction with Neural Networks",
        "site": "https://proceedings.mlr.press/v206/mofakhami23a.html",
        "author": "Mehrnaz Mofakhami; Ioannis Mitliagkas; Gauthier Gidel",
        "abstract": "Performative prediction is a framework for learning models that influence the data they intend to predict. We focus on finding classifiers that are performatively stable, i.e. optimal for the data distribution they induce. Standard convergence results for finding a performatively stable classifier with the method of repeated risk minimization assume that the data distribution is Lipschitz continuous to the model\u2019s parameters. Under this assumption, the loss must be strongly convex and smooth in these parameters; otherwise, the method will diverge for some problems. In this work, we instead assume that the data distribution is Lipschitz continuous with respect to the model\u2019s predictions, a more natural assumption for performative systems. As a result, we are able to significantly relax the assumptions on the loss function. In particular, we do not need to assume convexity with respect to the model\u2019s parameters. As an illustration, we introduce a resampling procedure that models realistic distribution shifts and show that it satisfies our assumptions. We support our theory by showing that one can learn performatively stable classifiers with neural networks making predictions about real data that shift according to our proposed procedure.",
        "bibtex": "@InProceedings{pmlr-v206-mofakhami23a,\n  title = \t {Performative Prediction with Neural Networks},\n  author =       {Mofakhami, Mehrnaz and Mitliagkas, Ioannis and Gidel, Gauthier},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11079--11093},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mofakhami23a/mofakhami23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mofakhami23a.html},\n  abstract = \t {Performative prediction is a framework for learning models that influence the data they intend to predict. We focus on finding classifiers that are performatively stable, i.e. optimal for the data distribution they induce. Standard convergence results for finding a performatively stable classifier with the method of repeated risk minimization assume that the data distribution is Lipschitz continuous to the model\u2019s parameters. Under this assumption, the loss must be strongly convex and smooth in these parameters; otherwise, the method will diverge for some problems. In this work, we instead assume that the data distribution is Lipschitz continuous with respect to the model\u2019s predictions, a more natural assumption for performative systems. As a result, we are able to significantly relax the assumptions on the loss function. In particular, we do not need to assume convexity with respect to the model\u2019s parameters. As an illustration, we introduce a resampling procedure that models realistic distribution shifts and show that it satisfies our assumptions. We support our theory by showing that one can learn performatively stable classifiers with neural networks making predictions about real data that shift according to our proposed procedure.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mofakhami23a/mofakhami23a.pdf",
        "supp": "",
        "pdf_size": 2655670,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8912936917087690307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3f12ced3f9",
        "title": "Piecewise Stationary Bandits under Risk Criteria",
        "site": "https://proceedings.mlr.press/v206/bhatt23b.html",
        "author": "Sujay Bhatt; Guanhua Fang; Ping Li",
        "abstract": "Piecewise stationary stochastic multi-armed bandits have been extensively explored in the risk-neutral and sub-Gaussian setting. In this work, we consider a multi-armed bandit framework in which the reward distributions are heavy-tailed and non-stationary, and evaluate the performance of algorithms using general risk criteria. Specifically, we make the following contributions: (i) We first propose a non-parametric change detection algorithm that can detect general distributional changes in heavy-tailed distributions. (ii)We then propose a truncation-based UCB-type bandit algorithm integrating the above regime change detection algorithm to minimize the regret of the non-stationary learning problem. (iii) Finally, we establish the regret bounds for the proposed bandit algorithm by characterizing the statistical properties of the general change detection algorithm, along with a novel regret analysis.",
        "bibtex": "@InProceedings{pmlr-v206-bhatt23b,\n  title = \t {Piecewise Stationary Bandits under Risk Criteria},\n  author =       {Bhatt, Sujay and Fang, Guanhua and Li, Ping},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4313--4335},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bhatt23b/bhatt23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bhatt23b.html},\n  abstract = \t {Piecewise stationary stochastic multi-armed bandits have been extensively explored in the risk-neutral and sub-Gaussian setting. In this work, we consider a multi-armed bandit framework in which the reward distributions are heavy-tailed and non-stationary, and evaluate the performance of algorithms using general risk criteria. Specifically, we make the following contributions: (i) We first propose a non-parametric change detection algorithm that can detect general distributional changes in heavy-tailed distributions. (ii)We then propose a truncation-based UCB-type bandit algorithm integrating the above regime change detection algorithm to minimize the regret of the non-stationary learning problem. (iii) Finally, we establish the regret bounds for the proposed bandit algorithm by characterizing the statistical properties of the general change detection algorithm, along with a novel regret analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bhatt23b/bhatt23b.pdf",
        "supp": "",
        "pdf_size": 519424,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1955720734633232332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "J.P. Morgan AI Research, New York City, USA; School of Management, Fudan University, China; LinkedIn Ads, Bellevue, WA 98004, USA",
        "aff_domain": "gmail.com;fudan.edu.cn;linkedin.com",
        "email": "gmail.com;fudan.edu.cn;linkedin.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "J.P. Morgan AI Research;Fudan University;LinkedIn",
        "aff_unique_dep": "AI Research;School of Management;LinkedIn Ads",
        "aff_unique_url": "https://www.jpmorgan.com/global/research;https://www.fudan.edu.cn;https://www.linkedin.com",
        "aff_unique_abbr": "JPM AI;Fudan;LinkedIn",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "New York City;;Bellevue",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "0cb13ec935",
        "title": "Pointwise sampling uncertainties on the Precision-Recall curve",
        "site": "https://proceedings.mlr.press/v206/urlus23a.html",
        "author": "Ralph E.Q. Urlus; Max Baak; St\u00e9phane Collot; Ilan Fridman Rojas",
        "abstract": "Quoting robust uncertainties on machine learning (ML) model metrics, such as f1-score, precision, recall, etc., from sources of uncertainty such as data sampling, parameter initialization, and target labelling, is typically not done in the field of data science, even though these are essential for the proper interpretation and comparison of ML models. This text shows how to calculate and visualize the impact of one dominant source of uncertainty - on each point of the Precision-Recall (PR) and Receiver Operating Characteristic (ROC) curves. This is particularly relevant for PR curves, where the joint uncertainty on recall and precision can be large and non-linear, especially at low recall. Four statistical methods to evaluate this uncertainty, both frequentist and Bayesian in origin, are compared in terms of coverage and speed. Of these, Wilks\u2019 toolbox.",
        "bibtex": "@InProceedings{pmlr-v206-urlus23a,\n  title = \t {Pointwise sampling uncertainties on the Precision-Recall curve},\n  author =       {Urlus, Ralph E.Q. and Baak, Max and Collot, St\\'ephane and Fridman Rojas, Ilan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8211--8232},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/urlus23a/urlus23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/urlus23a.html},\n  abstract = \t {Quoting robust uncertainties on machine learning (ML) model metrics, such as f1-score, precision, recall, etc., from sources of uncertainty such as data sampling, parameter initialization, and target labelling, is typically not done in the field of data science, even though these are essential for the proper interpretation and comparison of ML models. This text shows how to calculate and visualize the impact of one dominant source of uncertainty - on each point of the Precision-Recall (PR) and Receiver Operating Characteristic (ROC) curves. This is particularly relevant for PR curves, where the joint uncertainty on recall and precision can be large and non-linear, especially at low recall. Four statistical methods to evaluate this uncertainty, both frequentist and Bayesian in origin, are compared in terms of coverage and speed. Of these, Wilks\u2019 toolbox.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/urlus23a/urlus23a.pdf",
        "supp": "",
        "pdf_size": 6141780,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2986341900519519750&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "74063ece1d",
        "title": "Positional Encoder Graph Neural Networks for Geographic Data",
        "site": "https://proceedings.mlr.press/v206/klemmer23a.html",
        "author": "Konstantin Klemmer; Nathan S. Safir; Daniel B. Neill",
        "abstract": "Graph neural networks (GNNs) provide a powerful and scalable solution for modeling continuous spatial data. However, they often rely on Euclidean distances to construct the input graphs. This assumption can be improbable in many real-world settings, where the spatial structure is more complex and explicitly non-Euclidean (e.g., road networks). Here, we propose PE-GNN, a new framework that incorporates spatial context and correlation explicitly into the models. Building on recent advances in geospatial auxiliary task learning and semantic spatial embeddings, our proposed method (1) learns a context-aware vector encoding of the geographic coordinates and (2) predicts spatial autocorrelation in the data in parallel with the main task. On spatial interpolation and regression tasks, we show the effectiveness of our approach, improving performance over different state-of-the-art GNN approaches. We observe that our approach not only vastly improves over the GNN baselines, but can match Gaussian processes, the most commonly utilized method for spatial interpolation problems.",
        "bibtex": "@InProceedings{pmlr-v206-klemmer23a,\n  title = \t {Positional Encoder Graph Neural Networks for Geographic Data},\n  author =       {Klemmer, Konstantin and Safir, Nathan S. and Neill, Daniel B.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1379--1389},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/klemmer23a/klemmer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/klemmer23a.html},\n  abstract = \t {Graph neural networks (GNNs) provide a powerful and scalable solution for modeling continuous spatial data. However, they often rely on Euclidean distances to construct the input graphs. This assumption can be improbable in many real-world settings, where the spatial structure is more complex and explicitly non-Euclidean (e.g., road networks). Here, we propose PE-GNN, a new framework that incorporates spatial context and correlation explicitly into the models. Building on recent advances in geospatial auxiliary task learning and semantic spatial embeddings, our proposed method (1) learns a context-aware vector encoding of the geographic coordinates and (2) predicts spatial autocorrelation in the data in parallel with the main task. On spatial interpolation and regression tasks, we show the effectiveness of our approach, improving performance over different state-of-the-art GNN approaches. We observe that our approach not only vastly improves over the GNN baselines, but can match Gaussian processes, the most commonly utilized method for spatial interpolation problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/klemmer23a/klemmer23a.pdf",
        "supp": "",
        "pdf_size": 1183115,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13511103830459075216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3bc159f4b1",
        "title": "Posterior Tracking Algorithm for Classification Bandits",
        "site": "https://proceedings.mlr.press/v206/tabata23a.html",
        "author": "Koji Tabata; Junpei Komiyama; Atsuyoshi Nakamura; Tamiki Komatsuzaki",
        "abstract": "The classification bandit problem aims to determine whether a set of given $K$ arms contains at least $L$ good arms or not. Here, an arm is said to be good if its expected reward is no less than a specified threshold. To solve this problem, we introduce an asymptotically optimal algorithm, named P-tracking, based on posterior sampling. Unlike previous asymptotically optimal algorithms that require solving a linear programming problem with an exponentially large number of constraints, P-tracking solves an equivalent optimization problem that can be computed in time linear in $K$. Additionally, unlike existing algorithms, P-tracking does not require forced exploration steps. Empirical results show that P-tracking outperforms existing algorithms in sample efficiency.",
        "bibtex": "@InProceedings{pmlr-v206-tabata23a,\n  title = \t {Posterior Tracking Algorithm for Classification Bandits},\n  author =       {Tabata, Koji and Komiyama, Junpei and Nakamura, Atsuyoshi and Komatsuzaki, Tamiki},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10994--11022},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tabata23a/tabata23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tabata23a.html},\n  abstract = \t {The classification bandit problem aims to determine whether a set of given $K$ arms contains at least $L$ good arms or not. Here, an arm is said to be good if its expected reward is no less than a specified threshold. To solve this problem, we introduce an asymptotically optimal algorithm, named P-tracking, based on posterior sampling. Unlike previous asymptotically optimal algorithms that require solving a linear programming problem with an exponentially large number of constraints, P-tracking solves an equivalent optimization problem that can be computed in time linear in $K$. Additionally, unlike existing algorithms, P-tracking does not require forced exploration steps. Empirical results show that P-tracking outperforms existing algorithms in sample efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tabata23a/tabata23a.pdf",
        "supp": "",
        "pdf_size": 3884031,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14459911785413037096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e7c26fb147",
        "title": "Precision Recall Cover: A Method For Assessing Generative Models",
        "site": "https://proceedings.mlr.press/v206/cheema23a.html",
        "author": "Fasil Cheema; Ruth Urner",
        "abstract": "Generative modelling has seen enormous practical advances over the past few years. Evaluating the quality of a generative system however is often still based on subjective human inspection. To overcome this, very recently the research community has turned to exploring formal evaluation metrics and methods. In this work, we propose a novel evaluation paradigm based on a two way nearest neighbor neighborhood test. We define a novel measure of mutual coverage for two continuous probability distributions. From this, we derive an empirical analogue and show analytically that it exhibits favorable theoretical properties while it is also straightforward to compute. We show that, while algorithmically simple, our derived method is also statistically sound. In contrast to previously employed distance measures, our measure naturally stems from a notion of local discrepancy, which can be accessed separately. This provides more detailed information to practitioners on the diagnosis of where their generative models will perform well, or conversely where their models fail. We complement our analysis with a systematic experimental evaluation and comparison to other recently proposed measures. Using a wide array of experiments we demonstrate our algorithms strengths over other existing methods and confirm our results from the theoretical analysis.",
        "bibtex": "@InProceedings{pmlr-v206-cheema23a,\n  title = \t {Precision Recall Cover: A Method For Assessing Generative Models},\n  author =       {Cheema, Fasil and Urner, Ruth},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6571--6594},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cheema23a/cheema23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cheema23a.html},\n  abstract = \t {Generative modelling has seen enormous practical advances over the past few years. Evaluating the quality of a generative system however is often still based on subjective human inspection. To overcome this, very recently the research community has turned to exploring formal evaluation metrics and methods. In this work, we propose a novel evaluation paradigm based on a two way nearest neighbor neighborhood test. We define a novel measure of mutual coverage for two continuous probability distributions. From this, we derive an empirical analogue and show analytically that it exhibits favorable theoretical properties while it is also straightforward to compute. We show that, while algorithmically simple, our derived method is also statistically sound. In contrast to previously employed distance measures, our measure naturally stems from a notion of local discrepancy, which can be accessed separately. This provides more detailed information to practitioners on the diagnosis of where their generative models will perform well, or conversely where their models fail. We complement our analysis with a systematic experimental evaluation and comparison to other recently proposed measures. Using a wide array of experiments we demonstrate our algorithms strengths over other existing methods and confirm our results from the theoretical analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cheema23a/cheema23a.pdf",
        "supp": "",
        "pdf_size": 4736040,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11833448134542982840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Lassonde School of Engineering, EECS Department, York University, Toronto, Canada; Lassonde School of Engineering, EECS Department, York University, Toronto, Canada",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "York University",
        "aff_unique_dep": "EECS Department",
        "aff_unique_url": "https://yorku.ca",
        "aff_unique_abbr": "York U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "68cd12df5a",
        "title": "Precision/Recall on Imbalanced Test Data",
        "site": "https://proceedings.mlr.press/v206/shang23a.html",
        "author": "Hongwei Shang; Jean-Marc Langlois; Kostas Tsioutsiouliklis; Changsung Kang",
        "abstract": "In this paper we study the problem of estimating accurately the precision and recall for binary classification when the classes are imbalanced and only a limited number of human labels are available. One common strategy is to over-sample the small positive class predicted by the classifier. Rather than random sampling where the values in a confusion matrix are observations coming from a multinomial distribution, we over-sample the minority positive class predicted by the classifier, resulting in two independent binomial distributions. But how much should we over-sample? And what confidence/credible intervals can we deduce based on our over-sampling? We provide formulas for (1) the confidence intervals of the adjusted precision/recall after over-sampling; (2) Bayesian credible intervals of adjusted precision/recall. For precision, the higher the over-sampling rate, the narrower the confidence/credible interval. For recall, there exists an optimal over-sampling ratio, which minimizes the width of the confidence/credible interval. Also, we present experiments on synthetic data and real data to demonstrate the capability of our method to construct accurate intervals. Finally, we demonstrate how we can apply our techniques to Yahoo mail\u2019s quality monitoring system.",
        "bibtex": "@InProceedings{pmlr-v206-shang23a,\n  title = \t {Precision/Recall on Imbalanced Test Data},\n  author =       {Shang, Hongwei and Langlois, Jean-Marc and Tsioutsiouliklis, Kostas and Kang, Changsung},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9879--9891},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shang23a/shang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shang23a.html},\n  abstract = \t {In this paper we study the problem of estimating accurately the precision and recall for binary classification when the classes are imbalanced and only a limited number of human labels are available. One common strategy is to over-sample the small positive class predicted by the classifier. Rather than random sampling where the values in a confusion matrix are observations coming from a multinomial distribution, we over-sample the minority positive class predicted by the classifier, resulting in two independent binomial distributions. But how much should we over-sample? And what confidence/credible intervals can we deduce based on our over-sampling? We provide formulas for (1) the confidence intervals of the adjusted precision/recall after over-sampling; (2) Bayesian credible intervals of adjusted precision/recall. For precision, the higher the over-sampling rate, the narrower the confidence/credible interval. For recall, there exists an optimal over-sampling ratio, which minimizes the width of the confidence/credible interval. Also, we present experiments on synthetic data and real data to demonstrate the capability of our method to construct accurate intervals. Finally, we demonstrate how we can apply our techniques to Yahoo mail\u2019s quality monitoring system.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shang23a/shang23a.pdf",
        "supp": "",
        "pdf_size": 397651,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14475844748057533867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3ae4ff8ae2",
        "title": "Prediction-Oriented Bayesian Active Learning",
        "site": "https://proceedings.mlr.press/v206/bickfordsmith23a.html",
        "author": "Freddie Bickford Smith; Andreas Kirsch; Sebastian Farquhar; Yarin Gal; Adam Foster; Tom Rainforth",
        "abstract": "Information-theoretic approaches to active learning have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an input distribution and so is prone to prioritise data of limited relevance. To address this we propose the expected predictive information gain (EPIG), an acquisition function that measures information gain in the space of predictions rather than parameters. We find that using EPIG leads to stronger predictive performance compared with BALD across a range of datasets and models, and thus provides an appealing drop-in replacement.",
        "bibtex": "@InProceedings{pmlr-v206-bickfordsmith23a,\n  title = \t {Prediction-Oriented Bayesian Active Learning},\n  author =       {Bickford Smith, Freddie and Kirsch, Andreas and Farquhar, Sebastian and Gal, Yarin and Foster, Adam and Rainforth, Tom},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7331--7348},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bickfordsmith23a/bickfordsmith23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bickfordsmith23a.html},\n  abstract = \t {Information-theoretic approaches to active learning have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an input distribution and so is prone to prioritise data of limited relevance. To address this we propose the expected predictive information gain (EPIG), an acquisition function that measures information gain in the space of predictions rather than parameters. We find that using EPIG leads to stronger predictive performance compared with BALD across a range of datasets and models, and thus provides an appealing drop-in replacement.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bickfordsmith23a/bickfordsmith23a.pdf",
        "supp": "",
        "pdf_size": 905832,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3776674538366223394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8a998ddb1c",
        "title": "Preferential Subsampling for Stochastic Gradient Langevin Dynamics",
        "site": "https://proceedings.mlr.press/v206/putcha23a.html",
        "author": "Srshti Putcha; Christopher Nemeth; Paul Fearnhead",
        "abstract": "Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample size that is used.",
        "bibtex": "@InProceedings{pmlr-v206-putcha23a,\n  title = \t {Preferential Subsampling for Stochastic Gradient Langevin Dynamics},\n  author =       {Putcha, Srshti and Nemeth, Christopher and Fearnhead, Paul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8837--8856},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/putcha23a/putcha23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/putcha23a.html},\n  abstract = \t {Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample size that is used.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/putcha23a/putcha23a.pdf",
        "supp": "",
        "pdf_size": 5879434,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:1NyEjWKGCEYJ:scholar.google.com/&scioq=Preferential+Subsampling+for+Stochastic+Gradient+Langevin+Dynamics&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Lancaster University + Experian DataLabs (UK&I); Lancaster University; Lancaster University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0",
        "aff_unique_norm": "Lancaster University;Experian",
        "aff_unique_dep": ";DataLabs",
        "aff_unique_url": "https://www.lancaster.ac.uk;https://www.experian.com",
        "aff_unique_abbr": "Lancaster;Experian",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "db686a7daf",
        "title": "Pricing against a Budget and ROI Constrained Buyer",
        "site": "https://proceedings.mlr.press/v206/golrezaei23a.html",
        "author": "Negin Golrezaei; Patrick Jaillet; Jason Cheuk Nam Liang; Vahab Mirrokni",
        "abstract": "Internet advertisers (buyers) repeatedly procure ad impressions from ad platforms (sellers) with the aim to maximize total conversion (i.e. ad value) while respecting both budget and return-on-investment (ROI) constraints for efficient utilization of limited monetary resources. Facing such a constrained buyer who aims to learn her optimal strategy to acquire impressions, we study from a seller\u2019s perspective how to learn and price ad impressions through repeated posted price mechanisms to maximize revenue. For this two-sided learning setup, we propose a learning algorithm for the seller that utilizes an episodic binary-search procedure to identify a revenue-optimal selling price. We show that such a simple learning algorithm enjoys low seller regret when within each episode, the budget and ROI constrained buyer approximately best responds to the posted price. We present simple yet natural buyer\u2019s bidding algorithms under which the buyer approximately best responds while satisfying budget and ROI constraints, leading to a low regret for our proposed seller pricing algorithm. The design of our seller algorithm is motivated by the fact that the seller\u2019s revenue function admits a bell-shaped structure when the buyer best responds to prices under budget and ROI constraints, enabling our seller algorithm to identify revenue-optimal selling prices efficiently.",
        "bibtex": "@InProceedings{pmlr-v206-golrezaei23a,\n  title = \t {Pricing against a Budget and ROI Constrained Buyer},\n  author =       {Golrezaei, Negin and Jaillet, Patrick and Cheuk Nam Liang, Jason and Mirrokni, Vahab},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9282--9307},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/golrezaei23a/golrezaei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/golrezaei23a.html},\n  abstract = \t {Internet advertisers (buyers) repeatedly procure ad impressions from ad platforms (sellers) with the aim to maximize total conversion (i.e. ad value) while respecting both budget and return-on-investment (ROI) constraints for efficient utilization of limited monetary resources. Facing such a constrained buyer who aims to learn her optimal strategy to acquire impressions, we study from a seller\u2019s perspective how to learn and price ad impressions through repeated posted price mechanisms to maximize revenue. For this two-sided learning setup, we propose a learning algorithm for the seller that utilizes an episodic binary-search procedure to identify a revenue-optimal selling price. We show that such a simple learning algorithm enjoys low seller regret when within each episode, the budget and ROI constrained buyer approximately best responds to the posted price. We present simple yet natural buyer\u2019s bidding algorithms under which the buyer approximately best responds while satisfying budget and ROI constraints, leading to a low regret for our proposed seller pricing algorithm. The design of our seller algorithm is motivated by the fact that the seller\u2019s revenue function admits a bell-shaped structure when the buyer best responds to prices under budget and ROI constraints, enabling our seller algorithm to identify revenue-optimal selling prices efficiently.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/golrezaei23a/golrezaei23a.pdf",
        "supp": "",
        "pdf_size": 579223,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16696640773316322295&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8a5c4090ae",
        "title": "Principled Approaches for Private Adaptation from a Public Source",
        "site": "https://proceedings.mlr.press/v206/bassily23a.html",
        "author": "Raef Bassily; Mehryar Mohri; Ananda Theertha Suresh",
        "abstract": "A key problem in a variety of applications is that of domain adaptation from a public source domain, for which a relatively large amount of labeled data with no privacy constraints is at one\u2019s disposal, to a private target domain, for which a private sample is available with very few or no labeled data. In regression problems, where there are no privacy constraints on the source or target data, a discrepancy minimization approach was shown to outperform a number of other adaptation algorithm baselines. Building on that approach, we initiate a principled study of differentially private adaptation from a source domain with public labeled data to a target domain with unlabeled private data. We design differentially private discrepancy-based adaptation algorithms for this problem. The design and analysis of our private algorithms critically hinge upon several key properties we prove for a smooth approximation of the weighted discrepancy, such as its smoothness with respect to the $\\ell_1$-norm and the sensitivity of its gradient. We formally show that our adaptation algorithms benefit from strong generalization and privacy guarantees.",
        "bibtex": "@InProceedings{pmlr-v206-bassily23a,\n  title = \t {Principled Approaches for Private Adaptation from a Public Source},\n  author =       {Bassily, Raef and Mohri, Mehryar and Suresh, Ananda Theertha},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8405--8432},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bassily23a/bassily23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bassily23a.html},\n  abstract = \t {A key problem in a variety of applications is that of domain adaptation from a public source domain, for which a relatively large amount of labeled data with no privacy constraints is at one\u2019s disposal, to a private target domain, for which a private sample is available with very few or no labeled data. In regression problems, where there are no privacy constraints on the source or target data, a discrepancy minimization approach was shown to outperform a number of other adaptation algorithm baselines. Building on that approach, we initiate a principled study of differentially private adaptation from a source domain with public labeled data to a target domain with unlabeled private data. We design differentially private discrepancy-based adaptation algorithms for this problem. The design and analysis of our private algorithms critically hinge upon several key properties we prove for a smooth approximation of the weighted discrepancy, such as its smoothness with respect to the $\\ell_1$-norm and the sensitivity of its gradient. We formally show that our adaptation algorithms benefit from strong generalization and privacy guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bassily23a/bassily23a.pdf",
        "supp": "",
        "pdf_size": 506444,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15850687921622218018&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "The Ohio State University & Google Research NY; Google Research & Courant Institute of Mathematical Sciences, NY; Google Research, NY",
        "aff_domain": "osu.edu;google.com;google.com",
        "email": "osu.edu;google.com;google.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ohio State University;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.osu.edu;https://research.google",
        "aff_unique_abbr": "OSU;Google Res.",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "62acc8cb57",
        "title": "Privacy-preserving Sparse Generalized Eigenvalue Problem",
        "site": "https://proceedings.mlr.press/v206/hu23a.html",
        "author": "Lijie Hu; Zihang Xiang; Jiabin Liu; Di Wang",
        "abstract": "In this paper we study the (sparse) Generalized Eigenvalue Problem (GEP), which arises in a number of modern statistical learning models, such as principal component analysis (PCA), canonical correlation analysis (CCA), Fisher\u2019s discriminant analysis (FDA) and sliced inverse regression (SIR). We provide the first study on GEP in the differential privacy (DP) model under both deterministic and stochastic settings. In the low dimensional case, we provide a $\\rho$-Concentrated DP (CDP) method namely DP-Rayleigh Flow and show if the initial vector is close enough to the optimal vector, its output has an $\\ell_2$-norm estimation error of $\\tilde{O}(\\frac{d}{n}+\\frac{d}{n^2\\rho})$ (under some mild assumptions), where $d$ is the dimension and $n$ is the sample size. Next, we discuss how to find such a initial parameter privately. In the high dimensional sparse case where $d\\gg n$, we propose the DP-Truncated Rayleigh Flow method whose output could achieve an error of $\\tilde{O}(\\frac{s\\log d}{n}+\\frac{s\\log d}{n^2\\rho})$ for various statistical models, where $s$ is the sparsity of the underlying parameter.Moreover, we show that these errors in the stochastic setting are optimal up to a factor of $\\mathrm{Poly}(\\log n)$ by providing the lower bounds of PCA and SIR under statistical setting and in the CDP model. Finally, to give a separation between $\\epsilon$-DP and $\\rho$-CDP for GEP, we also provide the lower bound $\\Omega(\\frac{d}{n}+\\frac{d^2}{n^2\\epsilon^2})$ and $\\Omega(\\frac{s\\log d}{n}+\\frac{s^2\\log^2 d}{n^2\\epsilon^2})$ of private minimax risk for PCA, under the statistical setting and $\\epsilon$-DP model, in low and high dimensional sparse case respectively.",
        "bibtex": "@InProceedings{pmlr-v206-hu23a,\n  title = \t {Privacy-preserving Sparse Generalized Eigenvalue Problem},\n  author =       {Hu, Lijie and Xiang, Zihang and Liu, Jiabin and Wang, Di},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5052--5062},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hu23a/hu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hu23a.html},\n  abstract = \t {In this paper we study the (sparse) Generalized Eigenvalue Problem (GEP), which arises in a number of modern statistical learning models, such as principal component analysis (PCA), canonical correlation analysis (CCA), Fisher\u2019s discriminant analysis (FDA) and sliced inverse regression (SIR). We provide the first study on GEP in the differential privacy (DP) model under both deterministic and stochastic settings. In the low dimensional case, we provide a $\\rho$-Concentrated DP (CDP) method namely DP-Rayleigh Flow and show if the initial vector is close enough to the optimal vector, its output has an $\\ell_2$-norm estimation error of $\\tilde{O}(\\frac{d}{n}+\\frac{d}{n^2\\rho})$ (under some mild assumptions), where $d$ is the dimension and $n$ is the sample size. Next, we discuss how to find such a initial parameter privately. In the high dimensional sparse case where $d\\gg n$, we propose the DP-Truncated Rayleigh Flow method whose output could achieve an error of $\\tilde{O}(\\frac{s\\log d}{n}+\\frac{s\\log d}{n^2\\rho})$ for various statistical models, where $s$ is the sparsity of the underlying parameter.Moreover, we show that these errors in the stochastic setting are optimal up to a factor of $\\mathrm{Poly}(\\log n)$ by providing the lower bounds of PCA and SIR under statistical setting and in the CDP model. Finally, to give a separation between $\\epsilon$-DP and $\\rho$-CDP for GEP, we also provide the lower bound $\\Omega(\\frac{d}{n}+\\frac{d^2}{n^2\\epsilon^2})$ and $\\Omega(\\frac{s\\log d}{n}+\\frac{s^2\\log^2 d}{n^2\\epsilon^2})$ of private minimax risk for PCA, under the statistical setting and $\\epsilon$-DP model, in low and high dimensional sparse case respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hu23a/hu23a.pdf",
        "supp": "",
        "pdf_size": 482537,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=345147079375996503&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6f2d4c7d17",
        "title": "Private Non-Convex Federated Learning Without a Trusted Server",
        "site": "https://proceedings.mlr.press/v206/lowy23a.html",
        "author": "Andrew Lowy; Ali Ghafelebashi; Meisam Razaviyayn",
        "abstract": "We study federated learning (FL) with non-convex loss functions and data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) must protect the privacy of each person\u2019s medical record), even if the server or other silos act as adversarial eavesdroppers. To that end, we consider inter-silo record-level (ISRL) differential privacy (DP), which requires silo $i$\u2019s communications to satisfy record/item-level DP. We propose novel ISRL-DP algorithms for FL with heterogeneous (non-i.i.d.) silo data and two classes of Lipschitz continuous loss functions: First, we consider losses satisfying the Proximal Polyak-\\Lojasiewicz (PL) inequality, which is an extension of the classical PL condition to the constrained setting. In contrast to our result, prior works only considered unconstrained private optimization with Lipschitz PL loss, which rules out most interesting PL losses such as strongly convex problems and linear/logistic regression. Our algorithms nearly attain the optimal strongly convex, homogeneous (i.i.d.) rate for ISRL-DP FL without assuming convexity or i.i.d. data. Second, we give the first private algorithms for non-convex non-smooth loss functions. Our utility bounds even improve on the state-of-the-art bounds for smooth losses. We complement our upper bounds with lower bounds. Additionally, we provide shuffle DP (SDP) algorithms that improve over the state-of-the-art central DP algorithms under more practical trust assumptions. Numerical experiments show that our algorithm has better accuracy than baselines for most privacy levels.",
        "bibtex": "@InProceedings{pmlr-v206-lowy23a,\n  title = \t {Private Non-Convex Federated Learning Without a Trusted Server},\n  author =       {Lowy, Andrew and Ghafelebashi, Ali and Razaviyayn, Meisam},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5749--5786},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lowy23a/lowy23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lowy23a.html},\n  abstract = \t {We study federated learning (FL) with non-convex loss functions and data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) must protect the privacy of each person\u2019s medical record), even if the server or other silos act as adversarial eavesdroppers. To that end, we consider inter-silo record-level (ISRL) differential privacy (DP), which requires silo $i$\u2019s communications to satisfy record/item-level DP. We propose novel ISRL-DP algorithms for FL with heterogeneous (non-i.i.d.) silo data and two classes of Lipschitz continuous loss functions: First, we consider losses satisfying the Proximal Polyak-\\Lojasiewicz (PL) inequality, which is an extension of the classical PL condition to the constrained setting. In contrast to our result, prior works only considered unconstrained private optimization with Lipschitz PL loss, which rules out most interesting PL losses such as strongly convex problems and linear/logistic regression. Our algorithms nearly attain the optimal strongly convex, homogeneous (i.i.d.) rate for ISRL-DP FL without assuming convexity or i.i.d. data. Second, we give the first private algorithms for non-convex non-smooth loss functions. Our utility bounds even improve on the state-of-the-art bounds for smooth losses. We complement our upper bounds with lower bounds. Additionally, we provide shuffle DP (SDP) algorithms that improve over the state-of-the-art central DP algorithms under more practical trust assumptions. Numerical experiments show that our algorithm has better accuracy than baselines for most privacy levels.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lowy23a/lowy23a.pdf",
        "supp": "",
        "pdf_size": 3072782,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=906582638522956932&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e7953ebd7f",
        "title": "ProbNeRF: Uncertainty-Aware Inference of 3D Shapes from 2D Images",
        "site": "https://proceedings.mlr.press/v206/hoffman23a.html",
        "author": "Matthew D. Hoffman; Tuan Anh Le; Pavel Sountsov; Christopher Suter; Ben Lee; Vikash K. Mansinghka; Rif A. Saurous",
        "abstract": "The problem of inferring object shape from a single 2D image is underconstrained. Prior knowledge about what objects are plausible can help, but even given such prior knowledge there may still be uncertainty about the shapes of occluded parts of objects. Recently, conditional neural radiance field (NeRF) models have been developed that can learn to infer good point estimates of 3D models from single 2D images. The problem of inferring uncertainty estimates for these models has received less attention. In this work, we propose probabilistic NeRF (ProbNeRF), a model and inference strategy for learning probabilistic generative models of 3D objects\u2019 shapes and appearances, and for doing posterior inference to recover those properties from 2D images. ProbNeRF is trained as a variational autoencoder, but at test time we use Hamiltonian Monte Carlo (HMC) for inference. Given one or a few 2D images of an object (which may be partially occluded), ProbNeRF is able not only to accurately model the parts it sees, but also to propose realistic and diverse hypotheses about the parts it does not see. We show that key to the success of ProbNeRF are (i) a deterministic rendering scheme, (ii) an annealed-HMC strategy, (iii) a hypernetwork-based decoder architecture, and (iv) doing inference over a full set of NeRF weights, rather than just a low-dimensional code. Videos and code are available at https://probnerf.github.io.",
        "bibtex": "@InProceedings{pmlr-v206-hoffman23a,\n  title = \t {ProbNeRF: Uncertainty-Aware Inference of 3D Shapes from 2D Images},\n  author =       {Hoffman, Matthew D. and Le, Tuan Anh and Sountsov, Pavel and Suter, Christopher and Lee, Ben and Mansinghka, Vikash K. and Saurous, Rif A.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10425--10444},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hoffman23a/hoffman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hoffman23a.html},\n  abstract = \t {The problem of inferring object shape from a single 2D image is underconstrained. Prior knowledge about what objects are plausible can help, but even given such prior knowledge there may still be uncertainty about the shapes of occluded parts of objects. Recently, conditional neural radiance field (NeRF) models have been developed that can learn to infer good point estimates of 3D models from single 2D images. The problem of inferring uncertainty estimates for these models has received less attention. In this work, we propose probabilistic NeRF (ProbNeRF), a model and inference strategy for learning probabilistic generative models of 3D objects\u2019 shapes and appearances, and for doing posterior inference to recover those properties from 2D images. ProbNeRF is trained as a variational autoencoder, but at test time we use Hamiltonian Monte Carlo (HMC) for inference. Given one or a few 2D images of an object (which may be partially occluded), ProbNeRF is able not only to accurately model the parts it sees, but also to propose realistic and diverse hypotheses about the parts it does not see. We show that key to the success of ProbNeRF are (i) a deterministic rendering scheme, (ii) an annealed-HMC strategy, (iii) a hypernetwork-based decoder architecture, and (iv) doing inference over a full set of NeRF weights, rather than just a low-dimensional code. Videos and code are available at https://probnerf.github.io.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hoffman23a/hoffman23a.pdf",
        "supp": "",
        "pdf_size": 2572693,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8375664859171323877&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; Google Research; Google Research; Google Research; Google Research; MIT, Google Research; Google Research",
        "aff_domain": "; ; ; ; ; ; ",
        "email": "; ; ; ; ; ; ",
        "github": "",
        "project": "https://probnerf.github.io",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Google;Massachusetts Institute of Technology",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://web.mit.edu",
        "aff_unique_abbr": "Google Research;MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3c8e78e371",
        "title": "Probabilistic Conformal Prediction Using Conditional Random Samples",
        "site": "https://proceedings.mlr.press/v206/wang23n.html",
        "author": "Zhendong Wang; Ruijiang Gao; Mingzhang Yin; Mingyuan Zhou; David Blei",
        "abstract": "This paper proposes probabilistic conformal prediction (PCP), a predictive inference algorithm that estimates a target variable by a discontinuous predictive set. Given inputs, PCP constructs the predictive set based on random samples from an estimated generative model. It is efficient and compatible with conditional generative models with either explicit or implicit density functions. We show that PCP guarantees correct marginal coverage with finite samples and give empirical evidence of conditional coverage. We study PCP on a variety of simulated and real datasets. Compared to existing conformal prediction methods, PCP provides sharper predictive sets.",
        "bibtex": "@InProceedings{pmlr-v206-wang23n,\n  title = \t {Probabilistic Conformal Prediction Using Conditional Random Samples},\n  author =       {Wang, Zhendong and Gao, Ruijiang and Yin, Mingzhang and Zhou, Mingyuan and Blei, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8814--8836},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23n/wang23n.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23n.html},\n  abstract = \t {This paper proposes probabilistic conformal prediction (PCP), a predictive inference algorithm that estimates a target variable by a discontinuous predictive set. Given inputs, PCP constructs the predictive set based on random samples from an estimated generative model. It is efficient and compatible with conditional generative models with either explicit or implicit density functions. We show that PCP guarantees correct marginal coverage with finite samples and give empirical evidence of conditional coverage. We study PCP on a variety of simulated and real datasets. Compared to existing conformal prediction methods, PCP provides sharper predictive sets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23n/wang23n.pdf",
        "supp": "",
        "pdf_size": 34802189,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2502167176709410478&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "UT Austin, Department of Statistics and Data Sciences; UT Austin, McCombs School of Business; University of Florida, Warrington College of Business; UT Austin, McCombs School of Business; Columbia University, Department of Statistics and Computer Science",
        "aff_domain": "utexas.edu;utexas.edu;ufl.edu;mccombs.utexas.edu;columbia.edu",
        "email": "utexas.edu;utexas.edu;ufl.edu;mccombs.utexas.edu;columbia.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "University of Texas at Austin;University of Florida;Columbia University",
        "aff_unique_dep": "Department of Statistics and Data Sciences;Warrington College of Business;Department of Statistics and Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://www.ufl.edu;https://www.columbia.edu",
        "aff_unique_abbr": "UT Austin;UF;Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "67c25ac2c0",
        "title": "Probabilistic Querying of Continuous-Time Event Sequences",
        "site": "https://proceedings.mlr.press/v206/boyd23a.html",
        "author": "Alex Boyd; Yuxin Chang; Stephan Mandt; Padhraic Smyth",
        "abstract": "Continuous-time event sequences, i.e., sequences consisting of continuous time stamps and associated event types (\u201cmarks\u201d), are an important type of sequential data with many applications, e.g., in clinical medicine or user behavior modeling. Since these data are typically modeled in an autoregressive manner (e.g., using neural Hawkes processes or their classical counterparts), it is natural to ask questions about future scenarios such as \u201cwhat kind of event will occur next\u201d or \u201cwill an event of type $A$ occur before one of type $B$.\u201d Addressing such queries with direct methods such as naive simulation can be highly inefficient from a computational perspective. This paper introduces a new typology of query types and a framework for addressing them using importance sampling. Example queries include predicting the $n^\\mathrm{th}$ event type in a sequence and the hitting time distribution of one or more event types. We also leverage these findings further to be applicable for estimating general \u201c$A$ before $B$\u201d type of queries. We prove theoretically that our estimation method is effectively always better than naive simulation and demonstrate empirically based on three real-world datasets that our approach can produce orders of magnitude improvements in sampling efficiency compared to naive methods.",
        "bibtex": "@InProceedings{pmlr-v206-boyd23a,\n  title = \t {Probabilistic Querying of Continuous-Time Event Sequences},\n  author =       {Boyd, Alex and Chang, Yuxin and Mandt, Stephan and Smyth, Padhraic},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10235--10251},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/boyd23a/boyd23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/boyd23a.html},\n  abstract = \t {Continuous-time event sequences, i.e., sequences consisting of continuous time stamps and associated event types (\u201cmarks\u201d), are an important type of sequential data with many applications, e.g., in clinical medicine or user behavior modeling. Since these data are typically modeled in an autoregressive manner (e.g., using neural Hawkes processes or their classical counterparts), it is natural to ask questions about future scenarios such as \u201cwhat kind of event will occur next\u201d or \u201cwill an event of type $A$ occur before one of type $B$.\u201d Addressing such queries with direct methods such as naive simulation can be highly inefficient from a computational perspective. This paper introduces a new typology of query types and a framework for addressing them using importance sampling. Example queries include predicting the $n^\\mathrm{th}$ event type in a sequence and the hitting time distribution of one or more event types. We also leverage these findings further to be applicable for estimating general \u201c$A$ before $B$\u201d type of queries. We prove theoretically that our estimation method is effectively always better than naive simulation and demonstrate empirically based on three real-world datasets that our approach can produce orders of magnitude improvements in sampling efficiency compared to naive methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/boyd23a/boyd23a.pdf",
        "supp": "",
        "pdf_size": 810971,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9981010858629056839&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f3ff5acdc9",
        "title": "Probabilities of Causation: Role of Observational Data",
        "site": "https://proceedings.mlr.press/v206/li23d.html",
        "author": "Ang Li; Judea Pearl",
        "abstract": "Probabilities of causation play a crucial role in modern decision-making. Pearl defined three binary probabilities of causation, the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN). These probabilities were then bounded by Tian and Pearl using a combination of experimental and observational data. However, observational data are not always available in practice; in such a case, Tian and Pearl\u2019s Theorem provided valid but less effective bounds using pure experimental data. In this paper, we discuss the conditions that observational data are worth considering to improve the quality of the bounds. More specifically, we defined the expected improvement of the bounds by assuming the observational distributions are uniformly distributed on their feasible interval. We further applied the proposed theorems to the unit selection problem defined by Li and Pearl.",
        "bibtex": "@InProceedings{pmlr-v206-li23d,\n  title = \t {Probabilities of Causation: Role of Observational Data},\n  author =       {Li, Ang and Pearl, Judea},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10012--10027},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/li23d/li23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/li23d.html},\n  abstract = \t {Probabilities of causation play a crucial role in modern decision-making. Pearl defined three binary probabilities of causation, the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN). These probabilities were then bounded by Tian and Pearl using a combination of experimental and observational data. However, observational data are not always available in practice; in such a case, Tian and Pearl\u2019s Theorem provided valid but less effective bounds using pure experimental data. In this paper, we discuss the conditions that observational data are worth considering to improve the quality of the bounds. More specifically, we defined the expected improvement of the bounds by assuming the observational distributions are uniformly distributed on their feasible interval. We further applied the proposed theorems to the unit selection problem defined by Li and Pearl.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/li23d/li23d.pdf",
        "supp": "",
        "pdf_size": 436698,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6597419494549142905&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Cognitive Systems Laboratory, Department of Computer Science, University of California Los Angeles; Cognitive Systems Laboratory, Department of Computer Science, University of California Los Angeles",
        "aff_domain": "cs.ucla.edu;cs.ucla.edu",
        "email": "cs.ucla.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c307ff055a",
        "title": "Probing Graph Representations",
        "site": "https://proceedings.mlr.press/v206/akhondzadeh23a.html",
        "author": "Mohammad Sadegh Akhondzadeh; Vijay Lingam; Aleksandar Bojchevski",
        "abstract": "Today we have a good theoretical understanding of the representational power of Graph Neural Networks (GNNs). For example, their limitations have been characterized in relation to a hierarchy of Weisfeiler-Lehman (WL) isomorphism tests. However, we do not know what is encoded in the learned representations. This is our main question. We answer it using a probing framework to quantify the amount of meaningful information captured in graph representations. Our findings on molecular datasets show the potential of probing for understanding the inductive biases of graph-based models. We compare different families of models, and show that Graph Transformers capture more chemically relevant information compared to models based on message passing. We also study the effect of different design choices such as skip connections and virtual nodes. We advocate for probing as a useful diagnostic tool for evaluating and developing graph-based models.",
        "bibtex": "@InProceedings{pmlr-v206-akhondzadeh23a,\n  title = \t {Probing Graph Representations},\n  author =       {Akhondzadeh, Mohammad Sadegh and Lingam, Vijay and Bojchevski, Aleksandar},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11630--11649},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/akhondzadeh23a/akhondzadeh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/akhondzadeh23a.html},\n  abstract = \t {Today we have a good theoretical understanding of the representational power of Graph Neural Networks (GNNs). For example, their limitations have been characterized in relation to a hierarchy of Weisfeiler-Lehman (WL) isomorphism tests. However, we do not know what is encoded in the learned representations. This is our main question. We answer it using a probing framework to quantify the amount of meaningful information captured in graph representations. Our findings on molecular datasets show the potential of probing for understanding the inductive biases of graph-based models. We compare different families of models, and show that Graph Transformers capture more chemically relevant information compared to models based on message passing. We also study the effect of different design choices such as skip connections and virtual nodes. We advocate for probing as a useful diagnostic tool for evaluating and developing graph-based models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/akhondzadeh23a/akhondzadeh23a.pdf",
        "supp": "",
        "pdf_size": 5147772,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10068183256307666942&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "928fb7440f",
        "title": "Protecting Global Properties of Datasets with Distribution Privacy Mechanisms",
        "site": "https://proceedings.mlr.press/v206/chen23f.html",
        "author": "Michelle Chen; Olga Ohrimenko",
        "abstract": "We consider the problem of ensuring confidentiality of dataset properties aggregated over many records of a dataset. Such properties can encode sensitive information, such as trade secrets or demographic data, while involving a notion of data protection different to the privacy of individual records typically discussed in the literature. In this work, we demonstrate how a distribution privacy framework can be applied to formalize such data confidentiality. We extend the Wasserstein Mechanism from Pufferfish privacy and the Gaussian Mechanism from attribute privacy to this framework, then analyze their underlying data assumptions and how they can be relaxed. We then empirically evaluate the privacy-utility tradeoffs of these mechanisms and apply them against a practical property inference attack which targets global properties of datasets. The results show that our mechanisms can indeed reduce the effectiveness of the attack while providing utility substantially greater than a crude group differential privacy baseline. Our work thus provides groundwork for theoretical mechanisms for protecting global properties of datasets along with their evaluation in practice.",
        "bibtex": "@InProceedings{pmlr-v206-chen23f,\n  title = \t {Protecting Global Properties of Datasets with Distribution Privacy Mechanisms},\n  author =       {Chen, Michelle and Ohrimenko, Olga},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7472--7491},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23f/chen23f.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23f.html},\n  abstract = \t {We consider the problem of ensuring confidentiality of dataset properties aggregated over many records of a dataset. Such properties can encode sensitive information, such as trade secrets or demographic data, while involving a notion of data protection different to the privacy of individual records typically discussed in the literature. In this work, we demonstrate how a distribution privacy framework can be applied to formalize such data confidentiality. We extend the Wasserstein Mechanism from Pufferfish privacy and the Gaussian Mechanism from attribute privacy to this framework, then analyze their underlying data assumptions and how they can be relaxed. We then empirically evaluate the privacy-utility tradeoffs of these mechanisms and apply them against a practical property inference attack which targets global properties of datasets. The results show that our mechanisms can indeed reduce the effectiveness of the attack while providing utility substantially greater than a crude group differential privacy baseline. Our work thus provides groundwork for theoretical mechanisms for protecting global properties of datasets along with their evaluation in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23f/chen23f.pdf",
        "supp": "",
        "pdf_size": 490152,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9939585028700509783&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "The University of Melbourne; The University of Melbourne",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Melbourne",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unimelb.edu.au",
        "aff_unique_abbr": "UniMelb",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "b9445f50a8",
        "title": "Provable Hierarchy-Based Meta-Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/chua23a.html",
        "author": "Kurtland Chua; Qi Lei; Jason Lee",
        "abstract": "Hierarchical reinforcement learning (HRL) has seen widespread interest as an approach to tractable learning of complex modular behaviors. However, existing works either assume access to expert-constructed hierarchies, or use hierarchy-learning heuristics with no provable guarantees. To address this gap, we analyze HRL in the meta-RL setting, where a learner learns latent hierarchical structure during meta-training for use in a downstream task. We consider a tabular setting where natural hierarchical structure is embedded in the transition dynamics. Analogous to supervised meta-learning theory, we provide diversity conditions which, together with a tractable optimism-based algorithm, guarantee sample-efficient recovery of this natural hierarchy. Furthermore, we provide regret bounds on a learner using the recovered hierarchy to solve a meta-test task. Our bounds incorporate common notions in HRL literature such as temporal and state/action abstractions, suggesting that our setting and analysis capture important features of HRL in practice.",
        "bibtex": "@InProceedings{pmlr-v206-chua23a,\n  title = \t {Provable Hierarchy-Based Meta-Reinforcement Learning},\n  author =       {Chua, Kurtland and Lei, Qi and Lee, Jason},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10918--10967},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chua23a/chua23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chua23a.html},\n  abstract = \t {Hierarchical reinforcement learning (HRL) has seen widespread interest as an approach to tractable learning of complex modular behaviors. However, existing works either assume access to expert-constructed hierarchies, or use hierarchy-learning heuristics with no provable guarantees. To address this gap, we analyze HRL in the meta-RL setting, where a learner learns latent hierarchical structure during meta-training for use in a downstream task. We consider a tabular setting where natural hierarchical structure is embedded in the transition dynamics. Analogous to supervised meta-learning theory, we provide diversity conditions which, together with a tractable optimism-based algorithm, guarantee sample-efficient recovery of this natural hierarchy. Furthermore, we provide regret bounds on a learner using the recovered hierarchy to solve a meta-test task. Our bounds incorporate common notions in HRL literature such as temporal and state/action abstractions, suggesting that our setting and analysis capture important features of HRL in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chua23a/chua23a.pdf",
        "supp": "",
        "pdf_size": 792589,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13675452442671340777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "020ab75d20",
        "title": "Provable Safe Reinforcement Learning with Binary Feedback",
        "site": "https://proceedings.mlr.press/v206/bennett23a.html",
        "author": "Andrew Bennett; Dipendra Misra; Nathan Kallus",
        "abstract": "Safety is a crucial necessity in many applications of reinforcement learning (RL), whether robotic, automotive, or medical. Many existing approaches to safe RL rely on receiving numeric safety feedback, but in many cases this feedback can only take binary values; that is, whether an action in a given state is safe or unsafe. This is particularly true when feedback comes from human experts. We therefore consider the problem of provable safe RL when given access to an offline oracle providing binary feedback on the safety of state, action pairs. We provide a novel meta algorithm, SABRE, which can be applied to any MDP setting given access to a blackbox PAC RL algorithm for that setting. SABRE applies concepts from active learning to reinforcement learning to provably control the number of queries to the safety oracle. SABRE works by iteratively exploring the state space to find regions where the agent is currently uncertain about safety. Our main theoretical results shows that, under appropriate technical assumptions, SABRE never takes unsafe actions during training, and is guaranteed to return a near-optimal safe policy with high probability. We provide a discussion of how our meta-algorithm may be applied to various settings studied in both theoretical and empirical frameworks.",
        "bibtex": "@InProceedings{pmlr-v206-bennett23a,\n  title = \t {Provable Safe Reinforcement Learning with Binary Feedback},\n  author =       {Bennett, Andrew and Misra, Dipendra and Kallus, Nathan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10871--10900},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bennett23a/bennett23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bennett23a.html},\n  abstract = \t {Safety is a crucial necessity in many applications of reinforcement learning (RL), whether robotic, automotive, or medical. Many existing approaches to safe RL rely on receiving numeric safety feedback, but in many cases this feedback can only take binary values; that is, whether an action in a given state is safe or unsafe. This is particularly true when feedback comes from human experts. We therefore consider the problem of provable safe RL when given access to an offline oracle providing binary feedback on the safety of state, action pairs. We provide a novel meta algorithm, SABRE, which can be applied to any MDP setting given access to a blackbox PAC RL algorithm for that setting. SABRE applies concepts from active learning to reinforcement learning to provably control the number of queries to the safety oracle. SABRE works by iteratively exploring the state space to find regions where the agent is currently uncertain about safety. Our main theoretical results shows that, under appropriate technical assumptions, SABRE never takes unsafe actions during training, and is guaranteed to return a near-optimal safe policy with high probability. We provide a discussion of how our meta-algorithm may be applied to various settings studied in both theoretical and empirical frameworks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bennett23a/bennett23a.pdf",
        "supp": "",
        "pdf_size": 1480128,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13260861519024676070&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c57e4b1bf1",
        "title": "Provably Efficient Model-Free Algorithms for Non-stationary CMDPs",
        "site": "https://proceedings.mlr.press/v206/wei23b.html",
        "author": "Honghao Wei; Arnob Ghosh; Ness Shroff; Lei Ying; Xingyu Zhou",
        "abstract": "We study model-free reinforcement learning (RL) algorithms in episodic non-stationary constrained Markov decision processes (CMDPs), in which an agent aims to maximize the expected cumulative reward subject to a cumulative constraint on the expected utility (cost). In the non-stationary environment, the reward, utility functions, and the transition kernels can vary arbitrarily over time as long as the cumulative variations do not exceed certain variation budgets. We propose the first model-free, simulator-free RL algorithms with sublinear regret and zero constraint violation for non-stationary CMDPs in both tabular and linear function approximation settings with provable performance guarantees. Our results on regret bound and constraint violation for the tabular case match the corresponding best results for stationary CMDPs when the total budget is known. Additionally, we present a general framework for addressing with the well-known challenges associated with analyzing non-stationary CMDPs, without requiring prior knowledge of the variation budget. We apply the approach for both tabular and linear approximation settings.",
        "bibtex": "@InProceedings{pmlr-v206-wei23b,\n  title = \t {Provably Efficient Model-Free Algorithms for Non-stationary CMDPs},\n  author =       {Wei, Honghao and Ghosh, Arnob and Shroff, Ness and Ying, Lei and Zhou, Xingyu},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6527--6570},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wei23b/wei23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wei23b.html},\n  abstract = \t {We study model-free reinforcement learning (RL) algorithms in episodic non-stationary constrained Markov decision processes (CMDPs), in which an agent aims to maximize the expected cumulative reward subject to a cumulative constraint on the expected utility (cost). In the non-stationary environment, the reward, utility functions, and the transition kernels can vary arbitrarily over time as long as the cumulative variations do not exceed certain variation budgets. We propose the first model-free, simulator-free RL algorithms with sublinear regret and zero constraint violation for non-stationary CMDPs in both tabular and linear function approximation settings with provable performance guarantees. Our results on regret bound and constraint violation for the tabular case match the corresponding best results for stationary CMDPs when the total budget is known. Additionally, we present a general framework for addressing with the well-known challenges associated with analyzing non-stationary CMDPs, without requiring prior knowledge of the variation budget. We apply the approach for both tabular and linear approximation settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wei23b/wei23b.pdf",
        "supp": "",
        "pdf_size": 702503,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15402539611592704183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Michigan; The Ohio State University; The Ohio State University; University of Michigan; Wayne State University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "University of Michigan;Ohio State University;Wayne State University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.umich.edu;https://www.osu.edu;https://wayne.edu",
        "aff_unique_abbr": "UM;OSU;WSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8316395494",
        "title": "Provably Efficient Reinforcement Learning via Surprise Bound",
        "site": "https://proceedings.mlr.press/v206/zhu23c.html",
        "author": "Hanlin Zhu; Ruosong Wang; Jason Lee",
        "abstract": "Value function approximation is important in modern reinforcement learning (RL) problems especially when the state space is (infinitely) large. Despite the importance and wide applicability of value function approximation, its theoretical understanding is still not as sophisticated as its empirical success, especially in the context of general function approximation. In this paper, we propose a provably efficient RL algorithm (both computationally and statistically) with general value function approximations. We show that if the value functions can be approximated by a function class $\\mathcal{F}$ which satisfies the bellman-completeness assumption, our algorithm achieves an $\\widetilde{O}(\\mathrm{poly}(\\iota H)\\sqrt{T})$ regret bound where $\\iota$ is the product of the surprise bound and log-covering numbers, $H$ is the planning horizon, $K$ is the number of episodes and $T = HK$ is the total number of steps the agent interacts with the environment. Our algorithm achieves reasonable regret bounds when applied to both the linear setting and the sparse high-dimensional linear setting. Moreover, our algorithm only needs to solve $O(H\\log K)$ empirical risk minimization (ERM) problems, which is far more efficient than previous algorithms that need to solve ERM problems for $\\Omega(HK)$ times.",
        "bibtex": "@InProceedings{pmlr-v206-zhu23c,\n  title = \t {Provably Efficient Reinforcement Learning via Surprise Bound},\n  author =       {Zhu, Hanlin and Wang, Ruosong and Lee, Jason},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4006--4032},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhu23c/zhu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhu23c.html},\n  abstract = \t {Value function approximation is important in modern reinforcement learning (RL) problems especially when the state space is (infinitely) large. Despite the importance and wide applicability of value function approximation, its theoretical understanding is still not as sophisticated as its empirical success, especially in the context of general function approximation. In this paper, we propose a provably efficient RL algorithm (both computationally and statistically) with general value function approximations. We show that if the value functions can be approximated by a function class $\\mathcal{F}$ which satisfies the bellman-completeness assumption, our algorithm achieves an $\\widetilde{O}(\\mathrm{poly}(\\iota H)\\sqrt{T})$ regret bound where $\\iota$ is the product of the surprise bound and log-covering numbers, $H$ is the planning horizon, $K$ is the number of episodes and $T = HK$ is the total number of steps the agent interacts with the environment. Our algorithm achieves reasonable regret bounds when applied to both the linear setting and the sparse high-dimensional linear setting. Moreover, our algorithm only needs to solve $O(H\\log K)$ empirical risk minimization (ERM) problems, which is far more efficient than previous algorithms that need to solve ERM problems for $\\Omega(HK)$ times.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhu23c/zhu23c.pdf",
        "supp": "",
        "pdf_size": 383465,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5963644856755909169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Electrical Engineering and Computer Sciences, UC Berkeley; Paul G. Allen School of Computer Science & Engineering, University of Washington; Electrical and Computer Engineering, Princeton University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of California, Berkeley;University of Washington;Princeton University",
        "aff_unique_dep": "Electrical Engineering and Computer Sciences;Paul G. Allen School of Computer Science & Engineering;Electrical and Computer Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.washington.edu;https://www.princeton.edu",
        "aff_unique_abbr": "UC Berkeley;UW;Princeton",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Berkeley;Seattle;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5c367b885b",
        "title": "Random Features Model with General Convex Regularization: A Fine Grained Analysis with Precise Asymptotic Learning Curves",
        "site": "https://proceedings.mlr.press/v206/bosch23a.html",
        "author": "David Bosch; Ashkan Panahi; Ayca Ozcelikkale; Devdatt Dubhashi",
        "abstract": "We compute precise asymptotic expressions for the learning curves of least squares random feature (RF) models with either a separable strongly convex regularization or the $\\ell_1$ regularization. We propose a novel multi-level application of the convex Gaussian min max theorem (CGMT) to overcome the traditional difficulty of finding computable expressions for random features models with correlated data. Our result takes the form of a computable 4-dimensional scalar optimization. In contrast to previous results, our approach does not require solving an often intractable proximal operator, which scales with the number of model parameters. Furthermore, we extend the universality results for the training and generalization errors for RF models to $\\ell_1$ regularization. In particular, we demonstrate that under mild conditions, random feature models with elastic net or $\\ell_1$ regularization are asymptotically equivalent to a surrogate Gaussian model with the same first and second moments. We numerically demonstrate the predictive capacity of our results, and show experimentally that the predicted test error is accurate even in the non-asymptotic regime.",
        "bibtex": "@InProceedings{pmlr-v206-bosch23a,\n  title = \t {Random Features Model with General Convex Regularization: A Fine Grained Analysis with Precise Asymptotic Learning Curves},\n  author =       {Bosch, David and Panahi, Ashkan and Ozcelikkale, Ayca and Dubhashi, Devdatt},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11371--11414},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bosch23a/bosch23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bosch23a.html},\n  abstract = \t {We compute precise asymptotic expressions for the learning curves of least squares random feature (RF) models with either a separable strongly convex regularization or the $\\ell_1$ regularization. We propose a novel multi-level application of the convex Gaussian min max theorem (CGMT) to overcome the traditional difficulty of finding computable expressions for random features models with correlated data. Our result takes the form of a computable 4-dimensional scalar optimization. In contrast to previous results, our approach does not require solving an often intractable proximal operator, which scales with the number of model parameters. Furthermore, we extend the universality results for the training and generalization errors for RF models to $\\ell_1$ regularization. In particular, we demonstrate that under mild conditions, random feature models with elastic net or $\\ell_1$ regularization are asymptotically equivalent to a surrogate Gaussian model with the same first and second moments. We numerically demonstrate the predictive capacity of our results, and show experimentally that the predicted test error is accurate even in the non-asymptotic regime.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bosch23a/bosch23a.pdf",
        "supp": "",
        "pdf_size": 695754,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13444390520276198056&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b00958df87",
        "title": "Randomized Greedy Learning for Non-monotone Stochastic Submodular Maximization Under Full-bandit Feedback",
        "site": "https://proceedings.mlr.press/v206/fourati23a.html",
        "author": "Fares Fourati; Vaneet Aggarwal; Christopher Quinn; Mohamed-Slim Alouini",
        "abstract": "We investigate the problem of unconstrained combinatorial multi-armed bandits with full-bandit feedback and stochastic rewards for submodular maximization. Previous works investigate the same problem assuming a submodular and monotone reward function. In this work, we study a more general problem, i.e., when the reward function is not necessarily monotone, and the submodularity is assumed only in expectation. We propose Randomized Greedy Learning (RGL) algorithm and theoretically prove that it achieves a $\\frac{1}{2}$-regret upper bound of $\\tilde{\\mathcal{O}}(n T^{\\frac{2}{3}})$ for horizon $T$ and number of arms $n$. We also show in experiments that RGL empirically outperforms other full-bandit variants in submodular and non-submodular settings.",
        "bibtex": "@InProceedings{pmlr-v206-fourati23a,\n  title = \t {Randomized Greedy Learning for Non-monotone Stochastic Submodular Maximization Under Full-bandit Feedback},\n  author =       {Fourati, Fares and Aggarwal, Vaneet and Quinn, Christopher and Alouini, Mohamed-Slim},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7455--7471},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/fourati23a/fourati23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/fourati23a.html},\n  abstract = \t {We investigate the problem of unconstrained combinatorial multi-armed bandits with full-bandit feedback and stochastic rewards for submodular maximization. Previous works investigate the same problem assuming a submodular and monotone reward function. In this work, we study a more general problem, i.e., when the reward function is not necessarily monotone, and the submodularity is assumed only in expectation. We propose Randomized Greedy Learning (RGL) algorithm and theoretically prove that it achieves a $\\frac{1}{2}$-regret upper bound of $\\tilde{\\mathcal{O}}(n T^{\\frac{2}{3}})$ for horizon $T$ and number of arms $n$. We also show in experiments that RGL empirically outperforms other full-bandit variants in submodular and non-submodular settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/fourati23a/fourati23a.pdf",
        "supp": "",
        "pdf_size": 789549,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2805603828470676955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "KAUST; Purdue University + KAUST; Iowa State University; KAUST",
        "aff_domain": "kaust.edu.sa;kaust.edu.sa;iastate.edu;kaust.edu.sa",
        "email": "kaust.edu.sa;kaust.edu.sa;iastate.edu;kaust.edu.sa",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;2;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology;Purdue University;Iowa State University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.kaust.edu.sa;https://www.purdue.edu;https://www.iastate.edu",
        "aff_unique_abbr": "KAUST;Purdue;ISU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;1;0",
        "aff_country_unique": "Saudi Arabia;United States"
    },
    {
        "id": "1105711894",
        "title": "Randomized Primal-Dual Methods with Adaptive Step Sizes",
        "site": "https://proceedings.mlr.press/v206/yazdandoost-hamedani23a.html",
        "author": "Erfan Yazdandoost Hamedani; Afrooz Jalilzadeh; Necdet S. Aybat",
        "abstract": "In this paper we propose a class of randomized primal-dual methods incorporating line search to contend with large-scale saddle point (SP) problems defined by a convex-concave function $\\mathcal L(\\mathbf{x},y) = \\sum_{i=1}^M f_i(x_i)+\\Phi(\\mathbf{x},y)-h(y)$. We analyze the convergence rate of the proposed method under mere convexity and strong convexity assumptions of $\\mathcal L$ in $\\mathbf{x}$-variable. In particular, assuming $\\nabla_y\\Phi(\\cdot,\\cdot)$ is Lipschitz and $\\nabla_{\\mathbf{x}}\\Phi(\\cdot,y)$ is coordinate-wise Lipschitz for any fixed $y$, the ergodic sequence generated by the algorithm achieves the $\\mathcal O(M/k)$ convergence rate in the expected primal-dual gap. Furthermore, assuming that $\\mathcal L(\\cdot,y)$ is strongly convex for any $y$, and that $\\Phi(\\mathbf{x},\\cdot)$ is affine for any $\\mathbf{x}$, the scheme enjoys a faster rate of $\\mathcal O(M/k^2)$ in terms of primal solution suboptimality. We implemented the proposed algorithmic framework to solve kernel matrix learning problem, and tested it against other state-of-the-art first-order methods.",
        "bibtex": "@InProceedings{pmlr-v206-yazdandoost-hamedani23a,\n  title = \t {Randomized Primal-Dual Methods with Adaptive Step Sizes},\n  author =       {Yazdandoost Hamedani, Erfan and Jalilzadeh, Afrooz and Aybat, Necdet S.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11185--11212},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yazdandoost-hamedani23a/yazdandoost-hamedani23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yazdandoost-hamedani23a.html},\n  abstract = \t {In this paper we propose a class of randomized primal-dual methods incorporating line search to contend with large-scale saddle point (SP) problems defined by a convex-concave function $\\mathcal L(\\mathbf{x},y) = \\sum_{i=1}^M f_i(x_i)+\\Phi(\\mathbf{x},y)-h(y)$. We analyze the convergence rate of the proposed method under mere convexity and strong convexity assumptions of $\\mathcal L$ in $\\mathbf{x}$-variable. In particular, assuming $\\nabla_y\\Phi(\\cdot,\\cdot)$ is Lipschitz and $\\nabla_{\\mathbf{x}}\\Phi(\\cdot,y)$ is coordinate-wise Lipschitz for any fixed $y$, the ergodic sequence generated by the algorithm achieves the $\\mathcal O(M/k)$ convergence rate in the expected primal-dual gap. Furthermore, assuming that $\\mathcal L(\\cdot,y)$ is strongly convex for any $y$, and that $\\Phi(\\mathbf{x},\\cdot)$ is affine for any $\\mathbf{x}$, the scheme enjoys a faster rate of $\\mathcal O(M/k^2)$ in terms of primal solution suboptimality. We implemented the proposed algorithmic framework to solve kernel matrix learning problem, and tested it against other state-of-the-art first-order methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yazdandoost-hamedani23a/yazdandoost-hamedani23a.pdf",
        "supp": "",
        "pdf_size": 955421,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9910722547240263897&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "The University of Arizona; The University of Arizona; The Pennsylvania State University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Arizona;Pennsylvania State University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.arizona.edu;https://www.psu.edu",
        "aff_unique_abbr": "UA;PSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "81a309c651",
        "title": "Randomized geometric tools for anomaly detection in stock markets",
        "site": "https://proceedings.mlr.press/v206/bachelard23a.html",
        "author": "Cyril Bachelard; Apostolos Chalkis; Vissarion Fisikopoulos; Elias Tsigaridas",
        "abstract": "We propose novel randomized geometric tools to detect low-volatility anomalies in stock markets; a principal problem in financial economics. Our modeling of the (detection) problem results in sampling and estimating the (relative) volume of geodesically non-convex and non-connected spherical patches that arise by intersecting a non-standard simplex with a sphere. To sample, we introduce two novel Markov Chain Monte Carlo (MCMC) algorithms that exploit the geometry of the problem and employ state-of-the-art continuous geometric random walks (such as Billiard walk and Hit-and-Run) adapted on spherical patches. To our knowledge, this is the first geometric formulation and MCMC-based analysis of the volatility puzzle in stock markets. We have implemented our algorithms in C++ (along with an R interface) and we illustrate the power of our approach by performing extensive experiments on real data. Our analyses provide accurate detection and new insights into the distribution of portfolios\u2019 performance characteristics. Moreover, we use our tools to show that classical methods for low-volatility anomaly detection in finance form bad proxies that could lead to misleading or inaccurate results.",
        "bibtex": "@InProceedings{pmlr-v206-bachelard23a,\n  title = \t {Randomized geometric tools for anomaly detection in stock markets},\n  author =       {Bachelard, Cyril and Chalkis, Apostolos and Fisikopoulos, Vissarion and Tsigaridas, Elias},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9400--9416},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bachelard23a/bachelard23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bachelard23a.html},\n  abstract = \t {We propose novel randomized geometric tools to detect low-volatility anomalies in stock markets; a principal problem in financial economics. Our modeling of the (detection) problem results in sampling and estimating the (relative) volume of geodesically non-convex and non-connected spherical patches that arise by intersecting a non-standard simplex with a sphere. To sample, we introduce two novel Markov Chain Monte Carlo (MCMC) algorithms that exploit the geometry of the problem and employ state-of-the-art continuous geometric random walks (such as Billiard walk and Hit-and-Run) adapted on spherical patches. To our knowledge, this is the first geometric formulation and MCMC-based analysis of the volatility puzzle in stock markets. We have implemented our algorithms in C++ (along with an R interface) and we illustrate the power of our approach by performing extensive experiments on real data. Our analyses provide accurate detection and new insights into the distribution of portfolios\u2019 performance characteristics. Moreover, we use our tools to show that classical methods for low-volatility anomaly detection in finance form bad proxies that could lead to misleading or inaccurate results.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bachelard23a/bachelard23a.pdf",
        "supp": "",
        "pdf_size": 775224,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4198683917406964984&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0708d19d52",
        "title": "Rank-Based Causal Discovery for Post-Nonlinear Models",
        "site": "https://proceedings.mlr.press/v206/keropyan23a.html",
        "author": "Grigor Keropyan; David Strieder; Mathias Drton",
        "abstract": "Learning causal relationships from empirical observations is a central task in scientific research. A common method is to employ structural causal models that postulate noisy functional relations among a set of interacting variables. To ensure unique identifiability of causal directions, researchers consider restricted subclasses of structural causal models. Post-nonlinear (PNL) causal models constitute one of the most flexible options for such restricted subclasses, containing in particular the popular additive noise models as a further subclass. However, learning PNL models is not well studied beyond the bivariate case. The existing methods learn non-linear functional relations by minimizing residual dependencies and subsequently test independence from residuals to determine causal orientations. However, these methods can be prone to overfitting and, thus, difficult to tune appropriately in practice. As an alternative, we propose a new approach for PNL causal discovery that uses rank-based methods to estimate the functional parameters. This new approach exploits natural invariances of PNL models and disentangles the estimation of the non-linear functions from the independence tests used to find causal orientations. We prove consistency of our method and validate our results in numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v206-keropyan23a,\n  title = \t {Rank-Based Causal Discovery for Post-Nonlinear Models},\n  author =       {Keropyan, Grigor and Strieder, David and Drton, Mathias},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7849--7870},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/keropyan23a/keropyan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/keropyan23a.html},\n  abstract = \t {Learning causal relationships from empirical observations is a central task in scientific research. A common method is to employ structural causal models that postulate noisy functional relations among a set of interacting variables. To ensure unique identifiability of causal directions, researchers consider restricted subclasses of structural causal models. Post-nonlinear (PNL) causal models constitute one of the most flexible options for such restricted subclasses, containing in particular the popular additive noise models as a further subclass. However, learning PNL models is not well studied beyond the bivariate case. The existing methods learn non-linear functional relations by minimizing residual dependencies and subsequently test independence from residuals to determine causal orientations. However, these methods can be prone to overfitting and, thus, difficult to tune appropriately in practice. As an alternative, we propose a new approach for PNL causal discovery that uses rank-based methods to estimate the functional parameters. This new approach exploits natural invariances of PNL models and disentangles the estimation of the non-linear functions from the independence tests used to find causal orientations. We prove consistency of our method and validate our results in numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/keropyan23a/keropyan23a.pdf",
        "supp": "",
        "pdf_size": 638438,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11097375114014705187&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Technical University of Munich; Technical University of Munich; Technical University of Munich + Munich Center for Machine Learning",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Technical University of Munich;Munich Center for Machine Learning",
        "aff_unique_dep": ";Center for Machine Learning",
        "aff_unique_url": "https://www.tum.de;https://www.munich-center-for-machine-learning.de",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "67fc9a2a4d",
        "title": "Reconstructing Training Data from Model Gradient, Provably",
        "site": "https://proceedings.mlr.press/v206/wang23g.html",
        "author": "Zihan Wang; Jason Lee; Qi Lei",
        "abstract": "Understanding when and how much a model gradient leaks information about the training sample is an important question in privacy. In this paper, we present a surprising result: Even without training or memorizing the data, we can fully reconstruct the training samples from a single gradient query at a randomly chosen parameter value. We prove the identifiability of the training data under mild assumptions: with shallow or deep neural networks and wide range of activation functions. We also present a statistically and computationally efficient algorithm based on tensor decomposition to reconstruct the training data. As a provable attack that reveals sensitive training data, our findings suggest potential  severe threats to privacy, especially in federated learning.",
        "bibtex": "@InProceedings{pmlr-v206-wang23g,\n  title = \t {Reconstructing Training Data from Model Gradient, Provably},\n  author =       {Wang, Zihan and Lee, Jason and Lei, Qi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6595--6612},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23g/wang23g.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23g.html},\n  abstract = \t {Understanding when and how much a model gradient leaks information about the training sample is an important question in privacy. In this paper, we present a surprising result: Even without training or memorizing the data, we can fully reconstruct the training samples from a single gradient query at a randomly chosen parameter value. We prove the identifiability of the training data under mild assumptions: with shallow or deep neural networks and wide range of activation functions. We also present a statistically and computationally efficient algorithm based on tensor decomposition to reconstruct the training data. As a provable attack that reveals sensitive training data, our findings suggest potential  severe threats to privacy, especially in federated learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23g/wang23g.pdf",
        "supp": "",
        "pdf_size": 538294,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8060246276030587158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b9e6203372",
        "title": "Recurrent Neural Networks and Universal Approximation of Bayesian Filters",
        "site": "https://proceedings.mlr.press/v206/bishop23a.html",
        "author": "Adrian N. Bishop; Edwin V. Bonilla",
        "abstract": "We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results.",
        "bibtex": "@InProceedings{pmlr-v206-bishop23a,\n  title = \t {Recurrent Neural Networks and Universal Approximation of Bayesian Filters},\n  author =       {Bishop, Adrian N. and Bonilla, Edwin V.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6956--6967},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bishop23a/bishop23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bishop23a.html},\n  abstract = \t {We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bishop23a/bishop23a.pdf",
        "supp": "",
        "pdf_size": 526113,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8030785979323839692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Technology Sydney, and CSIRO; CSIRO\u2019s Data61",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Technology Sydney;CSIRO",
        "aff_unique_dep": ";Data61",
        "aff_unique_url": "https://www.uts.edu.au;https://www.csiro.au",
        "aff_unique_abbr": "UTS;CSIRO",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "4651def10c",
        "title": "Reducing Discretization Error in the Frank-Wolfe Method",
        "site": "https://proceedings.mlr.press/v206/chen23g.html",
        "author": "Zhaoyue Chen; Yifan Sun",
        "abstract": "The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. We view this as an artifact of discretization; that is to say, the Frank-Wolfe flow, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.",
        "bibtex": "@InProceedings{pmlr-v206-chen23g,\n  title = \t {Reducing Discretization Error in the Frank-Wolfe Method},\n  author =       {Chen, Zhaoyue and Sun, Yifan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9697--9727},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23g/chen23g.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23g.html},\n  abstract = \t {The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. We view this as an artifact of discretization; that is to say, the Frank-Wolfe flow, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23g/chen23g.pdf",
        "supp": "",
        "pdf_size": 2678996,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8798739231531715017&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Stony Brook University; Stony Brook University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8b181030ba",
        "title": "Refined Convergence and Topology Learning for Decentralized SGD with Heterogeneous Data",
        "site": "https://proceedings.mlr.press/v206/le-bars23a.html",
        "author": "Batiste Le Bars; Aur\u00e9lien Bellet; Marc Tommasi; Erick Lavoie; Anne-Marie Kermarrec",
        "abstract": "One of the key challenges in decentralized and federated learning is to design algorithms that efficiently deal with highly heterogeneous data distributions across agents. In this paper, we revisit the analysis of Decentralized Stochastic Gradient Descent algorithm (D-SGD) under data heterogeneity. We exhibit the key role played by a new quantity, called neighborhood heterogeneity, on the convergence rate of D-SGD. By coupling the communication topology and the heterogeneity, our analysis sheds light on the poorly understood interplay between these two concepts. We then argue that neighborhood heterogeneity provides a natural criterion to learn data-dependent topologies that reduce (and can even eliminate) the otherwise detrimental effect of data heterogeneity on the convergence time of D-SGD. For the important case of classification with label skew, we formulate the problem of learning such a good topology as a tractable optimization problem that we solve with a Frank-Wolfe algorithm. As illustrated over a set of simulated and real-world experiments, our approach provides a principled way to design a sparse topology that balances the convergence speed and the per-iteration communication costs of D-SGD under data heterogeneity.",
        "bibtex": "@InProceedings{pmlr-v206-le-bars23a,\n  title = \t {Refined Convergence and Topology Learning for Decentralized SGD with Heterogeneous Data},\n  author =       {Le Bars, Batiste and Bellet, Aur\\'elien and Tommasi, Marc and Lavoie, Erick and Kermarrec, Anne-Marie},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1672--1702},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/le-bars23a/le-bars23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/le-bars23a.html},\n  abstract = \t {One of the key challenges in decentralized and federated learning is to design algorithms that efficiently deal with highly heterogeneous data distributions across agents. In this paper, we revisit the analysis of Decentralized Stochastic Gradient Descent algorithm (D-SGD) under data heterogeneity. We exhibit the key role played by a new quantity, called neighborhood heterogeneity, on the convergence rate of D-SGD. By coupling the communication topology and the heterogeneity, our analysis sheds light on the poorly understood interplay between these two concepts. We then argue that neighborhood heterogeneity provides a natural criterion to learn data-dependent topologies that reduce (and can even eliminate) the otherwise detrimental effect of data heterogeneity on the convergence time of D-SGD. For the important case of classification with label skew, we formulate the problem of learning such a good topology as a tractable optimization problem that we solve with a Frank-Wolfe algorithm. As illustrated over a set of simulated and real-world experiments, our approach provides a principled way to design a sparse topology that balances the convergence speed and the per-iteration communication costs of D-SGD under data heterogeneity.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/le-bars23a/le-bars23a.pdf",
        "supp": "",
        "pdf_size": 1470866,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5296041533581482444&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 17,
        "aff": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189, CRIStAL, F-59000 Lille; Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189, CRIStAL, F-59000 Lille; Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189, CRIStAL, F-59000 Lille; Universit\u00e9 de B\u00e2le, B\u00e2le, Switzerland+EPFL, Lausanne, Switzerland; Universit\u00e9 de B\u00e2le, B\u00e2le, Switzerland+EPFL, Lausanne, Switzerland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1+2;1+2",
        "aff_unique_norm": "University of Lille;Universit\u00e9 de B\u00e2le;EPFL",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.univ-lille.fr;https://www.unibas.ch;https://www.epfl.ch",
        "aff_unique_abbr": "Univ. Lille;;EPFL",
        "aff_campus_unique_index": "0;0;0;1+2;1+2",
        "aff_campus_unique": "Lille;B\u00e2le;Lausanne",
        "aff_country_unique_index": "0;0;0;1+1;1+1",
        "aff_country_unique": "France;Switzerland"
    },
    {
        "id": "36b6079157",
        "title": "Regression as Classification: Influence of Task Formulation on Neural Network Features",
        "site": "https://proceedings.mlr.press/v206/stewart23a.html",
        "author": "Lawrence Stewart; Francis Bach; Quentin Berthet; Jean-Philippe Vert",
        "abstract": "Neural networks can be trained to solve regression problems by using gradient-based methods to minimize the square loss. However, practitioners often prefer to reformulate regression as a classification problem, observing that training on the cross entropy loss results in better performance. By focusing on two-layer ReLU networks, which can be fully characterized by measures over their feature space, we explore how the implicit bias induced by gradient-based optimization could partly explain the above phenomenon. We provide theoretical evidence that the regression formulation yields a measure whose support can differ greatly from that for classification, in the case of one-dimensional data. Our proposed optimal supports correspond directly to the features learned by the input layer of the network. The different nature of these supports sheds light on possible optimization difficulties the square loss could encounter during training, and we present empirical results illustrating this phenomenon.",
        "bibtex": "@InProceedings{pmlr-v206-stewart23a,\n  title = \t {Regression as Classification: Influence of Task Formulation on Neural Network Features},\n  author =       {Stewart, Lawrence and Bach, Francis and Berthet, Quentin and Vert, Jean-Philippe},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11563--11582},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/stewart23a/stewart23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/stewart23a.html},\n  abstract = \t {Neural networks can be trained to solve regression problems by using gradient-based methods to minimize the square loss. However, practitioners often prefer to reformulate regression as a classification problem, observing that training on the cross entropy loss results in better performance. By focusing on two-layer ReLU networks, which can be fully characterized by measures over their feature space, we explore how the implicit bias induced by gradient-based optimization could partly explain the above phenomenon. We provide theoretical evidence that the regression formulation yields a measure whose support can differ greatly from that for classification, in the case of one-dimensional data. Our proposed optimal supports correspond directly to the features learned by the input layer of the network. The different nature of these supports sheds light on possible optimization difficulties the square loss could encounter during training, and we present empirical results illustrating this phenomenon.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/stewart23a/stewart23a.pdf",
        "supp": "",
        "pdf_size": 1344961,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9963174573666451904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ce1b20cd1f",
        "title": "Regularization for Shuffled Data Problems via Exponential Family Priors on the Permutation Group",
        "site": "https://proceedings.mlr.press/v206/wang23a.html",
        "author": "Zhenbang Wang; Emanuel Ben-David; Martin Slawski",
        "abstract": "In the analysis of data sets consisting of (X, Y)-pairs, a tacit assumption is that each pair corresponds to the same observational unit. If, however, such pairs are obtained via record linkage of two files, this assumption can be violated as a result of mismatch error rooting, for example, in the lack of reliable identifiers in the two files. Recently, there has been a surge of interest in this setting under the term \u201cShuffled Data\u201d in which the underlying correct pairing of (X, Y)-pairs is represented via an unknown permutation. Explicit modeling of the permutation tends to be associated with overfitting, prompting the need for suitable methods of regularization. In this paper, we propose an exponential family prior on the permutation group for this purpose that can be used to integrate various structures such as sparse and local shuffling. This prior turns out to be conjugate for canonical shuffled data problems in which the likelihood conditional on a fixed permutation can be expressed as product over the corresponding (X,Y)-pairs. Inference can be based on the EM algorithm in which the E-step is approximated by sampling, e.g., via the Fisher-Yates algorithm. The M-step is shown to admit a reduction from $n^2$ to $n$ terms if the likelihood of (X,Y)-pairs has exponential family form. Comparisons on synthetic and real data show that the proposed approach compares favorably to competing methods.",
        "bibtex": "@InProceedings{pmlr-v206-wang23a,\n  title = \t {Regularization for Shuffled Data Problems via Exponential Family Priors on the Permutation Group},\n  author =       {Wang, Zhenbang and Ben-David, Emanuel and Slawski, Martin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2939--2959},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23a/wang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23a.html},\n  abstract = \t {In the analysis of data sets consisting of (X, Y)-pairs, a tacit assumption is that each pair corresponds to the same observational unit. If, however, such pairs are obtained via record linkage of two files, this assumption can be violated as a result of mismatch error rooting, for example, in the lack of reliable identifiers in the two files. Recently, there has been a surge of interest in this setting under the term \u201cShuffled Data\u201d in which the underlying correct pairing of (X, Y)-pairs is represented via an unknown permutation. Explicit modeling of the permutation tends to be associated with overfitting, prompting the need for suitable methods of regularization. In this paper, we propose an exponential family prior on the permutation group for this purpose that can be used to integrate various structures such as sparse and local shuffling. This prior turns out to be conjugate for canonical shuffled data problems in which the likelihood conditional on a fixed permutation can be expressed as product over the corresponding (X,Y)-pairs. Inference can be based on the EM algorithm in which the E-step is approximated by sampling, e.g., via the Fisher-Yates algorithm. The M-step is shown to admit a reduction from $n^2$ to $n$ terms if the likelihood of (X,Y)-pairs has exponential family form. Comparisons on synthetic and real data show that the proposed approach compares favorably to competing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23a/wang23a.pdf",
        "supp": "",
        "pdf_size": 1129198,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8004820718604283957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2d1ea9170b",
        "title": "Reinforcement Learning for Adaptive Mesh Refinement",
        "site": "https://proceedings.mlr.press/v206/yang23e.html",
        "author": "Jiachen Yang; Tarik Dzanic; Brenden Petersen; Jun Kudo; Ketan Mittal; Vladimir Tomov; Jean-Sylvain Camier; Tuo Zhao; Hongyuan Zha; Tzanio Kolev; Robert Anderson; Daniel Faissol",
        "abstract": "Finite element simulations of physical systems governed by partial differential equations (PDE) crucially depend on adaptive mesh refinement (AMR) to allocate computational budget to regions where higher resolution is required. Existing scalable AMR methods make heuristic refinement decisions based on instantaneous error estimation and thus do not aim for long-term optimality over an entire simulation. We propose a novel formulation of AMR as a Markov decision process and apply deep reinforcement learning (RL) to train refinement policies directly from simulation. AMR poses a challenge for RL as both the state dimension and available action set changes at every step, which we solve by proposing new policy architectures with differing generality and inductive bias. The model sizes of these policy architectures are independent of the mesh size and hence can be deployed on larger simulations than those used at training time. We demonstrate in comprehensive experiments on static function estimation and time-dependent equations that RL policies can be trained on problems without using ground truth solutions, are competitive with a widely-used error estimator, and generalize to larger and unseen test problems.",
        "bibtex": "@InProceedings{pmlr-v206-yang23e,\n  title = \t {Reinforcement Learning for Adaptive Mesh Refinement},\n  author =       {Yang, Jiachen and Dzanic, Tarik and Petersen, Brenden and Kudo, Jun and Mittal, Ketan and Tomov, Vladimir and Camier, Jean-Sylvain and Zhao, Tuo and Zha, Hongyuan and Kolev, Tzanio and Anderson, Robert and Faissol, Daniel},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5997--6014},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23e/yang23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23e.html},\n  abstract = \t {Finite element simulations of physical systems governed by partial differential equations (PDE) crucially depend on adaptive mesh refinement (AMR) to allocate computational budget to regions where higher resolution is required. Existing scalable AMR methods make heuristic refinement decisions based on instantaneous error estimation and thus do not aim for long-term optimality over an entire simulation. We propose a novel formulation of AMR as a Markov decision process and apply deep reinforcement learning (RL) to train refinement policies directly from simulation. AMR poses a challenge for RL as both the state dimension and available action set changes at every step, which we solve by proposing new policy architectures with differing generality and inductive bias. The model sizes of these policy architectures are independent of the mesh size and hence can be deployed on larger simulations than those used at training time. We demonstrate in comprehensive experiments on static function estimation and time-dependent equations that RL policies can be trained on problems without using ground truth solutions, are competitive with a widely-used error estimator, and generalize to larger and unseen test problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23e/yang23e.pdf",
        "supp": "",
        "pdf_size": 3058162,
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9213710282156170047&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "LLNL; Texas A&M University; LLNL; LLNL; LLNL; LLNL; LLNL; Georgia Tech; Georgia Tech; LLNL; LLNL; LLNL",
        "aff_domain": "llnl.gov;tamu.edu; ; ; ; ; ; ; ; ;llnl.gov;llnl.gov",
        "email": "llnl.gov;tamu.edu; ; ; ; ; ; ; ; ;llnl.gov;llnl.gov",
        "github": "",
        "project": "",
        "author_num": 12,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0;0;0;2;2;0;0;0",
        "aff_unique_norm": "Lawrence Livermore National Laboratory;Texas A&M University;Georgia Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.llnl.gov;https://www.tamu.edu;https://www.gatech.edu",
        "aff_unique_abbr": "LLNL;TAMU;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8064c84d05",
        "title": "Reinforcement Learning with Stepwise Fairness Constraints",
        "site": "https://proceedings.mlr.press/v206/deng23a.html",
        "author": "Zhun Deng; He Sun; Steven Wu; Linjun Zhang; David Parkes",
        "abstract": "AI methods are used in societally important settings, ranging from credit to employment to housing, and it is crucial to provide fairness in regard to automated decision making. Moreover, many settings are dynamic, with populations responding to sequential decision policies. We introduce the study of reinforcement learning (RL) with stepwise fairness constraints, which require group fairness at each time step. In the case of tabular episodic RL, we provide learning algorithms with strong theoretical guarantees in regard to policy optimality and fairness violations. Our framework provides tools to study the impact of fairness constraints in sequential settings and brings up new challenges in RL.",
        "bibtex": "@InProceedings{pmlr-v206-deng23a,\n  title = \t {Reinforcement Learning with Stepwise Fairness Constraints},\n  author =       {Deng, Zhun and Sun, He and Wu, Steven and Zhang, Linjun and Parkes, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10594--10618},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/deng23a/deng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/deng23a.html},\n  abstract = \t {AI methods are used in societally important settings, ranging from credit to employment to housing, and it is crucial to provide fairness in regard to automated decision making. Moreover, many settings are dynamic, with populations responding to sequential decision policies. We introduce the study of reinforcement learning (RL) with stepwise fairness constraints, which require group fairness at each time step. In the case of tabular episodic RL, we provide learning algorithms with strong theoretical guarantees in regard to policy optimality and fairness violations. Our framework provides tools to study the impact of fairness constraints in sequential settings and brings up new challenges in RL.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/deng23a/deng23a.pdf",
        "supp": "",
        "pdf_size": 7678129,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4162090700786117412&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Columbia University; Harvard University; Carnegie Mellon University; Rutgers University; DeepMind + Harvard University",
        "aff_domain": "g.harvard.edu;g.harvard.edu; ; ; ",
        "email": "g.harvard.edu;g.harvard.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4+1",
        "aff_unique_norm": "Columbia University;Harvard University;Carnegie Mellon University;Rutgers University;DeepMind",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.columbia.edu;https://www.harvard.edu;https://www.cmu.edu;https://www.rutgers.edu;https://deepmind.com",
        "aff_unique_abbr": "Columbia;Harvard;CMU;Rutgers;DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1+0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "e381ed4a04",
        "title": "Representation Learning in Deep RL via Discrete Information Bottleneck",
        "site": "https://proceedings.mlr.press/v206/islam23a.html",
        "author": "Riashat Islam; Hongyu Zang; Manan Tomar; Aniket Didolkar; Md Mofijul Islam; Samin Yeasar Arnob; Tariq Iqbal; Xin Li; Anirudh Goyal; Nicolas Heess; Alex Lamb",
        "abstract": "Several self-supervised representation learning methods have been proposed for reinforcement learning (RL) with rich observations. For real world applications of RL, recovering underlying latent states is crucial, particularly when sensory inputs can contain irrelevant and exogenous information. In this work, we study how information bottlenecjs can be used to construct latent states efficiently in the presence of task irrelevant information. We propose architectures that utilize variational and discrete information bottleneck, coined as RepDIB, to learn structured factorized representations. Exploiting the expressiveness bought by factorized representations, we introduce a simple, yet effective, bottleneck that can be integrated with any existing self supervised objective for RL. We demonstrate this across several online and offline RL benchmarks, along with a real robot arm task, where we find that compressed representations with RepDIB can lead to strong performance improvements, as the learnt bottlenecks can help predict only the relevant state, while ignoring irrelevant information.",
        "bibtex": "@InProceedings{pmlr-v206-islam23a,\n  title = \t {Representation Learning in Deep RL via Discrete Information Bottleneck},\n  author =       {Islam, Riashat and Zang, Hongyu and Tomar, Manan and Didolkar, Aniket and Islam, Md Mofijul and Arnob, Samin Yeasar and Iqbal, Tariq and Li, Xin and Goyal, Anirudh and Heess, Nicolas and Lamb, Alex},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8699--8722},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/islam23a/islam23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/islam23a.html},\n  abstract = \t {Several self-supervised representation learning methods have been proposed for reinforcement learning (RL) with rich observations. For real world applications of RL, recovering underlying latent states is crucial, particularly when sensory inputs can contain irrelevant and exogenous information. In this work, we study how information bottlenecjs can be used to construct latent states efficiently in the presence of task irrelevant information. We propose architectures that utilize variational and discrete information bottleneck, coined as RepDIB, to learn structured factorized representations. Exploiting the expressiveness bought by factorized representations, we introduce a simple, yet effective, bottleneck that can be integrated with any existing self supervised objective for RL. We demonstrate this across several online and offline RL benchmarks, along with a real robot arm task, where we find that compressed representations with RepDIB can lead to strong performance improvements, as the learnt bottlenecks can help predict only the relevant state, while ignoring irrelevant information.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/islam23a/islam23a.pdf",
        "supp": "",
        "pdf_size": 39209632,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7202919250809660378&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;;;;;;",
        "aff_domain": ";;;;;;;;;;",
        "email": ";;;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 11,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "29088fca72",
        "title": "Resolving the Approximability of Offline and Online Non-monotone DR-Submodular Maximization over General Convex Sets",
        "site": "https://proceedings.mlr.press/v206/mualem23a.html",
        "author": "Loay Mualem; Moran Feldman",
        "abstract": "In recent years, maximization of DR-submodular continuous functions became an important research field, with many real-worlds applications in the domains of machine learning, communication systems, operation research and economics. Most of the works in this field study maximization subject to down-closed convex set constraints due to an inapproximability result by Vondrak (2013). However, Durr et al. (2021) showed that one can bypass this inapproximability by proving approximation ratios that are functions of m, the minimum $\\ell-\\infty$ norm of any feasible vector. Given this observation, it is possible to get results for maximizing a DR-submodular function subject to general convex set constraints, which has led to multiple works on this problem. The most recent of which is a polynomial time 1/4(1 - m)-approximation offline algorithm due to Du (2022). However, only a sub-exponential time $(1 - m)/(3^{1.5})$-approximation algorithm is known for the corresponding online problem. In this work, we present a polynomial time online algorithm matching the 1/4(1 - m)-approximation of the state-of-the-art offline algorithm. We also present an inapproximability result showing that our online algorithm and Du\u2019s (2022) offline algorithm are both optimal in a strong sense. Finally, we study the empirical performance of our algorithm and the algorithm Du (2022) (which was only theoretically studied previously), and show that they consistently outperform previously suggested algorithms on revenue maximization, location summarization and quadratic programming applications.",
        "bibtex": "@InProceedings{pmlr-v206-mualem23a,\n  title = \t {Resolving the Approximability of Offline and Online Non-monotone DR-Submodular Maximization over General Convex Sets},\n  author =       {Mualem, Loay and Feldman, Moran},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2542--2564},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mualem23a/mualem23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mualem23a.html},\n  abstract = \t {In recent years, maximization of DR-submodular continuous functions became an important research field, with many real-worlds applications in the domains of machine learning, communication systems, operation research and economics. Most of the works in this field study maximization subject to down-closed convex set constraints due to an inapproximability result by Vondrak (2013). However, Durr et al. (2021) showed that one can bypass this inapproximability by proving approximation ratios that are functions of m, the minimum $\\ell-\\infty$ norm of any feasible vector. Given this observation, it is possible to get results for maximizing a DR-submodular function subject to general convex set constraints, which has led to multiple works on this problem. The most recent of which is a polynomial time 1/4(1 - m)-approximation offline algorithm due to Du (2022). However, only a sub-exponential time $(1 - m)/(3^{1.5})$-approximation algorithm is known for the corresponding online problem. In this work, we present a polynomial time online algorithm matching the 1/4(1 - m)-approximation of the state-of-the-art offline algorithm. We also present an inapproximability result showing that our online algorithm and Du\u2019s (2022) offline algorithm are both optimal in a strong sense. Finally, we study the empirical performance of our algorithm and the algorithm Du (2022) (which was only theoretically studied previously), and show that they consistently outperform previously suggested algorithms on revenue maximization, location summarization and quadratic programming applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mualem23a/mualem23a.pdf",
        "supp": "",
        "pdf_size": 493340,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2236618390429585994&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Haifa; University of Haifa",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Haifa",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.haifa.ac.il",
        "aff_unique_abbr": "UoH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "2fab34ebd9",
        "title": "Rethinking Initialization of the Sinkhorn Algorithm",
        "site": "https://proceedings.mlr.press/v206/thornton23a.html",
        "author": "James Thornton; Marco Cuturi",
        "abstract": "While the optimal transport (OT) problem was originally formulated as a linear program, the addition of entropic regularization has proven beneficial both computationally and statistically, for many applications. The Sinkhorn fixed-point algorithm is the most popular approach to solve this regularized problem, and, as a result, multiple attempts have been made to reduce its runtime using, e.g., annealing in the regularization parameter, momentum or acceleration. The premise of this work is that initialization of the Sinkhorn algorithm has received comparatively little attention, possibly due to two preconceptions: since the regularized OT problem is convex, it may not be worth crafting a good initialization, since any is guaranteed to work; secondly, because the outputs of the Sinkhorn algorithm are often unrolled in end-to-end pipelines, a data-dependent initialization would bias Jacobian computations. We challenge this conventional wisdom, and show that data-dependent initializers result in dramatic speed-ups, with no effect on differentiability as long as implicit differentiation is used. Our initializations rely on closed-forms for exact or approximate OT solutions that are known in the 1D, Gaussian or GMM settings. They can be used with minimal tuning, and result in consistent speed-ups for a wide variety of OT problems.",
        "bibtex": "@InProceedings{pmlr-v206-thornton23a,\n  title = \t {Rethinking Initialization of the Sinkhorn Algorithm},\n  author =       {Thornton, James and Cuturi, Marco},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8682--8698},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/thornton23a/thornton23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/thornton23a.html},\n  abstract = \t {While the optimal transport (OT) problem was originally formulated as a linear program, the addition of entropic regularization has proven beneficial both computationally and statistically, for many applications. The Sinkhorn fixed-point algorithm is the most popular approach to solve this regularized problem, and, as a result, multiple attempts have been made to reduce its runtime using, e.g., annealing in the regularization parameter, momentum or acceleration. The premise of this work is that initialization of the Sinkhorn algorithm has received comparatively little attention, possibly due to two preconceptions: since the regularized OT problem is convex, it may not be worth crafting a good initialization, since any is guaranteed to work; secondly, because the outputs of the Sinkhorn algorithm are often unrolled in end-to-end pipelines, a data-dependent initialization would bias Jacobian computations. We challenge this conventional wisdom, and show that data-dependent initializers result in dramatic speed-ups, with no effect on differentiability as long as implicit differentiation is used. Our initializations rely on closed-forms for exact or approximate OT solutions that are known in the 1D, Gaussian or GMM settings. They can be used with minimal tuning, and result in consistent speed-ups for a wide variety of OT problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/thornton23a/thornton23a.pdf",
        "supp": "",
        "pdf_size": 2108030,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10100298605762654169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Oxford \u2020; Apple",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Oxford;Apple",
        "aff_unique_dep": ";Apple Inc.",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.apple.com",
        "aff_unique_abbr": "Oxford;Apple",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9c1996d38c",
        "title": "Retrospective Uncertainties for Deep Models using Vine Copulas",
        "site": "https://proceedings.mlr.press/v206/tagasovska23a.html",
        "author": "Natasa Tagasovska; Firat Ozdemir; Axel Brando",
        "abstract": "Despite the major progress of deep models as learning machines, uncertainty estimation remains a major challenge. Existing solutions rely on modified loss functions or architectural changes. We propose to compensate for the lack of built-in uncertainty estimates by supplementing any network, retrospectively, with a subsequent vine copula model, in an overall compound we call Vine-Copula Neural Network (VCNN). Through synthetic and real-data experiments, we show that VCNNs could be task (regression/classification) and architecture (recurrent, fully connected) agnostic while providing reliable and better-calibrated uncertainty estimates, comparable to state-of-the-art built-in uncertainty solutions.",
        "bibtex": "@InProceedings{pmlr-v206-tagasovska23a,\n  title = \t {Retrospective Uncertainties for Deep Models using Vine Copulas},\n  author =       {Tagasovska, Natasa and Ozdemir, Firat and Brando, Axel},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7528--7539},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tagasovska23a/tagasovska23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tagasovska23a.html},\n  abstract = \t {Despite the major progress of deep models as learning machines, uncertainty estimation remains a major challenge. Existing solutions rely on modified loss functions or architectural changes. We propose to compensate for the lack of built-in uncertainty estimates by supplementing any network, retrospectively, with a subsequent vine copula model, in an overall compound we call Vine-Copula Neural Network (VCNN). Through synthetic and real-data experiments, we show that VCNNs could be task (regression/classification) and architecture (recurrent, fully connected) agnostic while providing reliable and better-calibrated uncertainty estimates, comparable to state-of-the-art built-in uncertainty solutions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tagasovska23a/tagasovska23a.pdf",
        "supp": "",
        "pdf_size": 1783917,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=751008616739779899&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cc143f88e6",
        "title": "Revisiting Fair-PAC Learning and the Axioms of Cardinal Welfare",
        "site": "https://proceedings.mlr.press/v206/cousins23a.html",
        "author": "Cyrus Cousins",
        "abstract": "Cardinal objectives serve as intuitive targets in fair machine learning by summarizing utility (welfare) or disutility (malfare) $u$ over $g$ groups. Under standard axioms, all welfare and malfare functions are $w$-weighted $p$-power-means, i.e. $M_p(u;w) = \\sqrt[p]{\\sum_{i=1}^g w_i u_i^p}$, with $p \\leq 1$ for welfare, or $p \\geq 1$ for malfare. We show the same under weaker axioms, and also identify stronger axioms that naturally restrict $p$. It is known that power-mean malfare functions are Lipschitz continuous, and thus statistically easy to estimate or learn. We show that all power means are locally Holder continuous, i.e., $|M(u; w)-M(u\u2019 ; w)| \\leq \\lambda \\parallel u - u\u2019\\parallel^\\alpha$ for some $\\lambda$, $\\alpha$,$\\parallel \\cdot \\parallel$. In particular, $\\lambda$ and $1/\\alpha$ are bounded except as $p \\rightarrow 0$ or $\\min_i w_i \\rightarrow 0$, and via this analysis we bound the sample complexity of optimizing welfare. This yields a novel concept of fair-PAC learning, wherein welfare functions are only polynomially harder to optimize than malfare functions, except when $p \\approx 0$ or $\\min_i w_i$ $\\approx$ 0, which is exponentially harder.",
        "bibtex": "@InProceedings{pmlr-v206-cousins23a,\n  title = \t {Revisiting Fair-PAC Learning and the Axioms of Cardinal Welfare},\n  author =       {Cousins, Cyrus},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6422--6442},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cousins23a/cousins23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cousins23a.html},\n  abstract = \t {Cardinal objectives serve as intuitive targets in fair machine learning by summarizing utility (welfare) or disutility (malfare) $u$ over $g$ groups. Under standard axioms, all welfare and malfare functions are $w$-weighted $p$-power-means, i.e. $M_p(u;w) = \\sqrt[p]{\\sum_{i=1}^g w_i u_i^p}$, with $p \\leq 1$ for welfare, or $p \\geq 1$ for malfare. We show the same under weaker axioms, and also identify stronger axioms that naturally restrict $p$. It is known that power-mean malfare functions are Lipschitz continuous, and thus statistically easy to estimate or learn. We show that all power means are locally Holder continuous, i.e., $|M(u; w)-M(u\u2019 ; w)| \\leq \\lambda \\parallel u - u\u2019\\parallel^\\alpha$ for some $\\lambda$, $\\alpha$,$\\parallel \\cdot \\parallel$. In particular, $\\lambda$ and $1/\\alpha$ are bounded except as $p \\rightarrow 0$ or $\\min_i w_i \\rightarrow 0$, and via this analysis we bound the sample complexity of optimizing welfare. This yields a novel concept of fair-PAC learning, wherein welfare functions are only polynomially harder to optimize than malfare functions, except when $p \\approx 0$ or $\\min_i w_i$ $\\approx$ 0, which is exponentially harder.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cousins23a/cousins23a.pdf",
        "supp": "",
        "pdf_size": 798746,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4595505076268400011&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "University of Massachusetts Amherst",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7bdc8ccbfc",
        "title": "Revisiting Weighted Strategy for Non-stationary Parametric Bandits",
        "site": "https://proceedings.mlr.press/v206/wang23k.html",
        "author": "Jing Wang; Peng Zhao; Zhi-Hua Zhou",
        "abstract": "Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a refined analysis framework, which simplifies the derivation and importantly produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\\tilde O(k_\\mu^{\\frac{5}{4}} c_\\mu^{-\\frac{3}{4}} d^{\\frac{3}{4}} P_T^{\\frac{1}{4}}T^{\\frac{3}{4}})$ regret, improving the $\\tilde O(k_\\mu^{2} c_\\mu^{-1}d^{\\frac{9}{10}} P_T^{\\frac{1}{5}}T^{\\frac{4}{5}})$ bound in prior work, where $k_\\mu$ and $c_\\mu$ characterize the reward model\u2019s nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon.",
        "bibtex": "@InProceedings{pmlr-v206-wang23k,\n  title = \t {Revisiting Weighted Strategy for Non-stationary Parametric Bandits},\n  author =       {Wang, Jing and Zhao, Peng and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7913--7942},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23k/wang23k.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23k.html},\n  abstract = \t {Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a refined analysis framework, which simplifies the derivation and importantly produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\\tilde O(k_\\mu^{\\frac{5}{4}} c_\\mu^{-\\frac{3}{4}} d^{\\frac{3}{4}} P_T^{\\frac{1}{4}}T^{\\frac{3}{4}})$ regret, improving the $\\tilde O(k_\\mu^{2} c_\\mu^{-1}d^{\\frac{9}{10}} P_T^{\\frac{1}{5}}T^{\\frac{4}{5}})$ bound in prior work, where $k_\\mu$ and $c_\\mu$ characterize the reward model\u2019s nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23k/wang23k.pdf",
        "supp": "",
        "pdf_size": 746836,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4772504335603534513&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "aff_domain": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "email": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "f25eb60818",
        "title": "Reward Learning as Doubly Nonparametric Bandits: Optimal Design and Scaling Laws",
        "site": "https://proceedings.mlr.press/v206/bhatia23a.html",
        "author": "Kush Bhatia; Wenshuo Guo; Jacob Steinhardt",
        "abstract": "Specifying reward functions for complex tasks like object manipulation or driving is challenging to do by hand. Reward learning seeks to address this by learning a reward model using human feedback on selected query policies. This shifts the burden of reward specification to the optimal design of the queries. We propose a theoretical framework for studying reward learning and the associated optimal experiment design problem. Our framework models rewards and policies as nonparametric functions belonging to subsets of Reproducing Kernel Hilbert Spaces (RKHSs). The learner receives (noisy) oracle access to a true reward and must output a policy that performs well under the true reward. For this setting, we first derive non-asymptotic excess risk bounds for a simple plug-in estimator based on ridge regression. We then solve the query design problem by optimizing these risk bounds with respect to the choice of query set and obtain a finite sample statistical rate, which depends primarily on the eigenvalue spectrum of a certain linear operator on the RKHSs. Despite the generality of these results, our bounds are stronger than previous bounds developed for more specialized problems. We specifically show that the well-studied problem of Gaussian process (GP) bandit optimization is a special case of our framework, and that our bounds either improve or are competitive with known regret guarantees for the Mat\u00e9rn kernel.",
        "bibtex": "@InProceedings{pmlr-v206-bhatia23a,\n  title = \t {Reward Learning as Doubly Nonparametric Bandits: Optimal Design and Scaling Laws},\n  author =       {Bhatia, Kush and Guo, Wenshuo and Steinhardt, Jacob},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11149--11171},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bhatia23a/bhatia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bhatia23a.html},\n  abstract = \t {Specifying reward functions for complex tasks like object manipulation or driving is challenging to do by hand. Reward learning seeks to address this by learning a reward model using human feedback on selected query policies. This shifts the burden of reward specification to the optimal design of the queries. We propose a theoretical framework for studying reward learning and the associated optimal experiment design problem. Our framework models rewards and policies as nonparametric functions belonging to subsets of Reproducing Kernel Hilbert Spaces (RKHSs). The learner receives (noisy) oracle access to a true reward and must output a policy that performs well under the true reward. For this setting, we first derive non-asymptotic excess risk bounds for a simple plug-in estimator based on ridge regression. We then solve the query design problem by optimizing these risk bounds with respect to the choice of query set and obtain a finite sample statistical rate, which depends primarily on the eigenvalue spectrum of a certain linear operator on the RKHSs. Despite the generality of these results, our bounds are stronger than previous bounds developed for more specialized problems. We specifically show that the well-studied problem of Gaussian process (GP) bandit optimization is a special case of our framework, and that our bounds either improve or are competitive with known regret guarantees for the Mat\u00e9rn kernel.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bhatia23a/bhatia23a.pdf",
        "supp": "",
        "pdf_size": 473046,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13473735382156668587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "35d48c5b34",
        "title": "Riemannian Accelerated Gradient Methods via Extrapolation",
        "site": "https://proceedings.mlr.press/v206/han23a.html",
        "author": "Andi Han; Bamdev Mishra; Pratik Jawanpuria; Junbin Gao",
        "abstract": "In this paper, we propose a convergence acceleration scheme for general Riemannian optimization problems by extrapolating iterates on manifolds. We show that when the iterates are generated from the Riemannian gradient descent method, the scheme achieves the optimal convergence rate asymptotically and is computationally more favorable than the recently proposed Riemannian Nesterov accelerated gradient methods. A salient feature of our analysis is the convergence guarantees with respect to the use of general retraction and vector transport. Empirically, we verify the practical benefits of the proposed acceleration strategy, including robustness to the choice of different averaging schemes on manifolds.",
        "bibtex": "@InProceedings{pmlr-v206-han23a,\n  title = \t {Riemannian Accelerated Gradient Methods via Extrapolation},\n  author =       {Han, Andi and Mishra, Bamdev and Jawanpuria, Pratik and Gao, Junbin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1554--1585},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/han23a/han23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/han23a.html},\n  abstract = \t {In this paper, we propose a convergence acceleration scheme for general Riemannian optimization problems by extrapolating iterates on manifolds. We show that when the iterates are generated from the Riemannian gradient descent method, the scheme achieves the optimal convergence rate asymptotically and is computationally more favorable than the recently proposed Riemannian Nesterov accelerated gradient methods. A salient feature of our analysis is the convergence guarantees with respect to the use of general retraction and vector transport. Empirically, we verify the practical benefits of the proposed acceleration strategy, including robustness to the choice of different averaging schemes on manifolds.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/han23a/han23a.pdf",
        "supp": "",
        "pdf_size": 1865172,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3018653704764552582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d02b7f9773",
        "title": "Risk Bounds on Aleatoric Uncertainty Recovery",
        "site": "https://proceedings.mlr.press/v206/zhang23h.html",
        "author": "Yikai Zhang; Jiahe Lin; Fengpei Li; Yeshaya Adler; Kashif Rasul; Anderson Schneider; Yuriy Nevmyvaka",
        "abstract": "Quantifying aleatoric uncertainty is a challenging task in machine learning. It is important for decision making associated with data-dependent uncertainty in model outcomes. Recently, many empirical studies in modeling aleatoric uncertainty under regression settings primarily rely on either a Gaussian likelihood or moment matching. However, the performance of these methods varies for different datasets whereas discussions on their theoretical guarantees are lacking. In this work, we investigate theoretical aspects of these approaches and establish risk bounds for their estimates. We provide conditions that are sufficient to guarantee the PAC-learnablility of the aleatoric uncertainty. The study suggests that the likelihood and moment matching-based methods enjoy different types of guarantee in their risk bounds, i.e., they calibrate different aspects of the uncertainty and thus exhibit distinct properties in different regimes of the parameter space. Finally, we conduct empirical study which shows promising results and supports our theorems.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23h,\n  title = \t {Risk Bounds on Aleatoric Uncertainty Recovery},\n  author =       {Zhang, Yikai and Lin, Jiahe and Li, Fengpei and Adler, Yeshaya and Rasul, Kashif and Schneider, Anderson and Nevmyvaka, Yuriy},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6015--6036},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23h/zhang23h.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23h.html},\n  abstract = \t {Quantifying aleatoric uncertainty is a challenging task in machine learning. It is important for decision making associated with data-dependent uncertainty in model outcomes. Recently, many empirical studies in modeling aleatoric uncertainty under regression settings primarily rely on either a Gaussian likelihood or moment matching. However, the performance of these methods varies for different datasets whereas discussions on their theoretical guarantees are lacking. In this work, we investigate theoretical aspects of these approaches and establish risk bounds for their estimates. We provide conditions that are sufficient to guarantee the PAC-learnablility of the aleatoric uncertainty. The study suggests that the likelihood and moment matching-based methods enjoy different types of guarantee in their risk bounds, i.e., they calibrate different aspects of the uncertainty and thus exhibit distinct properties in different regimes of the parameter space. Finally, we conduct empirical study which shows promising results and supports our theorems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23h/zhang23h.pdf",
        "supp": "",
        "pdf_size": 553472,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1670477154636894990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Machine Learning Research, Morgan Stanley; Machine Learning Research, Morgan Stanley; Machine Learning Research, Morgan Stanley; Machine Learning Research, Morgan Stanley; Machine Learning Research, Morgan Stanley; Machine Learning Research, Morgan Stanley; Machine Learning Research, Morgan Stanley",
        "aff_domain": "morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com",
        "email": "morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com;morganstanley.com",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Morgan Stanley",
        "aff_unique_dep": "Machine Learning Research",
        "aff_unique_url": "https://www.morganstanley.com",
        "aff_unique_abbr": "MS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3fda7e0f50",
        "title": "Risk-aware linear bandits with convex loss",
        "site": "https://proceedings.mlr.press/v206/saux23a.html",
        "author": "Patrick Saux; Odalric Maillard",
        "abstract": "In decision-making problems such as the multi-armed bandit, an agent learns sequentially by optimizing a certain feedback. While the mean reward criterion has been extensively studied, other measures that reflect an aversion to adverse outcomes, such as mean-variance or conditional value-at-risk (CVaR), can be of interest for critical applications (healthcare, agriculture). Algorithms have been proposed for such risk-aware measures under bandit feedback without contextual information. In this work, we study contextual bandits where such risk measures can be elicited as linear functions of the contexts through the minimization of a convex loss. A typical example that fits within this framework is the expectile measure, which is obtained as the solution of an asymmetric least-square problem. Using the method of mixtures for supermartingales, we derive confidence sequences for the estimation of such risk measures. We then propose an optimistic UCB algorithm to learn optimal risk-aware actions, with regret guarantees similar to those of generalized linear bandits. This approach requires solving a convex problem at each round of the algorithm, which we can relax by allowing only approximated solution obtained by online gradient descent, at the cost of slightly higher regret. We conclude by evaluating the resulting algorithms on numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v206-saux23a,\n  title = \t {Risk-aware linear bandits with convex loss},\n  author =       {Saux, Patrick and Maillard, Odalric},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7723--7754},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/saux23a/saux23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/saux23a.html},\n  abstract = \t {In decision-making problems such as the multi-armed bandit, an agent learns sequentially by optimizing a certain feedback. While the mean reward criterion has been extensively studied, other measures that reflect an aversion to adverse outcomes, such as mean-variance or conditional value-at-risk (CVaR), can be of interest for critical applications (healthcare, agriculture). Algorithms have been proposed for such risk-aware measures under bandit feedback without contextual information. In this work, we study contextual bandits where such risk measures can be elicited as linear functions of the contexts through the minimization of a convex loss. A typical example that fits within this framework is the expectile measure, which is obtained as the solution of an asymmetric least-square problem. Using the method of mixtures for supermartingales, we derive confidence sequences for the estimation of such risk measures. We then propose an optimistic UCB algorithm to learn optimal risk-aware actions, with regret guarantees similar to those of generalized linear bandits. This approach requires solving a convex problem at each round of the algorithm, which we can relax by allowing only approximated solution obtained by online gradient descent, at the cost of slightly higher regret. We conclude by evaluating the resulting algorithms on numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/saux23a/saux23a.pdf",
        "supp": "",
        "pdf_size": 796161,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16065423685604468156&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Inria, Univ. Lille, CNRS, Centrale Lille, UMR 9198-CRIStAL, F-59000 Lille, France; Inria, Univ. Lille, CNRS, Centrale Lille, UMR 9198-CRIStAL, F-59000 Lille, France",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "6075856b4c",
        "title": "Robust Linear Regression for General Feature Distribution",
        "site": "https://proceedings.mlr.press/v206/norman23a.html",
        "author": "Tom Norman; Nir Weinberger; Kfir Y. Levy",
        "abstract": "We investigate robust linear regression where data may be contaminated by an oblivious adversary, i.e., an adversary that knows the data distribution but is otherwise oblivious to the realization of the data samples. This model has been previously analyzed under strong assumptions. Concretely, (i) all previous works assume that the covariance matrix of the features is positive definite; (ii) most of them assume that the features are centered. Additionally, all previous works make additional restrictive assumptions, e.g., assuming Gaussianity of the features or symmetric distribution of the corruptions. In this work, we investigate robust regression under a more general set of assumptions: (i) the covariance matrix may be either positive definite or positive semi definite, (ii) features may not be centered, (iii) no assumptions beyond boundedness (or sub-Gaussianity) of the features and the measurement noise. Under these assumptions we analyze a sequential algorithm, namely, a natural SGD variant for this problem, and show that it enjoys a fast convergence rate when the covariance matrix is positive definite. In the positive semi definite case we show that there are two regimes: if the features are centered, we can obtain a standard convergence rate; Otherwise, the adversary can cause any learner to fail arbitrarily.",
        "bibtex": "@InProceedings{pmlr-v206-norman23a,\n  title = \t {Robust Linear Regression for General Feature Distribution},\n  author =       {Norman, Tom and Weinberger, Nir and Levy, Kfir Y.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2405--2435},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/norman23a/norman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/norman23a.html},\n  abstract = \t {We investigate robust linear regression where data may be contaminated by an oblivious adversary, i.e., an adversary that knows the data distribution but is otherwise oblivious to the realization of the data samples. This model has been previously analyzed under strong assumptions. Concretely, (i) all previous works assume that the covariance matrix of the features is positive definite; (ii) most of them assume that the features are centered. Additionally, all previous works make additional restrictive assumptions, e.g., assuming Gaussianity of the features or symmetric distribution of the corruptions. In this work, we investigate robust regression under a more general set of assumptions: (i) the covariance matrix may be either positive definite or positive semi definite, (ii) features may not be centered, (iii) no assumptions beyond boundedness (or sub-Gaussianity) of the features and the measurement noise. Under these assumptions we analyze a sequential algorithm, namely, a natural SGD variant for this problem, and show that it enjoys a fast convergence rate when the covariance matrix is positive definite. In the positive semi definite case we show that there are two regimes: if the features are centered, we can obtain a standard convergence rate; Otherwise, the adversary can cause any learner to fail arbitrarily.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/norman23a/norman23a.pdf",
        "supp": "",
        "pdf_size": 590209,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14700787738041424085&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1248f6d21c",
        "title": "Robust Linear Regression: Gradient-descent, Early-stopping, and Beyond",
        "site": "https://proceedings.mlr.press/v206/scetbon23a.html",
        "author": "Meyer Scetbon; Elvis Dohmatob",
        "abstract": "In this work we study the robustness to adversarial attacks, of early-stopping strategies on gradient-descent (GD) methods for linear regression. More precisely, we show that early-stopped GD is optimally robust (up to an absolute constant) against Euclidean-norm adversarial attacks. However, we show that this strategy can be arbitrarily sub-optimal in the case of general Mahalanobis attacks. This observation is compatible with recent findings in the case of classification Vardi et al. (2022) that show that GD provably converges to non-robust models. To alleviate this issue, we propose to apply instead a GD scheme on a transformation of the data adapted to the attack. This data transformation amounts to apply feature-depending learning rates and we show that this modified GD is able to handle any Mahalanobis attack, as well as more general attacks under some conditions. Unfortunately, choosing such adapted transformations can be hard for general attacks. To the rescue, we design a simple and tractable estimator whose adversarial risk is optimal up to within a multiplicative constant of 1.1124 in the population regime, and works for any norm.",
        "bibtex": "@InProceedings{pmlr-v206-scetbon23a,\n  title = \t {Robust Linear Regression: Gradient-descent, Early-stopping, and Beyond},\n  author =       {Scetbon, Meyer and Dohmatob, Elvis},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11583--11607},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/scetbon23a/scetbon23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/scetbon23a.html},\n  abstract = \t {In this work we study the robustness to adversarial attacks, of early-stopping strategies on gradient-descent (GD) methods for linear regression. More precisely, we show that early-stopped GD is optimally robust (up to an absolute constant) against Euclidean-norm adversarial attacks. However, we show that this strategy can be arbitrarily sub-optimal in the case of general Mahalanobis attacks. This observation is compatible with recent findings in the case of classification Vardi et al. (2022) that show that GD provably converges to non-robust models. To alleviate this issue, we propose to apply instead a GD scheme on a transformation of the data adapted to the attack. This data transformation amounts to apply feature-depending learning rates and we show that this modified GD is able to handle any Mahalanobis attack, as well as more general attacks under some conditions. Unfortunately, choosing such adapted transformations can be hard for general attacks. To the rescue, we design a simple and tractable estimator whose adversarial risk is optimal up to within a multiplicative constant of 1.1124 in the population regime, and works for any norm.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/scetbon23a/scetbon23a.pdf",
        "supp": "",
        "pdf_size": 620805,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11264774049021610094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Facebook AI Research; Facebook AI Research",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "497fafc0aa",
        "title": "Robust Variational Autoencoding with Wasserstein Penalty for Novelty Detection",
        "site": "https://proceedings.mlr.press/v206/lai23a.html",
        "author": "Chieh-Hsin Lai; Dongmian Zou; Gilad Lerman",
        "abstract": "We propose a new method for novelty detection that can tolerate high corruption of the training points, whereas previous works assumed either no or very low corruption. Our method trains a robust variational autoencoder (VAE), which aims to generate a model for the uncorrupted training points. To gain robustness to high corruption, we incorporate the following four changes to the common VAE: 1. Extracting crucial features of the latent code by a carefully designed dimension reduction component for distributions; 2. Modeling the latent distribution as a mixture of Gaussian low-rank inliers and full-rank outliers, where the testing only uses the inlier model; 3. Applying the Wasserstein-1 metric for regularization, instead of the Kullback-Leibler (KL) divergence; and 4. Using a robust error for reconstruction. We establish both robustness to outliers and suitability to low-rank modeling of the Wasserstein metric as opposed to the KL divergence. We illustrate state-of-the-art results on standard benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-lai23a,\n  title = \t {Robust Variational Autoencoding with Wasserstein Penalty for Novelty Detection},\n  author =       {Lai, Chieh-Hsin and Zou, Dongmian and Lerman, Gilad},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3538--3567},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lai23a/lai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lai23a.html},\n  abstract = \t {We propose a new method for novelty detection that can tolerate high corruption of the training points, whereas previous works assumed either no or very low corruption. Our method trains a robust variational autoencoder (VAE), which aims to generate a model for the uncorrupted training points. To gain robustness to high corruption, we incorporate the following four changes to the common VAE: 1. Extracting crucial features of the latent code by a carefully designed dimension reduction component for distributions; 2. Modeling the latent distribution as a mixture of Gaussian low-rank inliers and full-rank outliers, where the testing only uses the inlier model; 3. Applying the Wasserstein-1 metric for regularization, instead of the Kullback-Leibler (KL) divergence; and 4. Using a robust error for reconstruction. We establish both robustness to outliers and suitability to low-rank modeling of the Wasserstein metric as opposed to the KL divergence. We illustrate state-of-the-art results on standard benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lai23a/lai23a.pdf",
        "supp": "",
        "pdf_size": 20649302,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=955822276472389660&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Mathematics, University of Minnesota; Division of Natural and Applied Sciences, Duke Kunshan University + School of Mathematics, University of Minnesota; School of Mathematics, University of Minnesota",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0",
        "aff_unique_norm": "University of Minnesota;Duke Kunshan University",
        "aff_unique_dep": "School of Mathematics;Division of Natural and Applied Sciences",
        "aff_unique_url": "https://www.math.umn.edu;https://www.duk/Dkunshan.edu.cn",
        "aff_unique_abbr": "UMN;DKU",
        "aff_campus_unique_index": "0;1+0;0",
        "aff_campus_unique": "Minneapolis;Kunshan",
        "aff_country_unique_index": "0;1+0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "8a6e89549f",
        "title": "Robust and Agnostic Learning of Conditional Distributional Treatment Effects",
        "site": "https://proceedings.mlr.press/v206/kallus23a.html",
        "author": "Nathan Kallus; Miruna Oprescu",
        "abstract": "The conditional average treatment effect (CATE) is the best measure of individual causal effects given baseline covariates. However, the CATE only captures the (conditional) average, and can overlook risks and tail events, which are important to treatment choice. In aggregate analyses, this is usually addressed by measuring the distributional treatment effect (DTE), such as differences in quantiles or tail expectations between treatment groups. Hypothetically, one can similarly fit conditional quantile regressions in each treatment group and take their difference, but this would not be robust to misspecification or provide agnostic best-in-class predictions. We provide a new robust and model-agnostic methodology for learning the conditional DTE (CDTE) for a class of problems that includes conditional quantile treatment effects, conditional super-quantile treatment effects, and conditional treatment effects on coherent risk measures given by f-divergences. Our method is based on constructing a special pseudo-outcome and regressing it on covariates using any regression learner. Our method is model-agnostic in that it can provide the best projection of CDTE onto the regression model class. Our method is robust in that even if we learn these nuisances nonparametrically at very slow rates, we can still learn CDTEs at rates that depend on the class complexity and even conduct inferences on linear projections of CDTEs. We investigate the behavior of our proposal in simulations, as well as in a case study of 401(k) eligibility effects on wealth.",
        "bibtex": "@InProceedings{pmlr-v206-kallus23a,\n  title = \t {Robust and Agnostic Learning of Conditional Distributional Treatment Effects},\n  author =       {Kallus, Nathan and Oprescu, Miruna},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6037--6060},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kallus23a/kallus23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kallus23a.html},\n  abstract = \t {The conditional average treatment effect (CATE) is the best measure of individual causal effects given baseline covariates. However, the CATE only captures the (conditional) average, and can overlook risks and tail events, which are important to treatment choice. In aggregate analyses, this is usually addressed by measuring the distributional treatment effect (DTE), such as differences in quantiles or tail expectations between treatment groups. Hypothetically, one can similarly fit conditional quantile regressions in each treatment group and take their difference, but this would not be robust to misspecification or provide agnostic best-in-class predictions. We provide a new robust and model-agnostic methodology for learning the conditional DTE (CDTE) for a class of problems that includes conditional quantile treatment effects, conditional super-quantile treatment effects, and conditional treatment effects on coherent risk measures given by f-divergences. Our method is based on constructing a special pseudo-outcome and regressing it on covariates using any regression learner. Our method is model-agnostic in that it can provide the best projection of CDTE onto the regression model class. Our method is robust in that even if we learn these nuisances nonparametrically at very slow rates, we can still learn CDTEs at rates that depend on the class complexity and even conduct inferences on linear projections of CDTEs. We investigate the behavior of our proposal in simulations, as well as in a case study of 401(k) eligibility effects on wealth.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kallus23a/kallus23a.pdf",
        "supp": "",
        "pdf_size": 608429,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13811169782187454657&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Cornell University and Cornell Tech; Cornell University and Cornell Tech",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7929a7a274",
        "title": "Root Cause Identification for Collective Anomalies in Time Series given an Acyclic Summary Causal Graph with Loops",
        "site": "https://proceedings.mlr.press/v206/assaad23a.html",
        "author": "Charles K. Assaad; Imad Ez-Zejjari; Lei Zan",
        "abstract": "This paper presents an approach for identifying the root causes of collective anomalies given observational time series and an acyclic summary causal graph which depicts an abstraction of causal relations present in a dynamic system at its normal regime. The paper first shows how the problem of root cause identification can be divided into many independent subproblems by grouping related anomalies using d-separation. Further, it shows how, under this setting, some root causes can be found directly from the graph and from the time of appearance of anomalies. Finally, it shows, how the rest of the root causes can be found by comparing direct effects in the normal and in the anomalous regime. To this end, an adjustment set for identifying direct effects is introduced. Extensive experiments conducted on both simulated and real-world datasets demonstrate the effectiveness of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v206-assaad23a,\n  title = \t {Root Cause Identification for Collective Anomalies in Time Series given an Acyclic Summary Causal Graph with Loops},\n  author =       {Assaad, Charles K. and Ez-Zejjari, Imad and Zan, Lei},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8395--8404},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/assaad23a/assaad23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/assaad23a.html},\n  abstract = \t {This paper presents an approach for identifying the root causes of collective anomalies given observational time series and an acyclic summary causal graph which depicts an abstraction of causal relations present in a dynamic system at its normal regime. The paper first shows how the problem of root cause identification can be divided into many independent subproblems by grouping related anomalies using d-separation. Further, it shows how, under this setting, some root causes can be found directly from the graph and from the time of appearance of anomalies. Finally, it shows, how the rest of the root causes can be found by comparing direct effects in the normal and in the anomalous regime. To this end, an adjustment set for identifying direct effects is introduced. Extensive experiments conducted on both simulated and real-world datasets demonstrate the effectiveness of the proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/assaad23a/assaad23a.pdf",
        "supp": "",
        "pdf_size": 182954,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4678970739687136797&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "EasyVista; EasyVista; EasyVista+Univ Grenoble Alpes, CNRS, Grenoble INP, LIG",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "EasyVista;Universite Grenoble Alpes",
        "aff_unique_dep": ";Laboratoire d'Informatique de Grenoble",
        "aff_unique_url": "https://www.easyvista.com;https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": ";UGA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Grenoble",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "France"
    },
    {
        "id": "bac691725f",
        "title": "SMCP3: Sequential Monte Carlo with Probabilistic Program Proposals",
        "site": "https://proceedings.mlr.press/v206/lew23a.html",
        "author": "Alexander K. Lew; George Matheos; Tan Zhi-Xuan; Matin Ghavamizadeh; Nishad Gothoskar; Stuart Russell; Vikash K. Mansinghka",
        "abstract": "This paper introduces SMCP3, a method for automatically implementing custom sequential Monte Carlo samplers for inference in probabilistic programs. Unlike particle filters and resample-move SMC (Gilks and Berzuini, 2001), SMCP3 algorithms can improve the quality of samples and weights using pairs of Markov proposal kernels that are also specified by probabilistic programs. Unlike Del Moral et al. (2006b), these proposals can themselves be complex probabilistic computations that generate auxiliary variables, apply deterministic transformations, and lack tractable marginal densities. This paper also contributes an efficient implementation in Gen that eliminates the need to manually derive incremental importance weights. SMCP3 thus simultaneously expands the design space that can be explored by SMC practitioners and reduces the implementation effort. SMCP3 is illustrated using applications to 3D object tracking, state-space modeling, and data clustering, showing that SMCP3 methods can simultaneously improve the quality and reduce the cost of marginal likelihood estimation and posterior inference.",
        "bibtex": "@InProceedings{pmlr-v206-lew23a,\n  title = \t {SMCP3: Sequential Monte Carlo with Probabilistic Program Proposals},\n  author =       {Lew, Alexander K. and Matheos, George and Zhi-Xuan, Tan and Ghavamizadeh, Matin and Gothoskar, Nishad and Russell, Stuart and Mansinghka, Vikash K.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7061--7088},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lew23a/lew23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lew23a.html},\n  abstract = \t {This paper introduces SMCP3, a method for automatically implementing custom sequential Monte Carlo samplers for inference in probabilistic programs. Unlike particle filters and resample-move SMC (Gilks and Berzuini, 2001), SMCP3 algorithms can improve the quality of samples and weights using pairs of Markov proposal kernels that are also specified by probabilistic programs. Unlike Del Moral et al. (2006b), these proposals can themselves be complex probabilistic computations that generate auxiliary variables, apply deterministic transformations, and lack tractable marginal densities. This paper also contributes an efficient implementation in Gen that eliminates the need to manually derive incremental importance weights. SMCP3 thus simultaneously expands the design space that can be explored by SMC practitioners and reduces the implementation effort. SMCP3 is illustrated using applications to 3D object tracking, state-space modeling, and data clustering, showing that SMCP3 methods can simultaneously improve the quality and reduce the cost of marginal likelihood estimation and posterior inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lew23a/lew23a.pdf",
        "supp": "",
        "pdf_size": 1526683,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15134991906803191351&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ebf0ae5995",
        "title": "Safe Sequential Testing and Effect Estimation in Stratified Count Data",
        "site": "https://proceedings.mlr.press/v206/turner23a.html",
        "author": "Rosanne Turner; Peter Grunwald",
        "abstract": "Sequential decision making significantly speeds up research and is more cost-effective compared to fixed-n methods. We present a method for sequential decision making for stratified count data that retains Type-I error guarantee or false discovery rate under optional stopping, using e-variables. We invert the method to construct stratified anytime-valid confidence sequences, where cross-talk between subpopulations in the data can be allowed during data collection to improve power. Finally, we combine information collected in separate subpopulations through pseudo-Bayesian averaging and switching to create effective estimates for the minimal, mean and maximal treatment effects in the subpopulations.",
        "bibtex": "@InProceedings{pmlr-v206-turner23a,\n  title = \t {Safe Sequential Testing and Effect Estimation in Stratified Count Data},\n  author =       {Turner, Rosanne and Grunwald, Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4880--4893},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/turner23a/turner23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/turner23a.html},\n  abstract = \t {Sequential decision making significantly speeds up research and is more cost-effective compared to fixed-n methods. We present a method for sequential decision making for stratified count data that retains Type-I error guarantee or false discovery rate under optional stopping, using e-variables. We invert the method to construct stratified anytime-valid confidence sequences, where cross-talk between subpopulations in the data can be allowed during data collection to improve power. Finally, we combine information collected in separate subpopulations through pseudo-Bayesian averaging and switching to create effective estimates for the minimal, mean and maximal treatment effects in the subpopulations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/turner23a/turner23a.pdf",
        "supp": "",
        "pdf_size": 2047734,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14248062316903449636&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII",
        "gs_version_total": 8,
        "aff": "CWI, UMC Utrecht; CWI, Leiden University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Centrum Wiskunde & Informatica;Leiden University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cwi.nl;https://www.universiteitleiden.nl",
        "aff_unique_abbr": "CWI;LU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Leiden",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "e85bd768d6",
        "title": "Sample Complexity of Distinguishing Cause from Effect",
        "site": "https://proceedings.mlr.press/v206/acharya23b.html",
        "author": "Jayadev Acharya; Sourbh Bhadane; Arnab Bhattacharyya; Saravanan Kandasamy; Ziteng Sun",
        "abstract": "We study the sample complexity of causal structure learning on a two-variable system with observational and experimental data. Specifically, for two variables $X$ and $Y$, we consider the classical scenario where either $X$ causes $Y$, $Y$ causes $X$, or there is an unmeasured confounder between $X$ and $Y$. Let $m_1$ be the number of observational samples of $(X,Y)$, and let $m_2$ be the number of interventional samples where either $X$ or $Y$ has been subject to an external intervention. We show that if $X$ and $Y$ are over a finite domain of size $k$ and are significantly correlated, the minimum $m_2$ needed is sublinear in $k$. Moreover, as $m_1$ grows, the minimum $m_2$ needed to identify the causal structure decreases. In fact, we can give a tight characterization of the tradeoff between $m_1$ and $m_2$ when $m_1 = O(k)$ or is sufficiently large. We build upon techniques for closeness testing when $m_1$ is small (e.g., sublinear in $k$), and for non-parametric density estimation when $m_2$ is large. Our hardness results are based on carefully constructing causal models whose marginal and interventional distributions form hard instances of canonical results on property testing.",
        "bibtex": "@InProceedings{pmlr-v206-acharya23b,\n  title = \t {Sample Complexity of Distinguishing Cause from Effect},\n  author =       {Acharya, Jayadev and Bhadane, Sourbh and Bhattacharyya, Arnab and Kandasamy, Saravanan and Sun, Ziteng},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10487--10504},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/acharya23b/acharya23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/acharya23b.html},\n  abstract = \t {We study the sample complexity of causal structure learning on a two-variable system with observational and experimental data. Specifically, for two variables $X$ and $Y$, we consider the classical scenario where either $X$ causes $Y$, $Y$ causes $X$, or there is an unmeasured confounder between $X$ and $Y$. Let $m_1$ be the number of observational samples of $(X,Y)$, and let $m_2$ be the number of interventional samples where either $X$ or $Y$ has been subject to an external intervention. We show that if $X$ and $Y$ are over a finite domain of size $k$ and are significantly correlated, the minimum $m_2$ needed is sublinear in $k$. Moreover, as $m_1$ grows, the minimum $m_2$ needed to identify the causal structure decreases. In fact, we can give a tight characterization of the tradeoff between $m_1$ and $m_2$ when $m_1 = O(k)$ or is sufficiently large. We build upon techniques for closeness testing when $m_1$ is small (e.g., sublinear in $k$), and for non-parametric density estimation when $m_2$ is large. Our hardness results are based on carefully constructing causal models whose marginal and interventional distributions form hard instances of canonical results on property testing.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/acharya23b/acharya23b.pdf",
        "supp": "",
        "pdf_size": 360378,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11167302056933150902&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Cornell University; Cornell University; National University of Singapore; Cornell University; Google Research",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Cornell University;National University of Singapore;Google",
        "aff_unique_dep": ";;Google Research",
        "aff_unique_url": "https://www.cornell.edu;https://www.nus.edu.sg;https://research.google",
        "aff_unique_abbr": "Cornell;NUS;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "fcdb8022e9",
        "title": "Sample Complexity of Kernel-Based Q-Learning",
        "site": "https://proceedings.mlr.press/v206/yeh23a.html",
        "author": "Sing-Yuan Yeh; Fu-Chieh Chang; Chang-Wei Yueh; Pei-Yuan Wu; Alberto Bernacchia; Sattar Vakili",
        "abstract": "Modern reinforcement learning (RL) often faces an enormous state-action space. Existing analytical results are typically for settings with a small number of state-actions, or simple models such as linearly modeled Q functions. To derive statistically efficient RL policies handling large state-action spaces, with more general Q functions, some recent works have considered nonlinear function approximation using kernel ridge regression. In this work, we derive sample complexities for kernel based Q-learning when a generative model exists. We propose a non-parametric Q-learning algorithm which finds an $\\varepsilon$-optimal policy in an arbitrarily large scale discounted MDP. The sample complexity of the proposed algorithm is order optimal with respect to $\\varepsilon$ and the complexity of the kernel (in terms of its information gain). To the best of our knowledge, this is the first result showing a finite sample complexity under such a general model.",
        "bibtex": "@InProceedings{pmlr-v206-yeh23a,\n  title = \t {Sample Complexity of Kernel-Based Q-Learning},\n  author =       {Yeh, Sing-Yuan and Chang, Fu-Chieh and Yueh, Chang-Wei and Wu, Pei-Yuan and Bernacchia, Alberto and Vakili, Sattar},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {453--469},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yeh23a/yeh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yeh23a.html},\n  abstract = \t {Modern reinforcement learning (RL) often faces an enormous state-action space. Existing analytical results are typically for settings with a small number of state-actions, or simple models such as linearly modeled Q functions. To derive statistically efficient RL policies handling large state-action spaces, with more general Q functions, some recent works have considered nonlinear function approximation using kernel ridge regression. In this work, we derive sample complexities for kernel based Q-learning when a generative model exists. We propose a non-parametric Q-learning algorithm which finds an $\\varepsilon$-optimal policy in an arbitrarily large scale discounted MDP. The sample complexity of the proposed algorithm is order optimal with respect to $\\varepsilon$ and the complexity of the kernel (in terms of its information gain). To the best of our knowledge, this is the first result showing a finite sample complexity under such a general model.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yeh23a/yeh23a.pdf",
        "supp": "",
        "pdf_size": 343093,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6246951146398732943&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a1a5d9e0a0",
        "title": "Sample Efficiency of Data Augmentation Consistency Regularization",
        "site": "https://proceedings.mlr.press/v206/yang23c.html",
        "author": "Shuo Yang; Yijun Dong; Rachel Ward; Inderjit S. Dhillon; Sujay Sanghavi; Qi Lei",
        "abstract": "Data augmentation is popular in the training of large neural networks; however, currently, theoretical understanding of the discrepancy between different algorithmic choices of leveraging augmented data remains limited. In this paper, we take a step in this direction \u2013 we first present a simple and novel analysis for linear regression with label invariant augmentations, demonstrating that data augmentation consistency (DAC) is intrinsically more efficient than empirical risk minimization on augmented data (DA-ERM). The analysis is then generalized to misspecified augmentations (i.e., augmentations that change the labels), which again demonstrates the merit of DAC over DA-ERM. Further, we extend our analysis to non-linear models (e.g., neural networks) and present generalization bounds. Finally, we perform experiments that make a clean and apples-to-apples comparison (i.e., with no extra modeling or data tweaks) between DAC and DA-ERM using CIFAR-100 and WideResNet; these together demonstrate the superior efficacy of DAC.",
        "bibtex": "@InProceedings{pmlr-v206-yang23c,\n  title = \t {Sample Efficiency of Data Augmentation Consistency Regularization},\n  author =       {Yang, Shuo and Dong, Yijun and Ward, Rachel and Dhillon, Inderjit S. and Sanghavi, Sujay and Lei, Qi},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3825--3853},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yang23c/yang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yang23c.html},\n  abstract = \t {Data augmentation is popular in the training of large neural networks; however, currently, theoretical understanding of the discrepancy between different algorithmic choices of leveraging augmented data remains limited. In this paper, we take a step in this direction \u2013 we first present a simple and novel analysis for linear regression with label invariant augmentations, demonstrating that data augmentation consistency (DAC) is intrinsically more efficient than empirical risk minimization on augmented data (DA-ERM). The analysis is then generalized to misspecified augmentations (i.e., augmentations that change the labels), which again demonstrates the merit of DAC over DA-ERM. Further, we extend our analysis to non-linear models (e.g., neural networks) and present generalization bounds. Finally, we perform experiments that make a clean and apples-to-apples comparison (i.e., with no extra modeling or data tweaks) between DAC and DA-ERM using CIFAR-100 and WideResNet; these together demonstrate the superior efficacy of DAC.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yang23c/yang23c.pdf",
        "supp": "",
        "pdf_size": 650676,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9326889985135028471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; New York University",
        "aff_domain": "utexas.edu;utexas.edu; ; ; ;nyu.edu",
        "email": "utexas.edu;utexas.edu; ; ; ;nyu.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Texas at Austin;New York University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UT Austin;NYU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "16c3dcde67",
        "title": "Sampling From a Schr\u00f6dinger Bridge",
        "site": "https://proceedings.mlr.press/v206/stromme23a.html",
        "author": "Austin Stromme",
        "abstract": "The Schr\u00f6dinger bridge is a stochastic process that finds the most likely coupling of two measures with respect to Brownian motion, and is equivalent to the popular entropically regularized optimal transport problem. Motivated by recent applications of the Schr\u00f6dinger bridge to trajectory reconstruction problems, we study the problem of sampling from a Schr\u00f6dinger bridge in high dimensions. We assume sample access to the marginals of the Schr\u00f6dinger bridge process and prove that the natural plug-in sampler achieves a fast statistical rate of estimation for the population bridge in terms of relative entropy. This sampling procedure is given by computing the entropic OT plan between samples from each marginal, and joining a draw from this plan with a Brownian bridge. We apply this result to construct a new and computationally feasible estimator that yields improved rates for entropic optimal transport map estimation.",
        "bibtex": "@InProceedings{pmlr-v206-stromme23a,\n  title = \t {Sampling From a Schr\u00f6dinger Bridge},\n  author =       {Stromme, Austin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4058--4067},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/stromme23a/stromme23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/stromme23a.html},\n  abstract = \t {The Schr\u00f6dinger bridge is a stochastic process that finds the most likely coupling of two measures with respect to Brownian motion, and is equivalent to the popular entropically regularized optimal transport problem. Motivated by recent applications of the Schr\u00f6dinger bridge to trajectory reconstruction problems, we study the problem of sampling from a Schr\u00f6dinger bridge in high dimensions. We assume sample access to the marginals of the Schr\u00f6dinger bridge process and prove that the natural plug-in sampler achieves a fast statistical rate of estimation for the population bridge in terms of relative entropy. This sampling procedure is given by computing the entropic OT plan between samples from each marginal, and joining a draw from this plan with a Brownian bridge. We apply this result to construct a new and computationally feasible estimator that yields improved rates for entropic optimal transport map estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/stromme23a/stromme23a.pdf",
        "supp": "",
        "pdf_size": 258413,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17301440607400636895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Department of EECS, Massachusetts Institute of Technology",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5e879d5813",
        "title": "Scalable Bayesian Optimization Using Vecchia Approximations of Gaussian Processes",
        "site": "https://proceedings.mlr.press/v206/jimenez23a.html",
        "author": "Felix Jimenez; Matthias Katzfuss",
        "abstract": "Bayesian optimization is a technique for optimizing black-box target functions. At the core of Bayesian optimization is a surrogate model that predicts the output of the target function at previously unseen inputs to facilitate the selection of promising input values. Gaussian processes (GPs) are commonly used as surrogate models but are known to scale poorly with the number of observations. Inducing point GP approximations can mitigate scaling issues, but may provide overly smooth estimates of the target function. In this work we adapt the Vecchia approximation, a popular GP approximation from spatial statistics, to enable scalable high-dimensional Bayesian optimization. We develop several improvements and extensions to Vecchia, including training warped GPs using mini-batch gradient descent, approximate neighbor search, and variance recalibration. We demonstrate the superior performance of Vecchia in BO using both Thompson sampling and qUCB. On several test functions and on two reinforcement-learning problems, our methods compared favorably to the state of the art, often outperforming inducing point methods and even exact GPs.",
        "bibtex": "@InProceedings{pmlr-v206-jimenez23a,\n  title = \t {Scalable Bayesian Optimization Using Vecchia Approximations of Gaussian Processes},\n  author =       {Jimenez, Felix and Katzfuss, Matthias},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1492--1512},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/jimenez23a/jimenez23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/jimenez23a.html},\n  abstract = \t {Bayesian optimization is a technique for optimizing black-box target functions. At the core of Bayesian optimization is a surrogate model that predicts the output of the target function at previously unseen inputs to facilitate the selection of promising input values. Gaussian processes (GPs) are commonly used as surrogate models but are known to scale poorly with the number of observations. Inducing point GP approximations can mitigate scaling issues, but may provide overly smooth estimates of the target function. In this work we adapt the Vecchia approximation, a popular GP approximation from spatial statistics, to enable scalable high-dimensional Bayesian optimization. We develop several improvements and extensions to Vecchia, including training warped GPs using mini-batch gradient descent, approximate neighbor search, and variance recalibration. We demonstrate the superior performance of Vecchia in BO using both Thompson sampling and qUCB. On several test functions and on two reinforcement-learning problems, our methods compared favorably to the state of the art, often outperforming inducing point methods and even exact GPs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/jimenez23a/jimenez23a.pdf",
        "supp": "",
        "pdf_size": 546493,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9904794532133235765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Texas A&M University; Texas A&M University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e14c15ba52",
        "title": "Scalable Bicriteria Algorithms for Non-Monotone Submodular Cover",
        "site": "https://proceedings.mlr.press/v206/crawford23a.html",
        "author": "Victoria Crawford",
        "abstract": "In this paper, we consider the optimization problem Submodular Cover (SC), which is to find a minimum cost subset of a ground set $U$ such that the value of a submodular function $f$ is above a threshold $\\tau$. In contrast to most existing work on SC, it is not assumed that $f$ is monotone. Two bicriteria approximation algorithms are presented for SC that, for input parameter $0 < \\epsilon < 1$, give $O( 1 / \\epsilon^2 )$ ratio to the optimal cost and ensures the function $f$ is at least $\\tau(1 - \\epsilon)/2$. A lower bound shows that under the value query model shows that no polynomial-time algorithm can ensure that $f$ is larger than $\\tau/2$. Further, the algorithms presented are scalable to large data sets, processing the ground set in a stream. Similar algorithms developed for SC also work for the related optimization problem of Submodular Maximization (KCSM). Finally, the algorithms are demonstrated to be effective in experiments involving graph cut and data summarization functions.",
        "bibtex": "@InProceedings{pmlr-v206-crawford23a,\n  title = \t {Scalable Bicriteria Algorithms for Non-Monotone Submodular Cover},\n  author =       {Crawford, Victoria},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9517--9537},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/crawford23a/crawford23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/crawford23a.html},\n  abstract = \t {In this paper, we consider the optimization problem Submodular Cover (SC), which is to find a minimum cost subset of a ground set $U$ such that the value of a submodular function $f$ is above a threshold $\\tau$. In contrast to most existing work on SC, it is not assumed that $f$ is monotone. Two bicriteria approximation algorithms are presented for SC that, for input parameter $0 < \\epsilon < 1$, give $O( 1 / \\epsilon^2 )$ ratio to the optimal cost and ensures the function $f$ is at least $\\tau(1 - \\epsilon)/2$. A lower bound shows that under the value query model shows that no polynomial-time algorithm can ensure that $f$ is larger than $\\tau/2$. Further, the algorithms presented are scalable to large data sets, processing the ground set in a stream. Similar algorithms developed for SC also work for the related optimization problem of Submodular Maximization (KCSM). Finally, the algorithms are demonstrated to be effective in experiments involving graph cut and data summarization functions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/crawford23a/crawford23a.pdf",
        "supp": "",
        "pdf_size": 4608115,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17807245364788085420&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Texas A&M University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "507f5a274c",
        "title": "Scalable Spectral Clustering with Group Fairness Constraints",
        "site": "https://proceedings.mlr.press/v206/wang23h.html",
        "author": "Ji Wang; Ding Lu; Ian Davidson; Zhaojun Bai",
        "abstract": "There are synergies of research interests and industrial efforts in modeling fairness and correcting algorithmic bias in machine learning. In this paper, we present a scalable algorithm for spectral clustering (SC) with group fairness constraints. Group fairness is also known as statistical parity where in each cluster, each protected group is represented with the same proportion as in the entirety. While FairSC algorithm (Kleindessner et al., 2019) is able to find the fairer clustering, it is compromised by high computational costs due to the algorithm deflation such that the resulting algorithm, called s-FairSC, only involves the sparse matrix-vector products and is able to fully exploit the sparsity of the fair SC model. The experimental results on the modified stochastic block model demonstrate that while it is comparable with FairSC in recovering fair clustering, s-FairSC is 12$\\times$ faster than FairSC for moderate model sizes. s-FairSC is further demonstrated to be scalable in the sense that the computational costs of s-FairSC only increase marginally compared to the SC without fairness constraints.",
        "bibtex": "@InProceedings{pmlr-v206-wang23h,\n  title = \t {Scalable Spectral Clustering with Group Fairness Constraints},\n  author =       {Wang, Ji and Lu, Ding and Davidson, Ian and Bai, Zhaojun},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6613--6629},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23h/wang23h.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23h.html},\n  abstract = \t {There are synergies of research interests and industrial efforts in modeling fairness and correcting algorithmic bias in machine learning. In this paper, we present a scalable algorithm for spectral clustering (SC) with group fairness constraints. Group fairness is also known as statistical parity where in each cluster, each protected group is represented with the same proportion as in the entirety. While FairSC algorithm (Kleindessner et al., 2019) is able to find the fairer clustering, it is compromised by high computational costs due to the algorithm deflation such that the resulting algorithm, called s-FairSC, only involves the sparse matrix-vector products and is able to fully exploit the sparsity of the fair SC model. The experimental results on the modified stochastic block model demonstrate that while it is comparable with FairSC in recovering fair clustering, s-FairSC is 12$\\times$ faster than FairSC for moderate model sizes. s-FairSC is further demonstrated to be scalable in the sense that the computational costs of s-FairSC only increase marginally compared to the SC without fairness constraints.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23h/wang23h.pdf",
        "supp": "",
        "pdf_size": 3292153,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8174202008298772525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Univ. of California, Davis; University of Kentucky; Univ. of California, Davis; Univ. of California, Davis",
        "aff_domain": "ucdavis.edu;uky.edu;ucdavis.edu;ucdavis.edu",
        "email": "ucdavis.edu;uky.edu;ucdavis.edu;ucdavis.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, Davis;University of Kentucky",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucdavis.edu;https://www.uky.edu",
        "aff_unique_abbr": "UC Davis;UK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Davis;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7c1bd9d266",
        "title": "Scalable Unbalanced Sobolev Transport for Measures on a Graph",
        "site": "https://proceedings.mlr.press/v206/le23a.html",
        "author": "Tam Le; Truyen Nguyen; Kenji Fukumizu",
        "abstract": "Optimal transport (OT) is a popular and powerful tool for comparing probability measures. However, OT suffers a few drawbacks: (i) input measures required to have the same mass, (ii) a high computational complexity, and (iii) indefiniteness which limits its applications on kernel-dependent algorithmic approaches. To tackle issues (ii)\u2013(iii), Le et al. (2022) recently proposed Sobolev transport for measures on a graph having the same total mass by leveraging the graph structure over supports. In this work, we consider measures that may have different total mass and are supported on a graph metric space. To alleviate the disadvantages (i)\u2013(iii) of OT, we propose a novel and scalable approach to extend Sobolev transport for this unbalanced setting where measures may have different total mass. We show that the proposed unbalanced Sobolev transport (UST) admits a closed-form formula for fast computation, and it is also negative definite. Additionally, we derive geometric structures for the UST and establish relations between our UST and other transport distances. We further exploit the negative definiteness to design positive definite kernels and evaluate them on various simulations to illustrate their fast computation and comparable performances against other transport baselines for unbalanced measures on a graph.",
        "bibtex": "@InProceedings{pmlr-v206-le23a,\n  title = \t {Scalable Unbalanced Sobolev Transport for Measures on a Graph},\n  author =       {Le, Tam and Nguyen, Truyen and Fukumizu, Kenji},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8521--8560},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/le23a/le23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/le23a.html},\n  abstract = \t {Optimal transport (OT) is a popular and powerful tool for comparing probability measures. However, OT suffers a few drawbacks: (i) input measures required to have the same mass, (ii) a high computational complexity, and (iii) indefiniteness which limits its applications on kernel-dependent algorithmic approaches. To tackle issues (ii)\u2013(iii), Le et al. (2022) recently proposed Sobolev transport for measures on a graph having the same total mass by leveraging the graph structure over supports. In this work, we consider measures that may have different total mass and are supported on a graph metric space. To alleviate the disadvantages (i)\u2013(iii) of OT, we propose a novel and scalable approach to extend Sobolev transport for this unbalanced setting where measures may have different total mass. We show that the proposed unbalanced Sobolev transport (UST) admits a closed-form formula for fast computation, and it is also negative definite. Additionally, we derive geometric structures for the UST and establish relations between our UST and other transport distances. We further exploit the negative definiteness to design positive definite kernels and evaluate them on various simulations to illustrate their fast computation and comparable performances against other transport baselines for unbalanced measures on a graph.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/le23a/le23a.pdf",
        "supp": "",
        "pdf_size": 1543655,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11075459031625711154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "The Institute of Statistical Mathematics\u2020; The University of Akron\u22c4; RIKEN AIP\u2021",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Institute of Statistical Mathematics;University of Akron;RIKEN",
        "aff_unique_dep": ";;Advanced Institute for Computational Science",
        "aff_unique_url": "https://www.ism.ac.jp;https://www.uakron.edu;https://www.aip.riken.jp",
        "aff_unique_abbr": "ISM;UA;RIKEN AIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "ae6968d0aa",
        "title": "Scalable marked point processes for exchangeable and non-exchangeable event sequences",
        "site": "https://proceedings.mlr.press/v206/panos23a.html",
        "author": "Aristeidis Panos; Ioannis Kosmidis; Petros Dellaportas",
        "abstract": "We adopt the interpretability offered by a parametric, Hawkes-process-inspired conditional probability mass function for the marks and apply variational inference techniques to derive a general and scalable inferential framework for marked point processes. The framework can handle both exchangeable and non-exchangeable event sequences with minimal tuning and without any pre-training. This contrasts with many parametric and non-parametric state-of-the-art methods that typically require pre-training and/or careful tuning, and can only handle exchangeable event sequences. The framework\u2019s competitive computational and predictive performance against other state-of-the-art methods are illustrated through real data experiments. Its attractiveness for large-scale applications is demonstrated through a case study involving all events occurring in an English Premier League season.",
        "bibtex": "@InProceedings{pmlr-v206-panos23a,\n  title = \t {Scalable marked point processes for exchangeable and non-exchangeable event sequences},\n  author =       {Panos, Aristeidis and Kosmidis, Ioannis and Dellaportas, Petros},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {236--252},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/panos23a/panos23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/panos23a.html},\n  abstract = \t {We adopt the interpretability offered by a parametric, Hawkes-process-inspired conditional probability mass function for the marks and apply variational inference techniques to derive a general and scalable inferential framework for marked point processes. The framework can handle both exchangeable and non-exchangeable event sequences with minimal tuning and without any pre-training. This contrasts with many parametric and non-parametric state-of-the-art methods that typically require pre-training and/or careful tuning, and can only handle exchangeable event sequences. The framework\u2019s competitive computational and predictive performance against other state-of-the-art methods are illustrated through real data experiments. Its attractiveness for large-scale applications is demonstrated through a case study involving all events occurring in an English Premier League season.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/panos23a/panos23a.pdf",
        "supp": "",
        "pdf_size": 635037,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7414226359489284227&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Cambridge; University of Warwick; Athens University of Economics and Business + The Alan Turing Institute + University College London",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+3+4",
        "aff_unique_norm": "University of Cambridge;University of Warwick;Athens University of Economics and Business;Alan Turing Institute;University College London",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.warwick.ac.uk;https://www.aueb.gr;https://www.turing.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Cambridge;Warwick;AUEB;ATI;UCL",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Cambridge;;Athens",
        "aff_country_unique_index": "0;0;1+0+0",
        "aff_country_unique": "United Kingdom;Greece"
    },
    {
        "id": "26d1a7c836",
        "title": "Score-based Quickest Change Detection for Unnormalized Models",
        "site": "https://proceedings.mlr.press/v206/wu23b.html",
        "author": "Suya Wu; Enmao Diao; Taposh Banerjee; Jie Ding; Vahid Tarokh",
        "abstract": "Classical change detection algorithms typically require modeling pre-change and post-change distributions. The calculations may not be feasible for various machine learning models because of the complexity of computing the partition functions and normalized distributions. Additionally, these methods may suffer from a lack of robustness to model mismatch and noise. In this paper, we develop a new variant of the classical Cumulative Sum (CUSUM) change detection, namely Score-based CUSUM (SCUSUM), based on Fisher divergence and the Hyv\u00e4rinen score. Our method allows the applications of the quickest change detection for unnormalized distributions. We provide a theoretical analysis of the detection delay given the constraints on false alarms. We prove the asymptotic optimality of the proposed method in some particular cases. We also provide numerical experiments to demonstrate our method\u2019s computation, performance, and robustness advantages.",
        "bibtex": "@InProceedings{pmlr-v206-wu23b,\n  title = \t {Score-based Quickest Change Detection for Unnormalized Models},\n  author =       {Wu, Suya and Diao, Enmao and Banerjee, Taposh and Ding, Jie and Tarokh, Vahid},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10546--10565},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wu23b/wu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wu23b.html},\n  abstract = \t {Classical change detection algorithms typically require modeling pre-change and post-change distributions. The calculations may not be feasible for various machine learning models because of the complexity of computing the partition functions and normalized distributions. Additionally, these methods may suffer from a lack of robustness to model mismatch and noise. In this paper, we develop a new variant of the classical Cumulative Sum (CUSUM) change detection, namely Score-based CUSUM (SCUSUM), based on Fisher divergence and the Hyv\u00e4rinen score. Our method allows the applications of the quickest change detection for unnormalized distributions. We provide a theoretical analysis of the detection delay given the constraints on false alarms. We prove the asymptotic optimality of the proposed method in some particular cases. We also provide numerical experiments to demonstrate our method\u2019s computation, performance, and robustness advantages.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wu23b/wu23b.pdf",
        "supp": "",
        "pdf_size": 8088422,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15010781839491173243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Duke University; Duke University; University of Pittsburgh; University of Minnesota Twin Cities; Duke University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "this URL",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Duke University;University of Pittsburgh;University of Minnesota",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.duke.edu;https://www.pitt.edu;https://www.minnstate.edu",
        "aff_unique_abbr": "Duke;Pitt;UMN",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Twin Cities",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "84a2a35e48",
        "title": "Second Order Path Variationals in Non-Stationary Online Learning",
        "site": "https://proceedings.mlr.press/v206/baby23a.html",
        "author": "Dheeraj Baby; Yu-Xiang Wang",
        "abstract": "We consider the problem of universal dynamic regret minimization under exp-concave and smooth losses. We show that appropriately designed Strongly Adaptive algorithms achieve a dynamic regret of $\\tilde O(d^2 n^{1/5} [\\mathcal{TV}_1(w_{1:n})]^{2/5} \\vee d^2)$, where $n$ is the time horizon and $\\mathcal{TV}_1(w_{1:n})$ a path variational based on second order differences of the comparator sequence. Such a path variational naturally encodes comparator sequences that are piece-wise linear \u2013 a powerful family that tracks a variety of non-stationarity patterns in practice (Kim et al., 2009). The aforementioned dynamic regret is shown to be optimal modulo dimension dependencies and poly-logarithmic factors of $n$. To the best of our knowledge, this path variational has not been studied in the non-stochastic online learning literature before. Our proof techniques rely on analysing the KKT conditions of the offline oracle and requires several non-trivial generalizations of the ideas in Baby and Wang (2021) where the latter work only implies an $\\tilde{O}(n^{1/3})$ regret for the current problem.",
        "bibtex": "@InProceedings{pmlr-v206-baby23a,\n  title = \t {Second Order Path Variationals in Non-Stationary Online Learning},\n  author =       {Baby, Dheeraj and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9024--9075},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/baby23a/baby23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/baby23a.html},\n  abstract = \t {We consider the problem of universal dynamic regret minimization under exp-concave and smooth losses. We show that appropriately designed Strongly Adaptive algorithms achieve a dynamic regret of $\\tilde O(d^2 n^{1/5} [\\mathcal{TV}_1(w_{1:n})]^{2/5} \\vee d^2)$, where $n$ is the time horizon and $\\mathcal{TV}_1(w_{1:n})$ a path variational based on second order differences of the comparator sequence. Such a path variational naturally encodes comparator sequences that are piece-wise linear \u2013 a powerful family that tracks a variety of non-stationarity patterns in practice (Kim et al., 2009). The aforementioned dynamic regret is shown to be optimal modulo dimension dependencies and poly-logarithmic factors of $n$. To the best of our knowledge, this path variational has not been studied in the non-stochastic online learning literature before. Our proof techniques rely on analysing the KKT conditions of the offline oracle and requires several non-trivial generalizations of the ideas in Baby and Wang (2021) where the latter work only implies an $\\tilde{O}(n^{1/3})$ regret for the current problem.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/baby23a/baby23a.pdf",
        "supp": "",
        "pdf_size": 867592,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4400617005309159016&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of California Santa Barbara; Department of Computer Science, University of California Santa Barbara",
        "aff_domain": "cs.ucsb.edu;cs.ucsb.edu",
        "email": "cs.ucsb.edu;cs.ucsb.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "99b2c0582f",
        "title": "Select and Optimize: Learning to solve large-scale TSP instances",
        "site": "https://proceedings.mlr.press/v206/cheng23a.html",
        "author": "Hanni Cheng; Haosi Zheng; Ya Cong; Weihao Jiang; Shiliang Pu",
        "abstract": "Learning-based algorithms to solve TSP are getting popular in recent years, but most existing works cannot solve very large-scale TSP instances within a limited time. To solve this problem, this paper introduces a creative and distinctive method to select and locally optimize sub-parts of a solution. Concretely, we design a novel framework to generalize a small-scale selector-and-optimizer network to large-scale TSP instances by iteratively selecting while optimizing one sub-problem. At each iteration, the running time of sub-problem sampling and selection is significantly reduced due to the full use of parallel computing. Our neural model is well-designed to exploit the characteristics of the sub-problems. Furthermore, we introduce a trick called destroy-and-repair to avoid the local minimum of the iterative algorithm from a global perspective. Extensive experiments show that our method accelerates state-of-the-art learning-based algorithms more than 2x while achieving better solution quality on large-scale TSP instances ranging in size from 200 to 20,000.",
        "bibtex": "@InProceedings{pmlr-v206-cheng23a,\n  title = \t {Select and Optimize: Learning to aolve large-scale TSP instances},\n  author =       {Cheng, Hanni and Zheng, Haosi and Cong, Ya and Jiang, Weihao and Pu, Shiliang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1219--1231},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cheng23a/cheng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cheng23a.html},\n  abstract = \t {Learning-based algorithms to solve TSP are getting popular in recent years, but most existing works cannot solve very large-scale TSP instances within a limited time. To solve this problem, this paper introduces a creative and distinctive method to select and locally optimize sub-parts of a solution. Concretely, we design a novel framework to generalize a small-scale selector-and-optimizer network to large-scale TSP instances by iteratively selecting while optimizing one sub-problem. At each iteration, the running time of sub-problem sampling and selection is significantly reduced due to the full use of parallel computing. Our neural model is well-designed to exploit the characteristics of the sub-problems. Furthermore, we introduce a trick called destroy-and-repair to avoid the local minimum of the iterative algorithm from a global perspective. Extensive experiments show that our method accelerates state-of-the-art learning-based algorithms more than 2x while achieving better solution quality on large-scale TSP instances ranging in size from 200 to 20,000.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cheng23a/cheng23a.pdf",
        "supp": "",
        "pdf_size": 1468780,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1079020369800437375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hikvision Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.hikvision.com/cn/",
        "aff_unique_abbr": "Hikvision",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "10bfd61cb5",
        "title": "Semantic Strengthening of Neuro-Symbolic Learning",
        "site": "https://proceedings.mlr.press/v206/ahmed23a.html",
        "author": "Kareem Ahmed; Kai-Wei Chang; Guy Van den Broeck",
        "abstract": "Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses maximize the probability that the neural network\u2019s predictions satisfy the underlying domain. Unfortunately, this type of probabilistic inference is often computationally infeasible. Neuro-symbolic approaches therefore commonly resort to fuzzy approximations of this probabilistic objective, sacrificing sound probabilistic semantics, or to sampling which is very seldom feasible. We approach the problem by first assuming the constraint decomposes conditioned on the features learned by the network. We iteratively strengthen our approximation, restoring the dependence between the constraints most responsible for degrading the quality of the approximation. This corresponds to computing the mutual information between pairs of constraints conditioned on the network\u2019s learned features, and may be construed as a measure of how well aligned the gradients of two distributions are. We show how to compute this efficiently for tractable circuits. We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Sudoku puzzles, observing that it improves upon the baselines while sidestepping intractability.",
        "bibtex": "@InProceedings{pmlr-v206-ahmed23a,\n  title = \t {Semantic Strengthening of Neuro-Symbolic Learning},\n  author =       {Ahmed, Kareem and Chang, Kai-Wei and Van den Broeck, Guy},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10252--10261},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ahmed23a/ahmed23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ahmed23a.html},\n  abstract = \t {Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses maximize the probability that the neural network\u2019s predictions satisfy the underlying domain. Unfortunately, this type of probabilistic inference is often computationally infeasible. Neuro-symbolic approaches therefore commonly resort to fuzzy approximations of this probabilistic objective, sacrificing sound probabilistic semantics, or to sampling which is very seldom feasible. We approach the problem by first assuming the constraint decomposes conditioned on the features learned by the network. We iteratively strengthen our approximation, restoring the dependence between the constraints most responsible for degrading the quality of the approximation. This corresponds to computing the mutual information between pairs of constraints conditioned on the network\u2019s learned features, and may be construed as a measure of how well aligned the gradients of two distributions are. We show how to compute this efficiently for tractable circuits. We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Sudoku puzzles, observing that it improves upon the baselines while sidestepping intractability.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ahmed23a/ahmed23a.pdf",
        "supp": "",
        "pdf_size": 576076,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16288784229204221844&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Department, UCLA; Computer Science Department, UCLA; Computer Science Department, UCLA",
        "aff_domain": "cs.ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "email": "cs.ucla.edu;cs.ucla.edu;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "14332a67b5",
        "title": "Semi-Verified PAC Learning from the Crowd",
        "site": "https://proceedings.mlr.press/v206/zeng23a.html",
        "author": "Shiwei Zeng; Jie Shen",
        "abstract": "We study the problem of crowdsourced PAC learning of threshold functions. This is a challenging problem and only recently have query-efficient algorithms been established under the assumption that a noticeable fraction of the workers are perfect. In this work, we investigate a more challenging case where the majority may behave adversarially and the rest behave as the Massart noise \u2013 a significant generalization of the perfectness assumption. We show that under the semi-verified model of Charikar et al. (2017), where we have (limited) access to a trusted oracle who always returns correct annotations, it is possible to PAC learn the underlying hypothesis class with a manageable amount of label queries. Moreover, we show that the labeling cost can be drastically mitigated via the more easily obtained comparison queries. Orthogonal to recent developments in semi-verified or list-decodable learning that crucially rely on data distributional assumptions, our PAC guarantee holds by exploring the wisdom of the crowd.",
        "bibtex": "@InProceedings{pmlr-v206-zeng23a,\n  title = \t {Semi-Verified PAC Learning from the Crowd},\n  author =       {Zeng, Shiwei and Shen, Jie},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {505--522},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zeng23a/zeng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zeng23a.html},\n  abstract = \t {We study the problem of crowdsourced PAC learning of threshold functions. This is a challenging problem and only recently have query-efficient algorithms been established under the assumption that a noticeable fraction of the workers are perfect. In this work, we investigate a more challenging case where the majority may behave adversarially and the rest behave as the Massart noise \u2013 a significant generalization of the perfectness assumption. We show that under the semi-verified model of Charikar et al. (2017), where we have (limited) access to a trusted oracle who always returns correct annotations, it is possible to PAC learn the underlying hypothesis class with a manageable amount of label queries. Moreover, we show that the labeling cost can be drastically mitigated via the more easily obtained comparison queries. Orthogonal to recent developments in semi-verified or list-decodable learning that crucially rely on data distributional assumptions, our PAC guarantee holds by exploring the wisdom of the crowd.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zeng23a/zeng23a.pdf",
        "supp": "",
        "pdf_size": 321555,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=289049729248450403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Stevens Institute of Technology; Stevens Institute of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "72d5b2968e",
        "title": "Sequential Gradient Descent and Quasi-Newton\u2019s Method for Change-Point Analysis",
        "site": "https://proceedings.mlr.press/v206/zhang23b.html",
        "author": "Xianyang Zhang; Trisha Dawn",
        "abstract": "One common approach to detecting change-points is minimizing a cost function over possible numbers and locations of change-points. The framework includes several well-established procedures, such as the penalized likelihood and minimum description length. Such an approach requires finding the cost value repeatedly over different segments of the data set, which can be time-consuming when (i) the data sequence is long and (ii) obtaining the cost value involves solving a non-trivial optimization problem. This paper introduces a new sequential updating method (SE) to find the cost value effectively. The core idea is to update the cost value using the information from previous steps without re-optimizing the objective function. The new method is applied to change-point detection in generalized linear models and penalized regression. Numerical studies show that the new approach can be orders of magnitude faster than the Pruned Exact Linear Time (PELT) method without sacrificing estimation accuracy.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23b,\n  title = \t {Sequential Gradient Descent and Quasi-Newton\u2019s Method for Change-Point Analysis},\n  author =       {Zhang, Xianyang and Dawn, Trisha},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1129--1143},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23b/zhang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23b.html},\n  abstract = \t {One common approach to detecting change-points is minimizing a cost function over possible numbers and locations of change-points. The framework includes several well-established procedures, such as the penalized likelihood and minimum description length. Such an approach requires finding the cost value repeatedly over different segments of the data set, which can be time-consuming when (i) the data sequence is long and (ii) obtaining the cost value involves solving a non-trivial optimization problem. This paper introduces a new sequential updating method (SE) to find the cost value effectively. The core idea is to update the cost value using the information from previous steps without re-optimizing the objective function. The new method is applied to change-point detection in generalized linear models and penalized regression. Numerical studies show that the new approach can be orders of magnitude faster than the Pruned Exact Linear Time (PELT) method without sacrificing estimation accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23b/zhang23b.pdf",
        "supp": "",
        "pdf_size": 388916,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8787559338484915152&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Texas A&M University; Texas A&M University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f0d4a24e07",
        "title": "Simulator-Based Inference with WALDO: Confidence Regions by Leveraging Prediction Algorithms and Posterior Estimators for Inverse Problems",
        "site": "https://proceedings.mlr.press/v206/masserano23a.html",
        "author": "Luca Masserano; Tommaso Dorigo; Rafael Izbicki; Mikael Kuusela; Ann Lee",
        "abstract": "Prediction algorithms, such as deep neural networks (DNNs), are used in many domain sciences to directly estimate internal parameters of interest in simulator-based models, especially in settings where the observations include images or complex high-dimensional data. In parallel, modern neural density estimators, such as normalizing flows, are becoming increasingly popular for uncertainty quantification, especially when both parameters and observations are high-dimensional. However, parameter inference is an inverse problem and not a prediction task; thus, an open challenge is to construct conditionally valid and precise confidence regions, with a guaranteed probability of covering the true parameters of the data-generating process, no matter what the (unknown) parameter values are, and without relying on large-sample theory. Many simulator-based inference (SBI) methods are indeed known to produce biased or overly confident parameter regions, yielding misleading uncertainty estimates. This paper presents WALDO, a novel method to construct confidence regions with finite-sample conditional validity by leveraging prediction algorithms or posterior estimators that are currently widely adopted in SBI. WALDO reframes the well-known Wald test statistic, and uses a computationally efficient regression-based machinery for classical Neyman inversion of hypothesis tests. We apply our method to a recent high-energy physics problem, where prediction with DNNs has previously led to estimates with prediction bias. We also illustrate how our approach can correct overly confident posterior regions computed with normalizing flows.",
        "bibtex": "@InProceedings{pmlr-v206-masserano23a,\n  title = \t {Simulator-Based Inference with WALDO: Confidence Regions by Leveraging Prediction Algorithms and Posterior Estimators for Inverse Problems},\n  author =       {Masserano, Luca and Dorigo, Tommaso and Izbicki, Rafael and Kuusela, Mikael and Lee, Ann},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2960--2974},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/masserano23a/masserano23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/masserano23a.html},\n  abstract = \t {Prediction algorithms, such as deep neural networks (DNNs), are used in many domain sciences to directly estimate internal parameters of interest in simulator-based models, especially in settings where the observations include images or complex high-dimensional data. In parallel, modern neural density estimators, such as normalizing flows, are becoming increasingly popular for uncertainty quantification, especially when both parameters and observations are high-dimensional. However, parameter inference is an inverse problem and not a prediction task; thus, an open challenge is to construct conditionally valid and precise confidence regions, with a guaranteed probability of covering the true parameters of the data-generating process, no matter what the (unknown) parameter values are, and without relying on large-sample theory. Many simulator-based inference (SBI) methods are indeed known to produce biased or overly confident parameter regions, yielding misleading uncertainty estimates. This paper presents WALDO, a novel method to construct confidence regions with finite-sample conditional validity by leveraging prediction algorithms or posterior estimators that are currently widely adopted in SBI. WALDO reframes the well-known Wald test statistic, and uses a computationally efficient regression-based machinery for classical Neyman inversion of hypothesis tests. We apply our method to a recent high-energy physics problem, where prediction with DNNs has previously led to estimates with prediction bias. We also illustrate how our approach can correct overly confident posterior regions computed with normalizing flows.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/masserano23a/masserano23a.pdf",
        "supp": "",
        "pdf_size": 7795385,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12004320686932413617&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics & Data Science, Carnegie Mellon University + NSF AI Planning Institute for Data-Driven Discovery in Physics, Carnegie Mellon University; INFN, Sezione di Padova; Department of Statistics, Federal University of S\u00e3o Carlos; Department of Statistics & Data Science, Carnegie Mellon University + NSF AI Planning Institute for Data-Driven Discovery in Physics, Carnegie Mellon University; Department of Statistics & Data Science, Carnegie Mellon University + NSF AI Planning Institute for Data-Driven Discovery in Physics, Carnegie Mellon University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;1;2;0+0;0+0",
        "aff_unique_norm": "Carnegie Mellon University;Istituto Nazionale di Fisica Nucleare;Federal University of S\u00e3o Carlos",
        "aff_unique_dep": "Department of Statistics & Data Science;Sezione di Padova;Department of Statistics",
        "aff_unique_url": "https://www.cmu.edu;https://www.infn.it;https://www.ufscar.br",
        "aff_unique_abbr": "CMU;INFN;UFSCar",
        "aff_campus_unique_index": ";1;;",
        "aff_campus_unique": ";Padova",
        "aff_country_unique_index": "0+0;1;2;0+0;0+0",
        "aff_country_unique": "United States;Italy;Brazil"
    },
    {
        "id": "05a56065e5",
        "title": "Singular Value Representation: A New Graph Perspective On Neural Networks",
        "site": "https://proceedings.mlr.press/v206/meller23a.html",
        "author": "Dan Meller; Nicolas Berkouk",
        "abstract": "We introduce the Singular Value Representation (SVR), a new method to represent the internal state of neural networks using SVD factorization of the weights. This construction yields a new weighted graph connecting what we call spectral neurons, that correspond to specific activation patterns of classical neurons. We derive a precise statistical framework to discriminate meaningful connections between spectral neurons for fully connected and convolutional layers. To demonstrate the usefulness of our approach for machine learning research, we highlight two discoveries we made using the SVR. First, we highlight the emergence of a dominant connection in VGG networks that spans multiple deep layers. Second, we witness, without relying on any input data, that batch normalization can induce significant connections between near-kernels of deep layers, leading to a remarkable spontaneous sparsification phenomenon. code: a python implementation of the svr can be found at https://github.com/danmlr/svr.",
        "bibtex": "@InProceedings{pmlr-v206-meller23a,\n  title = \t {Singular Value Representation: A New Graph Perspective On Neural Networks},\n  author =       {Meller, Dan and Berkouk, Nicolas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3353--3369},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/meller23a/meller23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/meller23a.html},\n  abstract = \t {We introduce the Singular Value Representation (SVR), a new method to represent the internal state of neural networks using SVD factorization of the weights. This construction yields a new weighted graph connecting what we call spectral neurons, that correspond to specific activation patterns of classical neurons. We derive a precise statistical framework to discriminate meaningful connections between spectral neurons for fully connected and convolutional layers. To demonstrate the usefulness of our approach for machine learning research, we highlight two discoveries we made using the SVR. First, we highlight the emergence of a dominant connection in VGG networks that spans multiple deep layers. Second, we witness, without relying on any input data, that batch normalization can induce significant connections between near-kernels of deep layers, leading to a remarkable spontaneous sparsification phenomenon. code: a python implementation of the svr can be found at https://github.com/danmlr/svr.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/meller23a/meller23a.pdf",
        "supp": "",
        "pdf_size": 3949153,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2990361474180137306&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "\u00b4Ecole Polytechnique; EPFL - Topology and Neuroscience Lab+EPFL - Topology and Neuroscience Lab",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/danmlr/svr",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+1",
        "aff_unique_norm": "Ecole Polytechnique;EPFL",
        "aff_unique_dep": ";Topology and Neuroscience Lab",
        "aff_unique_url": "https://www.polytechnique.edu;https://www.epfl.ch",
        "aff_unique_abbr": "Polytechnique;EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+1",
        "aff_country_unique": "France;Switzerland"
    },
    {
        "id": "0267f057e8",
        "title": "Smoothly Giving up: Robustness for Simple Models",
        "site": "https://proceedings.mlr.press/v206/sypherd23a.html",
        "author": "Tyler Sypherd; Nathaniel Stromberg; Richard Nock; Visar Berisha; Lalitha Sankar",
        "abstract": "There is a growing need for models that are interpretable and have reduced energy/computational cost (e.g., in health care analytics and federated learning). Examples of algorithms to train such models include logistic regression and boosting. However, one challenge facing these algorithms is that they provably suffer from label noise; this has been attributed to the joint interaction between oft-used convex loss functions and simpler hypothesis classes, resulting in too much emphasis being placed on outliers. In this work, we use the margin-based $\\alpha$-loss, which continuously tunes between canonical convex and quasi-convex losses, to robustly train simple models. We show that the $\\alpha$ hyperparameter smoothly introduces non-convexity and offers the benefit of \u201cgiving up\u201d on noisy training examples. We also provide results on the Long-Servedio dataset for boosting and a COVID-19 survey dataset for logistic regression, highlighting the efficacy of our approach across multiple relevant domains.",
        "bibtex": "@InProceedings{pmlr-v206-sypherd23a,\n  title = \t {Smoothly Giving up: Robustness for Simple Models},\n  author =       {Sypherd, Tyler and Stromberg, Nathaniel and Nock, Richard and Berisha, Visar and Sankar, Lalitha},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5376--5410},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sypherd23a/sypherd23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sypherd23a.html},\n  abstract = \t {There is a growing need for models that are interpretable and have reduced energy/computational cost (e.g., in health care analytics and federated learning). Examples of algorithms to train such models include logistic regression and boosting. However, one challenge facing these algorithms is that they provably suffer from label noise; this has been attributed to the joint interaction between oft-used convex loss functions and simpler hypothesis classes, resulting in too much emphasis being placed on outliers. In this work, we use the margin-based $\\alpha$-loss, which continuously tunes between canonical convex and quasi-convex losses, to robustly train simple models. We show that the $\\alpha$ hyperparameter smoothly introduces non-convexity and offers the benefit of \u201cgiving up\u201d on noisy training examples. We also provide results on the Long-Servedio dataset for boosting and a COVID-19 survey dataset for logistic regression, highlighting the efficacy of our approach across multiple relevant domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sypherd23a/sypherd23a.pdf",
        "supp": "",
        "pdf_size": 28316747,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7251675816355995996&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Arizona State University; Arizona State University; Google Research; Arizona State University; Arizona State University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Arizona State University;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.asu.edu;https://research.google",
        "aff_unique_abbr": "ASU;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "50824745d0",
        "title": "SoundSynp: Sound Source Detection from Raw Waveforms with Multi-Scale Synperiodic Filterbanks",
        "site": "https://proceedings.mlr.press/v206/he23c.html",
        "author": "Yuhang He; Andrew Markham",
        "abstract": "We propose synperiodic filter banks, a novel multi-scale learnable filter bank construction strategy that all filters are synchronized by their rotating periodicity. By synchronizing in a certain periodicity, we naturally get filters whose temporal length are reduced if they carry higher frequency response, and vice versa. Such filters internally maintain a better time-frequency resolution trade-off. By further alternating the periodicity, we can easily obtain a group of synperiodic filter bank (we call synperiodic filter banks), where filters of same frequency response in different groups differ in temporal length. Convolving these filter banks with sound raw waveform achieves multi-scale perception in time domain. Moreover, applying the same filter banks to recursively process the 2x-downsampled waveform enables multi-scale perception in the frequency domain. Benefiting from the multi-scale perception in both time and frequency domains, our proposed synperiodic filter banks learn multi-scale time-frequency representation in a data-driven way. Experiments on both sound source direction of arrival (DoA) and physical location detection task show the superiority of synperiodic filter banks.",
        "bibtex": "@InProceedings{pmlr-v206-he23c,\n  title = \t {SoundSynp: Sound Source Detection from Raw Waveforms with Multi-Scale Synperiodic Filterbanks},\n  author =       {He, Yuhang and Markham, Andrew},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9010--9023},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/he23c/he23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/he23c.html},\n  abstract = \t {We propose synperiodic filter banks, a novel multi-scale learnable filter bank construction strategy that all filters are synchronized by their rotating periodicity. By synchronizing in a certain periodicity, we naturally get filters whose temporal length are reduced if they carry higher frequency response, and vice versa. Such filters internally maintain a better time-frequency resolution trade-off. By further alternating the periodicity, we can easily obtain a group of synperiodic filter bank (we call synperiodic filter banks), where filters of same frequency response in different groups differ in temporal length. Convolving these filter banks with sound raw waveform achieves multi-scale perception in time domain. Moreover, applying the same filter banks to recursively process the 2x-downsampled waveform enables multi-scale perception in the frequency domain. Benefiting from the multi-scale perception in both time and frequency domains, our proposed synperiodic filter banks learn multi-scale time-frequency representation in a data-driven way. Experiments on both sound source direction of arrival (DoA) and physical location detection task show the superiority of synperiodic filter banks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/he23c/he23c.pdf",
        "supp": "",
        "pdf_size": 1372627,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14002348663677877697&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "Department of Computer Science, University of Oxford, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom",
        "aff_domain": "cs.ox.ac.uk;cs.ox.ac.uk",
        "email": "cs.ox.ac.uk;cs.ox.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "a39a8afdd4",
        "title": "Sparse Bayesian optimization",
        "site": "https://proceedings.mlr.press/v206/liu23b.html",
        "author": "Sulin Liu; Qing Feng; David Eriksson; Benjamin Letham; Eytan Bakshy",
        "abstract": "Bayesian optimization (BO) is a powerful approach to sample-efficient optimization of black-box objective functions. However, the application of BO to areas such as recommendation systems often requires taking the interpretability and simplicity of the configurations into consideration, a setting that has not been previously studied in the BO literature. To make BO applicable in this setting, we present several regularization-based approaches that allow us to discover sparse and more interpretable configurations. We propose a novel differentiable relaxation based on homotopy continuation that makes it possible to target sparsity by working directly with $L_0$ regularization. We identify failure modes for regularized BO and develop a hyperparameter-free method, sparsity exploring Bayesian optimization (SEBO) that seeks to simultaneously maximize a target objective and sparsity. SEBO and methods based on fixed regularization are evaluated on synthetic and real-world problems, and we show that we are able to efficiently optimize for sparsity.",
        "bibtex": "@InProceedings{pmlr-v206-liu23b,\n  title = \t {Sparse Bayesian optimization},\n  author =       {Liu, Sulin and Feng, Qing and Eriksson, David and Letham, Benjamin and Bakshy, Eytan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3754--3774},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/liu23b/liu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/liu23b.html},\n  abstract = \t {Bayesian optimization (BO) is a powerful approach to sample-efficient optimization of black-box objective functions. However, the application of BO to areas such as recommendation systems often requires taking the interpretability and simplicity of the configurations into consideration, a setting that has not been previously studied in the BO literature. To make BO applicable in this setting, we present several regularization-based approaches that allow us to discover sparse and more interpretable configurations. We propose a novel differentiable relaxation based on homotopy continuation that makes it possible to target sparsity by working directly with $L_0$ regularization. We identify failure modes for regularized BO and develop a hyperparameter-free method, sparsity exploring Bayesian optimization (SEBO) that seeks to simultaneously maximize a target objective and sparsity. SEBO and methods based on fixed regularization are evaluated on synthetic and real-world problems, and we show that we are able to efficiently optimize for sparsity.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/liu23b/liu23b.pdf",
        "supp": "",
        "pdf_size": 3256186,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13585809575552290679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Princeton University; Meta; Meta; Meta; Meta",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Princeton University;Meta",
        "aff_unique_dep": ";Meta Platforms, Inc.",
        "aff_unique_url": "https://www.princeton.edu;https://meta.com",
        "aff_unique_abbr": "Princeton;Meta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bea3d1d2ab",
        "title": "Sparse Spectral Bayesian Permanental Process with Generalized Kernel",
        "site": "https://proceedings.mlr.press/v206/sellier23a.html",
        "author": "Jeremy Sellier; Petros Dellaportas",
        "abstract": "We introduce a novel scheme for Bayesian inference on permanental processes which models the Poisson intensity as the square of a Gaussian process. Combining generalized kernels and a Fourier features-based representation of the Gaussian process with a Laplace approximation to the posterior, we achieve a fast and efficient inference that does not require numerical integration over the input space, allows kernel design and scales linearly with the number of events. Our method builds and improves upon the state-of-theart Laplace Bayesian point process benchmark of Walder and Bishop (2017), demonstrated on both synthetic, real-world temporal and large spatial data sets.",
        "bibtex": "@InProceedings{pmlr-v206-sellier23a,\n  title = \t {Sparse Spectral Bayesian Permanental Process with Generalized Kernel},\n  author =       {Sellier, Jeremy and Dellaportas, Petros},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2769--2791},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sellier23a/sellier23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sellier23a.html},\n  abstract = \t {We introduce a novel scheme for Bayesian inference on permanental processes which models the Poisson intensity as the square of a Gaussian process. Combining generalized kernels and a Fourier features-based representation of the Gaussian process with a Laplace approximation to the posterior, we achieve a fast and efficient inference that does not require numerical integration over the input space, allows kernel design and scales linearly with the number of events. Our method builds and improves upon the state-of-theart Laplace Bayesian point process benchmark of Walder and Bishop (2017), demonstrated on both synthetic, real-world temporal and large spatial data sets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sellier23a/sellier23a.pdf",
        "supp": "",
        "pdf_size": 1386412,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7817957584263595971&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Statistical Science, University College London, UK; Department of Statistical Science, University College London, UK+Department of Statistics, Univ. of Econ. and Business, Athens, Greece+The Alan Turing Institute, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1+2",
        "aff_unique_norm": "University College London;University of Economics and Business;Alan Turing Institute",
        "aff_unique_dep": "Department of Statistical Science;Department of Statistics;",
        "aff_unique_url": "https://www.ucl.ac.uk;;https://www.turing.ac.uk",
        "aff_unique_abbr": "UCL;;ATI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Athens",
        "aff_country_unique_index": "0;0+1+0",
        "aff_country_unique": "United Kingdom;Greece"
    },
    {
        "id": "522d160302",
        "title": "Sparsity-Inducing Categorical Prior Improves Robustness of the Information Bottleneck",
        "site": "https://proceedings.mlr.press/v206/samaddar23a.html",
        "author": "Anirban Samaddar; Sandeep Madireddy; Prasanna Balaprakash; Taps Maiti; Gustavo de los Campos; Ian Fischer",
        "abstract": "The information bottleneck framework provides a systematic approach to learning representations that compress nuisance information in the input and extract semantically meaningful information about predictions. However, the choice of a prior distribution that fixes the dimensionality across all the data can restrict the flexibility of this approach for learning robust representations. We present a novel sparsity-inducing spike-slab categorical prior that uses sparsity as a mechanism to provide the flexibility that allows each data point to learn its own dimension distribution. In addition, it provides a mechanism for learning a joint distribution of the latent variable and the sparsity, and hence it can account for the complete uncertainty in the latent space. Through a series of experiments using in-distribution and out-of-distribution learning scenarios on the MNIST, CIFAR-10, and ImageNet data, we show that the proposed approach improves accuracy and robustness compared to traditional fixed-dimensional priors, as well as other sparsity induction mechanisms for latent variable models proposed in the literature.",
        "bibtex": "@InProceedings{pmlr-v206-samaddar23a,\n  title = \t {Sparsity-Inducing Categorical Prior Improves Robustness of the Information Bottleneck},\n  author =       {Samaddar, Anirban and Madireddy, Sandeep and Balaprakash, Prasanna and Maiti, Taps and de los Campos, Gustavo and Fischer, Ian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10207--10222},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/samaddar23a/samaddar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/samaddar23a.html},\n  abstract = \t {The information bottleneck framework provides a systematic approach to learning representations that compress nuisance information in the input and extract semantically meaningful information about predictions. However, the choice of a prior distribution that fixes the dimensionality across all the data can restrict the flexibility of this approach for learning robust representations. We present a novel sparsity-inducing spike-slab categorical prior that uses sparsity as a mechanism to provide the flexibility that allows each data point to learn its own dimension distribution. In addition, it provides a mechanism for learning a joint distribution of the latent variable and the sparsity, and hence it can account for the complete uncertainty in the latent space. Through a series of experiments using in-distribution and out-of-distribution learning scenarios on the MNIST, CIFAR-10, and ImageNet data, we show that the proposed approach improves accuracy and robustness compared to traditional fixed-dimensional priors, as well as other sparsity induction mechanisms for latent variable models proposed in the literature.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/samaddar23a/samaddar23a.pdf",
        "supp": "",
        "pdf_size": 11184066,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2879164098868372571&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Michigan State University; Argonne National Laboratory; Argonne National Laboratory; Michigan State University; Michigan State University; Google Research",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;0;2",
        "aff_unique_norm": "Michigan State University;Argonne National Laboratory;Google",
        "aff_unique_dep": ";;Google Research",
        "aff_unique_url": "https://www.msu.edu;https://www.anl.gov;https://research.google",
        "aff_unique_abbr": "MSU;ANL;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b2e74e8572",
        "title": "Spectral Augmentations for Graph Contrastive Learning",
        "site": "https://proceedings.mlr.press/v206/ghose23a.html",
        "author": "Amur Ghose; Yingxue Zhang; Jianye Hao; Mark Coates",
        "abstract": "Contrastive learning has emerged as a premier method for learning representations with or without supervision. Recent studies have shown its utility in graph representation learning for pre-training. Despite successes, the understanding of how to design effective graph augmentations that can capture structural properties common to many different types of downstream graphs remains incomplete. We propose a set of well-motivated graph transformation operations derived via graph spectral analysis to provide a bank of candidates when constructing augmentations for a graph contrastive objective, enabling contrastive learning to capture useful structural representation from pre-training graph datasets. We first present a spectral graph cropping augmentation that involves filtering nodes by applying thresholds to the eigenvalues of the leading Laplacian eigenvectors. Our second novel augmentation reorders the graph frequency components in a structural Laplacian-derived position graph embedding. Further, we introduce a method that leads to improved views of local subgraphs by performing alignment via global random walk embeddings. Our experimental results indicate consistent improvements in out-of-domain graph data transfer compared to state-of-the-art graph contrastive learning methods, shedding light on how to design a graph learner that is able to learn structural properties common to diverse graph types.",
        "bibtex": "@InProceedings{pmlr-v206-ghose23a,\n  title = \t {Spectral Augmentations for Graph Contrastive Learning},\n  author =       {Ghose, Amur and Zhang, Yingxue and Hao, Jianye and Coates, Mark},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11213--11266},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ghose23a/ghose23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ghose23a.html},\n  abstract = \t {Contrastive learning has emerged as a premier method for learning representations with or without supervision. Recent studies have shown its utility in graph representation learning for pre-training. Despite successes, the understanding of how to design effective graph augmentations that can capture structural properties common to many different types of downstream graphs remains incomplete. We propose a set of well-motivated graph transformation operations derived via graph spectral analysis to provide a bank of candidates when constructing augmentations for a graph contrastive objective, enabling contrastive learning to capture useful structural representation from pre-training graph datasets. We first present a spectral graph cropping augmentation that involves filtering nodes by applying thresholds to the eigenvalues of the leading Laplacian eigenvectors. Our second novel augmentation reorders the graph frequency components in a structural Laplacian-derived position graph embedding. Further, we introduce a method that leads to improved views of local subgraphs by performing alignment via global random walk embeddings. Our experimental results indicate consistent improvements in out-of-domain graph data transfer compared to state-of-the-art graph contrastive learning methods, shedding light on how to design a graph learner that is able to learn structural properties common to diverse graph types.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ghose23a/ghose23a.pdf",
        "supp": "",
        "pdf_size": 3135397,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9292794717077317618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "af29912d5d",
        "title": "Spread Flows for Manifold Modelling",
        "site": "https://proceedings.mlr.press/v206/zhang23k.html",
        "author": "Mingtian Zhang; Yitong Sun; Chen Zhang; Steven Mcdonagh",
        "abstract": "Flow-based models typically define a latent space with dimensionality identical to the observational space. In many problems, however, the data does not populate the full ambient data space that they natively reside in, rather inhabiting a lower-dimensional manifold. In such scenarios, flow-based models are unable to represent data structures exactly as their densities will always have support off the data manifold, potentially resulting in degradation of model performance. To address this issue, we propose to learn a manifold prior for flow models that leverage the recently proposed spread divergence towards fixing the crucial problem; the KL divergence and maximum likelihood estimation are ill-defined for manifold learning. In addition to improving both sample quality and representation quality, an auxiliary benefit enabled by our approach is the ability to identify the intrinsic dimension of the manifold distribution.",
        "bibtex": "@InProceedings{pmlr-v206-zhang23k,\n  title = \t {Spread Flows for Manifold Modelling},\n  author =       {Zhang, Mingtian and Sun, Yitong and Zhang, Chen and Mcdonagh, Steven},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11435--11456},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhang23k/zhang23k.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhang23k.html},\n  abstract = \t {Flow-based models typically define a latent space with dimensionality identical to the observational space. In many problems, however, the data does not populate the full ambient data space that they natively reside in, rather inhabiting a lower-dimensional manifold. In such scenarios, flow-based models are unable to represent data structures exactly as their densities will always have support off the data manifold, potentially resulting in degradation of model performance. To address this issue, we propose to learn a manifold prior for flow models that leverage the recently proposed spread divergence towards fixing the crucial problem; the KL divergence and maximum likelihood estimation are ill-defined for manifold learning. In addition to improving both sample quality and representation quality, an auxiliary benefit enabled by our approach is the ability to identify the intrinsic dimension of the manifold distribution.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhang23k/zhang23k.pdf",
        "supp": "",
        "pdf_size": 4715511,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8545003665096167426&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University College London*; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab",
        "aff_domain": "cs.ucl.ac.uk; ; ; ",
        "email": "cs.ucl.ac.uk; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University College London;Huawei",
        "aff_unique_dep": ";Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.huawei.com",
        "aff_unique_abbr": "UCL;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "37d4daa7b6",
        "title": "Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits",
        "site": "https://proceedings.mlr.press/v206/kim23d.html",
        "author": "Wonyoung Kim; Myunghee Cho Paik; Min-Hwan Oh",
        "abstract": "We propose a linear contextual bandit algorithm for linear contextual bandits with $O(\\sqrt{dT \\log T})$ regret bound, where $d$ is the dimension of contexts and $T$ is the time horizon. Our proposed algorithm is equipped with a novel estimator in which exploration is embedded through explicit randomization. Depending on the randomization, our proposed estimator takes contribution either from contexts of all arms or from selected contexts. We establish a self-normalized bound for our estimator, which allows a novel decomposition of the cumulative regret into additive dimension-dependent terms instead of multiplicative terms. We also prove a novel lower bound of $\\Omega(\\sqrt{dT})$ under our problem setting. Hence, the regret of our proposed algorithm matches the lower bound up to logarithmic factors. The numerical experiments support the theoretical guarantees and show that our proposed method outperforms the existing linear bandit algorithms.",
        "bibtex": "@InProceedings{pmlr-v206-kim23d,\n  title = \t {Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits},\n  author =       {Kim, Wonyoung and Paik, Myunghee Cho and Oh, Min-Hwan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3098--3124},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kim23d/kim23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kim23d.html},\n  abstract = \t {We propose a linear contextual bandit algorithm for linear contextual bandits with $O(\\sqrt{dT \\log T})$ regret bound, where $d$ is the dimension of contexts and $T$ is the time horizon. Our proposed algorithm is equipped with a novel estimator in which exploration is embedded through explicit randomization. Depending on the randomization, our proposed estimator takes contribution either from contexts of all arms or from selected contexts. We establish a self-normalized bound for our estimator, which allows a novel decomposition of the cumulative regret into additive dimension-dependent terms instead of multiplicative terms. We also prove a novel lower bound of $\\Omega(\\sqrt{dT})$ under our problem setting. Hence, the regret of our proposed algorithm matches the lower bound up to logarithmic factors. The numerical experiments support the theoretical guarantees and show that our proposed method outperforms the existing linear bandit algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kim23d/kim23d.pdf",
        "supp": "",
        "pdf_size": 1259481,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7631902439859959866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e8e8d1cc52",
        "title": "Statistical Analysis of Karcher Means for Random Restricted PSD Matrices",
        "site": "https://proceedings.mlr.press/v206/chen23a.html",
        "author": "Hengchao Chen; Xiang Li; Qiang Sun",
        "abstract": "Non-asymptotic statistical analysis is often missing for modern geometry-aware machine learning algorithms due to the possibly intricate non-linear manifold structure. This paper studies an intrinsic mean model on the manifold of restricted positive semi-definite matrices and provides a non-asymptotic statistical analysis of the Karcher mean. We also consider a general extrinsic signal-plus-noise model, under which a deterministic error bound of the Karcher mean is provided. As an application, we show that the distributed principal component analysis algorithm, LRC-dPCA, achieves the same performance as the full sample PCA algorithm. Numerical experiments lend strong support to our theories.",
        "bibtex": "@InProceedings{pmlr-v206-chen23a,\n  title = \t {Statistical Analysis of Karcher Means for Random Restricted PSD Matrices},\n  author =       {Chen, Hengchao and Li, Xiang and Sun, Qiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1437--1456},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23a/chen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23a.html},\n  abstract = \t {Non-asymptotic statistical analysis is often missing for modern geometry-aware machine learning algorithms due to the possibly intricate non-linear manifold structure. This paper studies an intrinsic mean model on the manifold of restricted positive semi-definite matrices and provides a non-asymptotic statistical analysis of the Karcher mean. We also consider a general extrinsic signal-plus-noise model, under which a deterministic error bound of the Karcher mean is provided. As an application, we show that the distributed principal component analysis algorithm, LRC-dPCA, achieves the same performance as the full sample PCA algorithm. Numerical experiments lend strong support to our theories.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23a/chen23a.pdf",
        "supp": "",
        "pdf_size": 535278,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=153934469638137006&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5c84badabc",
        "title": "Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient Methods",
        "site": "https://proceedings.mlr.press/v206/beznosikov23a.html",
        "author": "Aleksandr Beznosikov; Eduard Gorbunov; Hugo Berard; Nicolas Loizou",
        "abstract": "Stochastic Gradient Descent-Ascent (SGDA) is one of the most prominent algorithms for solving min-max optimization and variational inequalities problems (VIP) appearing in various machine learning tasks. The success of the method led to several advanced extensions of the classical SGDA, including variants with arbitrary sampling, variance reduction, coordinate randomization, and distributed variants with compression, which were extensively studied in the literature, especially during the last few years. In this paper, we propose a unified convergence analysis that covers a large variety of stochastic gradient descent-ascent methods, which so far have required different intuitions, have different applications and have been developed separately in various communities. A key to our unified framework is a parametric assumption on the stochastic estimates. Via our general theoretical framework, we either recover the sharpest known rates for the known special cases or tighten them. Moreover, to illustrate the flexibility of our approach we develop several new variants of SGDA such as a new variance-reduced method (L-SVRGDA), new distributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a new method with coordinate randomization (SEGA-SGDA). Although variants of the new methods are known for solving minimization problems, they were never considered or analyzed for solving min-max problems and VIPs. We also demonstrate the most important properties of the new methods through extensive numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v206-beznosikov23a,\n  title = \t {Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient Methods},\n  author =       {Beznosikov, Aleksandr and Gorbunov, Eduard and Berard, Hugo and Loizou, Nicolas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {172--235},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/beznosikov23a/beznosikov23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/beznosikov23a.html},\n  abstract = \t {Stochastic Gradient Descent-Ascent (SGDA) is one of the most prominent algorithms for solving min-max optimization and variational inequalities problems (VIP) appearing in various machine learning tasks. The success of the method led to several advanced extensions of the classical SGDA, including variants with arbitrary sampling, variance reduction, coordinate randomization, and distributed variants with compression, which were extensively studied in the literature, especially during the last few years. In this paper, we propose a unified convergence analysis that covers a large variety of stochastic gradient descent-ascent methods, which so far have required different intuitions, have different applications and have been developed separately in various communities. A key to our unified framework is a parametric assumption on the stochastic estimates. Via our general theoretical framework, we either recover the sharpest known rates for the known special cases or tighten them. Moreover, to illustrate the flexibility of our approach we develop several new variants of SGDA such as a new variance-reduced method (L-SVRGDA), new distributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a new method with coordinate randomization (SEGA-SGDA). Although variants of the new methods are known for solving minimization problems, they were never considered or analyzed for solving min-max problems and VIPs. We also demonstrate the most important properties of the new methods through extensive numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/beznosikov23a/beznosikov23a.pdf",
        "supp": "",
        "pdf_size": 1031159,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1243768628476381407&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8fbb1843e9",
        "title": "Stochastic Methods for AUC Optimization subject to AUC-based Fairness Constraints",
        "site": "https://proceedings.mlr.press/v206/yao23b.html",
        "author": "Yao Yao; Qihang Lin; Tianbao Yang",
        "abstract": "As machine learning being used increasingly in making high-stakes decisions, an arising challenge is to avoid unfair AI systems that lead to discriminatory decisions for protected population. A direct approach for obtaining a fair predictive model is to train the model through optimizing its prediction performance subject to fairness constraints. Among various fairness constraints, the ones based on the area under the ROC curve (AUC) are emerging recently because they are threshold-agnostic and effective for unbalanced data. In this work, we formulate the problem of training a fairness-aware predictive model as an AUC optimization problem subject to a class of AUC-based fairness constraints. This problem can be reformulated as a min-max optimization problem with min-max constraints, which we solve by stochastic first-order methods based on a new Bregman divergence designed for the special structure of the problem. We numerically demonstrate the effectiveness of our approach on real-world data under different fairness metrics.",
        "bibtex": "@InProceedings{pmlr-v206-yao23b,\n  title = \t {Stochastic Methods for AUC Optimization subject to AUC-based Fairness Constraints},\n  author =       {Yao, Yao and Lin, Qihang and Yang, Tianbao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10324--10342},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/yao23b/yao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/yao23b.html},\n  abstract = \t {As machine learning being used increasingly in making high-stakes decisions, an arising challenge is to avoid unfair AI systems that lead to discriminatory decisions for protected population. A direct approach for obtaining a fair predictive model is to train the model through optimizing its prediction performance subject to fairness constraints. Among various fairness constraints, the ones based on the area under the ROC curve (AUC) are emerging recently because they are threshold-agnostic and effective for unbalanced data. In this work, we formulate the problem of training a fairness-aware predictive model as an AUC optimization problem subject to a class of AUC-based fairness constraints. This problem can be reformulated as a min-max optimization problem with min-max constraints, which we solve by stochastic first-order methods based on a new Bregman divergence designed for the special structure of the problem. We numerically demonstrate the effectiveness of our approach on real-world data under different fairness metrics.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/yao23b/yao23b.pdf",
        "supp": "",
        "pdf_size": 690630,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7040221360552910259&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Iowa; University of Iowa; Texas A&M University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Iowa;Texas A&M University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uiowa.edu;https://www.tamu.edu",
        "aff_unique_abbr": "UIowa;TAMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a6f7d31524",
        "title": "Stochastic Mirror Descent for Large-Scale Sparse Recovery",
        "site": "https://proceedings.mlr.press/v206/ilandarideva23a.html",
        "author": "Sasila Ilandarideva; Yannis Bekri; Anatoli Iouditski; Vianney Perchet",
        "abstract": "We discuss an application of Stochastic Approximation to statistical estimation of high-dimensional sparse parameters. The proposed solution reduces to resolving a penalized stochastic optimization problem on each stage of a multistage algorithm; each problem being solved to a prescribed accuracy by the non-Euclidean Composite Stochastic Mirror Descent (CSMD) algorithm. Assuming that the problem objective is smooth and quadratically minorated and stochastic perturbations are sub-Gaussian, our analysis prescribes the method parameters which ensure fast convergence of the estimation error (the radius of a confidence ball of a given norm around the approximate solution). This convergence is linear during the first \u201cpreliminary\u201d phase of the routine and is sublinear during the second \u201casymptotic\u201d phase. We consider an application of the proposed approach to sparse Generalized Linear Regression problem. In this setting, we show that the proposed algorithm attains the optimal convergence of the estimation error under weak assumptions on the regressor distribution. We also present a numerical study illustrating the performance of the algorithm on high-dimensional simulation data.",
        "bibtex": "@InProceedings{pmlr-v206-ilandarideva23a,\n  title = \t {Stochastic Mirror Descent for Large-Scale Sparse Recovery},\n  author =       {Ilandarideva, Sasila and Bekri, Yannis and Iouditski, Anatoli and Perchet, Vianney},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5931--5957},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ilandarideva23a/ilandarideva23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ilandarideva23a.html},\n  abstract = \t {We discuss an application of Stochastic Approximation to statistical estimation of high-dimensional sparse parameters. The proposed solution reduces to resolving a penalized stochastic optimization problem on each stage of a multistage algorithm; each problem being solved to a prescribed accuracy by the non-Euclidean Composite Stochastic Mirror Descent (CSMD) algorithm. Assuming that the problem objective is smooth and quadratically minorated and stochastic perturbations are sub-Gaussian, our analysis prescribes the method parameters which ensure fast convergence of the estimation error (the radius of a confidence ball of a given norm around the approximate solution). This convergence is linear during the first \u201cpreliminary\u201d phase of the routine and is sublinear during the second \u201casymptotic\u201d phase. We consider an application of the proposed approach to sparse Generalized Linear Regression problem. In this setting, we show that the proposed algorithm attains the optimal convergence of the estimation error under weak assumptions on the regressor distribution. We also present a numerical study illustrating the performance of the algorithm on high-dimensional simulation data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ilandarideva23a/ilandarideva23a.pdf",
        "supp": "",
        "pdf_size": 1566185,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10814094848341725937&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ea50c575de",
        "title": "Stochastic Optimization for Spectral Risk Measures",
        "site": "https://proceedings.mlr.press/v206/mehta23b.html",
        "author": "Ronak Mehta; Vincent Roulet; Krishna Pillutla; Lang Liu; Zaid Harchaoui",
        "abstract": "Spectral risk objectives \u2013 also called L-risks \u2013 allow for learning systems to interpolate between optimizing average-case performance (as in empirical risk minimization) and worst-case performance on a task. We develop LSVRG, a stochastic algorithm to optimize these quantities by characterizing their subdifferential and addressing challenges such as biasedness of subgradient estimates and non-smoothness of the objective. We show theoretically and experimentally that out-of-the-box approaches such as stochastic subgradient and dual averaging can be hindered by bias, whereas our approach exhibits linear convergence.",
        "bibtex": "@InProceedings{pmlr-v206-mehta23b,\n  title = \t {Stochastic Optimization for Spectral Risk Measures},\n  author =       {Mehta, Ronak and Roulet, Vincent and Pillutla, Krishna and Liu, Lang and Harchaoui, Zaid},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10112--10159},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mehta23b/mehta23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mehta23b.html},\n  abstract = \t {Spectral risk objectives \u2013 also called L-risks \u2013 allow for learning systems to interpolate between optimizing average-case performance (as in empirical risk minimization) and worst-case performance on a task. We develop LSVRG, a stochastic algorithm to optimize these quantities by characterizing their subdifferential and addressing challenges such as biasedness of subgradient estimates and non-smoothness of the objective. We show theoretically and experimentally that out-of-the-box approaches such as stochastic subgradient and dual averaging can be hindered by bias, whereas our approach exhibits linear convergence.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mehta23b/mehta23b.pdf",
        "supp": "",
        "pdf_size": 2557563,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11805481966357479325&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Washington; University of Washington; Google Research + University of Washington; University of Washington; University of Washington",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+0;0;0",
        "aff_unique_norm": "University of Washington;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.washington.edu;https://research.google",
        "aff_unique_abbr": "UW;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0+0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f4e3977c49",
        "title": "Stochastic Tree Ensembles for Estimating Heterogeneous Effects",
        "site": "https://proceedings.mlr.press/v206/krantsevich23a.html",
        "author": "Nikolay Krantsevich; Jingyu He; P. Richard Hahn",
        "abstract": "Determining subgroups that respond especially well (or poorly) to specific interventions (medical or policy) requires new supervised learning methods tailored specifically for causal inference. Bayesian Causal Forest (BCF) is a recent method that has been documented to perform well on data generating processes with strong confounding of the sort that is plausible in many applications. This paper develops a novel algorithm for fitting the BCF model, which is more efficient than the previous Gibbs sampler. The new algorithm can be used to initialize independent chains of the existing Gibbs sampler leading to better posterior exploration and coverage of the associated interval estimates in simulation studies. The new algorithm is compared to related approaches via simulation studies as well as an empirical analysis.",
        "bibtex": "@InProceedings{pmlr-v206-krantsevich23a,\n  title = \t {Stochastic Tree Ensembles for Estimating Heterogeneous Effects},\n  author =       {Krantsevich, Nikolay and He, Jingyu and Hahn, P. Richard},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6120--6131},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/krantsevich23a/krantsevich23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/krantsevich23a.html},\n  abstract = \t {Determining subgroups that respond especially well (or poorly) to specific interventions (medical or policy) requires new supervised learning methods tailored specifically for causal inference. Bayesian Causal Forest (BCF) is a recent method that has been documented to perform well on data generating processes with strong confounding of the sort that is plausible in many applications. This paper develops a novel algorithm for fitting the BCF model, which is more efficient than the previous Gibbs sampler. The new algorithm can be used to initialize independent chains of the existing Gibbs sampler leading to better posterior exploration and coverage of the associated interval estimates in simulation studies. The new algorithm is compared to related approaches via simulation studies as well as an empirical analysis.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/krantsevich23a/krantsevich23a.pdf",
        "supp": "",
        "pdf_size": 517095,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3658955456313782721&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8e53b78c08",
        "title": "Strong Lottery Ticket Hypothesis with $\\varepsilon$\u2013perturbation",
        "site": "https://proceedings.mlr.press/v206/xiong23a.html",
        "author": "Zheyang Xiong; Fangshuo Liao; Anastasios Kyrillidis",
        "abstract": "The strong Lottery Ticket Hypothesis (LTH) (Ramanujan et al., 2019; Zhou et al., 2019) claims the existence of a subnetwork in a sufficiently large, randomly initialized neural network that approximates some target neural network without the need of training. We extend the theoretical guarantee of the strong LTH literature to a scenario more similar to the original LTH, by generalizing the weight change in the pre-training step to some perturbation around initialization. In particular, we focus on the following open questions: By allowing an $\\varepsilon$-scale perturbation on the random initial weights, can we reduce the over-parameterization requirement for the candidate network in the strong LTH? Furthermore, does the weight change by SGD coincide with a good set of such perturbation? We answer the first question by first extending the theoretical result on subset sum problem (Lueker, 1998) to allow perturbation on the candidates. Applying this result to the neural network setting, we show that by allowing $\\varepsilon$-scale perturbation, we can reduce the over-parameterization requirement of the strong LTH by a factor of $O(1/(1+\\varepsilon))$. To answer the second question, we show via experiments that the perturbed weight achieved by the projected SGD shows better performance under the strong LTH pruning.",
        "bibtex": "@InProceedings{pmlr-v206-xiong23a,\n  title = \t {Strong Lottery Ticket Hypothesis with $\\varepsilon$\u2013perturbation},\n  author =       {Xiong, Zheyang and Liao, Fangshuo and Kyrillidis, Anastasios},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6879--6902},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xiong23a/xiong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xiong23a.html},\n  abstract = \t {The strong Lottery Ticket Hypothesis (LTH) (Ramanujan et al., 2019; Zhou et al., 2019) claims the existence of a subnetwork in a sufficiently large, randomly initialized neural network that approximates some target neural network without the need of training. We extend the theoretical guarantee of the strong LTH literature to a scenario more similar to the original LTH, by generalizing the weight change in the pre-training step to some perturbation around initialization. In particular, we focus on the following open questions: By allowing an $\\varepsilon$-scale perturbation on the random initial weights, can we reduce the over-parameterization requirement for the candidate network in the strong LTH? Furthermore, does the weight change by SGD coincide with a good set of such perturbation? We answer the first question by first extending the theoretical result on subset sum problem (Lueker, 1998) to allow perturbation on the candidates. Applying this result to the neural network setting, we show that by allowing $\\varepsilon$-scale perturbation, we can reduce the over-parameterization requirement of the strong LTH by a factor of $O(1/(1+\\varepsilon))$. To answer the second question, we show via experiments that the perturbed weight achieved by the projected SGD shows better performance under the strong LTH pruning.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xiong23a/xiong23a.pdf",
        "supp": "",
        "pdf_size": 1947252,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Rice University; Rice University; Rice University",
        "aff_domain": "rice.edu;rice.edu;rice.edu",
        "email": "rice.edu;rice.edu;rice.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d50da0dca3",
        "title": "Structure of Nonlinear Node Embeddings in Stochastic Block Models",
        "site": "https://proceedings.mlr.press/v206/harker23a.html",
        "author": "Christopher Harker; Aditya Bhaskara",
        "abstract": "Nonlinear node embedding techniques such as DeepWalk and Node2Vec are used extensively in practice to uncover structure in graphs. Despite theoretical guarantees in special regimes (such as the case of high embedding dimension), the structure of the optimal low dimensional embeddings has not been formally understood even for graphs obtained from simple generative models. We consider the stochastic block model and show that under appropriate separation conditions, the optimal embeddings can be analytically characterized. Akin to known results on eigenvector based (spectral) embeddings, we prove theoretically that solution vectors are well-clustered, up to a sublinear error.",
        "bibtex": "@InProceedings{pmlr-v206-harker23a,\n  title = \t {Structure of Nonlinear Node Embeddings in Stochastic Block Models},\n  author =       {Harker, Christopher and Bhaskara, Aditya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6764--6782},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/harker23a/harker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/harker23a.html},\n  abstract = \t {Nonlinear node embedding techniques such as DeepWalk and Node2Vec are used extensively in practice to uncover structure in graphs. Despite theoretical guarantees in special regimes (such as the case of high embedding dimension), the structure of the optimal low dimensional embeddings has not been formally understood even for graphs obtained from simple generative models. We consider the stochastic block model and show that under appropriate separation conditions, the optimal embeddings can be analytically characterized. Akin to known results on eigenvector based (spectral) embeddings, we prove theoretically that solution vectors are well-clustered, up to a sublinear error.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/harker23a/harker23a.pdf",
        "supp": "",
        "pdf_size": 482719,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14793057225418664687&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of Utah; University of Utah",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "Utah",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "07a70f8ed8",
        "title": "Subset verification and search algorithms for causal DAGs",
        "site": "https://proceedings.mlr.press/v206/choo23a.html",
        "author": "Davin Choo; Kirankumar Shiragur",
        "abstract": "Learning causal relationships between variables is a fundamental task in causal inference and directed acyclic graphs (DAGs) are a popular choice to represent the causal relationships. As one can recover a causal graph only up to its Markov equivalence class from observations, interventions are often used for the recovery task. Interventions are costly in general and it is important to design algorithms that minimize the number of interventions performed. In this work, we study the problem of identifying the smallest set of interventions required to learn the causal relationships between a subset of edges (target edges). Under the assumptions of faithfulness, causal sufficiency, and ideal interventions, we study this problem in two settings: when the underlying ground truth causal graph is known (subset verification) and when it is unknown (subset search). For the subset verification problem, we provide an efficient algorithm to compute a minimum sized interventional set; we further extend these results to bounded size non-atomic interventions and node-dependent interventional costs. For the subset search problem, in the worst case, we show that no algorithm (even with adaptivity or randomization) can achieve an approximation ratio that is asymptotically better than the vertex cover of the target edges when compared with the subset verification number. This result is surprising as there exists a logarithmic approximation algorithm for the search problem when we wish to recover the whole causal graph. To obtain our results, we prove several interesting structural properties of interventional causal graphs that we believe have applications beyond the subset verification/search problems studied here.",
        "bibtex": "@InProceedings{pmlr-v206-choo23a,\n  title = \t {Subset verification and search algorithms for causal DAGs},\n  author =       {Choo, Davin and Shiragur, Kirankumar},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4409--4442},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/choo23a/choo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/choo23a.html},\n  abstract = \t {Learning causal relationships between variables is a fundamental task in causal inference and directed acyclic graphs (DAGs) are a popular choice to represent the causal relationships. As one can recover a causal graph only up to its Markov equivalence class from observations, interventions are often used for the recovery task. Interventions are costly in general and it is important to design algorithms that minimize the number of interventions performed. In this work, we study the problem of identifying the smallest set of interventions required to learn the causal relationships between a subset of edges (target edges). Under the assumptions of faithfulness, causal sufficiency, and ideal interventions, we study this problem in two settings: when the underlying ground truth causal graph is known (subset verification) and when it is unknown (subset search). For the subset verification problem, we provide an efficient algorithm to compute a minimum sized interventional set; we further extend these results to bounded size non-atomic interventions and node-dependent interventional costs. For the subset search problem, in the worst case, we show that no algorithm (even with adaptivity or randomization) can achieve an approximation ratio that is asymptotically better than the vertex cover of the target edges when compared with the subset verification number. This result is surprising as there exists a logarithmic approximation algorithm for the search problem when we wish to recover the whole causal graph. To obtain our results, we prove several interesting structural properties of interventional causal graphs that we believe have applications beyond the subset verification/search problems studied here.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/choo23a/choo23a.pdf",
        "supp": "",
        "pdf_size": 997271,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2505750459374608686&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "National University of Singapore; Broad Institute of MIT and Harvard",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "National University of Singapore;Broad Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.broadinstitute.org",
        "aff_unique_abbr": "NUS;Broad",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "c0b94e4038",
        "title": "Surveillance Evasion Through Bayesian Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/qi23a.html",
        "author": "Dongping Qi; David Bindel; Alexander Vladimirsky",
        "abstract": "We consider a task of surveillance-evading path-planning in a continuous setting. An Evader strives to escape from a 2D domain while minimizing the risk of detection (and immediate capture). The probability of detection is path-dependent and determined by the spatially inhomogeneous surveillance intensity, which is fixed but a priori unknown and gradually learned in the multi-episodic setting. We introduce a Bayesian reinforcement learning algorithm that relies on a Gaussian Process regression (to model the surveillance intensity function based on the information from prior episodes), numerical methods for Hamilton-Jacobi PDEs (to plan the best continuous trajectories based on the current model), and Confidence Bounds (to balance the exploration vs exploitation). We use numerical experiments and regret metrics to highlight the significant advantages of our approach compared to traditional graph-based algorithms of reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v206-qi23a,\n  title = \t {Surveillance Evasion Through Bayesian Reinforcement Learning},\n  author =       {Qi, Dongping and Bindel, David and Vladimirsky, Alexander},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8448--8462},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qi23a/qi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qi23a.html},\n  abstract = \t {We consider a task of surveillance-evading path-planning in a continuous setting. An Evader strives to escape from a 2D domain while minimizing the risk of detection (and immediate capture). The probability of detection is path-dependent and determined by the spatially inhomogeneous surveillance intensity, which is fixed but a priori unknown and gradually learned in the multi-episodic setting. We introduce a Bayesian reinforcement learning algorithm that relies on a Gaussian Process regression (to model the surveillance intensity function based on the information from prior episodes), numerical methods for Hamilton-Jacobi PDEs (to plan the best continuous trajectories based on the current model), and Confidence Bounds (to balance the exploration vs exploitation). We use numerical experiments and regret metrics to highlight the significant advantages of our approach compared to traditional graph-based algorithms of reinforcement learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qi23a/qi23a.pdf",
        "supp": "",
        "pdf_size": 1117114,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17100216878815625410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "db8479dac5",
        "title": "SurvivalGAN: Generating Time-to-Event Data for Survival Analysis",
        "site": "https://proceedings.mlr.press/v206/norcliffe23a.html",
        "author": "Alexander Norcliffe; Bogdan Cebere; Fergus Imrie; Pietro Li\u00f3; Mihaela van der Schaar",
        "abstract": "Synthetic data is becoming an increasingly promising technology, and successful applications can improve privacy, fairness, and data democratization. While there are many methods for generating synthetic tabular data, the task remains non-trivial and unexplored for specific scenarios. One such scenario is survival data. Here, the key difficulty is censoring: for some instances, we are not aware of the time of event, or if one even occurred. Imbalances in censoring and time horizons cause generative models to experience three new failure modes specific to survival analysis: (1) generating too few at-risk members; (2) generating too many at-risk members; and (3) censoring too early. We formalize these failure modes and provide three new generative metrics to quantify them. Following this, we propose SurvivalGAN, a generative model that handles survival data firstly by addressing the imbalance in the censoring and event horizons, and secondly by using a dedicated mechanism for approximating time-to-event/censoring. We evaluate this method via extensive experiments on medical datasets. SurvivalGAN outperforms multiple baselines at generating survival data, and in particular addresses the failure modes as measured by the new metrics, in addition to improving downstream performance of survival models trained on the synthetic data.",
        "bibtex": "@InProceedings{pmlr-v206-norcliffe23a,\n  title = \t {SurvivalGAN: Generating Time-to-Event Data for Survival Analysis},\n  author =       {Norcliffe, Alexander and Cebere, Bogdan and Imrie, Fergus and Li\\'o, Pietro and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10279--10304},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/norcliffe23a/norcliffe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/norcliffe23a.html},\n  abstract = \t {Synthetic data is becoming an increasingly promising technology, and successful applications can improve privacy, fairness, and data democratization. While there are many methods for generating synthetic tabular data, the task remains non-trivial and unexplored for specific scenarios. One such scenario is survival data. Here, the key difficulty is censoring: for some instances, we are not aware of the time of event, or if one even occurred. Imbalances in censoring and time horizons cause generative models to experience three new failure modes specific to survival analysis: (1) generating too few at-risk members; (2) generating too many at-risk members; and (3) censoring too early. We formalize these failure modes and provide three new generative metrics to quantify them. Following this, we propose SurvivalGAN, a generative model that handles survival data firstly by addressing the imbalance in the censoring and event horizons, and secondly by using a dedicated mechanism for approximating time-to-event/censoring. We evaluate this method via extensive experiments on medical datasets. SurvivalGAN outperforms multiple baselines at generating survival data, and in particular addresses the failure modes as measured by the new metrics, in addition to improving downstream performance of survival models trained on the synthetic data.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/norcliffe23a/norcliffe23a.pdf",
        "supp": "",
        "pdf_size": 3129852,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16270736596160781705&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Cambridge; University of Cambridge; University of California, Los Angeles + University of Cambridge; University of Cambridge; University of Cambridge + Alan Turing Institute",
        "aff_domain": "cam.ac.uk;cam.ac.uk;ucla.edu;cam.ac.uk;cam.ac.uk",
        "email": "cam.ac.uk;cam.ac.uk;ucla.edu;cam.ac.uk;cam.ac.uk",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+0;0;0+2",
        "aff_unique_norm": "University of Cambridge;University of California, Los Angeles;Alan Turing Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.ucla.edu;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;UCLA;ATI",
        "aff_campus_unique_index": "0;0;1+0;0;0",
        "aff_campus_unique": "Cambridge;Los Angeles;",
        "aff_country_unique_index": "0;0;1+0;0;0+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "d909ec9248",
        "title": "SwAMP: Swapped Assignment of Multi-Modal Pairs for Cross-Modal Retrieval",
        "site": "https://proceedings.mlr.press/v206/kim23e.html",
        "author": "Minyoung Kim",
        "abstract": "We tackle the cross-modal retrieval problem, where learning is only supervised by the relevant multi-modal pairs in the data. Although the contrastive learning is the most popular approach for this task, it makes potentially wrong assumption that the instances in different pairs are automatically irrelevant. To address the issue, we propose a novel loss function that is based on self-labeling of the unknown semantic classes. Specifically, we aim to predict class labels of the data instances in each modality, and assign those labels to the corresponding instances in the other modality (i.e., swapping the pseudo labels). With these swapped labels, we learn the data embedding for each modality using the supervised cross-entropy loss. This way, cross-modal instances from different pairs that are semantically related can be aligned to each other by the class predictor. We tested our approach on several real-world cross-modal retrieval problems, including text-based video retrieval, sketch-based image retrieval, and image-text retrieval. For all these tasks our method achieves significant performance improvement over the contrastive learning.",
        "bibtex": "@InProceedings{pmlr-v206-kim23e,\n  title = \t {SwAMP: Swapped Assignment of Multi-Modal Pairs for Cross-Modal Retrieval},\n  author =       {Kim, Minyoung},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9167--9190},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kim23e/kim23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kim23e.html},\n  abstract = \t {We tackle the cross-modal retrieval problem, where learning is only supervised by the relevant multi-modal pairs in the data. Although the contrastive learning is the most popular approach for this task, it makes potentially wrong assumption that the instances in different pairs are automatically irrelevant. To address the issue, we propose a novel loss function that is based on self-labeling of the unknown semantic classes. Specifically, we aim to predict class labels of the data instances in each modality, and assign those labels to the corresponding instances in the other modality (i.e., swapping the pseudo labels). With these swapped labels, we learn the data embedding for each modality using the supervised cross-entropy loss. This way, cross-modal instances from different pairs that are semantically related can be aligned to each other by the class predictor. We tested our approach on several real-world cross-modal retrieval problems, including text-based video retrieval, sketch-based image retrieval, and image-text retrieval. For all these tasks our method achieves significant performance improvement over the contrastive learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kim23e/kim23e.pdf",
        "supp": "",
        "pdf_size": 4610732,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16588615028063311549&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Samsung AI Center Cambridge, UK",
        "aff_domain": "gmail.com",
        "email": "gmail.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/research-innovation/ai-research-centers/samsung-ai-center-cambridge/",
        "aff_unique_abbr": "Samsung AI Cambridge",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "33229730c1",
        "title": "Symmetric (Optimistic) Natural Policy Gradient for Multi-Agent Learning with Parameter Convergence",
        "site": "https://proceedings.mlr.press/v206/pattathil23a.html",
        "author": "Sarath Pattathil; Kaiqing Zhang; Asuman Ozdaglar",
        "abstract": "Multi-agent interactions are increasingly important in the context of reinforcement learning, and the theoretical foundations of policy gradient methods have attracted surging research interest. We investigate the global convergence of natural policy gradient (NPG) algorithms in multi-agent learning. We first show that vanilla NPG may not have parameter convergence, i.e., the convergence of the vector that parameterizes the policy, even when the payoffs are regularized (which enabled strong convergence guarantees in the policy space in the literature). This non-convergence of parameters leads to stability issues in learning, which becomes especially relevant in the function approximation setting, where we can only operate on low-dimensional parameters, instead of the high-dimensional policy. We then propose variants of the NPG algorithm, for several standard multi-agent learning scenarios: two-player zero-sum matrix and Markov games, and multi-player monotone games, with global last-iterate parameter convergence guarantees. We also generalize the results to certain function approximation settings. Note that in our algorithms, the agents take symmetric roles. Our results might also be of independent interest for solving nonconvex-nonconcave minimax optimization problems with certain structures. Simulations are also provided to corroborate our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v206-pattathil23a,\n  title = \t {Symmetric (Optimistic) Natural Policy Gradient for Multi-Agent Learning with Parameter Convergence},\n  author =       {Pattathil, Sarath and Zhang, Kaiqing and Ozdaglar, Asuman},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5641--5685},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/pattathil23a/pattathil23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/pattathil23a.html},\n  abstract = \t {Multi-agent interactions are increasingly important in the context of reinforcement learning, and the theoretical foundations of policy gradient methods have attracted surging research interest. We investigate the global convergence of natural policy gradient (NPG) algorithms in multi-agent learning. We first show that vanilla NPG may not have parameter convergence, i.e., the convergence of the vector that parameterizes the policy, even when the payoffs are regularized (which enabled strong convergence guarantees in the policy space in the literature). This non-convergence of parameters leads to stability issues in learning, which becomes especially relevant in the function approximation setting, where we can only operate on low-dimensional parameters, instead of the high-dimensional policy. We then propose variants of the NPG algorithm, for several standard multi-agent learning scenarios: two-player zero-sum matrix and Markov games, and multi-player monotone games, with global last-iterate parameter convergence guarantees. We also generalize the results to certain function approximation settings. Note that in our algorithms, the agents take symmetric roles. Our results might also be of independent interest for solving nonconvex-nonconcave minimax optimization problems with certain structures. Simulations are also provided to corroborate our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/pattathil23a/pattathil23a.pdf",
        "supp": "",
        "pdf_size": 667959,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7085644027051090686&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b04014e9b7",
        "title": "T-Phenotype: Discovering Phenotypes of Predictive Temporal Patterns in Disease Progression",
        "site": "https://proceedings.mlr.press/v206/qin23b.html",
        "author": "Yuchao Qin; Mihaela van der Schaar; Changhee Lee",
        "abstract": "Clustering time-series data in healthcare is crucial for clinical phenotyping to understand patients\u2019 disease progression patterns and to design treatment guidelines tailored to homogeneous patient subgroups. While rich temporal dynamics enable the discovery of potential clusters beyond static correlations, two major challenges remain outstanding: i) discovery of predictive patterns from many potential temporal correlations in the multi-variate time-series data and ii) association of individual temporal patterns to the target label distribution that best characterizes the underlying clinical progression. To address such challenges, we develop a novel temporal clustering method, T-Phenotype, to discover phenotypes of predictive temporal patterns from labeled time-series data. We introduce an efficient representation learning approach in frequency domain that can encode variable-length, irregularly-sampled time-series into a unified representation space, which is then applied to identify various temporal patterns that potentially contribute to the target label using a new notion of path-based similarity. Throughout the experiments on synthetic and real-world datasets, we show that T-Phenotype achieves the best phenotype discovery performance over all the evaluated baselines. We further demonstrate the utility of T-Phenotype by uncovering clinically meaningful patient subgroups characterized by unique temporal patterns.",
        "bibtex": "@InProceedings{pmlr-v206-qin23b,\n  title = \t {T-Phenotype: Discovering Phenotypes of Predictive Temporal Patterns in Disease Progression},\n  author =       {Qin, Yuchao and van der Schaar, Mihaela and Lee, Changhee},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3466--3492},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qin23b/qin23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qin23b.html},\n  abstract = \t {Clustering time-series data in healthcare is crucial for clinical phenotyping to understand patients\u2019 disease progression patterns and to design treatment guidelines tailored to homogeneous patient subgroups. While rich temporal dynamics enable the discovery of potential clusters beyond static correlations, two major challenges remain outstanding: i) discovery of predictive patterns from many potential temporal correlations in the multi-variate time-series data and ii) association of individual temporal patterns to the target label distribution that best characterizes the underlying clinical progression. To address such challenges, we develop a novel temporal clustering method, T-Phenotype, to discover phenotypes of predictive temporal patterns from labeled time-series data. We introduce an efficient representation learning approach in frequency domain that can encode variable-length, irregularly-sampled time-series into a unified representation space, which is then applied to identify various temporal patterns that potentially contribute to the target label using a new notion of path-based similarity. Throughout the experiments on synthetic and real-world datasets, we show that T-Phenotype achieves the best phenotype discovery performance over all the evaluated baselines. We further demonstrate the utility of T-Phenotype by uncovering clinically meaningful patient subgroups characterized by unique temporal patterns.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qin23b/qin23b.pdf",
        "supp": "",
        "pdf_size": 1640743,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13432650067133105855&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2e17a8a889",
        "title": "TS-UCB: Improving on Thompson Sampling With Little to No Additional Computation",
        "site": "https://proceedings.mlr.press/v206/baek23a.html",
        "author": "Jackie Baek; Vivek Farias",
        "abstract": "Thompson sampling has become a ubiquitous approach to online decision problems with bandit feedback. The key algorithmic task for Thompson sampling is drawing a sample from the posterior of the optimal action. We propose an alternative arm selection rule we dub TS-UCB, that requires negligible additional computational effort but provides significant performance improvements relative to Thompson sampling. At each step, TS-UCB computes a score for each arm using two ingredients: posterior sample(s) and upper confidence bounds. TS-UCB can be used in any setting where these two quantities are available, and it is flexible in the number of posterior samples it takes as input. TS-UCB achieves materially lower regret on a comprehensive suite of synthetic and real-world datasets, including a personalized article recommendation dataset from Yahoo! and a suite of benchmark datasets from a deep bandit suite proposed in Riquelme et al. (2018). Finally, from a theoretical perspective, we establish optimal regret guarantees for TS-UCB for both the K-armed and linear bandit models.",
        "bibtex": "@InProceedings{pmlr-v206-baek23a,\n  title = \t {TS-UCB: Improving on Thompson Sampling With Little to No Additional Computation},\n  author =       {Baek, Jackie and Farias, Vivek},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11132--11148},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/baek23a/baek23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/baek23a.html},\n  abstract = \t {Thompson sampling has become a ubiquitous approach to online decision problems with bandit feedback. The key algorithmic task for Thompson sampling is drawing a sample from the posterior of the optimal action. We propose an alternative arm selection rule we dub TS-UCB, that requires negligible additional computational effort but provides significant performance improvements relative to Thompson sampling. At each step, TS-UCB computes a score for each arm using two ingredients: posterior sample(s) and upper confidence bounds. TS-UCB can be used in any setting where these two quantities are available, and it is flexible in the number of posterior samples it takes as input. TS-UCB achieves materially lower regret on a comprehensive suite of synthetic and real-world datasets, including a personalized article recommendation dataset from Yahoo! and a suite of benchmark datasets from a deep bandit suite proposed in Riquelme et al. (2018). Finally, from a theoretical perspective, we establish optimal regret guarantees for TS-UCB for both the K-armed and linear bandit models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/baek23a/baek23a.pdf",
        "supp": "",
        "pdf_size": 440108,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4908352410113040967&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "NYU Stern School of Business; MIT Sloan School of Management",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "New York University Stern School of Business;Massachusetts Institute of Technology",
        "aff_unique_dep": "Stern School of Business;Sloan School of Management",
        "aff_unique_url": "https:// stern.nyu.edu;https://mitsloan.mit.edu/",
        "aff_unique_abbr": "NYU Stern;MIT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "New York;Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "15598ba0dd",
        "title": "TabLLM: Few-shot Classification of Tabular Data with Large Language Models",
        "site": "https://proceedings.mlr.press/v206/hegselmann23a.html",
        "author": "Stefan Hegselmann; Alejandro Buendia; Hunter Lang; Monica Agrawal; Xiaoyi Jiang; David Sontag",
        "abstract": "We study the application of large language models to zero-shot and few-shot classification of tabular data. We prompt the large language model with a serialization of the tabular data to a natural-language string, together with a short description of the classification problem. In the few-shot setting, we fine-tune the large language model using some labeled examples. We evaluate several serialization methods including templates, table-to-text models, and large language models. Despite its simplicity, we find that this technique outperforms prior deep-learning-based tabular classification methods on several benchmark datasets. In most cases, even zero-shot classification obtains non-trivial performance, illustrating the method\u2019s ability to exploit prior knowledge encoded in large language models. Unlike many deep learning methods for tabular datasets, this approach is also competitive with strong traditional baselines like gradient-boosted trees, especially in the very-few-shot setting.",
        "bibtex": "@InProceedings{pmlr-v206-hegselmann23a,\n  title = \t {TabLLM: Few-shot Classification of Tabular Data with Large Language Models},\n  author =       {Hegselmann, Stefan and Buendia, Alejandro and Lang, Hunter and Agrawal, Monica and Jiang, Xiaoyi and Sontag, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5549--5581},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hegselmann23a/hegselmann23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hegselmann23a.html},\n  abstract = \t {We study the application of large language models to zero-shot and few-shot classification of tabular data. We prompt the large language model with a serialization of the tabular data to a natural-language string, together with a short description of the classification problem. In the few-shot setting, we fine-tune the large language model using some labeled examples. We evaluate several serialization methods including templates, table-to-text models, and large language models. Despite its simplicity, we find that this technique outperforms prior deep-learning-based tabular classification methods on several benchmark datasets. In most cases, even zero-shot classification obtains non-trivial performance, illustrating the method\u2019s ability to exploit prior knowledge encoded in large language models. Unlike many deep learning methods for tabular datasets, this approach is also competitive with strong traditional baselines like gradient-boosted trees, especially in the very-few-shot setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hegselmann23a/hegselmann23a.pdf",
        "supp": "",
        "pdf_size": 668692,
        "gs_citation": 353,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5172610541918268654&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "MIT CSAIL+University of M \u00a8unster; MIT CSAIL; MIT CSAIL; MIT CSAIL; University of M \u00a8unster; MIT CSAIL",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of M\u00fcnster",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.uni-muenster.de",
        "aff_unique_abbr": "MIT CSAIL;WWU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0+1;0;0;0;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "b43159957d",
        "title": "Temporal Graph Neural Networks for Irregular Data",
        "site": "https://proceedings.mlr.press/v206/oskarsson23a.html",
        "author": "Joel Oskarsson; Per Sid\u00e9n; Fredrik Lindsten",
        "abstract": "This paper proposes a temporal graph neural network model for forecasting of graph-structured irregularly observed time series. Our TGNN4I model is designed to handle both irregular time steps and partial observations of the graph. This is achieved by introducing a time-continuous latent state in each node, following a linear Ordinary Differential Equation (ODE) defined by the output of a Gated Recurrent Unit (GRU). The ODE has an explicit solution as a combination of exponential decay and periodic dynamics. Observations in the graph neighborhood are taken into account by integrating graph neural network layers in both the GRU state update and predictive model. The time-continuous dynamics additionally enable the model to make predictions at arbitrary time steps. We propose a loss function that leverages this and allows for training the model for forecasting over different time horizons. Experiments on simulated data and real-world data from traffic and climate modeling validate the usefulness of both the graph structure and time-continuous dynamics in settings with irregular observations.",
        "bibtex": "@InProceedings{pmlr-v206-oskarsson23a,\n  title = \t {Temporal Graph Neural Networks for Irregular Data},\n  author =       {Oskarsson, Joel and Sid\\'en, Per and Lindsten, Fredrik},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4515--4531},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/oskarsson23a/oskarsson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/oskarsson23a.html},\n  abstract = \t {This paper proposes a temporal graph neural network model for forecasting of graph-structured irregularly observed time series. Our TGNN4I model is designed to handle both irregular time steps and partial observations of the graph. This is achieved by introducing a time-continuous latent state in each node, following a linear Ordinary Differential Equation (ODE) defined by the output of a Gated Recurrent Unit (GRU). The ODE has an explicit solution as a combination of exponential decay and periodic dynamics. Observations in the graph neighborhood are taken into account by integrating graph neural network layers in both the GRU state update and predictive model. The time-continuous dynamics additionally enable the model to make predictions at arbitrary time steps. We propose a loss function that leverages this and allows for training the model for forecasting over different time horizons. Experiments on simulated data and real-world data from traffic and climate modeling validate the usefulness of both the graph structure and time-continuous dynamics in settings with irregular observations.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/oskarsson23a/oskarsson23a.pdf",
        "supp": "",
        "pdf_size": 668428,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13590696549690651779&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Link \u00a8oping University; Link \u00a8oping University; Arriver Software AB+Link \u00a8oping University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+0",
        "aff_unique_norm": "Link\u00f6ping University;Arriver Software",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.liu.se;https://www.arriver.com",
        "aff_unique_abbr": "LiU;Arriver",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "aed78f5f4d",
        "title": "Tensor-based Kernel Machines with Structured Inducing Points for Large and High-Dimensional Data",
        "site": "https://proceedings.mlr.press/v206/wesel23a.html",
        "author": "Frederiek Wesel; Kim Batselier",
        "abstract": "Kernel machines are one of the most studied family of methods in machine learning. In the exact setting, training requires to instantiate the kernel matrix, thereby prohibiting their application to large-sampled data. One popular kernel approximation strategy which allows to tackle large-sampled data consists in interpolating product kernels on a set of grid-structured inducing points. However, since the number of model parameters increases exponentially with the dimensionality of the data, these methods are limited to small-dimensional datasets. In this work we lift this limitation entirely by placing inducing points on a grid and constraining the primal weights to be a low-rank Canonical Polyadic Decomposition. We derive a block coordinate descent algorithm that efficiently exploits grid-structured inducing points. The computational complexity of the algorithm scales linearly both in the number of samples and in the dimensionality of the data for any product kernel. We demonstrate the performance of our algorithm on large-scale and high-dimensional data, achieving state-of-the art results on a laptop computer. Our results show that grid-structured approaches can work in higher-dimensional problems.",
        "bibtex": "@InProceedings{pmlr-v206-wesel23a,\n  title = \t {Tensor-based Kernel Machines with Structured Inducing Points for Large and High-Dimensional Data},\n  author =       {Wesel, Frederiek and Batselier, Kim},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8308--8320},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wesel23a/wesel23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wesel23a.html},\n  abstract = \t {Kernel machines are one of the most studied family of methods in machine learning. In the exact setting, training requires to instantiate the kernel matrix, thereby prohibiting their application to large-sampled data. One popular kernel approximation strategy which allows to tackle large-sampled data consists in interpolating product kernels on a set of grid-structured inducing points. However, since the number of model parameters increases exponentially with the dimensionality of the data, these methods are limited to small-dimensional datasets. In this work we lift this limitation entirely by placing inducing points on a grid and constraining the primal weights to be a low-rank Canonical Polyadic Decomposition. We derive a block coordinate descent algorithm that efficiently exploits grid-structured inducing points. The computational complexity of the algorithm scales linearly both in the number of samples and in the dimensionality of the data for any product kernel. We demonstrate the performance of our algorithm on large-scale and high-dimensional data, achieving state-of-the art results on a laptop computer. Our results show that grid-structured approaches can work in higher-dimensional problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wesel23a/wesel23a.pdf",
        "supp": "",
        "pdf_size": 1429605,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11990932751849892505&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Delft Center for Systems and Control, Delft University of Technology; Delft Center for Systems and Control, Delft University of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Delft Center for Systems and Control",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "d491f3c6f3",
        "title": "Testing of Horn Samplers",
        "site": "https://proceedings.mlr.press/v206/banerjee23a.html",
        "author": "Ansuman Banerjee; Shayak Chakraborty; Sourav Chakraborty; Kuldeep S. Meel; Uddalok Sarkar; Sayantan Sen",
        "abstract": "Sampling over combinatorial spaces is a fundamental problem in artificial intelligence with a wide variety of applications. Since state-of-the-art techniques heavily rely on heuristics whose rigorous analysis remains beyond the reach of current theoretical tools, the past few years have witnessed interest in the design of techniques to test the quality of samplers. The current state-of-the-art techniques, $\\mathsf{Barbarik}$ and $\\mathsf{Barbarik2}$, focuses on the cases where combinatorial spaces are encoded as Conjunctive Normal Form (CNF) formulas. While CNF is a general-purpose form, often techniques rely on exploiting specific representations to achieve speedup. Of particular interest are Horn clauses, which form the basis of the logic programming tools in AI. In this context, a natural question is whether it is possible to design a tester that can determine the correctness of a given Horn sampler. The primary contribution of this paper is an affirmative answer to the above question. We design the first tester, $\\mathsf{Flash}$, which tests the correctness of a given Horn sampler: given a specific distribution $\\mathcal{I}$ and parameters $\\eta$, $\\varepsilon$, and $\\delta$, the tester $\\mathsf{Flash}$ correctly (with probability at least $ 1-\\delta$) distinguishes whether the underlying distribution of the Horn-sampler is \u201c$\\varepsilon$-close\u201d to $\\mathcal{I}$ or \u201c$\\eta$-far\u201d from $\\mathcal{I}$ by sampling only $\\widetilde{\\mathcal{O}}(\\mathsf{tilt}^3/(\\eta - \\varepsilon)^4)$ samples from the Horn-sampler, where the $\\mathsf{tilt}$ is the ratio of the maximum and the minimum (non-zero) probability masses of $\\mathcal{I}$. We also provide a prototype implementation of $\\mathsf{Flash}$ and test three state-of-the-art samplers on a set of benchmarks.",
        "bibtex": "@InProceedings{pmlr-v206-banerjee23a,\n  title = \t {Testing of Horn Samplers},\n  author =       {Banerjee, Ansuman and Chakraborty, Shayak and Chakraborty, Sourav and Meel, Kuldeep S. and Sarkar, Uddalok and Sen, Sayantan},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1301--1330},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/banerjee23a/banerjee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/banerjee23a.html},\n  abstract = \t {Sampling over combinatorial spaces is a fundamental problem in artificial intelligence with a wide variety of applications. Since state-of-the-art techniques heavily rely on heuristics whose rigorous analysis remains beyond the reach of current theoretical tools, the past few years have witnessed interest in the design of techniques to test the quality of samplers. The current state-of-the-art techniques, $\\mathsf{Barbarik}$ and $\\mathsf{Barbarik2}$, focuses on the cases where combinatorial spaces are encoded as Conjunctive Normal Form (CNF) formulas. While CNF is a general-purpose form, often techniques rely on exploiting specific representations to achieve speedup. Of particular interest are Horn clauses, which form the basis of the logic programming tools in AI. In this context, a natural question is whether it is possible to design a tester that can determine the correctness of a given Horn sampler. The primary contribution of this paper is an affirmative answer to the above question. We design the first tester, $\\mathsf{Flash}$, which tests the correctness of a given Horn sampler: given a specific distribution $\\mathcal{I}$ and parameters $\\eta$, $\\varepsilon$, and $\\delta$, the tester $\\mathsf{Flash}$ correctly (with probability at least $ 1-\\delta$) distinguishes whether the underlying distribution of the Horn-sampler is \u201c$\\varepsilon$-close\u201d to $\\mathcal{I}$ or \u201c$\\eta$-far\u201d from $\\mathcal{I}$ by sampling only $\\widetilde{\\mathcal{O}}(\\mathsf{tilt}^3/(\\eta - \\varepsilon)^4)$ samples from the Horn-sampler, where the $\\mathsf{tilt}$ is the ratio of the maximum and the minimum (non-zero) probability masses of $\\mathcal{I}$. We also provide a prototype implementation of $\\mathsf{Flash}$ and test three state-of-the-art samplers on a set of benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/banerjee23a/banerjee23a.pdf",
        "supp": "",
        "pdf_size": 508468,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1470149331406360404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b23654ae49",
        "title": "The ELBO of Variational Autoencoders Converges to a Sum of Entropies",
        "site": "https://proceedings.mlr.press/v206/damm23a.html",
        "author": "Simon Damm; Dennis Forster; Dmytro Velychko; Zhenwen Dai; Asja Fischer; J\u00f6rg L\u00fccke",
        "abstract": "The central objective function of a variational autoencoder (VAE) is its variational lower bound (the ELBO). Here we show that for standard (i.e., Gaussian) VAEs the ELBO converges to a value given by the sum of three entropies: the (negative) entropy of the prior distribution, the expected (negative) entropy of the observable distribution, and the average entropy of the variational distributions (the latter is already part of the ELBO). Our derived analytical results are exact and apply for small as well as for intricate deep networks for encoder and decoder. Furthermore, they apply for finitely and infinitely many data points and at any stationary point (including local maxima and saddle points). The result implies that the ELBO can for standard VAEs often be computed in closed-form at stationary points while the original ELBO requires numerical approximations of integrals. As a main contribution, we provide the proof that the ELBO for VAEs is at stationary points equal to entropy sums. Numerical experiments then show that the obtained analytical results are sufficiently precise also in those vicinities of stationary points that are reached in practice. Furthermore, we discuss how the novel entropy form of the ELBO can be used to analyze and understand learning behavior. More generally, we believe that our contributions can be useful for future theoretical and practical studies on VAE learning as they provide novel information on those points in parameters space that optimization of VAEs converges to.",
        "bibtex": "@InProceedings{pmlr-v206-damm23a,\n  title = \t {The ELBO of Variational Autoencoders Converges to a Sum of Entropies},\n  author =       {Damm, Simon and Forster, Dennis and Velychko, Dmytro and Dai, Zhenwen and Fischer, Asja and L\\\"ucke, J\\\"org},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3931--3960},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/damm23a/damm23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/damm23a.html},\n  abstract = \t {The central objective function of a variational autoencoder (VAE) is its variational lower bound (the ELBO). Here we show that for standard (i.e., Gaussian) VAEs the ELBO converges to a value given by the sum of three entropies: the (negative) entropy of the prior distribution, the expected (negative) entropy of the observable distribution, and the average entropy of the variational distributions (the latter is already part of the ELBO). Our derived analytical results are exact and apply for small as well as for intricate deep networks for encoder and decoder. Furthermore, they apply for finitely and infinitely many data points and at any stationary point (including local maxima and saddle points). The result implies that the ELBO can for standard VAEs often be computed in closed-form at stationary points while the original ELBO requires numerical approximations of integrals. As a main contribution, we provide the proof that the ELBO for VAEs is at stationary points equal to entropy sums. Numerical experiments then show that the obtained analytical results are sufficiently precise also in those vicinities of stationary points that are reached in practice. Furthermore, we discuss how the novel entropy form of the ELBO can be used to analyze and understand learning behavior. More generally, we believe that our contributions can be useful for future theoretical and practical studies on VAE learning as they provide novel information on those points in parameters space that optimization of VAEs converges to.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/damm23a/damm23a.pdf",
        "supp": "",
        "pdf_size": 7726340,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6220631266886658811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Ruhr-University Bochum, Germany; Frankfurt University of Applied Sciences, Germany+University of Oldenburg, Germany; University of Oldenburg, Germany; Spotify, London, UK; Ruhr-University Bochum, Germany; University of Oldenburg, Germany",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;2;3;0;2",
        "aff_unique_norm": "Ruhr-University Bochum;Frankfurt University of Applied Sciences;University of Oldenburg;Spotify",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.ruhr-uni-bochum.de;https://www.frankfurt-university.de;https://www.uni-oldenburg.de/;https://www.spotify.com",
        "aff_unique_abbr": "RUB;Frankfurt UAS;;Spotify",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0+0;0;1;0;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "14ded2f112",
        "title": "The Lauritzen-Chen Likelihood For Graphical Models",
        "site": "https://proceedings.mlr.press/v206/shpitser23a.html",
        "author": "Ilya Shpitser",
        "abstract": "Graphical models such as Markov random fields (MRFs) that are associated with undirected graphs, and Bayesian networks (BNs) that are associated with directed acyclic graphs, have proven to be a very popular approach for reasoning under uncertainty, prediction problems and causal inference. Parametric MRF likelihoods are well-studied for Gaussian and categorical data. However, in more complicated parametric and semi-parametric settings, likelihoods specified via clique potential functions are generally not known to be congenial or non-redundant. Congenial and non-redundant DAG likelihoods are far simpler to specify in both parametric and semi-parametric settings by modeling Markov factors in the DAG factorization. However, DAG likelihoods specified in this way are not guaranteed to coincide in distinct DAGs within the same Markov equivalence class. This complicates likelihoods based model selection procedures for DAGs by \u201csneaking in\u201d potentially unwarranted assumptions about edge orientations. In this paper we link a density function decomposition due to Chen with the clique factorization of MRFs described by Lauritzen to provide a general likelihood for MRF models. The proposed likelihood is composed of variationally independent, and non-redundant closed form functionals of the observed data distribution, and is sufficiently general to apply to arbitrary parametric and semi-parametric models. We use an extension of our developments to give a general likelihood for DAG models that is guaranteed to coincide for all members of a Markov equivalence class. Our results have direct applications for model selection and semi-parametric inference.",
        "bibtex": "@InProceedings{pmlr-v206-shpitser23a,\n  title = \t {The Lauritzen-Chen Likelihood For Graphical Models},\n  author =       {Shpitser, Ilya},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4181--4195},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/shpitser23a/shpitser23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/shpitser23a.html},\n  abstract = \t {Graphical models such as Markov random fields (MRFs) that are associated with undirected graphs, and Bayesian networks (BNs) that are associated with directed acyclic graphs, have proven to be a very popular approach for reasoning under uncertainty, prediction problems and causal inference. Parametric MRF likelihoods are well-studied for Gaussian and categorical data. However, in more complicated parametric and semi-parametric settings, likelihoods specified via clique potential functions are generally not known to be congenial or non-redundant. Congenial and non-redundant DAG likelihoods are far simpler to specify in both parametric and semi-parametric settings by modeling Markov factors in the DAG factorization. However, DAG likelihoods specified in this way are not guaranteed to coincide in distinct DAGs within the same Markov equivalence class. This complicates likelihoods based model selection procedures for DAGs by \u201csneaking in\u201d potentially unwarranted assumptions about edge orientations. In this paper we link a density function decomposition due to Chen with the clique factorization of MRFs described by Lauritzen to provide a general likelihood for MRF models. The proposed likelihood is composed of variationally independent, and non-redundant closed form functionals of the observed data distribution, and is sufficiently general to apply to arbitrary parametric and semi-parametric models. We use an extension of our developments to give a general likelihood for DAG models that is guaranteed to coincide for all members of a Markov equivalence class. Our results have direct applications for model selection and semi-parametric inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/shpitser23a/shpitser23a.pdf",
        "supp": "",
        "pdf_size": 329639,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=672034724981580122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Johns Hopkins University",
        "aff_domain": "cs.jhu.edu",
        "email": "cs.jhu.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5f0b011000",
        "title": "The Lie-Group Bayesian Learning Rule",
        "site": "https://proceedings.mlr.press/v206/kiral23a.html",
        "author": "Eren Mehmet Kiral; Thomas Moellenhoff; Mohammad Emtiyaz Khan",
        "abstract": "The Bayesian Learning Rule provides a framework for generic algorithm design but can be difficult to use for three reasons. First, it requires a specific parameterization of exponential family. Second, it uses gradients which can be difficult to compute. Third, its update may not always stay on the manifold. We address these difficulties by proposing an extension based on Lie-groups where posteriors are parametrized through transformations of an arbitrary base distribution and updated via the group\u2019s exponential map. This simplifies all three difficulties for many cases, providing flexible parametrizations through group\u2019s action, simple gradient computation through reparameterization, and updates that always stay on the manifold. We use the new learning rule to derive a new algorithm for deep learning with desirable biologically-plausible attributes to learn sparse features. Our work opens a new frontier for the design of new algorithms by exploiting lie-group structures.",
        "bibtex": "@InProceedings{pmlr-v206-kiral23a,\n  title = \t {The Lie-Group Bayesian Learning Rule},\n  author =       {Kiral, Eren Mehmet and Moellenhoff, Thomas and Khan, Mohammad Emtiyaz},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3331--3352},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kiral23a/kiral23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kiral23a.html},\n  abstract = \t {The Bayesian Learning Rule provides a framework for generic algorithm design but can be difficult to use for three reasons. First, it requires a specific parameterization of exponential family. Second, it uses gradients which can be difficult to compute. Third, its update may not always stay on the manifold. We address these difficulties by proposing an extension based on Lie-groups where posteriors are parametrized through transformations of an arbitrary base distribution and updated via the group\u2019s exponential map. This simplifies all three difficulties for many cases, providing flexible parametrizations through group\u2019s action, simple gradient computation through reparameterization, and updates that always stay on the manifold. We use the new learning rule to derive a new algorithm for deep learning with desirable biologically-plausible attributes to learn sparse features. Our work opens a new frontier for the design of new algorithms by exploiting lie-group structures.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kiral23a/kiral23a.pdf",
        "supp": "",
        "pdf_size": 897044,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2951203691515035149&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c4317c4aaa",
        "title": "The Ordered Matrix Dirichlet for State-Space Models",
        "site": "https://proceedings.mlr.press/v206/stoehr23a.html",
        "author": "Niklas Stoehr; Benjamin J. Radford; Ryan Cotterell; Aaron Schein",
        "abstract": "Many dynamical systems in the real world are naturally described by latent states with intrinsic ordering, such as \u201cally\u201d, \u201cneutral\u201d, and \u201cenemy\u201d relationships in international relations. These latent states manifest through countries\u2019 cooperative versus conflictual interactions over time. State-space models (SSMs) explicitly relate the dynamics of observed measurements to transitions in latent states. For discrete data, SSMs commonly do so through a state-to-action emission matrix and a state-to-state transition matrix. This paper introduces the Ordered Matrix Dirichlet (OMD) as a prior distribution over ordered stochastic matrices wherein the discrete distribution in the kth row is stochastically dominated by the (k+1)th, such that probability mass is shifted to the right when moving down rows. We illustrate the OMD prior within two SSMs: a hidden Markov model, and a novel dynamic Poisson Tucker decomposition model tailored to international relations data. We find that models built on the OMD recover interpretable ordered latent structure without forfeiting predictive performance. We suggest future applications to other domains where models with stochastic matrices are popular (e.g., topic modeling), and publish user-friendly code.",
        "bibtex": "@InProceedings{pmlr-v206-stoehr23a,\n  title = \t {The Ordered Matrix Dirichlet for State-Space Models},\n  author =       {Stoehr, Niklas and Radford, Benjamin J. and Cotterell, Ryan and Schein, Aaron},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1888--1903},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/stoehr23a/stoehr23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/stoehr23a.html},\n  abstract = \t {Many dynamical systems in the real world are naturally described by latent states with intrinsic ordering, such as \u201cally\u201d, \u201cneutral\u201d, and \u201cenemy\u201d relationships in international relations. These latent states manifest through countries\u2019 cooperative versus conflictual interactions over time. State-space models (SSMs) explicitly relate the dynamics of observed measurements to transitions in latent states. For discrete data, SSMs commonly do so through a state-to-action emission matrix and a state-to-state transition matrix. This paper introduces the Ordered Matrix Dirichlet (OMD) as a prior distribution over ordered stochastic matrices wherein the discrete distribution in the kth row is stochastically dominated by the (k+1)th, such that probability mass is shifted to the right when moving down rows. We illustrate the OMD prior within two SSMs: a hidden Markov model, and a novel dynamic Poisson Tucker decomposition model tailored to international relations data. We find that models built on the OMD recover interpretable ordered latent structure without forfeiting predictive performance. We suggest future applications to other domains where models with stochastic matrices are popular (e.g., topic modeling), and publish user-friendly code.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/stoehr23a/stoehr23a.pdf",
        "supp": "",
        "pdf_size": 2742419,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17744134808390719199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "ETH Zurich; UNC Charlotte; ETH Zurich; The University of Chicago",
        "aff_domain": "inf.ethz.ch;uncc.edu;inf.ethz.ch;uchicago.edu",
        "email": "inf.ethz.ch;uncc.edu;inf.ethz.ch;uchicago.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "ETH Zurich;University of North Carolina at Charlotte;University of Chicago",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ethz.ch;https://www.uncc.edu;https://www.uchicago.edu",
        "aff_unique_abbr": "ETHZ;UNCC;UChicago",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Charlotte",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "54ad5cf1f3",
        "title": "The Power of Recursion in Graph Neural Networks for Counting Substructures",
        "site": "https://proceedings.mlr.press/v206/tahmasebi23a.html",
        "author": "Behrooz Tahmasebi; Derek Lim; Stefanie Jegelka",
        "abstract": "To achieve a graph representation, most Graph Neural Networks (GNNs) follow two steps: first, each graph is decomposed into a number of subgraphs (which we call the recursion step), and then the collection of subgraphs is encoded by several iterative pooling steps. While recently proposed higher-order networks show a remarkable increase in the expressive power through a single recursion on larger neighborhoods followed by iterative pooling, the power of deeper recursion in GNNs without any iterative pooling is still not fully understood. To make it concrete, we consider a pure recursion-based GNN which we call Recursive Neighborhood Pooling GNN (RNP-GNN). The expressive power of an RNP-GNN and its computational cost quantifies the power of (pure) recursion for a graph representation network. We quantify the power by means of counting substructures, which is one main limitation of the Message Passing graph Neural Networks (MPNNs), and show how RNP-GNN can exploit the sparsity of the underlying graph to achieve low-cost powerful representations. We also compare the recent lower bounds on the time complexity and show how recursion-based networks are near optimal.",
        "bibtex": "@InProceedings{pmlr-v206-tahmasebi23a,\n  title = \t {The Power of Recursion in Graph Neural Networks for Counting Substructures},\n  author =       {Tahmasebi, Behrooz and Lim, Derek and Jegelka, Stefanie},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11023--11042},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tahmasebi23a/tahmasebi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tahmasebi23a.html},\n  abstract = \t {To achieve a graph representation, most Graph Neural Networks (GNNs) follow two steps: first, each graph is decomposed into a number of subgraphs (which we call the recursion step), and then the collection of subgraphs is encoded by several iterative pooling steps. While recently proposed higher-order networks show a remarkable increase in the expressive power through a single recursion on larger neighborhoods followed by iterative pooling, the power of deeper recursion in GNNs without any iterative pooling is still not fully understood. To make it concrete, we consider a pure recursion-based GNN which we call Recursive Neighborhood Pooling GNN (RNP-GNN). The expressive power of an RNP-GNN and its computational cost quantifies the power of (pure) recursion for a graph representation network. We quantify the power by means of counting substructures, which is one main limitation of the Message Passing graph Neural Networks (MPNNs), and show how RNP-GNN can exploit the sparsity of the underlying graph to achieve low-cost powerful representations. We also compare the recent lower bounds on the time complexity and show how recursion-based networks are near optimal.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tahmasebi23a/tahmasebi23a.pdf",
        "supp": "",
        "pdf_size": 363345,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4534382830984577617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0e49abbd18",
        "title": "The Role of Codeword-to-Class Assignments in Error-Correcting Codes: An Empirical Study",
        "site": "https://proceedings.mlr.press/v206/evron23a.html",
        "author": "Itay Evron; Ophir Onn; Tamar Weiss; Hai Azeroual; Daniel Soudry",
        "abstract": "Error-correcting codes (ECC) are used to reduce multiclass classification tasks to multiple binary classification subproblems. In ECC, classes are represented by the rows of a binary matrix, corresponding to codewords in a codebook. Codebooks are commonly either predefined or problem dependent. Given predefined codebooks, codeword-to-class assignments are traditionally overlooked, and codewords are implicitly assigned to classes arbitrarily. Our paper shows that these assignments play a major role in the performance of ECC. Specifically, we examine similarity-preserving assignments, where similar codewords are assigned to similar classes. Addressing a controversy in existing literature, our extensive experiments confirm that similarity-preserving assignments induce easier subproblems and are superior to other assignment policies in terms of their generalization performance. We find that similarity-preserving assignments make predefined codebooks become problem-dependent, without altering other favorable codebook properties. Finally, we show that our findings can improve predefined codebooks dedicated to extreme classification.",
        "bibtex": "@InProceedings{pmlr-v206-evron23a,\n  title = \t {The Role of Codeword-to-Class Assignments in Error-Correcting Codes: An Empirical Study},\n  author =       {Evron, Itay and Onn, Ophir and Weiss, Tamar and Azeroual, Hai and Soudry, Daniel},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8053--8077},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/evron23a/evron23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/evron23a.html},\n  abstract = \t {Error-correcting codes (ECC) are used to reduce multiclass classification tasks to multiple binary classification subproblems. In ECC, classes are represented by the rows of a binary matrix, corresponding to codewords in a codebook. Codebooks are commonly either predefined or problem dependent. Given predefined codebooks, codeword-to-class assignments are traditionally overlooked, and codewords are implicitly assigned to classes arbitrarily. Our paper shows that these assignments play a major role in the performance of ECC. Specifically, we examine similarity-preserving assignments, where similar codewords are assigned to similar classes. Addressing a controversy in existing literature, our extensive experiments confirm that similarity-preserving assignments induce easier subproblems and are superior to other assignment policies in terms of their generalization performance. We find that similarity-preserving assignments make predefined codebooks become problem-dependent, without altering other favorable codebook properties. Finally, we show that our findings can improve predefined codebooks dedicated to extreme classification.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/evron23a/evron23a.pdf",
        "supp": "",
        "pdf_size": 2164200,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15653138806737150310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "71b33141fa",
        "title": "The Schr\u00f6dinger Bridge between Gaussian Measures has a Closed Form",
        "site": "https://proceedings.mlr.press/v206/bunne23a.html",
        "author": "Charlotte Bunne; Ya-Ping Hsieh; Marco Cuturi; Andreas Krause",
        "abstract": "The static optimal transport $(\\mathrm{OT})$ problem between Gaussians seeks to recover an optimal map, or more generally a coupling, to morph a Gaussian into another. It has been well studied and applied to a wide variety of tasks. Here we focus on the dynamic formulation of OT, also known as the Schr\u00f6dinger bridge (SB) problem, which has recently seen a surge of interest in machine learning due to its connections with diffusion-based generative models. In contrast to the static setting, much less is known about the dynamic setting, even for Gaussian distributions. In this paper, we provide closed-form expressions for SBs between Gaussian measures. In contrast to the static Gaussian OT problem, which can be simply reduced to studying convex programs, our framework for solving SBs requires significantly more involved tools such as Riemannian geometry and generator theory. Notably, we establish that the solutions of SBs between Gaussian measures are themselves Gaussian processes with explicit mean and covariance kernels, and thus are readily amenable for many downstream applications such as generative modeling or interpolation. To demonstrate the utility, we devise a new method for modeling the evolution of single-cell genomics data and report significantly improved numerical stability compared to existing SB-based approaches.",
        "bibtex": "@InProceedings{pmlr-v206-bunne23a,\n  title = \t {The Schr\u00f6dinger Bridge between Gaussian Measures has a Closed Form},\n  author =       {Bunne, Charlotte and Hsieh, Ya-Ping and Cuturi, Marco and Krause, Andreas},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5802--5833},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/bunne23a/bunne23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/bunne23a.html},\n  abstract = \t {The static optimal transport $(\\mathrm{OT})$ problem between Gaussians seeks to recover an optimal map, or more generally a coupling, to morph a Gaussian into another. It has been well studied and applied to a wide variety of tasks. Here we focus on the dynamic formulation of OT, also known as the Schr\u00f6dinger bridge (SB) problem, which has recently seen a surge of interest in machine learning due to its connections with diffusion-based generative models. In contrast to the static setting, much less is known about the dynamic setting, even for Gaussian distributions. In this paper, we provide closed-form expressions for SBs between Gaussian measures. In contrast to the static Gaussian OT problem, which can be simply reduced to studying convex programs, our framework for solving SBs requires significantly more involved tools such as Riemannian geometry and generator theory. Notably, we establish that the solutions of SBs between Gaussian measures are themselves Gaussian processes with explicit mean and covariance kernels, and thus are readily amenable for many downstream applications such as generative modeling or interpolation. To demonstrate the utility, we devise a new method for modeling the evolution of single-cell genomics data and report significantly improved numerical stability compared to existing SB-based approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/bunne23a/bunne23a.pdf",
        "supp": "",
        "pdf_size": 4761731,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10735180706941679303&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich; Apple\u2021ETH Z\u00fcrich; ETH Z\u00fcrich",
        "aff_domain": "ethz.ch;ethz.ch;apple.com;ethz.ch",
        "email": "ethz.ch;ethz.ch;apple.com;ethz.ch",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "848c0ba62a",
        "title": "The communication cost of security and privacy in federated frequency estimation",
        "site": "https://proceedings.mlr.press/v206/chen23e.html",
        "author": "Wei-Ning Chen; Ayfer Ozgur; Graham Cormode; Akash Bharadwaj",
        "abstract": "We consider the federated frequency estimation problem, where each user holds a private item $X_i$ from a size-$d$ domain and a server aims to estimate the empirical frequency (i.e., histogram) of $n$ items with $n \\ll d$. Without any security and privacy considerations, each user can communicate its item to the server by using $\\log d$ bits. A naive application of secure aggregation protocols would, however, require $d\\log n$ bits per user. Can we reduce the communication needed for secure aggregation, and does security come with a fundamental cost in communication? In this paper, we develop an information-theoretic model for secure aggregation that allows us to characterize the fundamental cost of security and privacy in terms of communication. We show that with security (and without privacy) $\\Omega\\left( n \\log d \\right)$ bits per user are necessary and sufficient to allow the server to compute the frequency distribution. This is significantly smaller than the $d\\log n$ bits per user needed by the naive scheme but significantly higher than the $\\log d$ bits per user needed without security. To achieve differential privacy, we construct a linear scheme based on a noisy sketch that locally perturbs the data and does not require a trusted server (a.k.a. distributed differential privacy). We analyze this scheme under $\\ell_2$ and $\\ell_\\infty$ loss. By using our information-theoretic framework, we show that the scheme achieves the optimal accuracy-privacy trade-off with optimal communication cost, while matching the performance in the centralized case where data is stored in the central server.",
        "bibtex": "@InProceedings{pmlr-v206-chen23e,\n  title = \t {The communication cost of security and privacy in federated frequency estimation},\n  author =       {Chen, Wei-Ning and Ozgur, Ayfer and Cormode, Graham and Bharadwaj, Akash},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4247--4274},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chen23e/chen23e.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chen23e.html},\n  abstract = \t {We consider the federated frequency estimation problem, where each user holds a private item $X_i$ from a size-$d$ domain and a server aims to estimate the empirical frequency (i.e., histogram) of $n$ items with $n \\ll d$. Without any security and privacy considerations, each user can communicate its item to the server by using $\\log d$ bits. A naive application of secure aggregation protocols would, however, require $d\\log n$ bits per user. Can we reduce the communication needed for secure aggregation, and does security come with a fundamental cost in communication? In this paper, we develop an information-theoretic model for secure aggregation that allows us to characterize the fundamental cost of security and privacy in terms of communication. We show that with security (and without privacy) $\\Omega\\left( n \\log d \\right)$ bits per user are necessary and sufficient to allow the server to compute the frequency distribution. This is significantly smaller than the $d\\log n$ bits per user needed by the naive scheme but significantly higher than the $\\log d$ bits per user needed without security. To achieve differential privacy, we construct a linear scheme based on a noisy sketch that locally perturbs the data and does not require a trusted server (a.k.a. distributed differential privacy). We analyze this scheme under $\\ell_2$ and $\\ell_\\infty$ loss. By using our information-theoretic framework, we show that the scheme achieves the optimal accuracy-privacy trade-off with optimal communication cost, while matching the performance in the centralized case where data is stored in the central server.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chen23e/chen23e.pdf",
        "supp": "",
        "pdf_size": 4383906,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15934562302878574580&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "19304685ba",
        "title": "Theoretically Grounded Loss Functions and Algorithms for Adversarial Robustness",
        "site": "https://proceedings.mlr.press/v206/awasthi23c.html",
        "author": "Pranjal Awasthi; Anqi Mao; Mehryar Mohri; Yutao Zhong",
        "abstract": "Adversarial robustness is a critical property of classifiers in applications as they are increasingly deployed in complex real-world systems. Yet, achieving accurate adversarial robustness in machine learning remains a persistent challenge and the choice of the surrogate loss function used for training a key factor. We present a family of new loss functions for adversarial robustness, smooth adversarial losses, which we show can be derived in a general way from broad families of loss functions used in multi-class classification. We prove strong H-consistency theoretical guarantees for these loss functions, including multi-class H-consistency bounds for sum losses in the adversarial setting. We design new regularized algorithms based on the minimization of these principled smooth adversarial losses (PSAL). We further show through a series of extensive experiments with the CIFAR-10, CIFAR-100 and SVHN datasets that our PSAL algorithm consistently outperforms the current state-of-the-art technique, TRADES, for both robust accuracy against l-infinity-norm bounded perturbations and, even more significantly, for clean accuracy. Finally, we prove that, unlike PSAL, the TRADES loss in general does not admit an H-consistency property.",
        "bibtex": "@InProceedings{pmlr-v206-awasthi23c,\n  title = \t {Theoretically Grounded Loss Functions and Algorithms for Adversarial Robustness},\n  author =       {Awasthi, Pranjal and Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10077--10094},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/awasthi23c/awasthi23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/awasthi23c.html},\n  abstract = \t {Adversarial robustness is a critical property of classifiers in applications as they are increasingly deployed in complex real-world systems. Yet, achieving accurate adversarial robustness in machine learning remains a persistent challenge and the choice of the surrogate loss function used for training a key factor. We present a family of new loss functions for adversarial robustness, smooth adversarial losses, which we show can be derived in a general way from broad families of loss functions used in multi-class classification. We prove strong H-consistency theoretical guarantees for these loss functions, including multi-class H-consistency bounds for sum losses in the adversarial setting. We design new regularized algorithms based on the minimization of these principled smooth adversarial losses (PSAL). We further show through a series of extensive experiments with the CIFAR-10, CIFAR-100 and SVHN datasets that our PSAL algorithm consistently outperforms the current state-of-the-art technique, TRADES, for both robust accuracy against l-infinity-norm bounded perturbations and, even more significantly, for clean accuracy. Finally, we prove that, unlike PSAL, the TRADES loss in general does not admit an H-consistency property.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/awasthi23c/awasthi23c.pdf",
        "supp": "",
        "pdf_size": 679496,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18127492452842805630&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "23eda11f95",
        "title": "Theory and Algorithm for Batch Distribution Drift Problems",
        "site": "https://proceedings.mlr.press/v206/awasthi23b.html",
        "author": "Pranjal Awasthi; Corinna Cortes; Christopher Mohri",
        "abstract": "We study a problem of batch distribution drift motivated by several applications, which consists of determining an accurate predictor for a target time segment, for which a moderate amount of labeled samples are at one\u2019s disposal, while leveraging past segments for which substantially more labeled samples are available. We give new algorithms for this problem guided by a new theoretical analysis and generalization bounds derived for this scenario. We further extend our results to the case where few or no labeled data is available for the period of interest. Finally, we report the results of extensive experiments demonstrating the benefits of our drifting algorithm, including comparisons with natural baselines. A by-product of our study is a principled solution to the problem of multiple-source adaptation with labeled source data and a moderate amount of target labeled data, which we briefly discuss and compare with.",
        "bibtex": "@InProceedings{pmlr-v206-awasthi23b,\n  title = \t {Theory and Algorithm for Batch Distribution Drift Problems},\n  author =       {Awasthi, Pranjal and Cortes, Corinna and Mohri, Christopher},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {9826--9851},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/awasthi23b/awasthi23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/awasthi23b.html},\n  abstract = \t {We study a problem of batch distribution drift motivated by several applications, which consists of determining an accurate predictor for a target time segment, for which a moderate amount of labeled samples are at one\u2019s disposal, while leveraging past segments for which substantially more labeled samples are available. We give new algorithms for this problem guided by a new theoretical analysis and generalization bounds derived for this scenario. We further extend our results to the case where few or no labeled data is available for the period of interest. Finally, we report the results of extensive experiments demonstrating the benefits of our drifting algorithm, including comparisons with natural baselines. A by-product of our study is a principled solution to the problem of multiple-source adaptation with labeled source data and a moderate amount of target labeled data, which we briefly discuss and compare with.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/awasthi23b/awasthi23b.pdf",
        "supp": "",
        "pdf_size": 1156021,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=478617926879781296&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "320ed0b8db",
        "title": "Thresholded linear bandits",
        "site": "https://proceedings.mlr.press/v206/mehta23a.html",
        "author": "Nishant A. Mehta; Junpei Komiyama; Vamsi K. Potluru; Andrea Nguyen; Mica Grant-Hagen",
        "abstract": "We introduce the thresholded linear bandit problem, a novel sequential decision making problem at the interface of structured stochastic multi-armed bandits and learning halfspaces. The set of arms is $[0, 1]^d$, the expected Bernoulli reward is piecewise constant with a jump at a separating hyperplane, and each arm is associated with a cost that is a positive linear combination of the arm\u2019s components. This problem is motivated by several practical applications. For instance, imagine tuning the continuous features of an offer to a consumer; higher values incur higher cost to the vendor but result in a more attractive offer. At some threshold, the offer is attractive enough for a random consumer to accept at the higher probability level. For the one-dimensional case, we present Leftist, which enjoys $\\log^2 T$ problem-dependent regret in favorable cases and has $\\log(T) \\sqrt{T}$ worst-case regret; we also give a lower bound suggesting this is unimprovable. We then present MD-Leftist, our extension of Leftist to the multi-dimensional case, which obtains similar regret bounds but with $d^{2.5} \\log d$ and $d^{1.5} \\log d$ dependence on dimension for the two types of bounds respectively. Finally, we experimentally evaluate Leftist.",
        "bibtex": "@InProceedings{pmlr-v206-mehta23a,\n  title = \t {Thresholded linear bandits},\n  author =       {Mehta, Nishant A. and Komiyama, Junpei and Potluru, Vamsi K. and Nguyen, Andrea and Grant-Hagen, Mica},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6968--7020},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mehta23a/mehta23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mehta23a.html},\n  abstract = \t {We introduce the thresholded linear bandit problem, a novel sequential decision making problem at the interface of structured stochastic multi-armed bandits and learning halfspaces. The set of arms is $[0, 1]^d$, the expected Bernoulli reward is piecewise constant with a jump at a separating hyperplane, and each arm is associated with a cost that is a positive linear combination of the arm\u2019s components. This problem is motivated by several practical applications. For instance, imagine tuning the continuous features of an offer to a consumer; higher values incur higher cost to the vendor but result in a more attractive offer. At some threshold, the offer is attractive enough for a random consumer to accept at the higher probability level. For the one-dimensional case, we present Leftist, which enjoys $\\log^2 T$ problem-dependent regret in favorable cases and has $\\log(T) \\sqrt{T}$ worst-case regret; we also give a lower bound suggesting this is unimprovable. We then present MD-Leftist, our extension of Leftist to the multi-dimensional case, which obtains similar regret bounds but with $d^{2.5} \\log d$ and $d^{1.5} \\log d$ dependence on dimension for the two types of bounds respectively. Finally, we experimentally evaluate Leftist.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mehta23a/mehta23a.pdf",
        "supp": "",
        "pdf_size": 1229721,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8778474785303194359&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Victoria; New York University; J.P. Morgan AI Research; University of Victoria; University of Victoria",
        "aff_domain": "uvic.ca;komiyama.info;jpmchase.com;uvic.ca;uvic.ca",
        "email": "uvic.ca;komiyama.info;jpmchase.com;uvic.ca;uvic.ca",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "University of Victoria;New York University;J.P. Morgan",
        "aff_unique_dep": ";;AI Research",
        "aff_unique_url": "https://www.uvic.ca;https://www.nyu.edu;https://www.jpmorgan.com",
        "aff_unique_abbr": "UVic;NYU;JPM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "eea01fa990",
        "title": "Tight Regret and Complexity Bounds for Thompson Sampling via Langevin Monte Carlo",
        "site": "https://proceedings.mlr.press/v206/huix23a.html",
        "author": "Tom Huix; Matthew Zhang; Alain Durmus",
        "abstract": "In this paper, we consider high dimensional contextual bandit problems. Within this setting, Thompson Sampling and its variants have been proposed and have been successfully applied to multiple machine learning problems. Existing theory on Thompson Sampling shows that it has suboptimal dimension dependency in contrast to upper confidence bound (UCB) algorithms. To circumvent this issue and obtain optimal regret bounds, (Zhang, 2021) recently proposed to modify Thompson Sampling by enforcing more exploration and hence is able to attain optimal regret bounds. Nonetheless, this analysis does not permit tractable implementation in high dimensions. The main challenge therein is the simulation of the posterior samples at each step given the available observations. To overcome this, we propose and analyze the use of Markov Chain Monte Carlo methods. As a corollary, we show that for contextual linear bandits, using Langevin Monte Carlo (LMC) or Metropolis Adjusted Langevin Algorithm (MALA), our algorithm attains optimal regret bounds of $\\tilde{O}(d\\sqrt{T})$. Furthermore, we show that this is obtained with $\\tilde{O}(dT^4)$, $\\tilde{O}(dT^2)$ data evaluations respectively for LMC and MALA. Finally, we validate our findings through numerical simulations and show that we outperform vanilla Thompson sampling in high dimensions.",
        "bibtex": "@InProceedings{pmlr-v206-huix23a,\n  title = \t {Tight Regret and Complexity Bounds for Thompson Sampling via Langevin Monte Carlo},\n  author =       {Huix, Tom and Zhang, Matthew and Durmus, Alain},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8749--8770},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/huix23a/huix23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/huix23a.html},\n  abstract = \t {In this paper, we consider high dimensional contextual bandit problems. Within this setting, Thompson Sampling and its variants have been proposed and have been successfully applied to multiple machine learning problems. Existing theory on Thompson Sampling shows that it has suboptimal dimension dependency in contrast to upper confidence bound (UCB) algorithms. To circumvent this issue and obtain optimal regret bounds, (Zhang, 2021) recently proposed to modify Thompson Sampling by enforcing more exploration and hence is able to attain optimal regret bounds. Nonetheless, this analysis does not permit tractable implementation in high dimensions. The main challenge therein is the simulation of the posterior samples at each step given the available observations. To overcome this, we propose and analyze the use of Markov Chain Monte Carlo methods. As a corollary, we show that for contextual linear bandits, using Langevin Monte Carlo (LMC) or Metropolis Adjusted Langevin Algorithm (MALA), our algorithm attains optimal regret bounds of $\\tilde{O}(d\\sqrt{T})$. Furthermore, we show that this is obtained with $\\tilde{O}(dT^4)$, $\\tilde{O}(dT^2)$ data evaluations respectively for LMC and MALA. Finally, we validate our findings through numerical simulations and show that we outperform vanilla Thompson sampling in high dimensions.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/huix23a/huix23a.pdf",
        "supp": "",
        "pdf_size": 2260803,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10624384830336788385&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "caf883df2e",
        "title": "Tighter PAC-Bayes Generalisation Bounds by Leveraging Example Difficulty",
        "site": "https://proceedings.mlr.press/v206/biggs23a.html",
        "author": "Felix Biggs; Benjamin Guedj",
        "abstract": "We introduce a modified version of the excess risk, which can be used to obtain empirically tighter, faster-rate PAC-Bayesian generalisation bounds. This modified excess risk leverages information about the relative hardness of data examples to reduce the variance of its empirical counterpart, tightening the bound. We combine this with a new bound for [$-$1, 1]-valued (and potentially non-independent) signed losses, which is more favourable when they empirically have low variance around 0. The primary new technical tool is a novel result for sequences of interdependent random vectors which may be of independent interest. We empirically evaluate these new bounds on a number of real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v206-biggs23a,\n  title = \t {Tighter PAC-Bayes Generalisation Bounds by Leveraging Example Difficulty},\n  author =       {Biggs, Felix and Guedj, Benjamin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8165--8182},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/biggs23a/biggs23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/biggs23a.html},\n  abstract = \t {We introduce a modified version of the excess risk, which can be used to obtain empirically tighter, faster-rate PAC-Bayesian generalisation bounds. This modified excess risk leverages information about the relative hardness of data examples to reduce the variance of its empirical counterpart, tightening the bound. We combine this with a new bound for [$-$1, 1]-valued (and potentially non-independent) signed losses, which is more favourable when they empirically have low variance around 0. The primary new technical tool is a novel result for sequences of interdependent random vectors which may be of independent interest. We empirically evaluate these new bounds on a number of real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/biggs23a/biggs23a.pdf",
        "supp": "",
        "pdf_size": 440934,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1067718785989548159&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "University College London and Inria; University College London and Inria",
        "aff_domain": "felixbiggs.com;ucl.ac.uk",
        "email": "felixbiggs.com;ucl.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "f1d3c63166",
        "title": "To Impute or not to Impute? Missing Data in Treatment Effect Estimation",
        "site": "https://proceedings.mlr.press/v206/berrevoets23a.html",
        "author": "Jeroen Berrevoets; Fergus Imrie; Trent Kyono; James Jordon; Mihaela van der Schaar",
        "abstract": "Missing data is a systemic problem in practical scenarios that causes noise and bias when estimating treatment effects. This makes treatment effect estimation from data with missingness a particularly tricky endeavour. A key reason for this is that standard assumptions on missingness are rendered insufficient due to the presence of an additional variable, treatment, besides the input (e.g. an individual) and the label (e.g. an outcome). The treatment variable introduces additional complexity with respect to why some variables are missing that is not fully explored by previous work. In our work we introduce mixed confounded missingness (MCM), a new missingness mechanism where some missingness determines treatment selection and other missingness is determined by treatment selection. Given MCM, we show that naively imputing all data leads to poor performing treatment effects models, as the act of imputation effectively removes information necessary to provide unbiased estimates. However, no imputation at all also leads to biased estimates, as missingness determined by treatment introduces bias in covariates. Our solution is selective imputation, where we use insights from MCM to inform precisely which variables should be imputed and which should not. We empirically demonstrate how various learners benefit from selective imputation compared to other solutions for missing data. We highlight that our experiments encompass both average treatment effects and conditional average treatment effects.",
        "bibtex": "@InProceedings{pmlr-v206-berrevoets23a,\n  title = \t {To Impute or not to Impute? Missing Data in Treatment Effect Estimation},\n  author =       {Berrevoets, Jeroen and Imrie, Fergus and Kyono, Trent and Jordon, James and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3568--3590},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/berrevoets23a/berrevoets23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/berrevoets23a.html},\n  abstract = \t {Missing data is a systemic problem in practical scenarios that causes noise and bias when estimating treatment effects. This makes treatment effect estimation from data with missingness a particularly tricky endeavour. A key reason for this is that standard assumptions on missingness are rendered insufficient due to the presence of an additional variable, treatment, besides the input (e.g. an individual) and the label (e.g. an outcome). The treatment variable introduces additional complexity with respect to why some variables are missing that is not fully explored by previous work. In our work we introduce mixed confounded missingness (MCM), a new missingness mechanism where some missingness determines treatment selection and other missingness is determined by treatment selection. Given MCM, we show that naively imputing all data leads to poor performing treatment effects models, as the act of imputation effectively removes information necessary to provide unbiased estimates. However, no imputation at all also leads to biased estimates, as missingness determined by treatment introduces bias in covariates. Our solution is selective imputation, where we use insights from MCM to inform precisely which variables should be imputed and which should not. We empirically demonstrate how various learners benefit from selective imputation compared to other solutions for missing data. We highlight that our experiments encompass both average treatment effects and conditional average treatment effects.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/berrevoets23a/berrevoets23a.pdf",
        "supp": "",
        "pdf_size": 338931,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12312409550453998112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Cambridge; UCLA; Meta; Alan Turing Institute; University of Cambridge + Alan Turing Institute",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0+3",
        "aff_unique_norm": "University of Cambridge;University of California, Los Angeles;Meta;Alan Turing Institute",
        "aff_unique_dep": ";;Meta Platforms, Inc.;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.ucla.edu;https://meta.com;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;UCLA;Meta;ATI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cambridge;Los Angeles;",
        "aff_country_unique_index": "0;1;1;0;0+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "a7fb7f38ef",
        "title": "Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling",
        "site": "https://proceedings.mlr.press/v206/wang23c.html",
        "author": "Rui Wang; Pengyu Cheng; Ricardo Henao",
        "abstract": "Pretrained language models (PLMs), such as GPT- 2, have achieved remarkable empirical performance in text generation tasks. However, pre- trained on large-scale natural language corpora, the generated text from PLMs may exhibit social bias against disadvantaged demographic groups. To improve the fairness of PLMs in text generation, we propose to minimize the mutual information between the semantics in the generated text sentences and their demographic polarity, i.e., the demographic group to which the sentence is referring. In this way, the mentioning of a demographic group (e.g., male or female) is encouraged to be independent from how it is described in the generated text, thus effectively alleviating the so cial bias. Moreover, we propose to efficiently estimate the upper bound of the above mutual information via importance sampling, leveraging a natural language corpus. We also propose a distillation mechanism that preserves the language modeling ability of the PLMs after debiasing. Empirical results on real-world benchmarks demonstrate that the proposed method yields superior performance in term of both fairness and language modeling ability.",
        "bibtex": "@InProceedings{pmlr-v206-wang23c,\n  title = \t {Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling},\n  author =       {Wang, Rui and Cheng, Pengyu and Henao, Ricardo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4473--4485},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23c/wang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23c.html},\n  abstract = \t {Pretrained language models (PLMs), such as GPT- 2, have achieved remarkable empirical performance in text generation tasks. However, pre- trained on large-scale natural language corpora, the generated text from PLMs may exhibit social bias against disadvantaged demographic groups. To improve the fairness of PLMs in text generation, we propose to minimize the mutual information between the semantics in the generated text sentences and their demographic polarity, i.e., the demographic group to which the sentence is referring. In this way, the mentioning of a demographic group (e.g., male or female) is encouraged to be independent from how it is described in the generated text, thus effectively alleviating the so cial bias. Moreover, we propose to efficiently estimate the upper bound of the above mutual information via importance sampling, leveraging a natural language corpus. We also propose a distillation mechanism that preserves the language modeling ability of the PLMs after debiasing. Empirical results on real-world benchmarks demonstrate that the proposed method yields superior performance in term of both fairness and language modeling ability.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23c/wang23c.pdf",
        "supp": "",
        "pdf_size": 430662,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6749704851417840422&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Duke University; Tencent AI Lab; Duke University & KAUST",
        "aff_domain": "duke.edu; ; ",
        "email": "duke.edu; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Duke University;Tencent",
        "aff_unique_dep": ";Tencent AI Lab",
        "aff_unique_url": "https://www.duke.edu;https://ai.tencent.com",
        "aff_unique_abbr": "Duke;Tencent AI Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "110653d57b",
        "title": "Towards Balanced Representation Learning for Credit Policy Evaluation",
        "site": "https://proceedings.mlr.press/v206/huang23b.html",
        "author": "Yiyan Huang; Cheuk Hang Leung; Shumin Ma; Zhiri Yuan; Qi Wu; Siyi Wang; Dongdong Wang; Zhixiang Huang",
        "abstract": "Credit policy evaluation presents profitable opportunities for E-commerce platforms through improved decision-making. The core of policy evaluation is estimating the causal effects of the policy on the target outcome. However, selection bias presents a key challenge in estimating causal effects from real-world data. Some recent causal inference methods attempt to mitigate selection bias by leveraging covariate balancing in the representation space to obtain the domain-invariant features. However, it is noticeable that balanced representation learning can be accompanied by a failure of domain discrimination, resulting in the loss of domain-related information. This is referred to as the over-balancing issue. In this paper, we introduce a novel objective for representation balancing methods to do policy evaluation. In particular, we construct a doubly robust loss based on the predictions of treatment and outcomes, serving as a prerequisite for covariate balancing to deal with the over-balancing issue. In addition, we investigate how to improve treatment effect estimations by exploiting the unconfoundedness assumption. The extensive experimental results on benchmark datasets and a newly introduced credit dataset show a general outperformance of our method compared with existing methods.",
        "bibtex": "@InProceedings{pmlr-v206-huang23b,\n  title = \t {Towards Balanced Representation Learning for Credit Policy Evaluation},\n  author =       {Huang, Yiyan and Leung, Cheuk Hang and Ma, Shumin and Yuan, Zhiri and Wu, Qi and Wang, Siyi and Wang, Dongdong and Huang, Zhixiang},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3677--3692},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/huang23b/huang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/huang23b.html},\n  abstract = \t {Credit policy evaluation presents profitable opportunities for E-commerce platforms through improved decision-making. The core of policy evaluation is estimating the causal effects of the policy on the target outcome. However, selection bias presents a key challenge in estimating causal effects from real-world data. Some recent causal inference methods attempt to mitigate selection bias by leveraging covariate balancing in the representation space to obtain the domain-invariant features. However, it is noticeable that balanced representation learning can be accompanied by a failure of domain discrimination, resulting in the loss of domain-related information. This is referred to as the over-balancing issue. In this paper, we introduce a novel objective for representation balancing methods to do policy evaluation. In particular, we construct a doubly robust loss based on the predictions of treatment and outcomes, serving as a prerequisite for covariate balancing to deal with the over-balancing issue. In addition, we investigate how to improve treatment effect estimations by exploiting the unconfoundedness assumption. The extensive experimental results on benchmark datasets and a newly introduced credit dataset show a general outperformance of our method compared with existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/huang23b/huang23b.pdf",
        "supp": "",
        "pdf_size": 3103060,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2713041393118390615&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "City University of Hong Kong; City University of Hong Kong; BNU-HKBU United International College; City University of Hong Kong; City University of Hong Kong; City University of Hong Kong; JD Digits; JD Digits",
        "aff_domain": "my.cityu.edu.hk;cityu.edu.hk;uic.edu.cn;gmail.com;cityu.edu.hk;my.cityu.edu.hk;jd.com;jd.com",
        "email": "my.cityu.edu.hk;cityu.edu.hk;uic.edu.cn;gmail.com;cityu.edu.hk;my.cityu.edu.hk;jd.com;jd.com",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0;0;2;2",
        "aff_unique_norm": "City University of Hong Kong;United International College;JD",
        "aff_unique_dep": ";;JD Digits",
        "aff_unique_url": "https://www.cityu.edu.hk;https://www.uic.edu.hk;https://digits.jd.com",
        "aff_unique_abbr": "CityU;UIC;JD Digits",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "d16b4dfa24",
        "title": "Towards Scalable and Robust Structured Bandits: A Meta-Learning Framework",
        "site": "https://proceedings.mlr.press/v206/wan23a.html",
        "author": "Runzhe Wan; Lin Ge; Rui Song",
        "abstract": "Online learning in large-scale structured bandits is known to be challenging due to the curse of dimensionality. In this paper, we propose a unified meta-learning framework for a wide class of structured bandit problems where the parameter space can be factorized to item-level, which covers many popular tasks. Compared with existing approaches, the proposed solution is both scalable to large systems and robust by utilizing a more flexible model. At the core of this framework is a Bayesian hierarchical model that allows information sharing among items via their features, upon which we design a meta Thompson sampling algorithm. Three representative examples are discussed thoroughly. Theoretical analysis and extensive numerical results both support the usefulness of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v206-wan23a,\n  title = \t {Towards Scalable and Robust Structured Bandits: A Meta-Learning Framework},\n  author =       {Wan, Runzhe and Ge, Lin and Song, Rui},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1144--1173},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wan23a/wan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wan23a.html},\n  abstract = \t {Online learning in large-scale structured bandits is known to be challenging due to the curse of dimensionality. In this paper, we propose a unified meta-learning framework for a wide class of structured bandit problems where the parameter space can be factorized to item-level, which covers many popular tasks. Compared with existing approaches, the proposed solution is both scalable to large systems and robust by utilizing a more flexible model. At the core of this framework is a Bayesian hierarchical model that allows information sharing among items via their features, upon which we design a meta Thompson sampling algorithm. Three representative examples are discussed thoroughly. Theoretical analysis and extensive numerical results both support the usefulness of the proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wan23a/wan23a.pdf",
        "supp": "",
        "pdf_size": 1534152,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12420357675192821013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "184c048740",
        "title": "Transport Elliptical Slice Sampling",
        "site": "https://proceedings.mlr.press/v206/cabezas23a.html",
        "author": "Alberto Cabezas; Christopher Nemeth",
        "abstract": "We propose a new framework for efficiently sampling from complex probability distributions using a combination of normalizing flows and elliptical slice sampling (Murray et al., 2010). The central idea is to learn a diffeomorphism, through normalizing flows, that maps the non-Gaussian structure of the target distribution to an approximately Gaussian distribution. We then use the elliptical slice sampler, an efficient and tuning-free Markov chain Monte Carlo (MCMC) algorithm, to sample from the transformed distribution. The samples are then pulled back using the inverse normalizing flow, yielding samples that approximate the stationary target distribution of interest. Our transport elliptical slice sampler (TESS) is optimized for modern computer architectures, where its adaptation mechanism utilizes parallel cores to rapidly run multiple Markov chains for a few iterations. Numerical demonstrations show that TESS produces Monte Carlo samples from the target distribution with lower autocorrelation compared to non-transformed samplers, and demonstrates significant improvements in efficiency when compared to gradient-based proposals designed for parallel computer architectures, given a flexible enough diffeomorphism.",
        "bibtex": "@InProceedings{pmlr-v206-cabezas23a,\n  title = \t {Transport Elliptical Slice Sampling},\n  author =       {Cabezas, Alberto and Nemeth, Christopher},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3664--3676},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cabezas23a/cabezas23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cabezas23a.html},\n  abstract = \t {We propose a new framework for efficiently sampling from complex probability distributions using a combination of normalizing flows and elliptical slice sampling (Murray et al., 2010). The central idea is to learn a diffeomorphism, through normalizing flows, that maps the non-Gaussian structure of the target distribution to an approximately Gaussian distribution. We then use the elliptical slice sampler, an efficient and tuning-free Markov chain Monte Carlo (MCMC) algorithm, to sample from the transformed distribution. The samples are then pulled back using the inverse normalizing flow, yielding samples that approximate the stationary target distribution of interest. Our transport elliptical slice sampler (TESS) is optimized for modern computer architectures, where its adaptation mechanism utilizes parallel cores to rapidly run multiple Markov chains for a few iterations. Numerical demonstrations show that TESS produces Monte Carlo samples from the target distribution with lower autocorrelation compared to non-transformed samplers, and demonstrates significant improvements in efficiency when compared to gradient-based proposals designed for parallel computer architectures, given a flexible enough diffeomorphism.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cabezas23a/cabezas23a.pdf",
        "supp": "",
        "pdf_size": 2544729,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7434846705358377649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Lancaster University; Lancaster University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Lancaster University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.lancaster.ac.uk",
        "aff_unique_abbr": "Lancaster",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "80037516e7",
        "title": "Transport Reversible Jump Proposals",
        "site": "https://proceedings.mlr.press/v206/davies23a.html",
        "author": "Laurence Davies; Robert Salomone; Matthew Sutton; Chris Drovandi",
        "abstract": "Reversible jump Markov chain Monte Carlo (RJMCMC) proposals that achieve reasonable acceptance rates and mixing are notoriously difficult to design in most applications. Inspired by recent advances in deep neural network-based normalizing flows and density estimation, we demonstrate an approach to enhance the efficiency of RJMCMC sampling by performing transdimensional jumps involving reference distributions. In contrast to other RJMCMC proposals, the proposed method is the first to apply a non-linear transport-based approach to construct efficient proposals between models with complicated dependency structures. It is shown that, in the setting where exact transports are used, our RJMCMC proposals have the desirable property that the acceptance probability depends only on the model probabilities. Numerical experiments demonstrate the efficacy of the approach.",
        "bibtex": "@InProceedings{pmlr-v206-davies23a,\n  title = \t {Transport Reversible Jump Proposals},\n  author =       {Davies, Laurence and Salomone, Robert and Sutton, Matthew and Drovandi, Chris},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6839--6852},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/davies23a/davies23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/davies23a.html},\n  abstract = \t {Reversible jump Markov chain Monte Carlo (RJMCMC) proposals that achieve reasonable acceptance rates and mixing are notoriously difficult to design in most applications. Inspired by recent advances in deep neural network-based normalizing flows and density estimation, we demonstrate an approach to enhance the efficiency of RJMCMC sampling by performing transdimensional jumps involving reference distributions. In contrast to other RJMCMC proposals, the proposed method is the first to apply a non-linear transport-based approach to construct efficient proposals between models with complicated dependency structures. It is shown that, in the setting where exact transports are used, our RJMCMC proposals have the desirable property that the acceptance probability depends only on the model probabilities. Numerical experiments demonstrate the efficacy of the approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/davies23a/davies23a.pdf",
        "supp": "",
        "pdf_size": 7263389,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4627387894143129998&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d69d21563d",
        "title": "Two-Sample Tests for Inhomogeneous Random Graphs in $L_r$ Norm: Optimality and Asymptotics",
        "site": "https://proceedings.mlr.press/v206/chatterjee23a.html",
        "author": "Sayak Chatterjee; Dibyendu Saha; Soham Dan; Bhaswar B. Bhattacharya",
        "abstract": "In this paper we study the two-sample problem for inhomogeneous Erd\u0151s-R\u00e9nyi (IER), random graph models, in the $L_r$ norm, in the high-dimensional regime where the number of samples is smaller or comparable to the size of the graphs. Given two symmetric matrices $P, Q \\in [0, 1]^{n \\times n}$ (with zeros on the diagonals), the two-sample problem for IER graphs (with respect to the $L_r$ norm $||\\cdot||_r$) is to test the hypothesis $H_0: P=Q$ versus $H_1: ||P-Q||_r \\geq \\varepsilon$, given a sample of $m$ graphs from the respective distributions. In this paper, we obtain the optimal sample complexity for testing in the $L_r$-norm, for all integers $r \\geq 1$. We also derive the asymptotic distribution of the optimal tests under $H_0$ and develop a method for consistently estimating their variances. This allows us to efficiently implement the optimal tests with precise asymptotic level and establish their asymptotic consistency. We validate our theoretical results by numerical experiments for various natural IER models.",
        "bibtex": "@InProceedings{pmlr-v206-chatterjee23a,\n  title = \t {Two-Sample Tests for Inhomogeneous Random Graphs in $L_r$ Norm: Optimality and Asymptotics},\n  author =       {Chatterjee, Sayak and Saha, Dibyendu and Dan, Soham and Bhattacharya, Bhaswar B.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6903--6911},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chatterjee23a/chatterjee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chatterjee23a.html},\n  abstract = \t {In this paper we study the two-sample problem for inhomogeneous Erd\u0151s-R\u00e9nyi (IER), random graph models, in the $L_r$ norm, in the high-dimensional regime where the number of samples is smaller or comparable to the size of the graphs. Given two symmetric matrices $P, Q \\in [0, 1]^{n \\times n}$ (with zeros on the diagonals), the two-sample problem for IER graphs (with respect to the $L_r$ norm $||\\cdot||_r$) is to test the hypothesis $H_0: P=Q$ versus $H_1: ||P-Q||_r \\geq \\varepsilon$, given a sample of $m$ graphs from the respective distributions. In this paper, we obtain the optimal sample complexity for testing in the $L_r$-norm, for all integers $r \\geq 1$. We also derive the asymptotic distribution of the optimal tests under $H_0$ and develop a method for consistently estimating their variances. This allows us to efficiently implement the optimal tests with precise asymptotic level and establish their asymptotic consistency. We validate our theoretical results by numerical experiments for various natural IER models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chatterjee23a/chatterjee23a.pdf",
        "supp": "",
        "pdf_size": 382560,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12422912654130912019&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of Pennsylvania; University of Wisconsin-Madison; IBM Research; University of Pennsylvania",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Pennsylvania;University of Wisconsin-Madison;IBM",
        "aff_unique_dep": ";;IBM Research",
        "aff_unique_url": "https://www.upenn.edu;https://www.wisc.edu;https://www.ibm.com/research",
        "aff_unique_abbr": "UPenn;UW-Madison;IBM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Madison",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ead65f5819",
        "title": "USIM Gate: UpSampling Module for Segmenting Precise Boundaries concerning Entropy",
        "site": "https://proceedings.mlr.press/v206/lee23a.html",
        "author": "Kyungsu Lee; Haeyun Lee; Jae Youn Hwang",
        "abstract": "Deep learning (DL) techniques for precise semantic segmentation have remained a challenge because of the vague boundaries of target objects caused by the low resolution of images. Despite the improved segmentation performance using up/downsampling operations in early DL models, conventional operators cannot fully preserve spatial information and thus generate vague boundaries of target objects. Therefore, for the precise segmentation of target objects in many domains, this paper presents two novel operators: (1) upsampling interpolation method (USIM), an operator that upsamples input feature maps and combines feature maps into one while preserving the spatial information of both inputs, and (2) USIM gate (UG), an advanced USIM operator with boundary-attention mechanisms. We designed our experiments using aerial images where the boundaries critically influence the results. Furthermore, we verified the feasibility that our approach effectively segments target objects using the cityscapes dataset. The experimental results demonstrate that using the USIM and UG with state-of-the-art DL models can improve the segmentation performance with clear boundaries of target objects (Intersection over Union: +6.9$%$; BJ: +10.1$%$). Furthermore, mathematical proofs verify that the USIM and UG contribute to the handling of spatial information.",
        "bibtex": "@InProceedings{pmlr-v206-lee23a,\n  title = \t {USIM Gate: UpSampling Module for Segmenting Precise Boundaries concerning Entropy},\n  author =       {Lee, Kyungsu and Lee, Haeyun and Hwang, Jae Youn},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {535--562},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lee23a/lee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lee23a.html},\n  abstract = \t {Deep learning (DL) techniques for precise semantic segmentation have remained a challenge because of the vague boundaries of target objects caused by the low resolution of images. Despite the improved segmentation performance using up/downsampling operations in early DL models, conventional operators cannot fully preserve spatial information and thus generate vague boundaries of target objects. Therefore, for the precise segmentation of target objects in many domains, this paper presents two novel operators: (1) upsampling interpolation method (USIM), an operator that upsamples input feature maps and combines feature maps into one while preserving the spatial information of both inputs, and (2) USIM gate (UG), an advanced USIM operator with boundary-attention mechanisms. We designed our experiments using aerial images where the boundaries critically influence the results. Furthermore, we verified the feasibility that our approach effectively segments target objects using the cityscapes dataset. The experimental results demonstrate that using the USIM and UG with state-of-the-art DL models can improve the segmentation performance with clear boundaries of target objects (Intersection over Union: +6.9$%$; BJ: +10.1$%$). Furthermore, mathematical proofs verify that the USIM and UG contribute to the handling of spatial information.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lee23a/lee23a.pdf",
        "supp": "",
        "pdf_size": 17778939,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:61uLpTu-QLoJ:scholar.google.com/&scioq=USIM+Gate:+UpSampling+Module+for+Segmenting+Precise+Boundaries+concerning+Entropy&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e67b097a35",
        "title": "Ultra-marginal Feature Importance: Learning from Data with Causal Guarantees",
        "site": "https://proceedings.mlr.press/v206/janssen23a.html",
        "author": "Joseph Janssen; Vincent Guan; Elina Robeva",
        "abstract": "Scientists frequently prioritize learning from data rather than training the best possible model; however, research in machine learning often prioritizes the latter. Marginal contribution feature importance (MCI) was developed to break this trend by providing a useful framework for quantifying the relationships in data. In this work, we aim to improve upon the theoretical properties, performance, and runtime of MCI by introducing ultra-marginal feature importance (UMFI), which uses dependence removal techniques from the AI fairness literature as its foundation. We first propose axioms for feature importance methods that seek to explain the causal and associative relationships in data, and we prove that UMFI satisfies these axioms under basic assumptions. We then show on real and simulated data that UMFI performs better than MCI, especially in the presence of correlated interactions and unrelated features, while partially learning the structure of the causal graph and reducing the exponential runtime of MCI to super-linear.",
        "bibtex": "@InProceedings{pmlr-v206-janssen23a,\n  title = \t {Ultra-marginal Feature Importance: Learning from Data with Causal Guarantees},\n  author =       {Janssen, Joseph and Guan, Vincent and Robeva, Elina},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10782--10814},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/janssen23a/janssen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/janssen23a.html},\n  abstract = \t {Scientists frequently prioritize learning from data rather than training the best possible model; however, research in machine learning often prioritizes the latter. Marginal contribution feature importance (MCI) was developed to break this trend by providing a useful framework for quantifying the relationships in data. In this work, we aim to improve upon the theoretical properties, performance, and runtime of MCI by introducing ultra-marginal feature importance (UMFI), which uses dependence removal techniques from the AI fairness literature as its foundation. We first propose axioms for feature importance methods that seek to explain the causal and associative relationships in data, and we prove that UMFI satisfies these axioms under basic assumptions. We then show on real and simulated data that UMFI performs better than MCI, especially in the presence of correlated interactions and unrelated features, while partially learning the structure of the causal graph and reducing the exponential runtime of MCI to super-linear.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/janssen23a/janssen23a.pdf",
        "supp": "",
        "pdf_size": 5705254,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1839229798276025529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6c6b5450da",
        "title": "Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition",
        "site": "https://proceedings.mlr.press/v206/gruber23a.html",
        "author": "Sebastian Gruber; Florian Buettner",
        "abstract": "Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. The most common way to measure this uncertainty is via the predicted confidence. While this tends to work well for in-domain samples, these estimates are unreliable under domain drift and restricted to classification. Alternatively, proper scores can be used for most predictive tasks but a bias-variance decomposition for model uncertainty does not exist in the current literature. In this work we introduce a general bias-variance decomposition for proper scores, giving rise to the Bregman Information as the variance term. We discover how exponential families and the classification log-likelihood are special cases and provide novel formulations. Surprisingly, we can express the classification case purely in the logit space. We showcase the practical relevance of this decomposition on several downstream tasks, including model ensembles and confidence regions. Further, we demonstrate how different approximations of the instance-level Bregman Information allow reliable out-of-distribution detection for all degrees of domain drift.",
        "bibtex": "@InProceedings{pmlr-v206-gruber23a,\n  title = \t {Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition},\n  author =       {Gruber, Sebastian and Buettner, Florian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11331--11354},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/gruber23a/gruber23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/gruber23a.html},\n  abstract = \t {Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. The most common way to measure this uncertainty is via the predicted confidence. While this tends to work well for in-domain samples, these estimates are unreliable under domain drift and restricted to classification. Alternatively, proper scores can be used for most predictive tasks but a bias-variance decomposition for model uncertainty does not exist in the current literature. In this work we introduce a general bias-variance decomposition for proper scores, giving rise to the Bregman Information as the variance term. We discover how exponential families and the classification log-likelihood are special cases and provide novel formulations. Surprisingly, we can express the classification case purely in the logit space. We showcase the practical relevance of this decomposition on several downstream tasks, including model ensembles and confidence regions. Further, we demonstrate how different approximations of the instance-level Bregman Information allow reliable out-of-distribution detection for all degrees of domain drift.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/gruber23a/gruber23a.pdf",
        "supp": "",
        "pdf_size": 7966554,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17300759318967437672&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "German Cancer Research Center (DKFZ) + German Cancer Consortium (DKTK) + Goethe University Frankfurt, Germany; German Cancer Research Center (DKFZ) + German Cancer Consortium (DKTK) + Frankfurt Cancer Institute, Germany + Goethe University Frankfurt, Germany",
        "aff_domain": "dkfz.de;dkfz.de",
        "email": "dkfz.de;dkfz.de",
        "github": "https://github.com/MLO-lab/Uncertainty_Estimates_via_BVD",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;0+1+3+2",
        "aff_unique_norm": "German Cancer Research Center;German Cancer Consortium;Goethe University Frankfurt;Frankfurt Cancer Institute",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.dkfz.de;https://www.dktk.org;https://www.uni-frankfurt.de;",
        "aff_unique_abbr": "DKFZ;DKTK;GU Frankfurt;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0+0;0+0+0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "971002d77b",
        "title": "Uncertainty-aware Unsupervised Video Hashing",
        "site": "https://proceedings.mlr.press/v206/wang23i.html",
        "author": "Yucheng Wang; Mingyuan Zhou; Yu Sun; Xiaoning Qian",
        "abstract": "Learning to hash has become popular for video retrieval due to its fast speed and low storage consumption. Previous efforts formulate video hashing as training a binary auto-encoder, for which noncontinuous latent representations are optimized by the biased straight-through\u00a0(ST) back-propagation heuristic. We propose to formulate video hashing as learning a discrete variational auto-encoder with the factorized Bernoulli latent distribution, termed as Bernoulli variational auto-encoder (BerVAE). The corresponding evidence lower bound (ELBO) in our BerVAE implementation leads to closed-form gradient expression, which can be applied to achieve principled training along with some other unbiased gradient estimators. BerVAE enables uncertainty-aware video hashing by predicting the probability distribution of video hash code-words, thus providing reliable uncertainty quantification. Experiments on both simulated and real-world large-scale video data demonstrate that our BerVAE trained with unbiased gradient estimators can achieve the state-of-the-art retrieval performance. Furthermore, we show that quantified uncertainty is highly correlated to video retrieval performance, which can be leveraged to further improve the retrieval accuracy. Our code is available at https://github.com/wangyucheng1234/BerVAE",
        "bibtex": "@InProceedings{pmlr-v206-wang23i,\n  title = \t {Uncertainty-aware Unsupervised Video Hashing},\n  author =       {Wang, Yucheng and Zhou, Mingyuan and Sun, Yu and Qian, Xiaoning},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {6722--6740},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wang23i/wang23i.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wang23i.html},\n  abstract = \t {Learning to hash has become popular for video retrieval due to its fast speed and low storage consumption. Previous efforts formulate video hashing as training a binary auto-encoder, for which noncontinuous latent representations are optimized by the biased straight-through\u00a0(ST) back-propagation heuristic. We propose to formulate video hashing as learning a discrete variational auto-encoder with the factorized Bernoulli latent distribution, termed as Bernoulli variational auto-encoder (BerVAE). The corresponding evidence lower bound (ELBO) in our BerVAE implementation leads to closed-form gradient expression, which can be applied to achieve principled training along with some other unbiased gradient estimators. BerVAE enables uncertainty-aware video hashing by predicting the probability distribution of video hash code-words, thus providing reliable uncertainty quantification. Experiments on both simulated and real-world large-scale video data demonstrate that our BerVAE trained with unbiased gradient estimators can achieve the state-of-the-art retrieval performance. Furthermore, we show that quantified uncertainty is highly correlated to video retrieval performance, which can be leveraged to further improve the retrieval accuracy. Our code is available at https://github.com/wangyucheng1234/BerVAE}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wang23i/wang23i.pdf",
        "supp": "",
        "pdf_size": 17439702,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10314753511936852017&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Texas A&M University; University of Texas at Austin; University of South Florida; Texas A&M University",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/wangyucheng1234/BerV AE",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Texas A&M University;University of Texas at Austin;University of South Florida",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tamu.edu;https://www.utexas.edu;https://www.usf.edu",
        "aff_unique_abbr": "TAMU;UT Austin;USF",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d875ed383f",
        "title": "Understanding Multimodal Contrastive Learning and Incorporating Unpaired Data",
        "site": "https://proceedings.mlr.press/v206/nakada23a.html",
        "author": "Ryumei Nakada; Halil Ibrahim Gulluk; Zhun Deng; Wenlong Ji; James Zou; Linjun Zhang",
        "abstract": "Language-supervised vision models have recently attracted great attention in computer vision. A common approach to build such models is to use contrastive learning on paired data across the two modalities, as exemplified by Contrastive Language-Image Pre-Training (CLIP). In this paper, (i) we initiate the investigation of a general class of nonlinear loss functions for multimodal contrastive learning (MMCL) including CLIP loss and show its connection to singular value decomposition (SVD). Namely, we show that each step of loss minimization by gradient descent can be seen as performing SVD on a contrastive cross-covariance matrix. Based on this insight, (ii) we analyze the performance of MMCL under linear representation settings. We quantitatively show that the feature learning ability of MMCL can be better than that of unimodal contrastive learning applied to each modality even under the presence of wrongly matched pairs. This characterizes the robustness of MMCL to noisy data. Furthermore, when we have access to additional unpaired data, (iii) we propose a new MMCL loss that incorporates additional unpaired datasets. We show that the algorithm can detect the ground-truth pairs and improve performance by fully exploiting unpaired datasets. The performance of the proposed algorithm was verified by numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v206-nakada23a,\n  title = \t {Understanding Multimodal Contrastive Learning and Incorporating Unpaired Data},\n  author =       {Nakada, Ryumei and Gulluk, Halil Ibrahim and Deng, Zhun and Ji, Wenlong and Zou, James and Zhang, Linjun},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4348--4380},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nakada23a/nakada23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nakada23a.html},\n  abstract = \t {Language-supervised vision models have recently attracted great attention in computer vision. A common approach to build such models is to use contrastive learning on paired data across the two modalities, as exemplified by Contrastive Language-Image Pre-Training (CLIP). In this paper, (i) we initiate the investigation of a general class of nonlinear loss functions for multimodal contrastive learning (MMCL) including CLIP loss and show its connection to singular value decomposition (SVD). Namely, we show that each step of loss minimization by gradient descent can be seen as performing SVD on a contrastive cross-covariance matrix. Based on this insight, (ii) we analyze the performance of MMCL under linear representation settings. We quantitatively show that the feature learning ability of MMCL can be better than that of unimodal contrastive learning applied to each modality even under the presence of wrongly matched pairs. This characterizes the robustness of MMCL to noisy data. Furthermore, when we have access to additional unpaired data, (iii) we propose a new MMCL loss that incorporates additional unpaired datasets. We show that the algorithm can detect the ground-truth pairs and improve performance by fully exploiting unpaired datasets. The performance of the proposed algorithm was verified by numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nakada23a/nakada23a.pdf",
        "supp": "",
        "pdf_size": 1265103,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8133053019332491652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "faec2cbcce",
        "title": "Understanding the Impact of Competing Events on Heterogeneous Treatment Effect Estimation from Time-to-Event Data",
        "site": "https://proceedings.mlr.press/v206/curth23a.html",
        "author": "Alicia Curth; Mihaela van der Schaar",
        "abstract": "We study the problem of inferring heterogeneous treatment effects (HTEs) from time-to-event data in the presence of competing events. Albeit its great practical relevance, this problem has received little attention compared to its counterparts studying HTE estimation without time-to-event data or competing events. We take an outcome modeling approach to estimating HTEs, and consider how and when existing prediction models for time-to-event data can be used as plug-in estimators for potential outcomes. We then investigate whether competing events present new challenges for HTE estimation \u2013 in addition to the standard confounding problem \u2013, and find that, because there are multiple definitions of causal effects in this setting \u2013 namely total, direct and separable effects \u2013, competing events can act as an additional source of covariate shift depending on the desired treatment effect interpretation and associated estimand. We theoretically analyze and empirically illustrate when and how these challenges play a role when using generic machine learning prediction models for the estimation of HTEs.",
        "bibtex": "@InProceedings{pmlr-v206-curth23a,\n  title = \t {Understanding the Impact of Competing Events on Heterogeneous Treatment Effect Estimation from Time-to-Event Data},\n  author =       {Curth, Alicia and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7961--7980},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/curth23a/curth23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/curth23a.html},\n  abstract = \t {We study the problem of inferring heterogeneous treatment effects (HTEs) from time-to-event data in the presence of competing events. Albeit its great practical relevance, this problem has received little attention compared to its counterparts studying HTE estimation without time-to-event data or competing events. We take an outcome modeling approach to estimating HTEs, and consider how and when existing prediction models for time-to-event data can be used as plug-in estimators for potential outcomes. We then investigate whether competing events present new challenges for HTE estimation \u2013 in addition to the standard confounding problem \u2013, and find that, because there are multiple definitions of causal effects in this setting \u2013 namely total, direct and separable effects \u2013, competing events can act as an additional source of covariate shift depending on the desired treatment effect interpretation and associated estimand. We theoretically analyze and empirically illustrate when and how these challenges play a role when using generic machine learning prediction models for the estimation of HTEs.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/curth23a/curth23a.pdf",
        "supp": "",
        "pdf_size": 3400235,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13322293653192622920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Cambridge; University of Cambridge + The Alan Turing Institute",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "University of Cambridge;Alan Turing Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;ATI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "69ed717556",
        "title": "Uni6Dv2: Noise Elimination for 6D Pose Estimation",
        "site": "https://proceedings.mlr.press/v206/sun23b.html",
        "author": "Mingshan Sun; Ye Zheng; Tianpeng Bao; Jianqiu Chen; Guoqiang Jin; Liwei Wu; Rui Zhao; Xiaoke Jiang",
        "abstract": "Uni6D is the first 6D pose estimation approach to employ a unified backbone network to extract features from both RGB and depth images. We discover that the principal reasons of Uni6D performance limitations are Instance-Outside and Instance-Inside noise. Uni6D\u2019s simple pipeline design inherently introduces Instance-Outside noise from background pixels in the receptive field, while ignoring Instance-Inside noise in the input depth data. In this paper, we propose a two-step denoising approach for dealing with the aforementioned noise in Uni6D. To reduce noise from non-instance regions, an instance segmentation network is utilized in the first step to crop and mask the instance. A lightweight depth denoising module is proposed in the second step to calibrate the depth feature before feeding it into the pose regression network. Extensive experiments show that our Uni6Dv2 reliably and robustly eliminates noise, outperforming Uni6D without sacrificing too much inference efficiency. It also reduces the need for annotated real data that requires costly labeling.",
        "bibtex": "@InProceedings{pmlr-v206-sun23b,\n  title = \t {Uni6Dv2: Noise Elimination for 6D Pose Estimation},\n  author =       {Sun, Mingshan and Zheng, Ye and Bao, Tianpeng and Chen, Jianqiu and Jin, Guoqiang and Wu, Liwei and Zhao, Rui and Jiang, Xiaoke},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1832--1844},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/sun23b/sun23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/sun23b.html},\n  abstract = \t {Uni6D is the first 6D pose estimation approach to employ a unified backbone network to extract features from both RGB and depth images. We discover that the principal reasons of Uni6D performance limitations are Instance-Outside and Instance-Inside noise. Uni6D\u2019s simple pipeline design inherently introduces Instance-Outside noise from background pixels in the receptive field, while ignoring Instance-Inside noise in the input depth data. In this paper, we propose a two-step denoising approach for dealing with the aforementioned noise in Uni6D. To reduce noise from non-instance regions, an instance segmentation network is utilized in the first step to crop and mask the instance. A lightweight depth denoising module is proposed in the second step to calibrate the depth feature before feeding it into the pose regression network. Extensive experiments show that our Uni6Dv2 reliably and robustly eliminates noise, outperforming Uni6D without sacrificing too much inference efficiency. It also reduces the need for annotated real data that requires costly labeling.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/sun23b/sun23b.pdf",
        "supp": "",
        "pdf_size": 5008541,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17377284423747263407&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "SenseTime Research; JD.com, Inc; SenseTime Research; Harbin Institute of Technology, Shenzhen; SenseTime Research; SenseTime Research; SenseTime Research; International Digital Economy Academy (IDEA)",
        "aff_domain": "; ; ; ; ; ; ; ",
        "email": "; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;0;0;0;3",
        "aff_unique_norm": "SenseTime;JD.com;Harbin Institute of Technology;International Digital Economy Academy",
        "aff_unique_dep": "SenseTime Research;;;",
        "aff_unique_url": "https://www.sensetime.com;https://www.jd.com;http://en.hhit.edu.cn/;",
        "aff_unique_abbr": "SenseTime;JD.com;HIT;IDEA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "60197e81cd",
        "title": "Unified Perspective on Probability Divergence via the Density-Ratio Likelihood: Bridging KL-Divergence and Integral Probability Metrics",
        "site": "https://proceedings.mlr.press/v206/kato23a.html",
        "author": "Masahiro Kato; Masaaki Imaizumi; Kentaro Minami",
        "abstract": "This paper provides a unified perspective for the Kullback-Leibler (KL)-divergence and the integral probability metrics (IPMs) from the perspective of maximum likelihood density-ratio estimation (DRE). Both the KL-divergence and the IPMs are widely used in various fields in applications such as generative modeling. However, a unified understanding of these concepts has still been unexplored. In this paper, we show that the KL-divergence and the IPMs can be represented as maximal likelihoods differing only by sampling schemes, and use this result to derive a unified form of the IPMs and a relaxed estimation method. To develop the estimation problem, we construct an unconstrained maximum likelihood estimator to perform DRE with a stratified sampling scheme. We further propose a novel class of probability divergences, called the Density Ratio Metrics (DRMs), that interpolates the KL-divergence and the IPMs. In addition to these findings, we also introduce some applications of the DRMs, such as DRE and generative adversarial networks. In experiments, we validate the effectiveness of our proposed methods.",
        "bibtex": "@InProceedings{pmlr-v206-kato23a,\n  title = \t {Unified Perspective on Probability Divergence via the Density-Ratio Likelihood: Bridging KL-Divergence and Integral Probability Metrics},\n  author =       {Kato, Masahiro and Imaizumi, Masaaki and Minami, Kentaro},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5271--5298},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/kato23a/kato23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/kato23a.html},\n  abstract = \t {This paper provides a unified perspective for the Kullback-Leibler (KL)-divergence and the integral probability metrics (IPMs) from the perspective of maximum likelihood density-ratio estimation (DRE). Both the KL-divergence and the IPMs are widely used in various fields in applications such as generative modeling. However, a unified understanding of these concepts has still been unexplored. In this paper, we show that the KL-divergence and the IPMs can be represented as maximal likelihoods differing only by sampling schemes, and use this result to derive a unified form of the IPMs and a relaxed estimation method. To develop the estimation problem, we construct an unconstrained maximum likelihood estimator to perform DRE with a stratified sampling scheme. We further propose a novel class of probability divergences, called the Density Ratio Metrics (DRMs), that interpolates the KL-divergence and the IPMs. In addition to these findings, we also introduce some applications of the DRMs, such as DRE and generative adversarial networks. In experiments, we validate the effectiveness of our proposed methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/kato23a/kato23a.pdf",
        "supp": "",
        "pdf_size": 1882813,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15340714449563725177&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "982658c1a5",
        "title": "Uniformly Conservative Exploration in Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v206/xu23j.html",
        "author": "Wanqiao Xu; Yecheng Ma; Kan Xu; Hamsa Bastani; Osbert Bastani",
        "abstract": "A key challenge to deploying reinforcement learning in practice is avoiding excessive (harmful) exploration in individual episodes. We propose a natural constraint on exploration\u2014uniformly outperforming a conservative policy (adaptively estimated from all data observed thus far), up to a per-episode exploration budget. We design a novel algorithm that uses a UCB reinforcement learning policy for exploration, but overrides it as needed to satisfy our exploration constraint with high probability. Importantly, to ensure unbiased exploration across the state space, our algorithm adaptively determines when to explore. We prove that our approach remains conservative while minimizing regret in the tabular setting. We experimentally validate our results on a sepsis treatment task and an HIV treatment task, demonstrating that our algorithm can learn while ensuring good performance compared to the baseline policy for every patient; the latter task also demonstrates that our approach extends to continuous state spaces via deep reinforcement learning.",
        "bibtex": "@InProceedings{pmlr-v206-xu23j,\n  title = \t {Uniformly Conservative Exploration in Reinforcement Learning},\n  author =       {Xu, Wanqiao and Ma, Yecheng and Xu, Kan and Bastani, Hamsa and Bastani, Osbert},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10856--10870},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/xu23j/xu23j.pdf},\n  url = \t {https://proceedings.mlr.press/v206/xu23j.html},\n  abstract = \t {A key challenge to deploying reinforcement learning in practice is avoiding excessive (harmful) exploration in individual episodes. We propose a natural constraint on exploration\u2014uniformly outperforming a conservative policy (adaptively estimated from all data observed thus far), up to a per-episode exploration budget. We design a novel algorithm that uses a UCB reinforcement learning policy for exploration, but overrides it as needed to satisfy our exploration constraint with high probability. Importantly, to ensure unbiased exploration across the state space, our algorithm adaptively determines when to explore. We prove that our approach remains conservative while minimizing regret in the tabular setting. We experimentally validate our results on a sepsis treatment task and an HIV treatment task, demonstrating that our algorithm can learn while ensuring good performance compared to the baseline policy for every patient; the latter task also demonstrates that our approach extends to continuous state spaces via deep reinforcement learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/xu23j/xu23j.pdf",
        "supp": "",
        "pdf_size": 628205,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13849134907542990256&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Stanford University; University of Pennsylvania; University of Pennsylvania; University of Pennsylvania; University of Pennsylvania",
        "aff_domain": "stanford.edu;seas.upenn.edu;sas.upenn.edu;wharton.upenn.edu;seas.upenn.edu",
        "email": "stanford.edu;seas.upenn.edu;sas.upenn.edu;wharton.upenn.edu;seas.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Stanford University;University of Pennsylvania",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.upenn.edu",
        "aff_unique_abbr": "Stanford;UPenn",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8fa9dbce39",
        "title": "Unifying local and global model explanations by functional decomposition of low dimensional structures",
        "site": "https://proceedings.mlr.press/v206/hiabu23a.html",
        "author": "Munir Hiabu; Joseph T. Meyer; Marvin N. Wright",
        "abstract": "We consider a global representation of a regression or classification function by decomposing it into the sum of main and interaction components of arbitrary order. We propose a new identification constraint that allows for the extraction of interventional SHAP values and partial dependence plots, thereby unifying local and global explanations. With our proposed identification, a feature\u2019s partial dependence plot corresponds to the main effect term plus the intercept. The interventional SHAP value of feature $k$ is a weighted sum of the main component and all interaction components that include $k$, with the weights given by the reciprocal of the component\u2019s dimension. This brings a new perspective to local explanations such as SHAP values which were previously motivated by game theory only. We show that the decomposition can be used to reduce direct and indirect bias by removing all components that include a protected feature. Lastly, we motivate a new measure of feature importance. In principle, our proposed functional decomposition can be applied to any machine learning model, but exact calculation is only feasible for low-dimensional structures or ensembles of those. We provide an algorithm and efficient implementation for gradient-boosted trees (xgboost) and random planted forest. Conducted experiments suggest that our method provides meaningful explanations and reveals interactions of higher orders. The proposed methods are implemented in an R package, available at https://github.com/PlantedML/glex.",
        "bibtex": "@InProceedings{pmlr-v206-hiabu23a,\n  title = \t {Unifying local and global model explanations by functional decomposition of low dimensional structures},\n  author =       {Hiabu, Munir and Meyer, Joseph T. and Wright, Marvin N.},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7040--7060},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hiabu23a/hiabu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hiabu23a.html},\n  abstract = \t {We consider a global representation of a regression or classification function by decomposing it into the sum of main and interaction components of arbitrary order. We propose a new identification constraint that allows for the extraction of interventional SHAP values and partial dependence plots, thereby unifying local and global explanations. With our proposed identification, a feature\u2019s partial dependence plot corresponds to the main effect term plus the intercept. The interventional SHAP value of feature $k$ is a weighted sum of the main component and all interaction components that include $k$, with the weights given by the reciprocal of the component\u2019s dimension. This brings a new perspective to local explanations such as SHAP values which were previously motivated by game theory only. We show that the decomposition can be used to reduce direct and indirect bias by removing all components that include a protected feature. Lastly, we motivate a new measure of feature importance. In principle, our proposed functional decomposition can be applied to any machine learning model, but exact calculation is only feasible for low-dimensional structures or ensembles of those. We provide an algorithm and efficient implementation for gradient-boosted trees (xgboost) and random planted forest. Conducted experiments suggest that our method provides meaningful explanations and reveals interactions of higher orders. The proposed methods are implemented in an R package, available at https://github.com/PlantedML/glex.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hiabu23a/hiabu23a.pdf",
        "supp": "",
        "pdf_size": 1851427,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14829576140415213811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "564350f6dd",
        "title": "Universal Agent Mixtures and the Geometry of Intelligence",
        "site": "https://proceedings.mlr.press/v206/alexander23a.html",
        "author": "Samuel Allen Alexander; David Quarel; Len Du; Marcus Hutter",
        "abstract": "Inspired by recent progress in multi-agent Reinforcement Learning (RL), in this work we examine the collective intelligent behaviour of theoretical universal agents by introducing a weighted mixture operation. Given a weighted set of agents, their weighted mixture is a new agent whose expected total reward in any environment is the corresponding weighted average of the original agents\u2019 expected total rewards in that environment. Thus, if RL agent intelligence is quantified in terms of performance across environments, the weighted mixture\u2019s intelligence is the weighted average of the original agents\u2019 intelligence. This operation enables various interesting new theorems that shed light on the geometry of RL agent intelligence, namely: results about symmetries, convex agent-sets, and local extrema. We also show that any RL agent intelligence measure based on average performance across environments, subject to certain weak technical conditions, is identical (up to a constant factor) to performance within a single environment dependent on said intelligence measure.",
        "bibtex": "@InProceedings{pmlr-v206-alexander23a,\n  title = \t {Universal Agent Mixtures and the Geometry of Intelligence},\n  author =       {Alexander, Samuel Allen and Quarel, David and Du, Len and Hutter, Marcus},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4231--4246},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/alexander23a/alexander23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/alexander23a.html},\n  abstract = \t {Inspired by recent progress in multi-agent Reinforcement Learning (RL), in this work we examine the collective intelligent behaviour of theoretical universal agents by introducing a weighted mixture operation. Given a weighted set of agents, their weighted mixture is a new agent whose expected total reward in any environment is the corresponding weighted average of the original agents\u2019 expected total rewards in that environment. Thus, if RL agent intelligence is quantified in terms of performance across environments, the weighted mixture\u2019s intelligence is the weighted average of the original agents\u2019 intelligence. This operation enables various interesting new theorems that shed light on the geometry of RL agent intelligence, namely: results about symmetries, convex agent-sets, and local extrema. We also show that any RL agent intelligence measure based on average performance across environments, subject to certain weak technical conditions, is identical (up to a constant factor) to performance within a single environment dependent on said intelligence measure.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/alexander23a/alexander23a.pdf",
        "supp": "",
        "pdf_size": 279712,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2703695699641441711&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e593770368",
        "title": "Unsupervised representation learning with recognition-parametrised probabilistic models",
        "site": "https://proceedings.mlr.press/v206/walker23a.html",
        "author": "William I. Walker; Hugo Soulat; Changmin Yu; Maneesh Sahani",
        "abstract": "We introduce a new approach to probabilistic unsupervised learning based on the recognition-parametrised model (RPM): a normalised semi-parametric hypothesis class for joint distributions over observed and latent variables. Under the key assumption that observations are conditionally independent given latents, the RPM combines parametric prior and observation-conditioned latent distributions with non-parametric observation marginals. This approach leads to a flexible learnt recognition model capturing latent dependence between observations, without the need for an explicit, parametric generative model. The RPM admits exact maximum-likelihood learning for discrete latents, even for powerful neural network-based recognition. We develop effective approximations applicable in the continuous latent case. Experiments demonstrate the effectiveness of the RPM on high-dimensional data, learning image classification from weak indirect supervision; direct image-level latent Dirichlet allocation; and Recognition-Parametrised Gaussian Process Factor Analysis (RP-GPFA) applied to multi-factorial spatiotemporal datasets. The RPM provides a powerful framework to discover meaningful latent structure underlying observational data, a function critical to both animal and artificial intelligence.",
        "bibtex": "@InProceedings{pmlr-v206-walker23a,\n  title = \t {Unsupervised representation learning with recognition-parametrised probabilistic models},\n  author =       {Walker, William I. and Soulat, Hugo and Yu, Changmin and Sahani, Maneesh},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4209--4230},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/walker23a/walker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/walker23a.html},\n  abstract = \t {We introduce a new approach to probabilistic unsupervised learning based on the recognition-parametrised model (RPM): a normalised semi-parametric hypothesis class for joint distributions over observed and latent variables. Under the key assumption that observations are conditionally independent given latents, the RPM combines parametric prior and observation-conditioned latent distributions with non-parametric observation marginals. This approach leads to a flexible learnt recognition model capturing latent dependence between observations, without the need for an explicit, parametric generative model. The RPM admits exact maximum-likelihood learning for discrete latents, even for powerful neural network-based recognition. We develop effective approximations applicable in the continuous latent case. Experiments demonstrate the effectiveness of the RPM on high-dimensional data, learning image classification from weak indirect supervision; direct image-level latent Dirichlet allocation; and Recognition-Parametrised Gaussian Process Factor Analysis (RP-GPFA) applied to multi-factorial spatiotemporal datasets. The RPM provides a powerful framework to discover meaningful latent structure underlying observational data, a function critical to both animal and artificial intelligence.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/walker23a/walker23a.pdf",
        "supp": "",
        "pdf_size": 6077434,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9929421415154659228&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7959450f29",
        "title": "Using Sliced Mutual Information to Study Memorization and Generalization in Deep Neural Networks",
        "site": "https://proceedings.mlr.press/v206/wongso23a.html",
        "author": "Shelvia Wongso; Rohan Ghosh; Mehul Motani",
        "abstract": "In this paper, we study the memorization and generalization behaviour of deep neural networks (DNNs) using sliced mutual information (SMI), which is the average of the mutual information (MI) between one-dimensional random projections. We argue that the SMI between features in a DNN ($T$) and ground truth labels ($Y$), $SI(T;Y)$, can be seen as a form of usable information that the features contain about the labels. We show theoretically that $SI(T;Y)$ can encode geometric properties of the feature distribution, such as its spherical soft-margin and intrinsic dimensionality, in a way that MI cannot. Additionally, we present empirical evidence showing how $SI(T;Y)$ can capture memorization and generalization in DNNs. In particular, we find that, in the presence of label noise, all layers start to memorize but the earlier layers stabilize more quickly than the deeper layers. Finally, we point out that, in the context of Bayesian Neural Networks, the SMI between the penultimate layer and the output represents the worst case uncertainty of the network\u2019s output.",
        "bibtex": "@InProceedings{pmlr-v206-wongso23a,\n  title = \t {Using Sliced Mutual Information to Study Memorization and Generalization in Deep Neural Networks},\n  author =       {Wongso, Shelvia and Ghosh, Rohan and Motani, Mehul},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11608--11629},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/wongso23a/wongso23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/wongso23a.html},\n  abstract = \t {In this paper, we study the memorization and generalization behaviour of deep neural networks (DNNs) using sliced mutual information (SMI), which is the average of the mutual information (MI) between one-dimensional random projections. We argue that the SMI between features in a DNN ($T$) and ground truth labels ($Y$), $SI(T;Y)$, can be seen as a form of usable information that the features contain about the labels. We show theoretically that $SI(T;Y)$ can encode geometric properties of the feature distribution, such as its spherical soft-margin and intrinsic dimensionality, in a way that MI cannot. Additionally, we present empirical evidence showing how $SI(T;Y)$ can capture memorization and generalization in DNNs. In particular, we find that, in the presence of label noise, all layers start to memorize but the earlier layers stabilize more quickly than the deeper layers. Finally, we point out that, in the context of Bayesian Neural Networks, the SMI between the penultimate layer and the output represents the worst case uncertainty of the network\u2019s output.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/wongso23a/wongso23a.pdf",
        "supp": "",
        "pdf_size": 1030378,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13188819189759689381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "c0ab63fa04",
        "title": "Variational Boosted Soft Trees",
        "site": "https://proceedings.mlr.press/v206/cinquin23a.html",
        "author": "Tristan Cinquin; Tammo Rukat; Philipp Schmidt; Martin Wistuba; Artur Bekasov",
        "abstract": "Gradient boosting machines (GBMs) based on decision trees consistently demonstrate state-of-the-art results on regression and classification tasks with tabular data, often outperforming deep neural networks. However, these models do not provide well-calibrated predictive uncertainties, which prevents their use for decision making in high-risk applications. The Bayesian treatment is known to improve predictive uncertainty calibration, but previously proposed Bayesian GBM methods are either computationally expensive, or resort to crude approximations. Variational inference is often used to implement Bayesian neural networks, but is difficult to apply to GBMs, because the decision trees used as weak learners are non-differentiable. In this paper, we propose to implement Bayesian GBMs using variational inference with soft decision trees, a fully differentiable alternative to standard decision trees introduced by Irsoy et al. Our experiments demonstrate that variational soft trees and variational soft GBMs provide useful uncertainty estimates, while retaining good predictive performance. The proposed models show higher test likelihoods when compared to the state-of-the-art Bayesian GBMs in 7/10 tabular regression datasets and improved out-of-distribution detection in 5/10 datasets.",
        "bibtex": "@InProceedings{pmlr-v206-cinquin23a,\n  title = \t {Variational Boosted Soft Trees},\n  author =       {Cinquin, Tristan and Rukat, Tammo and Schmidt, Philipp and Wistuba, Martin and Bekasov, Artur},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {5787--5801},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/cinquin23a/cinquin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/cinquin23a.html},\n  abstract = \t {Gradient boosting machines (GBMs) based on decision trees consistently demonstrate state-of-the-art results on regression and classification tasks with tabular data, often outperforming deep neural networks. However, these models do not provide well-calibrated predictive uncertainties, which prevents their use for decision making in high-risk applications. The Bayesian treatment is known to improve predictive uncertainty calibration, but previously proposed Bayesian GBM methods are either computationally expensive, or resort to crude approximations. Variational inference is often used to implement Bayesian neural networks, but is difficult to apply to GBMs, because the decision trees used as weak learners are non-differentiable. In this paper, we propose to implement Bayesian GBMs using variational inference with soft decision trees, a fully differentiable alternative to standard decision trees introduced by Irsoy et al. Our experiments demonstrate that variational soft trees and variational soft GBMs provide useful uncertainty estimates, while retaining good predictive performance. The proposed models show higher test likelihoods when compared to the state-of-the-art Bayesian GBMs in 7/10 tabular regression datasets and improved out-of-distribution detection in 5/10 datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/cinquin23a/cinquin23a.pdf",
        "supp": "",
        "pdf_size": 3458111,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11447542323230285353&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Tuebingen1; Deekard1; Amazon; Amazon; Amazon",
        "aff_domain": "uni-tuebingen.de;gmail.com;amazon.com;amazon.com;amazon.com",
        "email": "uni-tuebingen.de;gmail.com;amazon.com;amazon.com;amazon.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;2;2;2",
        "aff_unique_norm": "University of T\u00fcbingen;;Amazon",
        "aff_unique_dep": ";;Amazon.com, Inc.",
        "aff_unique_url": "https://www.uni-tuebingen.de/;;https://www.amazon.com",
        "aff_unique_abbr": "Uni T\u00fcbingen;;Amazon",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;2;2;2",
        "aff_country_unique": "Germany;;United States"
    },
    {
        "id": "1590a1c5bc",
        "title": "Variational Inference for Neyman-Scott Processes",
        "site": "https://proceedings.mlr.press/v206/hong23a.html",
        "author": "Chengkuan Hong; Christian Shelton",
        "abstract": "Neyman-Scott processes (NSPs) have been applied across a range of fields to model points or temporal events with a hierarchy of clusters. Markov chain Monte Carlo (MCMC) is typically used for posterior sampling in the model. However, MCMC\u2019s mixing time can cause the resulting inference to be slow, and thereby slow down model learning and prediction. We develop the first variational inference (VI) algorithm for NSPs, and give two examples of suitable variational posterior point process distributions. Our method minimizes the inclusive Kullback-Leibler (KL) divergence for VI to obtain the variational parameters. We generate samples from the approximate posterior point processes much faster than MCMC, as we can directly estimate the approximate posterior point processes without any MCMC steps or gradient descent. We include synthetic and real-world data experiments that demonstrate our VI algorithm achieves better prediction performance than MCMC when computational time is limited.",
        "bibtex": "@InProceedings{pmlr-v206-hong23a,\n  title = \t {Variational Inference for Neyman-Scott Processes},\n  author =       {Hong, Chengkuan and Shelton, Christian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2002--2018},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/hong23a/hong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/hong23a.html},\n  abstract = \t {Neyman-Scott processes (NSPs) have been applied across a range of fields to model points or temporal events with a hierarchy of clusters. Markov chain Monte Carlo (MCMC) is typically used for posterior sampling in the model. However, MCMC\u2019s mixing time can cause the resulting inference to be slow, and thereby slow down model learning and prediction. We develop the first variational inference (VI) algorithm for NSPs, and give two examples of suitable variational posterior point process distributions. Our method minimizes the inclusive Kullback-Leibler (KL) divergence for VI to obtain the variational parameters. We generate samples from the approximate posterior point processes much faster than MCMC, as we can directly estimate the approximate posterior point processes without any MCMC steps or gradient descent. We include synthetic and real-world data experiments that demonstrate our VI algorithm achieves better prediction performance than MCMC when computational time is limited.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/hong23a/hong23a.pdf",
        "supp": "",
        "pdf_size": 1335010,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1394299629652750447&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Tsinghua University; University of California, Riverside",
        "aff_domain": "ucr.edu;cs.ucr.edu",
        "email": "ucr.edu;cs.ucr.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Tsinghua University;University of California, Riverside",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.ucr.edu",
        "aff_unique_abbr": "THU;UCR",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Riverside",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "1fc5f2f814",
        "title": "Vector Optimization with Stochastic Bandit Feedback",
        "site": "https://proceedings.mlr.press/v206/ararat23a.html",
        "author": "Cagin Ararat; Cem Tekin",
        "abstract": "We introduce vector optimization problems with stochastic bandit feedback, in which preferences among designs are encoded by a polyhedral ordering cone $C$. Our setup generalizes the best arm identification problem to vector-valued rewards by extending the concept of Pareto set beyond multi-objective optimization. We characterize the sample complexity of ($\\epsilon,\\delta$)-PAC Pareto set identification by defining a new cone-dependent notion of complexity, called the ordering complexity. In particular, we provide gap-dependent and worst-case lower bounds on the sample complexity and show that, in the worst-case, the sample complexity scales with the square of ordering complexity. Furthermore, we investigate the sample complexity of the na{\u0131\u0308}ve elimination algorithm and prove that it nearly matches the worst-case sample complexity. Finally, we run experiments to verify our theoretical results and illustrate how $C$ and sampling budget affect the Pareto set, the returned ($\\epsilon,\\delta$)-PAC Pareto set, and the success of identification.",
        "bibtex": "@InProceedings{pmlr-v206-ararat23a,\n  title = \t {Vector Optimization with Stochastic Bandit Feedback},\n  author =       {Ararat, Cagin and Tekin, Cem},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2165--2190},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/ararat23a/ararat23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/ararat23a.html},\n  abstract = \t {We introduce vector optimization problems with stochastic bandit feedback, in which preferences among designs are encoded by a polyhedral ordering cone $C$. Our setup generalizes the best arm identification problem to vector-valued rewards by extending the concept of Pareto set beyond multi-objective optimization. We characterize the sample complexity of ($\\epsilon,\\delta$)-PAC Pareto set identification by defining a new cone-dependent notion of complexity, called the ordering complexity. In particular, we provide gap-dependent and worst-case lower bounds on the sample complexity and show that, in the worst-case, the sample complexity scales with the square of ordering complexity. Furthermore, we investigate the sample complexity of the na{\u0131\u0308}ve elimination algorithm and prove that it nearly matches the worst-case sample complexity. Finally, we run experiments to verify our theoretical results and illustrate how $C$ and sampling budget affect the Pareto set, the returned ($\\epsilon,\\delta$)-PAC Pareto set, and the success of identification.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/ararat23a/ararat23a.pdf",
        "supp": "",
        "pdf_size": 632722,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2442079940784568257&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Bilkent University, Ankara, Turkey; Bilkent University, Ankara, Turkey",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bilkent University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.bilkent.edu.tr",
        "aff_unique_abbr": "Bilkent",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ankara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "e056778167",
        "title": "Vector Quantized Time Series Generation with a Bidirectional Prior Model",
        "site": "https://proceedings.mlr.press/v206/lee23d.html",
        "author": "Daesoo Lee; Sara Malacarne; Erlend Aune",
        "abstract": "Time series generation (TSG) studies have mainly focused on the use of Generative Adversarial Networks (GANs) combined with recurrent neural network (RNN) variants. However, the fundamental limitations and challenges of training GANs still remain. In addition, the RNN-family typically has difficulties with temporal consistency between distant timesteps. Motivated by the successes in the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our knowledge, that uses vector quantization (VQ) techniques to address the TSG problem. Moreover, the priors of the discrete latent spaces are learned with bidirectional transformer models that can better capture global temporal consistency. We also propose VQ modeling in a time-frequency domain, separated into low-frequency (LF) and high-frequency (HF). This allows us to retain important characteristics of the time series and, in turn, generate new synthetic signals that are of better quality, with sharper changes in modularity, than its competing TSG methods. Our experimental evaluation is conducted on all datasets from the UCR archive, using well-established metrics in the IMG literature, such as Frechet inception distance and inception scores. Our implementation on GitHub: https://github.com/ML4ITS/TimeVQVAE.",
        "bibtex": "@InProceedings{pmlr-v206-lee23d,\n  title = \t {Vector Quantized Time Series Generation with a Bidirectional Prior Model},\n  author =       {Lee, Daesoo and Malacarne, Sara and Aune, Erlend},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {7665--7693},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lee23d/lee23d.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lee23d.html},\n  abstract = \t {Time series generation (TSG) studies have mainly focused on the use of Generative Adversarial Networks (GANs) combined with recurrent neural network (RNN) variants. However, the fundamental limitations and challenges of training GANs still remain. In addition, the RNN-family typically has difficulties with temporal consistency between distant timesteps. Motivated by the successes in the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our knowledge, that uses vector quantization (VQ) techniques to address the TSG problem. Moreover, the priors of the discrete latent spaces are learned with bidirectional transformer models that can better capture global temporal consistency. We also propose VQ modeling in a time-frequency domain, separated into low-frequency (LF) and high-frequency (HF). This allows us to retain important characteristics of the time series and, in turn, generate new synthetic signals that are of better quality, with sharper changes in modularity, than its competing TSG methods. Our experimental evaluation is conducted on all datasets from the UCR archive, using well-established metrics in the IMG literature, such as Frechet inception distance and inception scores. Our implementation on GitHub: https://github.com/ML4ITS/TimeVQVAE.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lee23d/lee23d.pdf",
        "supp": "",
        "pdf_size": 10485997,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4016002234391208753&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Norwegian University of Science and Technology; Telenor Research; Norwegian University of Science and Technology + BI Norwegian Business School",
        "aff_domain": "Abelee; ; ",
        "email": "Abelee; ; ",
        "github": "https://github.com/ML4ITS/TimeVQVAE",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2",
        "aff_unique_norm": "Norwegian University of Science and Technology;Telenor;BI Norwegian Business School",
        "aff_unique_dep": ";Telenor Research;",
        "aff_unique_url": "https://www.ntnu.no;https://www.telenor.com;https://www.bi.no",
        "aff_unique_abbr": "NTNU;Telenor;BI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "ccc0261bae",
        "title": "Wasserstein Distributional Learning via Majorization-Minimization",
        "site": "https://proceedings.mlr.press/v206/tang23b.html",
        "author": "Chengliang Tang; Nathan Lenssen; Ying Wei; Tian Zheng",
        "abstract": "Learning function-on-scalar predictive models for conditional densities and identifying factors that influence the entire probability distribution are vital tasks in many data-driven applications. We present an efficient Majorization-Minimization optimization algorithm, Wasserstein Distributional Learning (WDL), that trains Semi-parametric Conditional Gaussian Mixture Models (SCGMM) for conditional density functions and uses the Wasserstein distance $W_2$ as a proper metric for the space of density outcomes. We further provide theoretical convergence guarantees and illustrate the algorithm using boosted machines. Experiments on the synthetic data and real-world applications demonstrate the effectiveness of the proposed WDL algorithm.",
        "bibtex": "@InProceedings{pmlr-v206-tang23b,\n  title = \t {Wasserstein Distributional Learning via Majorization-Minimization},\n  author =       {Tang, Chengliang and Lenssen, Nathan and Wei, Ying and Zheng, Tian},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10703--10731},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/tang23b/tang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v206/tang23b.html},\n  abstract = \t {Learning function-on-scalar predictive models for conditional densities and identifying factors that influence the entire probability distribution are vital tasks in many data-driven applications. We present an efficient Majorization-Minimization optimization algorithm, Wasserstein Distributional Learning (WDL), that trains Semi-parametric Conditional Gaussian Mixture Models (SCGMM) for conditional density functions and uses the Wasserstein distance $W_2$ as a proper metric for the space of density outcomes. We further provide theoretical convergence guarantees and illustrate the algorithm using boosted machines. Experiments on the synthetic data and real-world applications demonstrate the effectiveness of the proposed WDL algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/tang23b/tang23b.pdf",
        "supp": "",
        "pdf_size": 4960023,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15455036087315804671&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a03f3b5227",
        "title": "Wasserstein Distributionally Robust Linear-Quadratic Estimation under Martingale Constraints",
        "site": "https://proceedings.mlr.press/v206/lotidis23a.html",
        "author": "Kyriakos Lotidis; Nicholas Bambos; Jose Blanchet; Jiajin Li",
        "abstract": "We focus on robust estimation of the unobserved state of a discrete-time stochastic system with linear dynamics. A standard analysis of this estimation problem assumes a baseline innovation model; with Gaussian innovations we recover the Kalman filter. However, in many settings, there is insufficient or corrupted data to validate the baseline model. To cope with this problem, we minimize the worst-case mean-squared estimation error of adversarial models chosen within a Wasserstein neighborhood around the baseline. We also constrain the adversarial innovations to form a martingale difference sequence. The martingale constraint relaxes the i.i.d. assumptions which are often imposed on the baseline model. Moreover, we show that the martingale constraints guarantee that the adversarial dynamics remain adapted to the natural time-generated information. Therefore, adding the martingale constraint allows to improve upon over-conservative policies that also protect against unrealistic omniscient adversaries. We establish a strong duality result which we use to develop an efficient subgradient method to compute the distributionally robust estimation policy. If the baseline innovations are Gaussian, we show that the worst-case adversary remains Gaussian. Our numerical experiments indicate that the martingale constraint may also aid in adding a layer of robustness in the choice of the adversarial power.",
        "bibtex": "@InProceedings{pmlr-v206-lotidis23a,\n  title = \t {Wasserstein Distributionally Robust Linear-Quadratic Estimation under Martingale Constraints},\n  author =       {Lotidis, Kyriakos and Bambos, Nicholas and Blanchet, Jose and Li, Jiajin},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {8629--8644},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/lotidis23a/lotidis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/lotidis23a.html},\n  abstract = \t {We focus on robust estimation of the unobserved state of a discrete-time stochastic system with linear dynamics. A standard analysis of this estimation problem assumes a baseline innovation model; with Gaussian innovations we recover the Kalman filter. However, in many settings, there is insufficient or corrupted data to validate the baseline model. To cope with this problem, we minimize the worst-case mean-squared estimation error of adversarial models chosen within a Wasserstein neighborhood around the baseline. We also constrain the adversarial innovations to form a martingale difference sequence. The martingale constraint relaxes the i.i.d. assumptions which are often imposed on the baseline model. Moreover, we show that the martingale constraints guarantee that the adversarial dynamics remain adapted to the natural time-generated information. Therefore, adding the martingale constraint allows to improve upon over-conservative policies that also protect against unrealistic omniscient adversaries. We establish a strong duality result which we use to develop an efficient subgradient method to compute the distributionally robust estimation policy. If the baseline innovations are Gaussian, we show that the worst-case adversary remains Gaussian. Our numerical experiments indicate that the martingale constraint may also aid in adding a layer of robustness in the choice of the adversarial power.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/lotidis23a/lotidis23a.pdf",
        "supp": "",
        "pdf_size": 411588,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3325571702937680499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4a3b502440",
        "title": "Weather2K: A Multivariate Spatio-Temporal Benchmark Dataset for Meteorological Forecasting Based on Real-Time Observation Data from Ground Weather Stations",
        "site": "https://proceedings.mlr.press/v206/zhu23a.html",
        "author": "Xun Zhu; Yutong Xiong; Ming Wu; Gaozhen Nie; Bin Zhang; Ziheng Yang",
        "abstract": "Weather forecasting is one of the cornerstones of meteorological work. In this paper, we present a new benchmark dataset named Weather2K, which aims to make up for the deficiencies of existing weather forecasting datasets in terms of real-time, reliability, and diversity, as well as the key bottleneck of data quality. To be specific, our Weather2K is featured from the following aspects: 1) Reliable and real-time data. The data is hourly collected from 2,130 ground weather stations covering an area of 6 million square kilometers. 2) Multivariate meteorological variables. 20 meteorological factors and 3 constants for position information are provided with a length of 40,896 time steps. 3) Applicable to diverse tasks. We conduct a set of baseline tests on time series forecasting and spatio-temporal forecasting. To the best of our knowledge, our Weather2K is the first attempt to tackle weather forecasting task by taking full advantage of the strengths of observation data from ground weather stations. Based on Weather2K, we further propose Meteorological Factors based Multi-Graph Convolution Network (MFMGCN), which can effectively construct the intrinsic correlation among geographic locations based on meteorological factors. Sufficient experiments show that MFMGCN improves both the forecasting performance and temporal robustness. We hope our Weather2K can significantly motivate researchers to develop efficient and accurate algorithms to advance the task of weather forecasting. The dataset can be available at https://github.com/bycnfz/weather2k/.",
        "bibtex": "@InProceedings{pmlr-v206-zhu23a,\n  title = \t {Weather2K: A Multivariate Spatio-Temporal Benchmark Dataset for Meteorological Forecasting Based on Real-Time Observation Data from Ground Weather Stations},\n  author =       {Zhu, Xun and Xiong, Yutong and Wu, Ming and Nie, Gaozhen and Zhang, Bin and Yang, Ziheng},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2704--2722},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/zhu23a/zhu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/zhu23a.html},\n  abstract = \t {Weather forecasting is one of the cornerstones of meteorological work. In this paper, we present a new benchmark dataset named Weather2K, which aims to make up for the deficiencies of existing weather forecasting datasets in terms of real-time, reliability, and diversity, as well as the key bottleneck of data quality. To be specific, our Weather2K is featured from the following aspects: 1) Reliable and real-time data. The data is hourly collected from 2,130 ground weather stations covering an area of 6 million square kilometers. 2) Multivariate meteorological variables. 20 meteorological factors and 3 constants for position information are provided with a length of 40,896 time steps. 3) Applicable to diverse tasks. We conduct a set of baseline tests on time series forecasting and spatio-temporal forecasting. To the best of our knowledge, our Weather2K is the first attempt to tackle weather forecasting task by taking full advantage of the strengths of observation data from ground weather stations. Based on Weather2K, we further propose Meteorological Factors based Multi-Graph Convolution Network (MFMGCN), which can effectively construct the intrinsic correlation among geographic locations based on meteorological factors. Sufficient experiments show that MFMGCN improves both the forecasting performance and temporal robustness. We hope our Weather2K can significantly motivate researchers to develop efficient and accurate algorithms to advance the task of weather forecasting. The dataset can be available at https://github.com/bycnfz/weather2k/.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/zhu23a/zhu23a.pdf",
        "supp": "",
        "pdf_size": 19457704,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6851940380720374567&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; National Meteorological Center, China Meteorological Administration, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China",
        "aff_domain": "bupt.edu.cn; ; ; ; ; ",
        "email": "bupt.edu.cn; ; ; ; ; ",
        "github": "https://github.com/bycnfz/weather2k/",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications;China Meteorological Administration",
        "aff_unique_dep": ";National Meteorological Center",
        "aff_unique_url": "http://www.bupt.edu.cn/;http://www.cma.gov.cn/",
        "aff_unique_abbr": "BUPT;CMA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "b44c39cf53",
        "title": "Weisfeiler and Leman go Hyperbolic: Learning Distance Preserving Node Representations",
        "site": "https://proceedings.mlr.press/v206/nikolentzos23a.html",
        "author": "Giannis Nikolentzos; Michail Chatzianastasis; Michalis Vazirgiannis",
        "abstract": "In recent years, graph neural networks (GNNs) have emerged as a promising tool for solving machine learning problems on graphs. Most GNNs are members of the family of message passing neural networks (MPNNs). There is a close connection between these models and the Weisfeiler-Leman (WL) test of isomorphism, an algorithm that can successfully test isomorphism for a broad class of graphs. Recently, much research has focused on measuring the expressive power of GNNs. For instance, it has been shown that standard MPNNs are at most as powerful as WL in terms of distinguishing non-isomorphic graphs. However, these studies have largely ignored the distances between the representations of the nodes/graphs which are of paramount importance for learning tasks. In this paper, we define a distance function between nodes which is based on the hierarchy produced by the WL algorithm, and propose a model that learns representations which preserve those distances between nodes. Since the emerging hierarchy corresponds to a tree, to learn these representations, we capitalize on recent advances in the field of hyperbolic neural networks. We empirically evaluate the proposed model on standard graph and node classification datasets where it achieves competitive performance with state-of-the-art models.",
        "bibtex": "@InProceedings{pmlr-v206-nikolentzos23a,\n  title = \t {Weisfeiler and Leman go Hyperbolic: Learning Distance Preserving Node Representations},\n  author =       {Nikolentzos, Giannis and Chatzianastasis, Michail and Vazirgiannis, Michalis},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1037--1054},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/nikolentzos23a/nikolentzos23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/nikolentzos23a.html},\n  abstract = \t {In recent years, graph neural networks (GNNs) have emerged as a promising tool for solving machine learning problems on graphs. Most GNNs are members of the family of message passing neural networks (MPNNs). There is a close connection between these models and the Weisfeiler-Leman (WL) test of isomorphism, an algorithm that can successfully test isomorphism for a broad class of graphs. Recently, much research has focused on measuring the expressive power of GNNs. For instance, it has been shown that standard MPNNs are at most as powerful as WL in terms of distinguishing non-isomorphic graphs. However, these studies have largely ignored the distances between the representations of the nodes/graphs which are of paramount importance for learning tasks. In this paper, we define a distance function between nodes which is based on the hierarchy produced by the WL algorithm, and propose a model that learns representations which preserve those distances between nodes. Since the emerging hierarchy corresponds to a tree, to learn these representations, we capitalize on recent advances in the field of hyperbolic neural networks. We empirically evaluate the proposed model on standard graph and node classification datasets where it achieves competitive performance with state-of-the-art models.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/nikolentzos23a/nikolentzos23a.pdf",
        "supp": "",
        "pdf_size": 513360,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8157069270262483489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "60c9b97844",
        "title": "Who Should Predict? Exact Algorithms For Learning to Defer to Humans",
        "site": "https://proceedings.mlr.press/v206/mozannar23a.html",
        "author": "Hussein Mozannar; Hunter Lang; Dennis Wei; Prasanna Sattigeri; Subhro Das; David Sontag",
        "abstract": "Automated AI classifiers should be able to defer the prediction to a human decision maker to ensure more accurate predictions. In this work, we jointly train a classifier with a rejector, which decides on each data point whether the classifier or the human should predict. We show that prior approaches can fail to find a human-AI system with low mis-classification error even when there exists a linear classifier and rejector that have zero error (the realizable setting). We prove that obtaining a linear pair with low error is NP-hard even when the problem is realizable. To complement this negative result, we give a mixed-integer-linear-programming (MILP) formulation that can optimally solve the problem in the linear setting. However, the MILP only scales to moderately-sized problems. Therefore, we provide a novel surrogate loss function that is realizable-consistent and performs well empirically. We test our approaches on a comprehensive set of datasets and compare to a wide range of baselines.",
        "bibtex": "@InProceedings{pmlr-v206-mozannar23a,\n  title = \t {Who Should Predict? Exact Algorithms For Learning to Defer to Humans},\n  author =       {Mozannar, Hussein and Lang, Hunter and Wei, Dennis and Sattigeri, Prasanna and Das, Subhro and Sontag, David},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {10520--10545},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/mozannar23a/mozannar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/mozannar23a.html},\n  abstract = \t {Automated AI classifiers should be able to defer the prediction to a human decision maker to ensure more accurate predictions. In this work, we jointly train a classifier with a rejector, which decides on each data point whether the classifier or the human should predict. We show that prior approaches can fail to find a human-AI system with low mis-classification error even when there exists a linear classifier and rejector that have zero error (the realizable setting). We prove that obtaining a linear pair with low error is NP-hard even when the problem is realizable. To complement this negative result, we give a mixed-integer-linear-programming (MILP) formulation that can optimally solve the problem in the linear setting. However, the MILP only scales to moderately-sized problems. Therefore, we provide a novel surrogate loss function that is realizable-consistent and performs well empirically. We test our approaches on a comprehensive set of datasets and compare to a wide range of baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/mozannar23a/mozannar23a.pdf",
        "supp": "",
        "pdf_size": 1516612,
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10754074689663909929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "074332ccd6",
        "title": "qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v206/astudillo23a.html",
        "author": "Raul Astudillo; Zhiyuan Jerry Lin; Eytan Bakshy; Peter Frazier",
        "abstract": "Preferential Bayesian optimization (PBO) is a framework for optimizing a decision maker\u2019s latent utility function using preference feedback. This work introduces the expected utility of the best option (qEUBO) as a novel acquisition function for PBO. When the decision maker\u2019s responses are noise-free, we show that qEUBO is one-step Bayes optimal and thus equivalent to the popular knowledge gradient acquisition function. We also show that qEUBO enjoys an additive constant approximation guarantee to the one-step Bayes-optimal policy when the decision maker\u2019s responses are corrupted by noise. We provide an extensive evaluation of qEUBO and demonstrate that it outperforms the state-of-the-art acquisition functions for PBO across many settings. Finally, we show that, under sufficient regularity conditions, qEUBO\u2019s Bayesian simple regret converges to zero at a rate $o(1/n)$ as the number of queries, $n$, goes to infinity. In contrast, we show that simple regret under qEI, a popular acquisition function for standard BO often used for PBO, can fail to converge to zero. Enjoying superior performance, simple computation, and a grounded decision-theoretic justification, qEUBO is a promising acquisition function for PBO.",
        "bibtex": "@InProceedings{pmlr-v206-astudillo23a,\n  title = \t {qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization},\n  author =       {Astudillo, Raul and Lin, Zhiyuan Jerry and Bakshy, Eytan and Frazier, Peter},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1093--1114},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/astudillo23a/astudillo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/astudillo23a.html},\n  abstract = \t {Preferential Bayesian optimization (PBO) is a framework for optimizing a decision maker\u2019s latent utility function using preference feedback. This work introduces the expected utility of the best option (qEUBO) as a novel acquisition function for PBO. When the decision maker\u2019s responses are noise-free, we show that qEUBO is one-step Bayes optimal and thus equivalent to the popular knowledge gradient acquisition function. We also show that qEUBO enjoys an additive constant approximation guarantee to the one-step Bayes-optimal policy when the decision maker\u2019s responses are corrupted by noise. We provide an extensive evaluation of qEUBO and demonstrate that it outperforms the state-of-the-art acquisition functions for PBO across many settings. Finally, we show that, under sufficient regularity conditions, qEUBO\u2019s Bayesian simple regret converges to zero at a rate $o(1/n)$ as the number of queries, $n$, goes to infinity. In contrast, we show that simple regret under qEI, a popular acquisition function for standard BO often used for PBO, can fail to converge to zero. Enjoying superior performance, simple computation, and a grounded decision-theoretic justification, qEUBO is a promising acquisition function for PBO.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/astudillo23a/astudillo23a.pdf",
        "supp": "",
        "pdf_size": 36529114,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1364346298359916224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5ebeaf29cf",
        "title": "{PF}$^2$ES: Parallel Feasible Pareto Frontier Entropy Search for Multi-Objective Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v206/qing23a.html",
        "author": "Jixiang Qing; Henry B. Moss; Tom Dhaene; Ivo Couckuyt",
        "abstract": "We present Parallel Feasible Pareto Frontier Entropy Search ($\\{\\mathrm{PF}\\}^2$ES) \u2014 a novel information-theoretic acquisition function for multi-objective Bayesian optimization supporting unknown constraints and batch queries. Due to the complexity of characterizing the mutual information between candidate evaluations and (feasible) Pareto frontiers, existing approaches must either employ crude approximations that significantly hamper their performance or rely on expensive inference schemes that substantially increase the optimization\u2019s computational overhead. By instead using a variational lower bound, $\\{\\mathrm{PF}\\}^2$ES provides a low-cost and accurate estimate of the mutual information. We benchmark $\\{\\mathrm{PF}\\}^2$ES against other information-theoretic acquisition functions, demonstrating its competitive performance for optimization across synthetic and real-world design problems.",
        "bibtex": "@InProceedings{pmlr-v206-qing23a,\n  title = \t {\\{PF\\}$^2$ES: Parallel Feasible Pareto Frontier Entropy Search for Multi-Objective Bayesian Optimization},\n  author =       {Qing, Jixiang and Moss, Henry B. and Dhaene, Tom and Couckuyt, Ivo},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2565--2588},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/qing23a/qing23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/qing23a.html},\n  abstract = \t {We present Parallel Feasible Pareto Frontier Entropy Search ($\\{\\mathrm{PF}\\}^2$ES) \u2014 a novel information-theoretic acquisition function for multi-objective Bayesian optimization supporting unknown constraints and batch queries. Due to the complexity of characterizing the mutual information between candidate evaluations and (feasible) Pareto frontiers, existing approaches must either employ crude approximations that significantly hamper their performance or rely on expensive inference schemes that substantially increase the optimization\u2019s computational overhead. By instead using a variational lower bound, $\\{\\mathrm{PF}\\}^2$ES provides a low-cost and accurate estimate of the mutual information. We benchmark $\\{\\mathrm{PF}\\}^2$ES against other information-theoretic acquisition functions, demonstrating its competitive performance for optimization across synthetic and real-world design problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/qing23a/qing23a.pdf",
        "supp": "",
        "pdf_size": 19465113,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1908422599277453535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Ghent University -imec; Secondmind.ai + Ghent University -imec; Ghent University -imec; Ghent University -imec",
        "aff_domain": "Ugent.be; ; ; ",
        "email": "Ugent.be; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;0",
        "aff_unique_norm": "Ghent University;Secondmind",
        "aff_unique_dep": "-imec;",
        "aff_unique_url": "https://www.ugent.be/en;https://www.secondmind.ai",
        "aff_unique_abbr": "UGent;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+0;0;0",
        "aff_country_unique": "Belgium;United Kingdom"
    },
    {
        "id": "f313f34051",
        "title": "\u201cPlus/minus the learning rate\u201d: Easy and Scalable Statistical Inference with SGD",
        "site": "https://proceedings.mlr.press/v206/chee23a.html",
        "author": "Jerry Chee; Hwanwoo Kim; Panos Toulis",
        "abstract": "In this paper, we develop a statistical inference procedure using stochastic gradient descent (SGD)-based confidence intervals. These intervals are of the simplest possible form: $\\theta_{N,j} \\pm 2\\sqrt{}(\\gamma/N)$ , where $\\theta_N$ is the SGD estimate of model parameters $\\theta$ over N data points, and $\\gamma$ is the learning rate. This construction relies only on a proper selection of the learning rate to ensure the standard SGD conditions for O(1/n) convergence. The procedure performs well in our empirical evaluations, achieving near-nominal coverage intervals scaling up to 20$\\times$ as many parameters as other SGD-based inference methods. We also demonstrate our method\u2019s  practical significance on modeling adverse events in emergency general surgery patients using a novel dataset from the Hospital of the University of Pennsylvania.",
        "bibtex": "@InProceedings{pmlr-v206-chee23a,\n  title = \t {\u201cPlus/minus the learning rate\u201d: Easy and Scalable Statistical Inference with SGD},\n  author =       {Chee, Jerry and Kim, Hwanwoo and Toulis, Panos},\n  booktitle = \t {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2285--2309},\n  year = \t {2023},\n  editor = \t {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},\n  volume = \t {206},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {25--27 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v206/chee23a/chee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v206/chee23a.html},\n  abstract = \t {In this paper, we develop a statistical inference procedure using stochastic gradient descent (SGD)-based confidence intervals. These intervals are of the simplest possible form: $\\theta_{N,j} \\pm 2\\sqrt{}(\\gamma/N)$ , where $\\theta_N$ is the SGD estimate of model parameters $\\theta$ over N data points, and $\\gamma$ is the learning rate. This construction relies only on a proper selection of the learning rate to ensure the standard SGD conditions for O(1/n) convergence. The procedure performs well in our empirical evaluations, achieving near-nominal coverage intervals scaling up to 20$\\times$ as many parameters as other SGD-based inference methods. We also demonstrate our method\u2019s  practical significance on modeling adverse events in emergency general surgery patients using a novel dataset from the Hospital of the University of Pennsylvania.}\n}",
        "pdf": "https://proceedings.mlr.press/v206/chee23a/chee23a.pdf",
        "supp": "",
        "pdf_size": 462844,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3162008087268077884&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Cornell University, Department of Computer Science; University of Chicago, Department of Statistics; University of Chicago, Booth School of Business",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Cornell University;University of Chicago",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics",
        "aff_unique_url": "https://www.cornell.edu;https://www.uchicago.edu",
        "aff_unique_abbr": "Cornell;UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    }
]