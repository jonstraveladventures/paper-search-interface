[
    {
        "id": "cb62e6a3a6",
        "title": "A Characterization of Mean Squared Error for Estimator with Bagging",
        "site": "https://proceedings.mlr.press/v108/mihelich20a.html",
        "author": "Martin Mihelich; Charles Dognin; Yan Shu; Michael Blot",
        "abstract": "Bagging can significantly improve the generalization performance of unstable machine learning algorithms such as trees or neural networks. Though bagging is now widely used in practice and many empirical studies have explored its behavior, we still know little about the theoretical properties of bagged predictions. In this paper, we theoretically investigate how the bagging method can reduce the Mean Squared Error (MSE) when applied on a statistical estimator. First, we prove that for any estimator, increasing the number of bagged estimators $N$ in the average can only reduce the MSE. This intuitive result, observed empirically and discussed in the literature, has not yet been rigorously proved. Second, we focus on the standard estimator of variance called unbiased sample variance and we develop an exact analytical expression of the MSE for this estimator with bagging.     This allows us to rigorously discuss the number of iterations $N$ and the batch size $m$ of the bagging method. From this expression, we state that only if the kurtosis of the distribution is greater than $\\frac{3}{2}$, the MSE of the variance estimator can be reduced with bagging. This result is important because it demonstrates that for distribution with low kurtosis, bagging can only deteriorate the performance of a statistical prediction. Finally, we propose a novel general-purpose algorithm to estimate with high precision the variance of a sample.",
        "bibtex": "@InProceedings{pmlr-v108-mihelich20a,\n  title = \t {A Characterization of Mean Squared Error for Estimator with Bagging},\n  author =       {Mihelich, Martin and Dognin, Charles and Shu, Yan and Blot, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {288--297},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mihelich20a/mihelich20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mihelich20a.html},\n  abstract = \t {Bagging can significantly improve the generalization performance of unstable machine learning algorithms such as trees or neural networks. Though bagging is now widely used in practice and many empirical studies have explored its behavior, we still know little about the theoretical properties of bagged predictions. In this paper, we theoretically investigate how the bagging method can reduce the Mean Squared Error (MSE) when applied on a statistical estimator. First, we prove that for any estimator, increasing the number of bagged estimators $N$ in the average can only reduce the MSE. This intuitive result, observed empirically and discussed in the literature, has not yet been rigorously proved. Second, we focus on the standard estimator of variance called unbiased sample variance and we develop an exact analytical expression of the MSE for this estimator with bagging.     This allows us to rigorously discuss the number of iterations $N$ and the batch size $m$ of the bagging method. From this expression, we state that only if the kurtosis of the distribution is greater than $\\frac{3}{2}$, the MSE of the variance estimator can be reduced with bagging. This result is important because it demonstrates that for distribution with low kurtosis, bagging can only deteriorate the performance of a statistical prediction. Finally, we propose a novel general-purpose algorithm to estimate with high precision the variance of a sample.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mihelich20a/mihelich20a.pdf",
        "supp": "",
        "pdf_size": 556588,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2102004190316261642&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "31f3e00c64",
        "title": "A Continuous-time Perspective for Modeling Acceleration in Riemannian Optimization",
        "site": "https://proceedings.mlr.press/v108/alimisis20a.html",
        "author": "Foivos Alimisis; Antonio Orvieto; Gary Becigneul; Aurelien Lucchi",
        "abstract": "We propose a novel second-order ODE as the continuous-time limit of a Riemannian accelerated gradient-based method on a manifold with curvature bounded from below. This ODE can be seen as a generalization of the  ODE derived for Euclidean spaces, and can also serve as an analysis tool. We analyze the convergence behavior of this ODE for different types of functions, such as geodesically convex, strongly-convex and weakly-quasi-convex. We demonstrate how such an ODE can be discretized using a semi-implicit and Nesterov-inspired numerical integrator, that empirically yields stable algorithms which are faithful to the continuous-time analysis and exhibit accelerated convergence.",
        "bibtex": "@InProceedings{pmlr-v108-alimisis20a,\n  title = \t {A Continuous-time Perspective for Modeling Acceleration in Riemannian Optimization},\n  author =       {Alimisis, Foivos and Orvieto, Antonio and Becigneul, Gary and Lucchi, Aurelien},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1297--1307},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/alimisis20a/alimisis20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/alimisis20a.html},\n  abstract = \t {We propose a novel second-order ODE as the continuous-time limit of a Riemannian accelerated gradient-based method on a manifold with curvature bounded from below. This ODE can be seen as a generalization of the  ODE derived for Euclidean spaces, and can also serve as an analysis tool. We analyze the convergence behavior of this ODE for different types of functions, such as geodesically convex, strongly-convex and weakly-quasi-convex. We demonstrate how such an ODE can be discretized using a semi-implicit and Nesterov-inspired numerical integrator, that empirically yields stable algorithms which are faithful to the continuous-time analysis and exhibit accelerated convergence.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/alimisis20a/alimisis20a.pdf",
        "supp": "",
        "pdf_size": 911087,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13763536727587697811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "db13792d29",
        "title": "A Deep Generative Model for Fragment-Based Molecule Generation",
        "site": "https://proceedings.mlr.press/v108/podda20a.html",
        "author": "Marco Podda; Davide Bacciu; Alessio Micheli",
        "abstract": "Molecule generation is a challenging open problem in cheminformatics. Currently, deep generative approaches addressing the challenge belong to two broad categories, differing in how molecules are represented. One approach encodes molecular graphs as strings of text, and learns their corresponding character-based language model. Another, more expressive, approach operates directly on the molecular graph. In this work, we address two limitations of the former: generation of invalid and duplicate molecules. To improve validity rates, we develop a language model for small molecular substructures called fragments, loosely inspired by the well-known paradigm of Fragment-Based Drug Design. In other words, we generate molecules fragment by fragment, instead of atom by atom. To improve uniqueness rates, we present a frequency-based masking strategy that helps generate molecules with infrequent fragments. We show experimentally that our model largely outperforms other language model-based competitors, reaching state-of-the-art performances typical of graph-based approaches. Moreover, generated molecules display  molecular properties similar to those in the training sample, even in absence of explicit task-specific supervision.",
        "bibtex": "@InProceedings{pmlr-v108-podda20a,\n  title = \t {A Deep Generative Model for Fragment-Based Molecule Generation},\n  author =       {Podda, Marco and Bacciu, Davide and Micheli, Alessio},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2240--2250},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/podda20a/podda20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/podda20a.html},\n  abstract = \t {Molecule generation is a challenging open problem in cheminformatics. Currently, deep generative approaches addressing the challenge belong to two broad categories, differing in how molecules are represented. One approach encodes molecular graphs as strings of text, and learns their corresponding character-based language model. Another, more expressive, approach operates directly on the molecular graph. In this work, we address two limitations of the former: generation of invalid and duplicate molecules. To improve validity rates, we develop a language model for small molecular substructures called fragments, loosely inspired by the well-known paradigm of Fragment-Based Drug Design. In other words, we generate molecules fragment by fragment, instead of atom by atom. To improve uniqueness rates, we present a frequency-based masking strategy that helps generate molecules with infrequent fragments. We show experimentally that our model largely outperforms other language model-based competitors, reaching state-of-the-art performances typical of graph-based approaches. Moreover, generated molecules display  molecular properties similar to those in the training sample, even in absence of explicit task-specific supervision.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/podda20a/podda20a.pdf",
        "supp": "",
        "pdf_size": 685748,
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8941496937643584295&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ab3ea33a2d",
        "title": "A Distributional Analysis of Sampling-Based Reinforcement Learning Algorithms",
        "site": "https://proceedings.mlr.press/v108/amortila20a.html",
        "author": "Philip Amortila; Doina Precup; Prakash Panangaden; Marc G. Bellemare",
        "abstract": "We present a distributional approach to theoretical analyses of reinforcement learning algorithms for constant step-sizes. We demonstrate its effectiveness by presenting simple and unified proofs of convergence for a variety of commonly-used methods. We show that value-based methods such as TD(?) and Q-Learning have update rules which are contractive in the space of distributions of functions, thus establishing their exponentially fast convergence to a stationary distribution. We demonstrate that the stationary distribution obtained by any algorithm whose target is an expected Bellman update has a mean which is equal to the true value function. Furthermore, we establish that the distributions concentrate around their mean as the step-size shrinks. We further analyse the optimistic policy iteration algorithm, for which the contraction property does not hold, and formulate a probabilistic policy improvement property which entails the convergence of the algorithm.",
        "bibtex": "@InProceedings{pmlr-v108-amortila20a,\n  title = \t {A Distributional Analysis of Sampling-Based Reinforcement Learning Algorithms},\n  author =       {Amortila, Philip and Precup, Doina and Panangaden, Prakash and Bellemare, Marc G.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4357--4366},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/amortila20a/amortila20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/amortila20a.html},\n  abstract = \t {We present a distributional approach to theoretical analyses of reinforcement learning algorithms for constant step-sizes. We demonstrate its effectiveness by presenting simple and unified proofs of convergence for a variety of commonly-used methods. We show that value-based methods such as TD(?) and Q-Learning have update rules which are contractive in the space of distributions of functions, thus establishing their exponentially fast convergence to a stationary distribution. We demonstrate that the stationary distribution obtained by any algorithm whose target is an expected Bellman update has a mean which is equal to the true value function. Furthermore, we establish that the distributions concentrate around their mean as the step-size shrinks. We further analyse the optimistic policy iteration algorithm, for which the contraction property does not hold, and formulate a probabilistic policy improvement property which entails the convergence of the algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/amortila20a/amortila20a.pdf",
        "supp": "",
        "pdf_size": 763241,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17184873335718998300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4e989adc4f",
        "title": "A Diversity-aware Model for Majority Vote Ensemble Accuracy",
        "site": "https://proceedings.mlr.press/v108/durrant20a.html",
        "author": "Bob Durrant; Nick Lim",
        "abstract": "Ensemble classifiers are a successful and popular approach for classification, and are frequently found to have better generalization performance than single models in practice. Although it is widely recognized that \u2018diversity\u2019 between ensemble members is important in achieving these performance gains, for classification ensembles it is not widely understood which diversity measures are most predictive of ensemble performance, nor how large an ensemble should be for a particular application. In this paper, we explore the predictive power of several common diversity measures and show \u2013 with extensive experiments \u2013 that contrary to earlier work that finds no clear link between these diversity measures (in isolation) and ensemble accuracy instead by using the $\\rho$ diversity measure of Sneath and Sokal as an estimator for the dispersion parameter of a Polya-Eggenberger distribution we can predict, independently of the choice of base classifier family, the accuracy of a majority vote classifier ensemble ridiculously well. We discuss our model and some implications of our findings \u2013 such as diversity-aware (non-greedy) pruning of a majority-voting ensemble.",
        "bibtex": "@InProceedings{pmlr-v108-durrant20a,\n  title = \t {A Diversity-aware Model for Majority Vote Ensemble Accuracy},\n  author =       {Durrant, Bob and Lim, Nick},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4078--4087},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/durrant20a/durrant20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/durrant20a.html},\n  abstract = \t {Ensemble classifiers are a successful and popular approach for classification, and are frequently found to have better generalization performance than single models in practice. Although it is widely recognized that \u2018diversity\u2019 between ensemble members is important in achieving these performance gains, for classification ensembles it is not widely understood which diversity measures are most predictive of ensemble performance, nor how large an ensemble should be for a particular application. In this paper, we explore the predictive power of several common diversity measures and show \u2013 with extensive experiments \u2013 that contrary to earlier work that finds no clear link between these diversity measures (in isolation) and ensemble accuracy instead by using the $\\rho$ diversity measure of Sneath and Sokal as an estimator for the dispersion parameter of a Polya-Eggenberger distribution we can predict, independently of the choice of base classifier family, the accuracy of a majority vote classifier ensemble ridiculously well. We discuss our model and some implications of our findings \u2013 such as diversity-aware (non-greedy) pruning of a majority-voting ensemble.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/durrant20a/durrant20a.pdf",
        "supp": "",
        "pdf_size": 4152952,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6658285113093668523&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3b658d00e8",
        "title": "A Double Residual Compression Algorithm for Efficient Distributed Learning",
        "site": "https://proceedings.mlr.press/v108/liu20a.html",
        "author": "Xiaorui Liu; Yao Li; Jiliang Tang; Ming Yan",
        "abstract": "Large-scale machine learning models are often trained by parallel stochastic gradient descent algorithms. However, the communication cost of gradient aggregation and model synchronization between the master and worker nodes becomes the major obstacle for efficient learning as the number of workers and the dimension of the model increase. In this paper, we propose DORE, a DOuble REsidual compression stochastic gradient descent algorithm, to reduce over $95%$ of the overall communication such that the obstacle can be immensely mitigated. Our theoretical analyses demonstrate that the proposed strategy has superior convergence properties for both strongly convex and nonconvex objective functions. The experimental results validate that DORE achieves the best communication efficiency while maintaining similar model accuracy and convergence speed in comparison with start-of-the-art baselines.",
        "bibtex": "@InProceedings{pmlr-v108-liu20a,\n  title = \t {A Double Residual Compression Algorithm for Efficient Distributed Learning},\n  author =       {Liu, Xiaorui and Li, Yao and Tang, Jiliang and Yan, Ming},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {133--143},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/liu20a/liu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/liu20a.html},\n  abstract = \t {Large-scale machine learning models are often trained by parallel stochastic gradient descent algorithms. However, the communication cost of gradient aggregation and model synchronization between the master and worker nodes becomes the major obstacle for efficient learning as the number of workers and the dimension of the model increase. In this paper, we propose DORE, a DOuble REsidual compression stochastic gradient descent algorithm, to reduce over $95%$ of the overall communication such that the obstacle can be immensely mitigated. Our theoretical analyses demonstrate that the proposed strategy has superior convergence properties for both strongly convex and nonconvex objective functions. The experimental results validate that DORE achieves the best communication efficiency while maintaining similar model accuracy and convergence speed in comparison with start-of-the-art baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/liu20a/liu20a.pdf",
        "supp": "",
        "pdf_size": 1824723,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1946752846152767883&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Michigan State University; Michigan State University; Michigan State University; Michigan State University",
        "aff_domain": "msu.edu;msu.edu;msu.edu;msu.edu",
        "email": "msu.edu;msu.edu;msu.edu;msu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "908a261e03",
        "title": "A Farewell to Arms: Sequential Reward Maximization on a Budget with a Giving Up Option",
        "site": "https://proceedings.mlr.press/v108/sharoff20a.html",
        "author": "P Sharoff; Nishant Mehta; Ravi Ganti",
        "abstract": "We consider a sequential decision-making problem where an agent can take one action at a time and each action has a stochastic temporal extent, i.e., a new action cannot be taken until the previous one is finished. Upon completion, the chosen action yields a stochastic reward. The agent seeks to maximize its cumulative reward over a finite time budget, with the option of \"giving up\" on a current action \u2014  hence forfeiting any reward \u2013 in order to choose another action. We cast this problem as a variant of the stochastic multi-armed bandits problem with stochastic consumption of resource. For this problem, we first establish that the optimal arm is the one that maximizes the ratio of the expected reward of the arm to the expected waiting time before the agent sees the reward due to pulling that arm. Using a novel upper confidence bound on this ratio, we then introduce an upper confidence based-algorithm, WAIT-UCB, for which we establish logarithmic, problem-dependent regret bound which has an improved dependence on problem parameters compared to previous works. Simulations on various problem configurations comparing WAIT-UCB against the state-of-the-art algorithms are also presented.",
        "bibtex": "@InProceedings{pmlr-v108-sharoff20a,\n  title = \t {A Farewell to Arms: Sequential Reward Maximization on a Budget with a Giving Up Option},\n  author =       {Sharoff, P and Mehta, Nishant and Ganti, Ravi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3707--3716},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sharoff20a/sharoff20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sharoff20a.html},\n  abstract = \t {We consider a sequential decision-making problem where an agent can take one action at a time and each action has a stochastic temporal extent, i.e., a new action cannot be taken until the previous one is finished. Upon completion, the chosen action yields a stochastic reward. The agent seeks to maximize its cumulative reward over a finite time budget, with the option of \"giving up\" on a current action \u2014  hence forfeiting any reward \u2013 in order to choose another action. We cast this problem as a variant of the stochastic multi-armed bandits problem with stochastic consumption of resource. For this problem, we first establish that the optimal arm is the one that maximizes the ratio of the expected reward of the arm to the expected waiting time before the agent sees the reward due to pulling that arm. Using a novel upper confidence bound on this ratio, we then introduce an upper confidence based-algorithm, WAIT-UCB, for which we establish logarithmic, problem-dependent regret bound which has an improved dependence on problem parameters compared to previous works. Simulations on various problem configurations comparing WAIT-UCB against the state-of-the-art algorithms are also presented.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sharoff20a/sharoff20a.pdf",
        "supp": "",
        "pdf_size": 477438,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6837823006209933032&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Victoria; Department of Computer Science, University of Victoria; Google",
        "aff_domain": "uvic.ca;uvic.ca;gmail.com",
        "email": "uvic.ca;uvic.ca;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Victoria;Google",
        "aff_unique_dep": "Department of Computer Science;Google",
        "aff_unique_url": "https://www.uvic.ca;https://www.google.com",
        "aff_unique_abbr": "UVic;Google",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Victoria;Mountain View",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "89a538861e",
        "title": "A Fast Anderson-Chebyshev Acceleration for Nonlinear Optimization",
        "site": "https://proceedings.mlr.press/v108/li20d.html",
        "author": "Zhize Li; Jian Li",
        "abstract": "\\emph{Anderson acceleration} (or Anderson mixing) is an efficient acceleration method for fixed point iterations $x_{t+1}=G(x_t)$, e.g., gradient descent can be viewed as iteratively applying the operation $G(x) \\triangleq x-\\alphaabla f(x)$.  It is known that Anderson acceleration is quite efficient in practice and can be viewed as an extension of Krylov subspace methods for nonlinear problems.  In this paper, we show that Anderson acceleration with Chebyshev polynomial can achieve the optimal convergence rate $O(\\sqrt{\\kappa}\\ln\\frac{1}{\\epsilon})$, which improves the previous result $O(\\kappa\\ln\\frac{1}{\\epsilon})$ provided by (Toth & Kelley, 2015) for quadratic functions.  Moreover, we provide a convergence analysis for minimizing general nonlinear problems.  Besides, if the hyperparameters (e.g., the Lipschitz smooth parameter $L$) are not available, we propose a \\emph{guessing algorithm} for guessing them dynamically and also prove a similar convergence rate.  Finally, the experimental results demonstrate that the proposed Anderson-Chebyshev acceleration method converges significantly faster than other algorithms, e.g., vanilla gradient descent (GD), Nesterov\u2019s Accelerated GD.  Also, these algorithms combined with the proposed guessing algorithm (guessing the hyperparameters dynamically) achieve much better performance.",
        "bibtex": "@InProceedings{pmlr-v108-li20d,\n  title = \t {A Fast Anderson-Chebyshev Acceleration for Nonlinear Optimization},\n  author =       {Li, Zhize and Li, Jian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1047--1057},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20d/li20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20d.html},\n  abstract = \t {\\emph{Anderson acceleration} (or Anderson mixing) is an efficient acceleration method for fixed point iterations $x_{t+1}=G(x_t)$, e.g., gradient descent can be viewed as iteratively applying the operation $G(x) \\triangleq x-\\alphaabla f(x)$.  It is known that Anderson acceleration is quite efficient in practice and can be viewed as an extension of Krylov subspace methods for nonlinear problems.  In this paper, we show that Anderson acceleration with Chebyshev polynomial can achieve the optimal convergence rate $O(\\sqrt{\\kappa}\\ln\\frac{1}{\\epsilon})$, which improves the previous result $O(\\kappa\\ln\\frac{1}{\\epsilon})$ provided by (Toth & Kelley, 2015) for quadratic functions.  Moreover, we provide a convergence analysis for minimizing general nonlinear problems.  Besides, if the hyperparameters (e.g., the Lipschitz smooth parameter $L$) are not available, we propose a \\emph{guessing algorithm} for guessing them dynamically and also prove a similar convergence rate.  Finally, the experimental results demonstrate that the proposed Anderson-Chebyshev acceleration method converges significantly faster than other algorithms, e.g., vanilla gradient descent (GD), Nesterov\u2019s Accelerated GD.  Also, these algorithms combined with the proposed guessing algorithm (guessing the hyperparameters dynamically) achieve much better performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20d/li20d.pdf",
        "supp": "",
        "pdf_size": 1100198,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11826083085800456206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "King Abdullah University of Science and Technology; Tsinghua University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "King Abdullah University of Science and Technology;Tsinghua University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kast.kau.edu.sa;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "KAUST;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Saudi Arabia;China"
    },
    {
        "id": "408bf30b06",
        "title": "A Framework for Sample Efficient Interval Estimation with Control Variates",
        "site": "https://proceedings.mlr.press/v108/zhao20e.html",
        "author": "Shengjia Zhao; Christopher Yeh; Stefano Ermon",
        "abstract": "We consider the problem of estimating confidence intervals for the mean of a random variable, where the goal is to produce the smallest possible interval for a given number of samples. While minimax optimal algorithms are known for this problem in the general case, improved performance is possible under additional assumptions. In particular, we design an estimation algorithm to take advantage of side information in the form of a control variate, leveraging order statistics. Under certain conditions on the quality of the control variates, we show improved asymptotic efficiency compared to existing estimation algorithms. Empirically, we demonstrate superior performance on several real world surveying and estimation tasks where we use regression models as control variates.",
        "bibtex": "@InProceedings{pmlr-v108-zhao20e,\n  title = \t {A Framework for Sample Efficient Interval Estimation with Control Variates},\n  author =       {Zhao, Shengjia and Yeh, Christopher and Ermon, Stefano},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4583--4592},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhao20e/zhao20e.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhao20e.html},\n  abstract = \t {We consider the problem of estimating confidence intervals for the mean of a random variable, where the goal is to produce the smallest possible interval for a given number of samples. While minimax optimal algorithms are known for this problem in the general case, improved performance is possible under additional assumptions. In particular, we design an estimation algorithm to take advantage of side information in the form of a control variate, leveraging order statistics. Under certain conditions on the quality of the control variates, we show improved asymptotic efficiency compared to existing estimation algorithms. Empirically, we demonstrate superior performance on several real world surveying and estimation tasks where we use regression models as control variates.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhao20e/zhao20e.pdf",
        "supp": "",
        "pdf_size": 459084,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11478778090227582100&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "62566147c6",
        "title": "A Hybrid Stochastic Policy Gradient Algorithm for Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v108/pham20a.html",
        "author": "Nhan Pham; Lam Nguyen; Dzung Phan; PHUONG HA NGUYEN; Marten Dijk; Quoc Tran-Dinh",
        "abstract": "We propose a novel hybrid stochastic policy gradient estimator by combining an unbiased policy gradient estimator, the REINFORCE estimator, with another biased one, an adapted SARAH estimator for policy optimization. The hybrid policy gradient estimator is shown to be biased, but has variance reduced property. Using this estimator, we develop a new Proximal Hybrid Stochastic Policy Gradient Algorithm (ProxHSPGA) to solve a composite policy optimization problem that allows us to handle constraints or regularizers on the policy parameters. We first propose a single-looped algorithm then introduce a more practical restarting variant. We prove that both algorithms can achieve the best-known trajectory complexity to attain a first-order stationary point for the composite problem which is better than existing REINFORCE/GPOMDP and SVRPG in the non-composite setting. We evaluate the performance of our algorithm on several well-known examples in reinforcement learning. Numerical results show that our algorithm outperforms two existing methods on these examples. Moreover, the composite settings indeed have some advantages compared to the non-composite ones on certain problems.",
        "bibtex": "@InProceedings{pmlr-v108-pham20a,\n  title = \t {A Hybrid Stochastic Policy Gradient Algorithm for Reinforcement Learning},\n  author =       {Pham, Nhan and Nguyen, Lam and Phan, Dzung and Nguyen, Phuong Ha and van Dijk, Marten and Tran-Dinh, Quoc},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {374--385},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pham20a/pham20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pham20a.html},\n  abstract = \t {We propose a novel hybrid stochastic policy gradient estimator by combining an unbiased policy gradient estimator, the REINFORCE estimator, with another biased one, an adapted SARAH estimator for policy optimization. The hybrid policy gradient estimator is shown to be biased, but has variance reduced property. Using this estimator, we develop a new Proximal Hybrid Stochastic Policy Gradient Algorithm (ProxHSPGA) to solve a composite policy optimization problem that allows us to handle constraints or regularizers on the policy parameters. We first propose a single-looped algorithm then introduce a more practical restarting variant. We prove that both algorithms can achieve the best-known trajectory complexity to attain a first-order stationary point for the composite problem which is better than existing REINFORCE/GPOMDP and SVRPG in the non-composite setting. We evaluate the performance of our algorithm on several well-known examples in reinforcement learning. Numerical results show that our algorithm outperforms two existing methods on these examples. Moreover, the composite settings indeed have some advantages compared to the non-composite ones on certain problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pham20a/pham20a.pdf",
        "supp": "",
        "pdf_size": 1204922,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9999237396662998436&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "UNC Chapel Hill; IBM Research; UConn; CWI Amsterdam; UNC Chapel Hill; UNC Chapel Hill",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;IBM;University of Connecticut;Centrum Wiskunde & Informatica",
        "aff_unique_dep": ";IBM Research;;",
        "aff_unique_url": "https://www.unc.edu;https://www.ibm.com/research;https://www.uconn.edu;https://www.cwi.nl",
        "aff_unique_abbr": "UNC;IBM;UConn;CWI",
        "aff_campus_unique_index": "0;2;0;0",
        "aff_campus_unique": "Chapel Hill;;Amsterdam",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Netherlands"
    },
    {
        "id": "db83fa6738",
        "title": "A Linear-time Independence Criterion Based on a Finite Basis Approximation",
        "site": "https://proceedings.mlr.press/v108/yan20a.html",
        "author": "Longfei Yan; W. Bastiaan Kleijn; Thushara Abhayapala",
        "abstract": "Detection of statistical dependence between random variables is an essential component in many machine learning algorithms. We propose a novel independence criterion for two random variables with linear-time complexity. We establish that our independence criterion is an upper bound of the Hirschfeld-Gebelein-R\u00e9nyi maximum correlation coefficient between tested variables. A finite set of basis functions is employed to approximate the mapping functions that can achieve the maximal correlation. Using classic benchmark experiments based on independent component analysis, we demonstrate that our independence criterion performs comparably with the state-of-the-art quadratic-time kernel dependence measures like the Hilbert-Schmidt Independence Criterion, while being more efficient in computation. The experimental results also show that our independence criterion outperforms another contemporary linear-time kernel dependence measure, the Finite Set Independence Criterion. The potential application of our criterion in deep neural networks is validated experimentally.",
        "bibtex": "@InProceedings{pmlr-v108-yan20a,\n  title = \t {A Linear-time Independence Criterion Based on a Finite Basis Approximation},\n  author =       {Yan, Longfei and Kleijn, W. Bastiaan and Abhayapala, Thushara},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {202--212},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yan20a/yan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yan20a.html},\n  abstract = \t {Detection of statistical dependence between random variables is an essential component in many machine learning algorithms. We propose a novel independence criterion for two random variables with linear-time complexity. We establish that our independence criterion is an upper bound of the Hirschfeld-Gebelein-R\u00e9nyi maximum correlation coefficient between tested variables. A finite set of basis functions is employed to approximate the mapping functions that can achieve the maximal correlation. Using classic benchmark experiments based on independent component analysis, we demonstrate that our independence criterion performs comparably with the state-of-the-art quadratic-time kernel dependence measures like the Hilbert-Schmidt Independence Criterion, while being more efficient in computation. The experimental results also show that our independence criterion outperforms another contemporary linear-time kernel dependence measure, the Finite Set Independence Criterion. The potential application of our criterion in deep neural networks is validated experimentally.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yan20a/yan20a.pdf",
        "supp": "",
        "pdf_size": 300896,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6689199313347219171&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6954faba58",
        "title": "A Locally Adaptive Bayesian Cubature Method",
        "site": "https://proceedings.mlr.press/v108/fisher20a.html",
        "author": "Matthew Fisher; Chris Oates; Catherine Powell; Aretha Teckentrup",
        "abstract": "Bayesian cubature (BC) is a popular inferential perspective on the cubature of expensive integrands, wherein the integrand is emulated using a stochastic process model. Several approaches have been put forward to encode sequential adaptation (i.e. dependence on previous integrand evaluations) into this framework. However, these proposals have been limited to either estimating the parameters of a stationary covariance model or focusing computational resources on regions where large values are taken by the integrand. In contrast, many classical adaptive cubature methods are locally adaptive in the sense that they focus computational resources on spatial regions in which local error estimates are largest. The main contributions of this work are twofold; first we establish that existing BC methods do not possess local adaptivity in the sense of many classical adaptive methods and secondly, we developed a novel BC method whose behaviour, demonstrated empirically, is analogous to such methods. Finally we present evidence that the novel method provides improved cubature performance, relative to standard BC, in a detailed empirical assessment.",
        "bibtex": "@InProceedings{pmlr-v108-fisher20a,\n  title = \t {A Locally Adaptive Bayesian Cubature Method},\n  author =       {Fisher, Matthew and Oates, Chris and Powell, Catherine and Teckentrup, Aretha},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1265--1275},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fisher20a/fisher20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fisher20a.html},\n  abstract = \t {Bayesian cubature (BC) is a popular inferential perspective on the cubature of expensive integrands, wherein the integrand is emulated using a stochastic process model. Several approaches have been put forward to encode sequential adaptation (i.e. dependence on previous integrand evaluations) into this framework. However, these proposals have been limited to either estimating the parameters of a stationary covariance model or focusing computational resources on regions where large values are taken by the integrand. In contrast, many classical adaptive cubature methods are locally adaptive in the sense that they focus computational resources on spatial regions in which local error estimates are largest. The main contributions of this work are twofold; first we establish that existing BC methods do not possess local adaptivity in the sense of many classical adaptive methods and secondly, we developed a novel BC method whose behaviour, demonstrated empirically, is analogous to such methods. Finally we present evidence that the novel method provides improved cubature performance, relative to standard BC, in a detailed empirical assessment. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/fisher20a/fisher20a.pdf",
        "supp": "",
        "pdf_size": 1159833,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8002989462746393788&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7e170fd6fa",
        "title": "A Lyapunov analysis for accelerated gradient methods: from deterministic to stochastic case",
        "site": "https://proceedings.mlr.press/v108/laborde20a.html",
        "author": "Maxime Laborde; Adam Oberman",
        "abstract": "Recent work by Su, Boyd and Candes made a connection between Nesterov\u2019s accelerated gradient descent method and an ordinary differential equation (ODE). We show that this connection can be extended to the case of stochastic gradients, and develop Lyapunov function based convergence rates proof for Nesterov\u2019s accelerated stochastic gradient descent. In the gradient case, we show Nesterov\u2019s method arises as a straightforward discretization of a modified ODE. Established Lyapunov analysis is used to recover the accelerated rates of convergence in both continuous and discrete time. Moreover, the Lyapunov analysis can be extended to the case of stochastic gradients. The result is a unified approach to accelerationin both continuous and discrete time, and in for both stochastic and full gradients.",
        "bibtex": "@InProceedings{pmlr-v108-laborde20a,\n  title = \t {A Lyapunov analysis for accelerated gradient methods: from deterministic to stochastic case},\n  author =       {Laborde, Maxime and Oberman, Adam},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {602--612},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/laborde20a/laborde20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/laborde20a.html},\n  abstract = \t {Recent work by Su, Boyd and Candes made a connection between Nesterov\u2019s accelerated gradient descent method and an ordinary differential equation (ODE). We show that this connection can be extended to the case of stochastic gradients, and develop Lyapunov function based convergence rates proof for Nesterov\u2019s accelerated stochastic gradient descent. In the gradient case, we show Nesterov\u2019s method arises as a straightforward discretization of a modified ODE. Established Lyapunov analysis is used to recover the accelerated rates of convergence in both continuous and discrete time. Moreover, the Lyapunov analysis can be extended to the case of stochastic gradients. The result is a unified approach to accelerationin both continuous and discrete time, and in for both stochastic and full gradients.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/laborde20a/laborde20a.pdf",
        "supp": "",
        "pdf_size": 389476,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3009036592684596814&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "McGill University; McGill University",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "7a1e32c8f9",
        "title": "A Multiclass Classification Approach to Label Ranking",
        "site": "https://proceedings.mlr.press/v108/vogel20a.html",
        "author": "Robin Vogel; St\u00e9phan Cl\u00e9men\\con",
        "abstract": "In multiclass classification, the goal is to learn how to predict a random label $Y$, valued in $\\mathcal{Y}=\\{1,; \\ldots,;{K} \\}$ with $K\\geq 3$, based upon observing a r.v. $X$, taking its values in $\\mathbb{R}^q$ with $q\\geq 1$ say, by means of a classification rule $g:\\mathbb{R}^q\\to \\mathcal{Y}$ with minimum probability of error $\\mathbb{P}\\{Yeq g(X) \\}$. However, in a wide variety of situations, the task targeted may be more ambitious, consisting in sorting all the possible label values $y$ that may be assigned to $X$ by decreasing order of the posterior probability $\\eta_y(X)=\\mathbb{P}\\{Y=y \\mid X \\}$. This article is devoted to the analysis of this statistical learning problem, halfway between multiclass classification and posterior probability estimation (regression) and referred to as \\textit{label ranking} here. We highlight the fact that it can be viewed as a specific variant of \\textit{ranking median regression} (RMR), where, rather than observing a random permutation $\\Sigma$ assigned to the input vector $X$ and drawn from a Bradley-Terry-Luce-Plackett model with conditional preference vector $(\\eta_1(X),; \\ldots,; \\eta_K(X))$, the sole information available for training a label ranking rule is the label $Y$ ranked on top, namely $\\Sigma^{-1}(1)$. Inspired by recent results in RMR, we prove that under appropriate noise conditions, the One-Versus-One (OVO) approach to multiclassification yields, as a by-product, an optimal ranking of the labels with overwhelming probability. Beyond theoretical guarantees, the relevance of the approach to label ranking promoted in this article is supported by experimental results.",
        "bibtex": "@InProceedings{pmlr-v108-vogel20a,\n  title = \t {A Multiclass Classification Approach to Label Ranking},\n  author =       {Vogel, Robin and Cl\\'emen{\\c}on, St\\'ephan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1421--1430},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/vogel20a/vogel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/vogel20a.html},\n  abstract = \t {In multiclass classification, the goal is to learn how to predict a random label $Y$, valued in $\\mathcal{Y}=\\{1,; \\ldots,;{K} \\}$ with $K\\geq 3$, based upon observing a r.v. $X$, taking its values in $\\mathbb{R}^q$ with $q\\geq 1$ say, by means of a classification rule $g:\\mathbb{R}^q\\to \\mathcal{Y}$ with minimum probability of error $\\mathbb{P}\\{Yeq g(X) \\}$. However, in a wide variety of situations, the task targeted may be more ambitious, consisting in sorting all the possible label values $y$ that may be assigned to $X$ by decreasing order of the posterior probability $\\eta_y(X)=\\mathbb{P}\\{Y=y \\mid X \\}$. This article is devoted to the analysis of this statistical learning problem, halfway between multiclass classification and posterior probability estimation (regression) and referred to as \\textit{label ranking} here. We highlight the fact that it can be viewed as a specific variant of \\textit{ranking median regression} (RMR), where, rather than observing a random permutation $\\Sigma$ assigned to the input vector $X$ and drawn from a Bradley-Terry-Luce-Plackett model with conditional preference vector $(\\eta_1(X),; \\ldots,; \\eta_K(X))$, the sole information available for training a label ranking rule is the label $Y$ ranked on top, namely $\\Sigma^{-1}(1)$. Inspired by recent results in RMR, we prove that under appropriate noise conditions, the One-Versus-One (OVO) approach to multiclassification yields, as a by-product, an optimal ranking of the labels with overwhelming probability. Beyond theoretical guarantees, the relevance of the approach to label ranking promoted in this article is supported by experimental results.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/vogel20a/vogel20a.pdf",
        "supp": "",
        "pdf_size": 1110574,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4736194143850933197&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "LTCI, T\u00b4 el\u00b4 ecom Paris, Institut Polytechnique de Paris; IDEMIA/LTCI, T\u00b4 el\u00b4 ecom Paris, Institut Polytechnique de Paris",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "T\u00e9l\u00e9com Paris",
        "aff_unique_dep": "LTCI",
        "aff_unique_url": "https://www.telecom-paris.fr",
        "aff_unique_abbr": "T\u00e9l\u00e9com Paris",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "30f6281c44",
        "title": "A Nonparametric Off-Policy Policy Gradient",
        "site": "https://proceedings.mlr.press/v108/tosatto20a.html",
        "author": "Samuele Tosatto; Joao Carvalho; Hany Abdulsamad; Jan Peters",
        "abstract": "Reinforcement learning (RL) algorithms still suffer from high sample complexity despite outstanding recent successes. The need for intensive interactions with the environment is especially observed in many widely popular policy gradient algorithms that perform updates using on-policy samples. The priceof such inefficiency becomes evident in real world scenarios such as interaction-driven robot learning, where the success of RL has been rather limited. We address this issue by building on the general sample efficiency of off-policy algorithms. With nonparametric regression and density estimation methods we construct a nonparametric Bellman equation in a principled manner, which allows us to obtain closed-form estimates of the value function, and to analytically express the full policy gradient. We provide a theoretical analysis of our estimate to show that it is consistent under mild smoothness assumptions and empirically show that our approach has better sample efficiency than state-of-the-art policy gradient methods.",
        "bibtex": "@InProceedings{pmlr-v108-tosatto20a,\n  title = \t {A Nonparametric Off-Policy Policy Gradient},\n  author =       {Tosatto, Samuele and Carvalho, Joao and Abdulsamad, Hany and Peters, Jan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {167--177},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tosatto20a/tosatto20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tosatto20a.html},\n  abstract = \t {Reinforcement learning (RL) algorithms still suffer from high sample complexity despite outstanding recent successes. The need for intensive interactions with the environment is especially observed in many widely popular policy gradient algorithms that perform updates using on-policy samples. The priceof such inefficiency becomes evident in real world scenarios such as interaction-driven robot learning, where the success of RL has been rather limited. We address this issue by building on the general sample efficiency of off-policy algorithms. With nonparametric regression and density estimation methods we construct a nonparametric Bellman equation in a principled manner, which allows us to obtain closed-form estimates of the value function, and to analytically express the full policy gradient. We provide a theoretical analysis of our estimate to show that it is consistent under mild smoothness assumptions and empirically show that our approach has better sample efficiency than state-of-the-art policy gradient methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tosatto20a/tosatto20a.pdf",
        "supp": "",
        "pdf_size": 1694258,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17338857243520054747&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Technische Universit\u00a8 at Darmstadt; Technische Universit\u00a8 at Darmstadt; Technische Universit\u00a8 at Darmstadt; Technische Universit\u00a8 at Darmstadt + Max Planck Institute for Intelligent Systems",
        "aff_domain": "ias.tu-darmstadt.de;ias.tu-darmstadt.de;ias.tu-darmstadt.de;ias.tu-darmstadt.de",
        "email": "ias.tu-darmstadt.de;ias.tu-darmstadt.de;ias.tu-darmstadt.de;ias.tu-darmstadt.de",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0+1",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";Intelligent Systems",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "TUD;MPI-IS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "f568b0b1c7",
        "title": "A Novel Confidence-Based Algorithm for Structured Bandits",
        "site": "https://proceedings.mlr.press/v108/tirinzoni20a.html",
        "author": "Andrea Tirinzoni; Alessandro Lazaric; Marcello Restelli",
        "abstract": "We study finite-armed stochastic bandits where the rewards of each arm might be correlated to those of other arms. We introduce a novel phased algorithm that exploits the given structure to build confidence sets over the parameters of the true bandit problem and rapidly discard all sub-optimal arms. In particular, unlike standard bandit algorithms with no structure, we show that the number of times a suboptimal arm is selected may actually be reduced thanks to the information collected by pulling other arms. Furthermore, we show that, in some structures, the regret of an anytime extension of our algorithm is uniformly bounded over time. For these constant-regret structures, we also derive a matching lower bound. Finally, we demonstrate numerically that our approach better exploits certain structures than existing methods.",
        "bibtex": "@InProceedings{pmlr-v108-tirinzoni20a,\n  title = \t {A Novel Confidence-Based Algorithm for Structured Bandits},\n  author =       {Tirinzoni, Andrea and Lazaric, Alessandro and Restelli, Marcello},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3175--3185},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tirinzoni20a/tirinzoni20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tirinzoni20a.html},\n  abstract = \t {We study finite-armed stochastic bandits where the rewards of each arm might be correlated to those of other arms. We introduce a novel phased algorithm that exploits the given structure to build confidence sets over the parameters of the true bandit problem and rapidly discard all sub-optimal arms. In particular, unlike standard bandit algorithms with no structure, we show that the number of times a suboptimal arm is selected may actually be reduced thanks to the information collected by pulling other arms. Furthermore, we show that, in some structures, the regret of an anytime extension of our algorithm is uniformly bounded over time. For these constant-regret structures, we also derive a matching lower bound. Finally, we demonstrate numerically that our approach better exploits certain structures than existing methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tirinzoni20a/tirinzoni20a.pdf",
        "supp": "",
        "pdf_size": 472439,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15261200577786641909&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a0183bb284",
        "title": "A PTAS for the Bayesian Thresholding Bandit Problem",
        "site": "https://proceedings.mlr.press/v108/peng20a.html",
        "author": "Jian Peng; Yue Qin; Yadi Wei; Yuan Zhou",
        "abstract": "In this paper, we study the Bayesian thresholding bandit problem (BTBP), where the goal is to adaptively make a budget of $Q$ queries to $n$ stochastic arms and determine the label for each arm (whether its mean reward is closer to $0$ or $1$). We present a polynomial-time approximation scheme for the BTBP with runtime $O(f(\\epsilon) + Q)$ that achieves expected labeling accuracy at least $(\\opt(Q) - \\epsilon)$, where $f(\\cdot)$ is a function that only depends on $\\epsilon$ and $\\opt(Q)$ is the optimal expected accuracy achieved by any algorithm. For any fixed $\\epsilon > 0$, our algorithm runs in time linear with $Q$. The main algorithmic ideas we use include discretization employed in the PTASs for many dynamic programming algorithms (such as Knapsack), as well as many problem specific techniques such as proving an upper bound on the number of query numbers for any arm made by an almost optimal policy, and establishing the smoothness property of the $\\opt(\\cdot)$ curve, etc.",
        "bibtex": "@InProceedings{pmlr-v108-peng20a,\n  title = \t {A PTAS for the Bayesian Thresholding Bandit Problem},\n  author =       {Peng, Jian and Qin, Yue and Wei, Yadi and Zhou, Yuan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2455--2464},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/qin20a/qin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/peng20a.html},\n  abstract = \t {In this paper, we study the Bayesian thresholding bandit problem (BTBP), where the goal is to adaptively make a budget of $Q$ queries to $n$ stochastic arms and determine the label for each arm (whether its mean reward is closer to $0$ or $1$). We present a polynomial-time approximation scheme for the BTBP with runtime $O(f(\\epsilon) + Q)$ that achieves expected labeling accuracy at least $(\\opt(Q) - \\epsilon)$, where $f(\\cdot)$ is a function that only depends on $\\epsilon$ and $\\opt(Q)$ is the optimal expected accuracy achieved by any algorithm. For any fixed $\\epsilon > 0$, our algorithm runs in time linear with $Q$. The main algorithmic ideas we use include discretization employed in the PTASs for many dynamic programming algorithms (such as Knapsack), as well as many problem specific techniques such as proving an upper bound on the number of query numbers for any arm made by an almost optimal policy, and establishing the smoothness property of the $\\opt(\\cdot)$ curve, etc.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/qin20a/qin20a.pdf",
        "supp": "",
        "pdf_size": 0,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:je-zakDLjIcJ:scholar.google.com/&scioq=A+PTAS+for+the+Bayesian+Thresholding+Bandit+Problem&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a8b8f5edf8",
        "title": "A Practical Algorithm for Multiplayer Bandits when Arm Means Vary Among Players",
        "site": "https://proceedings.mlr.press/v108/mehrabian20a.html",
        "author": "Abbas Mehrabian; Etienne Boursier; Emilie Kaufmann; Vianney Perchet",
        "abstract": "We study a multiplayer stochastic multi-armed bandit problem in which players cannot communicate, and if two or more players pull the same arm, a collision occurs and the involved players receive zero reward. We consider the challenging heterogeneous setting, in which different arms may have different means for different players, and propose a new and efficient algorithm that combines the idea of leveraging forced collisions for implicit communication and that of performing matching eliminations. We present a finite-time analysis of our algorithm, giving the first sublinear minimax regret bound for this problem, and prove that if the optimal assignment of players to arms is unique, our algorithm attains the optimal O(ln(T)) regret, solving an open question raised at NeurIPS 2018 by Bistritz and Leshem (2018).",
        "bibtex": "@InProceedings{pmlr-v108-mehrabian20a,\n  title = \t {A Practical Algorithm for Multiplayer Bandits when Arm Means Vary Among Players},\n  author =       {Mehrabian, Abbas and Boursier, Etienne and Kaufmann, Emilie and Perchet, Vianney},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1211--1221},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mehrabian20a/mehrabian20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mehrabian20a.html},\n  abstract = \t {We study a multiplayer stochastic multi-armed bandit problem in which players cannot communicate, and if two or more players pull the same arm, a collision occurs and the involved players receive zero reward. We consider the challenging heterogeneous setting, in which different arms may have different means for different players, and propose a new and efficient algorithm that combines the idea of leveraging forced collisions for implicit communication and that of performing matching eliminations. We present a finite-time analysis of our algorithm, giving the first sublinear minimax regret bound for this problem, and prove that if the optimal assignment of players to arms is unique, our algorithm attains the optimal O(ln(T)) regret, solving an open question raised at NeurIPS 2018 by Bistritz and Leshem (2018).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mehrabian20a/mehrabian20a.pdf",
        "supp": "",
        "pdf_size": 439917,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3275430885505187300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Universit \u00b4e Paris-Saclay, ENS Paris-Saclay + CNRS, Centre Borelli, Cachan, France; Univ. Lille, CNRS, Inria SequeL, UMR 9189 - CRIStAL, Lille, France; McGill University, Montr \u00b4eal, Canada; CREST, ENSAE Paris, Palaiseau, France + Criteo AI Lab, Paris, France",
        "aff_domain": "ens-paris-saclay.fr;univ-lille.fr;gmail.com;normalesup.org",
        "email": "ens-paris-saclay.fr;univ-lille.fr;gmail.com;normalesup.org",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;3;4+5",
        "aff_unique_norm": "Universit\u00e9 Paris-Saclay;CNRS;University of Lille;McGill University;CREST;Criteo",
        "aff_unique_dep": "ENS Paris-Saclay;Centre Borelli;Inria SequeL, UMR 9189 - CRIStAL;;;Criteo AI Lab",
        "aff_unique_url": "https://www.universite-paris-saclay.fr;https://www.cnrs.fr;https://www.univ-lille.fr;https://www.mcgill.ca;;https://www.criteo.com",
        "aff_unique_abbr": "UPS;CNRS;Univ. Lille;McGill;;Criteo",
        "aff_campus_unique_index": "0+1;2;3;4+5",
        "aff_campus_unique": "Paris-Saclay;Cachan;Lille;Montr\u00e9al;Palaiseau;Paris",
        "aff_country_unique_index": "0+0;0;1;0+0",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "55fb783c61",
        "title": "A Primal-Dual Solver for Large-Scale Tracking-by-Assignment",
        "site": "https://proceedings.mlr.press/v108/haller20a.html",
        "author": "Stefan Haller; Mangal Prakash; Lisa Hutschenreiter; Tobias Pietzsch; Carsten Rother; Florian Jug; Paul Swoboda; Bogdan Savchynskyy",
        "abstract": "We propose a fast approximate solver for the combinatorial problem known as tracking-by-assignment, which we apply to cell tracking. The latter plays a key role in discovery in many life sciences, especially in cell and developmental biology. So far, in the most general setting this problem was addressed by off-the-shelf solvers like Gurobi, whose run time and memory requirements rapidly grow with the size of the input. In contrast, for our method this growth is nearly linear. Our contribution consists of a new (1) decomposable compact representation of the problem; (2) dual block-coordinate ascent method for optimizing the decomposition-based dual; and (3) primal heuristics that reconstructs a feasible integer solution based on the dual information. Compared to solving the problem with Gurobi, we observe an up to 60 times speed-up, while reducing the memory footprint significantly. We demonstrate the efficacy of our method on real-world tracking problems.",
        "bibtex": "@InProceedings{pmlr-v108-haller20a,\n  title = \t {A Primal-Dual Solver for Large-Scale Tracking-by-Assignment},\n  author =       {Haller, Stefan and Prakash, Mangal and Hutschenreiter, Lisa and Pietzsch, Tobias and Rother, Carsten and Jug, Florian and Swoboda, Paul and Savchynskyy, Bogdan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2539--2549},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/haller20a/haller20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/haller20a.html},\n  abstract = \t {We propose a fast approximate solver for the combinatorial problem known as tracking-by-assignment, which we apply to cell tracking. The latter plays a key role in discovery in many life sciences, especially in cell and developmental biology. So far, in the most general setting this problem was addressed by off-the-shelf solvers like Gurobi, whose run time and memory requirements rapidly grow with the size of the input. In contrast, for our method this growth is nearly linear. Our contribution consists of a new (1) decomposable compact representation of the problem; (2) dual block-coordinate ascent method for optimizing the decomposition-based dual; and (3) primal heuristics that reconstructs a feasible integer solution based on the dual information. Compared to solving the problem with Gurobi, we observe an up to 60 times speed-up, while reducing the memory footprint significantly. We demonstrate the efficacy of our method on real-world tracking problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/haller20a/haller20a.pdf",
        "supp": "",
        "pdf_size": 516716,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=816914828657443179&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b2b6ce80ba",
        "title": "A Reduction from Reinforcement Learning to No-Regret Online Learning",
        "site": "https://proceedings.mlr.press/v108/cheng20b.html",
        "author": "Ching-An Cheng; Remi Tachet Combes; Byron Boots; Geoff Gordon",
        "abstract": "We present a reduction from reinforcement learning (RL) to no-regret online learning based on the saddle-point formulation of RL, by which \"any\" online algorithm with sublinear regret can generate policies with provable performance guarantees. This new perspective decouples the RL problem into two parts: regret minimization and function approximation. The first part admits a standard online-learning analysis, and the second part can be quantified independently of the learning algorithm. Therefore, the proposed reduction can be used as a tool to systematically design new RL algorithms. We demonstrate this idea by devising a simple RL algorithm based on mirror descent and the generative-model oracle. For any $\\gamma$-discounted tabular RL problem, with probability at least $1-\\delta$, it learns an $\\epsilon$-optimal policy using at most $\\tilde{O}\\left(\\frac{|\\SS||\u00c5|\\log(\\frac{1}{\\delta})}{(1-\\gamma)^4\\epsilon^2}\\right)$ samples. Furthermore, this algorithm admits a direct extension to linearly parameterized function approximators for large-scale applications, with computation and sample complexities independent of $|\\SS|$,$|\u00c5|$, though at the cost of potential approximation bias.",
        "bibtex": "@InProceedings{pmlr-v108-cheng20b,\n  title = \t {A Reduction from Reinforcement Learning to No-Regret Online Learning},\n  author =       {Cheng, Ching-An and des Combes, Remi Tachet and Boots, Byron and Gordon, Geoff},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3514--3524},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cheng20b/cheng20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cheng20b.html},\n  abstract = \t {We present a reduction from reinforcement learning (RL) to no-regret online learning based on the saddle-point formulation of RL, by which \"any\" online algorithm with sublinear regret can generate policies with provable performance guarantees. This new perspective decouples the RL problem into two parts: regret minimization and function approximation. The first part admits a standard online-learning analysis, and the second part can be quantified independently of the learning algorithm. Therefore, the proposed reduction can be used as a tool to systematically design new RL algorithms. We demonstrate this idea by devising a simple RL algorithm based on mirror descent and the generative-model oracle. For any $\\gamma$-discounted tabular RL problem, with probability at least $1-\\delta$, it learns an $\\epsilon$-optimal policy using at most $\\tilde{O}\\left(\\frac{|\\SS||\u00c5|\\log(\\frac{1}{\\delta})}{(1-\\gamma)^4\\epsilon^2}\\right)$ samples. Furthermore, this algorithm admits a direct extension to linearly parameterized function approximators for large-scale applications, with computation and sample complexities independent of $|\\SS|$,$|\u00c5|$, though at the cost of potential approximation bias.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cheng20b/cheng20b.pdf",
        "supp": "",
        "pdf_size": 662450,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3653820139711515773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2a84c40408",
        "title": "A Robust Univariate Mean Estimator is All You Need",
        "site": "https://proceedings.mlr.press/v108/prasad20a.html",
        "author": "Adarsh Prasad; Sivaraman Balakrishnan; Pradeep Ravikumar",
        "abstract": "We study the problem of designing estimators when the data has heavy-tails and is corrupted by outliers. In such an adversarial setup, we aim to design statistically optimal estimators for flexible non-parametric distribution classes such as distributions with bounded-2k moments and symmetric distributions. Our primary workhorse is a conceptually simple reduction from multivariate estimation to univariate estimation. Using this reduction, we design estimators which are optimal in both heavy-tailed and contaminated settings. Our estimators achieve an optimal dimension independent bias in the contaminated setting, while also simultaneously achieving high-probability error guarantees with optimal sample complexity. These results provide some of the first such estimators for a broad range of problems including Mean Estimation, Sparse Mean Estimation, Covariance Estimation, Sparse Covariance Estimation and Sparse PCA.",
        "bibtex": "@InProceedings{pmlr-v108-prasad20a,\n  title = \t {A Robust Univariate Mean Estimator is All You Need},\n  author =       {Prasad, Adarsh and Balakrishnan, Sivaraman and Ravikumar, Pradeep},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4034--4044},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/prasad20a/prasad20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/prasad20a.html},\n  abstract = \t {We study the problem of designing estimators when the data has heavy-tails and is corrupted by outliers. In such an adversarial setup, we aim to design statistically optimal estimators for flexible non-parametric distribution classes such as distributions with bounded-2k moments and symmetric distributions. Our primary workhorse is a conceptually simple reduction from multivariate estimation to univariate estimation. Using this reduction, we design estimators which are optimal in both heavy-tailed and contaminated settings. Our estimators achieve an optimal dimension independent bias in the contaminated setting, while also simultaneously achieving high-probability error guarantees with optimal sample complexity. These results provide some of the first such estimators for a broad range of problems including Mean Estimation, Sparse Mean Estimation, Covariance Estimation, Sparse Covariance Estimation and Sparse PCA.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/prasad20a/prasad20a.pdf",
        "supp": "",
        "pdf_size": 525649,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13616459583670782369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Machine Learning Department\u2021; Department of Statistics and Data Science\u2020; Machine Learning Department\u2021",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University;",
        "aff_unique_dep": "Machine Learning Department;",
        "aff_unique_url": "https://www.cs.cmu.edu/ml;",
        "aff_unique_abbr": "CMU ML;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "2258124243",
        "title": "A Rule for Gradient Estimator Selection, with an Application to Variational Inference",
        "site": "https://proceedings.mlr.press/v108/geffner20a.html",
        "author": "Tomas Geffner; Justin Domke",
        "abstract": "Stochastic gradient descent (SGD) is the workhorse of modern machine learning. Sometimes, there are many different potential gradient estimators that can be used. When so, choosing the one with the best tradeoff between cost and variance is important. This paper analyzes the convergence rates of SGD as a function of time, rather than iterations. This results in a simple rule to select the estimator that leads to the best optimization convergence guarantee. This choice is the same for different variants of SGD, and with different assumptions about the objective (e.g. convexity or smoothness). Inspired by this principle, we propose a technique to automatically select an estimator when a finite pool of estimators is given. Then, we extend to infinite pools of estimators, where each one is indexed by control variate weights. Empirically, automatically choosing an estimator performs comparably to the best estimator chosen with hindsight.",
        "bibtex": "@InProceedings{pmlr-v108-geffner20a,\n  title = \t {A Rule for Gradient Estimator Selection, with an Application to Variational Inference},\n  author =       {Geffner, Tomas and Domke, Justin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1803--1812},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/geffner20a/geffner20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/geffner20a.html},\n  abstract = \t {Stochastic gradient descent (SGD) is the workhorse of modern machine learning. Sometimes, there are many different potential gradient estimators that can be used. When so, choosing the one with the best tradeoff between cost and variance is important. This paper analyzes the convergence rates of SGD as a function of time, rather than iterations. This results in a simple rule to select the estimator that leads to the best optimization convergence guarantee. This choice is the same for different variants of SGD, and with different assumptions about the objective (e.g. convexity or smoothness). Inspired by this principle, we propose a technique to automatically select an estimator when a finite pool of estimators is given. Then, we extend to infinite pools of estimators, where each one is indexed by control variate weights. Empirically, automatically choosing an estimator performs comparably to the best estimator chosen with hindsight.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/geffner20a/geffner20a.pdf",
        "supp": "",
        "pdf_size": 1239664,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17511644172969851540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Massachusetts, Amherst; University of Massachusetts, Amherst",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2d92b69c0b",
        "title": "A Simple Approach for Non-stationary Linear Bandits",
        "site": "https://proceedings.mlr.press/v108/zhao20a.html",
        "author": "Peng Zhao; Lijun Zhang; Yuan Jiang; Zhi-Hua Zhou",
        "abstract": "This paper investigates the problem of non-stationary linear bandits, where the unknown regression parameter is evolving over time. Previous studies have adopted sophisticated mechanisms, such as sliding window or weighted penalty to achieve near-optimal dynamic regret. In this paper, we demonstrate that a simple restarted strategy is sufficient to attain the same regret guarantee. Specifically, we design an UCB-type algorithm to balance exploitation and exploration, and restart it periodically to handle the drift of unknown parameters. Let $T$ be the time horizon, $d$ be the dimension, and $P_T$ be the path-length that measures the fluctuation of the evolving unknown parameter, our approach enjoys an $\\tilde{O}(d^{2/3}(1+P_T)^{1/3}T^{2/3})$ dynamic regret, which is nearly optimal, matching the $\\Omega(d^{2/3}(1+P_T)^{1/3}T^{2/3})$ minimax lower bound up to logarithmic factors. Empirical studies also validate the efficacy of our approach.",
        "bibtex": "@InProceedings{pmlr-v108-zhao20a,\n  title = \t {A Simple Approach for Non-stationary Linear Bandits},\n  author =       {Zhao, Peng and Zhang, Lijun and Jiang, Yuan and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {746--755},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhao20a/zhao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhao20a.html},\n  abstract = \t {This paper investigates the problem of non-stationary linear bandits, where the unknown regression parameter is evolving over time. Previous studies have adopted sophisticated mechanisms, such as sliding window or weighted penalty to achieve near-optimal dynamic regret. In this paper, we demonstrate that a simple restarted strategy is sufficient to attain the same regret guarantee. Specifically, we design an UCB-type algorithm to balance exploitation and exploration, and restart it periodically to handle the drift of unknown parameters. Let $T$ be the time horizon, $d$ be the dimension, and $P_T$ be the path-length that measures the fluctuation of the evolving unknown parameter, our approach enjoys an $\\tilde{O}(d^{2/3}(1+P_T)^{1/3}T^{2/3})$ dynamic regret, which is nearly optimal, matching the $\\Omega(d^{2/3}(1+P_T)^{1/3}T^{2/3})$ minimax lower bound up to logarithmic factors. Empirical studies also validate the efficacy of our approach. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhao20a/zhao20a.pdf",
        "supp": "",
        "pdf_size": 384465,
        "gs_citation": 109,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10516231783544705805&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "aff_domain": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "email": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "4a98e08c1c",
        "title": "A Stein Goodness-of-fit Test for Directional Distributions",
        "site": "https://proceedings.mlr.press/v108/xu20a.html",
        "author": "Wenkai Xu; Takeru Matsuda",
        "abstract": "In many fields, data appears in the form of direction (unit vector) and usual statistical procedures are not applicable to such directional data. In this study, we propose nonparametric goodness-of-fit testing procedures for general directional distributions based on kernel Stein discrepancy. Our method is based on Stein\u2019s operator on spheres, which is derived by using Stokes\u2019 theorem. Notably, the proposed method is applicable to distributions with an intractable normalization constant, which commonly appear in directional statistics. Experimental results demonstrate that the proposed methods control type-I error well and have larger power than existing tests, including the test based on the maximum mean discrepancy.",
        "bibtex": "@InProceedings{pmlr-v108-xu20a,\n  title = \t {A Stein Goodness-of-fit Test for Directional Distributions},\n  author =       {Xu, Wenkai and Matsuda, Takeru},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {320--330},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/xu20a/xu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/xu20a.html},\n  abstract = \t {In many fields, data appears in the form of direction (unit vector) and usual statistical procedures are not applicable to such directional data. In this study, we propose nonparametric goodness-of-fit testing procedures for general directional distributions based on kernel Stein discrepancy. Our method is based on Stein\u2019s operator on spheres, which is derived by using Stokes\u2019 theorem. Notably, the proposed method is applicable to distributions with an intractable normalization constant, which commonly appear in directional statistics. Experimental results demonstrate that the proposed methods control type-I error well and have larger power than existing tests, including the test based on the maximum mean discrepancy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/xu20a/xu20a.pdf",
        "supp": "",
        "pdf_size": 1236705,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15781858677311082736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Gatsby Computational Neuroscience Unit; RIKEN Center for Brain Science",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University College London;RIKEN",
        "aff_unique_dep": "Gatsby Computational Neuroscience Unit;Center for Brain Science",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.riken.jp/en/",
        "aff_unique_abbr": "UCL;RIKEN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Kingdom;Japan"
    },
    {
        "id": "c0c27760ba",
        "title": "A Theoretical Case Study of Structured Variational Inference for Community Detection",
        "site": "https://proceedings.mlr.press/v108/yin20a.html",
        "author": "Mingzhang Yin; Y. X. Rachel Wang; Purnamrita Sarkar",
        "abstract": "Mean-field variational inference (MFVI) has been widely applied in large scale Bayesian inference. However, MFVI assumes independent distribution on the latent variables, which often leads to objective functions with many local optima, making optimization algorithms sensitive to initialization. In this paper, we study the advantage of  structured variational inference in the context of the two-class Stochastic Blockmodel. To facilitate theoretical analysis, the variational distribution is constructed to have a simple pairwise dependency structure on the nodes of the network.  We prove that, in a broad density regime and for general random initializations, unlike MFVI,  the estimated class labels by structured VI converge to the ground truth with high probability, when the model parameters are known, estimated within a reasonable range or jointly optimized with the variational parameters. In addition, empirically we demonstrate structured VI is more robust compared with MFVI when the graph is sparse and the signal to noise ratio is low. The paper takes a first step towards understanding the importance of dependency structure in variational inference for community detection.",
        "bibtex": "@InProceedings{pmlr-v108-yin20a,\n  title = \t {A Theoretical Case Study of Structured Variational Inference for Community Detection},\n  author =       {Yin, Mingzhang and Wang, Y. X. Rachel and Sarkar, Purnamrita},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3750--3761},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yin20a/yin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yin20a.html},\n  abstract = \t {Mean-field variational inference (MFVI) has been widely applied in large scale Bayesian inference. However, MFVI assumes independent distribution on the latent variables, which often leads to objective functions with many local optima, making optimization algorithms sensitive to initialization. In this paper, we study the advantage of  structured variational inference in the context of the two-class Stochastic Blockmodel. To facilitate theoretical analysis, the variational distribution is constructed to have a simple pairwise dependency structure on the nodes of the network.  We prove that, in a broad density regime and for general random initializations, unlike MFVI,  the estimated class labels by structured VI converge to the ground truth with high probability, when the model parameters are known, estimated within a reasonable range or jointly optimized with the variational parameters. In addition, empirically we demonstrate structured VI is more robust compared with MFVI when the graph is sparse and the signal to noise ratio is low. The paper takes a first step towards understanding the importance of dependency structure in variational inference for community detection.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yin20a/yin20a.pdf",
        "supp": "",
        "pdf_size": 1553184,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=870648436158009158&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "498e4b69d0",
        "title": "A Theoretical and Practical Framework for Regression and Classification from Truncated Samples",
        "site": "https://proceedings.mlr.press/v108/ilyas20a.html",
        "author": "Andrew Ilyas; Emmanouil Zampetakis; Constantinos Daskalakis",
        "abstract": "Machine learning and statistics are invaluable for extracting insights from data. A key assumption of most methods, however, is that they have access to independent samples from the distribution of relevant data. As such, these methods often perform poorly in the face of {\\em biased data} which breaks this assumption. In this work, we consider the classical challenge of bias due to truncation, wherein samples falling outside of an \u201cobservation window\u201d cannot be observed. We present a general framework for regression and classification from  samples that are truncated according to the value of the dependent variable. The framework argues that stochastic gradient descent (SGD) can be efficiently executed on the population log-likelihood of the truncated sample. Our framework is  broadly applicable, and we provide end-to-end guarantees for the well-studied problems of truncated logistic and probit regression, where we argue that the true model parameters can be identified computationally and statistically efficiently from truncated data, extending recent work on truncated linear regression. We also provide experiments to illustrate the practicality of our framework on synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v108-ilyas20a,\n  title = \t {A Theoretical and Practical Framework for Regression and Classification from Truncated Samples},\n  author =       {Ilyas, Andrew and Zampetakis, Emmanouil and Daskalakis, Constantinos},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4463--4473},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ilyas20a/ilyas20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ilyas20a.html},\n  abstract = \t {Machine learning and statistics are invaluable for extracting insights from data. A key assumption of most methods, however, is that they have access to independent samples from the distribution of relevant data. As such, these methods often perform poorly in the face of {\\em biased data} which breaks this assumption. In this work, we consider the classical challenge of bias due to truncation, wherein samples falling outside of an \u201cobservation window\u201d cannot be observed. We present a general framework for regression and classification from  samples that are truncated according to the value of the dependent variable. The framework argues that stochastic gradient descent (SGD) can be efficiently executed on the population log-likelihood of the truncated sample. Our framework is  broadly applicable, and we provide end-to-end guarantees for the well-studied problems of truncated logistic and probit regression, where we argue that the true model parameters can be identified computationally and statistically efficiently from truncated data, extending recent work on truncated linear regression. We also provide experiments to illustrate the practicality of our framework on synthetic and real data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ilyas20a/ilyas20a.pdf",
        "supp": "",
        "pdf_size": 661040,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5108640687528130607&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7c70dfd28f",
        "title": "A Three Sample Hypothesis Test for Evaluating Generative Models",
        "site": "https://proceedings.mlr.press/v108/meehan20a.html",
        "author": "Casey Meehan; Kamalika Chaudhuri; Sanjoy Dasgupta",
        "abstract": "Detecting overfitting in generative models is an important challenge in machine learning. In this work, we formalize a form of overfitting that we call {\\em{data-copying}} \u2013 where the generative model memorizes and outputs training samples or small variations thereof. We provide a three sample test for detecting data-copying that uses the training set, a separate sample from the target distribution, and a generated sample from the model, and study the performance of our test on several canonical models and datasets.",
        "bibtex": "@InProceedings{pmlr-v108-meehan20a,\n  title = \t {A Three Sample Hypothesis Test for Evaluating Generative Models},\n  author =       {Meehan, Casey and Chaudhuri, Kamalika and Dasgupta, Sanjoy},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3546--3556},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/meehan20a/meehan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/meehan20a.html},\n  abstract = \t {Detecting overfitting in generative models is an important challenge in machine learning. In this work, we formalize a form of overfitting that we call {\\em{data-copying}} \u2013 where the generative model memorizes and outputs training samples or small variations thereof. We provide a three sample test for detecting data-copying that uses the training set, a separate sample from the target distribution, and a generated sample from the model, and study the performance of our test on several canonical models and datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/meehan20a/meehan20a.pdf",
        "supp": "",
        "pdf_size": 3597247,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13743840833740258304&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "25dc44e285",
        "title": "A Tight and Unified Analysis of Gradient-Based Methods for a Whole Spectrum of Differentiable Games",
        "site": "https://proceedings.mlr.press/v108/azizian20b.html",
        "author": "Wa\u00efss Azizian; Ioannis Mitliagkas; Simon Lacoste-Julien; Gauthier Gidel",
        "abstract": "We consider differentiable games where the goal is to find a Nash equilibrium. The machine learning community has recently started using variants of the gradient method (GD). Prime examples are extragradient (EG), the optimistic gradient method (OG) and consensus optimization (CO) which enjoy linear convergence in cases like bilinear games, where the standard GD fails. The full benefits of theses relatively new methods are not known as there is no unified analysis for both strongly monotone and bilinear games. We provide new analysis of the EG\u2019s local and global convergence properties and use is to get a tighter global convergence rate for OG and CO. Our analysis covers the whole range of settings between bilinear and strongly monotone games. It reveals that these methods converges via different mechanisms at these extremes; in between, it exploits the most favorable mechanism for the given problem. We then prove that EG achieves the optimal rate for a wide class of algorithms with any number of extrapolations. Our tight analysis of EG\u2019s convergence rate in games shows that, unlike in convex minimization, EG may be much faster than GD.",
        "bibtex": "@InProceedings{pmlr-v108-azizian20b,\n  title = \t {A Tight and Unified Analysis of Gradient-Based Methods for a Whole Spectrum of Differentiable Games},\n  author =       {Azizian, Wa\\\"iss and Mitliagkas, Ioannis and Lacoste-Julien, Simon and Gidel, Gauthier},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2863--2873},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/azizian20b/azizian20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/azizian20b.html},\n  abstract = \t {We consider differentiable games where the goal is to find a Nash equilibrium. The machine learning community has recently started using variants of the gradient method (GD). Prime examples are extragradient (EG), the optimistic gradient method (OG) and consensus optimization (CO) which enjoy linear convergence in cases like bilinear games, where the standard GD fails. The full benefits of theses relatively new methods are not known as there is no unified analysis for both strongly monotone and bilinear games. We provide new analysis of the EG\u2019s local and global convergence properties and use is to get a tighter global convergence rate for OG and CO. Our analysis covers the whole range of settings between bilinear and strongly monotone games. It reveals that these methods converges via different mechanisms at these extremes; in between, it exploits the most favorable mechanism for the given problem. We then prove that EG achieves the optimal rate for a wide class of algorithms with any number of extrapolations. Our tight analysis of EG\u2019s convergence rate in games shows that, unlike in convex minimization, EG may be much faster than GD. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/azizian20b/azizian20b.pdf",
        "supp": "",
        "pdf_size": 418561,
        "gs_citation": 117,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14110113363737811793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "\u00b4Ecole Normale Sup\u00b4 erieure, Paris; Mila & DIRO, Universit\u00b4 e de Montr\u00b4 eal; Mila & DIRO, Universit\u00b4 e de Montr\u00b4 eal; Mila & DIRO, Universit\u00b4 e de Montr\u00b4 eal",
        "aff_domain": "ens.fr;mila.quebec;mila.quebec;mila.quebec",
        "email": "ens.fr;mila.quebec;mila.quebec;mila.quebec",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Ecole Normale Sup\u00e9rieure;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": ";Mila & DIRO",
        "aff_unique_url": "https://www.ens.fr;https://www.umontreal.ca",
        "aff_unique_abbr": "ENS;UdeM",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Paris;Montr\u00e9al",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "236a3fb98c",
        "title": "A Topology Layer for Machine Learning",
        "site": "https://proceedings.mlr.press/v108/gabrielsson20a.html",
        "author": "Rickard Br\u00fcel Gabrielsson; Bradley J. Nelson; Anjan Dwaraknath; Primoz Skraba",
        "abstract": "Topology applied to real world data using persistent homology has started to find applications within machine learning, including deep learning. We present a differentiable topology layer that computes persistent homology based on level set filtrations and edge-based filtrations. We present three  novel applications: the topological layer can (i) regularize data reconstruction or the weights of machine learning models, (ii) construct a loss on the output of a deep generative network to incorporate topological priors, and (iii) perform topological adversarial attacks on deep networks trained with persistence features. The code is publicly available and we hope its availability will facilitate the use of persistent homology in deep learning and other gradient based applications.",
        "bibtex": "@InProceedings{pmlr-v108-gabrielsson20a,\n  title = \t {A Topology Layer for Machine Learning},\n  author =       {Gabrielsson, Rickard Br\\\"uel and Nelson, Bradley J. and Dwaraknath, Anjan and Skraba, Primoz},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1553--1563},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gabrielsson20a/gabrielsson20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gabrielsson20a.html},\n  abstract = \t {Topology applied to real world data using persistent homology has started to find applications within machine learning, including deep learning. We present a differentiable topology layer that computes persistent homology based on level set filtrations and edge-based filtrations. We present three  novel applications: the topological layer can (i) regularize data reconstruction or the weights of machine learning models, (ii) construct a loss on the output of a deep generative network to incorporate topological priors, and (iii) perform topological adversarial attacks on deep networks trained with persistence features. The code is publicly available and we hope its availability will facilitate the use of persistent homology in deep learning and other gradient based applications. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/gabrielsson20a/gabrielsson20a.pdf",
        "supp": "",
        "pdf_size": 2324484,
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13292957457599218439&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ce3c0b10f8",
        "title": "A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for Saddle Point Problems: Proximal Point Approach",
        "site": "https://proceedings.mlr.press/v108/mokhtari20a.html",
        "author": "Aryan Mokhtari; Asuman Ozdaglar; Sarath Pattathil",
        "abstract": "In this paper we consider solving saddle point problems using two variants of Gradient Descent-Ascent algorithms, Extra-gradient (EG) and Optimistic Gradient Descent Ascent (OGDA) methods. We show that both of these algorithms admit a unified analysis as approximations of the classical proximal point method for solving saddle point problems. This viewpoint enables us to develop a new framework for analyzing EG and OGDA for bilinear and strongly convex-strongly concave settings. Moreover, we use the proximal point approximation interpretation to generalize the results for OGDA for a wide range of parameters.",
        "bibtex": "@InProceedings{pmlr-v108-mokhtari20a,\n  title = \t {A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for Saddle Point Problems: Proximal Point Approach},\n  author =       {Mokhtari, Aryan and Ozdaglar, Asuman and Pattathil, Sarath},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1497--1507},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mokhtari20a/mokhtari20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mokhtari20a.html},\n  abstract = \t {In this paper we consider solving saddle point problems using two variants of Gradient Descent-Ascent algorithms, Extra-gradient (EG) and Optimistic Gradient Descent Ascent (OGDA) methods. We show that both of these algorithms admit a unified analysis as approximations of the classical proximal point method for solving saddle point problems. This viewpoint enables us to develop a new framework for analyzing EG and OGDA for bilinear and strongly convex-strongly concave settings. Moreover, we use the proximal point approximation interpretation to generalize the results for OGDA for a wide range of parameters. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/mokhtari20a/mokhtari20a.pdf",
        "supp": "",
        "pdf_size": 850493,
        "gs_citation": 405,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13743733931681119629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6955982308",
        "title": "A Unified Statistically Efficient Estimation Framework for Unnormalized Models",
        "site": "https://proceedings.mlr.press/v108/uehara20a.html",
        "author": "Masatoshi Uehara; Takafumi Kanamori; Takashi Takenouchi; Takeru Matsuda",
        "abstract": "The parameter estimation of unnormalized models is a challenging problem. The maximum likelihood estimation (MLE) is computationally infeasible for these models since normalizing constants are not explicitly calculated. Although some consistent estimators have been proposed earlier, the problem of statistical efficiency remains. In this study, we propose a unified, statistically efficient estimation framework for unnormalized models and several efficient estimators, whose asymptotic variance is the same as the MLE. The computational cost of these estimators is also reasonable and they can be employed whether the sample space is discrete or continuous. The loss functions of the proposed estimators are derived by combining the following two methods: (1) density-ratio matching using Bregman divergence, and (2) plugging-in nonparametric estimators. We also analyze the properties of the proposed estimators when the unnormalized models are misspecified. The experimental results demonstrate the advantages of our method over existing approaches.",
        "bibtex": "@InProceedings{pmlr-v108-uehara20a,\n  title = \t {A Unified Statistically Efficient Estimation Framework for Unnormalized Models },\n  author =       {Uehara, Masatoshi and Kanamori, Takafumi and Takenouchi, Takashi and Matsuda, Takeru},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {809--819},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/uehara20a/uehara20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/uehara20a.html},\n  abstract = \t {The parameter estimation of unnormalized models is a challenging problem. The maximum likelihood estimation (MLE) is computationally infeasible for these models since normalizing constants are not explicitly calculated. Although some consistent estimators have been proposed earlier, the problem of statistical efficiency remains. In this study, we propose a unified, statistically efficient estimation framework for unnormalized models and several efficient estimators, whose asymptotic variance is the same as the MLE. The computational cost of these estimators is also reasonable and they can be employed whether the sample space is discrete or continuous. The loss functions of the proposed estimators are derived by combining the following two methods: (1) density-ratio matching using Bregman divergence, and (2) plugging-in nonparametric estimators. We also analyze the properties of the proposed estimators when the unnormalized models are misspecified. The experimental results demonstrate the advantages of our method over existing approaches. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/uehara20a/uehara20a.pdf",
        "supp": "",
        "pdf_size": 335137,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12132839264595146470&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a75ea392bc",
        "title": "A Unified Stochastic Gradient Approach to Designing Bayesian-Optimal Experiments",
        "site": "https://proceedings.mlr.press/v108/foster20a.html",
        "author": "Adam Foster; Martin Jankowiak; Matthew O\u2019Meara; Yee Whye Teh; Tom Rainforth",
        "abstract": "We introduce a fully stochastic gradient based approach to Bayesian optimal experimental design (BOED). Our approach utilizes variational lower bounds on the expected information gain (EIG) of an experiment that can be simultaneously optimized with respect to both the variational and design parameters. This allows the design process to be carried out through a single unified stochastic gradient ascent procedure, in contrast to existing approaches that typically construct a pointwise EIG estimator, before passing this estimator to a separate optimizer. We provide a number of different variational objectives including the novel adaptive contrastive estimation (ACE) bound. Finally, we show that our gradient-based approaches are able to provide effective design optimization in substantially higher dimensional settings than existing approaches.",
        "bibtex": "@InProceedings{pmlr-v108-foster20a,\n  title = \t {A Unified Stochastic Gradient Approach to Designing Bayesian-Optimal Experiments},\n  author =       {Foster, Adam and Jankowiak, Martin and O'Meara, Matthew and Teh, Yee Whye and Rainforth, Tom},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2959--2969},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/foster20a/foster20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/foster20a.html},\n  abstract = \t {We introduce a fully stochastic gradient based approach to Bayesian optimal experimental design (BOED). Our approach utilizes variational lower bounds on the expected information gain (EIG) of an experiment that can be simultaneously optimized with respect to both the variational and design parameters. This allows the design process to be carried out through a single unified stochastic gradient ascent procedure, in contrast to existing approaches that typically construct a pointwise EIG estimator, before passing this estimator to a separate optimizer. We provide a number of different variational objectives including the novel adaptive contrastive estimation (ACE) bound. Finally, we show that our gradient-based approaches are able to provide effective design optimization in substantially higher dimensional settings than existing approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/foster20a/foster20a.pdf",
        "supp": "",
        "pdf_size": 828708,
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8723323429553298991&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics, University of Oxford, Oxford, UK + Christ Church, University of Oxford, Oxford, UK; Uber AI, San Francisco, CA, USA; University of Michigan, Ann Arbor, MI, USA; Department of Statistics, University of Oxford, Oxford, UK + Christ Church, University of Oxford, Oxford, UK; Department of Statistics, University of Oxford, Oxford, UK + Christ Church, University of Oxford, Oxford, UK",
        "aff_domain": "stats.ox.ac.uk; ; ; ; ",
        "email": "stats.ox.ac.uk; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;1;2;0+0;0+0",
        "aff_unique_norm": "University of Oxford;Uber;University of Michigan",
        "aff_unique_dep": "Department of Statistics;Uber AI;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.uber.com;https://www.umich.edu",
        "aff_unique_abbr": "Oxford;Uber;UM",
        "aff_campus_unique_index": "0+0;1;2;0+0;0+0",
        "aff_campus_unique": "Oxford;San Francisco;Ann Arbor",
        "aff_country_unique_index": "0+0;1;1;0+0;0+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9019a37c01",
        "title": "A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent",
        "site": "https://proceedings.mlr.press/v108/gorbunov20a.html",
        "author": "Eduard Gorbunov; Filip Hanzely; Peter Richtarik",
        "abstract": "In this paper we introduce a unified analysis of a large family of variants of proximal stochastic gradient descent (SGD) which so far have required different intuitions, convergence analyses, have different applications, and which have been developed separately in various communities. We show that our framework includes methods with and without the following tricks, and their combinations: variance reduction, importance sampling, mini-batch sampling, quantization, and coordinate sub-sampling.  As a by-product, we obtain the first unified theory of SGD and randomized coordinate descent (RCD) methods,  the first unified theory of variance reduced and non-variance-reduced SGD methods, and the first unified theory of quantized and non-quantized methods. A key to our approach is a parametric assumption on the iterates and stochastic gradients. In a single theorem we establish a linear convergence result under this assumption and strong-quasi convexity of the loss function. Whenever we recover an existing method as a special case, our theorem gives the best known complexity result. Our approach can be  used to motivate the development of new useful methods, and offers pre-proved convergence guarantees. To illustrate the strength of our approach, we develop five new variants of SGD, and through numerical experiments demonstrate some of their properties.",
        "bibtex": "@InProceedings{pmlr-v108-gorbunov20a,\n  title = \t {A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent},\n  author =       {Gorbunov, Eduard and Hanzely, Filip and Richtarik, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {680--690},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gorbunov20a/gorbunov20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gorbunov20a.html},\n  abstract = \t {In this paper we introduce a unified analysis of a large family of variants of proximal stochastic gradient descent (SGD) which so far have required different intuitions, convergence analyses, have different applications, and which have been developed separately in various communities. We show that our framework includes methods with and without the following tricks, and their combinations: variance reduction, importance sampling, mini-batch sampling, quantization, and coordinate sub-sampling.  As a by-product, we obtain the first unified theory of SGD and randomized coordinate descent (RCD) methods,  the first unified theory of variance reduced and non-variance-reduced SGD methods, and the first unified theory of quantized and non-quantized methods. A key to our approach is a parametric assumption on the iterates and stochastic gradients. In a single theorem we establish a linear convergence result under this assumption and strong-quasi convexity of the loss function. Whenever we recover an existing method as a special case, our theorem gives the best known complexity result. Our approach can be  used to motivate the development of new useful methods, and offers pre-proved convergence guarantees. To illustrate the strength of our approach, we develop five new variants of SGD, and through numerical experiments demonstrate some of their properties.  }\n}",
        "pdf": "http://proceedings.mlr.press/v108/gorbunov20a/gorbunov20a.pdf",
        "supp": "",
        "pdf_size": 2677436,
        "gs_citation": 190,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16161729877531961455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "78294a55c0",
        "title": "A Wasserstein Minimum Velocity Approach to Learning Unnormalized Models",
        "site": "https://proceedings.mlr.press/v108/wang20j.html",
        "author": "Ziyu Wang; Shuyu Cheng; Li Yueru; Jun Zhu; Bo Zhang",
        "abstract": "Score matching provides an effective approach to learning flexible unnormalized models, but its scalability is limited by the need to evaluate a second-order derivative. In this paper, we present a scalable approximation to a general family of learning objectives including score matching, by observing a new connection between these objectives and Wasserstein gradient flows. We present applications with promise in learning neural density estimators on manifolds, and training implicit variational and Wasserstein auto-encoders with a manifold-valued prior.",
        "bibtex": "@InProceedings{pmlr-v108-wang20j,\n  title = \t {A Wasserstein Minimum Velocity Approach to Learning Unnormalized Models},\n  author =       {Wang, Ziyu and Cheng, Shuyu and Yueru, Li and Zhu, Jun and Zhang, Bo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3728--3738},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20j/wang20j.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20j.html},\n  abstract = \t {Score matching provides an effective approach to learning flexible unnormalized models, but its scalability is limited by the need to evaluate a second-order derivative. In this paper, we present a scalable approximation to a general family of learning objectives including score matching, by observing a new connection between these objectives and Wasserstein gradient flows. We present applications with promise in learning neural density estimators on manifolds, and training implicit variational and Wasserstein auto-encoders with a manifold-valued prior.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20j/wang20j.pdf",
        "supp": "",
        "pdf_size": 519302,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12447886252168993369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, Institute for AI, THBI Lab, Tsinghua University; Dept. of Comp. Sci. & Tech., BNRist Center, Institute for AI, THBI Lab, Tsinghua University; Dept. of Comp. Sci. & Tech., BNRist Center, Institute for AI, THBI Lab, Tsinghua University; Dept. of Comp. Sci. & Tech., BNRist Center, Institute for AI, THBI Lab, Tsinghua University; Dept. of Comp. Sci. & Tech., BNRist Center, Institute for AI, THBI Lab, Tsinghua University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Dept. of Comp. Sci. & Tech.",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "bf9089d7a0",
        "title": "A nonasymptotic law of iterated logarithm for general M-estimators",
        "site": "https://proceedings.mlr.press/v108/dalalyan20a.html",
        "author": "Nicolas Schreuder; Victor-Emmanuel Brunel; Arnak Dalalyan",
        "abstract": "M-estimators are ubiquitous in machine learning and statistical learning theory.  They are used both for defining prediction strategies and  for  evaluating  their  precision.   In  this paper, we propose the first non-asymptotic \u2019any-time\u2019 deviation bounds for general M-estimators, where \u2019any-time\u2019 means that the bound holds with a prescribed probability for every  sample  size.   These  bounds  are  non-asymptotic versions of the law of iterated logarithm.  They are established under general assumptions such as Lipschitz continuity of the loss function and (local) curvature of thepopulation risk.  These conditions are satisfied for most examples used in machine learning, including those ensuring robustness to outliers and to heavy tailed distributions.  As an example of application, we consider the problem of best arm identification in a stochastic multi-arm bandit setting.  We show that the established  bound  can  be  converted  into  a new  algorithm,  with  provably  optimal  theoretical guarantees.  Numerical experiments illustrating the validity of the algorithm are reported.",
        "bibtex": "@InProceedings{pmlr-v108-dalalyan20a,\n  title = \t {A nonasymptotic law of iterated logarithm for general M-estimators},\n  author =       {Schreuder, Nicolas and Brunel, Victor-Emmanuel and Dalalyan, Arnak},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1331--1341},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dalalyan20a/dalalyan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dalalyan20a.html},\n  abstract = \t {M-estimators are ubiquitous in machine learning and statistical learning theory.  They are used both for defining prediction strategies and  for  evaluating  their  precision.   In  this paper, we propose the first non-asymptotic \u2019any-time\u2019 deviation bounds for general M-estimators, where \u2019any-time\u2019 means that the bound holds with a prescribed probability for every  sample  size.   These  bounds  are  non-asymptotic versions of the law of iterated logarithm.  They are established under general assumptions such as Lipschitz continuity of the loss function and (local) curvature of thepopulation risk.  These conditions are satisfied for most examples used in machine learning, including those ensuring robustness to outliers and to heavy tailed distributions.  As an example of application, we consider the problem of best arm identification in a stochastic multi-arm bandit setting.  We show that the established  bound  can  be  converted  into  a new  algorithm,  with  provably  optimal  theoretical guarantees.  Numerical experiments illustrating the validity of the algorithm are reported.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/dalalyan20a/dalalyan20a.pdf",
        "supp": "",
        "pdf_size": 1205127,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6031602546542782209&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "814cc83412",
        "title": "A principled approach for generating adversarial images under non-smooth dissimilarity metrics",
        "site": "https://proceedings.mlr.press/v108/pooladian20a.html",
        "author": "Aram-Alexandre Pooladian; Chris Finlay; Tim Hoheisel; Adam Oberman",
        "abstract": "Deep neural networks perform well on real world data but are prone to adversarial perturbations: small changes in the input easily lead to misclassification. In this work, we propose an attack methodology not only for cases where the perturbations are measured by Lp norms, but in fact any adversarial dissimilarity metric with a closed proximal form. This includes, but is not limited to, L1, L2, and L-infinity perturbations; the L0 counting \"norm\" (i.e. true sparseness); and the total variation seminorm, which is a (Lp) convolutional dissimilarity measuring local pixel changes. Our approach is a natural extension of a recent adversarial attack method, and eliminates the differentiability requirement of the metric. We demonstrate our algorithm, ProxLogBarrier, on the MNIST, CIFAR10, and ImageNet-1k datasets. We consider undefended and defended models, and show that our algorithm easily transfers to various datasets. We observe that ProxLogBarrier outperforms a host of modern adversarial attacks specialized for the L0 case. Moreover, by altering images in the total variation seminorm,  we shed light on a new class of perturbations that exploit neighboring pixel information.",
        "bibtex": "@InProceedings{pmlr-v108-pooladian20a,\n  title = \t {A principled approach for generating adversarial images under non-smooth dissimilarity metrics},\n  author =       {Pooladian, Aram-Alexandre and Finlay, Chris and Hoheisel, Tim and Oberman, Adam},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1442--1452},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pooladian20a/pooladian20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pooladian20a.html},\n  abstract = \t {Deep neural networks perform well on real world data but are prone to adversarial perturbations: small changes in the input easily lead to misclassification. In this work, we propose an attack methodology not only for cases where the perturbations are measured by Lp norms, but in fact any adversarial dissimilarity metric with a closed proximal form. This includes, but is not limited to, L1, L2, and L-infinity perturbations; the L0 counting \"norm\" (i.e. true sparseness); and the total variation seminorm, which is a (Lp) convolutional dissimilarity measuring local pixel changes. Our approach is a natural extension of a recent adversarial attack method, and eliminates the differentiability requirement of the metric. We demonstrate our algorithm, ProxLogBarrier, on the MNIST, CIFAR10, and ImageNet-1k datasets. We consider undefended and defended models, and show that our algorithm easily transfers to various datasets. We observe that ProxLogBarrier outperforms a host of modern adversarial attacks specialized for the L0 case. Moreover, by altering images in the total variation seminorm,  we shed light on a new class of perturbations that exploit neighboring pixel information.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pooladian20a/pooladian20a.pdf",
        "supp": "",
        "pdf_size": 877440,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5184811875929187477&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bb162c7626",
        "title": "A single algorithm for both restless and rested rotting bandits",
        "site": "https://proceedings.mlr.press/v108/seznec20a.html",
        "author": "Julien Seznec; Pierre Menard; Alessandro Lazaric; Michal Valko",
        "abstract": "In many application domains (e.g., recommender systems, intelligent tutoring systems), the rewards associated to the available actions tend to decrease over time. This decay is either caused by the actions executed in the past (e.g., a user may get bored when songs of the same genre are recommended over and over) or by an external factor (e.g., content becomes outdated). These two situations can be modeled as specific instances of the rested and restless bandit settings, where arms are rotting (i.e., their value decrease over time). These problems were thought to be significantly different, since Levine et al. (2017) showed that state-of-the-art algorithms for restless bandit perform poorly in the rested rotting setting. In this paper, we introduce a novel algorithm, Rotting Adaptive Window UCB (RAW-UCB), that achieves near-optimal regret in both rotting rested and restless bandit, without any prior knowledge of the setting (rested or restless) and the type of non-stationarity (e.g., piece-wise constant, bounded variation). This is in striking contrast with previous negative results showing that no algorithm can achieve similar results as soon as rewards are allowed to increase. We confirm our theoretical findings on a number of synthetic and dataset-based experiments.",
        "bibtex": "@InProceedings{pmlr-v108-seznec20a,\n  title = \t {A single algorithm for both restless and rested rotting bandits},\n  author =       {Seznec, Julien and Menard, Pierre and Lazaric, Alessandro and Valko, Michal},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3784--3794},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/seznec20a/seznec20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/seznec20a.html},\n  abstract = \t {In many application domains (e.g., recommender systems, intelligent tutoring systems), the rewards associated to the available actions tend to decrease over time. This decay is either caused by the actions executed in the past (e.g., a user may get bored when songs of the same genre are recommended over and over) or by an external factor (e.g., content becomes outdated). These two situations can be modeled as specific instances of the rested and restless bandit settings, where arms are rotting (i.e., their value decrease over time). These problems were thought to be significantly different, since Levine et al. (2017) showed that state-of-the-art algorithms for restless bandit perform poorly in the rested rotting setting. In this paper, we introduce a novel algorithm, Rotting Adaptive Window UCB (RAW-UCB), that achieves near-optimal regret in both rotting rested and restless bandit, without any prior knowledge of the setting (rested or restless) and the type of non-stationarity (e.g., piece-wise constant, bounded variation). This is in striking contrast with previous negative results showing that no algorithm can achieve similar results as soon as rewards are allowed to increase. We confirm our theoretical findings on a number of synthetic and dataset-based experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/seznec20a/seznec20a.pdf",
        "supp": "",
        "pdf_size": 6939895,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14252594124407736748&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3035b55aa8",
        "title": "AMAGOLD: Amortized Metropolis Adjustment for Efficient Stochastic Gradient MCMC",
        "site": "https://proceedings.mlr.press/v108/zhang20e.html",
        "author": "Ruqi Zhang; A. Feder Cooper; Christopher De Sa",
        "abstract": "Stochastic gradient Hamiltonian Monte Carlo (SGHMC) is an efficient method for sampling from continuous distributions. It is a faster alternative to HMC: instead of using the whole dataset at each iteration, SGHMC uses only a subsample. This improves performance, but introduces bias that can cause SGHMC to converge to the wrong distribution. One can prevent this using a step size that decays to zero, but such a step size schedule can drastically slow down convergence. To address this tension, we propose a novel second-order SG-MCMC algorithm\u2014AMAGOLD\u2014that infrequently uses Metropolis-Hastings (M-H) corrections to remove bias. The infrequency of corrections amortizes their cost. We prove AMAGOLD converges to the target distribution with a fixed, rather than a diminishing, step size, and that its convergence rate is at most a constant factor slower than a full-batch baseline. We empirically demonstrate AMAGOLD\u2019s effectiveness on synthetic distributions, Bayesian logistic regression, and Bayesian neural networks.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20e,\n  title = \t {AMAGOLD: Amortized Metropolis Adjustment for Efficient Stochastic Gradient MCMC},\n  author =       {Zhang, Ruqi and Cooper, A. Feder and Sa, Christopher De},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2142--2152},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20e/zhang20e.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20e.html},\n  abstract = \t {Stochastic gradient Hamiltonian Monte Carlo (SGHMC) is an efficient method for sampling from continuous distributions. It is a faster alternative to HMC: instead of using the whole dataset at each iteration, SGHMC uses only a subsample. This improves performance, but introduces bias that can cause SGHMC to converge to the wrong distribution. One can prevent this using a step size that decays to zero, but such a step size schedule can drastically slow down convergence. To address this tension, we propose a novel second-order SG-MCMC algorithm\u2014AMAGOLD\u2014that infrequently uses Metropolis-Hastings (M-H) corrections to remove bias. The infrequency of corrections amortizes their cost. We prove AMAGOLD converges to the target distribution with a fixed, rather than a diminishing, step size, and that its convergence rate is at most a constant factor slower than a full-batch baseline. We empirically demonstrate AMAGOLD\u2019s effectiveness on synthetic distributions, Bayesian logistic regression, and Bayesian neural networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20e/zhang20e.pdf",
        "supp": "",
        "pdf_size": 1213285,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2395839674360561633&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "592c0bf5f6",
        "title": "AP-Perf: Incorporating Generic Performance Metrics in Differentiable Learning",
        "site": "https://proceedings.mlr.press/v108/fathony20a.html",
        "author": "Rizal Fathony; Zico Kolter",
        "abstract": "We propose a method that enables practitioners to conveniently incorporate custom non-decomposable performance metrics into differentiable learning pipelines, notably those based upon neural network architectures. Our approach is based on the recently developed adversarial prediction framework, a distributionally robust approach that optimizes a metric in the worst case given the statistical summary of the empirical distribution. We formulate a marginal distribution technique to reduce the complexity of optimizing the adversarial prediction formulation over a vast range of non-decomposable metrics. We demonstrate how easy it is to write and incorporate complex custom metrics using our provided tool. Finally, we show the effectiveness of our approach various classification tasks on tabular datasets from the UCI repository and benchmark datasets, as well as image classification tasks. The code for our proposed method is available at https://github.com/rizalzaf/AdversarialPrediction.jl.",
        "bibtex": "@InProceedings{pmlr-v108-fathony20a,\n  title = \t {AP-Perf: Incorporating Generic Performance Metrics in Differentiable Learning},\n  author =       {Fathony, Rizal and Kolter, Zico},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4130--4140},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fathony20a/fathony20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fathony20a.html},\n  abstract = \t {We propose a method that enables practitioners to conveniently incorporate custom non-decomposable performance metrics into differentiable learning pipelines, notably those based upon neural network architectures. Our approach is based on the recently developed adversarial prediction framework, a distributionally robust approach that optimizes a metric in the worst case given the statistical summary of the empirical distribution. We formulate a marginal distribution technique to reduce the complexity of optimizing the adversarial prediction formulation over a vast range of non-decomposable metrics. We demonstrate how easy it is to write and incorporate complex custom metrics using our provided tool. Finally, we show the effectiveness of our approach various classification tasks on tabular datasets from the UCI repository and benchmark datasets, as well as image classification tasks. The code for our proposed method is available at https://github.com/rizalzaf/AdversarialPrediction.jl.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fathony20a/fathony20a.pdf",
        "supp": "",
        "pdf_size": 520489,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13310433765188055192&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Carnegie Mellon University; Carnegie Mellon University and Bosch Center for AI",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu",
        "github": "https://github.com/rizalzaf/AdversarialPrediction.jl",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "df3b549f59",
        "title": "ASAP: Architecture Search, Anneal and Prune",
        "site": "https://proceedings.mlr.press/v108/noy20a.html",
        "author": "Asaf Noy; Niv Nayman; Tal Ridnik; Nadav Zamir; Sivan Doveh; Itamar Friedman; Raja Giryes; Lihi Zelnik",
        "abstract": "Automatic methods for Neural ArchitectureSearch (NAS) have been shown to produce state-of-the-art network models, yet, their main drawback is the computational complexity of the search process. As some primal methods optimized over a discrete search space, thousands of days of GPU were required for convergence. A recent approach is based on constructing a differentiable search space that enables gradient-based optimization, thus reducing the search time to a few days. While successful, such methods still include some incontinuous steps, e.g., the pruning of many weak connections at once. In this paper, we propose a differentiable search space that allows the annealing of architecture weights, while gradually pruning inferior operations, thus the search converges to a single output network in a continuous manner. Experiments on several vision datasets demonstrate the effectiveness of our method with respect to the search cost, accuracy and the memory footprint of the achieved model.",
        "bibtex": "@InProceedings{pmlr-v108-noy20a,\n  title = \t {ASAP: Architecture Search, Anneal and Prune},\n  author =       {Noy, Asaf and Nayman, Niv and Ridnik, Tal and Zamir, Nadav and Doveh, Sivan and Friedman, Itamar and Giryes, Raja and Zelnik, Lihi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {493--503},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/noy20a/noy20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/noy20a.html},\n  abstract = \t {Automatic methods for Neural ArchitectureSearch (NAS) have been shown to produce state-of-the-art network models, yet, their main drawback is the computational complexity of the search process. As some primal methods optimized over a discrete search space, thousands of days of GPU were required for convergence. A recent approach is based on constructing a differentiable search space that enables gradient-based optimization, thus reducing the search time to a few days. While successful, such methods still include some incontinuous steps, e.g., the pruning of many weak connections at once. In this paper, we propose a differentiable search space that allows the annealing of architecture weights, while gradually pruning inferior operations, thus the search converges to a single output network in a continuous manner. Experiments on several vision datasets demonstrate the effectiveness of our method with respect to the search cost, accuracy and the memory footprint of the achieved model.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/noy20a/noy20a.pdf",
        "supp": "",
        "pdf_size": 782052,
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16625883924806481823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1df14a7997",
        "title": "Accelerated Bayesian Optimisation through Weight-Prior Tuning",
        "site": "https://proceedings.mlr.press/v108/shilton20a.html",
        "author": "Alistair Shilton; Sunil Gupta; Santu Rana; Pratibha Vellanki; Cheng Li; Svetha Venkatesh; Laurence Park; Alessandra Sutti; David Rubin; Thomas Dorin; Alireza Vahid; Murray Height; Teo Slezak",
        "abstract": "Bayesian optimization (BO) is a widely-used method for optimizing expensive (to evaluate) problems.  At the core of most BO methods is the modeling of the objective function using a Gaussian Process (GP) whose covariance is selected from a set of standard covariance functions.  From a weight-space view, this models the objective as a linear function in a feature space implied by the given covariance $K$, with an arbitrary Gaussian weight prior ${\\bf w} \\sim ormdist ({\\bf 0},{\\bf I})$.  In many practical applications there is data available that has a similar (covariance) structure to the objective, but which, having different form, cannot be used directly in standard transfer learning.  In this paper we show how such auxiliary data may be used to construct a GP covariance corresponding to a more appropriate weight prior for the objective function.  Building on this, we show that we may accelerate BO by modeling the objective function using this (learned) weight prior, which we demonstrate on both test functions and a practical application to short-polymer fibre manufacture.",
        "bibtex": "@InProceedings{pmlr-v108-shilton20a,\n  title = \t {Accelerated Bayesian Optimisation through Weight-Prior Tuning},\n  author =       {Shilton, Alistair and Gupta, Sunil and Rana, Santu and Vellanki, Pratibha and Li, Cheng and Venkatesh, Svetha and Park, Laurence and Sutti, Alessandra and Rubin, David and Dorin, Thomas and Vahid, Alireza and Height, Murray and Slezak, Teo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {635--645},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shilton20a/shilton20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shilton20a.html},\n  abstract = \t {Bayesian optimization (BO) is a widely-used method for optimizing expensive (to evaluate) problems.  At the core of most BO methods is the modeling of the objective function using a Gaussian Process (GP) whose covariance is selected from a set of standard covariance functions.  From a weight-space view, this models the objective as a linear function in a feature space implied by the given covariance $K$, with an arbitrary Gaussian weight prior ${\\bf w} \\sim ormdist ({\\bf 0},{\\bf I})$.  In many practical applications there is data available that has a similar (covariance) structure to the objective, but which, having different form, cannot be used directly in standard transfer learning.  In this paper we show how such auxiliary data may be used to construct a GP covariance corresponding to a more appropriate weight prior for the objective function.  Building on this, we show that we may accelerate BO by modeling the objective function using this (learned) weight prior, which we demonstrate on both test functions and a practical application to short-polymer fibre manufacture.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shilton20a/shilton20a.pdf",
        "supp": "",
        "pdf_size": 815047,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3Bh_dFgoO_QJ:scholar.google.com/&scioq=Accelerated+Bayesian+Optimisation+through+Weight-Prior+Tuning&hl=en&as_sdt=0,33",
        "gs_version_total": 7,
        "aff": ";;;;;;;;;;;;",
        "aff_domain": ";;;;;;;;;;;;",
        "email": ";;;;;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 13,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "49ed566cfe",
        "title": "Accelerated Factored Gradient Descent for Low-Rank Matrix Factorization",
        "site": "https://proceedings.mlr.press/v108/zhou20b.html",
        "author": "Dongruo Zhou; Yuan Cao; Quanquan Gu",
        "abstract": "We study the low-rank matrix estimation problem, where the objective function $\\mathcal{L}(\\Mb)$ is defined over the space of positive semidefinite matrices with rank less than or equal to $r$. A fast approach to solve this problem is matrix factorization, which reparameterizes $\\mathbf{M}$ as the product of two smaller matrix such that $\\mathbf{M} =\\mathbf{U}\\mathbf{U}^\\top$ and then performs gradient descent on $\\mathbf{U}$ directly, a.k.a., factored gradient descent. Since the resulting problem is nonconvex, whether Nesterov\u2019s acceleration scheme can be adapted to it remains a long-standing question. In this paper, we answer this question affirmatively by proposing a novel and practical accelerated factored gradient descent method motivated by Nesterov\u2019s accelerated gradient descent. The proposed method enjoys better iteration complexity and computational complexity than the state-of-the-art algorithms in a wide regime. The key idea of our algorithm is to restrict all its iterates onto a special convex set, which enables the acceleration. Experimental results demonstrate the faster convergence of our algorithm and corroborate our theory.",
        "bibtex": "@InProceedings{pmlr-v108-zhou20b,\n  title = \t {Accelerated Factored Gradient Descent for Low-Rank Matrix Factorization},\n  author =       {Zhou, Dongruo and Cao, Yuan and Gu, Quanquan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4430--4440},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhou20b/zhou20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhou20b.html},\n  abstract = \t {We study the low-rank matrix estimation problem, where the objective function $\\mathcal{L}(\\Mb)$ is defined over the space of positive semidefinite matrices with rank less than or equal to $r$. A fast approach to solve this problem is matrix factorization, which reparameterizes $\\mathbf{M}$ as the product of two smaller matrix such that $\\mathbf{M} =\\mathbf{U}\\mathbf{U}^\\top$ and then performs gradient descent on $\\mathbf{U}$ directly, a.k.a., factored gradient descent. Since the resulting problem is nonconvex, whether Nesterov\u2019s acceleration scheme can be adapted to it remains a long-standing question. In this paper, we answer this question affirmatively by proposing a novel and practical accelerated factored gradient descent method motivated by Nesterov\u2019s accelerated gradient descent. The proposed method enjoys better iteration complexity and computational complexity than the state-of-the-art algorithms in a wide regime. The key idea of our algorithm is to restrict all its iterates onto a special convex set, which enables the acceleration. Experimental results demonstrate the faster convergence of our algorithm and corroborate our theory. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhou20b/zhou20b.pdf",
        "supp": "",
        "pdf_size": 598734,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4475326674878445097&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fbefe152b6",
        "title": "Accelerated Primal-Dual Algorithms for Distributed Smooth Convex Optimization over Networks",
        "site": "https://proceedings.mlr.press/v108/xu20b.html",
        "author": "Jinming Xu; Ye Tian; Ying Sun; Gesualdo Scutari",
        "abstract": "This paper proposes a novel family of primal-dual-based distributed algorithms for smooth, convex, multi-agent optimization over networks that uses only gradient information and gossip communications.  The algorithms can also employ acceleration on the computation and communications.  We provide a unified analysis of their convergence rate, measured in terms of the Bregman distance associated to the saddle point reformation of the distributed optimization problem.  When acceleration is employed, the rate is shown to be optimal, in the sense that it matches (under the proposed metric) existing complexity lower bounds of distributed algorithms applicable to such a class of problem and using only gradient information and gossip communications.  Preliminary numerical results on distributed least-square regression problems show that the proposed algorithm compares favorably on existing distributed schemes.",
        "bibtex": "@InProceedings{pmlr-v108-xu20b,\n  title = \t {Accelerated Primal-Dual Algorithms for Distributed Smooth Convex Optimization over Networks},\n  author =       {Xu, Jinming and Tian, Ye and Sun, Ying and Scutari, Gesualdo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2381--2391},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/xu20b/xu20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/xu20b.html},\n  abstract = \t {This paper proposes a novel family of primal-dual-based distributed algorithms for smooth, convex, multi-agent optimization over networks that uses only gradient information and gossip communications.  The algorithms can also employ acceleration on the computation and communications.  We provide a unified analysis of their convergence rate, measured in terms of the Bregman distance associated to the saddle point reformation of the distributed optimization problem.  When acceleration is employed, the rate is shown to be optimal, in the sense that it matches (under the proposed metric) existing complexity lower bounds of distributed algorithms applicable to such a class of problem and using only gradient information and gossip communications.  Preliminary numerical results on distributed least-square regression problems show that the proposed algorithm compares favorably on existing distributed schemes.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/xu20b/xu20b.pdf",
        "supp": "",
        "pdf_size": 886040,
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1823716524457460290&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d6d2f19135",
        "title": "Accelerating Gradient Boosting Machines",
        "site": "https://proceedings.mlr.press/v108/lu20a.html",
        "author": "Haihao Lu; Sai Praneeth Karimireddy; Natalia Ponomareva; Vahab Mirrokni",
        "abstract": "Gradient Boosting Machine (GBM) introduced by\u00a0\\cite{friedman2001greedy} is a widely popular ensembling technique and is routinely used in competitions such as Kaggle and the KDDCup\u00a0\\citep{chen2016xgboost}. In this work, we propose an Accelerated Gradient Boosting Machine (AGBM) by incorporating Nesterov\u2019s acceleration techniques into the design of GBM. The difficulty in accelerating GBM lies in the fact that weak (inexact) learners are commonly used, and therefore, with naive application, the errors can accumulate in the momentum term. To overcome it, we design a \u201ccorrected pseudo residual\u201d that serves as a new target for fitting a weak learner, in order to perform the z-update. Thus, we are able to derive novel computational guarantees for AGBM. This is the first GBM type of algorithm with a theoretically-justified accelerated convergence rate.",
        "bibtex": "@InProceedings{pmlr-v108-lu20a,\n  title = \t {Accelerating Gradient Boosting Machines},\n  author =       {Lu, Haihao and Karimireddy, Sai Praneeth and Ponomareva, Natalia and Mirrokni, Vahab},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {516--526},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lu20a/lu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lu20a.html},\n  abstract = \t {Gradient Boosting Machine (GBM) introduced by\u00a0\\cite{friedman2001greedy} is a widely popular ensembling technique and is routinely used in competitions such as Kaggle and the KDDCup\u00a0\\citep{chen2016xgboost}. In this work, we propose an Accelerated Gradient Boosting Machine (AGBM) by incorporating Nesterov\u2019s acceleration techniques into the design of GBM. The difficulty in accelerating GBM lies in the fact that weak (inexact) learners are commonly used, and therefore, with naive application, the errors can accumulate in the momentum term. To overcome it, we design a \u201ccorrected pseudo residual\u201d that serves as a new target for fitting a weak learner, in order to perform the z-update. Thus, we are able to derive novel computational guarantees for AGBM. This is the first GBM type of algorithm with a theoretically-justified accelerated convergence rate. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/lu20a/lu20a.pdf",
        "supp": "",
        "pdf_size": 2201575,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10129756944035067362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Google; University of Chicago; EPFL; Google",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Google;University of Chicago;EPFL",
        "aff_unique_dep": "Google;;",
        "aff_unique_url": "https://www.google.com;https://www.uchicago.edu;https://www.epfl.ch",
        "aff_unique_abbr": "Google;UChicago;EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "cd18221b6e",
        "title": "Accelerating Smooth Games by Manipulating Spectral Shapes",
        "site": "https://proceedings.mlr.press/v108/azizian20a.html",
        "author": "Wa\u00efss Azizian; Damien Scieur; Ioannis Mitliagkas; Simon Lacoste-Julien; Gauthier Gidel",
        "abstract": "We use matrix iteration theory to characterize acceleration in smooth games. We define the spectral shape of a family of games as the set containing all eigenvalues of the Jacobians of standard gradient dynamics in the family. Shapes restricted to the real line represent well-understood classes of problems, like minimization. Shapes spanning the complex plane capture the added numerical challenges in solving smooth games. In this framework, we describe gradient-based methods, such as extragradient, as transformations on the spectral shape. Using this perspective, we propose an optimal algorithm for bilinear games. For smooth and strongly monotone operators, we identify a continuum between convex minimization, where acceleration is possible using Polyak\u2019s momentum, and the worst case where gradient descent is optimal. Finally, going beyond first-order methods, we propose an accelerated version of consensus optimization.",
        "bibtex": "@InProceedings{pmlr-v108-azizian20a,\n  title = \t {Accelerating Smooth Games by Manipulating Spectral Shapes},\n  author =       {Azizian, Wa\\\"iss and Scieur, Damien and Mitliagkas, Ioannis and Lacoste-Julien, Simon and Gidel, Gauthier},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1705--1715},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/azizian20a/azizian20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/azizian20a.html},\n  abstract = \t {We use matrix iteration theory to characterize acceleration in smooth games. We define the spectral shape of a family of games as the set containing all eigenvalues of the Jacobians of standard gradient dynamics in the family. Shapes restricted to the real line represent well-understood classes of problems, like minimization. Shapes spanning the complex plane capture the added numerical challenges in solving smooth games. In this framework, we describe gradient-based methods, such as extragradient, as transformations on the spectral shape. Using this perspective, we propose an optimal algorithm for bilinear games. For smooth and strongly monotone operators, we identify a continuum between convex minimization, where acceleration is possible using Polyak\u2019s momentum, and the worst case where gradient descent is optimal. Finally, going beyond first-order methods, we propose an accelerated version of consensus optimization. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/azizian20a/azizian20a.pdf",
        "supp": "",
        "pdf_size": 412553,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12577885771771788050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "\u00b4Ecole Normale Sup\u00b4erieure, Paris; Mila & SAIT AI Lab, Montreal; Mila & DIRO, Universit\u00b4e de Montr\u00b4eal; Mila & DIRO, Universit\u00b4e de Montr\u00b4eal; Mila & DIRO, Universit\u00b4e de Montr\u00b4eal",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Ecole Normale Sup\u00e9rieure;Mila;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": ";AI Lab;Mila & DIRO",
        "aff_unique_url": "https://www.ens.fr;https://mila.quebec;https://www.usherbrooke.ca",
        "aff_unique_abbr": "ENS;Mila;UdeM",
        "aff_campus_unique_index": "0;1;2;2;2",
        "aff_campus_unique": "Paris;Montreal;Montr\u00e9al",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "a84b2b08f9",
        "title": "Active Community Detection with Maximal Expected Model Change",
        "site": "https://proceedings.mlr.press/v108/kushnir20a.html",
        "author": "Dan Kushnir; Benjamin Mirabelli",
        "abstract": "We present a novel active learning algorithm for community detection on networks. Our proposed algorithm uses a Maximal Expected Model Change (MEMC) criterion for querying network nodes label assignments. MEMC detects nodes that maximally change the community assignment likelihood model following a query. Our method is inspired by detection in the benchmark Stochastic Block Model (SBM), where we provide  sample complexity analysis and empirical study with SBM and real network data for binary as well as for the multi-class settings. The analysis also covers the most challenging case of sparse degree and below-detection-threshold SBMs, where we observe a super-linear error reduction. MEMC is shown to be superior to the random selection baseline and other state-of-the-art active learners.",
        "bibtex": "@InProceedings{pmlr-v108-kushnir20a,\n  title = \t {Active Community Detection with Maximal Expected Model Change},\n  author =       {Kushnir, Dan and Mirabelli, Benjamin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {724--734},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kushnir20a/kushnir20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kushnir20a.html},\n  abstract = \t {We present a novel active learning algorithm for community detection on networks. Our proposed algorithm uses a Maximal Expected Model Change (MEMC) criterion for querying network nodes label assignments. MEMC detects nodes that maximally change the community assignment likelihood model following a query. Our method is inspired by detection in the benchmark Stochastic Block Model (SBM), where we provide  sample complexity analysis and empirical study with SBM and real network data for binary as well as for the multi-class settings. The analysis also covers the most challenging case of sparse degree and below-detection-threshold SBMs, where we observe a super-linear error reduction. MEMC is shown to be superior to the random selection baseline and other state-of-the-art active learners.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kushnir20a/kushnir20a.pdf",
        "supp": "",
        "pdf_size": 1461872,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10960192619133575131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "NOKIA Bell Laboratories USA; Princeton University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Nokia Bell Laboratories;Princeton University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nokia.com bell-labs/;https://www.princeton.edu",
        "aff_unique_abbr": "Nokia Bell Labs;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "342fbfe99f",
        "title": "Adaptive Discretization for Evaluation of Probabilistic Cost Functions",
        "site": "https://proceedings.mlr.press/v108/zimmer20a.html",
        "author": "Christoph Zimmer; Danny Driess; Mona Meister; Nguyen-Tuong Duy",
        "abstract": "In many real-world planning applications, e.g. dynamic design of experiments, autonomous driving and robot manipulation, it is necessary to evaluate candidate movement paths with respect to a safety cost function. Here, the continuous candidate paths need to be discretized first and, subsequently, evaluated onthe discretization points. The resulting quality of planned paths, thus, highly depends on the definition of the safety cost functions, and the resolution of the discretization. In this paper, we propose an approach for evaluating continuous candidate paths by employing an adaptive discretization scheme, with a probabilistic cost function learned from observations. The obtained path is then guaranteed to be epsilon-safe, i.e. the remaining risk of still finding an unsafe point on the trajectory is smaller than epsilon. The proposed approach is investigated theoretically, as well as empirically validated on several robotic path planning scenarios.",
        "bibtex": "@InProceedings{pmlr-v108-zimmer20a,\n  title = \t {Adaptive Discretization for Evaluation of Probabilistic Cost Functions},\n  author =       {Zimmer, Christoph and Driess, Danny and Meister, Mona and Duy, Nguyen-Tuong},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2098--2108},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zimmer20a/zimmer20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zimmer20a.html},\n  abstract = \t {In many real-world planning applications, e.g. dynamic design of experiments, autonomous driving and robot manipulation, it is necessary to evaluate candidate movement paths with respect to a safety cost function. Here, the continuous candidate paths need to be discretized first and, subsequently, evaluated onthe discretization points. The resulting quality of planned paths, thus, highly depends on the definition of the safety cost functions, and the resolution of the discretization. In this paper, we propose an approach for evaluating continuous candidate paths by employing an adaptive discretization scheme, with a probabilistic cost function learned from observations. The obtained path is then guaranteed to be epsilon-safe, i.e. the remaining risk of still finding an unsafe point on the trajectory is smaller than epsilon. The proposed approach is investigated theoretically, as well as empirically validated on several robotic path planning scenarios.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zimmer20a/zimmer20a.pdf",
        "supp": "",
        "pdf_size": 775801,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7203836581852137421&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "353d03ce66",
        "title": "Adaptive Exploration in Linear Contextual Bandit",
        "site": "https://proceedings.mlr.press/v108/hao20b.html",
        "author": "Botao Hao; Tor Lattimore; Csaba Szepesvari",
        "abstract": "Contextual bandits serve as a fundamental model for many sequential decision making tasks. The most popular theoretically justified approaches are based on the optimism principle and Thompson sampling. While these algorithms can be practical, they are known to be suboptimal asymptotically. On the other hand, existing asymptotically optimal algorithms for this problem do not exploit the linear structure in an optimal way and suffer from lower-order terms that dominate the regret in all practically interesting regimes. We start to bridge the gap by designing an algorithm that is asymptotically optimal and has good finite-time empirical performance. At the same time, we make connections to the recent literature on when exploration-free methods are effective. Indeed, if the distribution of contexts is well behaved, then our algorithm acts mostly greedily and enjoys sub-logarithmic regret. Furthermore, our approach is adaptive in the sense that it automatically detects the nice case. Numerical results demonstrate significant regret reductions by our method relative to several baselines.",
        "bibtex": "@InProceedings{pmlr-v108-hao20b,\n  title = \t {Adaptive Exploration in Linear Contextual Bandit},\n  author =       {Hao, Botao and Lattimore, Tor and Szepesvari, Csaba},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3536--3545},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hao20b/hao20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hao20b.html},\n  abstract = \t {Contextual bandits serve as a fundamental model for many sequential decision making tasks. The most popular theoretically justified approaches are based on the optimism principle and Thompson sampling. While these algorithms can be practical, they are known to be suboptimal asymptotically. On the other hand, existing asymptotically optimal algorithms for this problem do not exploit the linear structure in an optimal way and suffer from lower-order terms that dominate the regret in all practically interesting regimes. We start to bridge the gap by designing an algorithm that is asymptotically optimal and has good finite-time empirical performance. At the same time, we make connections to the recent literature on when exploration-free methods are effective. Indeed, if the distribution of contexts is well behaved, then our algorithm acts mostly greedily and enjoys sub-logarithmic regret. Furthermore, our approach is adaptive in the sense that it automatically detects the nice case. Numerical results demonstrate significant regret reductions by our method relative to several baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hao20b/hao20b.pdf",
        "supp": "",
        "pdf_size": 400479,
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9278649694199162016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dfa21046d7",
        "title": "Adaptive Online Kernel Sampling for Vertex Classification",
        "site": "https://proceedings.mlr.press/v108/yang20a.html",
        "author": "Peng Yang; Ping Li",
        "abstract": "This paper studies online kernel learning (OKL) for graph classification problem, since the large approximation space provided by reproducing kernel Hilbert spaces often contains an accurate function. Nonetheless, optimizing over this space is computationally expensive. To address this issue, approximate OKL is introduced to reduce the complexity either by limiting the support vector (SV) used by the predictor, or by avoiding the kernelization process altogether using embedding. Nonetheless, as long as the size of the approximation space or the number of SV does not grow over time, an adversarial environment can always exploit the approximation process. In this paper, we introduce an online kernel sampling (OKS) technique, a new second-order OKL method that slightly improve the bound from $O(d \\log(T))$ down to $O(r \\log(T))$ where $r$ is the rank of the learned data and is usually much smaller than d. To reduce the computational complexity of second-order methods, we introduce a randomized sampling algorithm for sketching kernel matrix $K_t$ and show that our method is effective to reduce the time and space complexity significantly while maintaining comparable performance. Empirical experimental results demonstrate that the proposed model is highly effective on real-world graph datasets.",
        "bibtex": "@InProceedings{pmlr-v108-yang20a,\n  title = \t {Adaptive Online Kernel Sampling for Vertex Classification},\n  author =       {Yang, Peng and Li, Ping},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {363--373},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yang20a/yang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yang20a.html},\n  abstract = \t {This paper studies online kernel learning (OKL) for graph classification problem, since the large approximation space provided by reproducing kernel Hilbert spaces often contains an accurate function. Nonetheless, optimizing over this space is computationally expensive. To address this issue, approximate OKL is introduced to reduce the complexity either by limiting the support vector (SV) used by the predictor, or by avoiding the kernelization process altogether using embedding. Nonetheless, as long as the size of the approximation space or the number of SV does not grow over time, an adversarial environment can always exploit the approximation process. In this paper, we introduce an online kernel sampling (OKS) technique, a new second-order OKL method that slightly improve the bound from $O(d \\log(T))$ down to $O(r \\log(T))$ where $r$ is the rank of the learned data and is usually much smaller than d. To reduce the computational complexity of second-order methods, we introduce a randomized sampling algorithm for sketching kernel matrix $K_t$ and show that our method is effective to reduce the time and space complexity significantly while maintaining comparable performance. Empirical experimental results demonstrate that the proposed model is highly effective on real-world graph datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yang20a/yang20a.pdf",
        "supp": "",
        "pdf_size": 264699,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5056017799009614743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2cca098505",
        "title": "Adaptive Trade-Offs in Off-Policy Learning",
        "site": "https://proceedings.mlr.press/v108/rowland20a.html",
        "author": "Mark Rowland; Will Dabney; Remi Munos",
        "abstract": "A great variety of off-policy learning algorithms exist in the literature, and new breakthroughs in this area continue to be made, improving theoretical understanding and yielding state-of-the-art reinforcement learning algorithms. In this paper, we take a unifying view of this space of algorithms, and consider their trade-offs of three fundamental quantities: update variance, fixed-point bias, and contraction rate. This leads to new perspectives on existing methods, and also naturally yields novel algorithms for off-policy evaluation and control. We develop one such algorithm, C-trace, demonstrating that it is able to more efficiently make these trade-offs than existing methods in use, and that it can be scaled to yield state-of-the-art performance in large-scale environments.",
        "bibtex": "@InProceedings{pmlr-v108-rowland20a,\n  title = \t {Adaptive Trade-Offs in Off-Policy Learning},\n  author =       {Rowland, Mark and Dabney, Will and Munos, Remi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {34--44},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rowland20a/rowland20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rowland20a.html},\n  abstract = \t {A great variety of off-policy learning algorithms exist in the literature, and new breakthroughs in this area continue to be made, improving theoretical understanding and yielding state-of-the-art reinforcement learning algorithms. In this paper, we take a unifying view of this space of algorithms, and consider their trade-offs of three fundamental quantities: update variance, fixed-point bias, and contraction rate. This leads to new perspectives on existing methods, and also naturally yields novel algorithms for off-policy evaluation and control. We develop one such algorithm, C-trace, demonstrating that it is able to more efficiently make these trade-offs than existing methods in use, and that it can be scaled to yield state-of-the-art performance in large-scale environments.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rowland20a/rowland20a.pdf",
        "supp": "",
        "pdf_size": 4868810,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1019056474504823921&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bf1e09c732",
        "title": "Adaptive multi-fidelity optimization with fast learning rates",
        "site": "https://proceedings.mlr.press/v108/fiegel20a.html",
        "author": "C\u00f4me Fiegel; Victor Gabillon; Michal Valko",
        "abstract": "In multi-fidelity optimization, biased approximations of varying costs of the target function are available. This paper studies the problem of optimizing a locally smooth function with a limited budget, where the learner has to make a tradeoff between the cost and the bias of these approximations. We first prove lower bounds for the simple regret under different assumptions on the fidelities, based on a cost-to-bias function. We then present the Kometo algorithm which achieves, with additional logarithmic factors, the same rates without any knowledge of the function smoothness and fidelity assumptions, and improves previously proven guarantees. We finally empirically show that our algorithm outperforms previous multi-fidelity optimization methods without the knowledge of problem-dependent parameters.",
        "bibtex": "@InProceedings{pmlr-v108-fiegel20a,\n  title = \t {Adaptive multi-fidelity optimization with fast learning rates},\n  author =       {Fiegel, C\\^ome and Gabillon, Victor and Valko, Michal},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3493--3502},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fiegel20a/fiegel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fiegel20a.html},\n  abstract = \t {In multi-fidelity optimization, biased approximations of varying costs of the target function are available. This paper studies the problem of optimizing a locally smooth function with a limited budget, where the learner has to make a tradeoff between the cost and the bias of these approximations. We first prove lower bounds for the simple regret under different assumptions on the fidelities, based on a cost-to-bias function. We then present the Kometo algorithm which achieves, with additional logarithmic factors, the same rates without any knowledge of the function smoothness and fidelity assumptions, and improves previously proven guarantees. We finally empirically show that our algorithm outperforms previous multi-fidelity optimization methods without the knowledge of problem-dependent parameters.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fiegel20a/fiegel20a.pdf",
        "supp": "",
        "pdf_size": 1241379,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3936006559569806809&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "\u00c9cole Normale Sup\u00e9rieure, Paris; Inria Lille + Huawei R&D, UK; Inria Lille",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;1",
        "aff_unique_norm": "\u00c9cole Normale Sup\u00e9rieure;INRIA;Huawei",
        "aff_unique_dep": ";;R&D",
        "aff_unique_url": "https://www.ens.fr;https://www.inria.fr;https://www.huawei.com/uk",
        "aff_unique_abbr": "ENS;Inria;Huawei",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Paris;Lille;",
        "aff_country_unique_index": "0;0+1;0",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "7c31d19770",
        "title": "Adaptive, Distribution-Free Prediction Intervals for Deep Networks",
        "site": "https://proceedings.mlr.press/v108/kivaranovic20a.html",
        "author": "Danijel Kivaranovic; Kory D. Johnson; Hannes Leeb",
        "abstract": "The machine learning literature contains several constructions for prediction intervals that are intuitively reasonable but ultimately ad-hoc in that they do not come with provable performance guarantees. We present methods from the statistics literature that can be used efficiently with neural networks under minimal assumptions with guaranteed performance. We propose a neural network that outputs three values instead of a single point estimate and optimizes a loss function motivated by the standard quantile regression loss. We provide two prediction interval methods with finite sample coverage guarantees solely under the assumption that the observations are independent and identically distributed. The first method leverages the conformal inference framework and provides average coverage. The second method provides a new, stronger guarantee by conditioning on the observed data. Lastly, our loss function does not compromise the predictive accuracy of the network like other prediction interval methods. We demonstrate the ease of use of our procedures as well as its improvements over other methods on both simulated and real data. As most deep networks can easily be modified by our method to output predictions with valid prediction intervals, its use should become standard practice, much like reporting standard errors along with mean estimates.",
        "bibtex": "@InProceedings{pmlr-v108-kivaranovic20a,\n  title = \t {Adaptive, Distribution-Free Prediction Intervals for Deep Networks},\n  author =       {Kivaranovic, Danijel and Johnson, Kory D. and Leeb, Hannes},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4346--4356},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kivaranovic20a/kivaranovic20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kivaranovic20a.html},\n  abstract = \t {The machine learning literature contains several constructions for prediction intervals that are intuitively reasonable but ultimately ad-hoc in that they do not come with provable performance guarantees. We present methods from the statistics literature that can be used efficiently with neural networks under minimal assumptions with guaranteed performance. We propose a neural network that outputs three values instead of a single point estimate and optimizes a loss function motivated by the standard quantile regression loss. We provide two prediction interval methods with finite sample coverage guarantees solely under the assumption that the observations are independent and identically distributed. The first method leverages the conformal inference framework and provides average coverage. The second method provides a new, stronger guarantee by conditioning on the observed data. Lastly, our loss function does not compromise the predictive accuracy of the network like other prediction interval methods. We demonstrate the ease of use of our procedures as well as its improvements over other methods on both simulated and real data. As most deep networks can easily be modified by our method to output predictions with valid prediction intervals, its use should become standard practice, much like reporting standard errors along with mean estimates.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kivaranovic20a/kivaranovic20a.pdf",
        "supp": "",
        "pdf_size": 955962,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13865666168827834788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "86dfc5fdb2",
        "title": "Additive Tree-Structured Covariance Function for Conditional Parameter Spaces in Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v108/ma20a.html",
        "author": "Xingchen Ma; Matthew Blaschko",
        "abstract": "Bayesian optimization (BO) is a sample-efficient global optimization algorithm for black-box functions which are expensive to evaluate. Existing literature on model based optimization in conditional parameter spaces are usually built on trees. In this work, we generalize the additive assumption to tree-structured functions and propose an additive tree-structured covariance function, showing improved sample-efficiency, wider applicability and greater flexibility. Furthermore, by incorporating the structure information of parameter spaces and the additive assumption in the BO loop, we develop a parallel algorithm to optimize the acquisition function and this optimization can be performed in a low dimensional space. We demonstrate our method on an optimization benchmark function, as well as on a neural network model compression problem, and experimental results show our approach significantly outperforms the current state of the art for conditional parameter optimization including SMAC, TPE and Jenatton et al. (2017).",
        "bibtex": "@InProceedings{pmlr-v108-ma20a,\n  title = \t {Additive Tree-Structured Covariance Function for Conditional Parameter Spaces in Bayesian Optimization},\n  author =       {Ma, Xingchen and Blaschko, Matthew},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1015--1025},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ma20a/ma20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ma20a.html},\n  abstract = \t {Bayesian optimization (BO) is a sample-efficient global optimization algorithm for black-box functions which are expensive to evaluate. Existing literature on model based optimization in conditional parameter spaces are usually built on trees. In this work, we generalize the additive assumption to tree-structured functions and propose an additive tree-structured covariance function, showing improved sample-efficiency, wider applicability and greater flexibility. Furthermore, by incorporating the structure information of parameter spaces and the additive assumption in the BO loop, we develop a parallel algorithm to optimize the acquisition function and this optimization can be performed in a low dimensional space. We demonstrate our method on an optimization benchmark function, as well as on a neural network model compression problem, and experimental results show our approach significantly outperforms the current state of the art for conditional parameter optimization including SMAC, TPE and Jenatton et al. (2017).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ma20a/ma20a.pdf",
        "supp": "",
        "pdf_size": 558987,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2215164628740233283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "ESAT-PSI, KU Leuven, Belgium; ESAT-PSI, KU Leuven, Belgium",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "ESAT-PSI",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "ccea5032a8",
        "title": "Adversarial Risk Bounds through Sparsity based Compression",
        "site": "https://proceedings.mlr.press/v108/balda20a.html",
        "author": "Emilio Balda; Niklas Koep; Arash Behboodi; Rudolf Mathar",
        "abstract": "Neural networks have been shown to be vulnerable against minor adversarial perturbations of their inputs, especially for high dimensional data under $\\ell_\\infty$ attacks.To combat this problem, techniques like adversarial training have been employed to obtain models that are robust on the training set.However, the robustness of such models against adversarial perturbations may not generalize to unseen data.To study how robustness generalizes, recent works assume that the inputs have bounded $\\ell_2$-norm in order to bound the adversarial risk for $\\ell_\\infty$ attacks with no explicit dimension dependence.In this work, we focus on $\\ell_\\infty$ attacks with $\\ell_\\infty$ bounded inputs and prove margin-based bounds.Specifically, we use a compression-based approach that relies on efficiently compressing the set of tunable parameters without distorting the adversarial risk. To achieve this, we apply the concept of effective sparsity and effective joint sparsity on the weight matrices of neural networks.This leads to bounds with no explicit dependence on the input dimension, neither on the number of classes.Our results show that neural networks with approximately sparse weight matrices not only enjoy enhanced robustness but also better generalization. Finally, empirical simulations show that the notion of effective joint sparsity plays a significant role in generalizing robustness to $\\ell_\\infty$ attacks.",
        "bibtex": "@InProceedings{pmlr-v108-balda20a,\n  title = \t {Adversarial Risk Bounds through Sparsity based Compression},\n  author =       {Balda, Emilio and Koep, Niklas and Behboodi, Arash and Mathar, Rudolf},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3816--3825},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/balda20a/balda20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/balda20a.html},\n  abstract = \t {Neural networks have been shown to be vulnerable against minor adversarial perturbations of their inputs, especially for high dimensional data under $\\ell_\\infty$ attacks.To combat this problem, techniques like adversarial training have been employed to obtain models that are robust on the training set.However, the robustness of such models against adversarial perturbations may not generalize to unseen data.To study how robustness generalizes, recent works assume that the inputs have bounded $\\ell_2$-norm in order to bound the adversarial risk for $\\ell_\\infty$ attacks with no explicit dimension dependence.In this work, we focus on $\\ell_\\infty$ attacks with $\\ell_\\infty$ bounded inputs and prove margin-based bounds.Specifically, we use a compression-based approach that relies on efficiently compressing the set of tunable parameters without distorting the adversarial risk. To achieve this, we apply the concept of effective sparsity and effective joint sparsity on the weight matrices of neural networks.This leads to bounds with no explicit dependence on the input dimension, neither on the number of classes.Our results show that neural networks with approximately sparse weight matrices not only enjoy enhanced robustness but also better generalization. Finally, empirical simulations show that the notion of effective joint sparsity plays a significant role in generalizing robustness to $\\ell_\\infty$ attacks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/balda20a/balda20a.pdf",
        "supp": "",
        "pdf_size": 458055,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12431309201907365311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d6d9f24480",
        "title": "Adversarial Robustness Guarantees for Classification with Gaussian Processes",
        "site": "https://proceedings.mlr.press/v108/blaas20a.html",
        "author": "Arno Blaas; Andrea Patane; Luca Laurenti; Luca Cardelli; Marta Kwiatkowska; Stephen Roberts",
        "abstract": "We investigate adversarial robustness of Gaussian Process classification (GPC) models. Specifically, given a compact subset of the input space $T\\subseteq \\mathbb{R}^d$ enclosing a test point $x^*$ and a GPC trained on a dataset $\\mathcal{D}$, we aim to compute the minimum and the maximum classification probability for the GPC over all the points in $T$.In order to do so, we show how functions lower- and upper-bounding the GPC output in $T$ can be derived, and implement those in a branch and bound optimisation algorithm. For any error threshold $\\epsilon > 0$ selected \\emph{a priori}, we show that our algorithm is guaranteed to reach values $\\epsilon$-close to the actual values in finitely many iterations.We apply our method to investigate the robustness of GPC models on a 2D synthetic dataset, the SPAM dataset and a subset of the MNIST dataset, providing comparisons of different GPC training techniques, and show how our method can be used for interpretability analysis. Our empirical analysis suggests that GPC robustness increases with more accurate posterior estimation.",
        "bibtex": "@InProceedings{pmlr-v108-blaas20a,\n  title = \t {Adversarial Robustness Guarantees for Classification with Gaussian Processes},\n  author =       {Blaas, Arno and Patane, Andrea and Laurenti, Luca and Cardelli, Luca and Kwiatkowska, Marta and Roberts, Stephen},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3372--3382},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/blaas20a/blaas20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/blaas20a.html},\n  abstract = \t {We investigate adversarial robustness of Gaussian Process classification (GPC) models. Specifically, given a compact subset of the input space $T\\subseteq \\mathbb{R}^d$ enclosing a test point $x^*$ and a GPC trained on a dataset $\\mathcal{D}$, we aim to compute the minimum and the maximum classification probability for the GPC over all the points in $T$.In order to do so, we show how functions lower- and upper-bounding the GPC output in $T$ can be derived, and implement those in a branch and bound optimisation algorithm. For any error threshold $\\epsilon > 0$ selected \\emph{a priori}, we show that our algorithm is guaranteed to reach values $\\epsilon$-close to the actual values in finitely many iterations.We apply our method to investigate the robustness of GPC models on a 2D synthetic dataset, the SPAM dataset and a subset of the MNIST dataset, providing comparisons of different GPC training techniques, and show how our method can be used for interpretability analysis. Our empirical analysis suggests that GPC robustness increases with more accurate posterior estimation.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/blaas20a/blaas20a.pdf",
        "supp": "",
        "pdf_size": 917225,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13233474548914269432&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Engineering Science, University of Oxford; Department of Computer Science, University of Oxford; Department of Computer Science, University of Oxford; Department of Computer Science, University of Oxford; Department of Computer Science, University of Oxford; Department of Engineering Science, University of Oxford",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "c8ed7ed851",
        "title": "Adversarial Robustness of Flow-Based Generative Models",
        "site": "https://proceedings.mlr.press/v108/pope20a.html",
        "author": "Phillip Pope; Yogesh Balaji; Soheil Feizi",
        "abstract": "Flow-based generative models leverage invertible generator functions to fit a distribution to the training data using maximum likelihood. Despite their use in several application domains, robustness of these models to adversarial attacks has hardly been explored. In this paper, we study adversarial robustness of flow-based generative models both theoretically (for some simple models) and empirically (for more complex ones). First, we consider a linear flow-based generative model and compute optimal sample-specific and universal adversarial perturbations that maximally decrease the likelihood scores. Using this result, we study the robustness of the well-known adversarial training procedure, where we characterize the fundamental trade-off between model robustness and accuracy. Next, we empirically study the robustness of two prominent deep, non-linear, flow-based generative models, namely GLOW and RealNVP. We design two types of adversarial attacks; one that minimizes the likelihood scores of in-distribution samples, while the other that maximizes the likelihood scores of out-of-distribution ones. We find that GLOW and RealNVP are extremely sensitive to both types of attacks. Finally, using a hybrid adversarial training procedure, we significantly boost the robustness of these generative models.",
        "bibtex": "@InProceedings{pmlr-v108-pope20a,\n  title = \t {Adversarial Robustness of Flow-Based Generative Models},\n  author =       {Pope, Phillip and Balaji, Yogesh and Feizi, Soheil},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3795--3805},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pope20a/pope20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pope20a.html},\n  abstract = \t {Flow-based generative models leverage invertible generator functions to fit a distribution to the training data using maximum likelihood. Despite their use in several application domains, robustness of these models to adversarial attacks has hardly been explored. In this paper, we study adversarial robustness of flow-based generative models both theoretically (for some simple models) and empirically (for more complex ones). First, we consider a linear flow-based generative model and compute optimal sample-specific and universal adversarial perturbations that maximally decrease the likelihood scores. Using this result, we study the robustness of the well-known adversarial training procedure, where we characterize the fundamental trade-off between model robustness and accuracy. Next, we empirically study the robustness of two prominent deep, non-linear, flow-based generative models, namely GLOW and RealNVP. We design two types of adversarial attacks; one that minimizes the likelihood scores of in-distribution samples, while the other that maximizes the likelihood scores of out-of-distribution ones. We find that GLOW and RealNVP are extremely sensitive to both types of attacks. Finally, using a hybrid adversarial training procedure, we significantly boost the robustness of these generative models.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pope20a/pope20a.pdf",
        "supp": "",
        "pdf_size": 2442840,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4747224899661327864&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4468311d01",
        "title": "Almost-Matching-Exactly for Treatment Effect Estimation under Network Interference",
        "site": "https://proceedings.mlr.press/v108/awan20a.html",
        "author": "Usaid Awan; Marco Morucci; Vittorio Orlandi; Sudeepa Roy; Cynthia Rudin; Alexander Volfovsky",
        "abstract": "We propose a matching method that recovers direct treatment effects from randomized experiments where units are connected in an observed network, and units that share edges can potentially influence each others\u2019 outcomes. Traditional treatment effect estimators for randomized experiments are biased and error prone in this setting. Our method matches units almost exactly on counts of unique subgraphs within their neighborhood graphs. The matches that we construct are interpretable and high-quality. Our method can be extended easily to accommodate additional unit-level covariate information. We show empirically that our method performs better than other existing methodologies for this problem, while producing meaningful, interpretable results.",
        "bibtex": "@InProceedings{pmlr-v108-awan20a,\n  title = \t {Almost-Matching-Exactly for Treatment Effect Estimation under Network Interference},\n  author =       {Awan, Usaid and Morucci, Marco and Orlandi, Vittorio and Roy, Sudeepa and Rudin, Cynthia and Volfovsky, Alexander},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3252--3262},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/awan20a/awan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/awan20a.html},\n  abstract = \t {We propose a matching method that recovers direct treatment effects from randomized experiments where units are connected in an observed network, and units that share edges can potentially influence each others\u2019 outcomes. Traditional treatment effect estimators for randomized experiments are biased and error prone in this setting. Our method matches units almost exactly on counts of unique subgraphs within their neighborhood graphs. The matches that we construct are interpretable and high-quality. Our method can be extended easily to accommodate additional unit-level covariate information. We show empirically that our method performs better than other existing methodologies for this problem, while producing meaningful, interpretable results.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/awan20a/awan20a.pdf",
        "supp": "",
        "pdf_size": 1698700,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13596608449898766311&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b1e5e791ba",
        "title": "Alternating Minimization Converges Super-Linearly for  Mixed Linear Regression",
        "site": "https://proceedings.mlr.press/v108/ghosh20a.html",
        "author": "Avishek Ghosh; Ramchandran Kannan",
        "abstract": "We address the problem of solving mixed random linear equations. In this problem, we have unlabeled observations coming from multiple linear regressions, and each observation corresponds to exactly one of the regression models. The goal is to learn the linear regressors from the observations. Classically, Alternating Minimization (AM) (which may be thought as a variant of Expectation Maximization (EM)) is used to solve this problem. AM iteratively alternates between the estimation of labels and solving the regression problems with the estimated labels. Empirically, it is observed that, for a large variety of non-convex problems including mixed linear regression, AM converges at a much faster rate compared to gradient based algorithms. However, the existing theory suggests similar rate of convergence, failing to capture this empirical behavior. In this paper, we close this gap between theory and practice for the special case of a mixture of $2$ linear regressions.  We show that, provided initialized properly, AM enjoys a \\emph{super-linear} rate of convergence. To the best of our knowledge, this is the first work that theoretically establishes such rate for AM. Hence, if we want to recover the unknown regressors upto an error (in $\\ell_2$ norm) of $\\epsilon$, AM only takes $\\mathcal{O}(\\log \\log (1/\\epsilon))$ iterations.",
        "bibtex": "@InProceedings{pmlr-v108-ghosh20a,\n  title = \t {Alternating Minimization Converges Super-Linearly for  Mixed Linear Regression},\n  author =       {Ghosh, Avishek and Kannan, Ramchandran},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1093--1103},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ghosh20a/ghosh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ghosh20a.html},\n  abstract = \t {We address the problem of solving mixed random linear equations. In this problem, we have unlabeled observations coming from multiple linear regressions, and each observation corresponds to exactly one of the regression models. The goal is to learn the linear regressors from the observations. Classically, Alternating Minimization (AM) (which may be thought as a variant of Expectation Maximization (EM)) is used to solve this problem. AM iteratively alternates between the estimation of labels and solving the regression problems with the estimated labels. Empirically, it is observed that, for a large variety of non-convex problems including mixed linear regression, AM converges at a much faster rate compared to gradient based algorithms. However, the existing theory suggests similar rate of convergence, failing to capture this empirical behavior. In this paper, we close this gap between theory and practice for the special case of a mixture of $2$ linear regressions.  We show that, provided initialized properly, AM enjoys a \\emph{super-linear} rate of convergence. To the best of our knowledge, this is the first work that theoretically establishes such rate for AM. Hence, if we want to recover the unknown regressors upto an error (in $\\ell_2$ norm) of $\\epsilon$, AM only takes $\\mathcal{O}(\\log \\log (1/\\epsilon))$ iterations.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ghosh20a/ghosh20a.pdf",
        "supp": "",
        "pdf_size": 365235,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5516482690126983160&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering and Computer Sciences, UC Berkeley; Department of Electrical Engineering and Computer Sciences, UC Berkeley",
        "aff_domain": "berkeley.edu;eecs.berkeley.edu",
        "email": "berkeley.edu;eecs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "04dc77c7cf",
        "title": "Amortized Inference of Variational Bounds for Learning Noisy-OR",
        "site": "https://proceedings.mlr.press/v108/yan20b.html",
        "author": "Yiming Yan; Melissa Ailem; Fei Sha",
        "abstract": "Classical approaches for approximate inference depend on cleverly designed variational distributions and bounds. Modern approaches employ amortized variational inference, which uses a neural network to approximate any posterior without leveraging  the structures of the generative models. In this paper, we propose Amortized Conjugate Posterior (ACP), a hybrid approach taking advantages of both types of approaches. Specifically, we use the classical methods to derive specific forms of posterior distributions and then learn the variational parameters using amortized inference. We study the effectiveness of the proposed approach on  the Noisy-OR model  and compare to both the classical and the modern approaches for approximate inference and parameter learning. Our results show that the proposed method outperforms or are at par with other approaches.",
        "bibtex": "@InProceedings{pmlr-v108-yan20b,\n  title = \t {Amortized Inference of Variational Bounds for Learning Noisy-OR},\n  author =       {Yan, Yiming and Ailem, Melissa and Sha, Fei},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3632--3641},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yan20b/yan20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yan20b.html},\n  abstract = \t {Classical approaches for approximate inference depend on cleverly designed variational distributions and bounds. Modern approaches employ amortized variational inference, which uses a neural network to approximate any posterior without leveraging  the structures of the generative models. In this paper, we propose Amortized Conjugate Posterior (ACP), a hybrid approach taking advantages of both types of approaches. Specifically, we use the classical methods to derive specific forms of posterior distributions and then learn the variational parameters using amortized inference. We study the effectiveness of the proposed approach on  the Noisy-OR model  and compare to both the classical and the modern approaches for approximate inference and parameter learning. Our results show that the proposed method outperforms or are at par with other approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yan20b/yan20b.pdf",
        "supp": "",
        "pdf_size": 997042,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4091959915445944233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5f9d3d3dc5",
        "title": "An Asymptotic Rate for the LASSO Loss",
        "site": "https://proceedings.mlr.press/v108/rush20a.html",
        "author": "Cynthia Rush",
        "abstract": "The LASSO is a well-studied method for use in high-dimensional linear regression where one wishes to recover a sparse vector b from noisy observations y measured through a n-by-p matrix X with the model y = Xb + w where w is a vector of independent, mean-zero noise.  We study the linear asymptotic regime where the under sampling ratio, n/p, approaches a constant greater than 0 in the limit.Using a carefully constructed approximate message passing (AMP) algorithm that converges to the LASSO estimator and recent finite sample theoretical performance guarantees for AMP, we provide large deviations bounds between various measures of LASSO loss and their concentrating values predicted by the AMP state evolution that shows exponentially fast convergence (in n) when the measurement matrix X is i.i.d. Gaussian.  This work refines previous asymptotic analysis of LASSO loss in [Bayati and Montanari, 2012].",
        "bibtex": "@InProceedings{pmlr-v108-rush20a,\n  title = \t {An Asymptotic Rate for the LASSO Loss},\n  author =       {Rush, Cynthia},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3664--3673},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rush20a/rush20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rush20a.html},\n  abstract = \t {The LASSO is a well-studied method for use in high-dimensional linear regression where one wishes to recover a sparse vector b from noisy observations y measured through a n-by-p matrix X with the model y = Xb + w where w is a vector of independent, mean-zero noise.  We study the linear asymptotic regime where the under sampling ratio, n/p, approaches a constant greater than 0 in the limit.Using a carefully constructed approximate message passing (AMP) algorithm that converges to the LASSO estimator and recent finite sample theoretical performance guarantees for AMP, we provide large deviations bounds between various measures of LASSO loss and their concentrating values predicted by the AMP state evolution that shows exponentially fast convergence (in n) when the measurement matrix X is i.i.d. Gaussian.  This work refines previous asymptotic analysis of LASSO loss in [Bayati and Montanari, 2012].}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rush20a/rush20a.pdf",
        "supp": "",
        "pdf_size": 390217,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2168872504291056299&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Columbia University",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "eff853cd08",
        "title": "An Empirical Study of Stochastic Gradient Descent with Structured Covariance Noise",
        "site": "https://proceedings.mlr.press/v108/wen20a.html",
        "author": "Yeming Wen; Kevin Luk; Maxime Gazeau; Guodong Zhang; Harris Chan; Jimmy Ba",
        "abstract": "The choice of batch-size in a stochastic optimization algorithm plays a substantial role for both optimization and generalization. Increasing the batch-size used typically improves optimization but degrades generalization. To address the problem of improving generalization while maintaining optimal convergence in large-batch training, we propose to add covariance noise to the gradients. We demonstrate that the learning performance of our method is more accurately captured by the structure of the covariance matrix of the noise rather than by the variance of gradients. Moreover, over the convex-quadratic, we prove in theory that it can be characterized by the Frobenius norm of the noise matrix. Our empirical studies with standard deep learning model-architectures and datasets shows that our method not only improves generalization performance in large-batch training, but furthermore, does so in a way where the optimization performance remains desirable and the training duration is not elongated.",
        "bibtex": "@InProceedings{pmlr-v108-wen20a,\n  title = \t {An Empirical Study of Stochastic Gradient Descent with Structured Covariance Noise},\n  author =       {Wen, Yeming and Luk, Kevin and Gazeau, Maxime and Zhang, Guodong and Chan, Harris and Ba, Jimmy},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3621--3631},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wen20a/wen20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wen20a.html},\n  abstract = \t {The choice of batch-size in a stochastic optimization algorithm plays a substantial role for both optimization and generalization. Increasing the batch-size used typically improves optimization but degrades generalization. To address the problem of improving generalization while maintaining optimal convergence in large-batch training, we propose to add covariance noise to the gradients. We demonstrate that the learning performance of our method is more accurately captured by the structure of the covariance matrix of the noise rather than by the variance of gradients. Moreover, over the convex-quadratic, we prove in theory that it can be characterized by the Frobenius norm of the noise matrix. Our empirical studies with standard deep learning model-architectures and datasets shows that our method not only improves generalization performance in large-batch training, but furthermore, does so in a way where the optimization performance remains desirable and the training duration is not elongated.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wen20a/wen20a.pdf",
        "supp": "",
        "pdf_size": 1222773,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9156971838614598723&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ff6cb0898f",
        "title": "An Inverse-free Truncated Rayleigh-Ritz Method for Sparse Generalized Eigenvalue Problem",
        "site": "https://proceedings.mlr.press/v108/cai20a.html",
        "author": "Yunfeng Cai; Ping Li",
        "abstract": "This paper considers the sparse generalized eigenvalue problem (SGEP), which aims to find the leading eigenvector with at most $k$ nonzero entries. SGEP naturally arises in many applications in machine learning, statistics, and scientific computing, for example, the sparse principal component analysis (SPCA), the sparse discriminant analysis (SDA), and the sparse canonical correlation analysis (SCCA). In this paper, we focus on the development of a three-stage algorithm named {\\em inverse-free truncated Rayleigh-Ritz method} ({\\em IFTRR})  to efficiently solve  SGEP. In each iteration of IFTRR, only a small number of matrix-vector products is required. This makes IFTRR well-suited for large scale problems. Particularly, a new truncation strategy is proposed, which is able to find the support set of the leading eigenvector effectively. Theoretical results are developed to explain why IFTRR works well. Numerical simulations demonstrate the merits of IFTRR.",
        "bibtex": "@InProceedings{pmlr-v108-cai20a,\n  title = \t {An Inverse-free Truncated Rayleigh-Ritz Method for Sparse Generalized Eigenvalue Problem},\n  author =       {Cai, Yunfeng and Li, Ping},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3460--3470},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cai20a/cai20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cai20a.html},\n  abstract = \t {This paper considers the sparse generalized eigenvalue problem (SGEP), which aims to find the leading eigenvector with at most $k$ nonzero entries. SGEP naturally arises in many applications in machine learning, statistics, and scientific computing, for example, the sparse principal component analysis (SPCA), the sparse discriminant analysis (SDA), and the sparse canonical correlation analysis (SCCA). In this paper, we focus on the development of a three-stage algorithm named {\\em inverse-free truncated Rayleigh-Ritz method} ({\\em IFTRR})  to efficiently solve  SGEP. In each iteration of IFTRR, only a small number of matrix-vector products is required. This makes IFTRR well-suited for large scale problems. Particularly, a new truncation strategy is proposed, which is able to find the support set of the leading eigenvector effectively. Theoretical results are developed to explain why IFTRR works well. Numerical simulations demonstrate the merits of IFTRR.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cai20a/cai20a.pdf",
        "supp": "",
        "pdf_size": 578830,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14841496627465553543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Cognitive Computing Lab, Baidu Research, No. 10 Xibeiwang East Road, Beijing 100085, China; Cognitive Computing Lab, Baidu Research, 10900 NE 8th St. Bellevue, WA 98004, USA",
        "aff_domain": "baidu.com;baidu.com",
        "email": "baidu.com;baidu.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Cognitive Computing Lab",
        "aff_unique_url": "https://research.baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Beijing;Bellevue",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "3d7841e55b",
        "title": "An Optimal Algorithm for Adversarial Bandits with Arbitrary Delays",
        "site": "https://proceedings.mlr.press/v108/zimmert20a.html",
        "author": "Julian Zimmert; Yevgeny Seldin",
        "abstract": "We propose a new algorithm for adversarial multi-armed bandits with unrestricted delays. The algorithm is based on a novel hybrid regularizer applied in the Follow the Regularized Leader (FTRL) framework. It achieves $\\mathcal{O}(\\sqrt{kn}+\\sqrt{D\\log(k)})$ regret guarantee, where $k$ is the number of arms, $n$ is the number of rounds, and $D$ is the total delay. The result matches the lower bound within constants and requires no prior knowledge of $n$ or $D$. Additionally, we propose a refined tuning of the algorithm, which achieves $\\mathcal{O}(\\sqrt{kn}+\\min_{S}(|S|+\\sqrt{D_{\\bar S}\\log(k)}))$ regret guarantee, where $S$ is a set of rounds excluded from delay counting, $\\bar S = [n]\\setminus S$ are the counted rounds, and $D_{\\bar S}$ is the total delay in the counted rounds. If the delays are highly unbalanced, the latter regret guarantee can be significantly tighter than the former. The result requires no advance knowledge of the delays and resolves an open problem of Thune et al. (2019). The new FTRL algorithm and its refined tuning are anytime and require no doubling, which resolves another open problem of Thune et al. (2019).",
        "bibtex": "@InProceedings{pmlr-v108-zimmert20a,\n  title = \t {An Optimal Algorithm for Adversarial Bandits with Arbitrary Delays},\n  author =       {Zimmert, Julian and Seldin, Yevgeny},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3285--3294},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zimmert20a/zimmert20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zimmert20a.html},\n  abstract = \t {We propose a new algorithm for adversarial multi-armed bandits with unrestricted delays. The algorithm is based on a novel hybrid regularizer applied in the Follow the Regularized Leader (FTRL) framework. It achieves $\\mathcal{O}(\\sqrt{kn}+\\sqrt{D\\log(k)})$ regret guarantee, where $k$ is the number of arms, $n$ is the number of rounds, and $D$ is the total delay. The result matches the lower bound within constants and requires no prior knowledge of $n$ or $D$. Additionally, we propose a refined tuning of the algorithm, which achieves $\\mathcal{O}(\\sqrt{kn}+\\min_{S}(|S|+\\sqrt{D_{\\bar S}\\log(k)}))$ regret guarantee, where $S$ is a set of rounds excluded from delay counting, $\\bar S = [n]\\setminus S$ are the counted rounds, and $D_{\\bar S}$ is the total delay in the counted rounds. If the delays are highly unbalanced, the latter regret guarantee can be significantly tighter than the former. The result requires no advance knowledge of the delays and resolves an open problem of Thune et al. (2019). The new FTRL algorithm and its refined tuning are anytime and require no doubling, which resolves another open problem of Thune et al. (2019).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zimmert20a/zimmert20a.pdf",
        "supp": "",
        "pdf_size": 291341,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13706923657909291944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Copenhagen; University of Copenhagen",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Copenhagen",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ku.dk",
        "aff_unique_abbr": "UCPH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "e39a4450f5",
        "title": "An Optimal Algorithm for Bandit Convex Optimization with Strongly-Convex and Smooth Loss",
        "site": "https://proceedings.mlr.press/v108/ito20a.html",
        "author": "Shinji Ito",
        "abstract": "We consider non-stochastic bandit convex optimization with strongly-convex and smooth loss functions. For this problem, Hazan and Levy have proposed an algorithm with a regret bound of $\\tilde{O}(d^{3/2} \\sqrt{T})$ given access to an $O(d)$-self-concordant barrier over the feasible region, where $d$ and $T$ stand for the dimensionality of the feasible region and the number of rounds, respectively. However, there are no known efficient ways for constructing self-concordant barriers for general convex sets, and a $\\tilde{O}(\\sqrt{d})$ gap has remained between the upper and lower bounds, as the known regret lower bound is $\\Omega(d\\sqrt{T})$. Our study resolves these two issues by introducing an algorithm that achieves an optimal regret bound of $\\tilde{O}(d \\sqrt{T})$ under a mild assumption, without self-concordant barriers. More precisely, the algorithm requires only a membership oracle for the feasible region, and it achieves an optimal regret bound of $\\tilde{O}(d\\sqrt{T})$ under the assumption that the optimal solution is an interior of the feasible region. Even without this assumption, our algorithm achieves $\\tilde{O}(d^{3/2}\\sqrt{T})$-regret.",
        "bibtex": "@InProceedings{pmlr-v108-ito20a,\n  title = \t {An Optimal Algorithm for Bandit Convex Optimization with Strongly-Convex and Smooth Loss},\n  author =       {Ito, Shinji},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2229--2239},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ito20a/ito20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ito20a.html},\n  abstract = \t {We consider non-stochastic bandit convex optimization with strongly-convex and smooth loss functions. For this problem, Hazan and Levy have proposed an algorithm with a regret bound of $\\tilde{O}(d^{3/2} \\sqrt{T})$ given access to an $O(d)$-self-concordant barrier over the feasible region, where $d$ and $T$ stand for the dimensionality of the feasible region and the number of rounds, respectively. However, there are no known efficient ways for constructing self-concordant barriers for general convex sets, and a $\\tilde{O}(\\sqrt{d})$ gap has remained between the upper and lower bounds, as the known regret lower bound is $\\Omega(d\\sqrt{T})$. Our study resolves these two issues by introducing an algorithm that achieves an optimal regret bound of $\\tilde{O}(d \\sqrt{T})$ under a mild assumption, without self-concordant barriers. More precisely, the algorithm requires only a membership oracle for the feasible region, and it achieves an optimal regret bound of $\\tilde{O}(d\\sqrt{T})$ under the assumption that the optimal solution is an interior of the feasible region. Even without this assumption, our algorithm achieves $\\tilde{O}(d^{3/2}\\sqrt{T})$-regret.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ito20a/ito20a.pdf",
        "supp": "",
        "pdf_size": 316554,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16916450408009542909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "81b2acbef2",
        "title": "An approximate KLD based experimental design for models with intractable likelihoods",
        "site": "https://proceedings.mlr.press/v108/ao20a.html",
        "author": "Ziqiao Ao; Jinglai Li",
        "abstract": "Data collection is a critical step in statistical inference and data science,and the goal of statistical experimental design (ED) is to find the data collection setupthat can provide most information for the inference. In this work we consider a special type of ED problems where the likelihoods are not available in a closed form. In this case, the popular information-theoretic Kullback-Leibler divergence (KLD) based design criterioncan not be used directly, as it requires to evaluate the likelihood function. To address the issue, we derive a new utility function,which is a lower bound of the original KLD utility. This lower bound is expressed in terms of the summation of two or more entropies in the data space, and thus can be evaluated efficiently via entropy estimation methods.We provide several numerical examples to demonstrate the performance of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v108-ao20a,\n  title = \t {An approximate KLD based experimental design for models with intractable likelihoods},\n  author =       {Ao, Ziqiao and Li, Jinglai},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3241--3251},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ao20a/ao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ao20a.html},\n  abstract = \t {Data collection is a critical step in statistical inference and data science,and the goal of statistical experimental design (ED) is to find the data collection setupthat can provide most information for the inference. In this work we consider a special type of ED problems where the likelihoods are not available in a closed form. In this case, the popular information-theoretic Kullback-Leibler divergence (KLD) based design criterioncan not be used directly, as it requires to evaluate the likelihood function. To address the issue, we derive a new utility function,which is a lower bound of the original KLD utility. This lower bound is expressed in terms of the summation of two or more entropies in the data space, and thus can be evaluated efficiently via entropy estimation methods.We provide several numerical examples to demonstrate the performance of the proposed method. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/ao20a/ao20a.pdf",
        "supp": "",
        "pdf_size": 753604,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14395537809151856440&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "School of Mathematical Sciences, Shanghai Jiao Tong University; School of Mathematics, University of Birmingham",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;University of Birmingham",
        "aff_unique_dep": "School of Mathematical Sciences;School of Mathematics",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "SJTU;UoB",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "cc43924639",
        "title": "Approximate Cross-Validation in High Dimensions with Guarantees",
        "site": "https://proceedings.mlr.press/v108/stephenson20a.html",
        "author": "William Stephenson; Tamara Broderick",
        "abstract": "Leave-one-out cross-validation (LOOCV) can be particularly accurate among cross-validation (CV) variants for machine learning assessment tasks \u2013 e.g., assessing methods\u2019 error or variability. But it is expensive to re-fit a model $N$ times for a dataset of size $N$. Previous work has shown that approximations to LOOCV can be both fast and accurate \u2013 when the unknown parameter is of small, fixed dimension. But these approximations incur a running time roughly cubic in dimension \u2013 and we show that, besides computational issues, their accuracy dramatically deteriorates in high dimensions. Authors have suggested many potential and seemingly intuitive solutions, but these methods have not yet been systematically evaluated or compared. We find that all but one perform so poorly as to be unusable for approximating LOOCV. Crucially, though, we are able to show, both empirically and theoretically, that one approximation can perform well in high dimensions \u2013 in cases where the high-dimensional parameter exhibits sparsity. Under interpretable assumptions, our theory demonstrates that the problem can be reduced to working within an empirically recovered (small) support. This procedure is straightforward to implement, and we prove that its running time and error depend on the (small) support size even when the full parameter dimension is large.",
        "bibtex": "@InProceedings{pmlr-v108-stephenson20a,\n  title = \t {Approximate Cross-Validation in High Dimensions with Guarantees},\n  author =       {Stephenson, William and Broderick, Tamara},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2424--2434},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/stephenson20a/stephenson20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/stephenson20a.html},\n  abstract = \t {Leave-one-out cross-validation (LOOCV) can be particularly accurate among cross-validation (CV) variants for machine learning assessment tasks \u2013 e.g., assessing methods\u2019 error or variability. But it is expensive to re-fit a model $N$ times for a dataset of size $N$. Previous work has shown that approximations to LOOCV can be both fast and accurate \u2013 when the unknown parameter is of small, fixed dimension. But these approximations incur a running time roughly cubic in dimension \u2013 and we show that, besides computational issues, their accuracy dramatically deteriorates in high dimensions. Authors have suggested many potential and seemingly intuitive solutions, but these methods have not yet been systematically evaluated or compared. We find that all but one perform so poorly as to be unusable for approximating LOOCV. Crucially, though, we are able to show, both empirically and theoretically, that one approximation can perform well in high dimensions \u2013 in cases where the high-dimensional parameter exhibits sparsity. Under interpretable assumptions, our theory demonstrates that the problem can be reduced to working within an empirically recovered (small) support. This procedure is straightforward to implement, and we prove that its running time and error depend on the (small) support size even when the full parameter dimension is large.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/stephenson20a/stephenson20a.pdf",
        "supp": "",
        "pdf_size": 2664663,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18018759391399149368&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "MIT CSAIL; MIT CSAIL",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT CSAIL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "840be58051",
        "title": "Approximate Cross-validation: Guarantees for Model Assessment and Selection",
        "site": "https://proceedings.mlr.press/v108/wilson20a.html",
        "author": "Ashia Wilson; Maximilian Kasy; Lester Mackey",
        "abstract": "Cross-validation (CV) is a popular approach for assessing and selecting predictive models. However, when the number of folds is large, CV suffers from a need to repeatedly refit a learning procedure on a large number of training datasets. Recent work in empirical risk minimization (ERM) approximates the expensive refitting with a single Newton step warm-started from the full training set optimizer. While this can greatly reduce runtime, several open questions remain including whether these approximations lead to faithful model selection and whether they are suitable for non-smooth objectives. We address these questions with three main contributions: (i) we provide uniform non-asymptotic, deterministic model assessment guarantees for approximate CV; (ii) we show that (roughly) the same conditions also guarantee model selection performance comparable to CV; (iii) we provide a proximal Newton extension of the approximate CV framework for non-smooth prediction problems and develop improved assessment guarantees for problems such as L1-regularized ERM.",
        "bibtex": "@InProceedings{pmlr-v108-wilson20a,\n  title = \t {Approximate Cross-validation: Guarantees for Model Assessment and Selection},\n  author =       {Wilson, Ashia and Kasy, Maximilian and Mackey, Lester},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4530--4540},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wilson20a/wilson20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wilson20a.html},\n  abstract = \t {Cross-validation (CV) is a popular approach for assessing and selecting predictive models. However, when the number of folds is large, CV suffers from a need to repeatedly refit a learning procedure on a large number of training datasets. Recent work in empirical risk minimization (ERM) approximates the expensive refitting with a single Newton step warm-started from the full training set optimizer. While this can greatly reduce runtime, several open questions remain including whether these approximations lead to faithful model selection and whether they are suitable for non-smooth objectives. We address these questions with three main contributions: (i) we provide uniform non-asymptotic, deterministic model assessment guarantees for approximate CV; (ii) we show that (roughly) the same conditions also guarantee model selection performance comparable to CV; (iii) we provide a proximal Newton extension of the approximate CV framework for non-smooth prediction problems and develop improved assessment guarantees for problems such as L1-regularized ERM.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wilson20a/wilson20a.pdf",
        "supp": "",
        "pdf_size": 1490924,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14834706809350370001&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Microsoft Research; Harvard University; Microsoft Research",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Microsoft;Harvard University",
        "aff_unique_dep": "Microsoft Research;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.harvard.edu",
        "aff_unique_abbr": "MSR;Harvard",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d47a3e4f94",
        "title": "Approximate Inference in Discrete Distributions with Monte Carlo Tree Search and Value Functions",
        "site": "https://proceedings.mlr.press/v108/buesing20a.html",
        "author": "Lars Buesing; Nicolas Heess; Theophane Weber",
        "abstract": "Exact probabilistic inference in discrete models is often prohibitively expensive, as it may require evaluating the (unnormalized) target density on its entire domain. Here we consider the setting where only a limited budget of calls to the unnormalized target density oracle is available, raising the challenge of where in its domain to allocate these function calls in order to construct a good approximate solution. We formulate this problem as an instance of sequential decision-making under uncertainty and leverage methods from reinforcement learning for probabilistic inference with budget constraints. In particular, we propose the TreeSample algorithm, an adaptation of Monte Carlo Tree Search to approximate inference. This algorithm caches all previous queries to the density oracle in an explicit search tree, and dynamically allocates new queries based on a \"best-first\" heuristic for exploration, using existing upper confidence bound methods. Our non-parametric inference method can be effectively combined with neural networks that compile approximate conditionals of the target, which are then used to guide the inference search and enable generalization of across multiple target distributions. We show empirically that TreeSample outperforms standard approximate inference methods on synthetic factor graphs.",
        "bibtex": "@InProceedings{pmlr-v108-buesing20a,\n  title = \t {Approximate Inference in Discrete Distributions with Monte Carlo Tree Search and Value Functions},\n  author =       {Buesing, Lars and Heess, Nicolas and Weber, Theophane},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {624--634},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/buesing20a/buesing20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/buesing20a.html},\n  abstract = \t {Exact probabilistic inference in discrete models is often prohibitively expensive, as it may require evaluating the (unnormalized) target density on its entire domain. Here we consider the setting where only a limited budget of calls to the unnormalized target density oracle is available, raising the challenge of where in its domain to allocate these function calls in order to construct a good approximate solution. We formulate this problem as an instance of sequential decision-making under uncertainty and leverage methods from reinforcement learning for probabilistic inference with budget constraints. In particular, we propose the TreeSample algorithm, an adaptation of Monte Carlo Tree Search to approximate inference. This algorithm caches all previous queries to the density oracle in an explicit search tree, and dynamically allocates new queries based on a \"best-first\" heuristic for exploration, using existing upper confidence bound methods. Our non-parametric inference method can be effectively combined with neural networks that compile approximate conditionals of the target, which are then used to guide the inference search and enable generalization of across multiple target distributions. We show empirically that TreeSample outperforms standard approximate inference methods on synthetic factor graphs.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/buesing20a/buesing20a.pdf",
        "supp": "",
        "pdf_size": 1556298,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1335059732634540928&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "eac765e05e",
        "title": "Approximate Inference with Wasserstein Gradient Flows",
        "site": "https://proceedings.mlr.press/v108/frogner20a.html",
        "author": "Charlie Frogner; Tomaso Poggio",
        "abstract": "We present a novel approximate inference method for diffusion processes, based on the Wasserstein gradient flow formulation of the diffusion. In this formulation, the time-dependent density of the diffusion is derived as the limit of implicit Euler steps that follow the gradients of a particular free energy functional. Existing methods for computing Wasserstein gradient flows rely on discretization of the domain of the diffusion, prohibiting their application to domains in more than several dimensions. We propose instead a discretization-free inference method that computes the Wasserstein gradient flow directly in a space of continuous functions. We characterize approximation properties of the proposed method and evaluate it on a nonlinear filtering task, finding performance comparable to the state-of-the-art for filtering diffusions.",
        "bibtex": "@InProceedings{pmlr-v108-frogner20a,\n  title = \t {Approximate Inference with Wasserstein Gradient Flows},\n  author =       {Frogner, Charlie and Poggio, Tomaso},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2581--2590},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/frogner20a/frogner20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/frogner20a.html},\n  abstract = \t {We present a novel approximate inference method for diffusion processes, based on the Wasserstein gradient flow formulation of the diffusion. In this formulation, the time-dependent density of the diffusion is derived as the limit of implicit Euler steps that follow the gradients of a particular free energy functional. Existing methods for computing Wasserstein gradient flows rely on discretization of the domain of the diffusion, prohibiting their application to domains in more than several dimensions. We propose instead a discretization-free inference method that computes the Wasserstein gradient flow directly in a space of continuous functions. We characterize approximation properties of the proposed method and evaluate it on a nonlinear filtering task, finding performance comparable to the state-of-the-art for filtering diffusions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/frogner20a/frogner20a.pdf",
        "supp": "",
        "pdf_size": 5985339,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1867947911034997257&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "CSAIL, Massachusetts Institute of Technology; Center for Brains, Minds, and Machines, Massachusetts Institute of Technology",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "43eb083218",
        "title": "Assessing Local Generalization Capability in Deep Models",
        "site": "https://proceedings.mlr.press/v108/wang20f.html",
        "author": "Huan Wang; Nitish Shirish Keskar; Caiming Xiong; Richard Socher",
        "abstract": "While it has not yet been proven, empirical evidence suggests that model generalization is related to local properties of the optima, which can be described via the Hessian. We connect model generalization with the local property of a solution under the PAC-Bayes paradigm. In particular, we prove that model generalization ability is related to the Hessian, the higher-order \u201csmoothness\" terms characterized by the Lipschitz constant of the Hessian, and the scales of the parameters. Guided by the proof, we propose a metric to score the generalization capability of a model, as well as an algorithm that optimizes the perturbed model accordingly.",
        "bibtex": "@InProceedings{pmlr-v108-wang20f,\n  title = \t {Assessing Local Generalization Capability in Deep Models},\n  author =       {Wang, Huan and Keskar, Nitish Shirish and Xiong, Caiming and Socher, Richard},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2077--2087},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20f/wang20f.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20f.html},\n  abstract = \t {While it has not yet been proven, empirical evidence suggests that model generalization is related to local properties of the optima, which can be described via the Hessian. We connect model generalization with the local property of a solution under the PAC-Bayes paradigm. In particular, we prove that model generalization ability is related to the Hessian, the higher-order \u201csmoothness\" terms characterized by the Lipschitz constant of the Hessian, and the scales of the parameters. Guided by the proof, we propose a metric to score the generalization capability of a model, as well as an algorithm that optimizes the perturbed model accordingly. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20f/wang20f.pdf",
        "supp": "",
        "pdf_size": 3338178,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11391124877200114823&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Salesforce Research; Salesforce Research; Salesforce Research; Salesforce Research",
        "aff_domain": "salesforce.com;salesforce.com;salesforce.com;salesforce.com",
        "email": "salesforce.com;salesforce.com;salesforce.com;salesforce.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Salesforce",
        "aff_unique_dep": "Salesforce Research",
        "aff_unique_url": "https://research.salesforce.com",
        "aff_unique_abbr": "Salesforce",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "aa92bb9493",
        "title": "Asymptotic Analysis of Sampling Estimators for Randomized Numerical Linear Algebra Algorithms",
        "site": "https://proceedings.mlr.press/v108/ma20b.html",
        "author": "Ping Ma; Xinlian Zhang; Xin Xing; Jingyi Ma; Michael Mahoney",
        "abstract": "The statistical analysis of Randomized Numerical Linear Algebra (RandNLA) algorithms within the past few years has mostly focused on their performance as point estimators.  However, this is insufficient for conducting statistical inference, e.g., constructing confidence intervals and hypothesis testing, since the distribution of the estimator is lacking.  In this article, we develop asymptotic analysis to derive the distribution of RandNLA sampling estimators for the least-squares problem.  In particular, we derive the asymptotic distribution of a general sampling estimator with arbitrary sampling probabilities.  The analysis is conducted in two complementary settings, i.e., when the objective of interest is to approximate the full sample estimator or is to infer the underlying ground truth model parameters.  For each setting, we show that the sampling estimator is asymptotically normally distributed under mild regularity conditions.  Moreover, the sampling estimator is asymptotically unbiased in both settings.  Based on our asymptotic analysis, we use two criteria, the Asymptotic Mean Squared Error (AMSE) and the Expected Asymptotic Mean Squared Error (EAMSE), to identify optimal sampling probabilities.  Several of these optimal sampling probability distributions are new to the literature, e.g., the root leverage sampling estimator and the predictor length sampling estimator.  Our theoretical results clarify the role of leverage in the sampling process, and our empirical results demonstrate improvements over existing methods.",
        "bibtex": "@InProceedings{pmlr-v108-ma20b,\n  title = \t {Asymptotic Analysis of Sampling Estimators for Randomized Numerical Linear Algebra Algorithms},\n  author =       {Ma, Ping and Zhang, Xinlian and Xing, Xin and Ma, Jingyi and Mahoney, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1026--1035},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ma20b/ma20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ma20b.html},\n  abstract = \t {The statistical analysis of Randomized Numerical Linear Algebra (RandNLA) algorithms within the past few years has mostly focused on their performance as point estimators.  However, this is insufficient for conducting statistical inference, e.g., constructing confidence intervals and hypothesis testing, since the distribution of the estimator is lacking.  In this article, we develop asymptotic analysis to derive the distribution of RandNLA sampling estimators for the least-squares problem.  In particular, we derive the asymptotic distribution of a general sampling estimator with arbitrary sampling probabilities.  The analysis is conducted in two complementary settings, i.e., when the objective of interest is to approximate the full sample estimator or is to infer the underlying ground truth model parameters.  For each setting, we show that the sampling estimator is asymptotically normally distributed under mild regularity conditions.  Moreover, the sampling estimator is asymptotically unbiased in both settings.  Based on our asymptotic analysis, we use two criteria, the Asymptotic Mean Squared Error (AMSE) and the Expected Asymptotic Mean Squared Error (EAMSE), to identify optimal sampling probabilities.  Several of these optimal sampling probability distributions are new to the literature, e.g., the root leverage sampling estimator and the predictor length sampling estimator.  Our theoretical results clarify the role of leverage in the sampling process, and our empirical results demonstrate improvements over existing methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ma20b/ma20b.pdf",
        "supp": "",
        "pdf_size": 548519,
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14013309242305471853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of Georgia; University of California at San Diego; Harvard University; Central University of Finance and Economics; ICSI and University of California at Berkeley",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of Georgia;University of California, San Diego;Harvard University;Central University of Finance and Economics;University of California, Berkeley",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.uga.edu;https://ucsd.edu;https://www.harvard.edu;http://www.cufe.edu.cn;https://www.berkeley.edu",
        "aff_unique_abbr": "UGA;UCSD;Harvard;CUFE;UC Berkeley",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";San Diego;Berkeley",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "37dd736f72",
        "title": "Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v108/yin20b.html",
        "author": "Ming Yin; Yu-Xiang Wang",
        "abstract": "We consider the problem of off-policy evaluation for reinforcement learning, where the goal is to estimate the expected reward of a target policy $\\pi$ using offline data collected by running a logging policy $\\mu$.  Standard importance-sampling based approaches for this problem suffer from a variance that scales exponentially with time horizon $H$, which motivates a splurge of recent interest in alternatives that break the \"Curse of Horizon\" (Liu et al. 2018, Xie et al. 2019). In particular, it was shown that a marginalized importance sampling (MIS) approach can be used to achieve an estimation error of order $O(H^3/ n)$ in mean square error (MSE) under an episodic Markov Decision Process model with finite states and potentially infinite actions. The MSE bound however is still a factor of $H$ away from a Cramer-Rao lower bound of order  $\\Omega(H^2/n)$. In this paper, we prove that with a simple modification to the MIS estimator, we can asymptotically attain the Cramer-Rao lower bound, provided that the action space is finite. We also provide a general method for constructing MIS estimators with high-probability error bounds.",
        "bibtex": "@InProceedings{pmlr-v108-yin20b,\n  title = \t {Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement Learning},\n  author =       {Yin, Ming and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3948--3958},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yin20b/yin20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yin20b.html},\n  abstract = \t {We consider the problem of off-policy evaluation for reinforcement learning, where the goal is to estimate the expected reward of a target policy $\\pi$ using offline data collected by running a logging policy $\\mu$.  Standard importance-sampling based approaches for this problem suffer from a variance that scales exponentially with time horizon $H$, which motivates a splurge of recent interest in alternatives that break the \"Curse of Horizon\" (Liu et al. 2018, Xie et al. 2019). In particular, it was shown that a marginalized importance sampling (MIS) approach can be used to achieve an estimation error of order $O(H^3/ n)$ in mean square error (MSE) under an episodic Markov Decision Process model with finite states and potentially infinite actions. The MSE bound however is still a factor of $H$ away from a Cramer-Rao lower bound of order  $\\Omega(H^2/n)$. In this paper, we prove that with a simple modification to the MIS estimator, we can asymptotically attain the Cramer-Rao lower bound, provided that the action space is finite. We also provide a general method for constructing MIS estimators with high-probability error bounds. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/yin20b/yin20b.pdf",
        "supp": "",
        "pdf_size": 4573682,
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2501209412753224413&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Santa Barbara; University of California, Santa Barbara",
        "aff_domain": "ucsb.edu;cs.ucsb.edu",
        "email": "ucsb.edu;cs.ucsb.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f2b987afcf",
        "title": "AsyncQVI: Asynchronous-Parallel Q-Value Iteration for Discounted Markov Decision Processes with Near-Optimal Sample Complexity",
        "site": "https://proceedings.mlr.press/v108/zeng20a.html",
        "author": "Yibo Zeng; Fei Feng; Wotao Yin",
        "abstract": "In this paper, we propose AsyncQVI, an asynchronous-parallel Q-value iteration for discounted Markov decision processes whose transition and reward can only be sampled through a generative model. AsyncQVI is also the first asynchronous-parallel algorithm for discounted Markov decision processes that has a sample complexity, which nearly matches the theoretical lower bound. The relatively low memory footprint and parallel ability make AsyncQVI suitable for large-scale applications. In numerical tests, we compare AsyncQVI with four sample-based value iteration methods. The results show that our algorithm is highly efficient and achieves linear parallel speedup.",
        "bibtex": "@InProceedings{pmlr-v108-zeng20a,\n  title = \t {AsyncQVI: Asynchronous-Parallel Q-Value Iteration for Discounted Markov Decision Processes with Near-Optimal Sample Complexity},\n  author =       {Zeng, Yibo and Feng, Fei and Yin, Wotao},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {713--723},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zeng20a/zeng20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zeng20a.html},\n  abstract = \t {In this paper, we propose AsyncQVI, an asynchronous-parallel Q-value iteration for discounted Markov decision processes whose transition and reward can only be sampled through a generative model. AsyncQVI is also the first asynchronous-parallel algorithm for discounted Markov decision processes that has a sample complexity, which nearly matches the theoretical lower bound. The relatively low memory footprint and parallel ability make AsyncQVI suitable for large-scale applications. In numerical tests, we compare AsyncQVI with four sample-based value iteration methods. The results show that our algorithm is highly efficient and achieves linear parallel speedup.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zeng20a/zeng20a.pdf",
        "supp": "",
        "pdf_size": 740749,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8236080531872016128&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Fudan University; Columbia University; University of California, Los Angeles",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Fudan University;Columbia University;University of California, Los Angeles",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.fudan.edu.cn;https://www.columbia.edu;https://www.ucla.edu",
        "aff_unique_abbr": "Fudan;Columbia;UCLA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "bf4e12b6d5",
        "title": "Asynchronous Gibbs Sampling",
        "site": "https://proceedings.mlr.press/v108/terenin20a.html",
        "author": "Alexander Terenin; Daniel Simpson; David Draper",
        "abstract": "Gibbs sampling is a Markov Chain Monte Carlo (MCMC) method often used in Bayesian learning. MCMC methods can be difficult to deploy on parallel and distributed systems due to their inherently sequential nature. We study asynchronous Gibbs sampling, which achieves parallelism by simply ignoring sequential requirements. This method has been shown to produce good empirical results for some hierarchical models, and is popular in the topic modeling community, but was also shown to diverge for other targets. We introduce a theoretical framework for analyzing asynchronous Gibbs sampling and other extensions of MCMC that do not possess the Markov property. We prove that asynchronous Gibbs can be modified so that it converges under appropriate regularity conditions - we call this the exact asynchronous Gibbs algorithm. We study asynchronous Gibbs on a set of examples by comparing the exact and approximate algorithms, including two where it works well, and one where it fails dramatically. We conclude with a set of heuristics to describe settings where the algorithm can be effectively used.",
        "bibtex": "@InProceedings{pmlr-v108-terenin20a,\n  title = \t {Asynchronous Gibbs Sampling},\n  author =       {Terenin, Alexander and Simpson, Daniel and Draper, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {144--154},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/terenin20a/terenin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/terenin20a.html},\n  abstract = \t {Gibbs sampling is a Markov Chain Monte Carlo (MCMC) method often used in Bayesian learning. MCMC methods can be difficult to deploy on parallel and distributed systems due to their inherently sequential nature. We study asynchronous Gibbs sampling, which achieves parallelism by simply ignoring sequential requirements. This method has been shown to produce good empirical results for some hierarchical models, and is popular in the topic modeling community, but was also shown to diverge for other targets. We introduce a theoretical framework for analyzing asynchronous Gibbs sampling and other extensions of MCMC that do not possess the Markov property. We prove that asynchronous Gibbs can be modified so that it converges under appropriate regularity conditions - we call this the exact asynchronous Gibbs algorithm. We study asynchronous Gibbs on a set of examples by comparing the exact and approximate algorithms, including two where it works well, and one where it fails dramatically. We conclude with a set of heuristics to describe settings where the algorithm can be effectively used.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/terenin20a/terenin20a.pdf",
        "supp": "",
        "pdf_size": 190214,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16395061927140004190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f16a74a5d3",
        "title": "Auditing ML Models for Individual Bias and Unfairness",
        "site": "https://proceedings.mlr.press/v108/xue20a.html",
        "author": "Songkai Xue; Mikhail Yurochkin; Yuekai Sun",
        "abstract": "We consider the task of auditing ML models for individual bias/unfairness. We formalize the task in an optimization problem and develop a suite of inferential tools for the optimal value. Our tools permit us to obtain asymptotic confidence intervals and hypothesis tests that cover the target/control the Type I error rate exactly. To demonstrate the utility of our tools, we use them to reveal the gender and racial biases in Northpointe\u2019s COMPAS recidivism prediction instrument.",
        "bibtex": "@InProceedings{pmlr-v108-xue20a,\n  title = \t {Auditing ML Models for Individual Bias and Unfairness},\n  author =       {Xue, Songkai and Yurochkin, Mikhail and Sun, Yuekai},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4552--4562},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/xue20a/xue20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/xue20a.html},\n  abstract = \t {We consider the task of auditing ML models for individual bias/unfairness. We formalize the task in an optimization problem and develop a suite of inferential tools for the optimal value. Our tools permit us to obtain asymptotic confidence intervals and hypothesis tests that cover the target/control the Type I error rate exactly. To demonstrate the utility of our tools, we use them to reveal the gender and racial biases in Northpointe\u2019s COMPAS recidivism prediction instrument.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/xue20a/xue20a.pdf",
        "supp": "",
        "pdf_size": 1010586,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11865319779048903997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d7f22e8384",
        "title": "Automated Augmented Conjugate Inference for Non-conjugate Gaussian Process Models",
        "site": "https://proceedings.mlr.press/v108/galy-fajou20a.html",
        "author": "Theo Galy-Fajou; Florian Wenzel; Manfred Opper",
        "abstract": "We propose automated augmented conjugate inference, a new inference method for non-conjugate Gaussian processes (GP) models.Our method automatically constructs an auxiliary variable augmentation that renders the GP model conditionally conjugate. Building on the conjugate structure of the augmented model, we develop two inference methods. First, a fast and scalable stochastic variational inference method that uses efficient block coordinate ascent updates, which are computed in closed form. Second, an asymptotically correct Gibbs sampler that is useful for small datasets.Our experiments show that our method is up two orders of magnitude faster and more robust than existing state-of-the-art black-box methods.",
        "bibtex": "@InProceedings{pmlr-v108-galy-fajou20a,\n  title = \t {Automated Augmented Conjugate Inference for Non-conjugate Gaussian Process Models},\n  author =       {Galy-Fajou, Theo and Wenzel, Florian and Opper, Manfred},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3025--3035},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/galy-fajou20a/galy-fajou20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/galy-fajou20a.html},\n  abstract = \t {We propose automated augmented conjugate inference, a new inference method for non-conjugate Gaussian processes (GP) models.Our method automatically constructs an auxiliary variable augmentation that renders the GP model conditionally conjugate. Building on the conjugate structure of the augmented model, we develop two inference methods. First, a fast and scalable stochastic variational inference method that uses efficient block coordinate ascent updates, which are computed in closed form. Second, an asymptotically correct Gibbs sampler that is useful for small datasets.Our experiments show that our method is up two orders of magnitude faster and more robust than existing state-of-the-art black-box methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/galy-fajou20a/galy-fajou20a.pdf",
        "supp": "",
        "pdf_size": 3443216,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10587800491174601193&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Technical University of Berlin; Google Research\u2217Technical University of Berlin; Technical University of Berlin",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Berlin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "625a7b4b95",
        "title": "Automatic Differentiation of Sketched Regression",
        "site": "https://proceedings.mlr.press/v108/liao20a.html",
        "author": "Hang Liao; Barak A. Pearlmutter; Vamsi K. Potluru; David P. Woodruff",
        "abstract": "Sketching for speeding up regression problems involves using a sketching matrix $S$ to quickly find the approximate solution to a linear least squares regression (LLS) problem: given $A$ of size $n \\times d$, with $n \\gg d$, along with $b$ of size $n \\times 1$, we seek a vector $y$ with minimal regression error $\\lVert A y - b\\rVert_2$.  This approximation technique is now standard in data science, and many software systems use sketched regression internally, as a component. It is often useful to calculate derivatives (gradients for the purpose of optimization, for example) of such large systems, where sketched LLS is merely a component of a larger system whose derivatives are needed.  To support Automatic Differentiation (AD) of systems containing sketched LLS, we consider propagating derivatives through $\\textrm{LLS}$: both propagating perturbations (forward AD) and gradients (reverse AD). AD performs accurate differentiation and is efficient for problems with a huge number of independent variables.  Since we use $\\textrm{LLS}_S$ (sketched LLS) instead of $\\textrm{LLS}$ for reasons of efficiency, propagation of derivatives also needs to trade accuracy for efficiency, presumably by sketching.  There are two approaches for this: (a) use AD to transform the code that defines\u00a0$\\textrm{LLS}_S$, or (b) approximate exact derivative propagation through $\\textrm{LLS}$ using sketching methods.  We provide strong bounds on the errors produced due to these two natural forms of sketching in the context of AD, giving the first dimensionality reduction analysis for calculating the derivatives of a sketched computation.  Our results crucially depend on the analysis of the operator norm of a sketched inverse matrix product. Extensive experiments on both synthetic and real-world experiments demonstrate the efficacy of our sketched gradients.",
        "bibtex": "@InProceedings{pmlr-v108-liao20a,\n  title = \t {Automatic Differentiation of Sketched Regression},\n  author =       {Liao, Hang and Pearlmutter, Barak A. and Potluru, Vamsi K. and Woodruff, David P.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4367--4376},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/liao20a/liao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/liao20a.html},\n  abstract = \t {Sketching for speeding up regression problems involves using a sketching matrix $S$ to quickly find the approximate solution to a linear least squares regression (LLS) problem: given $A$ of size $n \\times d$, with $n \\gg d$, along with $b$ of size $n \\times 1$, we seek a vector $y$ with minimal regression error $\\lVert A y - b\\rVert_2$.  This approximation technique is now standard in data science, and many software systems use sketched regression internally, as a component. It is often useful to calculate derivatives (gradients for the purpose of optimization, for example) of such large systems, where sketched LLS is merely a component of a larger system whose derivatives are needed.  To support Automatic Differentiation (AD) of systems containing sketched LLS, we consider propagating derivatives through $\\textrm{LLS}$: both propagating perturbations (forward AD) and gradients (reverse AD). AD performs accurate differentiation and is efficient for problems with a huge number of independent variables.  Since we use $\\textrm{LLS}_S$ (sketched LLS) instead of $\\textrm{LLS}$ for reasons of efficiency, propagation of derivatives also needs to trade accuracy for efficiency, presumably by sketching.  There are two approaches for this: (a) use AD to transform the code that defines\u00a0$\\textrm{LLS}_S$, or (b) approximate exact derivative propagation through $\\textrm{LLS}$ using sketching methods.  We provide strong bounds on the errors produced due to these two natural forms of sketching in the context of AD, giving the first dimensionality reduction analysis for calculating the derivatives of a sketched computation.  Our results crucially depend on the analysis of the operator norm of a sketched inverse matrix product. Extensive experiments on both synthetic and real-world experiments demonstrate the efficacy of our sketched gradients.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/liao20a/liao20a.pdf",
        "supp": "",
        "pdf_size": 1472904,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13514209887109387030&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "CMUa; NUIM\u2217; Comcast Research\u2020; CMUa",
        "aff_domain": "cmu.edu;nuim.ie;comcast.net;cmu.edu",
        "email": "cmu.edu;nuim.ie;comcast.net;cmu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Carnegie Mellon University;National University of Ireland, Maynooth;Comcast",
        "aff_unique_dep": ";;Research",
        "aff_unique_url": "https://www.cmu.edu;https://nuim.ie;https://www.comcast.com",
        "aff_unique_abbr": "CMU;NUIM;Comcast",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Maynooth",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Ireland"
    },
    {
        "id": "eb9be9f8df",
        "title": "Automatic Differentiation of Some First-Order Methods in Parametric Optimization",
        "site": "https://proceedings.mlr.press/v108/mehmood20a.html",
        "author": "Sheheryar Mehmood; Peter Ochs",
        "abstract": "We aim at computing the derivative of the solution to a parametric optimization problem with respect to the involved parameters. For a class broader than that of strongly convex functions, this can be achieved by automatic differentiation of iterative minimization algorithms. If the iterative algorithm converges pointwise, then we prove that the derivative sequence also converges pointwise to the derivative of the minimizer with respect to the parameters. Moreover, we provide convergence rates for both sequences. In particular, we prove that the accelerated convergence rate of the Heavy-ball method compared to Gradient Descent also accelerates the derivative computation. An experiment with L2-Regularized Logistic Regression validates the theoretical results.",
        "bibtex": "@InProceedings{pmlr-v108-mehmood20a,\n  title = \t {Automatic Differentiation of Some First-Order Methods in Parametric Optimization},\n  author =       {Mehmood, Sheheryar and Ochs, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1584--1594},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mehmood20a/mehmood20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mehmood20a.html},\n  abstract = \t {We aim at computing the derivative of the solution to a parametric optimization problem with respect to the involved parameters. For a class broader than that of strongly convex functions, this can be achieved by automatic differentiation of iterative minimization algorithms. If the iterative algorithm converges pointwise, then we prove that the derivative sequence also converges pointwise to the derivative of the minimizer with respect to the parameters. Moreover, we provide convergence rates for both sequences. In particular, we prove that the accelerated convergence rate of the Heavy-ball method compared to Gradient Descent also accelerates the derivative computation. An experiment with L2-Regularized Logistic Regression validates the theoretical results.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mehmood20a/mehmood20a.pdf",
        "supp": "",
        "pdf_size": 1147648,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18274159896812201632&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Mathematics and Computer Science, Saarland University, Germany; Department of Mathematics and Computer Science, Saarland University, Germany",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Saarland University",
        "aff_unique_dep": "Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.uni-saarland.de",
        "aff_unique_abbr": "Saarland U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "a5c42e1b22",
        "title": "Balanced Off-Policy Evaluation in General Action Spaces",
        "site": "https://proceedings.mlr.press/v108/sondhi20a.html",
        "author": "Arjun Sondhi; David Arbour; Drew Dimmery",
        "abstract": "Estimation of importance sampling weights for off-policy evaluation of contextual bandits often results in imbalance\u2014a mismatch between the desired and the actual distribution of state-action pairs after weighting. In this work we present balanced off-policy evaluation (B-OPE), a generic method for estimating weights which minimize this imbalance. Estimation of these weights reduces to a binary classification problem regardless of action type. We show that minimizing the risk of the classifier implies minimization of imbalance to the desired counterfactual distribution. In turn, this is tied to the error of the off-policy estimate, allowing for easy tuning of hyperparameters. We provide experimental evidence that B-OPE improves weighting-based approaches for offline policy evaluation in both discrete and continuous action spaces.",
        "bibtex": "@InProceedings{pmlr-v108-sondhi20a,\n  title = \t {Balanced Off-Policy Evaluation in General Action Spaces},\n  author =       {Sondhi, Arjun and Arbour, David and Dimmery, Drew},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2413--2423},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sondhi20a/sondhi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sondhi20a.html},\n  abstract = \t {Estimation of importance sampling weights for off-policy evaluation of contextual bandits often results in imbalance\u2014a mismatch between the desired and the actual distribution of state-action pairs after weighting. In this work we present balanced off-policy evaluation (B-OPE), a generic method for estimating weights which minimize this imbalance. Estimation of these weights reduces to a binary classification problem regardless of action type. We show that minimizing the risk of the classifier implies minimization of imbalance to the desired counterfactual distribution. In turn, this is tied to the error of the off-policy estimate, allowing for easy tuning of hyperparameters. We provide experimental evidence that B-OPE improves weighting-based approaches for offline policy evaluation in both discrete and continuous action spaces.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sondhi20a/sondhi20a.pdf",
        "supp": "",
        "pdf_size": 405439,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5541589159500313052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "54a1d57872",
        "title": "Balancing Learning Speed and Stability in Policy Gradient via Adaptive Exploration",
        "site": "https://proceedings.mlr.press/v108/papini20a.html",
        "author": "Matteo Papini; Andrea Battistello; Marcello Restelli",
        "abstract": "In many Reinforcement Learning (RL) applications, the goal is to find an optimal deterministic policy. However, most RL algorithms require the policy to be stochastic in order to avoid instabilities and perform a sufficient amount of exploration. Adjusting the level of stochasticity during the learning process is non-trivial, as it is difficult to assess whether the costs of random exploration will be repaid in the long run, and to contain the risk of instability.We study this problem in the context of policy gradients (PG) with Gaussian policies. Using tools from the safe PG literature, we design a surrogate objective for the policy variance that captures the effects this parameter has on the learning speed and on the quality of the final solution. Furthermore, we provide a way to optimize this objective that guarantees stable improvement of the original performance measure. We evaluate the proposed methods on simulated continuous control tasks.",
        "bibtex": "@InProceedings{pmlr-v108-papini20a,\n  title = \t {Balancing Learning Speed and Stability in Policy Gradient via Adaptive Exploration},\n  author =       {Papini, Matteo and Battistello, Andrea and Restelli, Marcello},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1188--1199},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/papini20a/papini20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/papini20a.html},\n  abstract = \t { In many Reinforcement Learning (RL) applications, the goal is to find an optimal deterministic policy. However, most RL algorithms require the policy to be stochastic in order to avoid instabilities and perform a sufficient amount of exploration. Adjusting the level of stochasticity during the learning process is non-trivial, as it is difficult to assess whether the costs of random exploration will be repaid in the long run, and to contain the risk of instability.We study this problem in the context of policy gradients (PG) with Gaussian policies. Using tools from the safe PG literature, we design a surrogate objective for the policy variance that captures the effects this parameter has on the learning speed and on the quality of the final solution. Furthermore, we provide a way to optimize this objective that guarantees stable improvement of the original performance measure. We evaluate the proposed methods on simulated continuous control tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/papini20a/papini20a.pdf",
        "supp": "",
        "pdf_size": 1055130,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17022457994143679156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4730998b7a",
        "title": "Bandit Convex Optimization in Non-stationary Environments",
        "site": "https://proceedings.mlr.press/v108/zhao20b.html",
        "author": "Peng Zhao; Guanghui Wang; Lijun Zhang; Zhi-Hua Zhou",
        "abstract": "Bandit Convex Optimization (BCO) is a fundamental framework for modeling sequential decision-making with partial information, where the only feedback available to the player is the one-point or two-point function values. In this paper, we investigate BCO in non-stationary environments and choose the dynamic regret as the performance measure, which is defined as the difference between the cumulative loss incurred by the algorithm and that of any feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the path-length of the comparator sequence that reflects the non-stationarity of environments. We propose a novel algorithm that achieves $O(T^{3/4}(1+P_T)^{1/2})$ and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret respectively for the one-point and two-point feedback models. The latter result is optimal, matching the $\\Omega(T^{1/2}(1+P_T)^{1/2})$ lower bound established in this paper. Notably, our algorithm is more adaptive to non-stationary environments since it does not require prior knowledge of the path-length $P_T$ ahead of time, which is generally unknown.",
        "bibtex": "@InProceedings{pmlr-v108-zhao20b,\n  title = \t {Bandit Convex Optimization in Non-stationary Environments},\n  author =       {Zhao, Peng and Wang, Guanghui and Zhang, Lijun and Zhou, Zhi-Hua},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1508--1518},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhao20b/zhao20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhao20b.html},\n  abstract = \t {Bandit Convex Optimization (BCO) is a fundamental framework for modeling sequential decision-making with partial information, where the only feedback available to the player is the one-point or two-point function values. In this paper, we investigate BCO in non-stationary environments and choose the dynamic regret as the performance measure, which is defined as the difference between the cumulative loss incurred by the algorithm and that of any feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the path-length of the comparator sequence that reflects the non-stationarity of environments. We propose a novel algorithm that achieves $O(T^{3/4}(1+P_T)^{1/2})$ and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret respectively for the one-point and two-point feedback models. The latter result is optimal, matching the $\\Omega(T^{1/2}(1+P_T)^{1/2})$ lower bound established in this paper. Notably, our algorithm is more adaptive to non-stationary environments since it does not require prior knowledge of the path-length $P_T$ ahead of time, which is generally unknown.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhao20b/zhao20b.pdf",
        "supp": "",
        "pdf_size": 347636,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9005650934462956510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 17,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "aff_domain": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "email": "lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "ca3e94252c",
        "title": "Bandit optimisation of functions in the Mat\u00e9rn kernel RKHS",
        "site": "https://proceedings.mlr.press/v108/janz20a.html",
        "author": "David Janz; David Burt; Javier Gonzalez",
        "abstract": "We consider the problem of optimising functions in the reproducing kernel Hilbert space (RKHS) of a Mat\u00e9rn kernel with smoothness parameter $u$ over the domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the $\\pi$-GP-UCB algorithm, is the first practical approach with guaranteed sublinear regret for all $u>1$ and $d \\geq 1$. Empirical validation suggests better performance and drastically improved computational scalablity compared with its predecessor, Improved GP-UCB.",
        "bibtex": "@InProceedings{pmlr-v108-janz20a,\n  title = \t {Bandit optimisation of functions in the Mat\u00e9rn kernel RKHS},\n  author =       {Janz, David and Burt, David and Gonzalez, Javier},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2486--2495},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/janz20a/janz20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/janz20a.html},\n  abstract = \t {We consider the problem of optimising functions in the reproducing kernel Hilbert space (RKHS) of a Mat\u00e9rn kernel with smoothness parameter $u$ over the domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the $\\pi$-GP-UCB algorithm, is the first practical approach with guaranteed sublinear regret for all $u>1$ and $d \\geq 1$. Empirical validation suggests better performance and drastically improved computational scalablity compared with its predecessor, Improved GP-UCB.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/janz20a/janz20a.pdf",
        "supp": "",
        "pdf_size": 561462,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10577893659905518140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "227cf170ff",
        "title": "BasisVAE: Translation-invariant feature-level clustering with Variational Autoencoders",
        "site": "https://proceedings.mlr.press/v108/martens20b.html",
        "author": "Kaspar M\u00e4rtens; Christopher Yau",
        "abstract": "Variational Autoencoders (VAEs) provide a flexible and scalable framework for non-linear dimensionality reduction. However, in application domains such as genomics where data sets are typically tabular and high-dimensional, a black-box approach to dimensionality reduction does not provide sufficient insights. Common data analysis workflows additionally use clustering techniques to identify groups of similar features. This usually leads to a two-stage process, however, it would be desirable to construct a joint modelling framework for simultaneous dimensionality reduction and clustering of features. In this paper, we propose to achieve this through the BasisVAE: a combination of the VAE and a probabilistic clustering prior, which lets us learn a one-hot basis function representation as part of the decoder network. Furthermore, for scenarios where not all features are aligned, we develop an extension to handle translation-invariant basis functions. We show how a collapsed variational inference scheme leads to scalable and efficient inference for BasisVAE, demonstrated on various toy examples as well as on single-cell gene expression data.",
        "bibtex": "@InProceedings{pmlr-v108-martens20b,\n  title = \t {BasisVAE: Translation-invariant feature-level clustering with Variational Autoencoders},\n  author =       {M\\\"artens, Kaspar and Yau, Christopher},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2928--2937},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/martens20b/martens20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/martens20b.html},\n  abstract = \t {Variational Autoencoders (VAEs) provide a flexible and scalable framework for non-linear dimensionality reduction. However, in application domains such as genomics where data sets are typically tabular and high-dimensional, a black-box approach to dimensionality reduction does not provide sufficient insights. Common data analysis workflows additionally use clustering techniques to identify groups of similar features. This usually leads to a two-stage process, however, it would be desirable to construct a joint modelling framework for simultaneous dimensionality reduction and clustering of features. In this paper, we propose to achieve this through the BasisVAE: a combination of the VAE and a probabilistic clustering prior, which lets us learn a one-hot basis function representation as part of the decoder network. Furthermore, for scenarios where not all features are aligned, we develop an extension to handle translation-invariant basis functions. We show how a collapsed variational inference scheme leads to scalable and efficient inference for BasisVAE, demonstrated on various toy examples as well as on single-cell gene expression data. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/martens20b/martens20b.pdf",
        "supp": "",
        "pdf_size": 4158203,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8119910595894605427&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Oxford; Alan Turing Institute + University of Birmingham + University of Manchester",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2+3",
        "aff_unique_norm": "University of Oxford;Alan Turing Institute;University of Birmingham;University of Manchester",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.turing.ac.uk;https://www.birmingham.ac.uk;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Oxford;ATI;Birmingham;UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "00929c94a4",
        "title": "Bayesian Image Classification with Deep Convolutional Gaussian Processes",
        "site": "https://proceedings.mlr.press/v108/dutordoir20a.html",
        "author": "Vincent Dutordoir; Mark Wilk; Artem Artemev; James Hensman",
        "abstract": "In decision-making systems, it is important to have classifiers that have calibrated uncertainties, with an optimisation objective that can be used for automated model selection and training. Gaussian processes (GPs) provide uncertainty estimates and a marginal likelihood objective, but their weak inductive biases lead to inferior accuracy. This has limited their applicability in certain tasks (e.g. image classification). We propose a translation insensitive convolutional kernel, which relaxes the translation invariance constraint imposed by previous convolutional GPs. We show how we can use the marginal likelihood to learn the degree of insensitivity. We also reformulate GP image-to-image convolutional mappings as multi-output GPs, leading to deep convolutional GPs. We show experimentally that our new kernel improves performance in both single-layer and deep models. We also demonstrate that our fully Bayesian approach improves on dropout-based Bayesian deep learning methods in terms of uncertainty and marginal likelihood estimates.",
        "bibtex": "@InProceedings{pmlr-v108-dutordoir20a,\n  title = \t {Bayesian Image Classification with Deep Convolutional Gaussian Processes},\n  author =       {Dutordoir, Vincent and van der Wilk, Mark and Artemev, Artem and Hensman, James},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1529--1539},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dutordoir20a/dutordoir20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dutordoir20a.html},\n  abstract = \t {In decision-making systems, it is important to have classifiers that have calibrated uncertainties, with an optimisation objective that can be used for automated model selection and training. Gaussian processes (GPs) provide uncertainty estimates and a marginal likelihood objective, but their weak inductive biases lead to inferior accuracy. This has limited their applicability in certain tasks (e.g. image classification). We propose a translation insensitive convolutional kernel, which relaxes the translation invariance constraint imposed by previous convolutional GPs. We show how we can use the marginal likelihood to learn the degree of insensitivity. We also reformulate GP image-to-image convolutional mappings as multi-output GPs, leading to deep convolutional GPs. We show experimentally that our new kernel improves performance in both single-layer and deep models. We also demonstrate that our fully Bayesian approach improves on dropout-based Bayesian deep learning methods in terms of uncertainty and marginal likelihood estimates.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/dutordoir20a/dutordoir20a.pdf",
        "supp": "",
        "pdf_size": 739367,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8166544798335959471&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "73c8c5a6eb",
        "title": "Bayesian Reinforcement Learning via Deep, Sparse Sampling",
        "site": "https://proceedings.mlr.press/v108/grover20a.html",
        "author": "Divya Grover; Debabrota Basu; Christos Dimitrakakis",
        "abstract": "We address the problem of Bayesian reinforcement learning using efficient model-based online planning. We propose an optimism-free Bayes-adaptive algorithm to induce deeper and sparser exploration with a theoretical bound on its performance relative to the Bayes optimal as well as lower computational complexity. The main novelty is the use of a candidate policy generator, to generate long-term options in the planning tree (over beliefs), which allows us to create much sparser and deeper trees. Experimental results on different environments show that in comparison to the state-of-the-art, our algorithm is both computationally more efficient, and obtains significantly higher reward over time in discrete environments.",
        "bibtex": "@InProceedings{pmlr-v108-grover20a,\n  title = \t {Bayesian Reinforcement Learning via Deep, Sparse Sampling},\n  author =       {Grover, Divya and Basu, Debabrota and Dimitrakakis, Christos},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3036--3045},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/grover20a/grover20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/grover20a.html},\n  abstract = \t { We address the problem of Bayesian reinforcement learning using efficient model-based online planning. We propose an optimism-free Bayes-adaptive algorithm to induce deeper and sparser exploration with a theoretical bound on its performance relative to the Bayes optimal as well as lower computational complexity. The main novelty is the use of a candidate policy generator, to generate long-term options in the planning tree (over beliefs), which allows us to create much sparser and deeper trees. Experimental results on different environments show that in comparison to the state-of-the-art, our algorithm is both computationally more efficient, and obtains significantly higher reward over time in discrete environments.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/grover20a/grover20a.pdf",
        "supp": "",
        "pdf_size": 2317235,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2448611209443713108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Chalmers University of Technology; Chalmers University of Technology; Chalmers University of Technology+University of Oslo",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Chalmers University of Technology;University of Oslo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.chalmers.se;https://www.uio.no",
        "aff_unique_abbr": "Chalmers;UiO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "Sweden;Norway"
    },
    {
        "id": "76ed97d422",
        "title": "Bayesian experimental design using regularized determinantal point processes",
        "site": "https://proceedings.mlr.press/v108/derezinski20a.html",
        "author": "Michal Derezinski; Feynman Liang; Michael Mahoney",
        "abstract": "We establish a fundamental connection between Bayesian experimental design and determinantal point processes (DPPs). Experimental design is a classical task in combinatorial optimization, where we wish to select a small subset of $d$-dimensional vectors to minimize a statistical optimality criterion. We show that a new regularized variant of DPPs can be used to design efficient algorithms for finding $(1+\\epsilon)$-approximate solutions to experimental design under four commonly used optimality criteria: A-, C-, D- and V-optimality. A key novelty is that we offer improved guarantees under the Bayesian framework, where prior knowledge is incorporated into the criteria. Our algorithm returns a $(1+\\epsilon)$-approximate solution when the subset size $k$ is $\\Omega\\left(\\frac{d_A}{\\epsilon} + \\frac{\\log(11/epsilon)}{\\epsilon^2}\\right)$, where $d_A << d$ is an effective dimension determined by prior knowledge (via a precision matrix $\\mathbf{A}$).This is the first approximation guarantee where the dependence on $d$ is replaced by an effective dimension. Moreover, the time complexity of our algorithm significantly improves on existing approaches with comparable guarantees.",
        "bibtex": "@InProceedings{pmlr-v108-derezinski20a,\n  title = \t {Bayesian experimental design using regularized determinantal point processes},\n  author =       {Derezinski, Michal and Liang, Feynman and Mahoney, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3197--3207},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/derezinski20a/derezinski20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/derezinski20a.html},\n  abstract = \t {We establish a fundamental connection between Bayesian experimental design and determinantal point processes (DPPs). Experimental design is a classical task in combinatorial optimization, where we wish to select a small subset of $d$-dimensional vectors to minimize a statistical optimality criterion. We show that a new regularized variant of DPPs can be used to design efficient algorithms for finding $(1+\\epsilon)$-approximate solutions to experimental design under four commonly used optimality criteria: A-, C-, D- and V-optimality. A key novelty is that we offer improved guarantees under the Bayesian framework, where prior knowledge is incorporated into the criteria. Our algorithm returns a $(1+\\epsilon)$-approximate solution when the subset size $k$ is $\\Omega\\left(\\frac{d_A}{\\epsilon} + \\frac{\\log(11/epsilon)}{\\epsilon^2}\\right)$, where $d_A << d$ is an effective dimension determined by prior knowledge (via a precision matrix $\\mathbf{A}$).This is the first approximation guarantee where the dependence on $d$ is replaced by an effective dimension. Moreover, the time complexity of our algorithm significantly improves on existing approaches with comparable guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/derezinski20a/derezinski20a.pdf",
        "supp": "",
        "pdf_size": 1127713,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3927753868003084874&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, University of California, Berkeley; Department of Statistics, University of California, Berkeley; ICSI and Department of Statistics, University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;stat.berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;stat.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2faad71268",
        "title": "Best-item Learning in Random Utility Models with Subset Choices",
        "site": "https://proceedings.mlr.press/v108/aadirupa-saha20a.html",
        "author": "Aadirupa Saha; Aditya Gopalan",
        "abstract": "We consider the problem of PAC learning the most valuable item from a pool of $n$ items using sequential, adaptively chosen plays of subsets of $k$ items, when, upon playing a subset, the learner receives relative feedback sampled according to a general Random Utility Model (RUM) with independent noise perturbations to the latent item utilities. We identify a new property of such a RUM, termed the minimum advantage, that helps in characterizing the complexity of separating pairs of items based on their relative win/loss empirical counts, and can be bounded as a function of the noise distribution alone. We give a learning algorithm for general RUMs, based on pairwise relative counts of items and hierarchical elimination, along with a new PAC sample complexity guarantee of $O(\\frac{n}{c^2\\epsilon^2} \\log \\frac{k}{\\delta})$ rounds to identify an $\\epsilon$-optimal item with confidence $1-\\delta$, when the worst case pairwise advantage in the RUM has sensitivity at least $c$ to the parameter gaps of items. Fundamental lower bounds on PAC sample complexity show that this is near-optimal in terms of its dependence on $n,k$ and $c$.",
        "bibtex": "@InProceedings{pmlr-v108-aadirupa-saha20a,\n  title = \t {Best-item Learning in Random Utility Models with Subset Choices},\n  author =       {Saha, Aadirupa and Gopalan, Aditya},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4281--4291},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/aadirupa-saha20a/aadirupa-saha20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/aadirupa-saha20a.html},\n  abstract = \t {We consider the problem of PAC learning the most valuable item from a pool of $n$ items using sequential, adaptively chosen plays of subsets of $k$ items, when, upon playing a subset, the learner receives relative feedback sampled according to a general Random Utility Model (RUM) with independent noise perturbations to the latent item utilities. We identify a new property of such a RUM, termed the minimum advantage, that helps in characterizing the complexity of separating pairs of items based on their relative win/loss empirical counts, and can be bounded as a function of the noise distribution alone. We give a learning algorithm for general RUMs, based on pairwise relative counts of items and hierarchical elimination, along with a new PAC sample complexity guarantee of $O(\\frac{n}{c^2\\epsilon^2} \\log \\frac{k}{\\delta})$ rounds to identify an $\\epsilon$-optimal item with confidence $1-\\delta$, when the worst case pairwise advantage in the RUM has sensitivity at least $c$ to the parameter gaps of items. Fundamental lower bounds on PAC sample complexity show that this is near-optimal in terms of its dependence on $n,k$ and $c$. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/aadirupa-saha20a/aadirupa-saha20a.pdf",
        "supp": "",
        "pdf_size": 1059234,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13649022602004882336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Indian Institute of Science, Bengaluru, India; Indian Institute of Science, Bengaluru, India",
        "aff_domain": "iisc.ac.in;iisc.ac.in",
        "email": "iisc.ac.in;iisc.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bengaluru",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "a903765cf2",
        "title": "Better Long-Range Dependency By Bootstrapping A Mutual Information Regularizer",
        "site": "https://proceedings.mlr.press/v108/cao20a.html",
        "author": "Yanshuai Cao; Peng Xu",
        "abstract": "In this work, we develop a novel regularizer to improve the learning of long-range dependency of sequence data. Applied on language modelling, our regularizer expresses the inductive bias that sequence variables should have high mutual information even though the model might not see abundant observations for complex long-range dependency. We show how the \u201cnext sentence prediction (classification)\" heuristic can be derived in a principled way from our mutual information estimation framework, and be further extended to maximize the mutual information of sequence variables. The proposed approach not only is effective at increasing the mutual information of segments under the learned model but more importantly, leads to a higher likelihood on holdout data, and improved generation quality.  Code is releasedat https://github.com/BorealisAI/BMI.",
        "bibtex": "@InProceedings{pmlr-v108-cao20a,\n  title = \t {Better Long-Range Dependency By Bootstrapping A Mutual Information Regularizer},\n  author =       {Cao, Yanshuai and Xu, Peng},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3991--4001},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cao20a/cao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cao20a.html},\n  abstract = \t {In this work, we develop a novel regularizer to improve the learning of long-range dependency of sequence data. Applied on language modelling, our regularizer expresses the inductive bias that sequence variables should have high mutual information even though the model might not see abundant observations for complex long-range dependency. We show how the \u201cnext sentence prediction (classification)\" heuristic can be derived in a principled way from our mutual information estimation framework, and be further extended to maximize the mutual information of sequence variables. The proposed approach not only is effective at increasing the mutual information of segments under the learned model but more importantly, leads to a higher likelihood on holdout data, and improved generation quality.  Code is releasedat https://github.com/BorealisAI/BMI.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cao20a/cao20a.pdf",
        "supp": "",
        "pdf_size": 588401,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4058943898393966199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Borealis AI; Borealis AI",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/BorealisAI/BMI",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Borealis AI",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.borealisai.com",
        "aff_unique_abbr": "Borealis AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "5f732bb962",
        "title": "Beyond exploding and vanishing gradients: analysing RNN training using attractors and smoothness",
        "site": "https://proceedings.mlr.press/v108/ribeiro20a.html",
        "author": "Ant\u00f3nio H. Ribeiro; Koen Tiels; Luis A. Aguirre; Thomas Sch\u00f6n",
        "abstract": "The exploding and vanishing gradient problem has been the major conceptual principle behind most architecture and training improvements in recurrent neural networks (RNNs) during the last decade.  In this paper, we argue that this principle, while powerful, might need some refinement to explain recent developments. We refine the concept of exploding gradients by reformulating the problem in terms of the cost function smoothness, which gives insight into higher-order derivatives and the existence of regions with many close local minima. We also clarify the distinction between vanishing gradients and the need for the RNN to learn attractors to fully use its expressive power. Through the lens of these refinements, we shed new light on recent developments in the RNN field, namely stable RNN and unitary (or orthogonal) RNNs.",
        "bibtex": "@InProceedings{pmlr-v108-ribeiro20a,\n  title = \t {Beyond exploding and vanishing gradients: analysing RNN training using attractors and smoothness},\n  author =       {Ribeiro, Ant\\'onio H. and Tiels, Koen and Aguirre, Luis A. and Sch\\\"on, Thomas},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2370--2380},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ribeiro20a/ribeiro20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ribeiro20a.html},\n  abstract = \t {The exploding and vanishing gradient problem has been the major conceptual principle behind most architecture and training improvements in recurrent neural networks (RNNs) during the last decade.  In this paper, we argue that this principle, while powerful, might need some refinement to explain recent developments. We refine the concept of exploding gradients by reformulating the problem in terms of the cost function smoothness, which gives insight into higher-order derivatives and the existence of regions with many close local minima. We also clarify the distinction between vanishing gradients and the need for the RNN to learn attractors to fully use its expressive power. Through the lens of these refinements, we shed new light on recent developments in the RNN field, namely stable RNN and unitary (or orthogonal) RNNs.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ribeiro20a/ribeiro20a.pdf",
        "supp": "",
        "pdf_size": 2660769,
        "gs_citation": 192,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=347994350254273366&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Federal University of Minas Gerais; Eindhoven University of Technology; Federal University of Minas Gerais; Uppsala University",
        "aff_domain": "ufmg.br;tue.nl;ufmg.br;it.uu.se",
        "email": "ufmg.br;tue.nl;ufmg.br;it.uu.se",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Federal University of Minas Gerais;Eindhoven University of Technology;Uppsala University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ufmg.br;https://www.tue.nl;https://www.uu.se",
        "aff_unique_abbr": "UFMG;TU/e;UU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;2",
        "aff_country_unique": "Brazil;Netherlands;Sweden"
    },
    {
        "id": "40cc0736de",
        "title": "Bisect and Conquer: Hierarchical Clustering via Max-Uncut Bisection",
        "site": "https://proceedings.mlr.press/v108/chatziafratis20a.html",
        "author": "Vaggos Chatziafratis; Grigory Yaroslavtsev; Euiwoong Lee; Konstantin Makarychev; Sara Ahmadian; Alessandro Epasto; Mohammad Mahdian",
        "abstract": "Hierarchical Clustering is an unsupervised data   analysis   method   which   has   been widely used for decades.  Despite its popularity, it had an underdeveloped analytical foundation and to address this,  Dasgupta recently introduced an optimization viewpoint  of  hierarchical  clustering  with  pairwise similarity information that spurred a line  of  work  shedding  light  on  old  algorithms  (e.g.,  Average-Linkage),  but  also designing  new  algorithms.   Here,  for  the maximization  dual  of  Dasgupta\u2019s  objective  (introduced  by  Moseley-Wang),   we present  polynomial-time  42.46%  approximation  algorithms  that  use Max-Uncut Bisection as  a  subroutine.    The  previous  best  worst-case  approximation  factor in  polynomial  time was 33.6%,  improving only  slightly  over  Average-Linkage  which achieves  33.3%.   Finally,  we  complement our  positive  results  by  providing  APX-hardness (even for 0-1 similarities),  under the Small Set Expansion hypothesis.",
        "bibtex": "@InProceedings{pmlr-v108-chatziafratis20a,\n  title = \t {Bisect and Conquer: Hierarchical Clustering via Max-Uncut Bisection},\n  author =       {Chatziafratis, Vaggos and Yaroslavtsev, Grigory and Lee, Euiwoong and Makarychev, Konstantin and Ahmadian, Sara and Epasto, Alessandro and Mahdian, Mohammad},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3121--3132},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chatziafratis20a/chatziafratis20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chatziafratis20a.html},\n  abstract = \t {Hierarchical Clustering is an unsupervised data   analysis   method   which   has   been widely used for decades.  Despite its popularity, it had an underdeveloped analytical foundation and to address this,  Dasgupta recently introduced an optimization viewpoint  of  hierarchical  clustering  with  pairwise similarity information that spurred a line  of  work  shedding  light  on  old  algorithms  (e.g.,  Average-Linkage),  but  also designing  new  algorithms.   Here,  for  the maximization  dual  of  Dasgupta\u2019s  objective  (introduced  by  Moseley-Wang),   we present  polynomial-time  42.46%  approximation  algorithms  that  use Max-Uncut Bisection as  a  subroutine.    The  previous  best  worst-case  approximation  factor in  polynomial  time was 33.6%,  improving only  slightly  over  Average-Linkage  which achieves  33.3%.   Finally,  we  complement our  positive  results  by  providing  APX-hardness (even for 0-1 similarities),  under the Small Set Expansion hypothesis.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chatziafratis20a/chatziafratis20a.pdf",
        "supp": "",
        "pdf_size": 493599,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4894544763842131294&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bb4284dd4e",
        "title": "Black Box Submodular Maximization: Discrete and Continuous Settings",
        "site": "https://proceedings.mlr.press/v108/chen20c.html",
        "author": "Lin Chen; Mingrui Zhang; Hamed Hassani; Amin Karbasi",
        "abstract": "In this paper, we consider the problem of black box continuous submodular maximization where we only have access to the function values and no information about the derivatives is provided. For a monotone and continuous DR-submodular function, and subject to a bounded convex body constraint, we propose Black-box Continuous Greedy, a derivative-free algorithm that provably achieves the tight $[(1-1/e)OPT-\\epsilon]$ approximation guarantee with $O(d/\\epsilon^3)$ function evaluations. We then extend our result to the stochastic setting where function values are subject to stochastic zero-mean noise. It is through this stochastic generalization that we revisit the discrete submodular maximization problem and use the multi-linear extension as a bridge between discrete and continuous settings. Finally, we extensively evaluate the performance of our algorithm on continuous and discrete submodular objective functions using both synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v108-chen20c,\n  title = \t {Black Box Submodular Maximization: Discrete and Continuous Settings},\n  author =       {Chen, Lin and Zhang, Mingrui and Hassani, Hamed and Karbasi, Amin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1058--1070},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chen20c/chen20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chen20c.html},\n  abstract = \t {In this paper, we consider the problem of black box continuous submodular maximization where we only have access to the function values and no information about the derivatives is provided. For a monotone and continuous DR-submodular function, and subject to a bounded convex body constraint, we propose Black-box Continuous Greedy, a derivative-free algorithm that provably achieves the tight $[(1-1/e)OPT-\\epsilon]$ approximation guarantee with $O(d/\\epsilon^3)$ function evaluations. We then extend our result to the stochastic setting where function values are subject to stochastic zero-mean noise. It is through this stochastic generalization that we revisit the discrete submodular maximization problem and use the multi-linear extension as a bridge between discrete and continuous settings. Finally, we extensively evaluate the performance of our algorithm on continuous and discrete submodular objective functions using both synthetic and real data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chen20c/chen20c.pdf",
        "supp": "",
        "pdf_size": 654254,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13869961386632045371&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "064aa7add7",
        "title": "Black-Box Inference for Non-Linear Latent Force Models",
        "site": "https://proceedings.mlr.press/v108/ward20a.html",
        "author": "Wil Ward; Tom Ryder; Dennis Prangle; Mauricio Alvarez",
        "abstract": "Latent force models are systems whereby there is a mechanistic model describing the dynamics of the system state, with some unknown forcing term that is approximated with a Gaussian process. If such dynamics are non-linear, it can be difficult to estimate the posterior state and forcing term jointly, particularly when there are system parameters that also need estimating. This paper uses black-box variational inference to jointly estimate the posterior, designing a multivariate extension to local inverse autoregressive flows as a flexible approximator of the system. We compare estimates on systems where the posterior is known, demonstrating the effectiveness of the approximation, and apply to problems with non-linear dynamics, multi-output systems and models with non-Gaussian likelihoods.",
        "bibtex": "@InProceedings{pmlr-v108-ward20a,\n  title = \t {Black-Box Inference for Non-Linear Latent Force Models},\n  author =       {Ward, Wil and Ryder, Tom and Prangle, Dennis and Alvarez, Mauricio},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3088--3098},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ward20a/ward20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ward20a.html},\n  abstract = \t {Latent force models are systems whereby there is a mechanistic model describing the dynamics of the system state, with some unknown forcing term that is approximated with a Gaussian process. If such dynamics are non-linear, it can be difficult to estimate the posterior state and forcing term jointly, particularly when there are system parameters that also need estimating. This paper uses black-box variational inference to jointly estimate the posterior, designing a multivariate extension to local inverse autoregressive flows as a flexible approximator of the system. We compare estimates on systems where the posterior is known, demonstrating the effectiveness of the approximation, and apply to problems with non-linear dynamics, multi-output systems and models with non-Gaussian likelihoods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ward20a/ward20a.pdf",
        "supp": "",
        "pdf_size": 684299,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11803191662456509615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7d280b6fef",
        "title": "Budget Learning via Bracketing",
        "site": "https://proceedings.mlr.press/v108/acar20a.html",
        "author": "Durmus Alp Emre Acar; Aditya Gangrade; Venkatesh Saligrama",
        "abstract": "Conventional machine learning applications in the mobile/IoT setting transmit data to a cloud-server for predictions. Due to cost considerations (power, latency, monetary), it is desirable to minimise device-to-server transmissions. The budget learning (BL) problem poses the learner\u2019s goal as minimising use of the cloud while suffering no discernible loss in accuracy, under the constraint that the methods employed be edge-implementable. We propose a new formulation for the BL problem via the concept of bracketings. Concretely, we propose to sandwich the cloud\u2019s prediction, $g,$ via functions $h^-, h^+$ from a \u2018simple\u2019 class so that $h^- \\le g \\le h^+$ nearly always. On an instance $x$, if $h^+(x)=h^-(x)$, we leverage local processing, and bypass the cloud. We explore theoretical aspects of this formulation, providing PAC-style learnability definitions; associating the notion of budget learnability to approximability via brackets; and giving VC-theoretic analyses of their properties. We empirically validate our theory on real-world datasets, demonstrating improved performance over prior gating based methods.",
        "bibtex": "@InProceedings{pmlr-v108-acar20a,\n  title = \t {Budget Learning via Bracketing},\n  author =       {Acar, Durmus Alp Emre and Gangrade, Aditya and Saligrama, Venkatesh},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4109--4119},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/acar20a/acar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/acar20a.html},\n  abstract = \t {Conventional machine learning applications in the mobile/IoT setting transmit data to a cloud-server for predictions. Due to cost considerations (power, latency, monetary), it is desirable to minimise device-to-server transmissions. The budget learning (BL) problem poses the learner\u2019s goal as minimising use of the cloud while suffering no discernible loss in accuracy, under the constraint that the methods employed be edge-implementable. We propose a new formulation for the BL problem via the concept of bracketings. Concretely, we propose to sandwich the cloud\u2019s prediction, $g,$ via functions $h^-, h^+$ from a \u2018simple\u2019 class so that $h^- \\le g \\le h^+$ nearly always. On an instance $x$, if $h^+(x)=h^-(x)$, we leverage local processing, and bypass the cloud. We explore theoretical aspects of this formulation, providing PAC-style learnability definitions; associating the notion of budget learnability to approximability via brackets; and giving VC-theoretic analyses of their properties. We empirically validate our theory on real-world datasets, demonstrating improved performance over prior gating based methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/acar20a/acar20a.pdf",
        "supp": "",
        "pdf_size": 707628,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13957940481093950128&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Boston University; Boston University; Boston University",
        "aff_domain": "bu.edu;bu.edu;bu.edu",
        "email": "bu.edu;bu.edu;bu.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c0b31e893f",
        "title": "Budget-Constrained Bandits over General Cost and Reward Distributions",
        "site": "https://proceedings.mlr.press/v108/cayci20a.html",
        "author": "Semih Cayci; Atilla Eryilmaz; R Srikant",
        "abstract": "We consider a budget-constrained bandit problem where each arm pull incurs a random cost, and yields a random reward in return. The objective is to maximize the total expected reward under a budget constraint on the total cost. The model is general in the sense that it allows correlated and potentially heavy-tailed cost-reward pairs that can take on negative values as required by many applications. We show that if moments of order $(2+\\gamma)$ for some $\\gamma > 0$ exist for all cost-reward pairs, $O(\\log B)$ regret is achievable for a budget $B>0$. In order to achieve tight regret bounds, we propose algorithms that exploit the correlation between the cost and reward of each arm by extracting the common information via linear minimum mean-square error estimation. We prove a regret lower bound for this problem, and show that the proposed algorithms achieve tight problem-dependent regret bounds, which are optimal up to a universal constant factor in the case of jointly Gaussian cost and reward pairs.",
        "bibtex": "@InProceedings{pmlr-v108-cayci20a,\n  title = \t {Budget-Constrained Bandits over General Cost and Reward Distributions},\n  author =       {Cayci, Semih and Eryilmaz, Atilla and Srikant, R},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4388--4398},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cayci20a/cayci20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cayci20a.html},\n  abstract = \t {We consider a budget-constrained bandit problem where each arm pull incurs a random cost, and yields a random reward in return. The objective is to maximize the total expected reward under a budget constraint on the total cost. The model is general in the sense that it allows correlated and potentially heavy-tailed cost-reward pairs that can take on negative values as required by many applications. We show that if moments of order $(2+\\gamma)$ for some $\\gamma > 0$ exist for all cost-reward pairs, $O(\\log B)$ regret is achievable for a budget $B>0$. In order to achieve tight regret bounds, we propose algorithms that exploit the correlation between the cost and reward of each arm by extracting the common information via linear minimum mean-square error estimation. We prove a regret lower bound for this problem, and show that the proposed algorithms achieve tight problem-dependent regret bounds, which are optimal up to a universal constant factor in the case of jointly Gaussian cost and reward pairs.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cayci20a/cayci20a.pdf",
        "supp": "",
        "pdf_size": 342913,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1940547339382915311&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "77904b92b4",
        "title": "Calibrated Prediction with Covariate Shift via Unsupervised Domain Adaptation",
        "site": "https://proceedings.mlr.press/v108/park20b.html",
        "author": "Sangdon Park; Osbert Bastani; James Weimer; Insup Lee",
        "abstract": "Reliable uncertainty estimates are an important tool for helping autonomous agents or human decision makers understand and lever-age predictive models. However, existing approaches to estimating uncertainty largely ignore the possibility of covariate shift\u2014i.e.,where the real-world data distribution may differ from the training distribution.  As a consequence, existing algorithms can overestimate certainty, possibly yielding a false sense of confidence in the predictive model. We pro-pose an algorithm for calibrating predictions that accounts for the possibility of covariate shift, given labeled examples from the train-ing distribution and unlabeled examples from the real-world distribution. Our algorithm uses importance weighting to correct for the shift from the training to the real-world distribution. However, importance weighting relies on the training and real-world distributions to be sufficiently close. Building on ideas from domain adaptation, we additionally learn a feature map that tries to equalize these two distributions. In an empirical evaluation, we show that our proposed approach outperforms existing approaches to calibrated prediction when there is covariate shift.",
        "bibtex": "@InProceedings{pmlr-v108-park20b,\n  title = \t {Calibrated Prediction with Covariate Shift via Unsupervised Domain Adaptation},\n  author =       {Park, Sangdon and Bastani, Osbert and Weimer, James and Lee, Insup},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3219--3229},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/park20b/park20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/park20b.html},\n  abstract = \t {Reliable uncertainty estimates are an important tool for helping autonomous agents or human decision makers understand and lever-age predictive models. However, existing approaches to estimating uncertainty largely ignore the possibility of covariate shift\u2014i.e.,where the real-world data distribution may differ from the training distribution.  As a consequence, existing algorithms can overestimate certainty, possibly yielding a false sense of confidence in the predictive model. We pro-pose an algorithm for calibrating predictions that accounts for the possibility of covariate shift, given labeled examples from the train-ing distribution and unlabeled examples from the real-world distribution. Our algorithm uses importance weighting to correct for the shift from the training to the real-world distribution. However, importance weighting relies on the training and real-world distributions to be sufficiently close. Building on ideas from domain adaptation, we additionally learn a feature map that tries to equalize these two distributions. In an empirical evaluation, we show that our proposed approach outperforms existing approaches to calibrated prediction when there is covariate shift.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/park20b/park20b.pdf",
        "supp": "",
        "pdf_size": 857749,
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1780920898261953037&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c9d5b99832",
        "title": "Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification",
        "site": "https://proceedings.mlr.press/v108/bao20a.html",
        "author": "Han Bao; Masashi Sugiyama",
        "abstract": "Complex classification performance metrics such as the F-measure and Jaccard index are often used,  in order to handle class-imbalanced cases such as information retrieval and image segmentation.  These performance metrics are not decomposable, that is, they cannot be expressed in a per-example manner,  which hinders a straightforward application of M-estimation widely used in supervised learning.  In this paper, we consider linear-fractional metrics, which are a family of classification performance metrics that encompasses many standard ones such as the F-measure and Jaccard index,  and propose methods to directly maximize performances under those metrics.  A clue to tackle their direct optimization is a calibrated surrogate utility,  which is a tractable lower bound of the true utility function representing a given metric.  We characterize sufficient conditions which make the surrogate maximization coincide with the maximization of the true utility.  Simulation results on benchmark datasets validate the effectiveness of our calibrated surrogate maximization  especially if the sample sizes are extremely small.",
        "bibtex": "@InProceedings{pmlr-v108-bao20a,\n  title = \t {Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification},\n  author =       {Bao, Han and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2337--2347},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bao20a/bao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bao20a.html},\n  abstract = \t {  Complex classification performance metrics such as the F-measure and Jaccard index are often used,  in order to handle class-imbalanced cases such as information retrieval and image segmentation.  These performance metrics are not decomposable, that is, they cannot be expressed in a per-example manner,  which hinders a straightforward application of M-estimation widely used in supervised learning.  In this paper, we consider linear-fractional metrics, which are a family of classification performance metrics that encompasses many standard ones such as the F-measure and Jaccard index,  and propose methods to directly maximize performances under those metrics.  A clue to tackle their direct optimization is a calibrated surrogate utility,  which is a tractable lower bound of the true utility function representing a given metric.  We characterize sufficient conditions which make the surrogate maximization coincide with the maximization of the true utility.  Simulation results on benchmark datasets validate the effectiveness of our calibrated surrogate maximization  especially if the sample sizes are extremely small.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bao20a/bao20a.pdf",
        "supp": "",
        "pdf_size": 1536200,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17483225190418281065&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "The University of Tokyo; RIKEN AIP + The University of Tokyo",
        "aff_domain": "ms.k.u-tokyo.ac.jp;k.u-tokyo.ac.jp",
        "email": "ms.k.u-tokyo.ac.jp;k.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";Advanced Institute for Computational Science",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.aip.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN AIP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "354522c41c",
        "title": "Causal Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v108/aglietti20a.html",
        "author": "Virginia Aglietti; Xiaoyu Lu; Andrei Paleyes; Javier Gonz\u00e1lez",
        "abstract": "This paper studies the problem of globally optimizing a variable of interest that is part of a causal model in which a sequence of interventions can be performed. This problem arises in biology, operational research, communications and, more generally, in all fields where the goal is to optimize an output metric of a system of interconnected nodes. Our approach combines ideas from causal inference, uncertainty quantification and sequential decision making. In particular, it generalizes Bayesian optimization, which treats the input variables of the objective function as independent, to scenarios where causal information is available. We show how knowing the causal graph significantly improves the ability to reason about optimal decision making strategies decreasing the optimization cost while avoiding suboptimal solutions. We propose a new algorithm called Causal Bayesian Optimization (CBO). CBO automatically balances two trade-offs: the classical exploration-exploitation and the new observation-intervention, which emerges when combining real interventional data with the estimated intervention effects computed via do-calculus. We demonstrate the practical benefits of this method in a synthetic setting and in two real-world applications.",
        "bibtex": "@InProceedings{pmlr-v108-aglietti20a,\n  title = \t {Causal Bayesian Optimization},\n  author =       {Aglietti, Virginia and Lu, Xiaoyu and Paleyes, Andrei and Gonz\u00e1lez, Javier},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3155--3164},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/aglietti20a/aglietti20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/aglietti20a.html},\n  abstract = \t {This paper studies the problem of globally optimizing a variable of interest that is part of a causal model in which a sequence of interventions can be performed. This problem arises in biology, operational research, communications and, more generally, in all fields where the goal is to optimize an output metric of a system of interconnected nodes. Our approach combines ideas from causal inference, uncertainty quantification and sequential decision making. In particular, it generalizes Bayesian optimization, which treats the input variables of the objective function as independent, to scenarios where causal information is available. We show how knowing the causal graph significantly improves the ability to reason about optimal decision making strategies decreasing the optimization cost while avoiding suboptimal solutions. We propose a new algorithm called Causal Bayesian Optimization (CBO). CBO automatically balances two trade-offs: the classical exploration-exploitation and the new observation-intervention, which emerges when combining real interventional data with the estimated intervention effects computed via do-calculus. We demonstrate the practical benefits of this method in a synthetic setting and in two real-world applications. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/aglietti20a/aglietti20a.pdf",
        "supp": "",
        "pdf_size": 982323,
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1217696596807743220&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of Warwick; Amazon, Cambridge, UK; Amazon, Cambridge, UK; Amazon, Cambridge, UK",
        "aff_domain": "warwick.ac.uk;amazon.com;amazon.com;amazon.com",
        "email": "warwick.ac.uk;amazon.com;amazon.com;amazon.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Warwick;Amazon",
        "aff_unique_dep": ";Amazon",
        "aff_unique_url": "https://www.warwick.ac.uk;https://www.amazon.com",
        "aff_unique_abbr": "Warwick;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "c2bfa9ad50",
        "title": "Causal Mosaic: Cause-Effect Inference via Nonlinear ICA and Ensemble Method",
        "site": "https://proceedings.mlr.press/v108/wu20b.html",
        "author": "Pengzhou Wu; Kenji Fukumizu",
        "abstract": "We address the problem of distinguishing cause from effect in bivariate setting. Based on recent developments in nonlinear independent component analysis (ICA), we train general nonlinear causal models that are implemented by neural networks and allow non-additive noise. Further, we build an ensemble framework, namely Causal Mosaic, which models a causal pair by a mixture of nonlinear models. We compare this method with other recent methods on artificial and real world benchmark datasets, and our method shows state-of-the-art performance.",
        "bibtex": "@InProceedings{pmlr-v108-wu20b,\n  title = \t {Causal Mosaic: Cause-Effect Inference via Nonlinear ICA and Ensemble Method},\n  author =       {Wu, Pengzhou and Fukumizu, Kenji},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1157--1167},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wu20b/wu20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wu20b.html},\n  abstract = \t {We address the problem of distinguishing cause from effect in bivariate setting. Based on recent developments in nonlinear independent component analysis (ICA), we train general nonlinear causal models that are implemented by neural networks and allow non-additive noise. Further, we build an ensemble framework, namely Causal Mosaic, which models a causal pair by a mixture of nonlinear models. We compare this method with other recent methods on artificial and real world benchmark datasets, and our method shows state-of-the-art performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wu20b/wu20b.pdf",
        "supp": "",
        "pdf_size": 1480277,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=303377177644592821&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "The Graduate University for Advanced Studies; The Institute of Statistical Mathematics",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Graduate University for Advanced Studies;Institute of Statistical Mathematics",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gucas.jp;https://www.ism.ac.jp",
        "aff_unique_abbr": "GUAS;ISM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "00300866a0",
        "title": "Causal inference in degenerate systems: An impossibility result",
        "site": "https://proceedings.mlr.press/v108/wang20i.html",
        "author": "Yue Wang; Linbo Wang",
        "abstract": "Causal relationships among variables are commonly represented via directed acyclic graphs. There are many methods in the literature to quantify the strength of arrows in a causal acyclic graph. These methods, however, have undesirable properties when the causal system represented by a directed acyclic graph is degenerate. In this paper, we characterize a degenerate causal system using multiplicity of Markov boundaries. We show that in this case, it is impossible to find an identifiable quantitative measure of causal effects that satisfy a set of natural criteria. To supplement the impossibility result, we also develop algorithms to identify degenerate causal systems from observed data. Performance of our algorithms is investigated through synthetic data analysis.",
        "bibtex": "@InProceedings{pmlr-v108-wang20i,\n  title = \t {Causal inference in degenerate systems: An impossibility result},\n  author =       {Wang, Yue and Wang, Linbo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3383--3392},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20i/wang20i.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20i.html},\n  abstract = \t {Causal relationships among variables are commonly represented via directed acyclic graphs. There are many methods in the literature to quantify the strength of arrows in a causal acyclic graph. These methods, however, have undesirable properties when the causal system represented by a directed acyclic graph is degenerate. In this paper, we characterize a degenerate causal system using multiplicity of Markov boundaries. We show that in this case, it is impossible to find an identifiable quantitative measure of causal effects that satisfy a set of natural criteria. To supplement the impossibility result, we also develop algorithms to identify degenerate causal systems from observed data. Performance of our algorithms is investigated through synthetic data analysis.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20i/wang20i.pdf",
        "supp": "",
        "pdf_size": 383996,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9802157807353625608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Institut des Hautes \tEtudes Scienti\bfiques; University of Toronto",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Institut des Hautes Etudes Scientifiques;University of Toronto",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ihes.fr;https://www.utoronto.ca",
        "aff_unique_abbr": "IHES;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "4c83c5331f",
        "title": "Censored Quantile Regression Forest",
        "site": "https://proceedings.mlr.press/v108/li20g.html",
        "author": "Alexander Hanbo Li; Jelena Bradic",
        "abstract": "Random forests are powerful non-parametric regression method but are severely limited in their usage in the presence of randomly censored observations, and naively applied can exhibit poor predictive performance due to the incurred biases. Based on a local adaptive representation of random forests, we develop its regression adjustment for randomly censored regression quantile models. Regression adjustment is based on a new estimating equation that adapts to censoring and leads to quantile score whenever the data do not exhibit censoring. The proposed procedure named censored quantile regression forest, allows us to estimate quantiles of time-to-event without any parametric modeling assumption. We establish its consistency under mild model specifications. Numerical studies showcase a clear advantage of the proposed procedure.",
        "bibtex": "@InProceedings{pmlr-v108-li20g,\n  title = \t {Censored Quantile Regression Forest},\n  author =       {Li, Alexander Hanbo and Bradic, Jelena},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2109--2119},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20g/li20g.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20g.html},\n  abstract = \t {Random forests are powerful non-parametric regression method but are severely limited in their usage in the presence of randomly censored observations, and naively applied can exhibit poor predictive performance due to the incurred biases. Based on a local adaptive representation of random forests, we develop its regression adjustment for randomly censored regression quantile models. Regression adjustment is based on a new estimating equation that adapts to censoring and leads to quantile score whenever the data do not exhibit censoring. The proposed procedure named censored quantile regression forest, allows us to estimate quantiles of time-to-event without any parametric modeling assumption. We establish its consistency under mild model specifications. Numerical studies showcase a clear advantage of the proposed procedure.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20g/li20g.pdf",
        "supp": "",
        "pdf_size": 426340,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1710102797382889620&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Amazon Research + University of California San Diego; University of California San Diego",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "Amazon;University of California, San Diego",
        "aff_unique_dep": "Amazon Research;",
        "aff_unique_url": "https://www.amazon.science;https://ucsd.edu",
        "aff_unique_abbr": "Amazon;UCSD",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7b2ecbcbf4",
        "title": "Characterization of Overlap in Observational Studies",
        "site": "https://proceedings.mlr.press/v108/oberst20a.html",
        "author": "Michael Oberst; Fredrik Johansson; Dennis Wei; Tian Gao; Gabriel Brat; David Sontag; Kush Varshney",
        "abstract": "Overlap between treatment groups is required for non-parametric estimation of causal effects.  If a subgroup of subjects always receives the same intervention, we cannot estimate the effect of intervention changes on that subgroup without further assumptions.  When overlap does not hold globally, characterizing local regions of overlap can inform the relevance of causal conclusions for new subjects, and can help guide additional data collection. To have impact, these descriptions must be interpretable for downstream users who are not machine learning experts, such as policy makers.  We formalize overlap estimation as a problem of finding minimum volume sets subject to coverage constraints and reduce this problem to binary classification with Boolean rule classifiers. We then generalize this method to estimate overlap in off-policy policy evaluation. In several real-world applications, we demonstrate that these rules have comparable accuracy to black-box estimators and provide intuitive and informative explanations that can inform policy making.",
        "bibtex": "@InProceedings{pmlr-v108-oberst20a,\n  title = \t {Characterization of Overlap in Observational Studies},\n  author =       {Oberst, Michael and Johansson, Fredrik and Wei, Dennis and Gao, Tian and Brat, Gabriel and Sontag, David and Varshney, Kush},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {788--798},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/oberst20a/oberst20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/oberst20a.html},\n  abstract = \t {Overlap between treatment groups is required for non-parametric estimation of causal effects.  If a subgroup of subjects always receives the same intervention, we cannot estimate the effect of intervention changes on that subgroup without further assumptions.  When overlap does not hold globally, characterizing local regions of overlap can inform the relevance of causal conclusions for new subjects, and can help guide additional data collection. To have impact, these descriptions must be interpretable for downstream users who are not machine learning experts, such as policy makers.  We formalize overlap estimation as a problem of finding minimum volume sets subject to coverage constraints and reduce this problem to binary classification with Boolean rule classifiers. We then generalize this method to estimate overlap in off-policy policy evaluation. In several real-world applications, we demonstrate that these rules have comparable accuracy to black-box estimators and provide intuitive and informative explanations that can inform policy making.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/oberst20a/oberst20a.pdf",
        "supp": "",
        "pdf_size": 852727,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11964625128209201159&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c8fdda846f",
        "title": "ChemBO: Bayesian Optimization of Small Organic Molecules with Synthesizable Recommendations",
        "site": "https://proceedings.mlr.press/v108/korovina20a.html",
        "author": "Ksenia Korovina; Sailun Xu; Kirthevasan Kandasamy; Willie Neiswanger; Barnabas Poczos; Jeff Schneider; Eric Xing",
        "abstract": "In applications such as molecule design or drug discovery, it is desirable to have an algorithm which recommends new candidate molecules based on the results of past tests. These molecules first need to be synthesized and then tested for objective properties. We describe ChemBO, a Bayesian optimization framework for generating and optimizing organic molecules for desired molecular properties. While most existing data-driven methods for this problem do not account for sample efficiency or fail to enforce realistic constraints on synthesizability, our approach explores synthesis graphs in a sample-efficient way and produces synthesizable candidates. We implement ChemBO as a Gaussian process model and explore existing molecular kernels for it. Moreover, we propose a novel optimal-transport based distance and kernel that accounts for graphical information explicitly. In our experiments, we demonstrate the efficacy of the proposed approach on several molecular optimization problems.",
        "bibtex": "@InProceedings{pmlr-v108-korovina20a,\n  title = \t {ChemBO: Bayesian Optimization of Small Organic Molecules with Synthesizable Recommendations},\n  author =       {Korovina, Ksenia and Xu, Sailun and Kandasamy, Kirthevasan and Neiswanger, Willie and Poczos, Barnabas and Schneider, Jeff and Xing, Eric},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3393--3403},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/korovina20a/korovina20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/korovina20a.html},\n  abstract = \t {In applications such as molecule design or drug discovery, it is desirable to have an algorithm which recommends new candidate molecules based on the results of past tests. These molecules first need to be synthesized and then tested for objective properties. We describe ChemBO, a Bayesian optimization framework for generating and optimizing organic molecules for desired molecular properties. While most existing data-driven methods for this problem do not account for sample efficiency or fail to enforce realistic constraints on synthesizability, our approach explores synthesis graphs in a sample-efficient way and produces synthesizable candidates. We implement ChemBO as a Gaussian process model and explore existing molecular kernels for it. Moreover, we propose a novel optimal-transport based distance and kernel that accounts for graphical information explicitly. In our experiments, we demonstrate the efficacy of the proposed approach on several molecular optimization problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/korovina20a/korovina20a.pdf",
        "supp": "",
        "pdf_size": 2586586,
        "gs_citation": 169,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13846213824728494145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "424ec1b0fe",
        "title": "Choosing the Sample with Lowest Loss makes SGD Robust",
        "site": "https://proceedings.mlr.press/v108/shah20a.html",
        "author": "Vatsal Shah; Xiaoxia Wu; Sujay Sanghavi",
        "abstract": "The presence of outliers can potentially significantly skew the parameters of machine learning models trained via stochastic gradient descent (SGD). In this paper we propose a simple variant of the simple SGD method: in each step, first choose a set of k samples, then from these choose the one with the smallest current loss, and do an SGD-like update with this chosen sample. Vanilla SGD corresponds to $k=1$, i.e. no choice; $k>=2$ represents a new algorithm that is however effectively minimizing a non-convex surrogate loss. Our main contribution is a theoretical analysis of the robustness properties of this idea for ML problems which are sums of convex losses; these are backed up with synthetic and small-scale neural network experiments.",
        "bibtex": "@InProceedings{pmlr-v108-shah20a,\n  title = \t {Choosing the Sample with Lowest Loss makes SGD Robust},\n  author =       {Shah, Vatsal and Wu, Xiaoxia and Sanghavi, Sujay},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2120--2130},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shah20a/shah20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shah20a.html},\n  abstract = \t {The presence of outliers can potentially significantly skew the parameters of machine learning models trained via stochastic gradient descent (SGD). In this paper we propose a simple variant of the simple SGD method: in each step, first choose a set of k samples, then from these choose the one with the smallest current loss, and do an SGD-like update with this chosen sample. Vanilla SGD corresponds to $k=1$, i.e. no choice; $k>=2$ represents a new algorithm that is however effectively minimizing a non-convex surrogate loss. Our main contribution is a theoretical analysis of the robustness properties of this idea for ML problems which are sums of convex losses; these are backed up with synthetic and small-scale neural network experiments.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shah20a/shah20a.pdf",
        "supp": "",
        "pdf_size": 1190691,
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6870479877220003761&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "UT Austin; UT Austin; UT Austin",
        "aff_domain": "utexas.edu;math.utexas.edu;mail.utexas.edu",
        "email": "utexas.edu;math.utexas.edu;mail.utexas.edu",
        "github": "https://github.com/vatsal2020/mkl",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ea2a7f8702",
        "title": "Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Balls",
        "site": "https://proceedings.mlr.press/v108/zhuo20a.html",
        "author": "Jiacheng Zhuo; Qi Lei; Alex Dimakis; Constantine Caramanis",
        "abstract": "Large-scale machine learning training suffers from two prior challenges, specifically for nuclear-norm constrained problems with distributed systems: the synchronization slowdown due to the straggling workers, and high communication costs. In this work, we propose an asynchronous Stochastic Frank Wolfe (SFW-asyn) method, which, for the first time, solves the two problems simultaneously, while successfully maintaining the same convergence rate as the vanilla SFW. We implement our algorithm in python (with MPI) to run on Amazon EC2, and demonstrate that SFW-asyn yields speed-ups almost linear to the number of machines compared to the vanilla SFW.",
        "bibtex": "@InProceedings{pmlr-v108-zhuo20a,\n  title = \t {Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Balls},\n  author =       {Zhuo, Jiacheng and Lei, Qi and Dimakis, Alex and Caramanis, Constantine},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1464--1474},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhuo20a/zhuo20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhuo20a.html},\n  abstract = \t {Large-scale machine learning training suffers from two prior challenges, specifically for nuclear-norm constrained problems with distributed systems: the synchronization slowdown due to the straggling workers, and high communication costs. In this work, we propose an asynchronous Stochastic Frank Wolfe (SFW-asyn) method, which, for the first time, solves the two problems simultaneously, while successfully maintaining the same convergence rate as the vanilla SFW. We implement our algorithm in python (with MPI) to run on Amazon EC2, and demonstrate that SFW-asyn yields speed-ups almost linear to the number of machines compared to the vanilla SFW.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhuo20a/zhuo20a.pdf",
        "supp": "",
        "pdf_size": 1103541,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6459701485230701059&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "UT Austin; UT Austin; UT Austin; UT Austin",
        "aff_domain": "utexas.dot.edu; ; ; ",
        "email": "utexas.dot.edu; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ddf61b52db",
        "title": "Communication-Efficient Distributed Optimization in Networks with Gradient Tracking and Variance Reduction",
        "site": "https://proceedings.mlr.press/v108/li20f.html",
        "author": "Boyue Li; Shicong Cen; Yuxin Chen; Yuejie Chi",
        "abstract": "Due to the imminent need to alleviate the communication burden in multi-agent and federated learning, the investigation of communication-efficient distributed optimization algorithms for empirical risk minimization has flourished recently. A large fraction of existing algorithms are developed for the master/slave setting, relying on the presence of a central parameter server. This paper focuses on distributed optimization in the network setting (also known as the decentralized setting), where each agent is only allowed to aggregate information from its neighbors over a graph. By properly adjusting the global gradient estimate via a tracking term, we first develop a communication-efficient approximate Newton-type method, called Network-DANE,  which generalizes the attractive DANE algorithm to decentralized networks. Our key algorithmic ideas can be applied, in a systematic manner, to obtain decentralized versions of other master/slave distributed algorithms. Notably, we develop Network-SVRG/SARAH, which employ stochastic variance reduction at each agent to accelerate local computations. We establish linear convergence of Network-DANE and Network-SVRG for strongly convex losses, and Network-SARAH for quadratic losses, which shed light on the impact of data homogeneity, network connectivity, and local averaging upon the rate of convergence. Numerical evidence is provided to demonstrate the appealing performance of our algorithms over competitive baselines, in terms of both communication and computation efficiency.",
        "bibtex": "@InProceedings{pmlr-v108-li20f,\n  title = \t {Communication-Efficient Distributed Optimization in Networks with Gradient Tracking and Variance Reduction},\n  author =       {Li, Boyue and Cen, Shicong and Chen, Yuxin and Chi, Yuejie},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1662--1672},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20f/li20f.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20f.html},\n  abstract = \t {Due to the imminent need to alleviate the communication burden in multi-agent and federated learning, the investigation of communication-efficient distributed optimization algorithms for empirical risk minimization has flourished recently. A large fraction of existing algorithms are developed for the master/slave setting, relying on the presence of a central parameter server. This paper focuses on distributed optimization in the network setting (also known as the decentralized setting), where each agent is only allowed to aggregate information from its neighbors over a graph. By properly adjusting the global gradient estimate via a tracking term, we first develop a communication-efficient approximate Newton-type method, called Network-DANE,  which generalizes the attractive DANE algorithm to decentralized networks. Our key algorithmic ideas can be applied, in a systematic manner, to obtain decentralized versions of other master/slave distributed algorithms. Notably, we develop Network-SVRG/SARAH, which employ stochastic variance reduction at each agent to accelerate local computations. We establish linear convergence of Network-DANE and Network-SVRG for strongly convex losses, and Network-SARAH for quadratic losses, which shed light on the impact of data homogeneity, network connectivity, and local averaging upon the rate of convergence. Numerical evidence is provided to demonstrate the appealing performance of our algorithms over competitive baselines, in terms of both communication and computation efficiency.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20f/li20f.pdf",
        "supp": "",
        "pdf_size": 674595,
        "gs_citation": 136,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=912737045997244005&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8466b1733b",
        "title": "Competing Bandits in Matching Markets",
        "site": "https://proceedings.mlr.press/v108/liu20c.html",
        "author": "Lydia T. Liu; Horia Mania; Michael Jordan",
        "abstract": "Stable matching, a classical model for two-sided markets, has long been studied assuming known preferences. In reality agents often have to learn about their preferences through exploration. With the advent of massive online markets powered by data-driven matching platforms, it has become necessary to better understand the interplay between learning and market objectives. We propose a statistical learning model in which one side of the market does not have a priori knowledge about its preferences for the other side and is required to learn these from stochastic rewards. Our model extends the standard multi-armed bandits framework to multiple players, with the added feature that arms have preferences over players. We study both centralized and decentralized approaches to this problem and show surprising exploration-exploitation trade-offs compared to the single player multi-armed bandits setting.",
        "bibtex": "@InProceedings{pmlr-v108-liu20c,\n  title = \t {Competing Bandits in Matching Markets},\n  author =       {Liu, Lydia T. and Mania, Horia and Jordan, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1618--1628},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/liu20c/liu20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/liu20c.html},\n  abstract = \t {Stable matching, a classical model for two-sided markets, has long been studied assuming known preferences. In reality agents often have to learn about their preferences through exploration. With the advent of massive online markets powered by data-driven matching platforms, it has become necessary to better understand the interplay between learning and market objectives. We propose a statistical learning model in which one side of the market does not have a priori knowledge about its preferences for the other side and is required to learn these from stochastic rewards. Our model extends the standard multi-armed bandits framework to multiple players, with the added feature that arms have preferences over players. We study both centralized and decentralized approaches to this problem and show surprising exploration-exploitation trade-offs compared to the single player multi-armed bandits setting. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/liu20c/liu20c.pdf",
        "supp": "",
        "pdf_size": 617626,
        "gs_citation": 124,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11249279173808175162&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;cs.berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;cs.berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d7e15a2f4b",
        "title": "Computing Tight Differential Privacy Guarantees Using FFT",
        "site": "https://proceedings.mlr.press/v108/koskela20b.html",
        "author": "Antti Koskela; Joonas J\u00e4lk\u00f6; Antti Honkela",
        "abstract": "Differentially private (DP) machine learning has recently become popular. The privacy loss of DP algorithms is commonly reported using (e.d)-DP. In this paper, we propose a numerical accountant for evaluating the privacy loss for algorithms with continuous one dimensional output. This accountant can be applied to the subsampled multidimensional Gaussian mechanism which underlies the popular DP stochastic gradient descent. The proposed method is based on a numerical approximation of an integral formula which gives the exact (e.d)-values. The approximation is carried out by discretising the integral and by evaluating discrete convolutions using the fast Fourier transform algorithm. We give theoretical error bounds which show the convergence of the approximation and guarantee its accuracy to an arbitrary degree. We give both theoretical error bounds and numerical error estimates for the approximation. Experimental comparisons with state-of-the-art techniques demonstrate significant improvements in bound tightness and/or computation time.",
        "bibtex": "@InProceedings{pmlr-v108-koskela20b,\n  title = \t {Computing Tight Differential Privacy Guarantees Using FFT},\n  author =       {Koskela, Antti and J\\\"alk\\\"o, Joonas and Honkela, Antti},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2560--2569},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/koskela20b/koskela20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/koskela20b.html},\n  abstract = \t {Differentially private (DP) machine learning has recently become popular. The privacy loss of DP algorithms is commonly reported using (e.d)-DP. In this paper, we propose a numerical accountant for evaluating the privacy loss for algorithms with continuous one dimensional output. This accountant can be applied to the subsampled multidimensional Gaussian mechanism which underlies the popular DP stochastic gradient descent. The proposed method is based on a numerical approximation of an integral formula which gives the exact (e.d)-values. The approximation is carried out by discretising the integral and by evaluating discrete convolutions using the fast Fourier transform algorithm. We give theoretical error bounds which show the convergence of the approximation and guarantee its accuracy to an arbitrary degree. We give both theoretical error bounds and numerical error estimates for the approximation. Experimental comparisons with state-of-the-art techniques demonstrate significant improvements in bound tightness and/or computation time.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/koskela20b/koskela20b.pdf",
        "supp": "",
        "pdf_size": 585002,
        "gs_citation": 131,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9873215856124366516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "University of Helsinki; Aalto University; University of Helsinki",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Helsinki;Aalto University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.helsinki.fi;https://www.aalto.fi",
        "aff_unique_abbr": "UH;Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "c339bf6b44",
        "title": "Conditional Importance Sampling for Off-Policy Learning",
        "site": "https://proceedings.mlr.press/v108/rowland20b.html",
        "author": "Mark Rowland; Anna Harutyunyan; Hado Hasselt; Diana Borsa; Tom Schaul; Remi Munos; Will Dabney",
        "abstract": "The principal contribution of this paper is a conceptual framework for off-policy reinforcement learning, based on conditional expectations of importance sampling ratios. This framework yields new perspectives and understanding of existing off-policy algorithms, and reveals a broad space of unexplored algorithms. We theoretically analyse this space, and concretely investigate several algorithms that arise from this framework.",
        "bibtex": "@InProceedings{pmlr-v108-rowland20b,\n  title = \t {Conditional Importance Sampling for Off-Policy Learning},\n  author =       {Rowland, Mark and Harutyunyan, Anna and van Hasselt, Hado and Borsa, Diana and Schaul, Tom and Munos, Remi and Dabney, Will},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {45--55},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rowland20b/rowland20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rowland20b.html},\n  abstract = \t {The principal contribution of this paper is a conceptual framework for off-policy reinforcement learning, based on conditional expectations of importance sampling ratios. This framework yields new perspectives and understanding of existing off-policy algorithms, and reveals a broad space of unexplored algorithms. We theoretically analyse this space, and concretely investigate several algorithms that arise from this framework.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rowland20b/rowland20b.pdf",
        "supp": "",
        "pdf_size": 2610278,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7361859834915442343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "480d5cfbb0",
        "title": "Conditional Linear Regression",
        "site": "https://proceedings.mlr.press/v108/calderon20a.html",
        "author": "Diego Calderon; Brendan Juba; Sirui Li; Zongyi Li; Lisa Ruan",
        "abstract": "Work in machine learning and statistics commonly focuses on building models that capture the vast majority of data, possibly ignoring a segment of the population as outliers. However, there may not exist a good, simple model for the distribution, so we seek to find a small subset where there exists such a model. We give a computationally efficient algorithm with theoretical analysis for the conditional linear regression task, which is the joint task of identifying a significant portion of the data distribution, described by a k-DNF, along with a linear predictor on that portion with a small loss. In contrast to work in robust statistics on small subsets, our loss bounds do not feature a dependence on the density of the portion we fit, and compared to previous work on conditional linear regression, our algorithm\u2019s running time scales polynomially with the sparsity of the linear predictor.  We also demonstrate empirically that our algorithm can leverage this advantage to obtain a k-DNF with a better linear predictor in practice.",
        "bibtex": "@InProceedings{pmlr-v108-calderon20a,\n  title = \t {Conditional Linear Regression},\n  author =       {Calderon, Diego and Juba, Brendan and Li, Sirui and Li, Zongyi and Ruan, Lisa},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2164--2173},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/calderon20a/calderon20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/calderon20a.html},\n  abstract = \t {Work in machine learning and statistics commonly focuses on building models that capture the vast majority of data, possibly ignoring a segment of the population as outliers. However, there may not exist a good, simple model for the distribution, so we seek to find a small subset where there exists such a model. We give a computationally efficient algorithm with theoretical analysis for the conditional linear regression task, which is the joint task of identifying a significant portion of the data distribution, described by a k-DNF, along with a linear predictor on that portion with a small loss. In contrast to work in robust statistics on small subsets, our loss bounds do not feature a dependence on the density of the portion we fit, and compared to previous work on conditional linear regression, our algorithm\u2019s running time scales polynomially with the sparsity of the linear predictor.  We also demonstrate empirically that our algorithm can leverage this advantage to obtain a k-DNF with a better linear predictor in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/calderon20a/calderon20a.pdf",
        "supp": "",
        "pdf_size": 422608,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11256989609005383933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "UIUC; Washington U. St. Louis; MIT; Caltech; Harvard",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Washington University in St. Louis;Massachusetts Institute of Technology;California Institute of Technology;Harvard University",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www illinois.edu;https://wustl.edu;https://web.mit.edu;https://www.caltech.edu;https://www.harvard.edu",
        "aff_unique_abbr": "UIUC;WUSTL;MIT;Caltech;Harvard",
        "aff_campus_unique_index": "0;1;3",
        "aff_campus_unique": "Urbana-Champaign;St. Louis;;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "89f7b91b58",
        "title": "Conservative Exploration in Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v108/garcelon20a.html",
        "author": "Evrard Garcelon; Mohammad Ghavamzadeh; Alessandro Lazaric; Matteo Pirotta",
        "abstract": "While learning in an unknown Markov Decision Process (MDP), an agent should trade off exploration to discover new information about the MDP, and exploitation of the current knowledge to maximize the reward. Although the agent will eventually learn a good or optimal policy, there is no guarantee on the quality of the intermediate policies. This lack of control is undesired in real-world applications where a minimum requirement is that the executed policies are guaranteed to perform at least as well as an existing baseline. In this paper, we introduce the notion of conservative exploration for average reward and finite horizon problems. We present two optimistic algorithms that guarantee (w.h.p.) that the conservative constraint is never violated during learning. We derive regret bounds showing that being conservative does not hinder the learning ability of these algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-garcelon20a,\n  title = \t {Conservative Exploration in Reinforcement Learning},\n  author =       {Garcelon, Evrard and Ghavamzadeh, Mohammad and Lazaric, Alessandro and Pirotta, Matteo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1431--1441},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/garcelon20a/garcelon20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/garcelon20a.html},\n  abstract = \t {While learning in an unknown Markov Decision Process (MDP), an agent should trade off exploration to discover new information about the MDP, and exploitation of the current knowledge to maximize the reward. Although the agent will eventually learn a good or optimal policy, there is no guarantee on the quality of the intermediate policies. This lack of control is undesired in real-world applications where a minimum requirement is that the executed policies are guaranteed to perform at least as well as an existing baseline. In this paper, we introduce the notion of conservative exploration for average reward and finite horizon problems. We present two optimistic algorithms that guarantee (w.h.p.) that the conservative constraint is never violated during learning. We derive regret bounds showing that being conservative does not hinder the learning ability of these algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/garcelon20a/garcelon20a.pdf",
        "supp": "",
        "pdf_size": 835786,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16653746426590273641&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5550b684dc",
        "title": "Constructing a provably adversarially-robust classifier from a high accuracy one",
        "site": "https://proceedings.mlr.press/v108/gluch20a.html",
        "author": "Grzegorz Gluch; R\u00fcdiger Urbanke",
        "abstract": "Modern machine learning models with very high accuracy have been shown to be vulnerable to small, adversarially chosen perturbations of the input. Given black-box access to a high-accuracy classifier f, we show how to construct a new classifier g that has high accuracy and is also robust to adversarial L2-bounded perturbations. Our algorithm builds upon the framework of randomized smoothing that has been recently shown to outperform all previous defenses against L2-bounded adversaries. Using techniques like random partitions and doubling dimension, we are able to bound the adversarial error of g in terms of the optimum error. In this paper we focus on our conceptual contribution, but we do present two examples to illustrate our framework. We will argue that, under some assumptions, our bounds are optimal for these cases.",
        "bibtex": "@InProceedings{pmlr-v108-gluch20a,\n  title = \t {Constructing a provably adversarially-robust classifier from a high accuracy one},\n  author =       {Gluch, Grzegorz and Urbanke, R\\\"udiger},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3674--3684},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gluch20a/gluch20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gluch20a.html},\n  abstract = \t {Modern machine learning models with very high accuracy have been shown to be vulnerable to small, adversarially chosen perturbations of the input. Given black-box access to a high-accuracy classifier f, we show how to construct a new classifier g that has high accuracy and is also robust to adversarial L2-bounded perturbations. Our algorithm builds upon the framework of randomized smoothing that has been recently shown to outperform all previous defenses against L2-bounded adversaries. Using techniques like random partitions and doubling dimension, we are able to bound the adversarial error of g in terms of the optimum error. In this paper we focus on our conceptual contribution, but we do present two examples to illustrate our framework. We will argue that, under some assumptions, our bounds are optimal for these cases.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/gluch20a/gluch20a.pdf",
        "supp": "",
        "pdf_size": 473315,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6387644266670512302&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "EPFL; EPFL",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "4ddcbc621a",
        "title": "Context Mover\u2019s Distance & Barycenters: Optimal Transport of Contexts for Building Representations",
        "site": "https://proceedings.mlr.press/v108/singh20a.html",
        "author": "Sidak Pal Singh; Andreas Hug; Aymeric Dieuleveut; Martin Jaggi",
        "abstract": "We present a framework for building unsupervised representations of entities and their compositions, where each entity is viewed as a probability distribution rather than a vector embedding. In particular, this distribution is supported over the contexts which co-occur with the entity and are embedded in a suitable low-dimensional space. This enables us to consider representation learning from the perspective of Optimal Transport and take advantage of its tools such as Wasserstein distance and barycenters. We elaborate how the method can be applied for obtaining unsupervised representations of text and illustrate the performance (quantitatively as well as qualitatively) on tasks such as measuring sentence similarity, word entailment and similarity, where we empirically observe significant gains (e.g., 4.1% relative improvement over Sent2vec, GenSen).The key benefits of the proposed approach include: (a) capturing uncertainty and polysemy via modeling the entities as distributions, (b) utilizing the underlying geometry of the particular task (with the ground cost), (c) simultaneously providing interpretability with the notion of optimal transport between contexts and (d) easy applicability on top of existing point embedding methods. The code, as well as pre-built histograms, are available under https://github.com/context-mover/.",
        "bibtex": "@InProceedings{pmlr-v108-singh20a,\n  title = \t {Context Mover\u2019s Distance & Barycenters: Optimal Transport of Contexts for Building Representations},\n  author =       {Singh, Sidak Pal and Hug, Andreas and Dieuleveut, Aymeric and Jaggi, Martin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3437--3449},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/singh20a/singh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/singh20a.html},\n  abstract = \t {We present a framework for building unsupervised representations of entities and their compositions, where each entity is viewed as a probability distribution rather than a vector embedding. In particular, this distribution is supported over the contexts which co-occur with the entity and are embedded in a suitable low-dimensional space. This enables us to consider representation learning from the perspective of Optimal Transport and take advantage of its tools such as Wasserstein distance and barycenters. We elaborate how the method can be applied for obtaining unsupervised representations of text and illustrate the performance (quantitatively as well as qualitatively) on tasks such as measuring sentence similarity, word entailment and similarity, where we empirically observe significant gains (e.g., 4.1% relative improvement over Sent2vec, GenSen).The key benefits of the proposed approach include: (a) capturing uncertainty and polysemy via modeling the entities as distributions, (b) utilizing the underlying geometry of the particular task (with the ground cost), (c) simultaneously providing interpretability with the notion of optimal transport between contexts and (d) easy applicability on top of existing point embedding methods. The code, as well as pre-built histograms, are available under https://github.com/context-mover/.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/singh20a/singh20a.pdf",
        "supp": "",
        "pdf_size": 2201422,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1480733432414277760&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "EPFL; EPFL; EPFL and \u00c9cole Polytechnique; EPFL",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/context-mover/",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "01d0977341",
        "title": "Contextual Combinatorial Volatile Multi-armed Bandit with Adaptive Discretization",
        "site": "https://proceedings.mlr.press/v108/nika20a.html",
        "author": "Andi Nika; Sepehr Elahi; Cem Tekin",
        "abstract": "We consider contextual combinatorial volatile multi-armed bandit (CCV-MAB), in which at each round, the learner observes a set of available base arms and their contexts, and then, selects a super arm that contains $K$ base arms in order to maximize its cumulative reward. Under the semi-bandit feedback setting and assuming that the contexts lie in a space ${\\cal X}$ endowed with the Euclidean norm and that the expected base arm outcomes (expected rewards) are Lipschitz continuous in the contexts (expected base arm outcomes), we propose an algorithm called Adaptive Contextual Combinatorial Upper Confidence Bound (ACC-UCB). This algorithm, which adaptively discretizes ${\\cal X}$ to form estimates of base arm outcomes and uses an $\\alpha$-approximation oracle as a subroutine to select a super arm in each round, achieves $\\tilde{O} ( T^{(\\bar{D}+1)/(\\bar{D}+2) + \\epsilon}  )$ regret for any $\\epsilon>0$, where $\\bar{D}$ represents the approximate optimality dimension related to ${\\cal X}$. This dimension captures both the benignness of the base arm arrivals and the structure of the expected reward. In addition, we provide a recipe for obtaining more optimistic regret bounds by taking into account the volatility of the base arms and show that ACC-UCB achieves significant performance gains compared to the state-of-the-art for worker selection in mobile crowdsourcing.",
        "bibtex": "@InProceedings{pmlr-v108-nika20a,\n  title = \t {Contextual Combinatorial Volatile Multi-armed Bandit with Adaptive Discretization},\n  author =       {Nika, Andi and Elahi, Sepehr and Tekin, Cem},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1486--1496},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/nika20a/nika20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/nika20a.html},\n  abstract = \t {We consider contextual combinatorial volatile multi-armed bandit (CCV-MAB), in which at each round, the learner observes a set of available base arms and their contexts, and then, selects a super arm that contains $K$ base arms in order to maximize its cumulative reward. Under the semi-bandit feedback setting and assuming that the contexts lie in a space ${\\cal X}$ endowed with the Euclidean norm and that the expected base arm outcomes (expected rewards) are Lipschitz continuous in the contexts (expected base arm outcomes), we propose an algorithm called Adaptive Contextual Combinatorial Upper Confidence Bound (ACC-UCB). This algorithm, which adaptively discretizes ${\\cal X}$ to form estimates of base arm outcomes and uses an $\\alpha$-approximation oracle as a subroutine to select a super arm in each round, achieves $\\tilde{O} ( T^{(\\bar{D}+1)/(\\bar{D}+2) + \\epsilon}  )$ regret for any $\\epsilon>0$, where $\\bar{D}$ represents the approximate optimality dimension related to ${\\cal X}$. This dimension captures both the benignness of the base arm arrivals and the structure of the expected reward. In addition, we provide a recipe for obtaining more optimistic regret bounds by taking into account the volatility of the base arms and show that ACC-UCB achieves significant performance gains compared to the state-of-the-art for worker selection in mobile crowdsourcing.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/nika20a/nika20a.pdf",
        "supp": "",
        "pdf_size": 688258,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5322525197802631163&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical and Electronics Engineering, Bilkent University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Bilkent University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Bilkent University, Ankara, Turkey",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Bilkent University",
        "aff_unique_dep": "Department of Electrical and Electronics Engineering",
        "aff_unique_url": "https://www.bilkent.edu.tr",
        "aff_unique_abbr": "Bilkent",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ankara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "8be4619bb0",
        "title": "Contextual Constrained Learning for Dose-Finding Clinical Trials",
        "site": "https://proceedings.mlr.press/v108/lee20a.html",
        "author": "Hyun-Suk Lee; Cong Shen; James Jordon; Mihaela Schaar",
        "abstract": "Clinical trials in the medical domain are constrained by budgets. The number of patients that can be recruited is therefore limited. When a patient population is heterogeneous, this creates difficulties in learning subgroup specific responses to a particular drug and especially for a variety of dosages. In addition, patient recruitment can be difficult by the fact that clinical trials do not aim to provide a benefit to any given patient in the trial. In this paper, we propose C3T-Budget, a contextual constrained clinical trial algorithm for dose-finding under both budget and safety constraints. The algorithm aims to maximize drug efficacy within the clinical trial while also learning about the drug being tested. C3T-Budget recruits patients with consideration of the remaining budget, the remaining time, and the characteristics of each group, such as the population distribution, estimated expected efficacy, and estimation credibility. In addition, the algorithm aims to avoid unsafe dosages. These characteristics are further illustrated in a simulated clinical trial study, which corroborates the theoretical analysis and demonstrates an efficient budget usage as well as a balanced learning-treatment trade-off.",
        "bibtex": "@InProceedings{pmlr-v108-lee20a,\n  title = \t {Contextual Constrained Learning for Dose-Finding Clinical Trials},\n  author =       {Lee, Hyun-Suk and Shen, Cong and Jordon, James and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2645--2654},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lee20a/lee20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lee20a.html},\n  abstract = \t {Clinical trials in the medical domain are constrained by budgets. The number of patients that can be recruited is therefore limited. When a patient population is heterogeneous, this creates difficulties in learning subgroup specific responses to a particular drug and especially for a variety of dosages. In addition, patient recruitment can be difficult by the fact that clinical trials do not aim to provide a benefit to any given patient in the trial. In this paper, we propose C3T-Budget, a contextual constrained clinical trial algorithm for dose-finding under both budget and safety constraints. The algorithm aims to maximize drug efficacy within the clinical trial while also learning about the drug being tested. C3T-Budget recruits patients with consideration of the remaining budget, the remaining time, and the characteristics of each group, such as the population distribution, estimated expected efficacy, and estimation credibility. In addition, the algorithm aims to avoid unsafe dosages. These characteristics are further illustrated in a simulated clinical trial study, which corroborates the theoretical analysis and demonstrates an efficient budget usage as well as a balanced learning-treatment trade-off.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lee20a/lee20a.pdf",
        "supp": "",
        "pdf_size": 408533,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15473235325300566820&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ca33f00ca9",
        "title": "Contextual Online False Discovery Rate Control",
        "site": "https://proceedings.mlr.press/v108/chen20b.html",
        "author": "Shiyun Chen; Shiva Kasiviswanathan",
        "abstract": "Multiple hypothesis testing, a situation when we wish to consider many hypotheses, is a core problem in statistical inference that arises in almost every scientific field. In this setting, controlling the false discovery rate (FDR), which is the expected proportion of type I error, is an important challenge for making meaningful inferences. In this paper, we consider a setting where an ordered (possibly infinite) sequence of hypotheses arrives in a stream, and for each hypothesis we observe a p-value along with a set of features specific to that hypothesis. The decision whether or not to reject the current hypothesis must be made immediately at each time step, before the next hypothesis is observed. This model provides a general way of leveraging the side (contextual) information in the data to help maximize the number of discoveries while controlling the FDR.We propose a new class of powerful online testing procedures, where the rejection thresholds are learned sequentially by incorporating contextual information and previous results. We prove that any rule in this class controls online FDR under some standard assumptions. We then focus on a subclass of these procedures, based on weighting the rejection thresholds, to derive a practical algorithm that learns a parametric weight function in an online fashion to gain more discoveries. We also theoretically prove that our proposed procedures, under some easily verifiable assumptions, would lead to an increase of statistical power over a popular online testing procedure proposed by Javanmard and Montanari (2018). Finally, we demonstrate the superior performance of our procedure, by comparing it to state-of-the-art online multiple testing procedures, on both synthetic data and real data generated from different applications.",
        "bibtex": "@InProceedings{pmlr-v108-chen20b,\n  title = \t {Contextual Online False Discovery Rate Control},\n  author =       {Chen, Shiyun and Kasiviswanathan, Shiva},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {952--961},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chen20b/chen20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chen20b.html},\n  abstract = \t {Multiple hypothesis testing, a situation when we wish to consider many hypotheses, is a core problem in statistical inference that arises in almost every scientific field. In this setting, controlling the false discovery rate (FDR), which is the expected proportion of type I error, is an important challenge for making meaningful inferences. In this paper, we consider a setting where an ordered (possibly infinite) sequence of hypotheses arrives in a stream, and for each hypothesis we observe a p-value along with a set of features specific to that hypothesis. The decision whether or not to reject the current hypothesis must be made immediately at each time step, before the next hypothesis is observed. This model provides a general way of leveraging the side (contextual) information in the data to help maximize the number of discoveries while controlling the FDR.We propose a new class of powerful online testing procedures, where the rejection thresholds are learned sequentially by incorporating contextual information and previous results. We prove that any rule in this class controls online FDR under some standard assumptions. We then focus on a subclass of these procedures, based on weighting the rejection thresholds, to derive a practical algorithm that learns a parametric weight function in an online fashion to gain more discoveries. We also theoretically prove that our proposed procedures, under some easily verifiable assumptions, would lead to an increase of statistical power over a popular online testing procedure proposed by Javanmard and Montanari (2018). Finally, we demonstrate the superior performance of our procedure, by comparing it to state-of-the-art online multiple testing procedures, on both synthetic data and real data generated from different applications.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chen20b/chen20b.pdf",
        "supp": "",
        "pdf_size": 335856,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12216095572232012944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of California San Diego; Amazon, Sunnyvale, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, San Diego;Amazon",
        "aff_unique_dep": ";Amazon",
        "aff_unique_url": "https://ucsd.edu;https://www.amazon.com",
        "aff_unique_abbr": "UCSD;Amazon",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "San Diego;Sunnyvale",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4c31ad972d",
        "title": "Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling",
        "site": "https://proceedings.mlr.press/v108/mutny20a.html",
        "author": "Mojmir Mutny; Michal Derezinski; Andreas Krause",
        "abstract": "We analyze the convergence rate of the randomized Newton-like method        introduced by Qu et. al. (2016) for smooth and convex        objectives, which uses random coordinate        blocks of a Hessian-over-approximation matrix        M instead of the true Hessian. The convergence analysis of the algorithm is          challenging because of its complex dependence on the structure        of M. However, we show that when the coordinate blocks are        sampled with probability         proportional to their determinant, the convergence rate depends solely on the eigenvalue distribution of matrix M, and has an analytically tractable form. To         do so, we derive a fundamental new expectation formula for        determinantal point processes. We show that determinantal        sampling allows us to reason about the optimal subset size of        blocks in terms of the spectrum of M. Additionally, we        provide a        numerical evaluation of our analysis,        demonstrating cases where determinantal sampling is superior        or on par with uniform sampling.",
        "bibtex": "@InProceedings{pmlr-v108-mutny20a,\n  title = \t {Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling},\n  author =       {Mutny, Mojmir and Derezinski, Michal and Krause, Andreas},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3110--3120},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mutny20a/mutny20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mutny20a.html},\n  abstract = \t {We analyze the convergence rate of the randomized Newton-like method        introduced by Qu et. al. (2016) for smooth and convex        objectives, which uses random coordinate        blocks of a Hessian-over-approximation matrix        M instead of the true Hessian. The convergence analysis of the algorithm is          challenging because of its complex dependence on the structure        of M. However, we show that when the coordinate blocks are        sampled with probability         proportional to their determinant, the convergence rate depends solely on the eigenvalue distribution of matrix M, and has an analytically tractable form. To         do so, we derive a fundamental new expectation formula for        determinantal point processes. We show that determinantal        sampling allows us to reason about the optimal subset size of        blocks in terms of the spectrum of M. Additionally, we        provide a        numerical evaluation of our analysis,        demonstrating cases where determinantal sampling is superior        or on par with uniform sampling.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mutny20a/mutny20a.pdf",
        "supp": "",
        "pdf_size": 2108312,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11638550957122335721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, ETH Zurich, Switzerland; Department of Statistics, University of California, Berkeley; Department of Computer Science, ETH Zurich, Switzerland",
        "aff_domain": "inf.ethz.ch;berkeley.edu;inf.ethz.ch",
        "email": "inf.ethz.ch;berkeley.edu;inf.ethz.ch",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "ETH Zurich;University of California, Berkeley",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics",
        "aff_unique_url": "https://www.ethz.ch;https://www.berkeley.edu",
        "aff_unique_abbr": "ETHZ;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "cbd4c07f12",
        "title": "Convergence Rates of Gradient Descent and MM Algorithms for Bradley-Terry Models",
        "site": "https://proceedings.mlr.press/v108/vojnovic20a.html",
        "author": "Milan Vojnovic; Se-Young Yun; Kaifang Zhou",
        "abstract": "We present tight convergence rate bounds for gradient descent and MM algorithms for maximum likelihood (ML) estimation and maximum a posteriori probability (MAP) estimation of a popular Bayesian inference method, for Bradley-Terry models of ranking data. Our results show that MM algorithms have the same convergence rate, up to a constant factor, as gradient descent algorithms with optimal constant step size. For the ML estimation objective, the convergence is linear with the rate crucially determined by the algebraic connectivity of the matrix of item pair co-occurrences in observed comparison data. For the MAP estimation objective, we show that the convergence rate is also linear, with the rate determined by a parameter of the prior distribution in a way that can make convergence arbitrarily slow for small values of this parameter. The limit of small values of this parameter corresponds to a flat, non-informative prior distribution.",
        "bibtex": "@InProceedings{pmlr-v108-vojnovic20a,\n  title = \t {Convergence Rates of Gradient Descent and MM Algorithms for Bradley-Terry Models},\n  author =       {Vojnovic, Milan and Yun, Se-Young and Zhou, Kaifang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1254--1264},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/vojnovic20a/vojnovic20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/vojnovic20a.html},\n  abstract = \t {We present tight convergence rate bounds for gradient descent and MM algorithms for maximum likelihood (ML) estimation and maximum a posteriori probability (MAP) estimation of a popular Bayesian inference method, for Bradley-Terry models of ranking data. Our results show that MM algorithms have the same convergence rate, up to a constant factor, as gradient descent algorithms with optimal constant step size. For the ML estimation objective, the convergence is linear with the rate crucially determined by the algebraic connectivity of the matrix of item pair co-occurrences in observed comparison data. For the MAP estimation objective, we show that the convergence rate is also linear, with the rate determined by a parameter of the prior distribution in a way that can make convergence arbitrarily slow for small values of this parameter. The limit of small values of this parameter corresponds to a flat, non-informative prior distribution.  }\n}",
        "pdf": "http://proceedings.mlr.press/v108/vojnovic20a/vojnovic20a.pdf",
        "supp": "",
        "pdf_size": 557782,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8803120051892504033&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "db651a7e3c",
        "title": "Convergence Rates of Smooth Message Passing with Rounding in Entropy-Regularized MAP Inference",
        "site": "https://proceedings.mlr.press/v108/lee20b.html",
        "author": "Jonathan Lee; Aldo Pacchiano; Michael Jordan",
        "abstract": "Maximum a posteriori (MAP) inference is a fundamental computational paradigm for statistical inference. In the setting of graphical models, MAP inference entails solving a combinatorial optimization problem to find the most likely configuration of the discrete-valued model. Linear programming (LP) relaxations in the Sherali-Adams hierarchy are widely used to attempt to solve this problem, and smooth message passing algorithms have been proposed to solve regularized versions of these LPs with great success. This paper leverages recent work in entropy-regularized LPs to analyze convergence rates of a class of edge-based smooth message passing algorithms to epsilon-optimality in the relaxation. With an appropriately chosen regularization constant, we present a theoretical guarantee on the number of iterations sufficient to recover the true integral MAP solution when the LP is tight and the solution is unique.",
        "bibtex": "@InProceedings{pmlr-v108-lee20b,\n  title = \t {Convergence Rates of Smooth Message Passing with Rounding in Entropy-Regularized MAP Inference},\n  author =       {Lee, Jonathan and Pacchiano, Aldo and Jordan, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3003--3014},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lee20b/lee20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lee20b.html},\n  abstract = \t {Maximum a posteriori (MAP) inference is a fundamental computational paradigm for statistical inference. In the setting of graphical models, MAP inference entails solving a combinatorial optimization problem to find the most likely configuration of the discrete-valued model. Linear programming (LP) relaxations in the Sherali-Adams hierarchy are widely used to attempt to solve this problem, and smooth message passing algorithms have been proposed to solve regularized versions of these LPs with great success. This paper leverages recent work in entropy-regularized LPs to analyze convergence rates of a class of edge-based smooth message passing algorithms to epsilon-optimality in the relaxation. With an appropriately chosen regularization constant, we present a theoretical guarantee on the number of iterations sufficient to recover the true integral MAP solution when the LP is tight and the solution is unique.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lee20b/lee20b.pdf",
        "supp": "",
        "pdf_size": 1095990,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16500092818434080718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; UC Berkeley; UC Berkeley",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Stanford University;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;UC Berkeley",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Stanford;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bf52c48c89",
        "title": "Convex Geometry of Two-Layer ReLU Networks: Implicit Autoencoding and Interpretable Models",
        "site": "https://proceedings.mlr.press/v108/ergen20a.html",
        "author": "Tolga Ergen; Mert Pilanci",
        "abstract": "We develop a convex analytic framework for ReLU neural networks which elucidates the inner workings of hidden neurons and their function space characteristics. We show that rectified linear units in neural networks act as convex regularizers, where simple solutions are encouraged via extreme points of a certain convex set. For one dimensional regression and classification, we prove that finite two-layer ReLU networks with norm regularization yield linear spline interpolation. In  the more general higher dimensional case, we show that the training problem for two-layer networks can be cast as a convex optimization problem with infinitely many constraints. We then provide a family of convex relaxations to approximate the solution, and a cutting-plane algorithm to improve the relaxations. We derive conditions for the exactness of the relaxations and provide simple closed form formulas for the optimal neural network weights in certain cases.  Our results show that the hidden neurons of a ReLU network can be interpreted as convex autoencoders of the input layer. We also establish a connection to $\\ell_0$-$\\ell_1$ equivalence for neural networks analogous to the minimal cardinality solutions in compressed sensing. Extensive experimental results show that the proposed approach yields interpretable and accurate models.",
        "bibtex": "@InProceedings{pmlr-v108-ergen20a,\n  title = \t {Convex Geometry of Two-Layer ReLU Networks: Implicit Autoencoding and Interpretable Models},\n  author =       {Ergen, Tolga and Pilanci, Mert},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4024--4033},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ergen20a/ergen20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ergen20a.html},\n  abstract = \t {We develop a convex analytic framework for ReLU neural networks which elucidates the inner workings of hidden neurons and their function space characteristics. We show that rectified linear units in neural networks act as convex regularizers, where simple solutions are encouraged via extreme points of a certain convex set. For one dimensional regression and classification, we prove that finite two-layer ReLU networks with norm regularization yield linear spline interpolation. In  the more general higher dimensional case, we show that the training problem for two-layer networks can be cast as a convex optimization problem with infinitely many constraints. We then provide a family of convex relaxations to approximate the solution, and a cutting-plane algorithm to improve the relaxations. We derive conditions for the exactness of the relaxations and provide simple closed form formulas for the optimal neural network weights in certain cases.  Our results show that the hidden neurons of a ReLU network can be interpreted as convex autoencoders of the input layer. We also establish a connection to $\\ell_0$-$\\ell_1$ equivalence for neural networks analogous to the minimal cardinality solutions in compressed sensing. Extensive experimental results show that the proposed approach yields interpretable and accurate models.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ergen20a/ergen20a.pdf",
        "supp": "",
        "pdf_size": 900364,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16751872050373703268&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Stanford University; Stanford University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c9858ecd71",
        "title": "Coping With Simulators That Don\u2019t Always Return",
        "site": "https://proceedings.mlr.press/v108/warrington20a.html",
        "author": "Andrew Warrington; Saeid Naderiparizi; Frank Wood",
        "abstract": "Deterministic models are approximations of reality that are easy to interpret and often easier to build than stochastic alternatives. Unfortunately, as nature is capricious, observational data can never be fully explained by deterministic models in practice. Observation and process noise need to be added to adapt deterministic models to behave stochastically, such that they are capable of explaining and extrapolating from noisy data. We investigate and address computational inefficiencies that arise from adding process noise to deterministic simulators that fail to return for certain inputs; a property we describe as \u2019brittle\u2019. We show how to train a conditional normalizing flow to propose perturbations such that the simulator succeeds with high probability, increasing computational efficiency.",
        "bibtex": "@InProceedings{pmlr-v108-warrington20a,\n  title = \t {Coping With Simulators That Don\u2019t Always Return},\n  author =       {Warrington, Andrew and Naderiparizi, Saeid and Wood, Frank},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1748--1758},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/warrington20a/warrington20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/warrington20a.html},\n  abstract = \t {Deterministic models are approximations of reality that are easy to interpret and often easier to build than stochastic alternatives. Unfortunately, as nature is capricious, observational data can never be fully explained by deterministic models in practice. Observation and process noise need to be added to adapt deterministic models to behave stochastically, such that they are capable of explaining and extrapolating from noisy data. We investigate and address computational inefficiencies that arise from adding process noise to deterministic simulators that fail to return for certain inputs; a property we describe as \u2019brittle\u2019. We show how to train a conditional normalizing flow to propose perturbations such that the simulator succeeds with high probability, increasing computational efficiency.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/warrington20a/warrington20a.pdf",
        "supp": "",
        "pdf_size": 2895989,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8404227060027949368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Oxford; University of British Columbia; University of British Columbia",
        "aff_domain": "robots.ox.ac.uk;cs.ubc.ca;cs.ubc.ca",
        "email": "robots.ox.ac.uk;cs.ubc.ca;cs.ubc.ca",
        "github": "https://github.com/plai-group/stdr",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Oxford;University of British Columbia",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.ubc.ca",
        "aff_unique_abbr": "Oxford;UBC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "id": "808ffe6e9b",
        "title": "Corruption-Tolerant Gaussian Process Bandit Optimization",
        "site": "https://proceedings.mlr.press/v108/bogunovic20a.html",
        "author": "Ilija Bogunovic; Andreas Krause; Jonathan Scarlett",
        "abstract": "We consider the problem of optimizing an unknown (typically non-convex) function with a bounded norm in some Reproducing Kernel Hilbert Space (RKHS), based on noisy bandit feedback. We consider a novel variant of this problem in which the point evaluations are not only corrupted by random noise, but also adversarial corruptions. We introduce an algorithm Fast-Slow GP-UCB based on Gaussian process methods, randomized selection between two instances labeled \u2019fast\u2019 (but non-robust) and \u2019slow\u2019 (but robust), enlarged confidence bounds, and the principle of optimism under uncertainty. We present a novel theoret- ical analysis upper bounding the cumulative regret in terms of the corruption level, the time horizon, and the underlying kernel, and we argue that certain dependencies cannot be improved. We observe that distinct algorithmic ideas are required depending on whether one is required to perform well in both the corrupted and non-corrupted settings, and whether the corruption level is known or not.",
        "bibtex": "@InProceedings{pmlr-v108-bogunovic20a,\n  title = \t {Corruption-Tolerant Gaussian Process Bandit Optimization},\n  author =       {Bogunovic, Ilija and Krause, Andreas and Scarlett, Jonathan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1071--1081},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bogunovic20a/bogunovic20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bogunovic20a.html},\n  abstract = \t {We consider the problem of optimizing an unknown (typically non-convex) function with a bounded norm in some Reproducing Kernel Hilbert Space (RKHS), based on noisy bandit feedback. We consider a novel variant of this problem in which the point evaluations are not only corrupted by random noise, but also adversarial corruptions. We introduce an algorithm Fast-Slow GP-UCB based on Gaussian process methods, randomized selection between two instances labeled \u2019fast\u2019 (but non-robust) and \u2019slow\u2019 (but robust), enlarged confidence bounds, and the principle of optimism under uncertainty. We present a novel theoret- ical analysis upper bounding the cumulative regret in terms of the corruption level, the time horizon, and the underlying kernel, and we argue that certain dependencies cannot be improved. We observe that distinct algorithmic ideas are required depending on whether one is required to perform well in both the corrupted and non-corrupted settings, and whether the corruption level is known or not.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bogunovic20a/bogunovic20a.pdf",
        "supp": "",
        "pdf_size": 3203793,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9667746776425995837&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "772f1d1e26",
        "title": "DAve-QN: A Distributed Averaged Quasi-Newton Method with Local Superlinear Convergence Rate",
        "site": "https://proceedings.mlr.press/v108/soori20a.html",
        "author": "Saeed Soori; Konstantin Mishchenko; Aryan Mokhtari; Maryam Mehri Dehnavi; Mert Gurbuzbalaban",
        "abstract": "In this paper, we consider distributed algorithms for solving the empirical risk minimization problem under the master/worker communication model. We develop a distributed asynchronous quasi-Newton algorithm that can achieve superlinear convergence. To our knowledge, this is the first distributed asynchronous algorithm with superlinear convergence guarantees. Our algorithm is communication-efficient in the sense that at every iteration the master node and workers communicate vectors of size $O(p)$, where $p$ is the dimension of the decision variable.  The proposed method is based on a distributed asynchronous averaging scheme of decision vectors and gradients in a way to effectively capture the local Hessian information of the objective function. Our convergence theory supports asynchronous computations subject to both bounded delays and unbounded delays with a bounded time-average. Unlike in the majority of asynchronous optimization literature, we do not require choosing smaller stepsize when delays are huge. We provide numerical experiments that match our theoretical results and showcase significant improvement comparing to state-of-the-art distributed algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-soori20a,\n  title = \t {DAve-QN: A Distributed Averaged Quasi-Newton Method with Local Superlinear Convergence Rate},\n  author =       {Soori, Saeed and Mishchenko, Konstantin and Mokhtari, Aryan and Dehnavi, Maryam Mehri and Gurbuzbalaban, Mert},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1965--1976},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/soori20a/soori20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/soori20a.html},\n  abstract = \t {In this paper, we consider distributed algorithms for solving the empirical risk minimization problem under the master/worker communication model. We develop a distributed asynchronous quasi-Newton algorithm that can achieve superlinear convergence. To our knowledge, this is the first distributed asynchronous algorithm with superlinear convergence guarantees. Our algorithm is communication-efficient in the sense that at every iteration the master node and workers communicate vectors of size $O(p)$, where $p$ is the dimension of the decision variable.  The proposed method is based on a distributed asynchronous averaging scheme of decision vectors and gradients in a way to effectively capture the local Hessian information of the objective function. Our convergence theory supports asynchronous computations subject to both bounded delays and unbounded delays with a bounded time-average. Unlike in the majority of asynchronous optimization literature, we do not require choosing smaller stepsize when delays are huge. We provide numerical experiments that match our theoretical results and showcase significant improvement comparing to state-of-the-art distributed algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/soori20a/soori20a.pdf",
        "supp": "",
        "pdf_size": 1574331,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15331077287888398393&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "CS Department, University of Toronto; CS Department, University of Toronto + KAUST University; ECE Department, University of Texas at Austin; CS Department, University of Toronto; MSIS Department, Rutgers University",
        "aff_domain": "cs.toronto.edu;kaust.edu.sa;austin.utexas.edu;cs.toronto.edu;rutgers.edu",
        "email": "cs.toronto.edu;kaust.edu.sa;austin.utexas.edu;cs.toronto.edu;rutgers.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;2;0;3",
        "aff_unique_norm": "University of Toronto;King Abdullah University of Science and Technology;University of Texas at Austin;Rutgers University",
        "aff_unique_dep": "Department of Computer Science;;ECE Department;MSIS Department",
        "aff_unique_url": "https://www.utoronto.ca;https://www.kaust.edu.sa;https://www.utexas.edu;https://www.rutgers.edu",
        "aff_unique_abbr": "U of T;KAUST;UT Austin;Rutgers",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Toronto;;Austin",
        "aff_country_unique_index": "0;0+1;2;0;2",
        "aff_country_unique": "Canada;Saudi Arabia;United States"
    },
    {
        "id": "7efa3337e8",
        "title": "DYNOTEARS: Structure Learning from Time-Series Data",
        "site": "https://proceedings.mlr.press/v108/pamfil20a.html",
        "author": "Roxana Pamfil; Nisara Sriwattanaworachai; Shaan Desai; Philip Pilgerstorfer; Konstantinos Georgatzis; Paul Beaumont; Bryon Aragam",
        "abstract": "We revisit the structure learning problem for dynamic Bayesian networks and propose a method that simultaneously estimates contemporaneous (intra-slice) and time-lagged (inter-slice) relationships between variables in a time-series. Our approach is score-based, and revolves around minimizing a penalized loss subject to an acyclicity constraint. To solve this problem, we leverage a recent algebraic result characterizing the acyclicity constraint as a smooth equality constraint. The resulting algorithm, which we call DYNOTEARS, outperforms other methods on simulated data, especially in high-dimensions as the number of variables increases. We also apply this algorithm on real datasets from two different domains, finance and molecular biology, and analyze the resulting output. Compared to state-of-the-art methods for learning dynamic Bayesian networks, our method is both scalable and accurate on real data. The simple formulation and competitive performance of our method make it suitable for a variety of problems where one seeks to learn connections between variables across time.",
        "bibtex": "@InProceedings{pmlr-v108-pamfil20a,\n  title = \t {DYNOTEARS: Structure Learning from Time-Series Data},\n  author =       {Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer, Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1595--1605},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pamfil20a/pamfil20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pamfil20a.html},\n  abstract = \t {We revisit the structure learning problem for dynamic Bayesian networks and propose a method that simultaneously estimates contemporaneous (intra-slice) and time-lagged (inter-slice) relationships between variables in a time-series. Our approach is score-based, and revolves around minimizing a penalized loss subject to an acyclicity constraint. To solve this problem, we leverage a recent algebraic result characterizing the acyclicity constraint as a smooth equality constraint. The resulting algorithm, which we call DYNOTEARS, outperforms other methods on simulated data, especially in high-dimensions as the number of variables increases. We also apply this algorithm on real datasets from two different domains, finance and molecular biology, and analyze the resulting output. Compared to state-of-the-art methods for learning dynamic Bayesian networks, our method is both scalable and accurate on real data. The simple formulation and competitive performance of our method make it suitable for a variety of problems where one seeks to learn connections between variables across time.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pamfil20a/pamfil20a.pdf",
        "supp": "",
        "pdf_size": 1310691,
        "gs_citation": 251,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1811205596428722515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "QuantumBlack, a McKinsey company; QuantumBlack, a McKinsey company; QuantumBlack, a McKinsey company+University of Chicago; QuantumBlack, a McKinsey company; QuantumBlack, a McKinsey company; QuantumBlack, a McKinsey company; University of Chicago",
        "aff_domain": "quantumblack.com;quantumblack.com;quantumblack.com+bryon;quantumblack.com;quantumblack.com;quantumblack.com;chicagobooth.edu",
        "email": "quantumblack.com;quantumblack.com;quantumblack.com+bryon;quantumblack.com;quantumblack.com;quantumblack.com;chicagobooth.edu",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0;0;0;1",
        "aff_unique_norm": "QuantumBlack;University of Chicago",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.quantumblack.com;https://www.uchicago.edu",
        "aff_unique_abbr": "QuantumBlack;UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1;0;0;0;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "8d58acd9b3",
        "title": "Data Generation for Neural Programming by Example",
        "site": "https://proceedings.mlr.press/v108/clymo20a.html",
        "author": "Judith Clymo; Haik Manukian; Nathanael Fijalkow; Adria Gascon; Brooks Paige",
        "abstract": "Programming by example is the problem of synthesizing a program from a small set of input / output pairs. Recent works applying machine learning methods to this task show promise, but are typically reliant on generating synthetic examples for training. A particular challenge lies in generating meaningful sets of inputs and outputs, which well-characterize a given program and accurately demonstrate its behavior. Where examples used for testing are generated by the same method as training data then the performance of a model may be partly reliant on this similarity. In this paper we introduce a novel approach using an SMT solver to synthesize inputs which cover a diverse set of behaviors for a given program. We carry out a case study comparing this method to existing synthetic data generation procedures in the literature, and find that data generated using our approach improves both the discriminatory power of example sets and the ability of trained machine learning models to generalize to unfamiliar data.",
        "bibtex": "@InProceedings{pmlr-v108-clymo20a,\n  title = \t {Data Generation for Neural Programming by Example},\n  author =       {Clymo, Judith and Manukian, Haik and Fijalkow, Nathanael and Gascon, Adria and Paige, Brooks},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3450--3459},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/clymo20a/clymo20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/clymo20a.html},\n  abstract = \t {Programming by example is the problem of synthesizing a program from a small set of input / output pairs. Recent works applying machine learning methods to this task show promise, but are typically reliant on generating synthetic examples for training. A particular challenge lies in generating meaningful sets of inputs and outputs, which well-characterize a given program and accurately demonstrate its behavior. Where examples used for testing are generated by the same method as training data then the performance of a model may be partly reliant on this similarity. In this paper we introduce a novel approach using an SMT solver to synthesize inputs which cover a diverse set of behaviors for a given program. We carry out a case study comparing this method to existing synthetic data generation procedures in the literature, and find that data generated using our approach improves both the discriminatory power of example sets and the ability of trained machine learning models to generalize to unfamiliar data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/clymo20a/clymo20a.pdf",
        "supp": "",
        "pdf_size": 2983809,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4123401041687598352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of Leeds; University of California at San Diego; CNRS, LaBRI; Google + Alan Turing Institute; UCL + Alan Turing Institute",
        "aff_domain": "leeds.ac.uk;ucsd.edu;labri.fr;gmail.com;ucl.ac.uk",
        "email": "leeds.ac.uk;ucsd.edu;labri.fr;gmail.com;ucl.ac.uk",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3+4;5+4",
        "aff_unique_norm": "University of Leeds;University of California, San Diego;CNRS;Google;Alan Turing Institute;University College London",
        "aff_unique_dep": ";;LaBRI;Google;;",
        "aff_unique_url": "https://www.leeds.ac.uk;https://ucsd.edu;https://www.cnrs.fr;https://www.google.com;https://www.turing.ac.uk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Leeds;UCSD;CNRS;Google;ATI;UCL",
        "aff_campus_unique_index": "1;2;",
        "aff_campus_unique": ";San Diego;Mountain View",
        "aff_country_unique_index": "0;1;2;1+0;0+0",
        "aff_country_unique": "United Kingdom;United States;France"
    },
    {
        "id": "ab21c89dd1",
        "title": "Decentralized Multi-player Multi-armed Bandits with No Collision Information",
        "site": "https://proceedings.mlr.press/v108/shi20a.html",
        "author": "Chengshuai Shi; Wei Xiong; Cong Shen; Jing Yang",
        "abstract": "The decentralized stochastic multi-player multi-armed bandit (MP-MAB) problem, where the collision information is not available to the players, is studied in this paper. Building on the seminal work of Boursier and Perchet (2019), we propose error correction synchronization involving communication (EC-SIC), whose regret is shown to approach that of the centralized stochastic MP-MAB with collision information. By recognizing that the communication phase without collision information corresponds to the Z-channel model in information theory, the proposed EC-SIC algorithm applies optimal error correction coding for the communication of reward statistics. A fixed message length, as opposed to the logarithmically growing one in Boursier and Perchet (2019), also plays a crucial role in controlling the communication loss. Experiments with practical Z-channel codes, such as repetition code, flip code and modified Hamming code, demonstrate the superiority of EC-SIC in both synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v108-shi20a,\n  title = \t {Decentralized Multi-player Multi-armed Bandits with No Collision Information},\n  author =       {Shi, Chengshuai and Xiong, Wei and Shen, Cong and Yang, Jing},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1519--1528},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shi20a/shi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shi20a.html},\n  abstract = \t {The decentralized stochastic multi-player multi-armed bandit (MP-MAB) problem, where the collision information is not available to the players, is studied in this paper. Building on the seminal work of Boursier and Perchet (2019), we propose error correction synchronization involving communication (EC-SIC), whose regret is shown to approach that of the centralized stochastic MP-MAB with collision information. By recognizing that the communication phase without collision information corresponds to the Z-channel model in information theory, the proposed EC-SIC algorithm applies optimal error correction coding for the communication of reward statistics. A fixed message length, as opposed to the logarithmically growing one in Boursier and Perchet (2019), also plays a crucial role in controlling the communication loss. Experiments with practical Z-channel codes, such as repetition code, flip code and modified Hamming code, demonstrate the superiority of EC-SIC in both synthetic and real-world datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shi20a/shi20a.pdf",
        "supp": "",
        "pdf_size": 659530,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5782894409864734148&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b4441a76ea",
        "title": "Decentralized gradient methods: does topology matter?",
        "site": "https://proceedings.mlr.press/v108/neglia20a.html",
        "author": "Giovanni Neglia; Chuan Xu; Don Towsley; Gianmarco Calbi",
        "abstract": "Consensus-based distributed optimization methods have recently been advocated as alternatives to parameter server and ring all-reduce paradigms for large scale training of machine learning models. In this case, each worker maintains a local estimate of the optimal parameter vector and iteratively updates it by averaging the estimates obtained from its neighbors, and applying a correction on the basis of its local dataset. While theoretical results suggest that worker communication topology should have strong impact on the number of epochs needed to converge, previous experiments have shown the opposite conclusion. This paper sheds lights on this apparent contradiction and show how sparse topologies can lead to faster convergence even in the absence of communication delays.",
        "bibtex": "@InProceedings{pmlr-v108-neglia20a,\n  title = \t {Decentralized gradient methods: does topology matter?},\n  author =       {Neglia, Giovanni and Xu, Chuan and Towsley, Don and Calbi, Gianmarco},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2348--2358},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/neglia20a/neglia20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/neglia20a.html},\n  abstract = \t {Consensus-based distributed optimization methods have recently been advocated as alternatives to parameter server and ring all-reduce paradigms for large scale training of machine learning models. In this case, each worker maintains a local estimate of the optimal parameter vector and iteratively updates it by averaging the estimates obtained from its neighbors, and applying a correction on the basis of its local dataset. While theoretical results suggest that worker communication topology should have strong impact on the number of epochs needed to converge, previous experiments have shown the opposite conclusion. This paper sheds lights on this apparent contradiction and show how sparse topologies can lead to faster convergence even in the absence of communication delays. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/neglia20a/neglia20a.pdf",
        "supp": "",
        "pdf_size": 1056134,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14997093693108559466&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "175e6fea11",
        "title": "Deep Active Learning: Unified and Principled Method for Query and Training",
        "site": "https://proceedings.mlr.press/v108/shui20a.html",
        "author": "Changjian Shui; Fan Zhou; Christian Gagn\u00e9; Boyu Wang",
        "abstract": "In this paper, we are proposing a unified and principled method for both the querying and training processes in deep batch active learning. We are providing theoretical insights from the intuition of modeling the interactive procedure in active learning as distribution matching, by adopting the Wasserstein distance. As a consequence, we derived a new training loss from the theoretical analysis, which is decomposed into optimizing deep neural network parameters and batch query selection through alternative optimization. In addition, the loss for training a deep neural network is naturally formulated as a min-max optimization problem through leveraging the unlabeled data information. Moreover, the proposed principles also indicate an explicit uncertainty-diversity trade-off in the query batch selection. Finally, we evaluate our proposed method on different benchmarks, consistently showing better empirical performances and a better time-efficient query strategy compared to the baselines.",
        "bibtex": "@InProceedings{pmlr-v108-shui20a,\n  title = \t {Deep Active Learning: Unified and Principled Method for Query and Training},\n  author =       {Shui, Changjian and Zhou, Fan and Gagn\\'e, Christian and Wang, Boyu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1308--1318},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shui20a/shui20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shui20a.html},\n  abstract = \t {In this paper, we are proposing a unified and principled method for both the querying and training processes in deep batch active learning. We are providing theoretical insights from the intuition of modeling the interactive procedure in active learning as distribution matching, by adopting the Wasserstein distance. As a consequence, we derived a new training loss from the theoretical analysis, which is decomposed into optimizing deep neural network parameters and batch query selection through alternative optimization. In addition, the loss for training a deep neural network is naturally formulated as a min-max optimization problem through leveraging the unlabeled data information. Moreover, the proposed principles also indicate an explicit uncertainty-diversity trade-off in the query batch selection. Finally, we evaluate our proposed method on different benchmarks, consistently showing better empirical performances and a better time-efficient query strategy compared to the baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shui20a/shui20a.pdf",
        "supp": "",
        "pdf_size": 526631,
        "gs_citation": 205,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10515868640691975143&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e9519c9c4c",
        "title": "Deep Structured Mixtures of Gaussian Processes",
        "site": "https://proceedings.mlr.press/v108/trapp20a.html",
        "author": "Martin Trapp; Robert Peharz; Franz Pernkopf; Carl Edward Rasmussen",
        "abstract": "Gaussian Processes (GPs) are powerful non-parametric Bayesian regression models that allow exact posterior inference, but exhibit high computational and memory costs. In order to improve scalability of GPs, approximate posterior inference is frequently employed, where a prominent class of approximation techniques is based on local GP experts. However, local-expert techniques proposed so far are either not well-principled, come with limited approximation guarantees, or lead to intractable models. In this paper, we introduce deep structured mixtures of GP experts, a stochastic process model which i) allows exact posterior inference, ii) has attractive computational and memory costs, and iii) when used as GP approximation, captures predictive uncertainties consistently better than previous expert-based approximations. In a variety of experiments, we show that deep structured mixtures have a low approximation error and often perform competitive or outperform prior work.",
        "bibtex": "@InProceedings{pmlr-v108-trapp20a,\n  title = \t {Deep Structured Mixtures of Gaussian Processes},\n  author =       {Trapp, Martin and Peharz, Robert and Pernkopf, Franz and Rasmussen, Carl Edward},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2251--2261},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/trapp20a/trapp20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/trapp20a.html},\n  abstract = \t {Gaussian Processes (GPs) are powerful non-parametric Bayesian regression models that allow exact posterior inference, but exhibit high computational and memory costs. In order to improve scalability of GPs, approximate posterior inference is frequently employed, where a prominent class of approximation techniques is based on local GP experts. However, local-expert techniques proposed so far are either not well-principled, come with limited approximation guarantees, or lead to intractable models. In this paper, we introduce deep structured mixtures of GP experts, a stochastic process model which i) allows exact posterior inference, ii) has attractive computational and memory costs, and iii) when used as GP approximation, captures predictive uncertainties consistently better than previous expert-based approximations. In a variety of experiments, we show that deep structured mixtures have a low approximation error and often perform competitive or outperform prior work.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/trapp20a/trapp20a.pdf",
        "supp": "",
        "pdf_size": 862246,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15930603171269585543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3307d52cf2",
        "title": "Deontological Ethics By Monotonicity Shape Constraints",
        "site": "https://proceedings.mlr.press/v108/wang20e.html",
        "author": "Serena Wang; Maya Gupta",
        "abstract": "We demonstrate how easy it is for modern machine-learned systems to violate common deontological ethical principles and social norms such as \u201cfavor the less fortunate,\u201d and \u201cdo not penalize good attributes.\u201d We propose that in some cases such ethical principles can be incorporated into a machine-learned model by adding shape constraints that constrain the model to respond only positively to relevant inputs. We analyze the relationship between these deontological constraints that act on individuals and the consequentialist group-based fairness goals of one-sided statistical parity and equal opportunity.  This strategy works with sensitive attributes that are Boolean or real-valued such as income and age, and can help produce more responsible and trustworthy AI.",
        "bibtex": "@InProceedings{pmlr-v108-wang20e,\n  title = \t {Deontological Ethics By Monotonicity Shape Constraints},\n  author =       {Wang, Serena and Gupta, Maya},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2043--2054},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20e/wang20e.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20e.html},\n  abstract = \t {We demonstrate how easy it is for modern machine-learned systems to violate common deontological ethical principles and social norms such as \u201cfavor the less fortunate,\u201d and \u201cdo not penalize good attributes.\u201d We propose that in some cases such ethical principles can be incorporated into a machine-learned model by adding shape constraints that constrain the model to respond only positively to relevant inputs. We analyze the relationship between these deontological constraints that act on individuals and the consequentialist group-based fairness goals of one-sided statistical parity and equal opportunity.  This strategy works with sensitive attributes that are Boolean or real-valued such as income and age, and can help produce more responsible and trustworthy AI. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20e/wang20e.pdf",
        "supp": "",
        "pdf_size": 1096059,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16400168199843874773&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; Google Research",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "62d9ba5909",
        "title": "Dependent randomized rounding for clustering and partition systems with knapsack constraints",
        "site": "https://proceedings.mlr.press/v108/harris20a.html",
        "author": "David Harris; Thomas Pensyl; Aravind Srinivasan; Khoa Trinh",
        "abstract": "Clustering problems are fundamental to unsupervised learning. There is an increased emphasis on \\emph{fairness} in machine learning and AI; one representative notion of fairness is that no single demographic group should be over-represented among the cluster-centers. This, and much more general clustering problems, can be formulated with \u201cknapsack\" and \u201cpartition\" constraints. We develop new randomized algorithms targeting such problems, and study two in particular: multi-knapsack median and multi-knapsack center. Our rounding algorithms give new approximation and pseudo-approximation algorithms for these problems. One key technical tool we develop and use, which may be of independent interest, is a new tail bound analogous to Feige (2006) for sums of random variables with unbounded variances. Such bounds are very useful in inferring properties of large networks using few samples.",
        "bibtex": "@InProceedings{pmlr-v108-harris20a,\n  title = \t {Dependent randomized rounding for clustering and partition systems with knapsack constraints},\n  author =       {Harris, David and Pensyl, Thomas and Srinivasan, Aravind and Trinh, Khoa},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2273--2283},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/harris20a/harris20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/harris20a.html},\n  abstract = \t {Clustering problems are fundamental to unsupervised learning. There is an increased emphasis on \\emph{fairness} in machine learning and AI; one representative notion of fairness is that no single demographic group should be over-represented among the cluster-centers. This, and much more general clustering problems, can be formulated with \u201cknapsack\" and \u201cpartition\" constraints. We develop new randomized algorithms targeting such problems, and study two in particular: multi-knapsack median and multi-knapsack center. Our rounding algorithms give new approximation and pseudo-approximation algorithms for these problems. One key technical tool we develop and use, which may be of independent interest, is a new tail bound analogous to Feige (2006) for sums of random variables with unbounded variances. Such bounds are very useful in inferring properties of large networks using few samples.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/harris20a/harris20a.pdf",
        "supp": "",
        "pdf_size": 294448,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14716138958450752143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "03227b90ee",
        "title": "Derivative-Free & Order-Robust Optimisation",
        "site": "https://proceedings.mlr.press/v108/ammar20a.html",
        "author": "Haitham Ammar; Victor Gabillon; Rasul Tutunov; Michal Valko",
        "abstract": "In this paper, we formalise order-robust optimisation as an instance of online learning minimising simple regret, and propose Vroom, a zero\u2019th order optimisation algorithm capable of achieving vanishing regret in non-stationary environments, while recovering favorable rates under stochastic reward-generating processes. Our results are the first to target simple regret definitions in adversarial scenarios unveiling a challenge that has been rarely considered in prior work.",
        "bibtex": "@InProceedings{pmlr-v108-ammar20a,\n  title = \t {Derivative-Free & Order-Robust Optimisation},\n  author =       {Ammar, Haitham and Gabillon, Victor and Tutunov, Rasul and Valko, Michal},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2293--2303},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ammar20a/ammar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ammar20a.html},\n  abstract = \t {\tIn this paper, we formalise order-robust optimisation as an instance of online learning minimising simple regret, and propose Vroom, a zero\u2019th order optimisation algorithm capable of achieving vanishing regret in non-stationary environments, while recovering favorable rates under stochastic reward-generating processes. Our results are the first to target simple regret definitions in adversarial scenarios unveiling a challenge that has been rarely considered in prior work.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ammar20a/ammar20a.pdf",
        "supp": "",
        "pdf_size": 389472,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5378297238886727830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d4cb63e761",
        "title": "Deterministic Decoding for Discrete Data in Variational Autoencoders",
        "site": "https://proceedings.mlr.press/v108/polykovskiy20a.html",
        "author": "Daniil Polykovskiy; Dmitry Vetrov",
        "abstract": "Variational autoencoders are prominent generative models for modeling discrete data. However, with flexible decoders, they tend to ignore the latent codes.  In this paper, we study a VAE model with a deterministic decoder (DD-VAE) for sequential data that selects the highest-scoring tokens instead of sampling. Deterministic decoding solely relies on latent codes as the only way to produce diverse objects, which improves the structure of the learned manifold. To implement DD-VAE, we propose a new class of bounded support proposal distributions and derive Kullback-Leibler divergence for Gaussian and uniform priors. We also study a continuous relaxation of deterministic decoding objective function and analyze the relation of reconstruction accuracy and relaxation parameters. We demonstrate the performance of DD-VAE on multiple datasets, including molecular generation and optimization problems.",
        "bibtex": "@InProceedings{pmlr-v108-polykovskiy20a,\n  title = \t {Deterministic Decoding for Discrete Data in Variational Autoencoders},\n  author =       {Polykovskiy, Daniil and Vetrov, Dmitry},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3046--3056},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/polykovskiy20a/polykovskiy20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/polykovskiy20a.html},\n  abstract = \t {Variational autoencoders are prominent generative models for modeling discrete data. However, with flexible decoders, they tend to ignore the latent codes.  In this paper, we study a VAE model with a deterministic decoder (DD-VAE) for sequential data that selects the highest-scoring tokens instead of sampling. Deterministic decoding solely relies on latent codes as the only way to produce diverse objects, which improves the structure of the learned manifold. To implement DD-VAE, we propose a new class of bounded support proposal distributions and derive Kullback-Leibler divergence for Gaussian and uniform priors. We also study a continuous relaxation of deterministic decoding objective function and analyze the relation of reconstruction accuracy and relaxation parameters. We demonstrate the performance of DD-VAE on multiple datasets, including molecular generation and optimization problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/polykovskiy20a/polykovskiy20a.pdf",
        "supp": "",
        "pdf_size": 4702967,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14219313669062782825&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Insilico Medicine; National Research University Higher School of Economics",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Insilico Medicine;National Research University Higher School of Economics",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://hse.ru",
        "aff_unique_abbr": ";HSE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Unknown;Russian Federation"
    },
    {
        "id": "d1ee2e01f3",
        "title": "Diameter-based Interactive Structure Discovery",
        "site": "https://proceedings.mlr.press/v108/tosh20a.html",
        "author": "Christopher Tosh; Daniel Hsu",
        "abstract": "We introduce interactive structure discovery, a generic framework that encompasses many interactive learning settings, including active learning, top-k item identification, interactive drug discovery, and others. We adapt a recently developed active learning algorithm of Tosh and Dasgupta for interactive structure discovery, and show that the new algorithm can be made noise-tolerant and enjoys favorable query complexity bounds.",
        "bibtex": "@InProceedings{pmlr-v108-tosh20a,\n  title = \t {Diameter-based Interactive Structure Discovery},\n  author =       {Tosh, Christopher and Hsu, Daniel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {580--590},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tosh20a/tosh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tosh20a.html},\n  abstract = \t {We introduce interactive structure discovery, a generic framework that encompasses many interactive learning settings, including active learning, top-k item identification, interactive drug discovery, and others. We adapt a recently developed active learning algorithm of Tosh and Dasgupta for interactive structure discovery, and show that the new algorithm can be made noise-tolerant and enjoys favorable query complexity bounds.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tosh20a/tosh20a.pdf",
        "supp": "",
        "pdf_size": 686644,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2070502180758900625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Columbia University; Columbia University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6baf4f6dc8",
        "title": "Differentiable Causal Backdoor Discovery",
        "site": "https://proceedings.mlr.press/v108/gultchin20a.html",
        "author": "Limor Gultchin; Matt Kusner; Varun Kanade; Ricardo Silva",
        "abstract": "Discovering the causal effect of a decision is critical to nearly all forms of decision-making. In particular, it is a key quantity in drug development, in crafting government policy, and when implementing a real-world machine learning system. Given only observational data, confounders often obscure the true causal effect. Luckily, in some cases, it is possible to recover the causal effect by using certain observed variables to adjust for the effects of confounders. However, without access to the true causal model, finding this adjustment requires brute-force search. In this work, we present an algorithm that exploits auxiliary variables, similar to instruments, in order to find an appropriate adjustment by a gradient-based optimization method. We demonstrate that it outperforms practical alternatives in estimating the true causal effect, without knowledge of the full causal graph.",
        "bibtex": "@InProceedings{pmlr-v108-gultchin20a,\n  title = \t {Differentiable Causal Backdoor Discovery},\n  author =       {Gultchin, Limor and Kusner, Matt and Kanade, Varun and Silva, Ricardo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3970--3979},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gultchin20a/gultchin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gultchin20a.html},\n  abstract = \t {Discovering the causal effect of a decision is critical to nearly all forms of decision-making. In particular, it is a key quantity in drug development, in crafting government policy, and when implementing a real-world machine learning system. Given only observational data, confounders often obscure the true causal effect. Luckily, in some cases, it is possible to recover the causal effect by using certain observed variables to adjust for the effects of confounders. However, without access to the true causal model, finding this adjustment requires brute-force search. In this work, we present an algorithm that exploits auxiliary variables, similar to instruments, in order to find an appropriate adjustment by a gradient-based optimization method. We demonstrate that it outperforms practical alternatives in estimating the true causal effect, without knowledge of the full causal graph.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/gultchin20a/gultchin20a.pdf",
        "supp": "",
        "pdf_size": 1500686,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9776645992326297423&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "278a0b7236",
        "title": "Differentiable Feature Selection by Discrete Relaxation",
        "site": "https://proceedings.mlr.press/v108/sheth20a.html",
        "author": "Rishit Sheth; Nicol\u00f3 Fusi",
        "abstract": "In this paper, we introduce Differentiable Feature Selection, a gradient-based search algorithm for feature selection. Our approach extends a recent result on the estimation of learnability in the sublinear data regime by showing that the calculation can be performed iteratively (i.e. in mini-batches) and in linear time and space with respect to both the number of features D and the sample size N. This, along with a discrete-to-continuous relaxation of the search domain, allows for an efficient, gradient-based search algorithm among feature subsets for very large datasets. Our algorithm utilizes higher-order correlations between features and targets for both the N>D and N",
        "bibtex": "@InProceedings{pmlr-v108-sheth20a,\n  title = \t {Differentiable Feature Selection by Discrete Relaxation},\n  author =       {Sheth, Rishit and Fusi, Nicol\\'o},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1564--1572},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sheth20a/sheth20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sheth20a.html},\n  abstract = \t {In this paper, we introduce Differentiable Feature Selection, a gradient-based search algorithm for feature selection. Our approach extends a recent result on the estimation of learnability in the sublinear data regime by showing that the calculation can be performed iteratively (i.e. in mini-batches) and in linear time and space with respect to both the number of features D and the sample size N. This, along with a discrete-to-continuous relaxation of the search domain, allows for an efficient, gradient-based search algorithm among feature subsets for very large datasets. Our algorithm utilizes higher-order correlations between features and targets for both the N>D and N",
        "pdf": "http://proceedings.mlr.press/v108/sheth20a/sheth20a.pdf",
        "supp": "",
        "pdf_size": 4147704,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18044890186085317797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Microsoft Research New England; Microsoft Research New England",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-new-england",
        "aff_unique_abbr": "MSR NE",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New England",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bc9fb1f99a",
        "title": "Discrete Action On-Policy Learning with Action-Value Critic",
        "site": "https://proceedings.mlr.press/v108/yue20a.html",
        "author": "Yuguang Yue; Yunhao Tang; Mingzhang Yin; Mingyuan Zhou",
        "abstract": "Reinforcement learning (RL) in discrete action space is ubiquitous in real-world applications, but its complexity grows exponentially with the action-space dimension, making it challenging to apply existing on-policy gradient based deep RL algorithms efficiently. To effectively operate in multidimensional discrete action spaces, we construct a critic to estimate action-value functions, apply it on correlated actions, and combine these critic estimated action values to control the variance of gradient estimation. We follow rigorous statistical analysis to design how to generate and combine these correlated actions, and how to sparsify the gradients by shutting down the contributions from certain dimensions. These efforts result in a new discrete action on-policy RL algorithm that empirically outperforms related on-policy algorithms relying on variance control techniques. We demonstrate these properties on OpenAI Gym benchmark tasks, and illustrate how discretizing the action space could benefit the exploration phase and hence facilitate convergence to a better local optimal solution thanks to the flexibility of discrete policy.",
        "bibtex": "@InProceedings{pmlr-v108-yue20a,\n  title = \t {Discrete Action On-Policy Learning with Action-Value Critic},\n  author =       {Yue, Yuguang and Tang, Yunhao and Yin, Mingzhang and Zhou, Mingyuan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1977--1987},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yue20a/yue20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yue20a.html},\n  abstract = \t {Reinforcement learning (RL) in discrete action space is ubiquitous in real-world applications, but its complexity grows exponentially with the action-space dimension, making it challenging to apply existing on-policy gradient based deep RL algorithms efficiently. To effectively operate in multidimensional discrete action spaces, we construct a critic to estimate action-value functions, apply it on correlated actions, and combine these critic estimated action values to control the variance of gradient estimation. We follow rigorous statistical analysis to design how to generate and combine these correlated actions, and how to sparsify the gradients by shutting down the contributions from certain dimensions. These efforts result in a new discrete action on-policy RL algorithm that empirically outperforms related on-policy algorithms relying on variance control techniques. We demonstrate these properties on OpenAI Gym benchmark tasks, and illustrate how discretizing the action space could benefit the exploration phase and hence facilitate convergence to a better local optimal solution thanks to the flexibility of discrete policy. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/yue20a/yue20a.pdf",
        "supp": "",
        "pdf_size": 2852595,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9958721892199960073&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a2fe1acfe0",
        "title": "Distributed, partially collapsed MCMC for Bayesian Nonparametrics",
        "site": "https://proceedings.mlr.press/v108/dubey20a.html",
        "author": "Kumar Avinava Dubey; Michael Zhang; Eric Xing; Sinead Williamson",
        "abstract": "Bayesian nonparametric (BNP) models provide elegant methods for discovering underlying latent features within a data set, but inference in such models can be slow. We exploit the fact that completely random measures, which commonly-used models like the Dirichlet process and the beta-Bernoulli process can be expressed using, are decomposable into independent sub-measures.   We use this decomposition to partition the latent measure into a finite measure containing only instantiated components, and an infinite measure containing all other components. We then select different inference algorithms for the two components: uncollapsed samplers mix well on the finite measure, while collapsed samplers mix well on the infinite, sparsely occupied tail. The resulting hybrid algorithm can be applied to a wide class of models, and can be easily distributed to allow scalable inference without sacrificing asymptotic convergence guarantees.",
        "bibtex": "@InProceedings{pmlr-v108-dubey20a,\n  title = \t {Distributed, partially collapsed MCMC for Bayesian Nonparametrics},\n  author =       {Dubey, Kumar Avinava and Zhang, Michael and Xing, Eric and Williamson, Sinead},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3685--3695},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dubey20a/dubey20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dubey20a.html},\n  abstract = \t {Bayesian nonparametric (BNP) models provide elegant methods for discovering underlying latent features within a data set, but inference in such models can be slow. We exploit the fact that completely random measures, which commonly-used models like the Dirichlet process and the beta-Bernoulli process can be expressed using, are decomposable into independent sub-measures.   We use this decomposition to partition the latent measure into a finite measure containing only instantiated components, and an infinite measure containing all other components. We then select different inference algorithms for the two components: uncollapsed samplers mix well on the finite measure, while collapsed samplers mix well on the infinite, sparsely occupied tail. The resulting hybrid algorithm can be applied to a wide class of models, and can be easily distributed to allow scalable inference without sacrificing asymptotic convergence guarantees. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/dubey20a/dubey20a.pdf",
        "supp": "",
        "pdf_size": 5147365,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4549168835638753124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "45f70ba305",
        "title": "Distributionally Robust Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v108/kirschner20a.html",
        "author": "Johannes Kirschner; Ilija Bogunovic; Stefanie Jegelka; Andreas Krause",
        "abstract": "Robustness to distributional shift is one of the key challenges of contemporary machine learning. Attaining such robustness is the goal of distributionally robust optimization, which seeks a solution to an optimization problem that is worst-case robust under a specified distributional shift of an uncontrolled covariate. In this paper, we study such a problem when the distributional shift is measured via the maximum mean discrepancy (MMD). For the setting of zeroth-order, noisy optimization, we present a novel distributionally robust Bayesian optimization algorithm (DRBO). Our algorithm provably obtains sub-linear robust regret in various settings that differ in how the uncertain covariate is observed. We demonstrate the robust performance of our method on both synthetic and real-world benchmarks.",
        "bibtex": "@InProceedings{pmlr-v108-kirschner20a,\n  title = \t {Distributionally Robust Bayesian Optimization},\n  author =       {Kirschner, Johannes and Bogunovic, Ilija and Jegelka, Stefanie and Krause, Andreas},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2174--2184},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kirschner20a/kirschner20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kirschner20a.html},\n  abstract = \t {Robustness to distributional shift is one of the key challenges of contemporary machine learning. Attaining such robustness is the goal of distributionally robust optimization, which seeks a solution to an optimization problem that is worst-case robust under a specified distributional shift of an uncontrolled covariate. In this paper, we study such a problem when the distributional shift is measured via the maximum mean discrepancy (MMD). For the setting of zeroth-order, noisy optimization, we present a novel distributionally robust Bayesian optimization algorithm (DRBO). Our algorithm provably obtains sub-linear robust regret in various settings that differ in how the uncertain covariate is observed. We demonstrate the robust performance of our method on both synthetic and real-world benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kirschner20a/kirschner20a.pdf",
        "supp": "",
        "pdf_size": 506299,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10951407184479783785&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dd9960757f",
        "title": "Distributionally Robust Bayesian Quadrature Optimization",
        "site": "https://proceedings.mlr.press/v108/nguyen20a.html",
        "author": "Thanh Nguyen; Sunil Gupta; Huong Ha; Santu Rana; Svetha Venkatesh",
        "abstract": "Bayesian quadrature optimization (BQO) maximizes the expectation of an expensive black-box integrand taken over a known probability distribution. In this work, we study BQO under distributional uncertainty in which the underlying probability distribution is unknown except for a limited set of its i.i.d samples. A standard BQO approach maximizes the Monte Carlo estimate of the true expected objective given the fixed sample set. Though Monte Carlo estimate is unbiased, it has high variance given a small set of samples; thus can result in a spurious objective function. We adopt the distributionally robust optimization perspective to this problem by maximizing the expected objective under the most adversarial distribution. In particular, we propose a novel posterior sampling based algorithm, namely distributionally robust BQO (DRBQO) for this purpose. We demonstrate the empirical effectiveness of our proposed framework in synthetic and real-world problems, and characterize its theoretical convergence via Bayesian regret.",
        "bibtex": "@InProceedings{pmlr-v108-nguyen20a,\n  title = \t {Distributionally Robust Bayesian Quadrature Optimization},\n  author =       {Nguyen, Thanh and Gupta, Sunil and Ha, Huong and Rana, Santu and Venkatesh, Svetha},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1921--1931},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/nguyen20a/nguyen20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/nguyen20a.html},\n  abstract = \t {Bayesian quadrature optimization (BQO) maximizes the expectation of an expensive black-box integrand taken over a known probability distribution. In this work, we study BQO under distributional uncertainty in which the underlying probability distribution is unknown except for a limited set of its i.i.d samples. A standard BQO approach maximizes the Monte Carlo estimate of the true expected objective given the fixed sample set. Though Monte Carlo estimate is unbiased, it has high variance given a small set of samples; thus can result in a spurious objective function. We adopt the distributionally robust optimization perspective to this problem by maximizing the expected objective under the most adversarial distribution. In particular, we propose a novel posterior sampling based algorithm, namely distributionally robust BQO (DRBQO) for this purpose. We demonstrate the empirical effectiveness of our proposed framework in synthetic and real-world problems, and characterize its theoretical convergence via Bayesian regret.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/nguyen20a/nguyen20a.pdf",
        "supp": "",
        "pdf_size": 3586789,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6866003092713433818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Applied Arti\ufb01cial Intelligence Institute (A2I2); Deakin University, Geelong, Australia; Deakin University, Geelong, Australia; Deakin University, Geelong, Australia; Deakin University, Geelong, Australia",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Applied Arti\ufb01cial Intelligence Institute;Deakin University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.deakin.edu.au",
        "aff_unique_abbr": "A2I2;Deakin",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Geelong",
        "aff_country_unique_index": "1;1;1;1",
        "aff_country_unique": ";Australia"
    },
    {
        "id": "92c36e2a61",
        "title": "Distributionally Robust Formulation and Model Selection for the Graphical Lasso",
        "site": "https://proceedings.mlr.press/v108/cisneros20a.html",
        "author": "Pedro Cisneros-Velarde; Alexander Petersen; Sang-Yun Oh",
        "abstract": "Building on a recent framework for distributionally robust optimization, we consider inverse covariance matrix estimation for multivariate data. A novel notion of Wasserstein ambiguity set is provided that is specifically tailored to this problem, leading to a tractable class of regularized estimators. Penalized likelihood estimators for Gaussian data, specifically the graphical lasso estimator, are special cases. Consequently, a direction connection is made between the radius of the Wasserstein ambiguity and the regularization parameter, so that the level of robustness of the estimator is shown to correspond to the level of confidence with which the ambiguity set contains a distribution with the population covariance. A unique feature of the formulation is that the radius can be expressed in closed-form as a function of the ordinary sample covariance matrix. Taking advantage of this finding, a simple algorithm is developed to determine a regularization parameter for graphical lasso, using only the bootstrapped sample covariance matrices, rendering computationally expensive repeated evaluation of the graphical lasso algorithm unnecessary. Alternatively, the distributionally robust formulation can also quantify the robustness of the corresponding estimator if one uses an off-the-shelf method such as cross-validation. Finally, a numerical study is performed to analyze the robustness of the proposed method relative to other automated tuning procedures used in practice.",
        "bibtex": "@InProceedings{pmlr-v108-cisneros20a,\n  title = \t {Distributionally Robust Formulation and Model Selection for the Graphical Lasso},\n  author =       {Cisneros-Velarde, Pedro and Petersen, Alexander and Oh, Sang-Yun},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {756--765},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cisneros20a/cisneros20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cisneros20a.html},\n  abstract = \t {Building on a recent framework for distributionally robust optimization, we consider inverse covariance matrix estimation for multivariate data. A novel notion of Wasserstein ambiguity set is provided that is specifically tailored to this problem, leading to a tractable class of regularized estimators. Penalized likelihood estimators for Gaussian data, specifically the graphical lasso estimator, are special cases. Consequently, a direction connection is made between the radius of the Wasserstein ambiguity and the regularization parameter, so that the level of robustness of the estimator is shown to correspond to the level of confidence with which the ambiguity set contains a distribution with the population covariance. A unique feature of the formulation is that the radius can be expressed in closed-form as a function of the ordinary sample covariance matrix. Taking advantage of this finding, a simple algorithm is developed to determine a regularization parameter for graphical lasso, using only the bootstrapped sample covariance matrices, rendering computationally expensive repeated evaluation of the graphical lasso algorithm unnecessary. Alternatively, the distributionally robust formulation can also quantify the robustness of the corresponding estimator if one uses an off-the-shelf method such as cross-validation. Finally, a numerical study is performed to analyze the robustness of the proposed method relative to other automated tuning procedures used in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cisneros20a/cisneros20a.pdf",
        "supp": "",
        "pdf_size": 363856,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14753844225981427868&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Santa Barbara; University of California, Santa Barbara; Lawrence Berkeley National Lab + University of California, Santa Barbara",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+0",
        "aff_unique_norm": "University of California, Santa Barbara;Lawrence Berkeley National Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsb.edu;https://www.lbl.gov",
        "aff_unique_abbr": "UCSB;LBNL",
        "aff_campus_unique_index": "0;0;1+0",
        "aff_campus_unique": "Santa Barbara;Berkeley",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7875a0c490",
        "title": "Domain-Liftability of Relational Marginal Polytopes",
        "site": "https://proceedings.mlr.press/v108/kuzelka20a.html",
        "author": "Ondrej Kuzelka; Yuyi Wang",
        "abstract": "We study computational aspects of \"relational marginal polytopes\" which are statistical relational learning counterparts of marginal polytopes, well-known from probabilistic graphical models. Here, given some first-order logic formula, we can define its relational marginal statistic to be the fraction of groundings that make this formula true in a given possible world. For a list of first-order logic formulas, the relational marginal polytope is the set of all points that correspond to expected values of the relational marginal statistics that are realizable. In this paper we study the following two problems: (i) Do domain-liftability results for the partition functions of Markov logic networks (MLNs)carry over to the problem of relational marginal polytope construction? (ii) Is the relational marginal polytope containment problem hard under some plausible complexity-theoretic assumptions? Our positive results have consequences for lifted weight learning of MLNs. In particular, we show that weight learning of MLNs is domain-liftable whenever the computation of the partition function of the respective MLNs is domain-liftable (this result has not been rigorously proven before).",
        "bibtex": "@InProceedings{pmlr-v108-kuzelka20a,\n  title = \t {Domain-Liftability of Relational Marginal Polytopes},\n  author =       {Kuzelka, Ondrej and Wang, Yuyi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2284--2292},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kuzelka20a/kuzelka20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kuzelka20a.html},\n  abstract = \t {We study computational aspects of \"relational marginal polytopes\" which are statistical relational learning counterparts of marginal polytopes, well-known from probabilistic graphical models. Here, given some first-order logic formula, we can define its relational marginal statistic to be the fraction of groundings that make this formula true in a given possible world. For a list of first-order logic formulas, the relational marginal polytope is the set of all points that correspond to expected values of the relational marginal statistics that are realizable. In this paper we study the following two problems: (i) Do domain-liftability results for the partition functions of Markov logic networks (MLNs)carry over to the problem of relational marginal polytope construction? (ii) Is the relational marginal polytope containment problem hard under some plausible complexity-theoretic assumptions? Our positive results have consequences for lifted weight learning of MLNs. In particular, we show that weight learning of MLNs is domain-liftable whenever the computation of the partition function of the respective MLNs is domain-liftable (this result has not been rigorously proven before).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kuzelka20a/kuzelka20a.pdf",
        "supp": "",
        "pdf_size": 518900,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=743060231281276446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Czech Technical University in Prague, Czech Republic; ETH Zurich, Switzerland",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Czech Technical University;ETH Zurich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ctu.cz;https://www.ethz.ch",
        "aff_unique_abbr": "CTU;ETHZ",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Prague;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Czech Republic;Switzerland"
    },
    {
        "id": "948da308a1",
        "title": "Doubly Sparse Variational Gaussian Processes",
        "site": "https://proceedings.mlr.press/v108/adam20a.html",
        "author": "Vincent Adam; Stefanos Eleftheriadis; Artem Artemev; Nicolas Durrande; James Hensman",
        "abstract": "The use of Gaussian process models is typically limited to datasets with a few tens of thousands of observations due to their complexity and memory footprint.The two most commonly used methods to overcome this limitation are 1) the variational sparse approximation which relies on inducing points and 2) the state-space equivalent formulation of Gaussian processes which can be seen as exploiting some sparsity in the precision matrix.In this work, we propose to take the best of both worlds: we show that the inducing point framework is still valid for state space models and that it can bring further computational and memory savings. Furthermore, we provide the natural gradient formulation for the proposed variational parameterisation.Finally, this work makes it possible to use the state-space formulation inside deep Gaussian process models as illustrated in one of the experiments.",
        "bibtex": "@InProceedings{pmlr-v108-adam20a,\n  title = \t {Doubly Sparse Variational Gaussian Processes},\n  author =       {Adam, Vincent and Eleftheriadis, Stefanos and Artemev, Artem and Durrande, Nicolas and Hensman, James},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2874--2884},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/adam20a/adam20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/adam20a.html},\n  abstract = \t {The use of Gaussian process models is typically limited to datasets with a few tens of thousands of observations due to their complexity and memory footprint.The two most commonly used methods to overcome this limitation are 1) the variational sparse approximation which relies on inducing points and 2) the state-space equivalent formulation of Gaussian processes which can be seen as exploiting some sparsity in the precision matrix.In this work, we propose to take the best of both worlds: we show that the inducing point framework is still valid for state space models and that it can bring further computational and memory savings. Furthermore, we provide the natural gradient formulation for the proposed variational parameterisation.Finally, this work makes it possible to use the state-space formulation inside deep Gaussian process models as illustrated in one of the experiments. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/adam20a/adam20a.pdf",
        "supp": "",
        "pdf_size": 2626544,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17834404544049914710&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "PROWLER.io, Cambridge, UK; ; ; ;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "PROWLER.io",
        "aff_unique_dep": "",
        "aff_unique_url": "https://prowler.io",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "6b18c8be37",
        "title": "Dynamic content based ranking",
        "site": "https://proceedings.mlr.press/v108/virtanen20a.html",
        "author": "Seppo Virtanen; Mark Girolami",
        "abstract": "We introduce a novel state space model for a set of sequentially time-stamped partial rankings of items and textual descriptions for the items. Based on the data, the model infers text-based themes that are predictive of the rankings enabling forecasting tasks and performing trend analysis. We propose a scaled Gamma process based prior for capturing the underlying dynamics. Based on two challenging and contemporary real data collections, we show the model infers meaningful and useful textual themes as well as performs better than existing related dynamic models.",
        "bibtex": "@InProceedings{pmlr-v108-virtanen20a,\n  title = \t {Dynamic content based ranking},\n  author =       {Virtanen, Seppo and Girolami, Mark},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2315--2324},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/virtanen20a/virtanen20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/virtanen20a.html},\n  abstract = \t {We introduce a novel state space model for a set of sequentially time-stamped partial rankings of items and textual descriptions for the items. Based on the data, the model infers text-based themes that are predictive of the rankings enabling forecasting tasks and performing trend analysis. We propose a scaled Gamma process based prior for capturing the underlying dynamics. Based on two challenging and contemporary real data collections, we show the model infers meaningful and useful textual themes as well as performs better than existing related dynamic models.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/virtanen20a/virtanen20a.pdf",
        "supp": "",
        "pdf_size": 777793,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "University of Cambridge; University of Cambridge and The Alan Turing Institute",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "a5ebd728b3",
        "title": "Dynamical Systems Theory for Causal Inference with Application to Synthetic Control Methods",
        "site": "https://proceedings.mlr.press/v108/ding20a.html",
        "author": "Yi Ding; Panos Toulis",
        "abstract": "In this paper, we adopt results in nonlinear time series analysis for causal inference in dynamical settings. Our motivation is policy analysis with panel data, particularly  through the use of \u201csynthetic control\" methods. These methods regress pre-intervention outcomes of the treated unit to outcomes from a pool of control units, and then use the fitted regression model to estimate causal effects post-intervention. In this setting, we propose to screen out control units that have a weak dynamical relationship to the treated unit. In simulations, we show that this method can mitigate bias from \u201ccherry-picking\" of control units, which is usually an important concern. We illustrate on real-world applications, including the tobacco legislation example of \\citet{Abadie2010}, and Brexit.",
        "bibtex": "@InProceedings{pmlr-v108-ding20a,\n  title = \t {Dynamical Systems Theory for Causal Inference with Application to Synthetic Control Methods},\n  author =       {Ding, Yi and Toulis, Panos},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1888--1898},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ding20a/ding20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ding20a.html},\n  abstract = \t {In this paper, we adopt results in nonlinear time series analysis for causal inference in dynamical settings. Our motivation is policy analysis with panel data, particularly  through the use of \u201csynthetic control\" methods. These methods regress pre-intervention outcomes of the treated unit to outcomes from a pool of control units, and then use the fitted regression model to estimate causal effects post-intervention. In this setting, we propose to screen out control units that have a weak dynamical relationship to the treated unit. In simulations, we show that this method can mitigate bias from \u201ccherry-picking\" of control units, which is usually an important concern. We illustrate on real-world applications, including the tobacco legislation example of \\citet{Abadie2010}, and Brexit.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ding20a/ding20a.pdf",
        "supp": "",
        "pdf_size": 492586,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11022069141921175903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Chicago, Department of Computer Science; University of Chicago, Booth School of Business",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uchicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f7cc9fa3bb",
        "title": "EM Converges for a Mixture of Many Linear Regressions",
        "site": "https://proceedings.mlr.press/v108/kwon20a.html",
        "author": "Jeongyeol Kwon; Constantine Caramanis",
        "abstract": "We study the convergence of the Expectation-Maximization (EM) algorithm for mixtures of linear regressions with an arbitrary number $k$ of components. We show that as long as signal-to-noise ratio (SNR) is $\\tilde{\\Omega}(k)$, well-initialized EM converges to the true regression parameters. Previous results for $k \\geq 3$ have only established local convergence for the noiseless setting, i.e., where SNR is infinitely large. Our results enlarge the scope to the environment with noises, and notably, we establish a statistical error rate that is independent of the norm (or pairwise distance) of the regression parameters. In particular, our results imply exact recovery as $\\sigma \\rightarrow 0$, in contrast to most previous local convergence results for EM, where the statistical error scaled with the norm of parameters. Standard moment-method approaches may be applied to guarantee we are in the region where our local convergence guarantees apply.",
        "bibtex": "@InProceedings{pmlr-v108-kwon20a,\n  title = \t {EM Converges for a Mixture of Many Linear Regressions},\n  author =       {Kwon, Jeongyeol and Caramanis, Constantine},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1727--1736},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kwon20a/kwon20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kwon20a.html},\n  abstract = \t {We study the convergence of the Expectation-Maximization (EM) algorithm for mixtures of linear regressions with an arbitrary number $k$ of components. We show that as long as signal-to-noise ratio (SNR) is $\\tilde{\\Omega}(k)$, well-initialized EM converges to the true regression parameters. Previous results for $k \\geq 3$ have only established local convergence for the noiseless setting, i.e., where SNR is infinitely large. Our results enlarge the scope to the environment with noises, and notably, we establish a statistical error rate that is independent of the norm (or pairwise distance) of the regression parameters. In particular, our results imply exact recovery as $\\sigma \\rightarrow 0$, in contrast to most previous local convergence results for EM, where the statistical error scaled with the norm of parameters. Standard moment-method approaches may be applied to guarantee we are in the region where our local convergence guarantees apply.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kwon20a/kwon20a.pdf",
        "supp": "",
        "pdf_size": 341884,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13020399045852707432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "The University of Texas at Austin; The University of Texas at Austin",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "cf6268be0c",
        "title": "Efficient Distributed Hessian Free Algorithm for Large-scale Empirical Risk Minimization via Accumulating Sample Strategy",
        "site": "https://proceedings.mlr.press/v108/jahani20a.html",
        "author": "Majid Jahani; Xi He; Chenxin Ma; Aryan Mokhtari; Dheevatsa Mudigere; Alejandro Ribeiro; Martin Takac",
        "abstract": "In this paper, we propose a Distributed Accumulated Newton Conjugate gradiEnt (DANCE) method in which sample size is gradually increasing to quickly obtain a solution whose empirical loss is under satisfactory statistical accuracy. Our proposed method is multistage in which the solution of a stage serves as a warm start for the next stage which contains more samples (including the samples in the previous stage). The proposed multistage algorithm reduces the number of passes over data to achieve the statistical accuracy of the full training set. Moreover, our algorithm in nature is easy to be distributed and shares the strong scaling property indicating that acceleration is always expected by using more computing nodes. Various iteration complexity results regarding descent direction computation, communication efficiency and stopping criteria are analyzed under convex setting. Our numerical results illustrate that the proposed method outperforms other comparable methods for solving learning problems including neural networks.",
        "bibtex": "@InProceedings{pmlr-v108-jahani20a,\n  title = \t {Efficient Distributed Hessian Free Algorithm for Large-scale Empirical Risk Minimization via Accumulating Sample Strategy},\n  author =       {Jahani, Majid and He, Xi and Ma, Chenxin and Mokhtari, Aryan and Mudigere, Dheevatsa and Ribeiro, Alejandro and Takac, Martin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2634--2644},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/jahani20a/jahani20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/jahani20a.html},\n  abstract = \t {In this paper, we propose a Distributed Accumulated Newton Conjugate gradiEnt (DANCE) method in which sample size is gradually increasing to quickly obtain a solution whose empirical loss is under satisfactory statistical accuracy. Our proposed method is multistage in which the solution of a stage serves as a warm start for the next stage which contains more samples (including the samples in the previous stage). The proposed multistage algorithm reduces the number of passes over data to achieve the statistical accuracy of the full training set. Moreover, our algorithm in nature is easy to be distributed and shares the strong scaling property indicating that acceleration is always expected by using more computing nodes. Various iteration complexity results regarding descent direction computation, communication efficiency and stopping criteria are analyzed under convex setting. Our numerical results illustrate that the proposed method outperforms other comparable methods for solving learning problems including neural networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/jahani20a/jahani20a.pdf",
        "supp": "",
        "pdf_size": 1534664,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15792245608591420989&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ef713b0594",
        "title": "Efficient Planning under Partial Observability with Unnormalized Q Functions and Spectral Learning",
        "site": "https://proceedings.mlr.press/v108/li20h.html",
        "author": "Tianyu Li; Bogdan Mazoure; Doina Precup; Guillaume Rabusseau",
        "abstract": "Learning and planning in partially-observable domains is one of the most difficult problems in reinforcement learning. Traditional methods consider these two problems as independent, resulting in a classic two-stage paradigm: first learn the environment dynamics and then compute the optimal policy accordingly. This approach, however, disconnects the reward information from the learning of the environment model and can consequently lead to representations that are sample inefficient and time consuming for planning purpose. In this paper, we propose a novel algorithm that incorporate reward information into the representations of the environment to unify these two stages. Our algorithm is closely related to the spectral learning algorithm for predicitive state representations and offers appealing theoretical guarantees and time complexity. We empirically show on two domains that our approach is more sample  and time efficient compared to  classical methods.",
        "bibtex": "@InProceedings{pmlr-v108-li20h,\n  title = \t {Efficient Planning under Partial Observability with Unnormalized Q Functions and Spectral Learning},\n  author =       {Li, Tianyu and Mazoure, Bogdan and Precup, Doina and Rabusseau, Guillaume},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2852--2862},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20h/li20h.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20h.html},\n  abstract = \t {Learning and planning in partially-observable domains is one of the most difficult problems in reinforcement learning. Traditional methods consider these two problems as independent, resulting in a classic two-stage paradigm: first learn the environment dynamics and then compute the optimal policy accordingly. This approach, however, disconnects the reward information from the learning of the environment model and can consequently lead to representations that are sample inefficient and time consuming for planning purpose. In this paper, we propose a novel algorithm that incorporate reward information into the representations of the environment to unify these two stages. Our algorithm is closely related to the spectral learning algorithm for predicitive state representations and offers appealing theoretical guarantees and time complexity. We empirically show on two domains that our approach is more sample  and time efficient compared to  classical methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20h/li20h.pdf",
        "supp": "",
        "pdf_size": 726409,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2043379283901432584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "68b8284fec",
        "title": "Efficient Spectrum-Revealing CUR Matrix Decomposition",
        "site": "https://proceedings.mlr.press/v108/chen20a.html",
        "author": "Cheng Chen; Ming Gu; Zhihua Zhang; Weinan Zhang; Yong Yu",
        "abstract": "The CUR matrix decomposition is an important tool for low-rank matrix approximation. It approximates a data matrix though selecting a small number of columns and rows of the matrix. Those CUR algorithms with  gap-dependent approximation bounds can obtain high approximation quality for matrices with good singular value spectrum decay, but they have impractically high time complexities. In this paper, we propose a novel CUR algorithm based on truncated LU factorization with an efficient variant of complete pivoting. Our algorithm has gap-dependent approximation bounds on both spectral and Frobenius norms while maintaining high efficiency. Numerical experiments demonstrate the effectiveness of our algorithm and verify our theoretical guarantees.",
        "bibtex": "@InProceedings{pmlr-v108-chen20a,\n  title = \t {Efficient Spectrum-Revealing CUR Matrix Decomposition},\n  author =       {Chen, Cheng and Gu, Ming and Zhang, Zhihua and Zhang, Weinan and Yu, Yong},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {766--775},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chen20a/chen20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chen20a.html},\n  abstract = \t {The CUR matrix decomposition is an important tool for low-rank matrix approximation. It approximates a data matrix though selecting a small number of columns and rows of the matrix. Those CUR algorithms with  gap-dependent approximation bounds can obtain high approximation quality for matrices with good singular value spectrum decay, but they have impractically high time complexities. In this paper, we propose a novel CUR algorithm based on truncated LU factorization with an efficient variant of complete pivoting. Our algorithm has gap-dependent approximation bounds on both spectral and Frobenius norms while maintaining high efficiency. Numerical experiments demonstrate the effectiveness of our algorithm and verify our theoretical guarantees.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chen20a/chen20a.pdf",
        "supp": "",
        "pdf_size": 939547,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10524945420907124849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Shanghai Jiao Tong University; University of California, Berkeley; Peking University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;University of California, Berkeley;Peking University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.berkeley.edu;http://www.pku.edu.cn",
        "aff_unique_abbr": "SJTU;UC Berkeley;Peking U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "3164fe4400",
        "title": "Elimination of All Bad Local Minima in Deep Learning",
        "site": "https://proceedings.mlr.press/v108/kawaguchi20b.html",
        "author": "Kenji Kawaguchi; Leslie Kaelbling",
        "abstract": "In this paper, we theoretically prove that adding one special neuron per output unit eliminates all suboptimal local minima of any deep neural network, for multi-class classification, binary classification, and regression with an arbitrary loss function, under practical assumptions. At every local minimum of any deep neural network with these added neurons, the set of parameters of the original neural network (without added neurons) is guaranteed to be a global minimum of the original neural network. The effects of the added neurons are proven to automatically vanish at every local minimum. Moreover, we provide a novel theoretical characterization of a failure mode of eliminating suboptimal local minima via an additional theorem and several examples. This paper also introduces a novel proof technique based on the perturbable gradient basis (PGB) necessary condition of local minima, which provides new insight into the elimination of local minima and is applicable to analyze various models and transformations of objective functions beyond the elimination of local minima.",
        "bibtex": "@InProceedings{pmlr-v108-kawaguchi20b,\n  title = \t {Elimination of All Bad Local Minima in Deep Learning},\n  author =       {Kawaguchi, Kenji and Kaelbling, Leslie},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {853--863},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kawaguchi20b/kawaguchi20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kawaguchi20b.html},\n  abstract = \t {In this paper, we theoretically prove that adding one special neuron per output unit eliminates all suboptimal local minima of any deep neural network, for multi-class classification, binary classification, and regression with an arbitrary loss function, under practical assumptions. At every local minimum of any deep neural network with these added neurons, the set of parameters of the original neural network (without added neurons) is guaranteed to be a global minimum of the original neural network. The effects of the added neurons are proven to automatically vanish at every local minimum. Moreover, we provide a novel theoretical characterization of a failure mode of eliminating suboptimal local minima via an additional theorem and several examples. This paper also introduces a novel proof technique based on the perturbable gradient basis (PGB) necessary condition of local minima, which provides new insight into the elimination of local minima and is applicable to analyze various models and transformations of objective functions beyond the elimination of local minima. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/kawaguchi20b/kawaguchi20b.pdf",
        "supp": "",
        "pdf_size": 431322,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18370979943070053158&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "MIT; MIT",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9cc44baef1",
        "title": "Enriched mixtures of generalised Gaussian process experts",
        "site": "https://proceedings.mlr.press/v108/gadd20a.html",
        "author": "Charles Gadd; Sara Wade; Alexis Boukouvalas",
        "abstract": "Mixtures of experts probabilistically divide the input space into regions, where the assumptions of each expert, or conditional model, need only hold locally. Combined with Gaussian process (GP) experts, this results in a powerful and highly flexible model. We focus on alternative mixtures of GP experts, which  model the joint distribution of the inputs and targets explicitly. We highlight issues of this approach in multi-dimensional input spaces, namely,  poor scalability and the need for an unnecessarily large number of experts, degrading the predictive performance and increasing uncertainty. We construct a novel model to address these issues through a nested partitioning scheme that automatically infers the number of components at both levels. Multiple response types are accommodated through a generalised GP framework, while multiple input types are included through a factorised exponential family structure. We show the effectiveness of our approach in estimating a parsimonious probabilistic description of both  synthetic data of increasing dimension and an Alzheimer\u2019s challenge dataset.",
        "bibtex": "@InProceedings{pmlr-v108-gadd20a,\n  title = \t {Enriched mixtures of generalised Gaussian process experts},\n  author =       {Gadd, Charles and Wade, Sara and Boukouvalas, Alexis},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3144--3154},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gadd20a/gadd20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gadd20a.html},\n  abstract = \t {Mixtures of experts probabilistically divide the input space into regions, where the assumptions of each expert, or conditional model, need only hold locally. Combined with Gaussian process (GP) experts, this results in a powerful and highly flexible model. We focus on alternative mixtures of GP experts, which  model the joint distribution of the inputs and targets explicitly. We highlight issues of this approach in multi-dimensional input spaces, namely,  poor scalability and the need for an unnecessarily large number of experts, degrading the predictive performance and increasing uncertainty. We construct a novel model to address these issues through a nested partitioning scheme that automatically infers the number of components at both levels. Multiple response types are accommodated through a generalised GP framework, while multiple input types are included through a factorised exponential family structure. We show the effectiveness of our approach in estimating a parsimonious probabilistic description of both  synthetic data of increasing dimension and an Alzheimer\u2019s challenge dataset.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/gadd20a/gadd20a.pdf",
        "supp": "",
        "pdf_size": 699787,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11009286460962202844&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Dept. of Computer Science, Aalto University, Espoo, Finland; School of Mathematics, University of Edinburgh, Edinburgh, United Kingdom; PROWLER.io, Cambridge, United Kingdom",
        "aff_domain": "gmail.com;ed.ac.uk;prowler.io",
        "email": "gmail.com;ed.ac.uk;prowler.io",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Aalto University;University of Edinburgh;PROWLER.io",
        "aff_unique_dep": "Dept. of Computer Science;School of Mathematics;",
        "aff_unique_url": "https://www.aalto.fi;https://www.ed.ac.uk;https://prowler.io",
        "aff_unique_abbr": "Aalto;Edinburgh;",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Espoo;Edinburgh;Cambridge",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Finland;United Kingdom"
    },
    {
        "id": "bd3dbc82ac",
        "title": "Ensemble Gaussian Processes with Spectral Features for Online Interactive Learning with Scalability",
        "site": "https://proceedings.mlr.press/v108/lu20d.html",
        "author": "Qin Lu; Georgios Karanikolas; Yanning Shen; Georgios B. Giannakis",
        "abstract": "Combining benefits of kernels with Bayesian models, Gaussian process (GP) based approaches have well-documented merits not only in learning over a rich class of nonlinear functions, but also quantifying the associated uncertainty. While most GP approaches rely on a single preselected prior, the present work employs a weighted ensemble of GP priors, each having a unique covariance (kernel) belonging to a prescribed kernel dictionary \u2013 which leads to a richer space of learning functions. Leveraging kernel approximants formed by spectral features for scalability, an online interactive ensemble (OI-E) GP framework is developed to jointly learn the sought function, and for the first time select interactively the EGP kernel on-the-fly. Performance of OI-EGP is benchmarked by the best fixed function estimator via regret analysis. Furthermore, the novel OI-EGP is adapted to accommodate dynamic learning functions. Synthetic and real data tests demonstrate the effectiveness of the proposed schemes.",
        "bibtex": "@InProceedings{pmlr-v108-lu20d,\n  title = \t {Ensemble Gaussian Processes with Spectral Features for Online Interactive Learning with Scalability},\n  author =       {Lu, Qin and Karanikolas, Georgios and Shen, Yanning and Giannakis, Georgios B.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1910--1920},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lu20d/lu20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lu20d.html},\n  abstract = \t {Combining benefits of kernels with Bayesian models, Gaussian process (GP) based approaches have well-documented merits not only in learning over a rich class of nonlinear functions, but also quantifying the associated uncertainty. While most GP approaches rely on a single preselected prior, the present work employs a weighted ensemble of GP priors, each having a unique covariance (kernel) belonging to a prescribed kernel dictionary \u2013 which leads to a richer space of learning functions. Leveraging kernel approximants formed by spectral features for scalability, an online interactive ensemble (OI-E) GP framework is developed to jointly learn the sought function, and for the first time select interactively the EGP kernel on-the-fly. Performance of OI-EGP is benchmarked by the best fixed function estimator via regret analysis. Furthermore, the novel OI-EGP is adapted to accommodate dynamic learning functions. Synthetic and real data tests demonstrate the effectiveness of the proposed schemes.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lu20d/lu20d.pdf",
        "supp": "",
        "pdf_size": 1447574,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3370791249224858482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c4539dfec7",
        "title": "Entropy Weighted Power k-Means Clustering",
        "site": "https://proceedings.mlr.press/v108/chakraborty20a.html",
        "author": "Saptarshi Chakraborty; Debolina Paul; Swagatam Das; Jason Xu",
        "abstract": "Despite its well-known shortcomings, k-means remains one of the most widely used approaches to data clustering. Current research continues to tackle its flaws while attempting to preserve its simplicity. Recently, the power k-means algorithm was proposed to avoid poor local minima by annealing through a family of smoother surfaces. However,  the approach lacks statistical guarantees and fails in high dimensions when many features are irrelevant. This paper addresses these issues by introducing entropy regularization to learn feature relevance while annealing. We prove consistency of the proposed approach and derive a scalable majorization-minimization algorithm that enjoys closed-form updates and convergence guarantees. In particular, our method retains the same computational complexity of k-means and power k-means, but yields significant improvements over both. Its merits are thoroughly assessed on a suite of real and synthetic data.",
        "bibtex": "@InProceedings{pmlr-v108-chakraborty20a,\n  title = \t {Entropy Weighted Power k-Means Clustering},\n  author =       {Chakraborty, Saptarshi and Paul, Debolina and Das, Swagatam and Xu, Jason},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {691--701},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chakraborty20a/chakraborty20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chakraborty20a.html},\n  abstract = \t {Despite its well-known shortcomings, k-means remains one of the most widely used approaches to data clustering. Current research continues to tackle its flaws while attempting to preserve its simplicity. Recently, the power k-means algorithm was proposed to avoid poor local minima by annealing through a family of smoother surfaces. However,  the approach lacks statistical guarantees and fails in high dimensions when many features are irrelevant. This paper addresses these issues by introducing entropy regularization to learn feature relevance while annealing. We prove consistency of the proposed approach and derive a scalable majorization-minimization algorithm that enjoys closed-form updates and convergence guarantees. In particular, our method retains the same computational complexity of k-means and power k-means, but yields significant improvements over both. Its merits are thoroughly assessed on a suite of real and synthetic data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chakraborty20a/chakraborty20a.pdf",
        "supp": "",
        "pdf_size": 682685,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16486394235350818481&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Indian Statistical Institute, Kolkata, India; Indian Statistical Institute, Kolkata, India; Electronics and Communication Sciences Unit, Indian Statistical Institute; Department of Statistical Science, Duke University",
        "aff_domain": "isi.ac.in;isi.ac.in;isi.ac.in;duke.edu",
        "email": "isi.ac.in;isi.ac.in;isi.ac.in;duke.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Indian Statistical Institute;Duke University",
        "aff_unique_dep": ";Department of Statistical Science",
        "aff_unique_url": "https://www.isical.ac.in;https://www.duke.edu",
        "aff_unique_abbr": "ISI;Duke",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kolkata;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "41b5ba94a6",
        "title": "Equalized odds postprocessing under imperfect group information",
        "site": "https://proceedings.mlr.press/v108/awasthi20a.html",
        "author": "Pranjal Awasthi; Matth\u00e4us Kleindessner; Jamie Morgenstern",
        "abstract": "Most approaches aiming to ensure a model\u2019s fairness with respect to a protected attribute (such as gender or race) assume to know the true value of the attribute for every data point. In this paper, we ask to what extent fairness interventions can be effective even when only imperfect information about the protected attribute is available. In particular, we study the prominent equalized odds postprocessing method of Hardt et al. (2016) under a perturbation of the attribute. We identify conditions on the perturbation that guarantee that the bias of a classifier is reduced even by running equalized odds with the perturbed attribute. We also study the error of the resulting classifier. We empirically observe that under our identified conditions most often the error does not suffer from a perturbation of the protected attribute. For a special case, we formally prove this observation to be true.",
        "bibtex": "@InProceedings{pmlr-v108-awasthi20a,\n  title = \t {Equalized odds postprocessing under imperfect group information},\n  author =       {Awasthi, Pranjal and Kleindessner, Matth\\\"aus and Morgenstern, Jamie},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1770--1780},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/awasthi20a/awasthi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/awasthi20a.html},\n  abstract = \t {Most approaches aiming to ensure a model\u2019s fairness with respect to a protected attribute (such as gender or race) assume to know the true value of the attribute for every data point. In this paper, we ask to what extent fairness interventions can be effective even when only imperfect information about the protected attribute is available. In particular, we study the prominent equalized odds postprocessing method of Hardt et al. (2016) under a perturbation of the attribute. We identify conditions on the perturbation that guarantee that the bias of a classifier is reduced even by running equalized odds with the perturbed attribute. We also study the error of the resulting classifier. We empirically observe that under our identified conditions most often the error does not suffer from a perturbation of the protected attribute. For a special case, we formally prove this observation to be true.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/awasthi20a/awasthi20a.pdf",
        "supp": "",
        "pdf_size": 732973,
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14064530593548310806&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "85cd03f5ca",
        "title": "Error bounds in estimating the out-of-sample prediction error using leave-one-out cross validation in high-dimensions",
        "site": "https://proceedings.mlr.press/v108/rad20a.html",
        "author": "Kamiar Rahnama Rad; Wenda Zhou; Arian Maleki",
        "abstract": "We study the problem of out-of-sample risk estimation in the high dimensional regime where both the sample size $n$ and number of features $p$ are large, and $n/p$ can be less than one. Extensive empirical evidence confirms the accuracy of leave-one-out cross validation (LO) for out-of-sample risk estimation. Yet, a unifying theoretical evaluation of the accuracy of LO in high-dimensional problems has remained an open problem. This paper aims to fill this gap for penalized regression in the generalized linear family. With minor assumptions about the data generating process, and without any sparsity assumptions on the regression coefficients, our theoretical analysis obtains finite sample upper bounds on the expected squared error of LO in estimating the out-of-sample error. Our bounds show that the error goes to zero as $n,p \\rightarrow \\infty$, even when the dimension $p$ of the feature vectors is comparable with or  greater than the sample size $n$. One technical advantage of the theory is that it can be used to clarify and connect some results from the recent literature on  scalable approximate LO.",
        "bibtex": "@InProceedings{pmlr-v108-rad20a,\n  title = \t {Error bounds in estimating the out-of-sample prediction error using leave-one-out cross validation in high-dimensions},\n  author =       {Rad, Kamiar Rahnama and Zhou, Wenda and Maleki, Arian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4067--4077},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rad20a/rad20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rad20a.html},\n  abstract = \t {We study the problem of out-of-sample risk estimation in the high dimensional regime where both the sample size $n$ and number of features $p$ are large, and $n/p$ can be less than one. Extensive empirical evidence confirms the accuracy of leave-one-out cross validation (LO) for out-of-sample risk estimation. Yet, a unifying theoretical evaluation of the accuracy of LO in high-dimensional problems has remained an open problem. This paper aims to fill this gap for penalized regression in the generalized linear family. With minor assumptions about the data generating process, and without any sparsity assumptions on the regression coefficients, our theoretical analysis obtains finite sample upper bounds on the expected squared error of LO in estimating the out-of-sample error. Our bounds show that the error goes to zero as $n,p \\rightarrow \\infty$, even when the dimension $p$ of the feature vectors is comparable with or  greater than the sample size $n$. One technical advantage of the theory is that it can be used to clarify and connect some results from the recent literature on  scalable approximate LO.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rad20a/rad20a.pdf",
        "supp": "",
        "pdf_size": 482559,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=384029306262543053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e4d7ed9c73",
        "title": "Explaining the Explainer: A First Theoretical Analysis of LIME",
        "site": "https://proceedings.mlr.press/v108/garreau20a.html",
        "author": "Damien Garreau; Ulrike Luxburg",
        "abstract": "Machine learning is used more and more often for sensitive applications, sometimes replacing humans in critical decision-making processes. As such, interpretability of these algorithms is a pressing need. One popular algorithm to provide interpretability is LIME (Local Interpretable Model-Agnostic Explanation). In this paper, we provide the first theoretical analysis of LIME. We derive closed-form expressions for the coefficients of the interpretable model when the function to explain is linear. The good news is that these coefficients are proportional to the gradient of the function to explain: LIME indeed discovers meaningful features. However, our analysis also reveals that poor choices of parameters can lead LIME to miss important features.",
        "bibtex": "@InProceedings{pmlr-v108-garreau20a,\n  title = \t {Explaining the Explainer: A First Theoretical Analysis of LIME},\n  author =       {Garreau, Damien and von Luxburg, Ulrike},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1287--1296},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/garreau20a/garreau20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/garreau20a.html},\n  abstract = \t {Machine learning is used more and more often for sensitive applications, sometimes replacing humans in critical decision-making processes. As such, interpretability of these algorithms is a pressing need. One popular algorithm to provide interpretability is LIME (Local Interpretable Model-Agnostic Explanation). In this paper, we provide the first theoretical analysis of LIME. We derive closed-form expressions for the coefficients of the interpretable model when the function to explain is linear. The good news is that these coefficients are proportional to the gradient of the function to explain: LIME indeed discovers meaningful features. However, our analysis also reveals that poor choices of parameters can lead LIME to miss important features.  }\n}",
        "pdf": "http://proceedings.mlr.press/v108/garreau20a/garreau20a.pdf",
        "supp": "",
        "pdf_size": 4830689,
        "gs_citation": 310,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18148681232106388995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Max Planck Institute for Intelligent Systems, Germany + Universit\u00e9 C\u00f4te d\u2019Azur, Inria, CNRS, LJAD, France; University of T\u00fcbingen, Germany",
        "aff_domain": "unice.fr;uni-tuebingen.de",
        "email": "unice.fr;uni-tuebingen.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Universit\u00e9 C\u00f4te d\u2019Azur;University of T\u00fcbingen",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.univ-cotedazur.fr;https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "MPI-IS;UCA;Uni T\u00fcbingen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;0",
        "aff_country_unique": "Germany;France"
    },
    {
        "id": "1d579ad473",
        "title": "Explicit Mean-Square Error Bounds for Monte-Carlo and Linear Stochastic Approximation",
        "site": "https://proceedings.mlr.press/v108/chen20e.html",
        "author": "Shuhang Chen; Adithya Devraj; Ana Busic; Sean Meyn",
        "abstract": "This paper concerns error bounds for recursive equations subject to Markovian disturbances.   Motivating examples abound within the fields of Markov chain Monte Carlo (MCMC) and Reinforcement Learning (RL),   and many of these algorithms can be interpreted as special cases of stochastic approximation (SA).   It is argued that it is not possible in general to obtain a Hoeffding bound on the error sequence, even when the underlying Markov chain is reversible and geometrically ergodic, such as the M/M/1 queue.  This is motivation for the focus on mean square error bounds for parameter estimates.  It is shown that  mean square error achieves the optimal rate of $O(1/n)$, subject to conditions on the step-size sequence.    Moreover, the exact constants in the rate are obtained,   which is of great value in algorithm design.",
        "bibtex": "@InProceedings{pmlr-v108-chen20e,\n  title = \t {Explicit Mean-Square Error Bounds for Monte-Carlo and Linear Stochastic Approximation},\n  author =       {Chen, Shuhang and Devraj, Adithya and Busic, Ana and Meyn, Sean},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4173--4183},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chen20e/chen20e.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chen20e.html},\n  abstract = \t {This paper concerns error bounds for recursive equations subject to Markovian disturbances.   Motivating examples abound within the fields of Markov chain Monte Carlo (MCMC) and Reinforcement Learning (RL),   and many of these algorithms can be interpreted as special cases of stochastic approximation (SA).   It is argued that it is not possible in general to obtain a Hoeffding bound on the error sequence, even when the underlying Markov chain is reversible and geometrically ergodic, such as the M/M/1 queue.  This is motivation for the focus on mean square error bounds for parameter estimates.  It is shown that  mean square error achieves the optimal rate of $O(1/n)$, subject to conditions on the step-size sequence.    Moreover, the exact constants in the rate are obtained,   which is of great value in algorithm design.   }\n}",
        "pdf": "http://proceedings.mlr.press/v108/chen20e/chen20e.pdf",
        "supp": "",
        "pdf_size": 509446,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9273365069856032265&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c165c9e22e",
        "title": "Exploiting Categorical Structure Using Tree-Based Methods",
        "site": "https://proceedings.mlr.press/v108/lucena20a.html",
        "author": "Brian Lucena",
        "abstract": "Standard methods of using categorical variables as predictors either endow them with an ordinal structure or assume they have no structure at all.  However, categorical variables often possess structure that is more complicated than a linear ordering can capture. We develop a mathematical framework for representing the structure of categorical variables and show how to generalize decision trees to make use of this structure.  This approach is applicable to methods such as Gradient Boosted Trees which use a decision tree as the underlying learner.  We show results on weather data to demonstrate the improvement yielded by this approach.",
        "bibtex": "@InProceedings{pmlr-v108-lucena20a,\n  title = \t {Exploiting Categorical Structure Using Tree-Based Methods},\n  author =       {Lucena, Brian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2949--2958},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lucena20a/lucena20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lucena20a.html},\n  abstract = \t {Standard methods of using categorical variables as predictors either endow them with an ordinal structure or assume they have no structure at all.  However, categorical variables often possess structure that is more complicated than a linear ordering can capture. We develop a mathematical framework for representing the structure of categorical variables and show how to generalize decision trees to make use of this structure.  This approach is applicable to methods such as Gradient Boosted Trees which use a decision tree as the underlying learner.  We show results on weather data to demonstrate the improvement yielded by this approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lucena20a/lucena20a.pdf",
        "supp": "",
        "pdf_size": 846599,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16196681921345630582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Numeristical",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Numeristical",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": ""
    },
    {
        "id": "e66e48efdc",
        "title": "Expressiveness and Learning of Hidden Quantum Markov Models",
        "site": "https://proceedings.mlr.press/v108/adhikary20a.html",
        "author": "Sandesh Adhikary; Siddarth Srinivasan; Geoff Gordon; Byron Boots",
        "abstract": "Extending classical probabilistic reasoning using the quantum mechanical view of probability has been of recent interest, particularly in the development of hidden quantum Markov models (HQMMs) to model stochastic processes. However, there has been little progress in characterizing the expressiveness of such models and learning them from data. We tackle these problems by showing that HQMMs are a special subclass of the general class of observable operator models (OOMs) that do not suffer from the negative probability problem by design. We also provide a feasible retraction-based learning algorithm for HQMMs using constrained gradient descent on the Stiefel manifold of model parameters. We demonstrate that this approach is faster and scales to larger models than previous learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-adhikary20a,\n  title = \t {Expressiveness and Learning of Hidden Quantum Markov Models},\n  author =       {Adhikary, Sandesh and Srinivasan, Siddarth and Gordon, Geoff and Boots, Byron},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4151--4161},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/adhikary20a/adhikary20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/adhikary20a.html},\n  abstract = \t {Extending classical probabilistic reasoning using the quantum mechanical view of probability has been of recent interest, particularly in the development of hidden quantum Markov models (HQMMs) to model stochastic processes. However, there has been little progress in characterizing the expressiveness of such models and learning them from data. We tackle these problems by showing that HQMMs are a special subclass of the general class of observable operator models (OOMs) that do not suffer from the negative probability problem by design. We also provide a feasible retraction-based learning algorithm for HQMMs using constrained gradient descent on the Stiefel manifold of model parameters. We demonstrate that this approach is faster and scales to larger models than previous learning algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/adhikary20a/adhikary20a.pdf",
        "supp": "",
        "pdf_size": 698661,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8333955507556757771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Washington; MSR Montr\u00e9al; Georgia Tech; MSR Montr\u00e9al + University of Washington",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1+0",
        "aff_unique_norm": "University of Washington;Microsoft;Georgia Institute of Technology",
        "aff_unique_dep": ";Microsoft Research;",
        "aff_unique_url": "https://www.washington.edu;https://www.microsoft.com/en-us/research/group/montreal;https://www.gatech.edu",
        "aff_unique_abbr": "UW;MSR;Georgia Tech",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Montr\u00e9al",
        "aff_country_unique_index": "0;1;0;1+0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9e360fb328",
        "title": "Fair Correlation Clustering",
        "site": "https://proceedings.mlr.press/v108/ahmadian20a.html",
        "author": "Sara Ahmadian; Alessandro Epasto; Ravi Kumar; Mohammad Mahdian",
        "abstract": "In this paper, we study correlation clustering under fairness constraints.  Fair variants of $k$-median and $k$-center clustering have been studied recently, and approximation algorithms using a notion called fairlet decomposition have been proposed.  We obtain approximation algorithms for fair correlation clustering under several important types of fairness constraints.Our results hinge on obtaining a fairlet decomposition for correlation clustering by introducing a novel combinatorial optimization problem.  We define a fairlet decomposition with cost similar to the $k$-median cost and this allows us to obtain approximation algorithms for a wide range of fairness constraints. We complement our theoretical results with an in-depth analysis of our algorithms on real graphs where we show that fair solutions to correlation clustering can be obtained with limited increase in cost compared to the state-of-the-art (unfair) algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-ahmadian20a,\n  title = \t {Fair Correlation Clustering},\n  author =       {Ahmadian, Sara and Epasto, Alessandro and Kumar, Ravi and Mahdian, Mohammad},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4195--4205},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ahmadian20a/ahmadian20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ahmadian20a.html},\n  abstract = \t {In this paper, we study correlation clustering under fairness constraints.  Fair variants of $k$-median and $k$-center clustering have been studied recently, and approximation algorithms using a notion called fairlet decomposition have been proposed.  We obtain approximation algorithms for fair correlation clustering under several important types of fairness constraints.Our results hinge on obtaining a fairlet decomposition for correlation clustering by introducing a novel combinatorial optimization problem.  We define a fairlet decomposition with cost similar to the $k$-median cost and this allows us to obtain approximation algorithms for a wide range of fairness constraints. We complement our theoretical results with an in-depth analysis of our algorithms on real graphs where we show that fair solutions to correlation clustering can be obtained with limited increase in cost compared to the state-of-the-art (unfair) algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ahmadian20a/ahmadian20a.pdf",
        "supp": "",
        "pdf_size": 517500,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7421375001274374625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Google Research; Google Research; Google Research; Google Research",
        "aff_domain": "google.com;google.com;gmail.com;google.com",
        "email": "google.com;google.com;gmail.com;google.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b9165bf523",
        "title": "Fair Decisions Despite Imperfect Predictions",
        "site": "https://proceedings.mlr.press/v108/kilbertus20a.html",
        "author": "Niki Kilbertus; Manuel Gomez Rodriguez; Bernhard Sch\u00f6lkopf; Krikamol Muandet; Isabel Valera",
        "abstract": "Consequential decisions are increasingly informed by sophisticated data-driven predictive models. However, consistently learning accurate predictive models requires access to ground truth labels. Unfortunately, in practice, labels may only exist conditional on certain decisions\u2014if a loan is denied, there is not even an option for the individual to pay back the loan. In this paper, we show that, in this selective labels setting, learning to predict is suboptimal in terms of both fairness and utility. To avoid this undesirable behavior, we propose to directly learn stochastic decision policies that maximize utility under fairness constraints. In the context of fair machine learning, our results suggest the need for a paradigm shift from \"learning to predict\" to \"learning to decide\". Experiments on synthetic and real-world data illustrate the favorable properties of learning to decide, in terms of both utility and fairness.",
        "bibtex": "@InProceedings{pmlr-v108-kilbertus20a,\n  title = \t {Fair Decisions Despite Imperfect Predictions},\n  author =       {Kilbertus, Niki and Rodriguez, Manuel Gomez and Sch\\\"olkopf, Bernhard and Muandet, Krikamol and Valera, Isabel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {277--287},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kilbertus20a/kilbertus20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kilbertus20a.html},\n  abstract = \t {Consequential decisions are increasingly informed by sophisticated data-driven predictive models. However, consistently learning accurate predictive models requires access to ground truth labels. Unfortunately, in practice, labels may only exist conditional on certain decisions\u2014if a loan is denied, there is not even an option for the individual to pay back the loan. In this paper, we show that, in this selective labels setting, learning to predict is suboptimal in terms of both fairness and utility. To avoid this undesirable behavior, we propose to directly learn stochastic decision policies that maximize utility under fairness constraints. In the context of fair machine learning, our results suggest the need for a paradigm shift from \"learning to predict\" to \"learning to decide\". Experiments on synthetic and real-world data illustrate the favorable properties of learning to decide, in terms of both utility and fairness.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kilbertus20a/kilbertus20a.pdf",
        "supp": "",
        "pdf_size": 1718069,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9289041006063331321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "MPI for Intelligent Systems+University of Cambridge; MPI for Software Systems; MPI for Intelligent Systems; MPI for Intelligent Systems; MPI for Intelligent Systems",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;0;0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;University of Cambridge;Max Planck Institute for Software Systems",
        "aff_unique_dep": ";;Software Systems",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.cam.ac.uk;https://www.mpi-sws.org",
        "aff_unique_abbr": "MPI-IS;Cambridge;MPI-SWS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0+1;0;0;0;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "960db031d6",
        "title": "Fairness Evaluation in Presence of Biased Noisy Labels",
        "site": "https://proceedings.mlr.press/v108/fogliato20a.html",
        "author": "Riccardo Fogliato; Alexandra Chouldechova; Max G\u2019Sell",
        "abstract": "Risk assessment tools are widely used around the country to inform decision making within the criminal justice system. Recently, considerable attention has been devoted to the question of whether such tools may suffer from racial bias. In this type of assessment, a fundamental issue is that the training and evaluation of the model is based on a variable (arrest) that may represent a noisy version of an unobserved outcome of more central interest (offense). We propose a sensitivity analysis framework for assessing how assumptions on the noise across groups affect the predictive bias properties of the risk assessment model as a predictor of reoffense. Our experimental results on two real world criminal justice data sets demonstrate how even small biases in the observed labels may call into question the conclusions of an analysis based on the noisy outcome.",
        "bibtex": "@InProceedings{pmlr-v108-fogliato20a,\n  title = \t {Fairness Evaluation in Presence of Biased Noisy Labels},\n  author =       {Fogliato, Riccardo and Chouldechova, Alexandra and G'Sell, Max},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2325--2336},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fogliato20a/fogliato20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fogliato20a.html},\n  abstract = \t {Risk assessment tools are widely used around the country to inform decision making within the criminal justice system. Recently, considerable attention has been devoted to the question of whether such tools may suffer from racial bias. In this type of assessment, a fundamental issue is that the training and evaluation of the model is based on a variable (arrest) that may represent a noisy version of an unobserved outcome of more central interest (offense). We propose a sensitivity analysis framework for assessing how assumptions on the noise across groups affect the predictive bias properties of the risk assessment model as a predictor of reoffense. Our experimental results on two real world criminal justice data sets demonstrate how even small biases in the observed labels may call into question the conclusions of an analysis based on the noisy outcome. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/fogliato20a/fogliato20a.pdf",
        "supp": "",
        "pdf_size": 1648258,
        "gs_citation": 92,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1387225252816160505&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University + Partnership on AI",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Carnegie Mellon University;Partnership on AI",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.partnershiponai.org",
        "aff_unique_abbr": "CMU;PAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3077666358",
        "title": "Fast Algorithms for Computational Optimal Transport and Wasserstein Barycenter",
        "site": "https://proceedings.mlr.press/v108/guo20a.html",
        "author": "Wenshuo Guo; Nhat Ho; Michael Jordan",
        "abstract": "We provide theoretical complexity analysis for new algorithms to compute the optimal transport (OT) distance between two discrete probability distributions, and demonstrate their favorable practical performance compared to state-of-art primal-dual algorithms. First, we introduce the \\emph{accelerated primal-dual randomized coordinate descent} (APDRCD) algorithm for computing the OT distance. We show that its complexity is $\\bigOtil(\\frac{n^{5/2}}{\\varepsilon})$, where $n$ stands for the number of atoms of these probability measures and $\\varepsilon > 0$ is the desired accuracy. This complexity bound matches the best known complexities of primal-dual algorithms for the OT problems, including the adaptive primal-dual accelerated gradient descent (APDAGD) and the adaptive primal-dual accelerated mirror descent (APDAMD) algorithms. Then, we demonstrate the improved practical efficiency of the APDRCD algorithm through extensive comparative experimental studies.  We also propose a greedy version of APDRCD, which we refer to as \\emph{accelerated primal-dual greedy coordinate descent} (APDGCD), to further enhance practical performance. Finally, we generalize the APDRCD and APDGCD algorithms to distributed algorithms for computing the Wasserstein barycenter for multiple probability distributions.",
        "bibtex": "@InProceedings{pmlr-v108-guo20a,\n  title = \t {Fast Algorithms for Computational Optimal Transport and Wasserstein Barycenter},\n  author =       {Guo, Wenshuo and Ho, Nhat and Jordan, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2088--2097},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/guo20a/guo20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/guo20a.html},\n  abstract = \t {We provide theoretical complexity analysis for new algorithms to compute the optimal transport (OT) distance between two discrete probability distributions, and demonstrate their favorable practical performance compared to state-of-art primal-dual algorithms. First, we introduce the \\emph{accelerated primal-dual randomized coordinate descent} (APDRCD) algorithm for computing the OT distance. We show that its complexity is $\\bigOtil(\\frac{n^{5/2}}{\\varepsilon})$, where $n$ stands for the number of atoms of these probability measures and $\\varepsilon > 0$ is the desired accuracy. This complexity bound matches the best known complexities of primal-dual algorithms for the OT problems, including the adaptive primal-dual accelerated gradient descent (APDAGD) and the adaptive primal-dual accelerated mirror descent (APDAMD) algorithms. Then, we demonstrate the improved practical efficiency of the APDRCD algorithm through extensive comparative experimental studies.  We also propose a greedy version of APDRCD, which we refer to as \\emph{accelerated primal-dual greedy coordinate descent} (APDGCD), to further enhance practical performance. Finally, we generalize the APDRCD and APDGCD algorithms to distributed algorithms for computing the Wasserstein barycenter for multiple probability distributions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/guo20a/guo20a.pdf",
        "supp": "",
        "pdf_size": 1251011,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11686288545810576236&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9874eef56a",
        "title": "Fast Markov chain Monte Carlo algorithms via Lie groups",
        "site": "https://proceedings.mlr.press/v108/huntsman20a.html",
        "author": "Steve Huntsman",
        "abstract": "From basic considerations of the Lie group that preserves a target probability measure, we derive the Barker, Metropolis, and ensemble Markov chain Monte Carlo (MCMC) algorithms, as well as variants of waste-recycling Metropolis-Hastings and an altogether new MCMC algorithm. We illustrate these constructions with explicit numerical computations, and we empirically demonstrate on a spin glass that the new algorithm converges more quickly than its siblings.",
        "bibtex": "@InProceedings{pmlr-v108-huntsman20a,\n  title = \t {Fast Markov chain Monte Carlo algorithms via Lie groups},\n  author =       {Huntsman, Steve},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2841--2851},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/huntsman20a/huntsman20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/huntsman20a.html},\n  abstract = \t {From basic considerations of the Lie group that preserves a target probability measure, we derive the Barker, Metropolis, and ensemble Markov chain Monte Carlo (MCMC) algorithms, as well as variants of waste-recycling Metropolis-Hastings and an altogether new MCMC algorithm. We illustrate these constructions with explicit numerical computations, and we empirically demonstrate on a spin glass that the new algorithm converges more quickly than its siblings.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/huntsman20a/huntsman20a.pdf",
        "supp": "",
        "pdf_size": 959173,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9807160658821183878&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "BAE Systems FAST Labs",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "BAE Systems",
        "aff_unique_dep": "FAST Labs",
        "aff_unique_url": "https://www.baesystems.com/en-us",
        "aff_unique_abbr": "BAE",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9194cdcc8d",
        "title": "Fast Noise Removal for k-Means Clustering",
        "site": "https://proceedings.mlr.press/v108/im20a.html",
        "author": "Sungjin Im; Mahshid Montazer Qaem; Benjamin Moseley; Xiaorui Sun; Rudy Zhou",
        "abstract": "This paper considers k-means clustering in the presence of noise. It is known that k-means clustering is highly sensitive to noise, and thus noise should be removed to obtain a quality solution. A popular formulation of this problem is called k-means clustering with outliers. The goal of k-means clustering with outliers is to discard up to a specified number z of points as noise/outliers and then find a k-means solution on the remaining data. The problem has received significant attention, yet current algorithms with theoretical guarantees suffer from either high running time or inherent loss in the solution quality. The main contribution of this paper is two-fold. Firstly, we develop a simple greedy algorithm that has provably strong worst case guarantees. The greedy algorithm  adds a simple preprocessing step to remove noise, which can be combined with any k-means clustering algorithm. This algorithm gives the first pseudo-approximation-preserving reduction from k-means with outliers to k-means without outliers. Secondly, we show how to construct a coreset of size O(k log n).  When combined with our greedy algorithm, we obtain a scalable, near linear time algorithm. The theoretical contributions are verified experimentally by demonstrating that the algorithm quickly removes noise and obtains a high-quality clustering.",
        "bibtex": "@InProceedings{pmlr-v108-im20a,\n  title = \t {Fast Noise Removal for k-Means Clustering},\n  author =       {Im, Sungjin and Qaem, Mahshid Montazer and Moseley, Benjamin and Sun, Xiaorui and Zhou, Rudy},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {456--466},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/im20a/im20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/im20a.html},\n  abstract = \t {This paper considers k-means clustering in the presence of noise. It is known that k-means clustering is highly sensitive to noise, and thus noise should be removed to obtain a quality solution. A popular formulation of this problem is called k-means clustering with outliers. The goal of k-means clustering with outliers is to discard up to a specified number z of points as noise/outliers and then find a k-means solution on the remaining data. The problem has received significant attention, yet current algorithms with theoretical guarantees suffer from either high running time or inherent loss in the solution quality. The main contribution of this paper is two-fold. Firstly, we develop a simple greedy algorithm that has provably strong worst case guarantees. The greedy algorithm  adds a simple preprocessing step to remove noise, which can be combined with any k-means clustering algorithm. This algorithm gives the first pseudo-approximation-preserving reduction from k-means with outliers to k-means without outliers. Secondly, we show how to construct a coreset of size O(k log n).  When combined with our greedy algorithm, we obtain a scalable, near linear time algorithm. The theoretical contributions are verified experimentally by demonstrating that the algorithm quickly removes noise and obtains a high-quality clustering. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/im20a/im20a.pdf",
        "supp": "",
        "pdf_size": 628303,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15175095046985956568&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of California at Merced; University of California at Merced; Carnegie Mellon University; University of Illinois at Chicago; Carnegie Mellon University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;1",
        "aff_unique_norm": "University of California, Merced;Carnegie Mellon University;University of Illinois at Chicago",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucmerced.edu;https://www.cmu.edu;https://www.uic.edu",
        "aff_unique_abbr": "UC Merced;CMU;UIC",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Merced;;Chicago",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0b5d1333da",
        "title": "Fast and Accurate Ranking Regression",
        "site": "https://proceedings.mlr.press/v108/yildiz20a.html",
        "author": "Ilkay Yildiz; Jennifer Dy; Deniz Erdogmus; Jayashree Kalpathy-Cramer; Susan Ostmo; J. Peter Campbell; Michael F. Chiang; Stratis Ioannidis",
        "abstract": "We consider a ranking regression problem in which we use a dataset of ranked choices to learn Plackett-Luce scores as functions of sample features. We solve the maximum likelihood estimation problem by using the Alternating Directions Method of Multipliers (ADMM), effectively separating the learning of scores and model parameters. This separation allows us to  express scores as the stationary distribution of a continuous-time Markov Chain. Using this equivalence, we propose two spectral algorithms for ranking regression that learn model parameters up to 579 times faster than the Newton\u2019s method.",
        "bibtex": "@InProceedings{pmlr-v108-yildiz20a,\n  title = \t {Fast and Accurate Ranking Regression},\n  author =       {Yildiz, Ilkay and Dy, Jennifer and Erdogmus, Deniz and Kalpathy-Cramer, Jayashree and Ostmo, Susan and Campbell, J. Peter and Chiang, Michael F. and Ioannidis, Stratis},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {77--88},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yildiz20a/yildiz20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yildiz20a.html},\n  abstract = \t {We consider a ranking regression problem in which we use a dataset of ranked choices to learn Plackett-Luce scores as functions of sample features. We solve the maximum likelihood estimation problem by using the Alternating Directions Method of Multipliers (ADMM), effectively separating the learning of scores and model parameters. This separation allows us to  express scores as the stationary distribution of a continuous-time Markov Chain. Using this equivalence, we propose two spectral algorithms for ranking regression that learn model parameters up to 579 times faster than the Newton\u2019s method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yildiz20a/yildiz20a.pdf",
        "supp": "",
        "pdf_size": 685167,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10222072400684176367&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Dept. of ECE, Northeastern Univ.; Dept. of ECE, Northeastern Univ.; Dept. of ECE, Northeastern Univ.; Dept. of Radiology, MGH/Harvard Medical School; Dept. of Ophthalmology, Casey Eye Inst., OHSU; Dept. of Ophthalmology, Casey Eye Inst., OHSU; Dept. of Ophthalmology, Casey Eye Inst., OHSU; Dept. of ECE, Northeastern Univ.",
        "aff_domain": "ece.neu.edu;ece.neu.edu;ece.neu.edu;nmr.mgh.harvard.edu;ohsu.edu;ohsu.edu;ohsu.edu;ece.neu.edu",
        "email": "ece.neu.edu;ece.neu.edu;ece.neu.edu;nmr.mgh.harvard.edu;ohsu.edu;ohsu.edu;ohsu.edu;ece.neu.edu",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2;2;2;0",
        "aff_unique_norm": "Northeastern University;MGH/Harvard Medical School;Oregon Health & Science University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Dept. of Radiology;Department of Ophthalmology",
        "aff_unique_url": "https://www.northeastern.edu;https://www.mgh.harvard.edu;https://www.ohsu.edu",
        "aff_unique_abbr": "NU;MGH;OHSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";MGH",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b7ef2ec8bb",
        "title": "Fast and Bayes-consistent nearest neighbors",
        "site": "https://proceedings.mlr.press/v108/efremenko20a.html",
        "author": "Klim Efremenko; Aryeh Kontorovich; Moshe Noivirt",
        "abstract": "Research on nearest-neighbor methods tends to focus somewhat dichotomously either on the statistical or the computational aspects \u2013 either on, say, Bayes consistency and rates of convergence or on techniques for speeding up the proximity search. This paper aims at bridging these realms: to reap the advantages of fast evaluation time while maintaining Bayes consistency, and further without sacrificing too much in the risk decay rate. We combine the locality-sensitive hashing (LSH) technique with a novel missing-mass argument to obtain a fast and Bayes-consistent classifier. Our algorithm\u2019s prediction runtime compares favorably against state of the art approximate NN methods, while maintaining Bayes-consistency and attaining rates comparable to minimax. On samples of size $n$ in $\\R^d$, our pre-processing phase has runtime $O(d n \\log n)$, while the evaluation phase has runtime $O(d\\log n)$ per query point.",
        "bibtex": "@InProceedings{pmlr-v108-efremenko20a,\n  title = \t {Fast and Bayes-consistent nearest neighbors},\n  author =       {Efremenko, Klim and Kontorovich, Aryeh and Noivirt, Moshe},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1276--1286},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/efremenko20a/efremenko20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/efremenko20a.html},\n  abstract = \t {Research on nearest-neighbor methods tends to focus somewhat dichotomously either on the statistical or the computational aspects \u2013 either on, say, Bayes consistency and rates of convergence or on techniques for speeding up the proximity search. This paper aims at bridging these realms: to reap the advantages of fast evaluation time while maintaining Bayes consistency, and further without sacrificing too much in the risk decay rate. We combine the locality-sensitive hashing (LSH) technique with a novel missing-mass argument to obtain a fast and Bayes-consistent classifier. Our algorithm\u2019s prediction runtime compares favorably against state of the art approximate NN methods, while maintaining Bayes-consistency and attaining rates comparable to minimax. On samples of size $n$ in $\\R^d$, our pre-processing phase has runtime $O(d n \\log n)$, while the evaluation phase has runtime $O(d\\log n)$ per query point.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/efremenko20a/efremenko20a.pdf",
        "supp": "",
        "pdf_size": 320353,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8463041688753231915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6898597fe0",
        "title": "Fast and Furious Convergence: Stochastic Second Order Methods under Interpolation",
        "site": "https://proceedings.mlr.press/v108/meng20a.html",
        "author": "Si Yi Meng; Sharan Vaswani; Issam Hadj Laradji); Mark Schmidt; Simon Lacoste-Julien",
        "abstract": "We consider stochastic second-order methods for minimizing smooth and strongly-convex functions under an interpolation condition satisfied by over-parameterized models. Under this condition, we show that the regularized subsampled Newton method (R-SSN) achieves global linear convergence with an adaptive step-size and a constant batch-size. By growing the batch size for both the subsampled gradient and Hessian, we show that R-SSN can converge at a quadratic rate in a local neighbourhood of the solution. We also show that R-SSN attains local linear convergence for the family of self-concordant functions. Furthermore, we analyze stochastic BFGS algorithms in the interpolation setting and prove their global linear convergence. We empirically evaluate stochastic L-BFGS and a \"Hessian-free\" implementation of R-SSN for binary classification on synthetic, linearly-separable datasets and real datasets under a kernel mapping. Our experimental results demonstrate the fast convergence of these methods, both in terms of the number of iterations and wall-clock time.",
        "bibtex": "@InProceedings{pmlr-v108-meng20a,\n  title = \t {Fast and Furious Convergence: Stochastic Second Order Methods under Interpolation},\n  author =       {Meng, Si Yi and Vaswani, Sharan and Laradji), Issam Hadj and Schmidt, Mark and Lacoste-Julien, Simon},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1375--1386},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/meng20a/meng20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/meng20a.html},\n  abstract = \t {We consider stochastic second-order methods for minimizing smooth and strongly-convex functions under an interpolation condition satisfied by over-parameterized models. Under this condition, we show that the regularized subsampled Newton method (R-SSN) achieves global linear convergence with an adaptive step-size and a constant batch-size. By growing the batch size for both the subsampled gradient and Hessian, we show that R-SSN can converge at a quadratic rate in a local neighbourhood of the solution. We also show that R-SSN attains local linear convergence for the family of self-concordant functions. Furthermore, we analyze stochastic BFGS algorithms in the interpolation setting and prove their global linear convergence. We empirically evaluate stochastic L-BFGS and a \"Hessian-free\" implementation of R-SSN for binary classification on synthetic, linearly-separable datasets and real datasets under a kernel mapping. Our experimental results demonstrate the fast convergence of these methods, both in terms of the number of iterations and wall-clock time.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/meng20a/meng20a.pdf",
        "supp": "",
        "pdf_size": 2870581,
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7586452932375042311&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6185a350d6",
        "title": "Feature relevance quantification in explainable AI: A causal problem",
        "site": "https://proceedings.mlr.press/v108/janzing20a.html",
        "author": "Dominik Janzing; Lenon Minorics; Patrick Bloebaum",
        "abstract": "We discuss promising recent contributions on quantifying feature relevance using Shapley values, where we observed some confusion on which probability distribution is the right one for dropped features. We argue that the confusion is based on not carefully distinguishing between observational and interventional conditional probabilities and try a clarification based on Pearl\u2019s seminal work on causality. We conclude that unconditional rather than conditional expectations provide the right notion of dropping features. This contradicts the view of the authors of the software package SHAP. In that work, unconditional expectations (which we argue to be conceptually right) are only used as approximation for the conditional ones, which encouraged others to \u2019improve\u2019 SHAP in a way that we believe to be flawed.",
        "bibtex": "@InProceedings{pmlr-v108-janzing20a,\n  title = \t {Feature relevance quantification in explainable AI: A causal problem},\n  author =       {Janzing, Dominik and Minorics, Lenon and Bloebaum, Patrick},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2907--2916},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/janzing20a/janzing20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/janzing20a.html},\n  abstract = \t {We discuss promising recent contributions on quantifying feature relevance using Shapley values, where we observed some confusion on which probability distribution is the right one for dropped features. We argue that the confusion is based on not carefully distinguishing between observational and interventional conditional probabilities and try a clarification based on Pearl\u2019s seminal work on causality. We conclude that unconditional rather than conditional expectations provide the right notion of dropping features. This contradicts the view of the authors of the software package SHAP. In that work, unconditional expectations (which we argue to be conceptually right) are only used as approximation for the conditional ones, which encouraged others to \u2019improve\u2019 SHAP in a way that we believe to be flawed.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/janzing20a/janzing20a.pdf",
        "supp": "",
        "pdf_size": 285319,
        "gs_citation": 429,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12062617284865393714&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Amazon Research T \u00a8ubingen, Germany; ; ",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Amazon",
        "aff_unique_dep": "Amazon Research",
        "aff_unique_url": "https://www.amazon.science",
        "aff_unique_abbr": "Amazon Research",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "a0197a2434",
        "title": "FedPAQ: A Communication-Efficient Federated Learning Method with Periodic Averaging and Quantization",
        "site": "https://proceedings.mlr.press/v108/reisizadeh20a.html",
        "author": "Amirhossein Reisizadeh; Aryan Mokhtari; Hamed Hassani; Ali Jadbabaie; Ramtin Pedarsani",
        "abstract": "Federated learning is a distributed framework according to which  a model is trained over a set of devices, while keeping data localized. This framework  faces several systems-oriented challenges which include (i) communication bottleneck since a large number of devices upload their local updates to a parameter server, and (ii) scalability as the federated network consists of millions of devices. Due to these systems challenges as well as issues related to statistical heterogeneity of data and privacy concerns, designing a provably efficient federated learning method is of significant importance yet it remains challenging. In this paper, we present FedPAQ, a communication-efficient Federated Learning method with Periodic Averaging and Quantization. FedPAQ relies on three key features: (1) periodic averaging where models are updated locally at devices and only periodically averaged at the server; (2) partial device participation where only a fraction of devices participate in each round of the training; and (3) quantized message-passing where the edge nodes quantize their updates before uploading to the parameter server. These features address the communications and scalability challenges in federated learning. We also show that FedPAQ achieves near-optimal theoretical guarantees for strongly convex and non-convex loss functions and empirically demonstrate the communication-computation tradeoff provided by our method.",
        "bibtex": "@InProceedings{pmlr-v108-reisizadeh20a,\n  title = \t {FedPAQ: A Communication-Efficient Federated Learning Method with Periodic Averaging and Quantization},\n  author =       {Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Jadbabaie, Ali and Pedarsani, Ramtin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2021--2031},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/reisizadeh20a/reisizadeh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/reisizadeh20a.html},\n  abstract = \t {Federated learning is a distributed framework according to which  a model is trained over a set of devices, while keeping data localized. This framework  faces several systems-oriented challenges which include (i) communication bottleneck since a large number of devices upload their local updates to a parameter server, and (ii) scalability as the federated network consists of millions of devices. Due to these systems challenges as well as issues related to statistical heterogeneity of data and privacy concerns, designing a provably efficient federated learning method is of significant importance yet it remains challenging. In this paper, we present FedPAQ, a communication-efficient Federated Learning method with Periodic Averaging and Quantization. FedPAQ relies on three key features: (1) periodic averaging where models are updated locally at devices and only periodically averaged at the server; (2) partial device participation where only a fraction of devices participate in each round of the training; and (3) quantized message-passing where the edge nodes quantize their updates before uploading to the parameter server. These features address the communications and scalability challenges in federated learning. We also show that FedPAQ achieves near-optimal theoretical guarantees for strongly convex and non-convex loss functions and empirically demonstrate the communication-computation tradeoff provided by our method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/reisizadeh20a/reisizadeh20a.pdf",
        "supp": "",
        "pdf_size": 1195857,
        "gs_citation": 1017,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3241539560705490650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "UC Santa Barbara; UT Austin; UPenn; MIT; UC Santa Barbara",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of California, Santa Barbara;University of Texas at Austin;University of Pennsylvania;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.ucsb.edu;https://www.utexas.edu;https://www.upenn.edu;https://web.mit.edu",
        "aff_unique_abbr": "UCSB;UT Austin;UPenn;MIT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Santa Barbara;Austin;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "28bed7f212",
        "title": "Federated Heavy Hitters Discovery with Differential Privacy",
        "site": "https://proceedings.mlr.press/v108/zhu20a.html",
        "author": "Wennan Zhu; Peter Kairouz; Brendan McMahan; Haicheng Sun; Wei Li",
        "abstract": "The discovery of heavy hitters (most frequent items) in user-generated data streams drives improvements in the app and web ecosystems, but can incur substantial privacy risks if not done with care. To address these risks, we propose a distributed and privacy-preserving algorithm for discovering the heavy hitters in a population of user-generated data streams. We leverage the sampling and thresholding properties of our distributed algorithm to prove that it is inherently differentially private, without requiring additional noise. We also examine the trade-off between privacy and utility, and show that our algorithm provides excellent utility while also achieving strong privacy guarantees. A significant advantage of this approach is that it eliminates the need to centralize raw data while also avoiding the significant loss in utility incurred by local differential privacy. We validate our findings both theoretically, using worst-case analyses, and practically, using a Twitter dataset with 1.6M tweets and over 650k users. Finally, we carefully compare our approach to Apple\u2019s local differential privacy method for discovering heavy hitters.",
        "bibtex": "@InProceedings{pmlr-v108-zhu20a,\n  title = \t {Federated Heavy Hitters Discovery with Differential Privacy},\n  author =       {Zhu, Wennan and Kairouz, Peter and McMahan, Brendan and Sun, Haicheng and Li, Wei},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3837--3847},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhu20a/zhu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhu20a.html},\n  abstract = \t {The discovery of heavy hitters (most frequent items) in user-generated data streams drives improvements in the app and web ecosystems, but can incur substantial privacy risks if not done with care. To address these risks, we propose a distributed and privacy-preserving algorithm for discovering the heavy hitters in a population of user-generated data streams. We leverage the sampling and thresholding properties of our distributed algorithm to prove that it is inherently differentially private, without requiring additional noise. We also examine the trade-off between privacy and utility, and show that our algorithm provides excellent utility while also achieving strong privacy guarantees. A significant advantage of this approach is that it eliminates the need to centralize raw data while also avoiding the significant loss in utility incurred by local differential privacy. We validate our findings both theoretically, using worst-case analyses, and practically, using a Twitter dataset with 1.6M tweets and over 650k users. Finally, we carefully compare our approach to Apple\u2019s local differential privacy method for discovering heavy hitters.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhu20a/zhu20a.pdf",
        "supp": "",
        "pdf_size": 1300458,
        "gs_citation": 129,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6583797001284695689&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "RPI; Google; Google; Google; Google",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Rensselaer Polytechnic Institute;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.rpi.edu;https://www.google.com",
        "aff_unique_abbr": "RPI;Google",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "96e3b0d58c",
        "title": "Fenchel Lifted Networks: A Lagrange Relaxation of Neural Network Training",
        "site": "https://proceedings.mlr.press/v108/gu20a.html",
        "author": "Fangda Gu; Armin Askari; Laurent El Ghaoui",
        "abstract": "Despite the recent successes of deep neural networks, the corresponding training problem remains highly non-convex and difficult to optimize. Classes of models have been proposed that introduce greater structure to the objective function at the cost of lifting the dimension of the problem. However, these lifted methods sometimes perform poorly compared to traditional neural networks. In this paper, we introduce a new class of lifted models, Fenchel lifted networks, that enjoy the same benefits as previous lifted models, without suffering a degradation in performance over classical networks. Our model represents activation functions as equivalent biconvex constraints and uses Lagrange Multipliers to arrive at a rigorous lower bound of the traditional neural network training problem. This model is efficiently trained using block-coordinate descent and is parallelizable across data points and/or layers. We compare our model against standard fully connected and convolutional networks and show that we are able to match or beat their performance.",
        "bibtex": "@InProceedings{pmlr-v108-gu20a,\n  title = \t {Fenchel Lifted Networks: A Lagrange Relaxation of Neural Network Training},\n  author =       {Gu, Fangda and Askari, Armin and Ghaoui, Laurent El},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3362--3371},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gu20a/gu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gu20a.html},\n  abstract = \t {Despite the recent successes of deep neural networks, the corresponding training problem remains highly non-convex and difficult to optimize. Classes of models have been proposed that introduce greater structure to the objective function at the cost of lifting the dimension of the problem. However, these lifted methods sometimes perform poorly compared to traditional neural networks. In this paper, we introduce a new class of lifted models, Fenchel lifted networks, that enjoy the same benefits as previous lifted models, without suffering a degradation in performance over classical networks. Our model represents activation functions as equivalent biconvex constraints and uses Lagrange Multipliers to arrive at a rigorous lower bound of the traditional neural network training problem. This model is efficiently trained using block-coordinate descent and is parallelizable across data points and/or layers. We compare our model against standard fully connected and convolutional networks and show that we are able to match or beat their performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/gu20a/gu20a.pdf",
        "supp": "",
        "pdf_size": 526390,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6252086779295382196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California at Berkeley; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "https://github.com/beeperman/Fenchel_Lifted_Networks",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5d487a6ee6",
        "title": "Finite-Time Analysis of Decentralized Temporal-Difference Learning with Linear Function Approximation",
        "site": "https://proceedings.mlr.press/v108/sun20a.html",
        "author": "Jun Sun; Gang Wang; Georgios B. Giannakis; Qinmin Yang; Zaiyue Yang",
        "abstract": "Motivated by the emerging use of multi-agent reinforcement learning (MARL) in engineering applications such as networked robotics, swarming drones, and sensor networks, we investigate the policy evaluation problem in a fully decentralized setting, using temporal-difference (TD) learning with linear function approximation to handle large state spaces in practice. The goal of the group of agents is to collaboratively learn the value function of a given policy from locally private rewards observed in a shared environment, through exchanging local estimates with neighbors. Despite their simplicity and widespread use, our theoretical understanding of such decentralized TD learning algorithms remains limited. Existing results were obtained based on i.i.d. data samples, or by imposing an \u2018additional\u2019 projection step to control the \u2018gradient\u2019 bias incurred by the Markovian observations. In this paper, we provide a finite-time analysis of the fully decentralized TD(0) learning under both i.i.d. as well as Markovian samples, and prove that all local estimates converge linearly to a small neighborhood of the optimum. The resultant error bounds are the first of its type\u2014in the sense that they hold under the most practical assumptions\u2014which is made possible by means of a novel multi-step Lyapunov approach.",
        "bibtex": "@InProceedings{pmlr-v108-sun20a,\n  title = \t {Finite-Time Analysis of Decentralized Temporal-Difference Learning with Linear Function Approximation},\n  author =       {Sun, Jun and Wang, Gang and Giannakis, Georgios B. and Yang, Qinmin and Yang, Zaiyue},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4485--4495},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sun20a/sun20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sun20a.html},\n  abstract = \t {Motivated by the emerging use of multi-agent reinforcement learning (MARL) in engineering applications such as networked robotics, swarming drones, and sensor networks, we investigate the policy evaluation problem in a fully decentralized setting, using temporal-difference (TD) learning with linear function approximation to handle large state spaces in practice. The goal of the group of agents is to collaboratively learn the value function of a given policy from locally private rewards observed in a shared environment, through exchanging local estimates with neighbors. Despite their simplicity and widespread use, our theoretical understanding of such decentralized TD learning algorithms remains limited. Existing results were obtained based on i.i.d. data samples, or by imposing an \u2018additional\u2019 projection step to control the \u2018gradient\u2019 bias incurred by the Markovian observations. In this paper, we provide a finite-time analysis of the fully decentralized TD(0) learning under both i.i.d. as well as Markovian samples, and prove that all local estimates converge linearly to a small neighborhood of the optimum. The resultant error bounds are the first of its type\u2014in the sense that they hold under the most practical assumptions\u2014which is made possible by means of a novel multi-step Lyapunov approach.  }\n}",
        "pdf": "http://proceedings.mlr.press/v108/sun20a/sun20a.pdf",
        "supp": "",
        "pdf_size": 367569,
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3185984859971565990&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Zhejiang University; University of Minnesota; University of Minnesota; Zhejiang University; Southern University of Science and Technology",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "Zhejiang University;University of Minnesota;Southern University of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.zju.edu.cn;https://www.minnesota.edu;https://www.sustech.edu.cn",
        "aff_unique_abbr": "ZJU;UMN;SUSTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "546b0cb4ca",
        "title": "Finite-Time Error Bounds for Biased Stochastic Approximation with Applications to Q-Learning",
        "site": "https://proceedings.mlr.press/v108/wang20h.html",
        "author": "Gang Wang; Georgios B. Giannakis",
        "abstract": "Inspired by the widespread use of Q-learning algorithms in reinforcement learning (RL), this present paper studies a class of  biased stochastic approximation (SA) procedures under an \u2018ergodic-like\u2019 assumption on the underlying stochastic noise sequence. Leveraging a \\emph{multistep Lyapunov function} that looks ahead to several future updates to accommodate the gradient bias, we prove a general result on the convergence of the iterates, and use it to derive finite-time bounds on the mean-square error in the case of constant stepsizes. This novel viewpoint renders the finite-time analysis of \\emph{biased SA} algorithms under a broad family of stochastic perturbations possible. For direct comparison with past works, we also demonstrate these bounds by applying them to Q-learning with linear function approximation, under the realistic Markov chain observation model. The resultant finite-time error bound for Q-learning is \\emph{the first of its kind}, in the sense that it holds: i) for the unmodified version (i.e., without making any modifications to the updates), and ii), for Markov chains starting from any initial distribution, at least one of which has to be violated for existing results to be applicable.",
        "bibtex": "@InProceedings{pmlr-v108-wang20h,\n  title = \t {Finite-Time Error Bounds for Biased Stochastic Approximation with Applications to Q-Learning},\n  author =       {Wang, Gang and Giannakis, Georgios B.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3015--3024},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20h/wang20h.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20h.html},\n  abstract = \t {Inspired by the widespread use of Q-learning algorithms in reinforcement learning (RL), this present paper studies a class of  biased stochastic approximation (SA) procedures under an \u2018ergodic-like\u2019 assumption on the underlying stochastic noise sequence. Leveraging a \\emph{multistep Lyapunov function} that looks ahead to several future updates to accommodate the gradient bias, we prove a general result on the convergence of the iterates, and use it to derive finite-time bounds on the mean-square error in the case of constant stepsizes. This novel viewpoint renders the finite-time analysis of \\emph{biased SA} algorithms under a broad family of stochastic perturbations possible. For direct comparison with past works, we also demonstrate these bounds by applying them to Q-learning with linear function approximation, under the realistic Markov chain observation model. The resultant finite-time error bound for Q-learning is \\emph{the first of its kind}, in the sense that it holds: i) for the unmodified version (i.e., without making any modifications to the updates), and ii), for Markov chains starting from any initial distribution, at least one of which has to be violated for existing results to be applicable.  }\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20h/wang20h.pdf",
        "supp": "",
        "pdf_size": 316018,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10112170514670953798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455",
        "aff_domain": "umn.edu;umn.edu",
        "email": "umn.edu;umn.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8440c505ad",
        "title": "Fixed-confidence guarantees for Bayesian best-arm identification",
        "site": "https://proceedings.mlr.press/v108/shang20a.html",
        "author": "Xuedong Shang; Rianne Heide; Pierre Menard; Emilie Kaufmann; Michal Valko",
        "abstract": "We investigate and provide new insights on the sampling rule called Top-Two Thompson Sampling (TTTS). In particular, we justify its use for fixed-confidence best-arm identification. We further propose a variant of TTTS called Top-Two Transportation Cost (T3C), which disposes of the computational burden of TTTS. As our main contribution, we provide the first sample complexity analysis of TTTS and T3C when coupled with a very natural Bayesian stopping rule, for bandits with Gaussian rewards, solving one of the open questions raised by Russo (2016). We also provide new posterior convergence results for TTTS under two models that are commonly used in practice: bandits with Gaussian and Bernoulli rewards and conjugate priors.",
        "bibtex": "@InProceedings{pmlr-v108-shang20a,\n  title = \t {Fixed-confidence guarantees for Bayesian best-arm identification},\n  author =       {Shang, Xuedong and de Heide, Rianne and Menard, Pierre and Kaufmann, Emilie and Valko, Michal},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1823--1832},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shang20a/shang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shang20a.html},\n  abstract = \t {We investigate and provide new insights on the sampling rule called Top-Two Thompson Sampling (TTTS). In particular, we justify its use for fixed-confidence best-arm identification. We further propose a variant of TTTS called Top-Two Transportation Cost (T3C), which disposes of the computational burden of TTTS. As our main contribution, we provide the first sample complexity analysis of TTTS and T3C when coupled with a very natural Bayesian stopping rule, for bandits with Gaussian rewards, solving one of the open questions raised by Russo (2016). We also provide new posterior convergence results for TTTS under two models that are commonly used in practice: bandits with Gaussian and Bernoulli rewards and conjugate priors.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shang20a/shang20a.pdf",
        "supp": "",
        "pdf_size": 1238661,
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17516674132758653834&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 21,
        "aff": "Inria Lille Nord Europe+Universit\u00e9 de Lille; Leiden University+CWI; Inria Lille Nord Europe+CNRS; Inria Lille Nord Europe; DeepMind Paris+Inria Lille Nord Europe",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2+3;0+4;0;5+0",
        "aff_unique_norm": "INRIA;Universit\u00e9 de Lille;Leiden University;Centrum Wiskunde & Informatica;Centre National de la Recherche Scientifique;DeepMind",
        "aff_unique_dep": ";;;;;",
        "aff_unique_url": "https://www.inria.fr;https://www.univ-lille.fr;https://www.leidenuniv.nl;https://www.cwi.nl;https://www.cnrs.fr;https://deepmind.com",
        "aff_unique_abbr": "Inria;UdeL;LU;CWI;CNRS;DeepMind",
        "aff_campus_unique_index": "0;;0;0;2+0",
        "aff_campus_unique": "Lille;;Paris",
        "aff_country_unique_index": "0+0;1+1;0+0;0;0+0",
        "aff_country_unique": "France;Netherlands"
    },
    {
        "id": "cc6f35f484",
        "title": "Flexible distribution-free conditional predictive bands using density estimators",
        "site": "https://proceedings.mlr.press/v108/izbicki20a.html",
        "author": "Rafael Izbicki; Gilson Shimizu; Rafael Stern",
        "abstract": "Conformal methods create prediction bands that control average coverage assuming solely i.i.d. data. Besides average coverage, one might also desire to control conditional coverage, that is, coverage for every new testing point. However, without strong assumptions, conditional coverage is unachievable. Given this limitation, the literature has focused on methods with asymptotical conditional coverage. In order to obtain this property, these methods require strong conditions on the dependence between the target variable and the features. We introduce two conformal methods based on conditional density estimators that do not depend on this type of assumption to obtain asymptotic conditional coverage: Dist-split and CD-split. While Dist-split asymptotically obtains optimal intervals, which are easier to interpret than general regions, CD-split obtains optimal size regions, which are smaller than intervals. CD-split also obtains local coverage by creating prediction bands locally on a partition of the features space. This partition is data-driven and scales to high-dimensional settings. In a wide variety of simulated scenarios, our methods have a better control of conditional coverage and have smaller length than previously proposed methods.",
        "bibtex": "@InProceedings{pmlr-v108-izbicki20a,\n  title = \t {Flexible distribution-free conditional predictive bands using density estimators},\n  author =       {Izbicki, Rafael and Shimizu, Gilson and Stern, Rafael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3068--3077},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/izbicki20a/izbicki20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/izbicki20a.html},\n  abstract = \t {Conformal methods create prediction bands that control average coverage assuming solely i.i.d. data. Besides average coverage, one might also desire to control conditional coverage, that is, coverage for every new testing point. However, without strong assumptions, conditional coverage is unachievable. Given this limitation, the literature has focused on methods with asymptotical conditional coverage. In order to obtain this property, these methods require strong conditions on the dependence between the target variable and the features. We introduce two conformal methods based on conditional density estimators that do not depend on this type of assumption to obtain asymptotic conditional coverage: Dist-split and CD-split. While Dist-split asymptotically obtains optimal intervals, which are easier to interpret than general regions, CD-split obtains optimal size regions, which are smaller than intervals. CD-split also obtains local coverage by creating prediction bands locally on a partition of the features space. This partition is data-driven and scales to high-dimensional settings. In a wide variety of simulated scenarios, our methods have a better control of conditional coverage and have smaller length than previously proposed methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/izbicki20a/izbicki20a.pdf",
        "supp": "",
        "pdf_size": 7511905,
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9578843946080125842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9acd5f27c5",
        "title": "Formal Limitations on the Measurement of Mutual Information",
        "site": "https://proceedings.mlr.press/v108/mcallester20a.html",
        "author": "David McAllester; Karl Stratos",
        "abstract": "Measuring mutual information from finite data is difficult. Recent work has considered variational methods maximizing a lower bound. In this paper, we prove that serious statistical limitations are inherent to any method of measuring mutual information. More specifically, we show that any distribution-free high-confidence lower bound on mutual information estimated from N samples cannot be larger than O(ln N).",
        "bibtex": "@InProceedings{pmlr-v108-mcallester20a,\n  title = \t {Formal Limitations on the Measurement of Mutual Information},\n  author =       {McAllester, David and Stratos, Karl},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {875--884},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mcallester20a/mcallester20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mcallester20a.html},\n  abstract = \t {Measuring mutual information from finite data is difficult. Recent work has considered variational methods maximizing a lower bound. In this paper, we prove that serious statistical limitations are inherent to any method of measuring mutual information. More specifically, we show that any distribution-free high-confidence lower bound on mutual information estimated from N samples cannot be larger than O(ln N).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mcallester20a/mcallester20a.pdf",
        "supp": "",
        "pdf_size": 523711,
        "gs_citation": 331,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1389531273282997728&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Toyota Technological Institute at Chicago; Rutgers University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Toyota Technological Institute at Chicago;Rutgers University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tti-chicago.org;https://www.rutgers.edu",
        "aff_unique_abbr": "TTI Chicago;Rutgers",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Chicago;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "71cd6c9908",
        "title": "Frequentist Regret Bounds for Randomized Least-Squares Value Iteration",
        "site": "https://proceedings.mlr.press/v108/zanette20a.html",
        "author": "Andrea Zanette; David Brandfonbrener; Emma Brunskill; Matteo Pirotta; Alessandro Lazaric",
        "abstract": "We consider the exploration-exploitation dilemma in finite-horizon reinforcement learning (RL). When the state space is large or continuous, traditional tabular approaches are unfeasible and some form of function approximation is mandatory. In this paper, we introduce an optimistically-initialized variant of the popular randomized least-squares value iteration (RLSVI), a model-free algorithm where exploration is induced by perturbing the least-squares approximation of the action-value function. Under the assumption that the Markov decision process has low-rank transition dynamics, we prove that the frequentist regret of RLSVI is upper-bounded by $\\widetilde O(d^2 H^2 \\sqrt{T})$ where $ d $ are the feature dimension, $ H $ is the horizon, and $ T $ is the total number of steps. To the best of our knowledge, this is the first frequentist regret analysis for randomized exploration with function approximation.",
        "bibtex": "@InProceedings{pmlr-v108-zanette20a,\n  title = \t {Frequentist Regret Bounds for Randomized Least-Squares Value Iteration},\n  author =       {Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1954--1964},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zanette20a/zanette20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zanette20a.html},\n  abstract = \t {We consider the exploration-exploitation dilemma in finite-horizon reinforcement learning (RL). When the state space is large or continuous, traditional tabular approaches are unfeasible and some form of function approximation is mandatory. In this paper, we introduce an optimistically-initialized variant of the popular randomized least-squares value iteration (RLSVI), a model-free algorithm where exploration is induced by perturbing the least-squares approximation of the action-value function. Under the assumption that the Markov decision process has low-rank transition dynamics, we prove that the frequentist regret of RLSVI is upper-bounded by $\\widetilde O(d^2 H^2 \\sqrt{T})$ where $ d $ are the feature dimension, $ H $ is the horizon, and $ T $ is the total number of steps. To the best of our knowledge, this is the first frequentist regret analysis for randomized exploration with function approximation.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zanette20a/zanette20a.pdf",
        "supp": "",
        "pdf_size": 477840,
        "gs_citation": 161,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2465484613736814483&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; New York University; Stanford University; Facebook AI Research; Facebook AI Research",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Stanford University;New York University;Meta",
        "aff_unique_dep": ";;Facebook AI Research",
        "aff_unique_url": "https://www.stanford.edu;https://www.nyu.edu;https://research.facebook.com",
        "aff_unique_abbr": "Stanford;NYU;FAIR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "df1aca34a9",
        "title": "Fully Decentralized Joint Learning of Personalized Models and Collaboration Graphs",
        "site": "https://proceedings.mlr.press/v108/zantedeschi20a.html",
        "author": "Valentina Zantedeschi; Aur\u00e9lien Bellet; Marc Tommasi",
        "abstract": "We consider the fully decentralized machine learning scenario where many users with personal datasets collaborate to learn models through local peer-to-peer exchanges, without a central coordinator. We propose to train personalized models that leverage a collaboration graph describing the relationships between user personal tasks, which we learn jointly with the models. Our fully decentralized optimization procedure alternates between training nonlinear models given the graph in a greedy boosting manner, and updating the collaboration graph (with controlled sparsity) given the models. Throughout the process, users exchange messages only with a small number of peers (their direct neighbors when updating the models, and a few random users when updating the graph), ensuring that the procedure naturally scales with the number of users. Overall, our approach is communication-efficient and avoids exchanging personal data. We provide an extensive analysis of the convergence rate, memory and communication complexity of our approach, and demonstrate its benefits compared to competing techniques on synthetic and real datasets.",
        "bibtex": "@InProceedings{pmlr-v108-zantedeschi20a,\n  title = \t {Fully Decentralized Joint Learning of Personalized Models and Collaboration Graphs},\n  author =       {Zantedeschi, Valentina and Bellet, Aur\\'elien and Tommasi, Marc},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {864--874},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zantedeschi20a/zantedeschi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zantedeschi20a.html},\n  abstract = \t {We consider the fully decentralized machine learning scenario where many users with personal datasets collaborate to learn models through local peer-to-peer exchanges, without a central coordinator. We propose to train personalized models that leverage a collaboration graph describing the relationships between user personal tasks, which we learn jointly with the models. Our fully decentralized optimization procedure alternates between training nonlinear models given the graph in a greedy boosting manner, and updating the collaboration graph (with controlled sparsity) given the models. Throughout the process, users exchange messages only with a small number of peers (their direct neighbors when updating the models, and a few random users when updating the graph), ensuring that the procedure naturally scales with the number of users. Overall, our approach is communication-efficient and avoids exchanging personal data. We provide an extensive analysis of the convergence rate, memory and communication complexity of our approach, and demonstrate its benefits compared to competing techniques on synthetic and real datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zantedeschi20a/zantedeschi20a.pdf",
        "supp": "",
        "pdf_size": 546740,
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4273895155978485706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1f84c1da3b",
        "title": "Functional Gradient Boosting for Learning Residual-like Networks with Statistical Guarantees",
        "site": "https://proceedings.mlr.press/v108/nitanda20a.html",
        "author": "Atsushi Nitanda; Taiji Suzuki",
        "abstract": "Recently, several studies have proposed progressive or sequential layer-wise training methods based on the boosting theory for deep neural networks. However, most studies lack the global convergence guarantees or require weak learning conditions that can be verified a posteriori after running methods. Moreover, generalization bounds usually have a worse dependence on network depth. In this paper, to resolve these problems, we propose a new functional gradient boosting for learning deep residual-like networks in a layer-wise fashion with its statistical guarantees on multi-class classification tasks. In the proposed method, each residual block is recognized as a functional gradient (i.e., weak learner), and the functional gradient step is performed by stacking it on the network, resulting in a strong optimization ability. In the theoretical analysis, we show the global convergence of the method under a standard margin assumption on a data distribution instead of a weak learning condition, and we eliminate a worse dependence on the network depth in a generalization bound via a fine-grained convergence analysis. %, unlike existing studies. Moreover, we show that the existence of a learnable function with a large margin on a training dataset significantly improves a generalization bound. Finally, we experimentally demonstrate that our proposed method is certainly useful for learning deep residual networks.",
        "bibtex": "@InProceedings{pmlr-v108-nitanda20a,\n  title = \t {Functional Gradient Boosting for Learning Residual-like Networks with Statistical Guarantees},\n  author =       {Nitanda, Atsushi and Suzuki, Taiji},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2981--2991},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/nitanda20a/nitanda20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/nitanda20a.html},\n  abstract = \t {Recently, several studies have proposed progressive or sequential layer-wise training methods based on the boosting theory for deep neural networks. However, most studies lack the global convergence guarantees or require weak learning conditions that can be verified a posteriori after running methods. Moreover, generalization bounds usually have a worse dependence on network depth. In this paper, to resolve these problems, we propose a new functional gradient boosting for learning deep residual-like networks in a layer-wise fashion with its statistical guarantees on multi-class classification tasks. In the proposed method, each residual block is recognized as a functional gradient (i.e., weak learner), and the functional gradient step is performed by stacking it on the network, resulting in a strong optimization ability. In the theoretical analysis, we show the global convergence of the method under a standard margin assumption on a data distribution instead of a weak learning condition, and we eliminate a worse dependence on the network depth in a generalization bound via a fine-grained convergence analysis. %, unlike existing studies. Moreover, we show that the existence of a learnable function with a large margin on a training dataset significantly improves a generalization bound. Finally, we experimentally demonstrate that our proposed method is certainly useful for learning deep residual networks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/nitanda20a/nitanda20a.pdf",
        "supp": "",
        "pdf_size": 529733,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10082483648288360678&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo + Center for Advanced Intelligence Project, RIKEN + PRESTO, Japan Science and Technology Agency; Graduate School of Information Science and Technology, The University of Tokyo + Center for Advanced Intelligence Project, RIKEN",
        "aff_domain": "mist.i.u-tokyo.ac.jp;mist.i.u-tokyo.ac.jp",
        "email": "mist.i.u-tokyo.ac.jp;mist.i.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;0+1",
        "aff_unique_norm": "University of Tokyo;RIKEN;Japan Science and Technology Agency",
        "aff_unique_dep": "Graduate School of Information Science and Technology;Center for Advanced Intelligence Project;PRESTO",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp;https://www.jst.go.jp",
        "aff_unique_abbr": "UTokyo;RIKEN;JST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0+0+0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "89c0c07560",
        "title": "GAIT: A Geometric Approach to Information Theory",
        "site": "https://proceedings.mlr.press/v108/posada20a.html",
        "author": "Jose Gallego Posada; Ankit Vani; Max Schwarzer; Simon Lacoste-Julien",
        "abstract": "We advocate the use of a notion of entropy that reflects the relative abundances of the symbols in an alphabet, as well as the similarities between them. This concept was originally introduced in theoretical ecology to study the diversity of ecosystems. Based on this notion of entropy, we introduce geometry-aware counterparts for several concepts and theorems in information theory. Notably, our proposed divergence exhibits performance on par with state-of-the-art methods based on the Wasserstein distance, but enjoys a closed-form expression that can be computed efficiently. We demonstrate the versatility of our method via experiments on a broad range of domains: training generative models, computing image barycenters, approximating empirical measures and counting modes.",
        "bibtex": "@InProceedings{pmlr-v108-posada20a,\n  title = \t {GAIT: A Geometric Approach to Information Theory},\n  author =       {Posada, Jose Gallego and Vani, Ankit and Schwarzer, Max and Lacoste-Julien, Simon},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2601--2611},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/posada20a/posada20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/posada20a.html},\n  abstract = \t {We advocate the use of a notion of entropy that reflects the relative abundances of the symbols in an alphabet, as well as the similarities between them. This concept was originally introduced in theoretical ecology to study the diversity of ecosystems. Based on this notion of entropy, we introduce geometry-aware counterparts for several concepts and theorems in information theory. Notably, our proposed divergence exhibits performance on par with state-of-the-art methods based on the Wasserstein distance, but enjoys a closed-form expression that can be computed efficiently. We demonstrate the versatility of our method via experiments on a broad range of domains: training generative models, computing image barycenters, approximating empirical measures and counting modes.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/posada20a/posada20a.pdf",
        "supp": "",
        "pdf_size": 3566000,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18063634248154353886&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3677bd1d5f",
        "title": "GP-VAE: Deep Probabilistic Time Series Imputation",
        "site": "https://proceedings.mlr.press/v108/fortuin20a.html",
        "author": "Vincent Fortuin; Dmitry Baranchuk; Gunnar Raetsch; Stephan Mandt",
        "abstract": "Multivariate time series with missing values are common in areas such as healthcare and finance, and have grown in number and complexity over the years. This raises the question whether deep learning methodologies can outperform classical data imputation methods in this domain. However, naive applications of deep learning fall short in giving reliable confidence estimates and lack interpretability.We propose a new deep sequential latent variable model for dimensionality reduction and data imputation. Our modeling assumption is simple and interpretable: the high dimensional time series has a lower-dimensional representation which evolves smoothly in time according to a Gaussian process. The non-linear dimensionality reduction in the presence of missing data is achieved using a VAE approach with a novel structured variational approximation. We demonstrate that our approach outperforms both classical and recent deep learning-based data imputation methods on high dimensional data from the domains of computer vision and healthcare.",
        "bibtex": "@InProceedings{pmlr-v108-fortuin20a,\n  title = \t {GP-VAE: Deep Probabilistic Time Series Imputation},\n  author =       {Fortuin, Vincent and Baranchuk, Dmitry and Raetsch, Gunnar and Mandt, Stephan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1651--1661},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fortuin20a/fortuin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fortuin20a.html},\n  abstract = \t {Multivariate time series with missing values are common in areas such as healthcare and finance, and have grown in number and complexity over the years. This raises the question whether deep learning methodologies can outperform classical data imputation methods in this domain. However, naive applications of deep learning fall short in giving reliable confidence estimates and lack interpretability.We propose a new deep sequential latent variable model for dimensionality reduction and data imputation. Our modeling assumption is simple and interpretable: the high dimensional time series has a lower-dimensional representation which evolves smoothly in time according to a Gaussian process. The non-linear dimensionality reduction in the presence of missing data is achieved using a VAE approach with a novel structured variational approximation. We demonstrate that our approach outperforms both classical and recent deep learning-based data imputation methods on high dimensional data from the domains of computer vision and healthcare.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fortuin20a/fortuin20a.pdf",
        "supp": "",
        "pdf_size": 3237163,
        "gs_citation": 359,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10396485072460929956&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "ETH Z\u00fcrich, Switzerland; Yandex, Russia + ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; UC Irvine, USA",
        "aff_domain": "inf.ethz.ch; ; ; ",
        "email": "inf.ethz.ch; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;2",
        "aff_unique_norm": "ETH Zurich;Yandex;University of California, Irvine",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ethz.ch;https://yandex.com;https://www.uci.edu",
        "aff_unique_abbr": "ETHZ;Yandex;UCI",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Irvine",
        "aff_country_unique_index": "0;1+0;0;2",
        "aff_country_unique": "Switzerland;Russian Federation;United States"
    },
    {
        "id": "b6bfc0383e",
        "title": "Gain with no Pain: Efficiency of Kernel-PCA by Nystr\u00f6m Sampling",
        "site": "https://proceedings.mlr.press/v108/sterge20a.html",
        "author": "Nicholas Sterge; Bharath Sriperumbudur; Lorenzo Rosasco; Alessandro Rudi",
        "abstract": "In this paper, we analyze a Nystr\u00f6m based approach to efficient large scale kernel principal component analysis  (PCA). The latter is a natural nonlinear extension of classical PCA based on considering a nonlinear feature map or the  corresponding kernel. Like other kernel approaches, kernel PCA enjoys good mathematical and statistical properties but, numerically, it scales poorly with the sample size. Our analysis shows that Nystr\u00f6m sampling greatly improves computational efficiency without incurring any loss of statistical accuracy. While similar effects have been observed in supervised learning, this is the first such result for PCA. Our theoretical findings are based on a combination of analytic and concentration of measure techniques. Our study is more broadly motivated by the question of understanding the  interplay  between statistical and computational requirements for learning.",
        "bibtex": "@InProceedings{pmlr-v108-sterge20a,\n  title = \t {Gain with no Pain: Efficiency of Kernel-PCA by Nystr\u00f6m Sampling},\n  author =       {Sterge, Nicholas and Sriperumbudur, Bharath and Rosasco, Lorenzo and Rudi, Alessandro},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3642--3652},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sterge20a/sterge20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sterge20a.html},\n  abstract = \t { In this paper, we analyze a Nystr\u00f6m based approach to efficient large scale kernel principal component analysis  (PCA). The latter is a natural nonlinear extension of classical PCA based on considering a nonlinear feature map or the  corresponding kernel. Like other kernel approaches, kernel PCA enjoys good mathematical and statistical properties but, numerically, it scales poorly with the sample size. Our analysis shows that Nystr\u00f6m sampling greatly improves computational efficiency without incurring any loss of statistical accuracy. While similar effects have been observed in supervised learning, this is the first such result for PCA. Our theoretical findings are based on a combination of analytic and concentration of measure techniques. Our study is more broadly motivated by the question of understanding the  interplay  between statistical and computational requirements for learning.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sterge20a/sterge20a.pdf",
        "supp": "",
        "pdf_size": 340058,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1866599211018962164&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "008e70d8a3",
        "title": "Gaussian Sketching yields a J-L Lemma in RKHS",
        "site": "https://proceedings.mlr.press/v108/kpotufe20a.html",
        "author": "Samory Kpotufe; Bharath Sriperumbudur",
        "abstract": "The main contribution of the paper is to show that Gaussian sketching of a kernel-Gram matrix $\\bm K$ yields an operator whose counterpart in an RKHS $\\cal H$, is a \\emph{random projection} operator\u2014in the spirit of Johnson-Lindenstrauss (J-L) lemma. To be precise, given a random matrix $Z$ with i.i.d. Gaussian entries, we show that a sketch $Z\\bm{K}$ corresponds to a particular random operator in (infinite-dimensional) Hilbert space $\\cal H$ that maps functions $f \\in \\cal H$ to a low-dimensional space $\\bb R^d$, while preserving a weighted RKHS inner-product of the form $\u27e8f, g \\rangle_{\\Sigma} \\doteq \u27e8f, \\Sigma^3 g \\rangle_{\\cal H}$, where $\\Sigma$ is the \\emph{covariance} operator induced by the data distribution. In particular, under similar assumptions as in kernel PCA (KPCA), or kernel $k$-means (K-$k$-means), well-separated subsets of feature-space $\\{K(\\cdot, x): x \\in \\cal X\\}$ remain well-separated after such operation, which suggests similar benefits as in KPCA and/or K-$k$-means, albeit at the much cheaper cost of a random projection. In particular, our convergence rates suggest that, given a large dataset $\\{X_i\\}_{i=1}^N$ of size $N$, we can build the Gram matrix $\\bm K$ on a much smaller subsample of size $n\\ll N$, so that the sketch $Z\\bm K$ is very cheap to obtain and subsequently apply as a projection operator on the original data $\\{X_i\\}_{i=1}^N$.  We verify these insights empirically on synthetic data, and on real-world clustering applications.",
        "bibtex": "@InProceedings{pmlr-v108-kpotufe20a,\n  title = \t {Gaussian Sketching yields a J-L Lemma in RKHS},\n  author =       {Kpotufe, Samory and Sriperumbudur, Bharath},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3928--3937},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kpotufe20a/kpotufe20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kpotufe20a.html},\n  abstract = \t {The main contribution of the paper is to show that Gaussian sketching of a kernel-Gram matrix $\\bm K$ yields an operator whose counterpart in an RKHS $\\cal H$, is a \\emph{random projection} operator\u2014in the spirit of Johnson-Lindenstrauss (J-L) lemma. To be precise, given a random matrix $Z$ with i.i.d. Gaussian entries, we show that a sketch $Z\\bm{K}$ corresponds to a particular random operator in (infinite-dimensional) Hilbert space $\\cal H$ that maps functions $f \\in \\cal H$ to a low-dimensional space $\\bb R^d$, while preserving a weighted RKHS inner-product of the form $\u27e8f, g \\rangle_{\\Sigma} \\doteq \u27e8f, \\Sigma^3 g \\rangle_{\\cal H}$, where $\\Sigma$ is the \\emph{covariance} operator induced by the data distribution. In particular, under similar assumptions as in kernel PCA (KPCA), or kernel $k$-means (K-$k$-means), well-separated subsets of feature-space $\\{K(\\cdot, x): x \\in \\cal X\\}$ remain well-separated after such operation, which suggests similar benefits as in KPCA and/or K-$k$-means, albeit at the much cheaper cost of a random projection. In particular, our convergence rates suggest that, given a large dataset $\\{X_i\\}_{i=1}^N$ of size $N$, we can build the Gram matrix $\\bm K$ on a much smaller subsample of size $n\\ll N$, so that the sketch $Z\\bm K$ is very cheap to obtain and subsequently apply as a projection operator on the original data $\\{X_i\\}_{i=1}^N$.  We verify these insights empirically on synthetic data, and on real-world clustering applications.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kpotufe20a/kpotufe20a.pdf",
        "supp": "",
        "pdf_size": 1132321,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3683466344990620982&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Statistics, Columbia University; Statistics, Pennsylvania State University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Columbia University;Pennsylvania State University",
        "aff_unique_dep": "Department of Statistics;Department of Statistics",
        "aff_unique_url": "https://www.columbia.edu;https://www.psu.edu",
        "aff_unique_abbr": "Columbia;PSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fe15a42a79",
        "title": "Gaussian-Smoothed Optimal Transport: Metric Structure and Statistical Efficiency",
        "site": "https://proceedings.mlr.press/v108/goldfeld20a.html",
        "author": "Ziv Goldfeld; Kristjan Greenewald",
        "abstract": "Optimal transport (OT), and in particular the Wasserstein distance, has seen a surge of interest and applications in machine learning. However, empirical approximation under Wasserstein distances suffers from a severe curse of dimensionality, rendering them impractical in high dimensions. As a result, entropically regularized OT has become a popular workaround. However, while it enjoys fast algorithms and better statistical properties, it looses the metric structure that Wasserstein distances enjoy. This work proposes a novel Gaussian-smoothed OT (GOT) framework, that achieves the best of both worlds: preserving the 1-Wasserstein metric structure while alleviating the empirical approximation curse of dimensionality. Furthermore, as the Gaussian-smoothing parameter shrinks to zero, GOT $\\Gamma$-converges towards classic OT (with convergence of optimizers), thus serving as a natural extension. An empirical study that validates the theoretical results is provided, promoting Gaussian-smoothed OT as a powerful alternative to entropic OT.",
        "bibtex": "@InProceedings{pmlr-v108-goldfeld20a,\n  title = \t {Gaussian-Smoothed Optimal Transport: Metric Structure and Statistical Efficiency},\n  author =       {Goldfeld, Ziv and Greenewald, Kristjan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3327--3337},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/goldfeld20a/goldfeld20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/goldfeld20a.html},\n  abstract = \t {Optimal transport (OT), and in particular the Wasserstein distance, has seen a surge of interest and applications in machine learning. However, empirical approximation under Wasserstein distances suffers from a severe curse of dimensionality, rendering them impractical in high dimensions. As a result, entropically regularized OT has become a popular workaround. However, while it enjoys fast algorithms and better statistical properties, it looses the metric structure that Wasserstein distances enjoy. This work proposes a novel Gaussian-smoothed OT (GOT) framework, that achieves the best of both worlds: preserving the 1-Wasserstein metric structure while alleviating the empirical approximation curse of dimensionality. Furthermore, as the Gaussian-smoothing parameter shrinks to zero, GOT $\\Gamma$-converges towards classic OT (with convergence of optimizers), thus serving as a natural extension. An empirical study that validates the theoretical results is provided, promoting Gaussian-smoothed OT as a powerful alternative to entropic OT.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/goldfeld20a/goldfeld20a.pdf",
        "supp": "",
        "pdf_size": 789473,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9812394844584435373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Cornell University; MIT-IBM Watson AI Lab",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Cornell University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";IBM Watson AI Lab",
        "aff_unique_url": "https://www.cornell.edu;https://www.mitibmwatsonailab.org",
        "aff_unique_abbr": "Cornell;MIT-IBM AI Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "dc248731ec",
        "title": "Gaussianization Flows",
        "site": "https://proceedings.mlr.press/v108/meng20b.html",
        "author": "Chenlin Meng; Yang Song; Jiaming Song; Stefano Ermon",
        "abstract": "Iterative Gaussianization is a fixed-point iteration procedure that allows one to transform a continuous distribution to Gaussian distribution. Based on iterative Gaussianization, we propose a new type of normalizing flow models that grants both efficient computation of likelihoods and efficient inversion for sample generation. We demonstrate that this new family of flow models, named as Gaussianization flows, are universal approximators for continuous probability distributions under some regularity conditions. This guaranteed expressivity, enabling them to capture multimodal target distributions better without compromising the efficiency in sample generation. Experimentally, we show that Gaussianization flows achieve better or comparable performance on several tabular datasets, compared to other efficiently invertible flow models such as Real NVP, Glow and FFJORD. In particular, Gaussianization flows are easier to initialize, demonstrate better robustness with respect to different transformations of the training data, and generalize better on small training sets.",
        "bibtex": "@InProceedings{pmlr-v108-meng20b,\n  title = \t {Gaussianization Flows},\n  author =       {Meng, Chenlin and Song, Yang and Song, Jiaming and Ermon, Stefano},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4336--4345},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/meng20b/meng20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/meng20b.html},\n  abstract = \t {Iterative Gaussianization is a fixed-point iteration procedure that allows one to transform a continuous distribution to Gaussian distribution. Based on iterative Gaussianization, we propose a new type of normalizing flow models that grants both efficient computation of likelihoods and efficient inversion for sample generation. We demonstrate that this new family of flow models, named as Gaussianization flows, are universal approximators for continuous probability distributions under some regularity conditions. This guaranteed expressivity, enabling them to capture multimodal target distributions better without compromising the efficiency in sample generation. Experimentally, we show that Gaussianization flows achieve better or comparable performance on several tabular datasets, compared to other efficiently invertible flow models such as Real NVP, Glow and FFJORD. In particular, Gaussianization flows are easier to initialize, demonstrate better robustness with respect to different transformations of the training data, and generalize better on small training sets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/meng20b/meng20b.pdf",
        "supp": "",
        "pdf_size": 3895343,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11183139355547952695&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1156cee001",
        "title": "General Identification of Dynamic Treatment Regimes Under Interference",
        "site": "https://proceedings.mlr.press/v108/sherman20a.html",
        "author": "Eli Sherman; David Arbour; Ilya Shpitser",
        "abstract": "In many applied fields, researchers are ofteninterested in tailoring treatments to unit-levelcharacteristics in order to optimize an outcomeof interest. Methods for identifying andestimating treatment policies are the subjectof the dynamic treatment regime literature. Separately, in many settings the assumptionthat data are independent and identically distributeddoes not hold due to inter-subjectdependence. The phenomenon where a subject\u2019s outcome is dependent on his neighbor\u2019s exposure is known as interference. These areasintersect in myriad real-world settings. Inthis paper we consider the problem of identifyingoptimal treatment policies in the presenceof interference. Using a general representationof interference, via Lauritzen-Wermuth-Freydenburg chain graphs (Lauritzen andRichardson, 2002), we formalize a variety ofpolicy interventions under interference andextend existing identification theory (Tian,2008; Sherman and Shpitser, 2018). Finally, we illustrate the efficacy of policy maximization under interference in a simulation study.",
        "bibtex": "@InProceedings{pmlr-v108-sherman20a,\n  title = \t {General Identification of Dynamic Treatment Regimes Under Interference},\n  author =       {Sherman, Eli and Arbour, David and Shpitser, Ilya},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3917--3927},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sherman20a/sherman20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sherman20a.html},\n  abstract = \t {In many applied fields, researchers are ofteninterested in tailoring treatments to unit-levelcharacteristics in order to optimize an outcomeof interest. Methods for identifying andestimating treatment policies are the subjectof the dynamic treatment regime literature. Separately, in many settings the assumptionthat data are independent and identically distributeddoes not hold due to inter-subjectdependence. The phenomenon where a subject\u2019s outcome is dependent on his neighbor\u2019s exposure is known as interference. These areasintersect in myriad real-world settings. Inthis paper we consider the problem of identifyingoptimal treatment policies in the presenceof interference. Using a general representationof interference, via Lauritzen-Wermuth-Freydenburg chain graphs (Lauritzen andRichardson, 2002), we formalize a variety ofpolicy interventions under interference andextend existing identification theory (Tian,2008; Sherman and Shpitser, 2018). Finally, we illustrate the efficacy of policy maximization under interference in a simulation study.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sherman20a/sherman20a.pdf",
        "supp": "",
        "pdf_size": 493312,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2463075950172902942&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Johns Hopkins University; Adobe Inc.; Johns Hopkins University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Johns Hopkins University;Adobe",
        "aff_unique_dep": ";Adobe Inc.",
        "aff_unique_url": "https://www.jhu.edu;https://www.adobe.com",
        "aff_unique_abbr": "JHU;Adobe",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "36b702302b",
        "title": "Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks",
        "site": "https://proceedings.mlr.press/v108/li20j.html",
        "author": "Mingchen Li; Mahdi Soltanolkotabi; Samet Oymak",
        "abstract": "Modern neural networks are typically trained in an over-parameterized regime where the parameters of the model far exceed the size of the training data. Such neural networks in principle have the capacity to (over)fit any set of labels including significantly corrupted ones. Despite this (over)fitting capacity in this paper we demonstrate that such overparameterized networks have an intriguing robustness capability: they are surprisingly robust to label noise when first order methods with early stopping is used to train them. This paper also takes a step towards demystifying this phenomena. Under a rich dataset model, we show that gradient descent is provably robust to noise/corruption on a constant fraction of the labels. In particular, we prove that: (i) In the first few iterations where the updates are still in the vicinity of the initialization gradient descent only fits to the correct labels essentially ignoring the noisy labels. (ii) To start to overfit to the noisy labels network must stray rather far from the initialization which can only occur after many more iterations. Together, these results show that gradient descent with early stopping is provably robust to label noise and shed light on the empirical robustness of deep networks as well as commonly adopted heuristics to prevent overfitting.",
        "bibtex": "@InProceedings{pmlr-v108-li20j,\n  title = \t {Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks},\n  author =       {Li, Mingchen and Soltanolkotabi, Mahdi and Oymak, Samet},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4313--4324},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20j/li20j.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20j.html},\n  abstract = \t {Modern neural networks are typically trained in an over-parameterized regime where the parameters of the model far exceed the size of the training data. Such neural networks in principle have the capacity to (over)fit any set of labels including significantly corrupted ones. Despite this (over)fitting capacity in this paper we demonstrate that such overparameterized networks have an intriguing robustness capability: they are surprisingly robust to label noise when first order methods with early stopping is used to train them. This paper also takes a step towards demystifying this phenomena. Under a rich dataset model, we show that gradient descent is provably robust to noise/corruption on a constant fraction of the labels. In particular, we prove that: (i) In the first few iterations where the updates are still in the vicinity of the initialization gradient descent only fits to the correct labels essentially ignoring the noisy labels. (ii) To start to overfit to the noisy labels network must stray rather far from the initialization which can only occur after many more iterations. Together, these results show that gradient descent with early stopping is provably robust to label noise and shed light on the empirical robustness of deep networks as well as commonly adopted heuristics to prevent overfitting.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20j/li20j.pdf",
        "supp": "",
        "pdf_size": 1562748,
        "gs_citation": 453,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17442044895096571308&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c15a0eff93",
        "title": "Graph Coarsening with Preserved Spectral Properties",
        "site": "https://proceedings.mlr.press/v108/jin20a.html",
        "author": "Yu Jin; Andreas Loukas; Joseph JaJa",
        "abstract": "In graph coarsening, one aims to produce a coarse graph of reduced size while preserving important graph properties. However, as there is no consensus on which specific graph properties should be preserved by coarse graphs, measuring the differences between original and coarse graphs remains a key challenge. This work relies on spectral graph theory to justify a distance function constructed to measure the similarity between original and coarse graphs. We show that the proposed spectral distance captures the structural differences in the graph coarsening process. We also propose graph coarsening algorithms that aim to minimize the spectral distance. Experiments show that the proposed algorithms can outperform previous graph coarsening methods in graph classification and stochastic block recovery tasks.",
        "bibtex": "@InProceedings{pmlr-v108-jin20a,\n  title = \t {Graph Coarsening with Preserved Spectral Properties},\n  author =       {Jin, Yu and Loukas, Andreas and JaJa, Joseph},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4452--4462},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/jin20a/jin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/jin20a.html},\n  abstract = \t {In graph coarsening, one aims to produce a coarse graph of reduced size while preserving important graph properties. However, as there is no consensus on which specific graph properties should be preserved by coarse graphs, measuring the differences between original and coarse graphs remains a key challenge. This work relies on spectral graph theory to justify a distance function constructed to measure the similarity between original and coarse graphs. We show that the proposed spectral distance captures the structural differences in the graph coarsening process. We also propose graph coarsening algorithms that aim to minimize the spectral distance. Experiments show that the proposed algorithms can outperform previous graph coarsening methods in graph classification and stochastic block recovery tasks. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/jin20a/jin20a.pdf",
        "supp": "",
        "pdf_size": 635543,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11227024497539801143&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Maryland; EPFL; University of Maryland",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Maryland;EPFL",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www/umd.edu;https://www.epfl.ch",
        "aff_unique_abbr": "UMD;EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "0f2e3e965c",
        "title": "Graph DNA: Deep Neighborhood Aware Graph Encoding for Collaborative Filtering",
        "site": "https://proceedings.mlr.press/v108/wu20a.html",
        "author": "Liwei Wu; Hsiang-Fu Yu; Nikhil Rao; James Sharpnack; Cho-Jui Hsieh",
        "abstract": "In this paper, we consider recommender systems with side information in the form of graphs. Existing collaborative filtering algorithms mainly utilize only immediate neighborhood information and do not efficiently take advantage of deeper neighborhoods beyond 1-2 hops. The main issue with exploiting deeper graph information is the rapidly growing time and space complexity when incorporating information from these neighborhoods. In this paper, we propose using Graph DNA, a novel Deep Neighborhood Aware graph encoding algorithm, for exploiting multi-hop neighborhood information. DNA encoding computes approximate deep neighborhood information in linear time using Bloom filters, and results in a per-node encoding whose dimension is logarithmic in the number of nodes in the graph. It can be used in conjunction with both feature-based and graph-regularization-based collaborative filtering algorithms.  Graph DNA has the advantages of being memory and time efficient and providing additional regularization when compared to directly using higher order graph information. We provide theoretical performance bounds for graph DNA encoding, and experimentally show that graph DNA can be used with 4 popular collaborative filtering algorithms to consistently boost their performances with little computational and memory overhead.",
        "bibtex": "@InProceedings{pmlr-v108-wu20a,\n  title = \t {Graph DNA: Deep Neighborhood Aware Graph Encoding for Collaborative Filtering},\n  author =       {Wu, Liwei and Yu, Hsiang-Fu and Rao, Nikhil and Sharpnack, James and Hsieh, Cho-Jui},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {776--787},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wu20a/wu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wu20a.html},\n  abstract = \t {In this paper, we consider recommender systems with side information in the form of graphs. Existing collaborative filtering algorithms mainly utilize only immediate neighborhood information and do not efficiently take advantage of deeper neighborhoods beyond 1-2 hops. The main issue with exploiting deeper graph information is the rapidly growing time and space complexity when incorporating information from these neighborhoods. In this paper, we propose using Graph DNA, a novel Deep Neighborhood Aware graph encoding algorithm, for exploiting multi-hop neighborhood information. DNA encoding computes approximate deep neighborhood information in linear time using Bloom filters, and results in a per-node encoding whose dimension is logarithmic in the number of nodes in the graph. It can be used in conjunction with both feature-based and graph-regularization-based collaborative filtering algorithms.  Graph DNA has the advantages of being memory and time efficient and providing additional regularization when compared to directly using higher order graph information. We provide theoretical performance bounds for graph DNA encoding, and experimentally show that graph DNA can be used with 4 popular collaborative filtering algorithms to consistently boost their performances with little computational and memory overhead.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wu20a/wu20a.pdf",
        "supp": "",
        "pdf_size": 909402,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13112425939427567012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of California, Davis; Amazon; Amazon; University of California, Davis; University of California, Los Angeles",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "University of California, Davis;Amazon;University of California, Los Angeles",
        "aff_unique_dep": ";Amazon.com, Inc.;",
        "aff_unique_url": "https://www.ucdavis.edu;https://www.amazon.com;https://www.ucla.edu",
        "aff_unique_abbr": "UC Davis;Amazon;UCLA",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Davis;;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c2dc0761c4",
        "title": "Greed Meets Sparsity: Understanding and Improving Greedy Coordinate Descent for Sparse Optimization",
        "site": "https://proceedings.mlr.press/v108/fang20a.html",
        "author": "Huang Fang; Zhenan Fan; Yifan Sun; Michael Friedlander",
        "abstract": "We consider greedy coordinate descent (GCD) for composite problems with sparsity inducing regularizers, including 1-norm regularization and non-negative constraints. Empirical evidence strongly suggests that GCD, when initialized with the zero vector, has an implicit screening ability that usually selects at each iteration coordinates that at are nonzero at the solution. Thus, for problems with sparse solutions, GCD can converge significantly faster than randomized coordinate descent. We present an improved convergence analysis of GCD for sparse optimization, and a formal analysis of its screening properties. We also propose and analyze an improved selection rule with stronger ability to produce sparse iterates. Numerical experiments on both synthetic and real-world data support our analysis and the effectiveness of the proposed selection rule.",
        "bibtex": "@InProceedings{pmlr-v108-fang20a,\n  title = \t {Greed Meets Sparsity: Understanding and Improving Greedy Coordinate Descent for Sparse Optimization},\n  author =       {Fang, Huang and Fan, Zhenan and Sun, Yifan and Friedlander, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {434--444},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fang20a/fang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fang20a.html},\n  abstract = \t {We consider greedy coordinate descent (GCD) for composite problems with sparsity inducing regularizers, including 1-norm regularization and non-negative constraints. Empirical evidence strongly suggests that GCD, when initialized with the zero vector, has an implicit screening ability that usually selects at each iteration coordinates that at are nonzero at the solution. Thus, for problems with sparse solutions, GCD can converge significantly faster than randomized coordinate descent. We present an improved convergence analysis of GCD for sparse optimization, and a formal analysis of its screening properties. We also propose and analyze an improved selection rule with stronger ability to produce sparse iterates. Numerical experiments on both synthetic and real-world data support our analysis and the effectiveness of the proposed selection rule.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fang20a/fang20a.pdf",
        "supp": "",
        "pdf_size": 1152078,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4028450139193975712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7343e452c5",
        "title": "Guaranteed Validity for Empirical Approaches to Adaptive Data Analysis",
        "site": "https://proceedings.mlr.press/v108/rogers20a.html",
        "author": "Ryan Rogers; Aaron Roth; Adam Smith; Nathan Srebro; Om Thakkar; Blake Woodworth",
        "abstract": "We design a general framework for answering adaptive statistical queries that focuses on providing explicit confidence intervals along with point estimates. Prior work in this area has either focused on providing tight confidence intervals for specific analyses, or providing general worst-case bounds for point estimates. Unfortunately, as we observe, these worst-case bounds are loose in many settings \u2014 often not even beating simple baselines like sample splitting. Our main contribution is to design a framework for providing valid, instance-specific confidence intervals for point estimates that can be generated by heuristics. When paired with good heuristics, this method gives guarantees that are orders of magnitude better than the best worst-case bounds. We provide a Python library implementing our method.",
        "bibtex": "@InProceedings{pmlr-v108-rogers20a,\n  title = \t {Guaranteed Validity for Empirical Approaches to Adaptive Data Analysis},\n  author =       {Rogers, Ryan and Roth, Aaron and Smith, Adam and Srebro, Nathan and Thakkar, Om and Woodworth, Blake},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2830--2840},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rogers20a/rogers20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rogers20a.html},\n  abstract = \t {We design a general framework for answering adaptive statistical queries that focuses on providing explicit confidence intervals along with point estimates. Prior work in this area has either focused on providing tight confidence intervals for specific analyses, or providing general worst-case bounds for point estimates. Unfortunately, as we observe, these worst-case bounds are loose in many settings \u2014 often not even beating simple baselines like sample splitting. Our main contribution is to design a framework for providing valid, instance-specific confidence intervals for point estimates that can be generated by heuristics. When paired with good heuristics, this method gives guarantees that are orders of magnitude better than the best worst-case bounds. We provide a Python library implementing our method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rogers20a/rogers20a.pdf",
        "supp": "",
        "pdf_size": 650300,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=908838307207852743&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d5916172a3",
        "title": "Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with Cardinality Constraint",
        "site": "https://proceedings.mlr.press/v108/sakaue20a.html",
        "author": "Shinsaku Sakaue",
        "abstract": "Submodular maximization with a cardinality constraint can model various problems, and those problems are often very large in practice. For the case where objective functions are monotone, many fast approximation algorithms have been developed. The stochastic greedy algorithm (SG) is one such algorithm, which is widely used thanks to its simplicity, efficiency, and high empirical performance. However, its approximation guarantee has been proved only for monotone objective functions. When it comes to non-monotone objective functions, existing approximation algorithms are inefficient relative to the fast algorithms developed for the case of monotone objectives. In this paper, we prove that SG (with slight modification) can achieve almost $1/4$-approximation guarantees in expectation in linear time even if objective functions are non-monotone. Our result provides a constant-factor approximation algorithm with the fewest oracle queries for non-monotone submodular maximization with a cardinality constraint. Experiments validate the performance of (modified) SG.",
        "bibtex": "@InProceedings{pmlr-v108-sakaue20a,\n  title = \t {Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with Cardinality Constraints},\n  author =       {Sakaue, Shinsaku},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {11--21},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sakaue20a/sakaue20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sakaue20a.html},\n  abstract = \t {Submodular maximization with a cardinality constraint can model various problems, and those problems are often very large in practice. For the case where objective functions are monotone, many fast approximation algorithms have been developed. The stochastic greedy algorithm (SG) is one such algorithm, which is widely used thanks to its simplicity, efficiency, and high empirical performance. However, its approximation guarantee has been proved only for monotone objective functions. When it comes to non-monotone objective functions, existing approximation algorithms are inefficient relative to the fast algorithms developed for the case of monotone objectives. In this paper, we prove that SG (with slight modification) can achieve almost $1/4$-approximation guarantees in expectation in linear time even if objective functions are non-monotone. Our result provides a constant-factor approximation algorithm with the fewest oracle queries for non-monotone submodular maximization with a cardinality constraint. Experiments validate the performance of (modified) SG.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sakaue20a/sakaue20a.pdf",
        "supp": "",
        "pdf_size": 557022,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15585441723075402751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "NTT Communication Science Laboratories",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "NTT Communication Science Laboratories",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ntt-csl.com",
        "aff_unique_abbr": "NTT CSL",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "b1ecb9c856",
        "title": "Hamiltonian Monte Carlo Swindles",
        "site": "https://proceedings.mlr.press/v108/piponi20a.html",
        "author": "Dan Piponi; Matthew Hoffman; Pavel Sountsov",
        "abstract": "Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC) algorithm for estimating expectations with respect to continuous un-normalized probability distributions. MCMC estimators typically have higher variance than classical Monte Carlo with i.i.d. samples due to autocorrelations; most MCMC research tries to reduce these autocorrelations. In this work, we explore a complementary approach to variance reduction based on two classical Monte Carlo \u2019swindles\u2019: first, running an auxiliary coupled chain targeting a tractable approximation to the target distribution, and using the auxiliary samples as control variates; and second, generating anti-correlated (\"antithetic\") samples by running two chains with flipped randomness. Both ideas have been explored previously in the context of Gibbs samplers and random-walk Metropolis algorithms, but we argue that they are ripe for adaptation to HMC in light of recent coupling results from the HMC theory literature. For many posterior distributions, we find that these swindles generate effective sample sizes orders of magnitude larger than plain HMC, as well as being more efficient than analogous swindles for Metropolis-adjusted Langevin algorithm and random-walk Metropolis.",
        "bibtex": "@InProceedings{pmlr-v108-piponi20a,\n  title = \t {Hamiltonian Monte Carlo Swindles},\n  author =       {Piponi, Dan and Hoffman, Matthew and Sountsov, Pavel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3774--3783},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/piponi20a/piponi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/piponi20a.html},\n  abstract = \t {Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC) algorithm for estimating expectations with respect to continuous un-normalized probability distributions. MCMC estimators typically have higher variance than classical Monte Carlo with i.i.d. samples due to autocorrelations; most MCMC research tries to reduce these autocorrelations. In this work, we explore a complementary approach to variance reduction based on two classical Monte Carlo \u2019swindles\u2019: first, running an auxiliary coupled chain targeting a tractable approximation to the target distribution, and using the auxiliary samples as control variates; and second, generating anti-correlated (\"antithetic\") samples by running two chains with flipped randomness. Both ideas have been explored previously in the context of Gibbs samplers and random-walk Metropolis algorithms, but we argue that they are ripe for adaptation to HMC in light of recent coupling results from the HMC theory literature. For many posterior distributions, we find that these swindles generate effective sample sizes orders of magnitude larger than plain HMC, as well as being more efficient than analogous swindles for Metropolis-adjusted Langevin algorithm and random-walk Metropolis. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/piponi20a/piponi20a.pdf",
        "supp": "",
        "pdf_size": 1068773,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2584579556878334837&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f90a029e94",
        "title": "Hermitian matrices for clustering directed graphs: insights and applications",
        "site": "https://proceedings.mlr.press/v108/cucuringu20a.html",
        "author": "Mihai Cucuringu; Huan Li; He Sun; Luca Zanetti",
        "abstract": "Graph clustering is a basic technique in machine learning, and has widespread applications in different domains. While spectral techniques have been successfully applied for clustering undirected graphs, the performance of spectral clustering algorithms for directed graphs (digraphs) is not in general satisfactory: these algorithms usually require  symmetrising the matrix representing a digraph, and typical objective functions for undirected graph clustering   do not capture  cluster-structures in which the information given by the direction of the edges is crucial. To overcome these downsides,  we propose  a spectral clustering algorithm based on a complex-valued matrix representation of digraphs. We analyse its theoretical performance on a Stochastic Block Model for digraphs in which the cluster-structure is given not only by variations in edge densities, but also by the direction of the edges. The significance of our work is   highlighted  on a data set pertaining to internal migration in the United States: while previous spectral clustering algorithms for digraphs can only reveal that people are more likely to move between counties that are geographically close, our approach is able to cluster together counties with  a similar socio-economical profile even when they are geographically distant, and illustrates how people tend to move from rural to more urbanised areas.",
        "bibtex": "@InProceedings{pmlr-v108-cucuringu20a,\n  title = \t {Hermitian matrices for clustering directed graphs: insights and applications},\n  author =       {Cucuringu, Mihai and Li, Huan and Sun, He and Zanetti, Luca},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {983--992},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cucuringu20a/cucuringu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cucuringu20a.html},\n  abstract = \t {Graph clustering is a basic technique in machine learning, and has widespread applications in different domains. While spectral techniques have been successfully applied for clustering undirected graphs, the performance of spectral clustering algorithms for directed graphs (digraphs) is not in general satisfactory: these algorithms usually require  symmetrising the matrix representing a digraph, and typical objective functions for undirected graph clustering   do not capture  cluster-structures in which the information given by the direction of the edges is crucial. To overcome these downsides,  we propose  a spectral clustering algorithm based on a complex-valued matrix representation of digraphs. We analyse its theoretical performance on a Stochastic Block Model for digraphs in which the cluster-structure is given not only by variations in edge densities, but also by the direction of the edges. The significance of our work is   highlighted  on a data set pertaining to internal migration in the United States: while previous spectral clustering algorithms for digraphs can only reveal that people are more likely to move between counties that are geographically close, our approach is able to cluster together counties with  a similar socio-economical profile even when they are geographically distant, and illustrates how people tend to move from rural to more urbanised areas.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cucuringu20a/cucuringu20a.pdf",
        "supp": "",
        "pdf_size": 4584717,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18192949375367969717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1230513926",
        "title": "High Dimensional Robust Sparse Regression",
        "site": "https://proceedings.mlr.press/v108/liu20b.html",
        "author": "Liu Liu; Yanyao Shen; Tianyang Li; Constantine Caramanis",
        "abstract": "We provide a novel \u2013 and to the best of our knowledge, the first \u2013 algorithm for high dimensional sparse regression with constant fraction of corruptions in explanatory and/or response variables. Our algorithm recovers the true sparse parameters with sub-linear sample complexity,in the presence of a constant fraction of arbitrary corruptions. Our main contribution is a robust variant of Iterative Hard Thresholding. Using this, we provide accurate estimators:when the covariance matrix in sparse regression is identity,  our error guarantee is near information-theoretically optimal. We then deal with robust sparse regression with unknown structured covariance matrix. We propose a filtering algorithm whichconsists of a novel randomized outlier removal technique for robust sparse mean estimation that may be of interest in its own right: the filtering algorithm is flexible enough to deal with unknown covariance.Also, it is orderwise more efficient computationally than the ellipsoid algorithm.Using sub-linear sample complexity, our algorithm achieves the best known (and first) error guarantee. We demonstrate the effectiveness on large-scale sparse regression problems with arbitrary corruptions.",
        "bibtex": "@InProceedings{pmlr-v108-liu20b,\n  title = \t {High Dimensional Robust Sparse Regression},\n  author =       {Liu, Liu and Shen, Yanyao and Li, Tianyang and Caramanis, Constantine},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {411--421},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/liu20b/liu20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/liu20b.html},\n  abstract = \t {We provide a novel \u2013 and to the best of our knowledge, the first \u2013 algorithm for high dimensional sparse regression with constant fraction of corruptions in explanatory and/or response variables. Our algorithm recovers the true sparse parameters with sub-linear sample complexity,in the presence of a constant fraction of arbitrary corruptions. Our main contribution is a robust variant of Iterative Hard Thresholding. Using this, we provide accurate estimators:when the covariance matrix in sparse regression is identity,  our error guarantee is near information-theoretically optimal. We then deal with robust sparse regression with unknown structured covariance matrix. We propose a filtering algorithm whichconsists of a novel randomized outlier removal technique for robust sparse mean estimation that may be of interest in its own right: the filtering algorithm is flexible enough to deal with unknown covariance.Also, it is orderwise more efficient computationally than the ellipsoid algorithm.Using sub-linear sample complexity, our algorithm achieves the best known (and first) error guarantee. We demonstrate the effectiveness on large-scale sparse regression problems with arbitrary corruptions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/liu20b/liu20b.pdf",
        "supp": "",
        "pdf_size": 531969,
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7463330344494959473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "355ce94492",
        "title": "How To Backdoor Federated Learning",
        "site": "https://proceedings.mlr.press/v108/bagdasaryan20a.html",
        "author": "Eugene Bagdasaryan; Andreas Veit; Yiqing Hua; Deborah Estrin; Vitaly Shmatikov",
        "abstract": "Federated models are created by aggregating model updates submittedby participants.  To protect confidentiality of the training data,the aggregator by design has no visibility into how these updates aregenerated.  We show that this makes federated learning vulnerable to amodel-poisoning attack that is significantly more powerful than poisoningattacks that target only the training data.A single or multiple malicious participants can use modelreplacement to introduce backdoor functionality into the joint model,e.g., modify an image classifier so that it assigns an attacker-chosenlabel to images with certain features, or force a word predictor tocomplete certain sentences with an attacker-chosen word.  We evaluatemodel replacement under different assumptions for the standardfederated-learning tasks and show that it greatly outperformstraining-data poisoning.Federated learning employs secure aggregation to protect confidentialityof participants\u2019 local models and thus cannot detect anomalies inparticipants\u2019 contributions to the joint model.  To demonstrate thatanomaly detection would not have been effective in any case, we alsodevelop and evaluate a generic constrain-and-scale technique thatincorporates the evasion of defenses into the attacker\u2019s loss functionduring training.",
        "bibtex": "@InProceedings{pmlr-v108-bagdasaryan20a,\n  title = \t {How To Backdoor Federated Learning},\n  author =       {Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2938--2948},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bagdasaryan20a.html},\n  abstract = \t {Federated models are created by aggregating model updates submittedby participants.  To protect confidentiality of the training data,the aggregator by design has no visibility into how these updates aregenerated.  We show that this makes federated learning vulnerable to amodel-poisoning attack that is significantly more powerful than poisoningattacks that target only the training data.A single or multiple malicious participants can use modelreplacement to introduce backdoor functionality into the joint model,e.g., modify an image classifier so that it assigns an attacker-chosenlabel to images with certain features, or force a word predictor tocomplete certain sentences with an attacker-chosen word.  We evaluatemodel replacement under different assumptions for the standardfederated-learning tasks and show that it greatly outperformstraining-data poisoning.Federated learning employs secure aggregation to protect confidentialityof participants\u2019 local models and thus cannot detect anomalies inparticipants\u2019 contributions to the joint model.  To demonstrate thatanomaly detection would not have been effective in any case, we alsodevelop and evaluate a generic constrain-and-scale technique thatincorporates the evasion of defenses into the attacker\u2019s loss functionduring training.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf",
        "supp": "",
        "pdf_size": 878788,
        "gs_citation": 2644,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5359624145400700362&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Cornell Tech; Cornell Tech; Cornell Tech; Cornell Tech; Cornell Tech",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://tech.cornell.edu",
        "aff_unique_abbr": "Cornell Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York City",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "57009a15f8",
        "title": "How fine can fine-tuning be?  Learning efficient language models",
        "site": "https://proceedings.mlr.press/v108/radiya-dixit20a.html",
        "author": "Evani Radiya-Dixit; Xin Wang",
        "abstract": "State-of-the-art performance on language understanding tasks is now achieved with increasingly large networks; the current record holder has billions of parameters.  Given a language model pre-trained on massive unlabeled text corpora, only very light supervised fine-tuning is needed to learn a task: the number of fine-tuning steps is typically five orders of magnitude lower than the total parameter count.  Does this mean that fine-tuning only introduces \\emph{small} differences from the pre-trained model in the parameter space?  If so, can one avoid storing and computing an entire model for each task?  In this work, we address these questions by using Bidirectional Encoder Representations from Transformers (BERT) as an example.  As expected, we find that the fine-tuned models are close in parameter space to the pre-trained one, with the closeness varying from layer to layer.  We show that it suffices to fine-tune only the most critical layers.  Further, we find that there are surprisingly many \\emph{good} solutions in the set of sparsified versions of the pre-trained model.  As a result, fine-tuning of huge language models can be achieved by simply setting a certain number of entries in certain layers of the pre-trained parameters to zero, saving both task-specific parameter storage and computational cost.",
        "bibtex": "@InProceedings{pmlr-v108-radiya-dixit20a,\n  title = \t {How fine can fine-tuning be?  Learning efficient language models},\n  author =       {Radiya-Dixit, Evani and Wang, Xin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2435--2443},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/radiya-dixit20a/radiya-dixit20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/radiya-dixit20a.html},\n  abstract = \t {State-of-the-art performance on language understanding tasks is now achieved with increasingly large networks; the current record holder has billions of parameters.  Given a language model pre-trained on massive unlabeled text corpora, only very light supervised fine-tuning is needed to learn a task: the number of fine-tuning steps is typically five orders of magnitude lower than the total parameter count.  Does this mean that fine-tuning only introduces \\emph{small} differences from the pre-trained model in the parameter space?  If so, can one avoid storing and computing an entire model for each task?  In this work, we address these questions by using Bidirectional Encoder Representations from Transformers (BERT) as an example.  As expected, we find that the fine-tuned models are close in parameter space to the pre-trained one, with the closeness varying from layer to layer.  We show that it suffices to fine-tune only the most critical layers.  Further, we find that there are surprisingly many \\emph{good} solutions in the set of sparsified versions of the pre-trained model.  As a result, fine-tuning of huge language models can be achieved by simply setting a certain number of entries in certain layers of the pre-trained parameters to zero, saving both task-specific parameter storage and computational cost. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/radiya-dixit20a/radiya-dixit20a.pdf",
        "supp": "",
        "pdf_size": 652450,
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7034531909597436054&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Stanford University; Cerebras Systems",
        "aff_domain": "gmail.com; ",
        "email": "gmail.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Stanford University;Cerebras Systems",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.cerebras.com",
        "aff_unique_abbr": "Stanford;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "84f5ac0e06",
        "title": "Hyperbolic Manifold Regression",
        "site": "https://proceedings.mlr.press/v108/marconi20a.html",
        "author": "Gian Marconi; Carlo Ciliberto; Lorenzo Rosasco",
        "abstract": "Geometric representation learning has shown great promise for important tasks inartificial intelligence and machine learning. However, an open problem is yethow to integrate non-Euclidean representations with standard machine learningmethods.In this work, we consider the task of regression onto hyperbolic space for whichwe propose two approaches: a non-parametric kernel-method for which we also proveexcess risk bounds and a parametric deep learning model that is informed bythe geodesics of the target space.By recasting predictions on trees as manifold regression problems we demonstrate the applications of our approach on two challenging tasks: 1)hierarchical classification via label embeddings and 2) inventing new conceptsby predicting their embedding in a continuous representation of a base taxonomy.In our experiments, we find that the proposed estimators outperform their naivecounterparts that perform regression in the ambient Euclidean space.",
        "bibtex": "@InProceedings{pmlr-v108-marconi20a,\n  title = \t {Hyperbolic Manifold Regression},\n  author =       {Marconi, Gian and Ciliberto, Carlo and Rosasco, Lorenzo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2570--2580},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/marconi20a/marconi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/marconi20a.html},\n  abstract = \t {Geometric representation learning has shown great promise for important tasks inartificial intelligence and machine learning. However, an open problem is yethow to integrate non-Euclidean representations with standard machine learningmethods.In this work, we consider the task of regression onto hyperbolic space for whichwe propose two approaches: a non-parametric kernel-method for which we also proveexcess risk bounds and a parametric deep learning model that is informed bythe geodesics of the target space.By recasting predictions on trees as manifold regression problems we demonstrate the applications of our approach on two challenging tasks: 1)hierarchical classification via label embeddings and 2) inventing new conceptsby predicting their embedding in a continuous representation of a base taxonomy.In our experiments, we find that the proposed estimators outperform their naivecounterparts that perform regression in the ambient Euclidean space.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/marconi20a/marconi20a.pdf",
        "supp": "",
        "pdf_size": 1843018,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9585803750096643061&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "730e6ae8fe",
        "title": "Hypothesis Testing Interpretations and Renyi Differential Privacy",
        "site": "https://proceedings.mlr.press/v108/balle20a.html",
        "author": "Borja Balle; Gilles Barthe; Marco Gaboardi; Justin Hsu; Tetsuya Sato",
        "abstract": "Differential privacy is a de facto standard in data privacy, with applicationsin the public and private sectors. One way of explaining differential privacy,which is particularly appealing to statistician and social scientists, is bymeans of its statistical hypothesis testing interpretation. Informally, onecannot effectively test whether a specific individual has contributed her databy observing the output of a private mechanism\u2014any test cannot have bothhigh significance and high power.In this paper, we identify some conditions under which a privacy definition given in terms of a statistical divergence satisfies a similar interpretation.These conditions are useful to analyze the distinguishing power of divergencesand we use them to study the hypothesis testing interpretation of somerelaxations of differential privacy based on Renyi divergence. Ouranalysis also results in an improved conversion rule between these definitionsand differential privacy.",
        "bibtex": "@InProceedings{pmlr-v108-balle20a,\n  title = \t {Hypothesis Testing Interpretations and Renyi Differential Privacy},\n  author =       {Balle, Borja and Barthe, Gilles and Gaboardi, Marco and Hsu, Justin and Sato, Tetsuya},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2496--2506},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/balle20a/balle20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/balle20a.html},\n  abstract = \t {Differential privacy is a de facto standard in data privacy, with applicationsin the public and private sectors. One way of explaining differential privacy,which is particularly appealing to statistician and social scientists, is bymeans of its statistical hypothesis testing interpretation. Informally, onecannot effectively test whether a specific individual has contributed her databy observing the output of a private mechanism\u2014any test cannot have bothhigh significance and high power.In this paper, we identify some conditions under which a privacy definition given in terms of a statistical divergence satisfies a similar interpretation.These conditions are useful to analyze the distinguishing power of divergencesand we use them to study the hypothesis testing interpretation of somerelaxations of differential privacy based on Renyi divergence. Ouranalysis also results in an improved conversion rule between these definitionsand differential privacy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/balle20a/balle20a.pdf",
        "supp": "",
        "pdf_size": 573168,
        "gs_citation": 131,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1313428460413233565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "MPI for Security and Privacy and IMDEA Software Institute\u2020; MPI for Security and Privacy and IMDEA Software Institute\u2020; Boston University; University of Wisconsin\u2013Madison; Seikei University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "Max Planck Institute for Security and Privacy;Boston University;University of Wisconsin\u2013Madison;Seikei University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.mpi-sws.org;https://www.bu.edu;https://www.wisc.edu;https://www.seikei-u.ac.jp",
        "aff_unique_abbr": "MPI-SWS;BU;UW\u2013Madison;Seikei U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Madison",
        "aff_country_unique_index": "0;0;1;1;2",
        "aff_country_unique": "Germany;United States;Japan"
    },
    {
        "id": "5d52e56a64",
        "title": "Identifying and Correcting Label Bias in Machine Learning",
        "site": "https://proceedings.mlr.press/v108/jiang20a.html",
        "author": "Heinrich Jiang; Ofir Nachum",
        "abstract": "Datasets often contain biases which unfairly disadvantage certain groups, and classifiers trained on such datasets can inherit these biases. In this paper, we provide a mathematical formulation of how this bias can arise. We do so by assuming the existence of underlying, unknown, and unbiased labels which are overwritten by an agent who intends to provide accurate labels but may have biases against certain groups. Despite the fact that we only observe the biased labels, we are able to show that the bias may nevertheless be corrected by re-weighting the data points without changing the labels. We show, with theoretical guarantees, that training on the re-weighted dataset corresponds to training on the unobserved but unbiased labels, thus leading to an unbiased machine learning classifier. Our procedure is fast and robust and can be used with virtually any learning algorithm. We evaluate on a number of standard machine learning fairness datasets and a variety of fairness notions, finding that our method outperforms standard approaches in achieving fair classification.",
        "bibtex": "@InProceedings{pmlr-v108-jiang20a,\n  title = \t {Identifying and Correcting Label Bias in Machine Learning},\n  author =       {Jiang, Heinrich and Nachum, Ofir},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {702--712},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/jiang20a/jiang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/jiang20a.html},\n  abstract = \t {Datasets often contain biases which unfairly disadvantage certain groups, and classifiers trained on such datasets can inherit these biases. In this paper, we provide a mathematical formulation of how this bias can arise. We do so by assuming the existence of underlying, unknown, and unbiased labels which are overwritten by an agent who intends to provide accurate labels but may have biases against certain groups. Despite the fact that we only observe the biased labels, we are able to show that the bias may nevertheless be corrected by re-weighting the data points without changing the labels. We show, with theoretical guarantees, that training on the re-weighted dataset corresponds to training on the unobserved but unbiased labels, thus leading to an unbiased machine learning classifier. Our procedure is fast and robust and can be used with virtually any learning algorithm. We evaluate on a number of standard machine learning fairness datasets and a variety of fairness notions, finding that our method outperforms standard approaches in achieving fair classification.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/jiang20a/jiang20a.pdf",
        "supp": "",
        "pdf_size": 504228,
        "gs_citation": 417,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18053901079892085212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research; Google Research",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/google-research/google-research/tree/master/label_bias",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google Research",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "869454b67e",
        "title": "Importance Sampling via Local Sensitivity",
        "site": "https://proceedings.mlr.press/v108/raj20a.html",
        "author": "Anant Raj; Cameron Musco; Lester Mackey",
        "abstract": "Given a loss function $F:\\mathcal{X} \\rightarrow \\R^+$ that can be written as the sum of losses over a large set of inputs $a_1,\\ldots, a_n$,  it is often desirable to approximate $F$ by subsampling the input points. Strong theoretical guarantees require taking into account the importance of each point, measured by how much its individual loss contributes to $F(x)$. Maximizing this importance over all $x \\in \\mathcal{X}$ yields the \\emph{sensitivity score} of $a_i$. Sampling with probabilities proportional to these scores gives strong guarantees, allowing one to approximately minimize of $F$ using just the subsampled points.Unfortunately, sensitivity sampling is difficult to apply since (1) it is unclear how to efficiently compute the sensitivity scores and (2) the sample size required is often impractically large. To overcome both obstacles we introduce \\emph{local sensitivity}, which measures data point importance in a ball around some center $x_0$. We show that the local sensitivity can be efficiently estimated using the \\emph{leverage scores} of a quadratic approximation to $F$ and that the sample size required to approximate $F$ around $x_0$ can be bounded. We propose employing local sensitivity sampling in an iterative optimization method  and analyze its convergence when $F$ is smooth and convex.",
        "bibtex": "@InProceedings{pmlr-v108-raj20a,\n  title = \t {Importance Sampling via Local Sensitivity},\n  author =       {Raj, Anant and Musco, Cameron and Mackey, Lester},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3099--3109},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/raj20a/raj20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/raj20a.html},\n  abstract = \t {Given a loss function $F:\\mathcal{X} \\rightarrow \\R^+$ that can be written as the sum of losses over a large set of inputs $a_1,\\ldots, a_n$,  it is often desirable to approximate $F$ by subsampling the input points. Strong theoretical guarantees require taking into account the importance of each point, measured by how much its individual loss contributes to $F(x)$. Maximizing this importance over all $x \\in \\mathcal{X}$ yields the \\emph{sensitivity score} of $a_i$. Sampling with probabilities proportional to these scores gives strong guarantees, allowing one to approximately minimize of $F$ using just the subsampled points.Unfortunately, sensitivity sampling is difficult to apply since (1) it is unclear how to efficiently compute the sensitivity scores and (2) the sample size required is often impractically large. To overcome both obstacles we introduce \\emph{local sensitivity}, which measures data point importance in a ball around some center $x_0$. We show that the local sensitivity can be efficiently estimated using the \\emph{leverage scores} of a quadratic approximation to $F$ and that the sample size required to approximate $F$ around $x_0$ can be bounded. We propose employing local sensitivity sampling in an iterative optimization method  and analyze its convergence when $F$ is smooth and convex.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/raj20a/raj20a.pdf",
        "supp": "",
        "pdf_size": 651864,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11763394399422686055&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f8c299e656",
        "title": "Improved Regret Bounds for Projection-free Bandit Convex Optimization",
        "site": "https://proceedings.mlr.press/v108/garber20a.html",
        "author": "Dan Garber; Ben Kretzu",
        "abstract": "We revisit the challenge of designing online algorithms for the bandit convex optimization problem (BCO) which are also scalable to high dimensional problems. Hence, we consider algorithms that are \\textit{projection-free}, i.e., based on the conditional gradient method whose only access to the feasible decision set, is through a linear optimization oracle (as opposed to other methods which require potentially much more computationally-expensive subprocedures, such as computing Euclidean projections). We present the first such algorithm that attains $O(T^{3/4})$ expected regret using only $O(T)$ overall calls to the linear optimization oracle, in expectation, where $T$ in the number of prediction rounds. This improves over the $O(T^{4/5})$ expected regret bound recently obtained by  \\cite{Karbasi19}, and actually matches the current best regret bound for projection-free online learning in the \\textit{full information} setting.",
        "bibtex": "@InProceedings{pmlr-v108-garber20a,\n  title = \t {Improved Regret Bounds for Projection-free Bandit Convex Optimization},\n  author =       {Garber, Dan and Kretzu, Ben},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2196--2206},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/garber20a/garber20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/garber20a.html},\n  abstract = \t {We revisit the challenge of designing online algorithms for the bandit convex optimization problem (BCO) which are also scalable to high dimensional problems. Hence, we consider algorithms that are \\textit{projection-free}, i.e., based on the conditional gradient method whose only access to the feasible decision set, is through a linear optimization oracle (as opposed to other methods which require potentially much more computationally-expensive subprocedures, such as computing Euclidean projections). We present the first such algorithm that attains $O(T^{3/4})$ expected regret using only $O(T)$ overall calls to the linear optimization oracle, in expectation, where $T$ in the number of prediction rounds. This improves over the $O(T^{4/5})$ expected regret bound recently obtained by  \\cite{Karbasi19}, and actually matches the current best regret bound for projection-free online learning in the \\textit{full information} setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/garber20a/garber20a.pdf",
        "supp": "",
        "pdf_size": 343065,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4797253762633563717&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Technion - Israel Institute of Technology; Technion - Israel Institute of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "25aa19f0ce",
        "title": "Improving Maximum Likelihood Training for Text Generation with Density Ratio Estimation",
        "site": "https://proceedings.mlr.press/v108/song20a.html",
        "author": "Yuxuan Song; Ning Miao; Hao Zhou; Lantao Yu; Mingxuan Wang; Lei Li",
        "abstract": "Autoregressive neural sequence generative models trained by Maximum Likelihood Estimation suffer the exposure bias problem in practical finite sample scenarios. The crux is that the number of training samples for Maximum Likelihood Estimation is usually limited and the input data distributions are different at training and inference stages. Many methods have been proposed to solve the above problem, which relies on sampling from the non-stationary model distribution and suffers from high variance or biased estimations. In this paper, we propose $\\psi$-MLE, a new training scheme for autoregressive sequence generative models, which is effective and stable when operating at large sample space encountered in text generation.  We derive our algorithm from a new perspective of self-augmentation and introduce bias correction with density ratio estimation. Extensive experimental results on synthetic data and real-world text generation tasks demonstrate that our method stably outperforms Maximum Likelihood Estimation and other state-of-the-art sequence generative models in terms of both quality and diversity.",
        "bibtex": "@InProceedings{pmlr-v108-song20a,\n  title = \t {Improving Maximum Likelihood Training for Text Generation with Density Ratio Estimation},\n  author =       {Song, Yuxuan and Miao, Ning and Zhou, Hao and Yu, Lantao and Wang, Mingxuan and Li, Lei},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {122--132},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/song20a/song20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/song20a.html},\n  abstract = \t {Autoregressive neural sequence generative models trained by Maximum Likelihood Estimation suffer the exposure bias problem in practical finite sample scenarios. The crux is that the number of training samples for Maximum Likelihood Estimation is usually limited and the input data distributions are different at training and inference stages. Many methods have been proposed to solve the above problem, which relies on sampling from the non-stationary model distribution and suffers from high variance or biased estimations. In this paper, we propose $\\psi$-MLE, a new training scheme for autoregressive sequence generative models, which is effective and stable when operating at large sample space encountered in text generation.  We derive our algorithm from a new perspective of self-augmentation and introduce bias correction with density ratio estimation. Extensive experimental results on synthetic data and real-world text generation tasks demonstrate that our method stably outperforms Maximum Likelihood Estimation and other state-of-the-art sequence generative models in terms of both quality and diversity.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/song20a/song20a.pdf",
        "supp": "",
        "pdf_size": 352251,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9530388328584518784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a20ab905f6",
        "title": "Imputation estimators for unnormalized models with missing data",
        "site": "https://proceedings.mlr.press/v108/uehara20b.html",
        "author": "Masatoshi Uehara; Takeru Matsuda; Jae Kwang Kim",
        "abstract": "Several statistical models are given in the form of unnormalized densities and calculation of the normalization constant is intractable. We propose estimation methods for such unnormalized models with missing data. The key concept is to combine imputation techniques with estimators for unnormalized models including noise contrastive estimation and score matching. Further, we derive asymptotic distributions of the proposed estimators and construct confidence intervals. Simulation results with truncated Gaussian graphical models and the application to real data of wind direction demonstrate that the proposed methods enable statistical inference from missing data properly.",
        "bibtex": "@InProceedings{pmlr-v108-uehara20b,\n  title = \t {Imputation estimators for unnormalized models with missing data},\n  author =       {Uehara, Masatoshi and Matsuda, Takeru and Kim, Jae Kwang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {831--841},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/uehara20b/uehara20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/uehara20b.html},\n  abstract = \t {Several statistical models are given in the form of unnormalized densities and calculation of the normalization constant is intractable. We propose estimation methods for such unnormalized models with missing data. The key concept is to combine imputation techniques with estimators for unnormalized models including noise contrastive estimation and score matching. Further, we derive asymptotic distributions of the proposed estimators and construct confidence intervals. Simulation results with truncated Gaussian graphical models and the application to real data of wind direction demonstrate that the proposed methods enable statistical inference from missing data properly.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/uehara20b/uehara20b.pdf",
        "supp": "",
        "pdf_size": 346787,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15696872559250674685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "af606ae7a5",
        "title": "Independent Subspace Analysis for Unsupervised Learning of Disentangled Representations",
        "site": "https://proceedings.mlr.press/v108/stuehmer20a.html",
        "author": "Jan Stuehmer; Richard Turner; Sebastian Nowozin",
        "abstract": "Recently there has been an increased interest in unsupervised learning of disentangled representations using the Variational Autoencoder (VAE) framework. Most of the existing work has focused largely on modifying the variational cost function to achieve this goal. We first show that these modifications, e.g. beta-VAE, simplify the tendency of variational inference to underfit, causing pathological over-pruning and over-orthogonalization of learned components. Second, we propose a complementary approach: to modify the probabilistic model with a structured latent prior. This prior discovers latent variable representations that are structured into a hierarchy of independent vector spaces. The proposed prior has three major advantages: First, in contrast to the standard VAE normal prior, the proposed prior is not rotationally invariant. This feature of our approach resolves the problem of unidentifiability of the standard VAE normal prior. Second, we demonstrate that the proposed prior encourages a disentangled latent representation which facilitates learning of disentangled representations. Third, extensive quantitative experiments demonstrate that the prior significantly mitigates the trade-off between reconstruction loss and disentanglement over the state of the art.",
        "bibtex": "@InProceedings{pmlr-v108-stuehmer20a,\n  title = \t {Independent Subspace Analysis for Unsupervised Learning of Disentangled Representations},\n  author =       {Stuehmer, Jan and Turner, Richard and Nowozin, Sebastian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1200--1210},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/stuehmer20a/stuehmer20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/stuehmer20a.html},\n  abstract = \t {Recently there has been an increased interest in unsupervised learning of disentangled representations using the Variational Autoencoder (VAE) framework. Most of the existing work has focused largely on modifying the variational cost function to achieve this goal. We first show that these modifications, e.g. beta-VAE, simplify the tendency of variational inference to underfit, causing pathological over-pruning and over-orthogonalization of learned components. Second, we propose a complementary approach: to modify the probabilistic model with a structured latent prior. This prior discovers latent variable representations that are structured into a hierarchy of independent vector spaces. The proposed prior has three major advantages: First, in contrast to the standard VAE normal prior, the proposed prior is not rotationally invariant. This feature of our approach resolves the problem of unidentifiability of the standard VAE normal prior. Second, we demonstrate that the proposed prior encourages a disentangled latent representation which facilitates learning of disentangled representations. Third, extensive quantitative experiments demonstrate that the prior significantly mitigates the trade-off between reconstruction loss and disentanglement over the state of the art.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/stuehmer20a/stuehmer20a.pdf",
        "supp": "",
        "pdf_size": 2631261,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17931820104423226955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Microsoft Research; University of Cambridge; Google Brain",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Microsoft;University of Cambridge;Google",
        "aff_unique_dep": "Microsoft Research;;Google Brain",
        "aff_unique_url": "https://www.microsoft.com/en-us/research;https://www.cam.ac.uk;https://brain.google.com",
        "aff_unique_abbr": "MSR;Cambridge;Google Brain",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Cambridge;Mountain View",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9aa17f90b0",
        "title": "Inference of Dynamic Graph Changes for Functional Connectome",
        "site": "https://proceedings.mlr.press/v108/ji20a.html",
        "author": "Dingjue Ji; Junwei Lu; Yiliang Zhang; Siyuan Gao; Hongyu Zhao",
        "abstract": "Dynamic functional connectivity is an effective measure for the brain\u2019s responses to continuous stimuli. We propose an inferential method to detect the dynamic changes of brain networks based on time-varying graphical models. Whereas most existing methods focus on testing the existence of change points, the dynamics in the brain network offer more signals in many neuroscience studies. We propose a novel method to conduct hypothesis testing on changes in dynamic brain networks. We introduce a bootstrap statistic to approximate the supreme of the high-dimensional empirical processes over dynamically changing edges. Our simulations show that this framework can capture the change points with changed connectivity. Finally, we apply our method to a brain imaging dataset under a natural audio-video stimulus and illustrate that we are able to detect temporal changes in brain networks. The functions of the identified regions are consistent with specific emotional annotations, which are closely associated with changes inferred by our method.",
        "bibtex": "@InProceedings{pmlr-v108-ji20a,\n  title = \t {Inference of Dynamic Graph Changes for Functional Connectome},\n  author =       {Ji, Dingjue and Lu, Junwei and Zhang, Yiliang and Gao, Siyuan and Zhao, Hongyu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3230--3240},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ji20a/ji20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ji20a.html},\n  abstract = \t {Dynamic functional connectivity is an effective measure for the brain\u2019s responses to continuous stimuli. We propose an inferential method to detect the dynamic changes of brain networks based on time-varying graphical models. Whereas most existing methods focus on testing the existence of change points, the dynamics in the brain network offer more signals in many neuroscience studies. We propose a novel method to conduct hypothesis testing on changes in dynamic brain networks. We introduce a bootstrap statistic to approximate the supreme of the high-dimensional empirical processes over dynamically changing edges. Our simulations show that this framework can capture the change points with changed connectivity. Finally, we apply our method to a brain imaging dataset under a natural audio-video stimulus and illustrate that we are able to detect temporal changes in brain networks. The functions of the identified regions are consistent with specific emotional annotations, which are closely associated with changes inferred by our method. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/ji20a/ji20a.pdf",
        "supp": "",
        "pdf_size": 967788,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4969572478258569079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Interdepartmental Program of Computational Biology & Bioinformatics\u2020; Department of Biostatistics, Harvard T.H. Chan School of Public Health\u266f; Department of Biostatistics\u2021; Department of Biomedical Engineering\u00a7; Interdepartmental Program of Computational Biology & Bioinformatics\u2020+Department of Biostatistics\u2021",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0+2",
        "aff_unique_norm": "Interdepartmental Program of Computational Biology & Bioinformatics;Harvard T.H. Chan School of Public Health;Department of Biostatistics;Department of Biomedical Engineering",
        "aff_unique_dep": "Computational Biology & Bioinformatics;Department of Biostatistics;Biostatistics;Biomedical Engineering",
        "aff_unique_url": ";https://www.hsph.harvard.edu;;",
        "aff_unique_abbr": ";Harvard Chan School;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1;",
        "aff_country_unique": ";United States"
    },
    {
        "id": "29bff11a7c",
        "title": "Infinitely deep neural networks as diffusion processes",
        "site": "https://proceedings.mlr.press/v108/peluchetti20a.html",
        "author": "Stefano Peluchetti; Stefano Favaro",
        "abstract": "When the parameters are independently and identically distributed (initialized) neural networks exhibit undesirable properties that emerge as the number of layers increases, e.g. a vanishing dependency on the input and a concentration on restrictive families of functions including constant functions. We consider parameter distributions that shrink as the number of layers increases in order to recover well-behaved stochastic processes in the limit of infinite depth. This leads to set forth a link between infinitely deep residual networks and solutions to stochastic differential equations, i.e. diffusion processes. We show that these limiting processes do not suffer from the aforementioned issues and investigate their properties.",
        "bibtex": "@InProceedings{pmlr-v108-peluchetti20a,\n  title = \t {Infinitely deep neural networks as diffusion processes},\n  author =       {Peluchetti, Stefano and Favaro, Stefano},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1126--1136},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/peluchetti20a/peluchetti20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/peluchetti20a.html},\n  abstract = \t {When the parameters are independently and identically distributed (initialized) neural networks exhibit undesirable properties that emerge as the number of layers increases, e.g. a vanishing dependency on the input and a concentration on restrictive families of functions including constant functions. We consider parameter distributions that shrink as the number of layers increases in order to recover well-behaved stochastic processes in the limit of infinite depth. This leads to set forth a link between infinitely deep residual networks and solutions to stochastic differential equations, i.e. diffusion processes. We show that these limiting processes do not suffer from the aforementioned issues and investigate their properties.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/peluchetti20a/peluchetti20a.pdf",
        "supp": "",
        "pdf_size": 764917,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11986569720767621126&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Cogent Labs Department ESOMAS; University of Torino and Collegio Carlo Alberto",
        "aff_domain": "cogent.co.jp;unito.it",
        "email": "cogent.co.jp;unito.it",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Cogent Labs;University of Torino",
        "aff_unique_dep": "Department ESOMAS;",
        "aff_unique_url": ";https://www.unito.it",
        "aff_unique_abbr": ";Unito",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";Italy"
    },
    {
        "id": "20aaeb8b6d",
        "title": "Integrals over Gaussians under Linear Domain Constraints",
        "site": "https://proceedings.mlr.press/v108/gessner20a.html",
        "author": "Alexandra Gessner; Oindrila Kanjilal; Philipp Hennig",
        "abstract": "Integrals of linearly constrained multivariate Gaussian densities are a frequent problem in machine learning and statistics, arising in tasks like generalized linear models and Bayesian optimization. Yet they are notoriously hard to compute, and to further complicate matters, the numerical values of such integrals may be very small. We present an efficient black-box algorithm that exploits geometry for the estimation of integrals over a small, truncated Gaussian volume, and to simulate therefrom. Our algorithm uses the Holmes-Diaconis-Ross (HDR) method combined with an analytic version of elliptical slice sampling (ESS). Adapted to the linear setting, ESS allows for rejection-free sampling, because intersections of ellipses and domain boundaries have closed-form solutions. The key idea of HDR is to decompose the integral into easier-to-compute conditional probabilities by using a sequence of nested domains. Remarkably, it allows for direct computation of the logarithm of the integral value and thus enables the computation of extremely small probability masses. We demonstrate the effectiveness of our tailored combination of HDR and ESS on high-dimensional integrals and on entropy search for Bayesian optimization.",
        "bibtex": "@InProceedings{pmlr-v108-gessner20a,\n  title = \t {Integrals over Gaussians under Linear Domain Constraints},\n  author =       {Gessner, Alexandra and Kanjilal, Oindrila and Hennig, Philipp},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2764--2774},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/gessner20a/gessner20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/gessner20a.html},\n  abstract = \t {Integrals of linearly constrained multivariate Gaussian densities are a frequent problem in machine learning and statistics, arising in tasks like generalized linear models and Bayesian optimization. Yet they are notoriously hard to compute, and to further complicate matters, the numerical values of such integrals may be very small. We present an efficient black-box algorithm that exploits geometry for the estimation of integrals over a small, truncated Gaussian volume, and to simulate therefrom. Our algorithm uses the Holmes-Diaconis-Ross (HDR) method combined with an analytic version of elliptical slice sampling (ESS). Adapted to the linear setting, ESS allows for rejection-free sampling, because intersections of ellipses and domain boundaries have closed-form solutions. The key idea of HDR is to decompose the integral into easier-to-compute conditional probabilities by using a sequence of nested domains. Remarkably, it allows for direct computation of the logarithm of the integral value and thus enables the computation of extremely small probability masses. We demonstrate the effectiveness of our tailored combination of HDR and ESS on high-dimensional integrals and on entropy search for Bayesian optimization.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/gessner20a/gessner20a.pdf",
        "supp": "",
        "pdf_size": 818982,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=805263408629689061&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of Tuebingen + MPI for Intelligent Systems; University of Tuebingen + Technical University of Munich; University of Tuebingen + MPI for Intelligent Systems",
        "aff_domain": "tue.mpg.de;tum.de;tue.mpg.de",
        "email": "tue.mpg.de;tum.de;tue.mpg.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+2;0+1",
        "aff_unique_norm": "University of Tuebingen;Max Planck Institute for Intelligent Systems;Technical University of Munich",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.mpi-is.mpg.de;https://www.tum.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;MPI-IS;TUM",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "b2d23d5e70",
        "title": "Interpretable Companions for Black-Box Models",
        "site": "https://proceedings.mlr.press/v108/pan20a.html",
        "author": "Danqing Pan; Tong Wang; Satoshi Hara",
        "abstract": "We present an interpretable companion model for any pre-trained black-box classifiers. The idea is that for any input, a user can decide to either receive a prediction from the black-box model, with high accuracy but no explanations, or employ a \\emph{companion rule} to obtain an interpretable prediction with slightly lower accuracy. The companion model is trained from data and the predictions of the black-box model, with the objective combining area under the transparency\u2013accuracy curve and model complexity. Our model provides flexible choices for practitioners who face the dilemma of choosing between always using interpretable models and always using black-box models for a predictive task, so users can, for any given input, take a step back to resort to an interpretable prediction if they find the predictive performance satisfying, or stick to the black-box model if the rules are unsatisfying. To show the value of companion models, we design a human evaluation on more than a hundred people to investigate the tolerable accuracy loss to gain interpretability for humans.",
        "bibtex": "@InProceedings{pmlr-v108-pan20a,\n  title = \t {Interpretable Companions for Black-Box Models},\n  author =       {Pan, Danqing and Wang, Tong and Hara, Satoshi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2444--2454},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pan20a/pan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pan20a.html},\n  abstract = \t {We present an interpretable companion model for any pre-trained black-box classifiers. The idea is that for any input, a user can decide to either receive a prediction from the black-box model, with high accuracy but no explanations, or employ a \\emph{companion rule} to obtain an interpretable prediction with slightly lower accuracy. The companion model is trained from data and the predictions of the black-box model, with the objective combining area under the transparency\u2013accuracy curve and model complexity. Our model provides flexible choices for practitioners who face the dilemma of choosing between always using interpretable models and always using black-box models for a predictive task, so users can, for any given input, take a step back to resort to an interpretable prediction if they find the predictive performance satisfying, or stick to the black-box model if the rules are unsatisfying. To show the value of companion models, we design a human evaluation on more than a hundred people to investigate the tolerable accuracy loss to gain interpretability for humans. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/pan20a/pan20a.pdf",
        "supp": "",
        "pdf_size": 3295869,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3088762132555188018&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "05d177efba",
        "title": "Interpretable Deep Gaussian Processes with Moments",
        "site": "https://proceedings.mlr.press/v108/lu20b.html",
        "author": "Chi-Ken Lu; Scott Cheng-Hsin Yang; Xiaoran Hao; Patrick Shafto",
        "abstract": "Deep Gaussian Processes (DGPs) combine the the expressiveness of Deep Neural Networks (DNNs) with quantified uncertainty of Gaussian Processes (GPs). Expressive power and intractable inference both result from the non-Gaussian distribution over composition functions. We propose interpretable DGP based on approximating DGP as a GP by calculating the exact moments, which additionally identify the heavy-tailed nature of some DGP distributions. Consequently, our approach admits interpretation as both NNs with specified activation functions and as a variational approximation to DGP. We identify the expressivity parameter of DGP and find non-local and non-stationary correlation from DGP composition. We provide general recipes for deriving the effective kernels for DGP of two, three, or infinitely many layers, composed of homogeneous or heterogeneous kernels. Results illustrate the expressiveness of our effective kernels through samples from the prior and inference on simulated and real data and demonstrate advantages of interpretability by analysis of analytic forms, and draw relations and equivalences across kernels.",
        "bibtex": "@InProceedings{pmlr-v108-lu20b,\n  title = \t {Interpretable Deep Gaussian Processes with Moments},\n  author =       {Lu, Chi-Ken and Yang, Scott Cheng-Hsin and Hao, Xiaoran and Shafto, Patrick},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {613--623},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lu20b/lu20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lu20b.html},\n  abstract = \t {Deep Gaussian Processes (DGPs) combine the the expressiveness of Deep Neural Networks (DNNs) with quantified uncertainty of Gaussian Processes (GPs). Expressive power and intractable inference both result from the non-Gaussian distribution over composition functions. We propose interpretable DGP based on approximating DGP as a GP by calculating the exact moments, which additionally identify the heavy-tailed nature of some DGP distributions. Consequently, our approach admits interpretation as both NNs with specified activation functions and as a variational approximation to DGP. We identify the expressivity parameter of DGP and find non-local and non-stationary correlation from DGP composition. We provide general recipes for deriving the effective kernels for DGP of two, three, or infinitely many layers, composed of homogeneous or heterogeneous kernels. Results illustrate the expressiveness of our effective kernels through samples from the prior and inference on simulated and real data and demonstrate advantages of interpretability by analysis of analytic forms, and draw relations and equivalences across kernels.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lu20b/lu20b.pdf",
        "supp": "",
        "pdf_size": 822115,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14162230588984028411&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5a551b4f45",
        "title": "Invertible Generative Modeling using Linear Rational Splines",
        "site": "https://proceedings.mlr.press/v108/dolatabadi20a.html",
        "author": "Hadi Mohaghegh Dolatabadi; Sarah Erfani; Christopher Leckie",
        "abstract": "Normalizing flows attempt to model an arbitrary probability distribution through a set of invertible mappings. These transformations are required to achieve a tractable Jacobian determinant that can be used in high-dimensional scenarios. The first normalizing flow designs used coupling layer mappings built upon affine transformations. The significant advantage of such models is their easy-to-compute inverse. Nevertheless, making use of affine transformations may limit the expressiveness of such models. Recently, invertible piecewise polynomial functions as a replacement for affine transformations have attracted attention. However, these methods require solving a polynomial equation to calculate their inverse. In this paper, we explore using linear rational splines as a replacement for affine transformations used in coupling layers. Besides having a straightforward inverse, inference and generation have similar cost and architecture in this method. Moreover, simulation results demonstrate the competitiveness of this approach\u2019s performance compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v108-dolatabadi20a,\n  title = \t {Invertible Generative Modeling using Linear Rational Splines},\n  author =       {Dolatabadi, Hadi Mohaghegh and Erfani, Sarah and Leckie, Christopher},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4236--4246},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dolatabadi20a/dolatabadi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dolatabadi20a.html},\n  abstract = \t {Normalizing flows attempt to model an arbitrary probability distribution through a set of invertible mappings. These transformations are required to achieve a tractable Jacobian determinant that can be used in high-dimensional scenarios. The first normalizing flow designs used coupling layer mappings built upon affine transformations. The significant advantage of such models is their easy-to-compute inverse. Nevertheless, making use of affine transformations may limit the expressiveness of such models. Recently, invertible piecewise polynomial functions as a replacement for affine transformations have attracted attention. However, these methods require solving a polynomial equation to calculate their inverse. In this paper, we explore using linear rational splines as a replacement for affine transformations used in coupling layers. Besides having a straightforward inverse, inference and generation have similar cost and architecture in this method. Moreover, simulation results demonstrate the competitiveness of this approach\u2019s performance compared to existing methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/dolatabadi20a/dolatabadi20a.pdf",
        "supp": "",
        "pdf_size": 1677437,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17204933288805106812&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fed23bff25",
        "title": "Ivy: Instrumental Variable Synthesis for Causal Inference",
        "site": "https://proceedings.mlr.press/v108/kuang20a.html",
        "author": "Zhaobin Kuang; Frederic Sala; Nimit Sohoni; Sen Wu; Aldo C\u00f3rdova-Palomera; Jared Dunnmon; James Priest; Christopher Re",
        "abstract": "A popular way to estimate the causal effect of a variable x on y from observational data is to use an instrumental variable (IV): a third variable z that affects y only through x. The more strongly z is associated with x, the more reliable the estimate is, but such strong IVs are difficult to find. Instead, practitioners combine more commonly available IV candidates\u2014which are not necessarily strong, or even valid, IVs\u2014into a single \"summary\" that is plugged into causal effect estimators in place of an IV. In genetic epidemiology, such approaches are known as allele scores. Allele scores require strong assumptions\u2014independence and validity of all IV candidates\u2014for the resulting estimate to be reliable. To relax these assumptions, we propose Ivy, a new method to combine IV candidates that can handle correlated and invalid IV candidates in a robust manner. Theoretically, we characterize this robustness, its limits, and its impact on the resulting causal estimates. Empirically, Ivy can correctly identify the directionality of known relationships and is robust against false discovery (median effect size <= 0.025) on three real-world datasets with no causal effects, while allele scores return more biased estimates (median effect size  >= 0.118).",
        "bibtex": "@InProceedings{pmlr-v108-kuang20a,\n  title = \t {Ivy: Instrumental Variable Synthesis for Causal Inference},\n  author =       {Kuang, Zhaobin and Sala, Frederic and Sohoni, Nimit and Wu, Sen and C\\'ordova-Palomera, Aldo and Dunnmon, Jared and Priest, James and Re, Christopher},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {398--410},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kuang20a/kuang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kuang20a.html},\n  abstract = \t {A popular way to estimate the causal effect of a variable x on y from observational data is to use an instrumental variable (IV): a third variable z that affects y only through x. The more strongly z is associated with x, the more reliable the estimate is, but such strong IVs are difficult to find. Instead, practitioners combine more commonly available IV candidates\u2014which are not necessarily strong, or even valid, IVs\u2014into a single \"summary\" that is plugged into causal effect estimators in place of an IV. In genetic epidemiology, such approaches are known as allele scores. Allele scores require strong assumptions\u2014independence and validity of all IV candidates\u2014for the resulting estimate to be reliable. To relax these assumptions, we propose Ivy, a new method to combine IV candidates that can handle correlated and invalid IV candidates in a robust manner. Theoretically, we characterize this robustness, its limits, and its impact on the resulting causal estimates. Empirically, Ivy can correctly identify the directionality of known relationships and is robust against false discovery (median effect size <= 0.025) on three real-world datasets with no causal effects, while allele scores return more biased estimates (median effect size  >= 0.118).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kuang20a/kuang20a.pdf",
        "supp": "",
        "pdf_size": 527355,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11561563588874482424&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6d0520000a",
        "title": "Kernel Conditional Density Operators",
        "site": "https://proceedings.mlr.press/v108/schuster20a.html",
        "author": "Ingmar Schuster; Mattes Mollenhauer; Stefan Klus; Krikamol Muandet",
        "abstract": "We introduce a novel conditional density estimationmodel termed the conditional densityoperator (CDO). It naturally captures multivariate,multimodal output densities andshows performance that is competitive withrecent neural conditional density models andGaussian processes. The proposed model isbased on a novel approach to the reconstructionof probability densities from their kernelmean embeddings by drawing connections toestimation of Radon-Nikodym derivatives inthe reproducing kernel Hilbert space (RKHS).We prove finite sample bounds for the estimationerror in a standard density reconstructionscenario, independent of problem dimensionality.Interestingly, when a kernel is used thatis also a probability density, the CDO allowsus to both evaluate and sample the outputdensity efficiently. We demonstrate the versatilityand performance of the proposed modelon both synthetic and real-world data.",
        "bibtex": "@InProceedings{pmlr-v108-schuster20a,\n  title = \t {Kernel Conditional Density Operators},\n  author =       {Schuster, Ingmar and Mollenhauer, Mattes and Klus, Stefan and Muandet, Krikamol},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {993--1004},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/schuster20a/schuster20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/schuster20a.html},\n  abstract = \t {We introduce a novel conditional density estimationmodel termed the conditional densityoperator (CDO). It naturally captures multivariate,multimodal output densities andshows performance that is competitive withrecent neural conditional density models andGaussian processes. The proposed model isbased on a novel approach to the reconstructionof probability densities from their kernelmean embeddings by drawing connections toestimation of Radon-Nikodym derivatives inthe reproducing kernel Hilbert space (RKHS).We prove finite sample bounds for the estimationerror in a standard density reconstructionscenario, independent of problem dimensionality.Interestingly, when a kernel is used thatis also a probability density, the CDO allowsus to both evaluate and sample the outputdensity efficiently. We demonstrate the versatilityand performance of the proposed modelon both synthetic and real-world data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/schuster20a/schuster20a.pdf",
        "supp": "",
        "pdf_size": 789621,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1832441753241428850&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "406780fe84",
        "title": "Kernels over Sets of Finite Sets using RKHS Embeddings, with Application to Bayesian (Combinatorial) Optimization",
        "site": "https://proceedings.mlr.press/v108/buathong20a.html",
        "author": "Poompol Buathong; David Ginsbourger; Tipaluck Krityakierne",
        "abstract": "We focus on kernel methods for set-valued inputs and their application to Bayesian set optimization, notably combinatorial optimization. We investigate two classes of set kernels that both rely on Reproducing Kernel Hilbert Space embeddings, namely the \"Double Sum\" (DS) kernels recently considered in Bayesian set optimization, and a class introduced here called \"Deep Embedding\" (DE) kernels that essentially consists in applying a radial kernel on Hilbert space on top of the canonical distance induced by another kernel such as a DS kernel. We establish in particular that while DS kernels typically suffer from a lack of strict positive definiteness, vast subclasses of DE kernels built upon DS kernels do possess this property, enabling in turn combinatorial optimization without requiring to introduce a jitter parameter.  Proofs of theoretical results about considered kernels are complemented by a few practicalities regarding hyperparameter fitting. We furthermore demonstrate the applicability of our approach in prediction and optimization tasks, relying both on toy examples and on two test cases from mechanical engineering and hydrogeology, respectively. Experimental results highlight the applicability and compared merits of the considered approaches while opening new perspectives in prediction and sequential design with set inputs.",
        "bibtex": "@InProceedings{pmlr-v108-buathong20a,\n  title = \t {Kernels over Sets of Finite Sets using RKHS Embeddings, with Application to Bayesian (Combinatorial) Optimization},\n  author =       {Buathong, Poompol and Ginsbourger, David and Krityakierne, Tipaluck},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2731--2741},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/buathong20a/buathong20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/buathong20a.html},\n  abstract = \t {We focus on kernel methods for set-valued inputs and their application to Bayesian set optimization, notably combinatorial optimization. We investigate two classes of set kernels that both rely on Reproducing Kernel Hilbert Space embeddings, namely the \"Double Sum\" (DS) kernels recently considered in Bayesian set optimization, and a class introduced here called \"Deep Embedding\" (DE) kernels that essentially consists in applying a radial kernel on Hilbert space on top of the canonical distance induced by another kernel such as a DS kernel. We establish in particular that while DS kernels typically suffer from a lack of strict positive definiteness, vast subclasses of DE kernels built upon DS kernels do possess this property, enabling in turn combinatorial optimization without requiring to introduce a jitter parameter.  Proofs of theoretical results about considered kernels are complemented by a few practicalities regarding hyperparameter fitting. We furthermore demonstrate the applicability of our approach in prediction and optimization tasks, relying both on toy examples and on two test cases from mechanical engineering and hydrogeology, respectively. Experimental results highlight the applicability and compared merits of the considered approaches while opening new perspectives in prediction and sequential design with set inputs.   }\n}",
        "pdf": "http://proceedings.mlr.press/v108/buathong20a/buathong20a.pdf",
        "supp": "",
        "pdf_size": 548800,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17294748619129578941&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Mathematics, Faculty of Science, Mahidol University, Thailand; Uncertainty Quanti\ufb01cation and Optimal Design group, Idiap Research Institute, Switzerland+Institute of Mathematical Statistics and Actuarial Science, University of Bern, Switzerland; Department of Mathematics, Faculty of Science, Mahidol University, Thailand+Centre of Excellence in Mathematics, CHE, Thailand",
        "aff_domain": "mahidol.ac.th;idiap.ch;mahidol.ac.th",
        "email": "mahidol.ac.th;idiap.ch;mahidol.ac.th",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;0+3",
        "aff_unique_norm": "Mahidol University;Idiap Research Institute;University of Bern;Centre of Excellence in Mathematics",
        "aff_unique_dep": "Department of Mathematics;Uncertainty Quanti\ufb01cation and Optimal Design group;Institute of Mathematical Statistics and Actuarial Science;Centre of Excellence in Mathematics",
        "aff_unique_url": "https://www.mahidol.ac.th;https://www.idiap.ch;https://www.unibe.ch;",
        "aff_unique_abbr": ";;;",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+1;0+0",
        "aff_country_unique": "Thailand;Switzerland"
    },
    {
        "id": "99887fc6a4",
        "title": "LIBRE: Learning Interpretable Boolean Rule Ensembles",
        "site": "https://proceedings.mlr.press/v108/mita20a.html",
        "author": "Graziano Mita; Paolo Papotti; Maurizio Filippone; Pietro Michiardi",
        "abstract": "We present a novel method\u2014LIBRE\u2014learn an interpretable classifier, which materializes as a set of Boolean rules. LIBRE uses an ensemble of bottom-up, weak learners operating on a random subset of features, which allows for the learning of rules that generalize well on unseen data even in imbalanced settings. Weak learners are combined with a simple union so that the final ensemble is also interpretable. Experimental results indicate that LIBRE efficiently strikes the right balance between prediction accuracy, which is competitive with black-box methods, and interpretability, which is often superior to alternative methods from the literature.",
        "bibtex": "@InProceedings{pmlr-v108-mita20a,\n  title = \t {LIBRE: Learning Interpretable Boolean Rule Ensembles},\n  author =       {Mita, Graziano and Papotti, Paolo and Filippone, Maurizio and Michiardi, Pietro},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {245--255},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mita20a/mita20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mita20a.html},\n  abstract = \t {We present a novel method\u2014LIBRE\u2014learn an interpretable classifier, which materializes as a set of Boolean rules. LIBRE uses an ensemble of bottom-up, weak learners operating on a random subset of features, which allows for the learning of rules that generalize well on unseen data even in imbalanced settings. Weak learners are combined with a simple union so that the final ensemble is also interpretable. Experimental results indicate that LIBRE efficiently strikes the right balance between prediction accuracy, which is competitive with black-box methods, and interpretability, which is often superior to alternative methods from the literature.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mita20a/mita20a.pdf",
        "supp": "",
        "pdf_size": 387538,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10636406853008420013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "EURECOM, 06410 Biot (France); EURECOM, 06410 Biot (France); EURECOM, 06410 Biot (France); EURECOM, 06410 Biot (France)",
        "aff_domain": "eurecom.fr;eurecom.fr;eurecom.fr;eurecom.fr",
        "email": "eurecom.fr;eurecom.fr;eurecom.fr;eurecom.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EURECOM",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.eurecom.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "28faee1fe0",
        "title": "Langevin Monte Carlo without smoothness",
        "site": "https://proceedings.mlr.press/v108/chatterji20a.html",
        "author": "Niladri Chatterji; Jelena Diakonikolas; Michael I. Jordan; Peter Bartlett",
        "abstract": "Langevin Monte Carlo (LMC) is an iterative algorithm used to generate samples from a distribution that is known only up to a normalizing constant. The nonasymptotic dependence of its mixing time on the dimension and target accuracy is understood mainly in the setting of smooth (gradient-Lipschitz) log-densities, a serious limitation for applications in machine learning. In this paper, we remove this limitation, providing polynomial-time convergence guarantees for a variant of LMC in the setting of nonsmooth log-concave distributions. At a high level, our results follow by leveraging the implicit smoothing of the log-density that comes from a small  Gaussian perturbation that we add to the iterates of the algorithm and controlling the bias and variance that are induced by this perturbation.",
        "bibtex": "@InProceedings{pmlr-v108-chatterji20a,\n  title = \t {Langevin Monte Carlo without smoothness},\n  author =       {Chatterji, Niladri and Diakonikolas, Jelena and Jordan, Michael I. and Bartlett, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1716--1726},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chatterji20a/chatterji20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chatterji20a.html},\n  abstract = \t {Langevin Monte Carlo (LMC) is an iterative algorithm used to generate samples from a distribution that is known only up to a normalizing constant. The nonasymptotic dependence of its mixing time on the dimension and target accuracy is understood mainly in the setting of smooth (gradient-Lipschitz) log-densities, a serious limitation for applications in machine learning. In this paper, we remove this limitation, providing polynomial-time convergence guarantees for a variant of LMC in the setting of nonsmooth log-concave distributions. At a high level, our results follow by leveraging the implicit smoothing of the log-density that comes from a small  Gaussian perturbation that we add to the iterates of the algorithm and controlling the bias and variance that are induced by this perturbation.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chatterji20a/chatterji20a.pdf",
        "supp": "",
        "pdf_size": 550438,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1573496108731800851&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "07a6085bb2",
        "title": "Laplacian-Regularized Graph Bandits: Algorithms and Theoretical Analysis",
        "site": "https://proceedings.mlr.press/v108/yang20c.html",
        "author": "Kaige Yang; Laura Toni; Xiaowen Dong",
        "abstract": "We consider a stochastic linear bandit problem with multiple users, where the relationship between users is captured by an underlying graph and user preferences are represented as smooth signals on the  graph. We introduce a novel bandit algorithm where the smoothness prior is imposed via the random-walk graph Laplacian, which leads to a single-user cumulative regret scaling as $\\Tilde{\\mathcal{O}}(\\Psi d \\sqrt{T})$ with time horizon $T$, feature dimensionality $d$, and the scalar parameter $\\Psi \\in (0,1)$ that depends on the graph connectivity. This is an improvement over $\\Tilde{\\mathcal{O}}(d \\sqrt{T})$ in \\algo{LinUCB}\u00a0\\Ccite{li2010contextual}, where user relationship is not taken into account.In terms of network regret (sum of cumulative regret over $n$ users), the proposed algorithm leads to a scaling as $\\Tilde{\\mathcal{O}}(\\Psi d\\sqrt{nT})$, which is a significant improvement over $\\Tilde{\\mathcal{O}}(nd\\sqrt{T})$ in the state-of-the-art algorithm \\algo{Gob.Lin} \\Ccite{cesa2013gang}. To improve scalability, we further propose a simplified algorithm with a linear computational complexity with respect to the number of users, while maintaining the same regret. Finally, we present a finite-time analysis on the proposed algorithms, and demonstrate their advantage in comparison with state-of-the-art graph-based bandit algorithms on both synthetic and real-world data.",
        "bibtex": "@InProceedings{pmlr-v108-yang20c,\n  title = \t {Laplacian-Regularized Graph Bandits: Algorithms and Theoretical Analysis},\n  author =       {Yang, Kaige and Toni, Laura and Dong, Xiaowen},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3133--3143},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yang20c/yang20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yang20c.html},\n  abstract = \t {We consider a stochastic linear bandit problem with multiple users, where the relationship between users is captured by an underlying graph and user preferences are represented as smooth signals on the  graph. We introduce a novel bandit algorithm where the smoothness prior is imposed via the random-walk graph Laplacian, which leads to a single-user cumulative regret scaling as $\\Tilde{\\mathcal{O}}(\\Psi d \\sqrt{T})$ with time horizon $T$, feature dimensionality $d$, and the scalar parameter $\\Psi \\in (0,1)$ that depends on the graph connectivity. This is an improvement over $\\Tilde{\\mathcal{O}}(d \\sqrt{T})$ in \\algo{LinUCB}\u00a0\\Ccite{li2010contextual}, where user relationship is not taken into account.In terms of network regret (sum of cumulative regret over $n$ users), the proposed algorithm leads to a scaling as $\\Tilde{\\mathcal{O}}(\\Psi d\\sqrt{nT})$, which is a significant improvement over $\\Tilde{\\mathcal{O}}(nd\\sqrt{T})$ in the state-of-the-art algorithm \\algo{Gob.Lin} \\Ccite{cesa2013gang}. To improve scalability, we further propose a simplified algorithm with a linear computational complexity with respect to the number of users, while maintaining the same regret. Finally, we present a finite-time analysis on the proposed algorithms, and demonstrate their advantage in comparison with state-of-the-art graph-based bandit algorithms on both synthetic and real-world data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yang20c/yang20c.pdf",
        "supp": "",
        "pdf_size": 765891,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12956143278333653418&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6dc0f8ade2",
        "title": "LdSM: Logarithm-depth Streaming Multi-label Decision Trees",
        "site": "https://proceedings.mlr.press/v108/majzoubi20a.html",
        "author": "Maryam Majzoubi; Anna Choromanska",
        "abstract": "We consider multi-label classification where the goal is to annotate each data point with the most relevant subset of labels from an extremely large label set. Efficient annotation can be achieved with balanced tree predictors, i.e. trees with logarithmic-depth in the label complexity, whose leaves correspond to labels. Designing prediction mechanism with such trees for real data applications is non-trivial as it needs to accommodate sending examples to multiple leaves while at the same time sustain high prediction accuracy. In this paper we develop the LdSM algorithm for the construction and training of multi-label decision trees, where in every node of the tree we optimize a novel objective function that favors balanced splits, maintains high class purity of children nodes, and allows sending examples to multiple directions but with a penalty that prevents tree over-growth. Each node of the tree is trained once the previous node is completed leading to a streaming approach for training. We analyze the proposed objective theoretically and show that minimizing it leads to pure and balanced data splits. Furthermore, we show a boosting theorem that captures its connection to the multi-label classification error. Experimental results  on benchmark data sets demonstrate that our approach achieves high prediction accuracy and low prediction time and position LdSM as a competitive tool among existing state-of-the-art approaches.",
        "bibtex": "@InProceedings{pmlr-v108-majzoubi20a,\n  title = \t {LdSM: Logarithm-depth Streaming Multi-label Decision Trees},\n  author =       {Majzoubi, Maryam and Choromanska, Anna},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4247--4257},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/majzoubi20a/majzoubi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/majzoubi20a.html},\n  abstract = \t { We consider multi-label classification where the goal is to annotate each data point with the most relevant subset of labels from an extremely large label set. Efficient annotation can be achieved with balanced tree predictors, i.e. trees with logarithmic-depth in the label complexity, whose leaves correspond to labels. Designing prediction mechanism with such trees for real data applications is non-trivial as it needs to accommodate sending examples to multiple leaves while at the same time sustain high prediction accuracy. In this paper we develop the LdSM algorithm for the construction and training of multi-label decision trees, where in every node of the tree we optimize a novel objective function that favors balanced splits, maintains high class purity of children nodes, and allows sending examples to multiple directions but with a penalty that prevents tree over-growth. Each node of the tree is trained once the previous node is completed leading to a streaming approach for training. We analyze the proposed objective theoretically and show that minimizing it leads to pure and balanced data splits. Furthermore, we show a boosting theorem that captures its connection to the multi-label classification error. Experimental results  on benchmark data sets demonstrate that our approach achieves high prediction accuracy and low prediction time and position LdSM as a competitive tool among existing state-of-the-art approaches. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/majzoubi20a/majzoubi20a.pdf",
        "supp": "",
        "pdf_size": 358733,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6173739229413459153&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "New York University; New York University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ab5837d996",
        "title": "Learnable Bernoulli Dropout for Bayesian Deep Learning",
        "site": "https://proceedings.mlr.press/v108/boluki20a.html",
        "author": "Shahin Boluki; Randy Ardywibowo; Siamak Zamani Dadaneh; Mingyuan Zhou; Xiaoning Qian",
        "abstract": "In this work, we propose learnable Bernoulli dropout (LBD), a new model-agnostic dropout scheme that considers the dropout rates as parameters jointly optimized with other model parameters. By probabilistic modeling of Bernoulli dropout, our method enables more robust prediction and uncertainty quantification in deep models. Especially, when combined with variational auto-encoders (VAEs), LBD enables flexible semi-implicit posterior representations, leading to new semi-implicit VAE (SIVAE) models. We solve the optimization for training with respect to the dropout parameters using Augment-REINFORCE-Merge (ARM), an unbiased and low-variance gradient estimator. Our experiments on a range of tasks show the superior performance of our approach compared with other commonly used dropout schemes. Overall, LBD leads to improved accuracy and uncertainty estimates in image classification and semantic segmentation. Moreover, using SIVAE, we can achieve state-of-the-art performance on collaborative filtering for implicit feedback on several public datasets.",
        "bibtex": "@InProceedings{pmlr-v108-boluki20a,\n  title = \t {Learnable Bernoulli Dropout for Bayesian Deep Learning},\n  author =       {Boluki, Shahin and Ardywibowo, Randy and Dadaneh, Siamak Zamani and Zhou, Mingyuan and Qian, Xiaoning},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3905--3916},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/boluki20a/boluki20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/boluki20a.html},\n  abstract = \t {In this work, we propose learnable Bernoulli dropout (LBD), a new model-agnostic dropout scheme that considers the dropout rates as parameters jointly optimized with other model parameters. By probabilistic modeling of Bernoulli dropout, our method enables more robust prediction and uncertainty quantification in deep models. Especially, when combined with variational auto-encoders (VAEs), LBD enables flexible semi-implicit posterior representations, leading to new semi-implicit VAE (SIVAE) models. We solve the optimization for training with respect to the dropout parameters using Augment-REINFORCE-Merge (ARM), an unbiased and low-variance gradient estimator. Our experiments on a range of tasks show the superior performance of our approach compared with other commonly used dropout schemes. Overall, LBD leads to improved accuracy and uncertainty estimates in image classification and semantic segmentation. Moreover, using SIVAE, we can achieve state-of-the-art performance on collaborative filtering for implicit feedback on several public datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/boluki20a/boluki20a.pdf",
        "supp": "",
        "pdf_size": 1158453,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9031172771203563893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Texas A&M University; Texas A&M University; Texas A&M University; The University of Texas at Austin; Texas A&M University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Texas A&M University;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tamu.edu;https://www.utexas.edu",
        "aff_unique_abbr": "TAMU;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a28b90e988",
        "title": "Learning Dynamic Hierarchical Topic Graph with Graph Convolutional Network for Document Classification",
        "site": "https://proceedings.mlr.press/v108/wang20l.html",
        "author": "Zhengjue Wang; Chaojie Wang; Hao Zhang; Zhibin Duan; Mingyuan Zhou; Bo Chen",
        "abstract": "Constructing a graph with graph convolutional network (GCN)  to explore the relational structure of the data has attracted lots of interests in various tasks. However, for document classification, existing graph based methods often focus on the straightforward word-word and word-document relations, ignoring the hierarchical semantics. Besides, the graph construction is often independent from the task-specific GCN learning. To address these constrains, we integrate a probabilistic deep topic model into graph construction, and propose a novel trainable hierarchical topic graph (HTG), including word-level, hierarchical topic-level and document-level nodes, exhibiting semantic variation from fine-grained to coarse. Regarding the document classification as a document-node label generation task, HTG can be dynamically evolved with GCN by performing variational inference, which leads to an end-to-end document classification method, named dynamic HTG (DHTG). Besides achieving state-of-the-art classification results, our model learns an interpretable document graph with meaningful node embeddings and semantic edges.",
        "bibtex": "@InProceedings{pmlr-v108-wang20l,\n  title = \t {Learning Dynamic Hierarchical Topic Graph with Graph Convolutional Network for Document Classification},\n  author =       {Wang, Zhengjue and Wang, Chaojie and Zhang, Hao and Duan, Zhibin and Zhou, Mingyuan and Chen, Bo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3959--3969},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20l/wang20l.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20l.html},\n  abstract = \t {Constructing a graph with graph convolutional network (GCN)  to explore the relational structure of the data has attracted lots of interests in various tasks. However, for document classification, existing graph based methods often focus on the straightforward word-word and word-document relations, ignoring the hierarchical semantics. Besides, the graph construction is often independent from the task-specific GCN learning. To address these constrains, we integrate a probabilistic deep topic model into graph construction, and propose a novel trainable hierarchical topic graph (HTG), including word-level, hierarchical topic-level and document-level nodes, exhibiting semantic variation from fine-grained to coarse. Regarding the document classification as a document-node label generation task, HTG can be dynamically evolved with GCN by performing variational inference, which leads to an end-to-end document classification method, named dynamic HTG (DHTG). Besides achieving state-of-the-art classification results, our model learns an interpretable document graph with meaningful node embeddings and semantic edges.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20l/wang20l.pdf",
        "supp": "",
        "pdf_size": 1423815,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5650363017786179935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "National Laboratory of Radar Signal Processing, Xidian University, Xi\u2019an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi\u2019an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi\u2019an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi\u2019an, China; McCombs School of Business The University of Texas at Austin, Austin, TX 78712, USA; National Laboratory of Radar Signal Processing, Xidian University, Xi\u2019an, China",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Xidian University;University of Texas at Austin",
        "aff_unique_dep": "National Laboratory of Radar Signal Processing;McCombs School of Business",
        "aff_unique_url": "http://www.xidian.edu.cn/;https://www.mccombs.utexas.edu",
        "aff_unique_abbr": "Xidian;UT Austin",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Xi'an;Austin",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "ff29bd0231",
        "title": "Learning Dynamic and Personalized Comorbidity Networks from Event Data using Deep Diffusion Processes",
        "site": "https://proceedings.mlr.press/v108/qian20a.html",
        "author": "Zhaozhi Qian; Ahmed Alaa; Alexis Bellot; Mihaela Schaar; Jem Rashbass",
        "abstract": "Comorbid diseases co-occur and progress via complex temporal patterns that vary among individuals. In electronic medical records, we only observe onsets of diseases, but not their triggering comorbidities \u2014 i.e., the mechanisms underlying temporal relations between diseases need to be inferred. Learning such temporal patterns from event data is crucial for understanding disease pathology and predicting prognoses. To this end, we develop deep diffusion processes (DDP) to model \u2019dynamic comorbidity networks\u2019, i.e., the temporal relationships between comorbid disease onsets expressed through a dynamic graph. A DDP comprises events modelled as a multi-dimensional point process, with an intensity function parameterized by the edges of a dynamic weighted graph. The graph structure is modulated by a neural network that maps patient history to edge weights, enabling rich temporal representations for disease trajectories. The DDP parameters decouple into clinically meaningful components, which enables serving the dual purpose of accurate risk prediction and intelligible representation of disease pathology. We illustrate these features in experiments using cancer registry data.",
        "bibtex": "@InProceedings{pmlr-v108-qian20a,\n  title = \t {Learning Dynamic and Personalized Comorbidity Networks from Event Data using Deep Diffusion Processes},\n  author =       {Qian, Zhaozhi and Alaa, Ahmed and Bellot, Alexis and van der Schaar, Mihaela and Rashbass, Jem},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3295--3305},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/qian20a/qian20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/qian20a.html},\n  abstract = \t {Comorbid diseases co-occur and progress via complex temporal patterns that vary among individuals. In electronic medical records, we only observe onsets of diseases, but not their triggering comorbidities \u2014 i.e., the mechanisms underlying temporal relations between diseases need to be inferred. Learning such temporal patterns from event data is crucial for understanding disease pathology and predicting prognoses. To this end, we develop deep diffusion processes (DDP) to model \u2019dynamic comorbidity networks\u2019, i.e., the temporal relationships between comorbid disease onsets expressed through a dynamic graph. A DDP comprises events modelled as a multi-dimensional point process, with an intensity function parameterized by the edges of a dynamic weighted graph. The graph structure is modulated by a neural network that maps patient history to edge weights, enabling rich temporal representations for disease trajectories. The DDP parameters decouple into clinically meaningful components, which enables serving the dual purpose of accurate risk prediction and intelligible representation of disease pathology. We illustrate these features in experiments using cancer registry data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/qian20a/qian20a.pdf",
        "supp": "",
        "pdf_size": 2824870,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15637526415963166973&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Cambridge; UCLA; University of Cambridge; NHS Digital + Public Health England; University of Cambridge + UCLA + The Alan Turing Institute",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2+3;0+1+4",
        "aff_unique_norm": "University of Cambridge;University of California, Los Angeles;NHS Digital;Public Health England;Alan Turing Institute",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.ucla.edu;https://www.nhs.uk;https://www.gov.uk/public-health-england;https://www.turing.ac.uk",
        "aff_unique_abbr": "Cambridge;UCLA;NHS Digital;PHE;ATI",
        "aff_campus_unique_index": "0;1;0;;0+1",
        "aff_campus_unique": "Cambridge;Los Angeles;",
        "aff_country_unique_index": "0;1;0;0+0;0+1+0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "eed519b0fe",
        "title": "Learning Entangled Single-Sample Distributions via Iterative Trimming",
        "site": "https://proceedings.mlr.press/v108/yuan20a.html",
        "author": "Hui Yuan; Yingyu Liang",
        "abstract": "In the setting of entangled single-sample distributions, the goal is to estimate some common parameter shared by a family of distributions, given one \\emph{single} sample from each distribution. We study mean estimation and linear regression under general conditions, and analyze a simple and computationally efficient method based on iteratively trimming samples and re-estimating the parameter on the trimmed sample set. We show that the method in logarithmic iterations outputs an estimation whose error only depends on the noise level of the $\\lceil \\alpha n \\rceil$-th noisiest data point where $\\alpha$ is a constant and $n$ is the sample size. This means it can tolerate a constant fraction of high-noise points. These are the first such results under our general conditions with computationally efficient estimators. It also justifies the wide application and empirical success of iterative trimming in practice. Our theoretical results are complemented by experiments on synthetic data.",
        "bibtex": "@InProceedings{pmlr-v108-yuan20a,\n  title = \t {Learning Entangled Single-Sample Distributions via Iterative Trimming},\n  author =       {Yuan, Hui and Liang, Yingyu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2666--2676},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yuan20a/yuan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yuan20a.html},\n  abstract = \t {In the setting of entangled single-sample distributions, the goal is to estimate some common parameter shared by a family of distributions, given one \\emph{single} sample from each distribution. We study mean estimation and linear regression under general conditions, and analyze a simple and computationally efficient method based on iteratively trimming samples and re-estimating the parameter on the trimmed sample set. We show that the method in logarithmic iterations outputs an estimation whose error only depends on the noise level of the $\\lceil \\alpha n \\rceil$-th noisiest data point where $\\alpha$ is a constant and $n$ is the sample size. This means it can tolerate a constant fraction of high-noise points. These are the first such results under our general conditions with computationally efficient estimators. It also justifies the wide application and empirical success of iterative trimming in practice. Our theoretical results are complemented by experiments on synthetic data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yuan20a/yuan20a.pdf",
        "supp": "",
        "pdf_size": 316728,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6648672384364943384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics and Finance, University of Science and Technology of China; Department of Computer Sciences, University of Wisconsin-Madison",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Science and Technology of China;University of Wisconsin-Madison",
        "aff_unique_dep": "Department of Statistics and Finance;Department of Computer Sciences",
        "aff_unique_url": "http://www.ustc.edu.cn;https://www.wisc.edu",
        "aff_unique_abbr": "USTC;UW-Madison",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Madison",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "3dbccee246",
        "title": "Learning Fair Representations for Kernel Models",
        "site": "https://proceedings.mlr.press/v108/tan20a.html",
        "author": "Zilong Tan; Samuel Yeom; Matt Fredrikson; Ameet Talwalkar",
        "abstract": "Fair representations are a powerful tool for establishing criteria like statistical parity, proxy non-discrimination, and equality of opportunity in learned models. Existing techniques for learning these representations are typically model-agnostic, as they preprocess the original data such that the output satisfies some fairness criterion, and can be used with arbitrary learning methods. In contrast, we demonstrate the promise of learning a model-aware fair representation, focusing on kernel-based models. We leverage the classical Sufficient Dimension Reduction (SDR) framework to construct representations as subspaces of the reproducing kernel Hilbert space (RKHS), whose member functions are guaranteed to satisfy fairness. Our method supports several fairness criteria,  continuous and discrete data, and multiple protected attributes.  We further show how to calibrate the accuracy tradeoff by characterizing it in terms of the principal angles between subspaces of the RKHS. Finally, we apply our approach to obtain the first Fair Gaussian Process (FGP) prior for fair Bayesian learning, and show that it is competitive with, and in some cases outperforms, state-of-the-art methods on real data.",
        "bibtex": "@InProceedings{pmlr-v108-tan20a,\n  title = \t {Learning Fair Representations for Kernel Models},\n  author =       {Tan, Zilong and Yeom, Samuel and Fredrikson, Matt and Talwalkar, Ameet},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {155--166},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tan20a/tan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tan20a.html},\n  abstract = \t {Fair representations are a powerful tool for establishing criteria like statistical parity, proxy non-discrimination, and equality of opportunity in learned models. Existing techniques for learning these representations are typically model-agnostic, as they preprocess the original data such that the output satisfies some fairness criterion, and can be used with arbitrary learning methods. In contrast, we demonstrate the promise of learning a model-aware fair representation, focusing on kernel-based models. We leverage the classical Sufficient Dimension Reduction (SDR) framework to construct representations as subspaces of the reproducing kernel Hilbert space (RKHS), whose member functions are guaranteed to satisfy fairness. Our method supports several fairness criteria,  continuous and discrete data, and multiple protected attributes.  We further show how to calibrate the accuracy tradeoff by characterizing it in terms of the principal angles between subspaces of the RKHS. Finally, we apply our approach to obtain the first Fair Gaussian Process (FGP) prior for fair Bayesian learning, and show that it is competitive with, and in some cases outperforms, state-of-the-art methods on real data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tan20a/tan20a.pdf",
        "supp": "",
        "pdf_size": 417794,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11588536623991296692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University + Determined AI; Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu;cs.cmu.edu;cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu;cs.cmu.edu;cmu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0",
        "aff_unique_norm": "Carnegie Mellon University;Determined AI",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://determined.ai",
        "aff_unique_abbr": "CMU;Determined AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "be3af7b004",
        "title": "Learning Gaussian Graphical Models via Multiplicative Weights",
        "site": "https://proceedings.mlr.press/v108/chaturvedi20a.html",
        "author": "Anamay Chaturvedi; Jonathan Scarlett",
        "abstract": "Graphical model selection in Markov random fields is a fundamental problem in statistics and machine learning.  Two particularly prominent models, the Ising model and Gaussian model, have largely developed in parallel using different (though often related) techniques, and several practical algorithms with rigorous sample complexity bounds have been established for each.  In this paper, we adapt a recently proposed algorithm of Klivans and Meka (FOCS, 2017), based on the method of multiplicative weight updates, from the Ising model to the Gaussian model, via non-trivial modifications to both the algorithm and its analysis.  The algorithm enjoys a sample complexity bound that is qualitatively similar to others in the literature, has a low runtime $O(mp^2)$ in the case of $m$ samples and $p$ nodes, and can trivially be implemented in an online manner.",
        "bibtex": "@InProceedings{pmlr-v108-chaturvedi20a,\n  title = \t {Learning Gaussian Graphical Models via Multiplicative Weights},\n  author =       {Chaturvedi, Anamay and Scarlett, Jonathan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1104--1114},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chaturvedi20a/chaturvedi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chaturvedi20a.html},\n  abstract = \t {Graphical model selection in Markov random fields is a fundamental problem in statistics and machine learning.  Two particularly prominent models, the Ising model and Gaussian model, have largely developed in parallel using different (though often related) techniques, and several practical algorithms with rigorous sample complexity bounds have been established for each.  In this paper, we adapt a recently proposed algorithm of Klivans and Meka (FOCS, 2017), based on the method of multiplicative weight updates, from the Ising model to the Gaussian model, via non-trivial modifications to both the algorithm and its analysis.  The algorithm enjoys a sample complexity bound that is qualitatively similar to others in the literature, has a low runtime $O(mp^2)$ in the case of $m$ samples and $p$ nodes, and can trivially be implemented in an online manner.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chaturvedi20a/chaturvedi20a.pdf",
        "supp": "",
        "pdf_size": 384516,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8592407383132525915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Khoury College of Computer Sciences, Northeastern University; Depts. Computer Science & Mathematics, National University of Singapore",
        "aff_domain": "northeastern.edu;comp.nus.edu.sg",
        "email": "northeastern.edu;comp.nus.edu.sg",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Northeastern University;National University of Singapore",
        "aff_unique_dep": "Khoury College of Computer Sciences;Department of Computer Science & Mathematics",
        "aff_unique_url": "https://www.northeastern.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "NU;NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "ef177bb9b2",
        "title": "Learning Hierarchical Interactions at Scale: A Convex Optimization Approach",
        "site": "https://proceedings.mlr.press/v108/hazimeh20a.html",
        "author": "Hussein Hazimeh; Rahul Mazumder",
        "abstract": "In many learning settings, it is beneficial to augment the main features with pairwise interactions. Such interaction models can be often enhanced by performing variable selection under the so-called strong hierarchy constraint: an interaction is non-zero only if its associated main features are non-zero. Existing convex optimization-based algorithms face difficulties in handling problems where the number of main features p \u00a0 10^3 (with total number of features \u00a0 p^2). In this paper, we study a convex relaxation which enforces strong hierarchy and develop a highly scalable algorithm based on proximal gradient descent. We introduce novel screening rules that allow for solving the complicated proximal problem in parallel. In addition, we introduce a specialized active-set strategy with gradient screening for avoiding costly gradient computations. The framework can handle problems having dense design matrices, with p = 50,000 (\u00a0 10^9 interactions)\u2014instances that are much larger than the state of the art. Experiments on real and synthetic data suggest that our toolkit hierScale outperforms the state of the art in terms of prediction and variable selection and can achieve over a 4900x speed-up.",
        "bibtex": "@InProceedings{pmlr-v108-hazimeh20a,\n  title = \t {Learning Hierarchical Interactions at Scale: A Convex Optimization Approach},\n  author =       {Hazimeh, Hussein and Mazumder, Rahul},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1833--1843},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hazimeh20a/hazimeh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hazimeh20a.html},\n  abstract = \t {In many learning settings, it is beneficial to augment the main features with pairwise interactions. Such interaction models can be often enhanced by performing variable selection under the so-called strong hierarchy constraint: an interaction is non-zero only if its associated main features are non-zero. Existing convex optimization-based algorithms face difficulties in handling problems where the number of main features p \u00a0 10^3 (with total number of features \u00a0 p^2). In this paper, we study a convex relaxation which enforces strong hierarchy and develop a highly scalable algorithm based on proximal gradient descent. We introduce novel screening rules that allow for solving the complicated proximal problem in parallel. In addition, we introduce a specialized active-set strategy with gradient screening for avoiding costly gradient computations. The framework can handle problems having dense design matrices, with p = 50,000 (\u00a0 10^9 interactions)\u2014instances that are much larger than the state of the art. Experiments on real and synthetic data suggest that our toolkit hierScale outperforms the state of the art in terms of prediction and variable selection and can achieve over a 4900x speed-up.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hazimeh20a/hazimeh20a.pdf",
        "supp": "",
        "pdf_size": 501389,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4367581985916125574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "647e0b6419",
        "title": "Learning High-dimensional Gaussian Graphical Models under Total Positivity without Adjustment of Tuning Parameters",
        "site": "https://proceedings.mlr.press/v108/wang20g.html",
        "author": "Yuhao Wang; Uma Roy; Caroline Uhler",
        "abstract": "We consider the problem of estimating an undirected Gaussian graphical model when the underlying distribution is multivariate totally positive of order 2 (MTP2), a strong form of positive dependence. Such distributions are relevant for example for portfolio selection, since assets are usually positively dependent. A large body of methods have been proposed for learning undirected graphical models without the MTP2 constraint. A major limitation of these methods is that their structure recovery guarantees in the high-dimensional setting usually require a particular choice of a tuning parameter, which is unknown a priori in real world applications. We here propose a new method to estimate the underlying undirected graphical model under MTP2 and show that it is provably consistent in structure recovery without adjusting the tuning parameters. This is achieved by a constraint-based estimator that infers the structure of the underlying graphical model by testing the signs of the empirical partial correlation coefficients. We evaluate the performance of our estimator in simulations and on financial data.",
        "bibtex": "@InProceedings{pmlr-v108-wang20g,\n  title = \t {Learning High-dimensional Gaussian Graphical Models under Total Positivity without Adjustment of Tuning Parameters},\n  author =       {Wang, Yuhao and Roy, Uma and Uhler, Caroline},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2698--2708},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20g/wang20g.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20g.html},\n  abstract = \t {We consider the problem of estimating an undirected Gaussian graphical model when the underlying distribution is multivariate totally positive of order 2 (MTP2), a strong form of positive dependence. Such distributions are relevant for example for portfolio selection, since assets are usually positively dependent. A large body of methods have been proposed for learning undirected graphical models without the MTP2 constraint. A major limitation of these methods is that their structure recovery guarantees in the high-dimensional setting usually require a particular choice of a tuning parameter, which is unknown a priori in real world applications. We here propose a new method to estimate the underlying undirected graphical model under MTP2 and show that it is provably consistent in structure recovery without adjusting the tuning parameters. This is achieved by a constraint-based estimator that infers the structure of the underlying graphical model by testing the signs of the empirical partial correlation coefficients. We evaluate the performance of our estimator in simulations and on financial data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20g/wang20g.pdf",
        "supp": "",
        "pdf_size": 754031,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11896891377767305090&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Cambridge; Google Research + Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "cam.ac.uk;gmail.com;mit.edu",
        "email": "cam.ac.uk;gmail.com;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;2",
        "aff_unique_norm": "University of Cambridge;Google;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Google Research;",
        "aff_unique_url": "https://www.cam.ac.uk;https://research.google;https://web.mit.edu",
        "aff_unique_abbr": "Cambridge;Google Research;MIT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Cambridge;Mountain View;",
        "aff_country_unique_index": "0;1+1;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "1748830b76",
        "title": "Learning Ising and Potts Models with Latent Variables",
        "site": "https://proceedings.mlr.press/v108/goel20a.html",
        "author": "Surbhi Goel",
        "abstract": "We study the problem of learning graphical models with latent variables. We give the {\\em first} efficient algorithms for learning: 1) ferromagnetic Ising models with latent variables under {\\em arbitrary} external fields, and 2) ferromagnetic Potts model with latent variables under unidirectional non-negative external field. Our algorithms have optimal dependence on the dimension but suffer from a sub-optimal dependence on the underlying sparsity of the graph.Our results rely on two structural properties of the underlying graphical models. These in turn allow us to design an influence function which can be maximized greedily to recover the structure of the underlying graphical model. These structural results may be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v108-goel20a,\n  title = \t {Learning Ising and Potts Models with Latent Variables},\n  author =       {Goel, Surbhi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3557--3566},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/goel20a/goel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/goel20a.html},\n  abstract = \t {We study the problem of learning graphical models with latent variables. We give the {\\em first} efficient algorithms for learning: 1) ferromagnetic Ising models with latent variables under {\\em arbitrary} external fields, and 2) ferromagnetic Potts model with latent variables under unidirectional non-negative external field. Our algorithms have optimal dependence on the dimension but suffer from a sub-optimal dependence on the underlying sparsity of the graph.Our results rely on two structural properties of the underlying graphical models. These in turn allow us to design an influence function which can be maximized greedily to recover the structure of the underlying graphical model. These structural results may be of independent interest.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/goel20a/goel20a.pdf",
        "supp": "",
        "pdf_size": 219381,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14712823407622633945&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "The University of Texas at Austin",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0ed6dd4886",
        "title": "Learning Overlapping Representations for the Estimation of Individualized Treatment Effects",
        "site": "https://proceedings.mlr.press/v108/zhang20c.html",
        "author": "Yao Zhang; Alexis Bellot; Mihaela Schaar",
        "abstract": "The choice of making an intervention depends on its potential benefit or harm in comparison to alternatives. Estimating the likely outcome of alternatives from observational data is a challenging problem as all outcomes are never observed, and selection bias precludes the direct comparison of differently intervened groups. Despite their empirical success, we show that algorithms that learn domain-invariant representations of inputs (on which to make predictions) are often inappropriate, and develop generalization bounds that demonstrate the dependence on domain overlap and highlight the need for invertible latent maps. Based on these results, we develop a deep kernel regression algorithm and posterior regularization framework that substantially outperforms the state-of-the-art on a variety of benchmarks data sets.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20c,\n  title = \t {Learning Overlapping Representations for the Estimation of Individualized Treatment Effects},\n  author =       {Zhang, Yao and Bellot, Alexis and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1005--1014},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20c/zhang20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20c.html},\n  abstract = \t {The choice of making an intervention depends on its potential benefit or harm in comparison to alternatives. Estimating the likely outcome of alternatives from observational data is a challenging problem as all outcomes are never observed, and selection bias precludes the direct comparison of differently intervened groups. Despite their empirical success, we show that algorithms that learn domain-invariant representations of inputs (on which to make predictions) are often inappropriate, and develop generalization bounds that demonstrate the dependence on domain overlap and highlight the need for invertible latent maps. Based on these results, we develop a deep kernel regression algorithm and posterior regularization framework that substantially outperforms the state-of-the-art on a variety of benchmarks data sets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20c/zhang20c.pdf",
        "supp": "",
        "pdf_size": 1964570,
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11231829386250497511&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Cambridge; University of Cambridge; University of Cambridge + The Alan Turing Institute + UCLA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1+2",
        "aff_unique_norm": "University of Cambridge;Alan Turing Institute;University of California, Los Angeles",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.turing.ac.uk;https://www.ucla.edu",
        "aff_unique_abbr": "Cambridge;ATI;UCLA",
        "aff_campus_unique_index": "0;0;0+2",
        "aff_campus_unique": "Cambridge;;Los Angeles",
        "aff_country_unique_index": "0;0;0+0+1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "424d762a1d",
        "title": "Learning Rate Adaptation for Differentially Private Learning",
        "site": "https://proceedings.mlr.press/v108/koskela20a.html",
        "author": "Antti Koskela; Antti Honkela",
        "abstract": "Differentially private learning has recently emerged as the leading approach for privacy-preserving machine learning. Differential privacy can complicate learning procedures because each access to the data needs to be carefully designed and carries a privacy cost. For example, standard parameter tuning with a validation set cannot be easily applied. In this paper, we propose a differentially private algorithm for the adaptation of the learning rate for differentially private stochastic gradient descent (SGD) that avoids the need for validation set use. The idea for the adaptiveness comes from the technique of extrapolation in numerical analysis: to get an estimate for the error against the gradient flow we compare the result obtained by one full step and two half-steps. We prove the privacy of the method using the moments accountant mechanism. This allows us to compute tight privacy bounds. Empirically we show that our method is competitive with manually tuned commonly used optimisation methods for training deep neural networks and differentially private variational inference.",
        "bibtex": "@InProceedings{pmlr-v108-koskela20a,\n  title = \t {Learning Rate Adaptation for Differentially Private Learning},\n  author =       {Koskela, Antti and Honkela, Antti},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2465--2475},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/koskela20a/koskela20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/koskela20a.html},\n  abstract = \t {Differentially private learning has recently emerged as the leading approach for privacy-preserving machine learning. Differential privacy can complicate learning procedures because each access to the data needs to be carefully designed and carries a privacy cost. For example, standard parameter tuning with a validation set cannot be easily applied. In this paper, we propose a differentially private algorithm for the adaptation of the learning rate for differentially private stochastic gradient descent (SGD) that avoids the need for validation set use. The idea for the adaptiveness comes from the technique of extrapolation in numerical analysis: to get an estimate for the error against the gradient flow we compare the result obtained by one full step and two half-steps. We prove the privacy of the method using the moments accountant mechanism. This allows us to compute tight privacy bounds. Empirically we show that our method is competitive with manually tuned commonly used optimisation methods for training deep neural networks and differentially private variational inference.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/koskela20a/koskela20a.pdf",
        "supp": "",
        "pdf_size": 666715,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12890072592087413542&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "University of Helsinki; University of Helsinki",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Helsinki",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.helsinki.fi",
        "aff_unique_abbr": "UH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "edcd25104e",
        "title": "Learning Sparse Nonparametric DAGs",
        "site": "https://proceedings.mlr.press/v108/zheng20a.html",
        "author": "Xun Zheng; Chen Dan; Bryon Aragam; Pradeep Ravikumar; Eric Xing",
        "abstract": "We develop a framework for learning sparse nonparametric directed acyclic graphs (DAGs) from data. Our approach is based on a recent algebraic characterization of DAGs that led to the first fully continuous optimization for score-based learning of DAG models parametrized by a linear structural equation model (SEM). We extend this algebraic characterization to nonparametric SEM by leveraging nonparametric sparsity based on partial derivatives, resulting in a continuous optimization problem that can be applied to a variety of nonparametric and semiparametric models including GLMs, additive noise models, and index models as special cases. Unlike existing approaches that require specific modeling choices, loss functions, or algorithms, we present a completely general framework that can be applied to general nonlinear models (e.g. without additive noise), general differentiable loss functions, and generic black-box optimization routines.",
        "bibtex": "@InProceedings{pmlr-v108-zheng20a,\n  title = \t {Learning Sparse Nonparametric DAGs},\n  author =       {Zheng, Xun and Dan, Chen and Aragam, Bryon and Ravikumar, Pradeep and Xing, Eric},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3414--3425},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zheng20a/zheng20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zheng20a.html},\n  abstract = \t {We develop a framework for learning sparse nonparametric directed acyclic graphs (DAGs) from data. Our approach is based on a recent algebraic characterization of DAGs that led to the first fully continuous optimization for score-based learning of DAG models parametrized by a linear structural equation model (SEM). We extend this algebraic characterization to nonparametric SEM by leveraging nonparametric sparsity based on partial derivatives, resulting in a continuous optimization problem that can be applied to a variety of nonparametric and semiparametric models including GLMs, additive noise models, and index models as special cases. Unlike existing approaches that require specific modeling choices, loss functions, or algorithms, we present a completely general framework that can be applied to general nonlinear models (e.g. without additive noise), general differentiable loss functions, and generic black-box optimization routines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zheng20a/zheng20a.pdf",
        "supp": "",
        "pdf_size": 988915,
        "gs_citation": 343,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7302362084671044229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Carnegie Mellon University; Carnegie Mellon University; University of Chicago; Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/xunzheng/notears",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Chicago",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.uchicago.edu",
        "aff_unique_abbr": "CMU;UChicago",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c13af02967",
        "title": "Learning in Gated Neural Networks",
        "site": "https://proceedings.mlr.press/v108/makkuva20a.html",
        "author": "Ashok Makkuva; Sewoong Oh; Sreeram Kannan; Pramod Viswanath",
        "abstract": "Gating is a key feature in modern neural networks including LSTMs, GRUs and sparsely-gated deep neural networks. The backbone of such gated networks is a mixture-of-experts layer, where several experts make regression decisions and gating controls how to weigh the decisions in an input-dependent manner. Despite having such a prominent role in both modern and classical machine learning, very little is understood about parameter recovery of mixture-of-experts since gradient descent and EM algorithms are known to be stuck in local optima in such models.In this paper, we perform a careful analysis of the optimization landscape and show that with appropriately designed loss functions, gradient descent can indeed learn the parameters accurately. A key idea underpinning our results is the design of two {\\em distinct} loss functions, one for recovering the expert parameters and another for recovering the gating parameters. We demonstrate the first sample complexity results for parameter recovery in this model for any algorithm and demonstrate significant performance gains over standard loss functions in numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v108-makkuva20a,\n  title = \t {Learning in Gated Neural Networks},\n  author =       {Makkuva, Ashok and Oh, Sewoong and Kannan, Sreeram and Viswanath, Pramod},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3338--3348},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/makkuva20a/makkuva20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/makkuva20a.html},\n  abstract = \t {Gating is a key feature in modern neural networks including LSTMs, GRUs and sparsely-gated deep neural networks. The backbone of such gated networks is a mixture-of-experts layer, where several experts make regression decisions and gating controls how to weigh the decisions in an input-dependent manner. Despite having such a prominent role in both modern and classical machine learning, very little is understood about parameter recovery of mixture-of-experts since gradient descent and EM algorithms are known to be stuck in local optima in such models.In this paper, we perform a careful analysis of the optimization landscape and show that with appropriately designed loss functions, gradient descent can indeed learn the parameters accurately. A key idea underpinning our results is the design of two {\\em distinct} loss functions, one for recovering the expert parameters and another for recovering the gating parameters. We demonstrate the first sample complexity results for parameter recovery in this model for any algorithm and demonstrate significant performance gains over standard loss functions in numerical experiments. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/makkuva20a/makkuva20a.pdf",
        "supp": "",
        "pdf_size": 2560923,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9619319532195885024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "342f1b8317",
        "title": "Learning piecewise Lipschitz functions in changing environments",
        "site": "https://proceedings.mlr.press/v108/sharma20a.html",
        "author": "Dravyansh Sharma; Maria-Florina Balcan; Travis Dick",
        "abstract": "Optimization in the presence of sharp (non-Lipschitz), unpredictable (w.r.t. time and amount) changes is a challenging and largely unexplored problem of great significance. We consider the class of piecewise Lipschitz functions, which is the most general online setting considered in the literature for the problem, and arises naturally in various combinatorial algorithm selection problems where utility functions can have sharp discontinuities. The usual performance metric of \u2018static\u2019 regret minimizes the gap between the payoff accumulated and that of the best fixed point for the entire duration, and thus fails to capture changing environments. Shifting regret is a useful alternative, which allows for up to $s$ environment {\\it shifts}. In this work we provide an $O(\\sqrt{sdT\\log T}+sT^{1-\\beta})$ regret bound for $\\beta$-dispersed functions, where $\\beta$ roughly quantifies the rate at which discontinuities appear in the utility functions in expectation (typically $\\beta\\ge1/2$ in problems of practical interest \\cite{2019arXiv190409014B,balcan2018dispersion}). We also present a lower bound tight up to sub-logarithmic factors. We further obtain improved bounds when selecting from a small pool of experts. We empirically demonstrate a key application of our algorithms to online clustering problems on popular benchmarks.",
        "bibtex": "@InProceedings{pmlr-v108-sharma20a,\n  title = \t {Learning piecewise Lipschitz functions in changing environments},\n  author =       {Sharma, Dravyansh and Balcan, Maria-Florina and Dick, Travis},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3567--3577},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sharma20a/sharma20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sharma20a.html},\n  abstract = \t {Optimization in the presence of sharp (non-Lipschitz), unpredictable (w.r.t. time and amount) changes is a challenging and largely unexplored problem of great significance. We consider the class of piecewise Lipschitz functions, which is the most general online setting considered in the literature for the problem, and arises naturally in various combinatorial algorithm selection problems where utility functions can have sharp discontinuities. The usual performance metric of \u2018static\u2019 regret minimizes the gap between the payoff accumulated and that of the best fixed point for the entire duration, and thus fails to capture changing environments. Shifting regret is a useful alternative, which allows for up to $s$ environment {\\it shifts}. In this work we provide an $O(\\sqrt{sdT\\log T}+sT^{1-\\beta})$ regret bound for $\\beta$-dispersed functions, where $\\beta$ roughly quantifies the rate at which discontinuities appear in the utility functions in expectation (typically $\\beta\\ge1/2$ in problems of practical interest \\cite{2019arXiv190409014B,balcan2018dispersion}). We also present a lower bound tight up to sub-logarithmic factors. We further obtain improved bounds when selecting from a small pool of experts. We empirically demonstrate a key application of our algorithms to online clustering problems on popular benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sharma20a/sharma20a.pdf",
        "supp": "",
        "pdf_size": 733476,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11056419747725225499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9655ef0de3",
        "title": "Learning spectrograms with convolutional spectral kernels",
        "site": "https://proceedings.mlr.press/v108/shen20a.html",
        "author": "Zheyang Shen; Markus Heinonen; Samuel Kaski",
        "abstract": "We introduce the convolutional spectral kernel (CSK), a novel family of non-stationary, nonparametric covariance kernels for Gaussian process (GP) models, derived from the convolution between two imaginary radial basis functions. We present a principled framework to interpret CSK, as well as other deep probabilistic models, using approximated Fourier transform, yielding a concise representation of input-frequency spectrogram. Observing through the lens of the spectrogram, we provide insight on the interpretability of deep models. We then infer the functional hyperparameters using scalable variational and MCMC methods. On small- and medium-sized spatiotemporal datasets, we demonstrate improved generalization of GP models when equipped with CSK, and their capability to extract non-stationary periodic patterns.",
        "bibtex": "@InProceedings{pmlr-v108-shen20a,\n  title = \t {Learning spectrograms with convolutional spectral kernels},\n  author =       {Shen, Zheyang and Heinonen, Markus and Kaski, Samuel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3826--3836},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shen20a/shen20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shen20a.html},\n  abstract = \t {We introduce the convolutional spectral kernel (CSK), a novel family of non-stationary, nonparametric covariance kernels for Gaussian process (GP) models, derived from the convolution between two imaginary radial basis functions. We present a principled framework to interpret CSK, as well as other deep probabilistic models, using approximated Fourier transform, yielding a concise representation of input-frequency spectrogram. Observing through the lens of the spectrogram, we provide insight on the interpretability of deep models. We then infer the functional hyperparameters using scalable variational and MCMC methods. On small- and medium-sized spatiotemporal datasets, we demonstrate improved generalization of GP models when equipped with CSK, and their capability to extract non-stationary periodic patterns.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shen20a/shen20a.pdf",
        "supp": "",
        "pdf_size": 7518505,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5039109533458150484&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8fa3be99bb",
        "title": "Learning with minibatch Wasserstein  : asymptotic and gradient properties",
        "site": "https://proceedings.mlr.press/v108/fatras20a.html",
        "author": "Kilian Fatras; Younes Zine; R\u00e9mi Flamary; Remi Gribonval; Nicolas Courty",
        "abstract": "Optimal transport distances are powerful tools to compare probability distributions and have found many applications in machine learning. Yet their algorithmic complexity prevents their direct use on large scale datasets. To overcome this challenge, practitioners compute these distances on minibatches i.e., they average the outcome of several smaller optimal transport problems. We propose in this paper an analysis of this practice, which effects are not well understood so far. We notably argue that it is equivalent to an implicit regularization of the original problem, with appealing properties such as unbiased estimators, gradients and a concentration bound around the expectation, but also with defects such as loss of distance property. Along with this theoretical analysis, we also conduct empirical experiments on gradient flows, GANs or color transfer that highlight the practical interest of this strategy.",
        "bibtex": "@InProceedings{pmlr-v108-fatras20a,\n  title = \t {Learning with minibatch Wasserstein  : asymptotic and gradient properties},\n  author =       {Fatras, Kilian and Zine, Younes and Flamary, R\\'emi and Gribonval, Remi and Courty, Nicolas},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2131--2141},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fatras20a/fatras20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fatras20a.html},\n  abstract = \t {Optimal transport distances are powerful tools to compare probability distributions and have found many applications in machine learning. Yet their algorithmic complexity prevents their direct use on large scale datasets. To overcome this challenge, practitioners compute these distances on minibatches i.e., they average the outcome of several smaller optimal transport problems. We propose in this paper an analysis of this practice, which effects are not well understood so far. We notably argue that it is equivalent to an implicit regularization of the original problem, with appealing properties such as unbiased estimators, gradients and a concentration bound around the expectation, but also with defects such as loss of distance property. Along with this theoretical analysis, we also conduct empirical experiments on gradient flows, GANs or color transfer that highlight the practical interest of this strategy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fatras20a/fatras20a.pdf",
        "supp": "",
        "pdf_size": 7536227,
        "gs_citation": 107,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1361291129412662704&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Univ Bretagne Sud, Inria, CNRS, IRISA, France; Univ Rennes, Inria, CNRS, IRISA, France; Univ C \u02c6ote d\u2019Azur, OCA, UMR 7293, CNRS, Laboratoire Lagrange, France; Univ Lyon, Inria, CNRS, ENS de Lyon, UCB Lyon 1, LIP UMR 5668, F-69342, Lyon, France; Univ Bretagne Sud, Inria, CNRS, IRISA, France",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Bretagne Sud;University of Rennes;Univ C\u00f4te d\u2019Azur;University of Lyon",
        "aff_unique_dep": ";;Laboratoire Lagrange;",
        "aff_unique_url": "https://www.univ-ubs.fr;https://www.univ-rennes1.fr;https://www.univ-cotedazur.fr;https://www.universite-lyon.fr",
        "aff_unique_abbr": "UBS;Univ Rennes;;Univ Lyon",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Lyon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "b29723909c",
        "title": "Leave-One-Out Cross-Validation for Bayesian Model Comparison in Large Data",
        "site": "https://proceedings.mlr.press/v108/magnusson20a.html",
        "author": "M\u00e5ns Magnusson; Aki Vehtari; Johan Jonasson; Michael Andersen",
        "abstract": "Recently, new methods for model assessment, based on subsampling and posterior approximations, have been proposed for scaling leave-one-out cross-validation (LOO-CV) to large datasets. Although these methods work well for estimating predictive performance for individual models, they are less powerful in model comparison. We propose an efficient method for estimating differences in predictive performance by combining fast approximate LOO surrogates with exact LOO sub-sampling using the difference estimator and supply proofs with regards to scaling characteristics. The resulting approach can be orders of magnitude more efficient than previous approaches, as well as being better suited to model comparison.",
        "bibtex": "@InProceedings{pmlr-v108-magnusson20a,\n  title = \t {Leave-One-Out Cross-Validation for Bayesian Model Comparison in Large Data},\n  author =       {Magnusson, M{\\aa}ns and Vehtari, Aki and Jonasson, Johan and Andersen, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {341--351},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/magnusson20a/magnusson20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/magnusson20a.html},\n  abstract = \t {Recently, new methods for model assessment, based on subsampling and posterior approximations, have been proposed for scaling leave-one-out cross-validation (LOO-CV) to large datasets. Although these methods work well for estimating predictive performance for individual models, they are less powerful in model comparison. We propose an efficient method for estimating differences in predictive performance by combining fast approximate LOO surrogates with exact LOO sub-sampling using the difference estimator and supply proofs with regards to scaling characteristics. The resulting approach can be orders of magnitude more efficient than previous approaches, as well as being better suited to model comparison.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/magnusson20a/magnusson20a.pdf",
        "supp": "",
        "pdf_size": 311713,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=447735021681543347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6c35fc1e39",
        "title": "Linear Convergence of Adaptive Stochastic Gradient Descent",
        "site": "https://proceedings.mlr.press/v108/xie20a.html",
        "author": "Yuege Xie; Xiaoxia Wu; Rachel Ward",
        "abstract": "We prove that the norm version of the adaptive stochastic gradient method (AdaGrad-Norm) achieves a linear convergence rate for a subset of either strongly convex functions or non-convex functions that satisfy the Polyak Lojasiewicz (PL) inequality. The paper introduces the notion of Restricted Uniform Inequality of Gradients (RUIG)\u2014which is a measure of the balanced-ness of the stochastic gradient norms\u2014to depict the landscape of a function. RUIG plays a key role in proving the robustness of AdaGrad-Norm to its hyper-parameter tuning in the stochastic setting. On top of RUIG, we develop a two-stage framework to prove the linear convergence of AdaGrad-Norm without knowing the parameters of the objective functions. This framework can likely be extended to other adaptive stepsize algorithms. The numerical experiments validate the theory and suggest future directions for improvement.",
        "bibtex": "@InProceedings{pmlr-v108-xie20a,\n  title = \t {Linear Convergence of Adaptive Stochastic Gradient Descent},\n  author =       {Xie, Yuege and Wu, Xiaoxia and Ward, Rachel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1475--1485},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/xie20a/xie20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/xie20a.html},\n  abstract = \t {We prove that the norm version of the adaptive stochastic gradient method (AdaGrad-Norm) achieves a linear convergence rate for a subset of either strongly convex functions or non-convex functions that satisfy the Polyak Lojasiewicz (PL) inequality. The paper introduces the notion of Restricted Uniform Inequality of Gradients (RUIG)\u2014which is a measure of the balanced-ness of the stochastic gradient norms\u2014to depict the landscape of a function. RUIG plays a key role in proving the robustness of AdaGrad-Norm to its hyper-parameter tuning in the stochastic setting. On top of RUIG, we develop a two-stage framework to prove the linear convergence of AdaGrad-Norm without knowing the parameters of the objective functions. This framework can likely be extended to other adaptive stepsize algorithms. The numerical experiments validate the theory and suggest future directions for improvement.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/xie20a/xie20a.pdf",
        "supp": "",
        "pdf_size": 3554232,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9316528926711655685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c3d6f58857",
        "title": "Linear Dynamics: Clustering without identification",
        "site": "https://proceedings.mlr.press/v108/hsu20b.html",
        "author": "Chloe Hsu; Michaela Hardt; Moritz Hardt",
        "abstract": "Linear dynamical systems are a fundamental and powerful parametric model class. However, identifying the parameters of a linear dynamical system is a venerable task, permitting provably efficient solutions only in special cases. This work shows that the eigenspectrum of unknown linear dynamics can be identified without full system identification. We analyze a computationally efficient and provably convergent algorithm to estimate the eigenvalues of the state-transition matrix in a linear dynamical system.When applied to time series clustering, our algorithm can efficiently cluster multi-dimensional time series with temporal offsets and varying lengths, under the assumption that the time series are generated from linear dynamical systems. Evaluating our algorithm on both synthetic data and real electrocardiogram (ECG) signals, we see improvements in clustering quality over existing baselines.",
        "bibtex": "@InProceedings{pmlr-v108-hsu20b,\n  title = \t {Linear Dynamics: Clustering without identification},\n  author =       {Hsu, Chloe and Hardt, Michaela and Hardt, Moritz},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {918--929},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hsu20b/hsu20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hsu20b.html},\n  abstract = \t {Linear dynamical systems are a fundamental and powerful parametric model class. However, identifying the parameters of a linear dynamical system is a venerable task, permitting provably efficient solutions only in special cases. This work shows that the eigenspectrum of unknown linear dynamics can be identified without full system identification. We analyze a computationally efficient and provably convergent algorithm to estimate the eigenvalues of the state-transition matrix in a linear dynamical system.When applied to time series clustering, our algorithm can efficiently cluster multi-dimensional time series with temporal offsets and varying lengths, under the assumption that the time series are generated from linear dynamical systems. Evaluating our algorithm on both synthetic data and real electrocardiogram (ECG) signals, we see improvements in clustering quality over existing baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hsu20b/hsu20b.pdf",
        "supp": "",
        "pdf_size": 535366,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2388198834987158958&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of California, Berkeley; Amazon; University of California, Berkeley",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Amazon",
        "aff_unique_dep": ";Amazon.com, Inc.",
        "aff_unique_url": "https://www.berkeley.edu;https://www.amazon.com",
        "aff_unique_abbr": "UC Berkeley;Amazon",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "58a1394aa4",
        "title": "Linear predictor on linearly-generated data with missing values: non consistency and solutions",
        "site": "https://proceedings.mlr.press/v108/morvan20a.html",
        "author": "Marine Le Morvan; Nicolas Prost; Julie Josse; Erwan Scornet; Gael Varoquaux",
        "abstract": "We consider building predictors when the data have missing values. We study the seemingly-simple case where the target to predict is a linear function of the fully observed data and we show that, in the presence of missing values, the optimal predictor is not linear in general. In the particular Gaussian case, it can be written as a linear function of multiway interactions between the observed data and the various missing value indicators. Due to its intrinsic complexity, we study a simple approximation and prove generalization bounds with finite samples, highlighting regimes for which each method performs best. We then show that multilayer perceptrons with ReLU activation functions can be consistent, and can explore good trade-offs between the true model and approximations. Our study highlights the interesting family of models that are beneficial to fit with missing values depending on the amount of data available.",
        "bibtex": "@InProceedings{pmlr-v108-morvan20a,\n  title = \t {Linear predictor on linearly-generated data with missing values: non consistency and solutions},\n  author =       {Morvan, Marine Le and Prost, Nicolas and Josse, Julie and Scornet, Erwan and Varoquaux, Gael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3165--3174},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/morvan20a/morvan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/morvan20a.html},\n  abstract = \t {We consider building predictors when the data have missing values. We study the seemingly-simple case where the target to predict is a linear function of the fully observed data and we show that, in the presence of missing values, the optimal predictor is not linear in general. In the particular Gaussian case, it can be written as a linear function of multiway interactions between the observed data and the various missing value indicators. Due to its intrinsic complexity, we study a simple approximation and prove generalization bounds with finite samples, highlighting regimes for which each method performs best. We then show that multilayer perceptrons with ReLU activation functions can be consistent, and can explore good trade-offs between the true model and approximations. Our study highlights the interesting family of models that are beneficial to fit with missing values depending on the amount of data available.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/morvan20a/morvan20a.pdf",
        "supp": "",
        "pdf_size": 4227066,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13154293555830686629&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1886265de2",
        "title": "Linearly Convergent Frank-Wolfe with Backtracking Line-Search",
        "site": "https://proceedings.mlr.press/v108/pedregosa20a.html",
        "author": "Fabian Pedregosa; Geoffrey Negiar; Armin Askari; Martin Jaggi",
        "abstract": "Structured constraints in Machine Learning have recently brought the Frank-Wolfe (FW) family of algorithms back in the spotlight. While the classical FW algorithm has poor local convergence properties, the Away-steps and Pairwise FW variants have emerged as improved variants with faster convergence. However, these improved variants suffer from two practical limitations: they require at each iteration to solve a 1-dimensional minimization problem to set the step-size and also require the Frank-Wolfe linear subproblems to be solved exactly. In this paper we propose variants of Away-steps and Pairwise FW that lift both restrictions simultaneously. The proposed methods set the step-size based on a sufficient decrease condition, and do not require prior knowledge of the objective. Furthermore, they inherit all the favorable convergence properties of the exact line-search version, including linear convergence for strongly convex functions over polytopes. Benchmarks on different machine learning problems illustrate large performance gains of the proposed variants.",
        "bibtex": "@InProceedings{pmlr-v108-pedregosa20a,\n  title = \t {Linearly Convergent Frank-Wolfe with Backtracking Line-Search},\n  author =       {Pedregosa, Fabian and Negiar, Geoffrey and Askari, Armin and Jaggi, Martin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1--10},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pedregosa20a/pedregosa20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pedregosa20a.html},\n  abstract = \t {Structured constraints in Machine Learning have recently brought the Frank-Wolfe (FW) family of algorithms back in the spotlight. While the classical FW algorithm has poor local convergence properties, the Away-steps and Pairwise FW variants have emerged as improved variants with faster convergence. However, these improved variants suffer from two practical limitations: they require at each iteration to solve a 1-dimensional minimization problem to set the step-size and also require the Frank-Wolfe linear subproblems to be solved exactly. In this paper we propose variants of Away-steps and Pairwise FW that lift both restrictions simultaneously. The proposed methods set the step-size based on a sufficient decrease condition, and do not require prior knowledge of the objective. Furthermore, they inherit all the favorable convergence properties of the exact line-search version, including linear convergence for strongly convex functions over polytopes. Benchmarks on different machine learning problems illustrate large performance gains of the proposed variants.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pedregosa20a/pedregosa20a.pdf",
        "supp": "",
        "pdf_size": 793300,
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4552712882634589491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "26c099b2ad",
        "title": "Lipschitz Continuous Autoencoders in Application to Anomaly Detection",
        "site": "https://proceedings.mlr.press/v108/kim20c.html",
        "author": "Young-geun Kim; Yongchan Kwon; Hyunwoong Chang; Myunghee Cho Paik",
        "abstract": "Anomaly detection is the task of finding abnormal data that are distinct from normal behavior. Current deep learning-based anomaly detection methods train neural networks with normal data alone and calculate anomaly scores based on the trained model. In this work, we formalize current practices, build a theoretical framework of anomaly detection algorithms equipped with an objective function and a hypothesis space, and establish a desirable property of the anomaly detection algorithm, namely, admissibility. Admissibility implies that optimal autoencoders for normal data yield a larger reconstruction error for anomalous data than that for normal data on average. We then propose a class of admissible anomaly detection algorithms equipped with an integral probability metric-based objective function and a class of autoencoders, Lipschitz continuous autoencoders. The proposed algorithm for Wasserstein distance is implemented by minimizing an approximated Wasserstein distance with a penalty to enforce Lipschitz continuity with respect to Wasserstein distance. Through ablation studies, we demonstrate the efficacy of enforcing Lipschitz continuity of the proposed method. The proposed method is shown to be more effective in detecting anomalies than existing methods via applications to network traffic and image datasets.",
        "bibtex": "@InProceedings{pmlr-v108-kim20c,\n  title = \t {Lipschitz Continuous Autoencoders in Application to Anomaly Detection},\n  author =       {Kim, Young-geun and Kwon, Yongchan and Chang, Hyunwoong and Paik, Myunghee Cho},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2507--2517},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kim20c/kim20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kim20c.html},\n  abstract = \t {Anomaly detection is the task of finding abnormal data that are distinct from normal behavior. Current deep learning-based anomaly detection methods train neural networks with normal data alone and calculate anomaly scores based on the trained model. In this work, we formalize current practices, build a theoretical framework of anomaly detection algorithms equipped with an objective function and a hypothesis space, and establish a desirable property of the anomaly detection algorithm, namely, admissibility. Admissibility implies that optimal autoencoders for normal data yield a larger reconstruction error for anomalous data than that for normal data on average. We then propose a class of admissible anomaly detection algorithms equipped with an integral probability metric-based objective function and a class of autoencoders, Lipschitz continuous autoencoders. The proposed algorithm for Wasserstein distance is implemented by minimizing an approximated Wasserstein distance with a penalty to enforce Lipschitz continuity with respect to Wasserstein distance. Through ablation studies, we demonstrate the efficacy of enforcing Lipschitz continuity of the proposed method. The proposed method is shown to be more effective in detecting anomalies than existing methods via applications to network traffic and image datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kim20c/kim20c.pdf",
        "supp": "",
        "pdf_size": 228208,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3653362434433924031&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f4101c556c",
        "title": "Local Differential Privacy for Sampling",
        "site": "https://proceedings.mlr.press/v108/husain20a.html",
        "author": "Hisham Husain; Borja Balle; Zac Cranko; Richard Nock",
        "abstract": "Differential privacy (DP) is a leading privacy protection  focused by design on individual privacy. In the local model of DP, strong privacy is achieved by privatizing each user\u2019s individual data before sending it to an untrusted aggregator for analysis. While in recent years local DP has been adopted for practical deployments, most research in this area focuses on problems where each individual holds a single data record. In many problems of practical interest this assumption is unrealistic since nowadays most user-owned devices collect large quantities of data (e.g. pictures, text messages, time series). We propose to model this scenario by assuming each individual holds a distribution over the space of data records, and develop novel local DP methods to sample privately from these distributions. Our main contribution is a boosting-based density estimation algorithm for learning samplers that generate synthetic data while protecting the underlying distribution of each user with local DP. We give approximation guarantees quantifying how well these samplers approximate the true distribution. Experimental results against DP kernel density estimation and DP GANs displays the quality of our results.",
        "bibtex": "@InProceedings{pmlr-v108-husain20a,\n  title = \t {Local Differential Privacy for Sampling},\n  author =       {Husain, Hisham and Balle, Borja and Cranko, Zac and Nock, Richard},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3404--3413},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/husain20a/husain20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/husain20a.html},\n  abstract = \t {Differential privacy (DP) is a leading privacy protection  focused by design on individual privacy. In the local model of DP, strong privacy is achieved by privatizing each user\u2019s individual data before sending it to an untrusted aggregator for analysis. While in recent years local DP has been adopted for practical deployments, most research in this area focuses on problems where each individual holds a single data record. In many problems of practical interest this assumption is unrealistic since nowadays most user-owned devices collect large quantities of data (e.g. pictures, text messages, time series). We propose to model this scenario by assuming each individual holds a distribution over the space of data records, and develop novel local DP methods to sample privately from these distributions. Our main contribution is a boosting-based density estimation algorithm for learning samplers that generate synthetic data while protecting the underlying distribution of each user with local DP. We give approximation guarantees quantifying how well these samplers approximate the true distribution. Experimental results against DP kernel density estimation and DP GANs displays the quality of our results.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/husain20a/husain20a.pdf",
        "supp": "",
        "pdf_size": 3849452,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15580964034473113721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "da2513a24b",
        "title": "Locally Accelerated Conditional Gradients",
        "site": "https://proceedings.mlr.press/v108/diakonikolas20a.html",
        "author": "Jelena Diakonikolas; Alejandro Carderera; Sebastian Pokutta",
        "abstract": "Conditional gradients constitute a class of projection-free first-order algorithms for smooth convex optimization. As such, they are frequently used in solving smooth convex optimization problems over polytopes, for which the computational cost of projections is prohibitive. However, they do not enjoy the optimal convergence rates achieved by projection-based accelerated methods; moreover, achieving such globally-accelerated rates is information-theoretically impossible. To address this issue, we present Locally Accelerated Conditional Gradients \u2013 an algorithmic framework that couples accelerated steps with conditional gradient steps to achieve \\emph{local} acceleration on smooth strongly convex problems. Our approach does not require projections onto the feasible set, but only on (typically low-dimensional) simplices, thus keeping the computational cost of projections at bay. Further, it achieves optimal accelerated local convergence. Our theoretical results are supported by numerical experiments, which demonstrate significant speedups over state of the art methods in both per-iteration progress and wall-clock time.",
        "bibtex": "@InProceedings{pmlr-v108-diakonikolas20a,\n  title = \t {Locally Accelerated Conditional Gradients},\n  author =       {Diakonikolas, Jelena and Carderera, Alejandro and Pokutta, Sebastian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1737--1747},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/diakonikolas20a/diakonikolas20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/diakonikolas20a.html},\n  abstract = \t {Conditional gradients constitute a class of projection-free first-order algorithms for smooth convex optimization. As such, they are frequently used in solving smooth convex optimization problems over polytopes, for which the computational cost of projections is prohibitive. However, they do not enjoy the optimal convergence rates achieved by projection-based accelerated methods; moreover, achieving such globally-accelerated rates is information-theoretically impossible. To address this issue, we present Locally Accelerated Conditional Gradients \u2013 an algorithmic framework that couples accelerated steps with conditional gradient steps to achieve \\emph{local} acceleration on smooth strongly convex problems. Our approach does not require projections onto the feasible set, but only on (typically low-dimensional) simplices, thus keeping the computational cost of projections at bay. Further, it achieves optimal accelerated local convergence. Our theoretical results are supported by numerical experiments, which demonstrate significant speedups over state of the art methods in both per-iteration progress and wall-clock time. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/diakonikolas20a/diakonikolas20a.pdf",
        "supp": "",
        "pdf_size": 798677,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9388518501070594014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0a6939d8e5",
        "title": "Logistic regression with peer-group effects via inference in higher-order Ising models",
        "site": "https://proceedings.mlr.press/v108/daskalakis20a.html",
        "author": "Constantinos Daskalakis; Nishanth Dikkala; Ioannis Panageas",
        "abstract": "Spin glass models, such as the Sherrington-Kirkpatrick, Hopfield and Ising models, are all well-studied members of the exponential family of discrete distributions, and have been influential in a number of application domains where they are used to model correlation phenomena on networks. Conventionally these models have quadratic sufficient statistics and consequently capture correlations arising from pairwise interactions. In this work we study extensions of these models to models with higher-order sufficient statistics, modeling behavior on a social network with peer-group effects. In particular, we model binary outcomes on a network as a higher-order spin glass, where the behavior of an individual depends on a linear function of their own vector of covariates and some polynomial function of the behavior of others, capturing peer-group effects. Using a {\\em single}, high-dimensional sample from such model our goal is to recover the coefficients of the linear function as well as the strength of the peer-group effects. The heart of our result is a novel approach for showing strong concavity of the log pseudo-likelihood of the model, implying statistical error rate of $\\sqrt{d/n}$ for the Maximum Pseudo-Likelihood Estimator (MPLE), where $d$ is the dimensionality of the covariate vectors and $n$ is the size of the network (number of nodes). Our model generalizes vanilla logistic regression  as well as the models studied in recent works of \u00a0\\cite{chatterjee2007estimation,ghosal2018joint,DDP19}, and our results extend these results to accommodate higher-order interactions.",
        "bibtex": "@InProceedings{pmlr-v108-daskalakis20a,\n  title = \t {Logistic regression with peer-group effects via inference in higher-order Ising models},\n  author =       {Daskalakis, Constantinos and Dikkala, Nishanth and Panageas, Ioannis},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3653--3663},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/daskalakis20a/daskalakis20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/daskalakis20a.html},\n  abstract = \t {Spin glass models, such as the Sherrington-Kirkpatrick, Hopfield and Ising models, are all well-studied members of the exponential family of discrete distributions, and have been influential in a number of application domains where they are used to model correlation phenomena on networks. Conventionally these models have quadratic sufficient statistics and consequently capture correlations arising from pairwise interactions. In this work we study extensions of these models to models with higher-order sufficient statistics, modeling behavior on a social network with peer-group effects. In particular, we model binary outcomes on a network as a higher-order spin glass, where the behavior of an individual depends on a linear function of their own vector of covariates and some polynomial function of the behavior of others, capturing peer-group effects. Using a {\\em single}, high-dimensional sample from such model our goal is to recover the coefficients of the linear function as well as the strength of the peer-group effects. The heart of our result is a novel approach for showing strong concavity of the log pseudo-likelihood of the model, implying statistical error rate of $\\sqrt{d/n}$ for the Maximum Pseudo-Likelihood Estimator (MPLE), where $d$ is the dimensionality of the covariate vectors and $n$ is the size of the network (number of nodes). Our model generalizes vanilla logistic regression  as well as the models studied in recent works of \u00a0\\cite{chatterjee2007estimation,ghosal2018joint,DDP19}, and our results extend these results to accommodate higher-order interactions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/daskalakis20a/daskalakis20a.pdf",
        "supp": "",
        "pdf_size": 326512,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2137430043353524793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5d78f84277",
        "title": "Long-and Short-Term Forecasting for  Portfolio Selection with Transaction Costs",
        "site": "https://proceedings.mlr.press/v108/uziel20a.html",
        "author": "Guy Uziel; Ran El-Yaniv",
        "abstract": "In this paper we focus on the problem of online portfolio selection with transaction costs. We tackle this problem using a novel approach for combining the predictions of long-term experts with those of short-term experts so as\tto effectively reduce transaction costs.  We prove that the new strategy \tmaintains bounded regret relative to the performance of the best possible combination (switching times) of the long-and short-term experts.\tWe empirically validate our approach on several standard benchmark datasets.\tThese studies indicate that the proposed approach \tachieves state-of-the-art performance.",
        "bibtex": "@InProceedings{pmlr-v108-uziel20a,\n  title = \t {Long-and Short-Term Forecasting for  Portfolio Selection with Transaction Costs},\n  author =       {Uziel, Guy and El-Yaniv, Ran},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {100--110},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/uziel20a/uziel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/uziel20a.html},\n  abstract = \t {\tIn this paper we focus on the problem of online portfolio selection with transaction costs. We tackle this problem using a novel approach for combining the predictions of long-term experts with those of short-term experts so as\tto effectively reduce transaction costs.  We prove that the new strategy \tmaintains bounded regret relative to the performance of the best possible combination (switching times) of the long-and short-term experts.\tWe empirically validate our approach on several standard benchmark datasets.\tThese studies indicate that the proposed approach \tachieves state-of-the-art performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/uziel20a/uziel20a.pdf",
        "supp": "",
        "pdf_size": 534250,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15274154552838650012&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Technion - Israel Institute of Technology, Haifa, Israel; Department of Computer Science, Technion - Israel Institute of Technology, Haifa, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "d81700f059",
        "title": "Low-rank regularization and solution uniqueness in over-parameterized matrix sensing",
        "site": "https://proceedings.mlr.press/v108/geyer20a.html",
        "author": "Kelly Geyer; Anastasios Kyrillidis; Amir Kalev",
        "abstract": "We consider the question whether algorithmic choices in over-parameterized linear matrix factorization introduce implicit low-rank regularization.We focus on the noiseless matrix sensing scenario over low-rank positive semi-definite (PSD) matrices over the reals, with a sensing mechanism that satisfies restricted isometry properties.Surprisingly, it was recently argued that for recovery of PSD matrices, gradient descent over a squared, \\textit{full-rank} factorized space introduces implicit low-rank regularization.Thus, a clever choice of the recovery algorithm avoids the need for explicit low-rank regularization.  In this contribution, we prove that in fact, under certain conditions, the PSD constraint by itself is sufficient to lead to a unique low-rank matrix recovery, without explicit or implicit regularization.Therefore, under these conditions, the set of PSD matrices that are consistent with the observed data, is a singleton, regardless of the algorithm used. Our numerical study indicates that this result is general and extends to cases beyond the those covered by the proof.",
        "bibtex": "@InProceedings{pmlr-v108-geyer20a,\n  title = \t {Low-rank regularization and solution uniqueness in over-parameterized matrix sensing},\n  author =       {Geyer, Kelly and Kyrillidis, Anastasios and Kalev, Amir},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {930--940},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/geyer20a/geyer20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/geyer20a.html},\n  abstract = \t {We consider the question whether algorithmic choices in over-parameterized linear matrix factorization introduce implicit low-rank regularization.We focus on the noiseless matrix sensing scenario over low-rank positive semi-definite (PSD) matrices over the reals, with a sensing mechanism that satisfies restricted isometry properties.Surprisingly, it was recently argued that for recovery of PSD matrices, gradient descent over a squared, \\textit{full-rank} factorized space introduces implicit low-rank regularization.Thus, a clever choice of the recovery algorithm avoids the need for explicit low-rank regularization.  In this contribution, we prove that in fact, under certain conditions, the PSD constraint by itself is sufficient to lead to a unique low-rank matrix recovery, without explicit or implicit regularization.Therefore, under these conditions, the set of PSD matrices that are consistent with the observed data, is a singleton, regardless of the algorithm used. Our numerical study indicates that this result is general and extends to cases beyond the those covered by the proof.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/geyer20a/geyer20a.pdf",
        "supp": "",
        "pdf_size": 513580,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15063392282324821439&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4072eea582",
        "title": "MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search",
        "site": "https://proceedings.mlr.press/v108/han20b.html",
        "author": "Insu Han; Jennifer Gillenwater",
        "abstract": "Determinantal point processes (DPPs) are a good fit for modeling diversity in many machine learning applications.  For instance, in recommender systems, one might have a basic DPP defined by item features, and a customized version of this DPP for each user with features re-weighted according to user preferences.  While such models perform well, they are typically applied only to relatively small datasets, because existing maximum a posteriori (MAP) approximation algorithms are expensive.  In this work, we propose a new MAP algorithm: we show that, by performing a one-time preprocessing step on a basic DPP, it is possible to run an approximate version of the standard greedy MAP approximation algorithm on any customized version of the DPP in time sublinear in the number of items.  Our key observation is that the core computation can be written as a maximum inner product search (MIPS), which allows us to accelerate inference via approximate MIPS structures, e.g., trees or hash tables.  We provide a theoretical analysis of the algorithm\u2019s approximation quality, as well as empirical results on real-world datasets demonstrating that it is often orders of magnitude faster while sacrificing little accuracy.",
        "bibtex": "@InProceedings{pmlr-v108-han20b,\n  title = \t {MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search},\n  author =       {Han, Insu and Gillenwater, Jennifer},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2797--2807},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/han20b/han20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/han20b.html},\n  abstract = \t {Determinantal point processes (DPPs) are a good fit for modeling diversity in many machine learning applications.  For instance, in recommender systems, one might have a basic DPP defined by item features, and a customized version of this DPP for each user with features re-weighted according to user preferences.  While such models perform well, they are typically applied only to relatively small datasets, because existing maximum a posteriori (MAP) approximation algorithms are expensive.  In this work, we propose a new MAP algorithm: we show that, by performing a one-time preprocessing step on a basic DPP, it is possible to run an approximate version of the standard greedy MAP approximation algorithm on any customized version of the DPP in time sublinear in the number of items.  Our key observation is that the core computation can be written as a maximum inner product search (MIPS), which allows us to accelerate inference via approximate MIPS structures, e.g., trees or hash tables.  We provide a theoretical analysis of the algorithm\u2019s approximation quality, as well as empirical results on real-world datasets demonstrating that it is often orders of magnitude faster while sacrificing little accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/han20b/han20b.pdf",
        "supp": "",
        "pdf_size": 509146,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7667684752136567488&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Korea Advanced Institute of Science and Technology; Google Research",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.kaist.ac.kr;https://research.google",
        "aff_unique_abbr": "KAIST;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "d1154a7902",
        "title": "Marginal Densities, Factor Graph Duality, and High-Temperature Series Expansions",
        "site": "https://proceedings.mlr.press/v108/molkaraie20a.html",
        "author": "Mehdi Molkaraie",
        "abstract": "We prove that the marginal densities of a global probability mass function in aprimal normal factor graph and the corresponding marginal densities in the dual normal factor graph are related via local mappings. The mapping depends on the Fourier transform of the local factors of the models. Details of the mapping, including its fixed points, are derived for the Ising model, and then extended to the Potts model. By employing the mapping, we can transform simultaneously all the estimated marginal densities from one domain to the other, which is advantageous if estimating the marginals can be carried out more efficiently in the dual domain.An example of particular significance is the ferromagnetic Ising model in a positive external field, for which there is a rapidly mixing Markov chain (called the subgraphs-world process) to generate configurations in the dual normal factor graph of the model. Our numerical experiments illustrate that the proposed procedure can provide more accurate estimates of marginal densities in various settings.",
        "bibtex": "@InProceedings{pmlr-v108-molkaraie20a,\n  title = \t {Marginal Densities, Factor Graph Duality, and High-Temperature Series Expansions},\n  author =       {Molkaraie, Mehdi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {256--265},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/molkaraie20a/molkaraie20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/molkaraie20a.html},\n  abstract = \t {We prove that the marginal densities of a global probability mass function in aprimal normal factor graph and the corresponding marginal densities in the dual normal factor graph are related via local mappings. The mapping depends on the Fourier transform of the local factors of the models. Details of the mapping, including its fixed points, are derived for the Ising model, and then extended to the Potts model. By employing the mapping, we can transform simultaneously all the estimated marginal densities from one domain to the other, which is advantageous if estimating the marginals can be carried out more efficiently in the dual domain.An example of particular significance is the ferromagnetic Ising model in a positive external field, for which there is a rapidly mixing Markov chain (called the subgraphs-world process) to generate configurations in the dual normal factor graph of the model. Our numerical experiments illustrate that the proposed procedure can provide more accurate estimates of marginal densities in various settings. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/molkaraie20a/molkaraie20a.pdf",
        "supp": "",
        "pdf_size": 452833,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5500255471407892702&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Statistical Sciences, University of Toronto",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Statistical Sciences",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "a3e261ce20",
        "title": "Measuring Mutual Information Between All Pairs of Variables in Subquadratic Complexity",
        "site": "https://proceedings.mlr.press/v108/ferdosi20a.html",
        "author": "Mohsen Ferdosi; Arash Gholamidavoodi; Hosein Mohimani",
        "abstract": "Finding associations between pairs of variables in large datasets is crucial for various disciplines. The brute force method for solving this problem requires computing the mutual information between $\\binom{N}{2}$ pairs. In this paper, we consider the problem of finding pairs of variables with high mutual information in sub-quadratic complexity. This problem is analogous to the nearest neighbor search, where the goal is to find pairs among $N$ variables that are similar to each other. To solve this problem, we develop a new algorithm for finding associations based on constructing a decision tree that assigns a hash to each variable, in a way that for pairs with higher mutual information, the chance of having the same hash is higher. For any $1 \\leq \\lambda \\leq 2$, we prove that in the case of binary data, we can reduce the number of necessary mutual information computations for finding all pairs satisfying $I(X, Y) > 2- \\lambda$ from $O(N^2)$ to $O(N^\\lambda)$,  where $I(X,Y)$ is the empirical mutual information between variables $X$ and $Y$. Finally, we confirmed our theory by experiments on simulated and real data. The implementation of our method and experiments is publicly available at \\href{https://github.com/mohimanilab/HashMI}{https://github.com/mohimanilab/HashMI}.",
        "bibtex": "@InProceedings{pmlr-v108-ferdosi20a,\n  title = \t {Measuring Mutual Information Between All Pairs of Variables in Subquadratic Complexity},\n  author =       {Ferdosi, Mohsen and Gholamidavoodi, Arash and Mohimani, Hosein},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4399--4409},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ferdosi20a/ferdosi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ferdosi20a.html},\n  abstract = \t {Finding associations between pairs of variables in large datasets is crucial for various disciplines. The brute force method for solving this problem requires computing the mutual information between $\\binom{N}{2}$ pairs. In this paper, we consider the problem of finding pairs of variables with high mutual information in sub-quadratic complexity. This problem is analogous to the nearest neighbor search, where the goal is to find pairs among $N$ variables that are similar to each other. To solve this problem, we develop a new algorithm for finding associations based on constructing a decision tree that assigns a hash to each variable, in a way that for pairs with higher mutual information, the chance of having the same hash is higher. For any $1 \\leq \\lambda \\leq 2$, we prove that in the case of binary data, we can reduce the number of necessary mutual information computations for finding all pairs satisfying $I(X, Y) > 2- \\lambda$ from $O(N^2)$ to $O(N^\\lambda)$,  where $I(X,Y)$ is the empirical mutual information between variables $X$ and $Y$. Finally, we confirmed our theory by experiments on simulated and real data. The implementation of our method and experiments is publicly available at \\href{https://github.com/mohimanilab/HashMI}{https://github.com/mohimanilab/HashMI}.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ferdosi20a/ferdosi20a.pdf",
        "supp": "",
        "pdf_size": 1332783,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12962261018757034405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9ad608a9c0",
        "title": "Minimax Bounds for Structured Prediction Based on Factor Graphs",
        "site": "https://proceedings.mlr.press/v108/bello20a.html",
        "author": "Kevin Bello; Asish Ghoshal; Jean Honorio",
        "abstract": "Structured prediction can be considered as a generalization of many standard supervised learning tasks, and is usually thought as a simultaneous prediction of multiple labels. One standard approach is to maximize a score function on the space of labels, which usually decomposes as a sum of unary and pairwise potentials, each depending on one or two specific labels, respectively.For this approach, several learning and inference algorithms have been proposed over the years, ranging from exact to approximate methods while balancing the computational complexity.However, in contrast to binary and multiclass classification, results on the necessary number of samples for achieving learning are still limited, even for a specific family of predictors such as factor graphs.In this work, we provide minimax lower bounds for a class of general factor-graph inference models in the context of structured prediction.That is, we characterize the necessary sample complexity for any conceivable algorithm to achieve learning of general factor-graph predictors.",
        "bibtex": "@InProceedings{pmlr-v108-bello20a,\n  title = \t {Minimax Bounds for Structured Prediction Based on Factor Graphs},\n  author =       {Bello, Kevin and Ghoshal, Asish and Honorio, Jean},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {213--222},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bello20a/bello20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bello20a.html},\n  abstract = \t {Structured prediction can be considered as a generalization of many standard supervised learning tasks, and is usually thought as a simultaneous prediction of multiple labels. One standard approach is to maximize a score function on the space of labels, which usually decomposes as a sum of unary and pairwise potentials, each depending on one or two specific labels, respectively.For this approach, several learning and inference algorithms have been proposed over the years, ranging from exact to approximate methods while balancing the computational complexity.However, in contrast to binary and multiclass classification, results on the necessary number of samples for achieving learning are still limited, even for a specific family of predictors such as factor graphs.In this work, we provide minimax lower bounds for a class of general factor-graph inference models in the context of structured prediction.That is, we characterize the necessary sample complexity for any conceivable algorithm to achieve learning of general factor-graph predictors.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bello20a/bello20a.pdf",
        "supp": "",
        "pdf_size": 306802,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14417439779738087904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA",
        "aff_domain": "purdue.edu;purdue.edu;purdue.edu",
        "email": "purdue.edu;purdue.edu;purdue.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d8e233e14c",
        "title": "Minimax Rank-$1$ Matrix Factorization",
        "site": "https://proceedings.mlr.press/v108/saligrama20a.html",
        "author": "Venkatesh Saligrama; Alexander Olshevsky; Julien Hendrickx",
        "abstract": "We consider the problem of recovering a rank-one matrix when a perturbed subset of its entries is revealed. We  propose a method based on least squares in the log-space and show its performance matches  the  lower bounds that we derive for this problem in the small-perturbation regime,  which are related to the spectral gap of a graph representing the revealed entries. Unfortunately, we show that for larger disturbances, potentially exponentially growing errors are unavoidable for any consistent recovery method. We then propose a second algorithm relying on encoding the matrix factorization in the stationary distribution of a certain Markov chain.  We show that, under the stronger assumption of known upper and lower bounds on the entries of the true matrix,   this second method does not have exponential error growth for large disturbances. Both algorithms can be implemented in nearly linear time.",
        "bibtex": "@InProceedings{pmlr-v108-saligrama20a,\n  title = \t {Minimax Rank-$1$ Matrix Factorization},\n  author =       {Saligrama, Venkatesh and Olshevsky, Alexander and Hendrickx, Julien},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3426--3436},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/saligrama20a/saligrama20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/saligrama20a.html},\n  abstract = \t {We consider the problem of recovering a rank-one matrix when a perturbed subset of its entries is revealed. We  propose a method based on least squares in the log-space and show its performance matches  the  lower bounds that we derive for this problem in the small-perturbation regime,  which are related to the spectral gap of a graph representing the revealed entries. Unfortunately, we show that for larger disturbances, potentially exponentially growing errors are unavoidable for any consistent recovery method. We then propose a second algorithm relying on encoding the matrix factorization in the stationary distribution of a certain Markov chain.  We show that, under the stronger assumption of known upper and lower bounds on the entries of the true matrix,   this second method does not have exponential error growth for large disturbances. Both algorithms can be implemented in nearly linear time.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/saligrama20a/saligrama20a.pdf",
        "supp": "",
        "pdf_size": 788393,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15148850461548400016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "UCLouvain; Boston University; Boston University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Universit\u00e9 catholique de Louvain;Boston University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uclouvain.be;https://www.bu.edu",
        "aff_unique_abbr": "UCL;BU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Belgium;United States"
    },
    {
        "id": "dc0ff5468f",
        "title": "Minimax Testing of Identity to a Reference Ergodic Markov Chain",
        "site": "https://proceedings.mlr.press/v108/wolfer20a.html",
        "author": "Geoffrey Wolfer; Aryeh Kontorovich",
        "abstract": "We exhibit an efficient procedure for testing, based on a single long state sequence, whether an unknown Markov chain is identical to or e-far from a given reference chain. We obtain nearly matching (up to logarithmic factors) upper and lower sample complexity bounds for our notion of distance, which is based on total variation. Perhaps surprisingly, we discover that the sample complexity depends solely on the properties of the known reference chain and does not involve the unknown chain at all, which is not even assumed to be ergodic.",
        "bibtex": "@InProceedings{pmlr-v108-wolfer20a,\n  title = \t {Minimax Testing of Identity to a Reference Ergodic Markov Chain},\n  author =       {Wolfer, Geoffrey and Kontorovich, Aryeh},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {191--201},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wolfer20a/wolfer20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wolfer20a.html},\n  abstract = \t {We exhibit an efficient procedure for testing, based on a single long state sequence, whether an unknown Markov chain is identical to or e-far from a given reference chain. We obtain nearly matching (up to logarithmic factors) upper and lower sample complexity bounds for our notion of distance, which is based on total variation. Perhaps surprisingly, we discover that the sample complexity depends solely on the properties of the known reference chain and does not involve the unknown chain at all, which is not even assumed to be ergodic.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wolfer20a/wolfer20a.pdf",
        "supp": "",
        "pdf_size": 587356,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14480961785807007690&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev; Department of Computer Science, Ben-Gurion University of the Negev",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "60ae352fe1",
        "title": "Minimizing Dynamic Regret and Adaptive Regret Simultaneously",
        "site": "https://proceedings.mlr.press/v108/zhang20a.html",
        "author": "Lijun Zhang; Shiyin Lu; Tianbao Yang",
        "abstract": "Regret minimization is treated as the golden rule in the traditional study of online learning. However, regret minimization algorithms tend to converge to the static optimum, thus being suboptimal for changing environments. To address this limitation, new performance measures, including dynamic regret and adaptive regret have been proposed to guide the design of online algorithms. The former one aims to minimize the global regret with respect to a sequence of changing comparators, and the latter one attempts to minimize every local regret with respect to a fixed comparator. Existing algorithms for dynamic regret and adaptive regret are developed independently, and only target one performance measure. In this paper, we bridge this gap by proposing novel online algorithms that are able to minimize the dynamic regret and adaptive regret simultaneously. In fact, our theoretical guarantee is even stronger in the sense that one algorithm is able to minimize the dynamic regret over any interval.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20a,\n  title = \t {Minimizing Dynamic Regret and Adaptive Regret Simultaneously},\n  author =       {Zhang, Lijun and Lu, Shiyin and Yang, Tianbao},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {309--319},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20a/zhang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20a.html},\n  abstract = \t {Regret minimization is treated as the golden rule in the traditional study of online learning. However, regret minimization algorithms tend to converge to the static optimum, thus being suboptimal for changing environments. To address this limitation, new performance measures, including dynamic regret and adaptive regret have been proposed to guide the design of online algorithms. The former one aims to minimize the global regret with respect to a sequence of changing comparators, and the latter one attempts to minimize every local regret with respect to a fixed comparator. Existing algorithms for dynamic regret and adaptive regret are developed independently, and only target one performance measure. In this paper, we bridge this gap by proposing novel online algorithms that are able to minimize the dynamic regret and adaptive regret simultaneously. In fact, our theoretical guarantee is even stronger in the sense that one algorithm is able to minimize the dynamic regret over any interval.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20a/zhang20a.pdf",
        "supp": "",
        "pdf_size": 353303,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9901886070668706474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; Department of Computer Science, The University of Iowa, Iowa City, IA 52242, USA",
        "aff_domain": "lamda.nju.edu.cn;lamda.nju.edu.cn;uiowa.edu",
        "email": "lamda.nju.edu.cn;lamda.nju.edu.cn;uiowa.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Nanjing University;University of Iowa",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology;Department of Computer Science",
        "aff_unique_url": "http://www.nju.edu.cn;https://www.uiowa.edu",
        "aff_unique_abbr": "Nanjing U;UIowa",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Nanjing;Iowa City",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "5d060f3efb",
        "title": "Mitigating Overfitting in Supervised Classification from Two Unlabeled Datasets: A Consistent Risk Correction Approach",
        "site": "https://proceedings.mlr.press/v108/lu20c.html",
        "author": "Nan Lu; Tianyi Zhang; Gang Niu; Masashi Sugiyama",
        "abstract": "The recently proposed unlabeled-unlabeled (UU) classification method allows us to train a binary classifier only from two unlabeled datasets with different class priors. Since this method is based on the empirical risk minimization, it works as if it is a supervised classification method, compatible with any model and optimizer. However, this method sometimes suffers from severe overfitting, which we would like to prevent in this paper. Our empirical finding in applying the original UU method is that overfitting often co-occurs with the empirical risk going negative, which is not legitimate. Therefore, we propose to wrap the terms that cause a negative empirical risk by certain correction functions. Then, we prove the consistency of the corrected risk estimator and derive an estimation error bound for the corrected risk minimizer. Experiments show that our proposal can successfully mitigate overfitting of the UU method and significantly improve the classification accuracy.",
        "bibtex": "@InProceedings{pmlr-v108-lu20c,\n  title = \t {Mitigating Overfitting in Supervised Classification from Two Unlabeled Datasets: A Consistent Risk Correction Approach},\n  author =       {Lu, Nan and Zhang, Tianyi and Niu, Gang and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1115--1125},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lu20c/lu20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lu20c.html},\n  abstract = \t {The recently proposed unlabeled-unlabeled (UU) classification method allows us to train a binary classifier only from two unlabeled datasets with different class priors. Since this method is based on the empirical risk minimization, it works as if it is a supervised classification method, compatible with any model and optimizer. However, this method sometimes suffers from severe overfitting, which we would like to prevent in this paper. Our empirical finding in applying the original UU method is that overfitting often co-occurs with the empirical risk going negative, which is not legitimate. Therefore, we propose to wrap the terms that cause a negative empirical risk by certain correction functions. Then, we prove the consistency of the corrected risk estimator and derive an estimation error bound for the corrected risk minimizer. Experiments show that our proposal can successfully mitigate overfitting of the UU method and significantly improve the classification accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lu20c/lu20c.pdf",
        "supp": "",
        "pdf_size": 3974657,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17936539872920049649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8df6f8dba0",
        "title": "Mixed Strategies for Robust Optimization of Unknown Objectives",
        "site": "https://proceedings.mlr.press/v108/sessa20a.html",
        "author": "Pier Giuseppe Sessa; Ilija Bogunovic; Maryam Kamgarpour; Andreas Krause",
        "abstract": "We consider robust optimization problems, where the goal is to optimize an unknown objective function against the worst-case realization of an uncertain parameter. For this setting, we design a novel sample-efficient algorithm GP-MRO, which sequentially learns about the unknown objective from noisy point evaluations. GP-MRO seeks to discover a robust and randomized mixed strategy, that maximizes the worst-case expected objective value. To achieve this, it combines techniques from online learning with nonparametric confidence bounds from Gaussian processes. Our theoretical results characterize the number of samples required by GP-MRO to discover a robust near-optimal mixed strategy for different GP kernels of interest. We experimentally demonstrate the performance of our algorithm on synthetic datasets and on human-assisted trajectory planning tasks for autonomous vehicles. In our simulations, we show that robust deterministic strategies can be overly conservative, while the mixed strategies found by GP-MRO significantly improve the overall performance.",
        "bibtex": "@InProceedings{pmlr-v108-sessa20a,\n  title = \t {Mixed Strategies for Robust Optimization of Unknown Objectives},\n  author =       {Sessa, Pier Giuseppe and Bogunovic, Ilija and Kamgarpour, Maryam and Krause, Andreas},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2970--2980},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sessa20a/sessa20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sessa20a.html},\n  abstract = \t {We consider robust optimization problems, where the goal is to optimize an unknown objective function against the worst-case realization of an uncertain parameter. For this setting, we design a novel sample-efficient algorithm GP-MRO, which sequentially learns about the unknown objective from noisy point evaluations. GP-MRO seeks to discover a robust and randomized mixed strategy, that maximizes the worst-case expected objective value. To achieve this, it combines techniques from online learning with nonparametric confidence bounds from Gaussian processes. Our theoretical results characterize the number of samples required by GP-MRO to discover a robust near-optimal mixed strategy for different GP kernels of interest. We experimentally demonstrate the performance of our algorithm on synthetic datasets and on human-assisted trajectory planning tasks for autonomous vehicles. In our simulations, we show that robust deterministic strategies can be overly conservative, while the mixed strategies found by GP-MRO significantly improve the overall performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sessa20a/sessa20a.pdf",
        "supp": "",
        "pdf_size": 1458218,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9660126920088229630&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "11260afb54",
        "title": "Model-Agnostic Counterfactual Explanations for Consequential Decisions",
        "site": "https://proceedings.mlr.press/v108/karimi20a.html",
        "author": "Amir-Hossein Karimi; Gilles Barthe; Borja Balle; Isabel Valera",
        "abstract": "Predictive models are being increasingly used to support consequential decision making at the individual level in contexts such as pretrial bail and loan approval. As a result, there is increasing social and legal pressure to provide explanations that help the affected individuals not only to understand why a prediction was output, but also how to act to obtain a desired outcome. To this end, several works have proposed optimization-based methods to generate nearest counterfactual explanations. However, these methods are often restricted to a particular subset of models (e.g., decision trees or linear models) and differentiable distance functions. In contrast, we build on standard theory and tools from formal verification and propose a novel algorithm that solves a sequence of satisfiability problems, where both the distance function (objective) and predictive model (constraints) are represented as logic formulae. As shown by our experiments on real-world data, our algorithm is: i) model-agnostic ({non-}linear, {non-}differentiable, {non-}convex); ii) data-type-agnostic (heterogeneous features); iii) distance-agnostic (l0, l1, l8, and combinations thereof); iv) able to generate plausible and diverse counterfactuals for any sample (i.e., 100% coverage); and v) at provably optimal distances.",
        "bibtex": "@InProceedings{pmlr-v108-karimi20a,\n  title = \t {Model-Agnostic Counterfactual Explanations for Consequential Decisions},\n  author =       {Karimi, Amir-Hossein and Barthe, Gilles and Balle, Borja and Valera, Isabel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {895--905},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/karimi20a/karimi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/karimi20a.html},\n  abstract = \t {Predictive models are being increasingly used to support consequential decision making at the individual level in contexts such as pretrial bail and loan approval. As a result, there is increasing social and legal pressure to provide explanations that help the affected individuals not only to understand why a prediction was output, but also how to act to obtain a desired outcome. To this end, several works have proposed optimization-based methods to generate nearest counterfactual explanations. However, these methods are often restricted to a particular subset of models (e.g., decision trees or linear models) and differentiable distance functions. In contrast, we build on standard theory and tools from formal verification and propose a novel algorithm that solves a sequence of satisfiability problems, where both the distance function (objective) and predictive model (constraints) are represented as logic formulae. As shown by our experiments on real-world data, our algorithm is: i) model-agnostic ({non-}linear, {non-}differentiable, {non-}convex); ii) data-type-agnostic (heterogeneous features); iii) distance-agnostic (l0, l1, l8, and combinations thereof); iv) able to generate plausible and diverse counterfactuals for any sample (i.e., 100% coverage); and v) at provably optimal distances.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/karimi20a/karimi20a.pdf",
        "supp": "",
        "pdf_size": 763366,
        "gs_citation": 418,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15053016866299323188&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "MPI-IS; MPI-SP/IMDEA Software Institute - MPI-IS; MPI-IS; MPI-SP/IMDEA Software Institute - MPI-IS",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Max Planck Institute for Software Systems",
        "aff_unique_dep": ";IMDEA Software Institute",
        "aff_unique_url": "https://www.mpituebingen.mpg.de;https://www.mpi-sws.org",
        "aff_unique_abbr": "MPI-IS;MPI-SWS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "302706c130",
        "title": "Modular Block-diagonal Curvature Approximations for Feedforward Architectures",
        "site": "https://proceedings.mlr.press/v108/dangel20a.html",
        "author": "Felix Dangel; Stefan Harmeling; Philipp Hennig",
        "abstract": "We propose a modular extension of backpropagation for the computation of block-diagonal approximations to various curvature matrices of the training objective (in particular, the Hessian, generalized Gauss-Newton, and positive-curvature Hessian). The approach reduces the otherwise tedious manual derivation of these matrices into local modules, and is easy to integrate into existing machine learning libraries. Moreover, we develop a compact notation derived from matrix differential calculus. We outline different strategies applicable to our method. They subsume recently-proposed block-diagonal approximations as special cases, and are extended to convolutional neural networks in this work.",
        "bibtex": "@InProceedings{pmlr-v108-dangel20a,\n  title = \t { Modular Block-diagonal Curvature Approximations for Feedforward Architectures},\n  author =       {Dangel, Felix and Harmeling, Stefan and Hennig, Philipp},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {799--808},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dangel20a/dangel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dangel20a.html},\n  abstract = \t {We propose a modular extension of backpropagation for the computation of block-diagonal approximations to various curvature matrices of the training objective (in particular, the Hessian, generalized Gauss-Newton, and positive-curvature Hessian). The approach reduces the otherwise tedious manual derivation of these matrices into local modules, and is easy to integrate into existing machine learning libraries. Moreover, we develop a compact notation derived from matrix differential calculus. We outline different strategies applicable to our method. They subsume recently-proposed block-diagonal approximations as special cases, and are extended to convolutional neural networks in this work.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/dangel20a/dangel20a.pdf",
        "supp": "",
        "pdf_size": 539088,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6850079546634269512&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of T\u00fcbingen; Heinrich Heine University D\u00fcsseldorf; University of T\u00fcbingen + MPI for Intelligent Systems, T\u00fcbingen",
        "aff_domain": "tue.mpg.de;hhu.de;tue.mpg.de",
        "email": "tue.mpg.de;hhu.de;tue.mpg.de",
        "github": "github.com/f-dangel/hbp",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+2",
        "aff_unique_norm": "University of T\u00fcbingen;Heinrich Heine University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.hhu.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;HHU;MPI-IS",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";D\u00fcsseldorf;T\u00fcbingen",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9d79cfebd4",
        "title": "Momentum in Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v108/vieillard20a.html",
        "author": "Nino Vieillard; Bruno Scherrer; Olivier Pietquin; Matthieu Geist",
        "abstract": "We adapt the optimization\u2019s concept of momentum to reinforcement learning. Seeing the state-action value functions as an anlog to the gradients in optimization, we interpret momentum as an average of consecutive $q$-functions. We derive Momentum Value Iteration (MoVI), a variation of Value iteration that incorporates this momentum idea. Our analysis shows that this allows MoVI to average errors over successive iterations. We show that the proposed approach can be readily extended to deep learning. Specifically,we propose a simple improvement on DQN based on MoVI, and experiment it on Atari games.",
        "bibtex": "@InProceedings{pmlr-v108-vieillard20a,\n  title = \t {Momentum in Reinforcement Learning},\n  author =       {Vieillard, Nino and Scherrer, Bruno and Pietquin, Olivier and Geist, Matthieu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2529--2538},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/vieillard20a/vieillard20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/vieillard20a.html},\n  abstract = \t {We adapt the optimization\u2019s concept of momentum to reinforcement learning. Seeing the state-action value functions as an anlog to the gradients in optimization, we interpret momentum as an average of consecutive $q$-functions. We derive Momentum Value Iteration (MoVI), a variation of Value iteration that incorporates this momentum idea. Our analysis shows that this allows MoVI to average errors over successive iterations. We show that the proposed approach can be readily extended to deep learning. Specifically,we propose a simple improvement on DQN based on MoVI, and experiment it on Atari games.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/vieillard20a/vieillard20a.pdf",
        "supp": "",
        "pdf_size": 4568298,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3447607032521565915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7573cfab65",
        "title": "Monotonic Gaussian Process Flows",
        "site": "https://proceedings.mlr.press/v108/ustyuzhaninov20a.html",
        "author": "Ivan Ustyuzhaninov; Ieva Kazlauskaite; Carl Henrik Ek; Neill Campbell",
        "abstract": "We propose a new framework for imposing monotonicity constraints in a Bayesian non-parametric setting based on numerical solutions of stochastic differential equations. We derive a nonparametric model of monotonic functions that allows for interpretable priors and principled quantification of hierarchical uncertainty. We demonstrate the efficacy of the proposed model by providing competitive results to other probabilistic monotonic models on a number of benchmark functions. In addition, we consider the utility of a monotonic random process as a part of a hierarchical probabilistic model; we examine the task of temporal alignment of time-series data where it is beneficial to use a monotonic random process in order to preserve the uncertainty in the temporal warpings.",
        "bibtex": "@InProceedings{pmlr-v108-ustyuzhaninov20a,\n  title = \t {Monotonic Gaussian Process Flows},\n  author =       {Ustyuzhaninov, Ivan and Kazlauskaite, Ieva and Ek, Carl Henrik and Campbell, Neill},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3057--3067},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ustyuzhaninov20a/ustyuzhaninov20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ustyuzhaninov20a.html},\n  abstract = \t {We propose a new framework for imposing monotonicity constraints in a Bayesian non-parametric setting based on numerical solutions of stochastic differential equations. We derive a nonparametric model of monotonic functions that allows for interpretable priors and principled quantification of hierarchical uncertainty. We demonstrate the efficacy of the proposed model by providing competitive results to other probabilistic monotonic models on a number of benchmark functions. In addition, we consider the utility of a monotonic random process as a part of a hierarchical probabilistic model; we examine the task of temporal alignment of time-series data where it is beneficial to use a monotonic random process in order to preserve the uncertainty in the temporal warpings. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/ustyuzhaninov20a/ustyuzhaninov20a.pdf",
        "supp": "",
        "pdf_size": 6396405,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17770519516897284460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ccaa2447c9",
        "title": "More Powerful Selective Kernel Tests for Feature Selection",
        "site": "https://proceedings.mlr.press/v108/lim20a.html",
        "author": "Jen Ning Lim; Makoto Yamada; Wittawat Jitkrittum; Yoshikazu Terada; Shigeyuki Matsui; Hidetoshi Shimodaira",
        "abstract": "Refining one\u2019s hypotheses in light of data is a commonplace scientific practice, however,this approach introduces selection bias and can lead to specious statisticalanalysis.One approach of addressing this phenomena is via  conditioning on the selection procedure, i.e., how we have used the data to generate our hypotheses, and prevents information to be used again after selection.Many selective inference (a.k.a. post-selection inference) algorithms typically take this approach but will \u201cover-condition\u201dfor sake of tractability. While this practice obtains well calibrated $p$-values,it can incur a major loss in power. In our work, we extend two recent proposals for selecting features using the Maximum Mean Discrepancyand Hilbert Schmidt Independence Criterion to condition on the minimalconditioning event. We show how recent advances inmultiscale bootstrap makesthis possible and demonstrate our proposal over a range of synthetic and real world experiments.Our results show that our proposed test is indeed more powerful in most scenarios.",
        "bibtex": "@InProceedings{pmlr-v108-lim20a,\n  title = \t {More Powerful Selective Kernel Tests for Feature Selection},\n  author =       {Lim, Jen Ning and Yamada, Makoto and Jitkrittum, Wittawat and Terada, Yoshikazu and Matsui, Shigeyuki and Shimodaira, Hidetoshi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {820--830},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lim20a/lim20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lim20a.html},\n  abstract = \t {Refining one\u2019s hypotheses in light of data is a commonplace scientific practice, however,this approach introduces selection bias and can lead to specious statisticalanalysis.One approach of addressing this phenomena is via  conditioning on the selection procedure, i.e., how we have used the data to generate our hypotheses, and prevents information to be used again after selection.Many selective inference (a.k.a. post-selection inference) algorithms typically take this approach but will \u201cover-condition\u201dfor sake of tractability. While this practice obtains well calibrated $p$-values,it can incur a major loss in power. In our work, we extend two recent proposals for selecting features using the Maximum Mean Discrepancyand Hilbert Schmidt Independence Criterion to condition on the minimalconditioning event. We show how recent advances inmultiscale bootstrap makesthis possible and demonstrate our proposal over a range of synthetic and real world experiments.Our results show that our proposed test is indeed more powerful in most scenarios.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lim20a/lim20a.pdf",
        "supp": "",
        "pdf_size": 5576206,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9675419236718903223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University College London; Kyoto University, RIKEN AIP; MPI for Intelligent Systems, T\u00fcbingen; Osaka University, RIKEN AIP; Nagoya University; Kyoto University, RIKEN AIP",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4;1",
        "aff_unique_norm": "University College London;Kyoto University;Max Planck Institute for Intelligent Systems;Osaka University;Nagoya University",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.kyoto-u.ac.jp;https://www.mpi-is.mpg.de;https://www.osaka-u.ac.jp;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "UCL;Kyoto U;MPI-IS;Osaka U;Nagoya U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0;1;2;1;1;1",
        "aff_country_unique": "United Kingdom;Japan;Germany"
    },
    {
        "id": "eb1e613f9c",
        "title": "Multi-attribute Bayesian optimization with interactive preference learning",
        "site": "https://proceedings.mlr.press/v108/astudillo20a.html",
        "author": "Raul Astudillo; Peter Frazier",
        "abstract": "We consider black-box global optimization of time-consuming-to-evaluate functions on behalf of a decision-maker (DM) whose preferences must be learned. Each feasible design is associated with a time-consuming-to-evaluate vector of attributes and each vector of attributes is assigned a utility by the DM\u2019s utility function, which may be learned approximately using preferences expressed over pairs of attribute vectors. Past work has used a point estimate of this utility function as if it were error-free within single-objective optimization. However, utility estimation errors may yield a poor suggested design. Furthermore, this approach produces a single suggested \u2018best\u2019 design, whereas DMs often prefer to choose from a menu. We propose a novel multi-attribute Bayesian optimization with preference learning approach. Our approach acknowledges the uncertainty in preference estimation and implicitly chooses designs to evaluate that are good not just for a single estimated utility function but a range of likely ones. The outcome of our approach is a menu of designs and evaluated attributes from which the DM makes a final selection. We demonstrate the value and flexibility of our approach in a variety of experiments.",
        "bibtex": "@InProceedings{pmlr-v108-astudillo20a,\n  title = \t {Multi-attribute Bayesian optimization with interactive preference learning},\n  author =       {Astudillo, Raul and Frazier, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4496--4507},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/astudillo20a/astudillo20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/astudillo20a.html},\n  abstract = \t {We consider black-box global optimization of time-consuming-to-evaluate functions on behalf of a decision-maker (DM) whose preferences must be learned. Each feasible design is associated with a time-consuming-to-evaluate vector of attributes and each vector of attributes is assigned a utility by the DM\u2019s utility function, which may be learned approximately using preferences expressed over pairs of attribute vectors. Past work has used a point estimate of this utility function as if it were error-free within single-objective optimization. However, utility estimation errors may yield a poor suggested design. Furthermore, this approach produces a single suggested \u2018best\u2019 design, whereas DMs often prefer to choose from a menu. We propose a novel multi-attribute Bayesian optimization with preference learning approach. Our approach acknowledges the uncertainty in preference estimation and implicitly chooses designs to evaluate that are good not just for a single estimated utility function but a range of likely ones. The outcome of our approach is a menu of designs and evaluated attributes from which the DM makes a final selection. We demonstrate the value and flexibility of our approach in a variety of experiments. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/astudillo20a/astudillo20a.pdf",
        "supp": "",
        "pdf_size": 2381007,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5138323854853116194&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Cornell University; Cornell University+Uber",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Cornell University;Uber Technologies Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cornell.edu;https://www.uber.com",
        "aff_unique_abbr": "Cornell;Uber",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "37a7476ea3",
        "title": "Multi-level Gaussian Graphical Models Conditional on Covariates",
        "site": "https://proceedings.mlr.press/v108/kim20d.html",
        "author": "Gi Bum Kim; Seyoung Kim",
        "abstract": "We address the problem of learning the structure of a high-dimensional Gaussian graphical model conditional on covariates, when each sample belongs to groups at multiple levels of hierarchy. The existing statistical methods for learning covariate-conditioned Gaussian  graphical models focused on learning the aggregate behavior of inputs and outputs in a single-layer network. We propose a statistical model called multi-level conditional Gaussian graphical models for modeling multi-level output networks influenced by both individual-level and group-level inputs. We describe a decomposition of our model into a product of two components, one for sum variables and the other for difference variables derived from the original variables. This decomposition leads to an efficient learning algorithm for both complete data and incomplete data with randomly missing individual observations, as the expensive repeated computation of the partition function can be avoided. We demonstrate our method on simulated data and real-world data in finance and genomics.",
        "bibtex": "@InProceedings{pmlr-v108-kim20d,\n  title = \t {Multi-level Gaussian Graphical Models Conditional on Covariates},\n  author =       {Kim, Gi Bum and Kim, Seyoung},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4216--4225},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kim20d/kim20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kim20d.html},\n  abstract = \t {We address the problem of learning the structure of a high-dimensional Gaussian graphical model conditional on covariates, when each sample belongs to groups at multiple levels of hierarchy. The existing statistical methods for learning covariate-conditioned Gaussian  graphical models focused on learning the aggregate behavior of inputs and outputs in a single-layer network. We propose a statistical model called multi-level conditional Gaussian graphical models for modeling multi-level output networks influenced by both individual-level and group-level inputs. We describe a decomposition of our model into a product of two components, one for sum variables and the other for difference variables derived from the original variables. This decomposition leads to an efficient learning algorithm for both complete data and incomplete data with randomly missing individual observations, as the expensive repeated computation of the partition function can be avoided. We demonstrate our method on simulated data and real-world data in finance and genomics.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kim20d/kim20d.pdf",
        "supp": "",
        "pdf_size": 2900247,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4305616856305117944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Computational Biology Department, Carnegie Mellon University; Computational Biology Department, Carnegie Mellon University",
        "aff_domain": "cs.cmu.edu;cs.cmu.edu",
        "email": "cs.cmu.edu;cs.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Computational Biology Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "096626c5c7",
        "title": "Multiplicative Gaussian Particle Filter",
        "site": "https://proceedings.mlr.press/v108/su20a.html",
        "author": "Xuan Su; Wee Sun Lee; Zhen Zhang",
        "abstract": "We propose a new sampling-based approach for approximate inference in filtering problems. Instead of approximating conditional distributions with a finite set of states, as done in particle filters, our approach approximates the distribution with a weighted sum of functions from a set of continuous functions. Central to the approach is the use of sampling to approximate multiplications in the Bayes filter. We provide theoretical analysis, giving conditions for sampling to give good approximation. We next specialize to the case of weighted sums of Gaussians, and show how properties of Gaussians enable closed-form transition and efficient multiplication. Lastly, we conduct preliminary experiments on a robot localization problem and compare performance with the particle filter, to demonstrate the potential of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v108-su20a,\n  title = \t {Multiplicative Gaussian Particle Filter},\n  author =       {Su, Xuan and Lee, Wee Sun and Zhang, Zhen},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {56--65},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/su20a/su20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/su20a.html},\n  abstract = \t {We propose a new sampling-based approach for approximate inference in filtering problems. Instead of approximating conditional distributions with a finite set of states, as done in particle filters, our approach approximates the distribution with a weighted sum of functions from a set of continuous functions. Central to the approach is the use of sampling to approximate multiplications in the Bayes filter. We provide theoretical analysis, giving conditions for sampling to give good approximation. We next specialize to the case of weighted sums of Gaussians, and show how properties of Gaussians enable closed-form transition and efficient multiplication. Lastly, we conduct preliminary experiments on a robot localization problem and compare performance with the particle filter, to demonstrate the potential of the proposed method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/su20a/su20a.pdf",
        "supp": "",
        "pdf_size": 747799,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1682936166391943704&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "68b3d78749",
        "title": "Naive Feature Selection: Sparsity in Naive Bayes",
        "site": "https://proceedings.mlr.press/v108/askari20a.html",
        "author": "Armin Askari; Alexandre d\u2019Aspremont; Laurent El Ghaoui",
        "abstract": "Due to its linear complexity, naive Bayes classification remains an attractive supervised learning method, especially in very large-scale settings. We propose a sparse version of naive Bayes, which can be used for feature selection. This leads to a combinatorial maximum-likelihood problem, for which we provide an exact solution in the case of binary data, or a bound in the multinomial case. We prove that our bound becomes tight as the marginal contribution of additional features decreases. Both binary and multinomial sparse models are solvable in time almost linear in problem size, representing a very small extra relative cost compared to the classical naive Bayes. Numerical experiments on text data show that the naive Bayes feature selection method is as statistically effective as state-of-the-art feature selection methods such as recursive feature elimination, l_1-penalized logistic regression and LASSO, while being orders of magnitude faster. For a large data set, having more than with 1.6 million training points and about 12 million features, and with a non-optimized CPU implementation, our sparse naive Bayes model can be trained in less than 15 seconds.",
        "bibtex": "@InProceedings{pmlr-v108-askari20a,\n  title = \t {Naive Feature Selection: Sparsity in Naive Bayes},\n  author =       {Askari, Armin and d'Aspremont, Alexandre and Ghaoui, Laurent El},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1813--1822},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/askari20a/askari20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/askari20a.html},\n  abstract = \t {Due to its linear complexity, naive Bayes classification remains an attractive supervised learning method, especially in very large-scale settings. We propose a sparse version of naive Bayes, which can be used for feature selection. This leads to a combinatorial maximum-likelihood problem, for which we provide an exact solution in the case of binary data, or a bound in the multinomial case. We prove that our bound becomes tight as the marginal contribution of additional features decreases. Both binary and multinomial sparse models are solvable in time almost linear in problem size, representing a very small extra relative cost compared to the classical naive Bayes. Numerical experiments on text data show that the naive Bayes feature selection method is as statistically effective as state-of-the-art feature selection methods such as recursive feature elimination, l_1-penalized logistic regression and LASSO, while being orders of magnitude faster. For a large data set, having more than with 1.6 million training points and about 12 million features, and with a non-optimized CPU implementation, our sparse naive Bayes model can be trained in less than 15 seconds.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/askari20a/askari20a.pdf",
        "supp": "",
        "pdf_size": 1198383,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13815197229698228768&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2b9ec98643",
        "title": "Neighborhood Growth Determines Geometric Priors for Relational Representation Learning",
        "site": "https://proceedings.mlr.press/v108/weber20a.html",
        "author": "Melanie Weber",
        "abstract": "The problem of identifying geometric structure in heterogeneous, high-dimensional data is a cornerstone of representation learning. While there exists a large body of literature on the embeddability of canonical graphs, such as lattices or trees, the heterogeneity of the relational data typically encountered in practice limits the applicability of these classical methods. In this paper, we propose a combinatorial approach to evaluating embeddability, i.e., to decide whether a data set is best represented in Euclidean, Hyperbolic or Spherical space. Our method analyzes nearest-neighbor structures and local neighborhood growth rates to identify the geometric priors of suitable embedding spaces. For canonical graphs, the algorithm\u2019s prediction provably matches classical results. As for large, heterogeneous graphs, we introduce an efficiently computable statistic that approximates the algorithm\u2019s decision rule. We validate our method over a range of benchmark data sets and compare with recently published optimization-based embeddability methods.",
        "bibtex": "@InProceedings{pmlr-v108-weber20a,\n  title = \t {Neighborhood Growth Determines Geometric Priors for Relational Representation Learning},\n  author =       {Weber, Melanie},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {266--276},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/weber20a/weber20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/weber20a.html},\n  abstract = \t {The problem of identifying geometric structure in heterogeneous, high-dimensional data is a cornerstone of representation learning. While there exists a large body of literature on the embeddability of canonical graphs, such as lattices or trees, the heterogeneity of the relational data typically encountered in practice limits the applicability of these classical methods. In this paper, we propose a combinatorial approach to evaluating embeddability, i.e., to decide whether a data set is best represented in Euclidean, Hyperbolic or Spherical space. Our method analyzes nearest-neighbor structures and local neighborhood growth rates to identify the geometric priors of suitable embedding spaces. For canonical graphs, the algorithm\u2019s prediction provably matches classical results. As for large, heterogeneous graphs, we introduce an efficiently computable statistic that approximates the algorithm\u2019s decision rule. We validate our method over a range of benchmark data sets and compare with recently published optimization-based embeddability methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/weber20a/weber20a.pdf",
        "supp": "",
        "pdf_size": 437743,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7885195789862128170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Princeton University",
        "aff_domain": "math.princeton.edu",
        "email": "math.princeton.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fce9d4ee93",
        "title": "Nested-Wasserstein Self-Imitation Learning for Sequence Generation",
        "site": "https://proceedings.mlr.press/v108/zhang20b.html",
        "author": "Ruiyi Zhang; Changyou Chen; Zhe Gan; Zheng Wen; Wenlin Wang; Lawrence Carin",
        "abstract": "Reinforcement learning (RL) has been widely studied for improving sequence-generation models. However, the conventional rewards used for RL training typically cannot capture sufficient semantic information and therefore render model bias. Further, the sparse and delayed rewards make RL exploration inefficient. To alleviate these issues, we propose the concept of nested-Wasserstein distance for distributional semantic matching. To further exploit it, a novel nested-Wasserstein self-imitation learning framework is developed, encouraging the model to exploit historical high-rewarded sequences for enhanced exploration and better semantic matching. Our solution can be understood as approximately executing proximal policy optimization with Wasserstein trust-regions. Experiments on a variety of unconditional and conditional sequence-generation tasks demonstrate the proposed approach consistently leads to improved performance.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20b,\n  title = \t {Nested-Wasserstein Self-Imitation Learning for Sequence Generation},\n  author =       {Zhang, Ruiyi and Chen, Changyou and Gan, Zhe and Wen, Zheng and Wang, Wenlin and Carin, Lawrence},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {422--433},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20b/zhang20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20b.html},\n  abstract = \t {Reinforcement learning (RL) has been widely studied for improving sequence-generation models. However, the conventional rewards used for RL training typically cannot capture sufficient semantic information and therefore render model bias. Further, the sparse and delayed rewards make RL exploration inefficient. To alleviate these issues, we propose the concept of nested-Wasserstein distance for distributional semantic matching. To further exploit it, a novel nested-Wasserstein self-imitation learning framework is developed, encouraging the model to exploit historical high-rewarded sequences for enhanced exploration and better semantic matching. Our solution can be understood as approximately executing proximal policy optimization with Wasserstein trust-regions. Experiments on a variety of unconditional and conditional sequence-generation tasks demonstrate the proposed approach consistently leads to improved performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20b/zhang20b.pdf",
        "supp": "",
        "pdf_size": 1180668,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1373916254882725662&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Duke University; University at Buffalo; Microsoft Dynamics 365 AI Research; DeepMind; Duke University; Duke University",
        "aff_domain": "cs.duke.edu; ; ; ; ; ",
        "email": "cs.duke.edu; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0;0",
        "aff_unique_norm": "Duke University;University at Buffalo;Microsoft;DeepMind",
        "aff_unique_dep": ";;Dynamics 365 AI Research;",
        "aff_unique_url": "https://www.duke.edu;https://www.buffalo.edu;https://www.microsoft.com;https://deepmind.com",
        "aff_unique_abbr": "Duke;UB;Microsoft;DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "073ea52951",
        "title": "Neural Decomposition: Functional ANOVA with Variational Autoencoders",
        "site": "https://proceedings.mlr.press/v108/martens20a.html",
        "author": "Kaspar M\u00e4rtens; Christopher Yau",
        "abstract": "Variational Autoencoders (VAEs) have become a popular approach for dimensionality reduction. However, despite their ability to identify latent low-dimensional structures embedded within high-dimensional data, these latent representations are typically hard to interpret on their own. Due to the black-box nature of VAEs, their utility for healthcare and genomics applications has been limited. In this paper, we focus on characterising the sources of variation in Conditional VAEs. Our goal is to provide a feature-level variance decomposition, i.e. to decompose variation in the data by separating out the marginal additive effects of latent variables z and fixed inputs c from their non-linear interactions. We propose to achieve this through what we call Neural Decomposition \u2013 an adaptation of the well-known concept of functional ANOVA variance decomposition from classical statistics to deep learning models. We show how identifiability can be achieved by training models subject to constraints on the marginal properties of the decoder networks. We demonstrate the utility of our Neural Decomposition on a series of synthetic examples as well as high-dimensional genomics data.",
        "bibtex": "@InProceedings{pmlr-v108-martens20a,\n  title = \t {Neural Decomposition: Functional ANOVA with Variational Autoencoders},\n  author =       {M\\\"artens, Kaspar and Yau, Christopher},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2917--2927},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/martens20a/martens20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/martens20a.html},\n  abstract = \t {Variational Autoencoders (VAEs) have become a popular approach for dimensionality reduction. However, despite their ability to identify latent low-dimensional structures embedded within high-dimensional data, these latent representations are typically hard to interpret on their own. Due to the black-box nature of VAEs, their utility for healthcare and genomics applications has been limited. In this paper, we focus on characterising the sources of variation in Conditional VAEs. Our goal is to provide a feature-level variance decomposition, i.e. to decompose variation in the data by separating out the marginal additive effects of latent variables z and fixed inputs c from their non-linear interactions. We propose to achieve this through what we call Neural Decomposition \u2013 an adaptation of the well-known concept of functional ANOVA variance decomposition from classical statistics to deep learning models. We show how identifiability can be achieved by training models subject to constraints on the marginal properties of the decoder networks. We demonstrate the utility of our Neural Decomposition on a series of synthetic examples as well as high-dimensional genomics data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/martens20a/martens20a.pdf",
        "supp": "",
        "pdf_size": 2269033,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5783623559537101637&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9d5b1e891c",
        "title": "Neural Topic Model with Attention for Supervised Learning",
        "site": "https://proceedings.mlr.press/v108/wang20c.html",
        "author": "Xinyi Wang; YI YANG",
        "abstract": "Topic modeling utilizing neural variational inference has shown promising results recently. Unlike traditional Bayesian topic models, neural topic models use deep neural network to approximate the intractable marginal distribution and thus gain strong generalisation ability. However, neural topic models are unsupervised model. Directly using the document-specific topic proportions in downstream prediction tasks could lead to sub-optimal performance. This paper presents Topic Attention Model (TAM), a supervised neural topic model that integrates an attention recurrent neural network (RNN) model. We design a novel way to utilize document-specific topic proportions and global topic vectors learned from neural topic model in the attention mechanism. We also develop backpropagation inference method that allows for joint model optimisation.  Experimental results on three public datasets show that TAM  not only significantly improves supervised learning tasks, including classification and regression, but also achieves lower perplexity for the document modeling.",
        "bibtex": "@InProceedings{pmlr-v108-wang20c,\n  title = \t {Neural Topic Model with Attention for Supervised Learning},\n  author =       {Wang, Xinyi and YANG, YI},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1147--1156},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20c/wang20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20c.html},\n  abstract = \t {Topic modeling utilizing neural variational inference has shown promising results recently. Unlike traditional Bayesian topic models, neural topic models use deep neural network to approximate the intractable marginal distribution and thus gain strong generalisation ability. However, neural topic models are unsupervised model. Directly using the document-specific topic proportions in downstream prediction tasks could lead to sub-optimal performance. This paper presents Topic Attention Model (TAM), a supervised neural topic model that integrates an attention recurrent neural network (RNN) model. We design a novel way to utilize document-specific topic proportions and global topic vectors learned from neural topic model in the attention mechanism. We also develop backpropagation inference method that allows for joint model optimisation.  Experimental results on three public datasets show that TAM  not only significantly improves supervised learning tasks, including classification and regression, but also achieves lower perplexity for the document modeling.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20c/wang20c.pdf",
        "supp": "",
        "pdf_size": 663614,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9177217125222298667&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics; Department of Information Systems, Business Statistics, and Operations Management",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/WANGXinyiLinda/Neural-Topic-Model-with-Attention-for-Supervised-Learning",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Mathematics Department;Department of Information Systems, Business Statistics, and Operations Management",
        "aff_unique_dep": "Department of Mathematics;Information Systems, Business Statistics, and Operations Management",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "0c1eebef26",
        "title": "Noisy-Input Entropy Search for Efficient Robust Bayesian Optimization",
        "site": "https://proceedings.mlr.press/v108/frohlich20a.html",
        "author": "Lukas Fr\u00f6hlich; Edgar Klenske; Julia Vinogradska; Christian Daniel; Melanie Zeilinger",
        "abstract": "We consider the problem of robust optimization within the well-established Bayesian Optimization (BO) framework.While BO is intrinsically robust to noisy evaluations of the objective function, standard approaches do not consider the case of uncertainty about the input parameters.In this paper, we propose Noisy-Input Entropy Search (NES), a novel information-theoretic acquisition function that is designed to find robust optima for problems with both input and measurement noise.NES is based on the key insight that the robust objective in many cases can be modeled as a Gaussian process, however, it cannot be observed directly.We evaluate NES on several benchmark problems from the optimization literature and from engineering.The results show that NES reliably finds robust optima, outperforming existing methods from the literature on all benchmarks.",
        "bibtex": "@InProceedings{pmlr-v108-frohlich20a,\n  title = \t {Noisy-Input Entropy Search for Efficient Robust Bayesian Optimization},\n  author =       {Fr\\\"ohlich, Lukas and Klenske, Edgar and Vinogradska, Julia and Daniel, Christian and Zeilinger, Melanie},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2262--2272},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/frohlich20a/frohlich20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/frohlich20a.html},\n  abstract = \t {We consider the problem of robust optimization within the well-established Bayesian Optimization (BO) framework.While BO is intrinsically robust to noisy evaluations of the objective function, standard approaches do not consider the case of uncertainty about the input parameters.In this paper, we propose Noisy-Input Entropy Search (NES), a novel information-theoretic acquisition function that is designed to find robust optima for problems with both input and measurement noise.NES is based on the key insight that the robust objective in many cases can be modeled as a Gaussian process, however, it cannot be observed directly.We evaluate NES on several benchmark problems from the optimization literature and from engineering.The results show that NES reliably finds robust optima, outperforming existing methods from the literature on all benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/frohlich20a/frohlich20a.pdf",
        "supp": "",
        "pdf_size": 1227015,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14162784876647513497&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Bosch Center for Arti\ufb01cial Intelligence, Renningen, Germany+ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Bosch Center for Arti\ufb01cial Intelligence, Renningen, Germany; Bosch Center for Arti\ufb01cial Intelligence, Renningen, Germany; Bosch Center for Arti\ufb01cial Intelligence, Renningen, Germany; ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;0;1",
        "aff_unique_norm": "Bosch Center for Arti\ufb01cial Intelligence;ETH Zurich",
        "aff_unique_dep": "Artificial Intelligence;",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.ethz.ch",
        "aff_unique_abbr": "BCAI;ETHZ",
        "aff_campus_unique_index": "0+1;0;0;0;1",
        "aff_campus_unique": "Renningen;Z\u00fcrich",
        "aff_country_unique_index": "0+1;0;0;0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "df87ab4a9d",
        "title": "Non-Parametric Calibration for Classification",
        "site": "https://proceedings.mlr.press/v108/wenger20a.html",
        "author": "Jonathan Wenger; Hedvig Kjellstr\u00f6m; Rudolph Triebel)",
        "abstract": "Many applications of classification methods not only require high accuracy but also reliable estimation of predictive uncertainty. However, while many current classification frameworks, in particular deep neural networks, achieve high accuracy, they tend to incorrectly estimate uncertainty. In this paper, we propose a method that adjusts the confidence estimates of a general classifier such that they approach the probability of classifying correctly. In contrast to existing approaches, our calibration method employs a non-parametric representation using a latent Gaussian process, and is specifically designed for multi-class classification. It can be applied to any classifier that outputs confidence estimates and is not limited to neural networks. We also provide a theoretical analysis regarding the over- and underconfidence of a classifier and its relationship to calibration, as well as an empirical outlook for calibrated active learning. In experiments we show the universally strong performance of our method across different classifiers and benchmark data sets, in particular for state-of-the art neural network architectures.",
        "bibtex": "@InProceedings{pmlr-v108-wenger20a,\n  title = \t {Non-Parametric Calibration for Classification},\n  author =       {Wenger, Jonathan and Kjellstr\\\"om, Hedvig and Triebel), Rudolph},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {178--190},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wenger20a/wenger20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wenger20a.html},\n  abstract = \t {Many applications of classification methods not only require high accuracy but also reliable estimation of predictive uncertainty. However, while many current classification frameworks, in particular deep neural networks, achieve high accuracy, they tend to incorrectly estimate uncertainty. In this paper, we propose a method that adjusts the confidence estimates of a general classifier such that they approach the probability of classifying correctly. In contrast to existing approaches, our calibration method employs a non-parametric representation using a latent Gaussian process, and is specifically designed for multi-class classification. It can be applied to any classifier that outputs confidence estimates and is not limited to neural networks. We also provide a theoretical analysis regarding the over- and underconfidence of a classifier and its relationship to calibration, as well as an empirical outlook for calibrated active learning. In experiments we show the universally strong performance of our method across different classifiers and benchmark data sets, in particular for state-of-the art neural network architectures.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wenger20a/wenger20a.pdf",
        "supp": "",
        "pdf_size": 1045166,
        "gs_citation": 123,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14328787546114573917&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of Tuebingen; TU Munich + KTH Royal Institute of Technology; KTH Royal Institute of Technology + German Aerospace Center (DLR) + TU Munich",
        "aff_domain": "uni-tuebingen.de;kth.se;dlr.de",
        "email": "uni-tuebingen.de;kth.se;dlr.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;2+3+1",
        "aff_unique_norm": "University of Tuebingen;Technical University of Munich;KTH Royal Institute of Technology;German Aerospace Center",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.tum.de;https://www.kth.se;https://www.dlr.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;TUM;KTH;DLR",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+1;1+0+0",
        "aff_country_unique": "Germany;Sweden"
    },
    {
        "id": "4134ebeef7",
        "title": "Non-exchangeable feature allocation models with sublinear growth of the feature sizes",
        "site": "https://proceedings.mlr.press/v108/benedetto20a.html",
        "author": "Giuseppe Di Benedetto; Francois Caron; Yee Whye Teh",
        "abstract": "Feature allocation models are popular models used in different applications such as unsupervised learning or network modeling. In particular, the Indian buffet process is a flexible and simple one-parameter feature allocation model where the number of features grows unboundedly with the number of objects. The Indian buffet process, like most feature allocation models, satisfies a  symmetry property of exchangeability: the distribution is invariant under permutation of the objects. While this property is desirable in some cases, it has some strong implications. Importantly, the number of objects sharing a particular feature grows linearly with the number of objects. In this article, we describe a class of non-exchangeable feature allocation models where the number of objects sharing a given feature grows sublinearly, where the rate can be controlled by a tuning parameter. We derive the asymptotic properties of the model, and show that such models provides a better fit and better predictive performances on various datasets.",
        "bibtex": "@InProceedings{pmlr-v108-benedetto20a,\n  title = \t {Non-exchangeable feature allocation models with sublinear growth of the feature sizes},\n  author =       {Benedetto, Giuseppe Di and Caron, Francois and Teh, Yee Whye},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3208--3218},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/benedetto20a/benedetto20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/benedetto20a.html},\n  abstract = \t {Feature allocation models are popular models used in different applications such as unsupervised learning or network modeling. In particular, the Indian buffet process is a flexible and simple one-parameter feature allocation model where the number of features grows unboundedly with the number of objects. The Indian buffet process, like most feature allocation models, satisfies a  symmetry property of exchangeability: the distribution is invariant under permutation of the objects. While this property is desirable in some cases, it has some strong implications. Importantly, the number of objects sharing a particular feature grows linearly with the number of objects. In this article, we describe a class of non-exchangeable feature allocation models where the number of objects sharing a given feature grows sublinearly, where the rate can be controlled by a tuning parameter. We derive the asymptotic properties of the model, and show that such models provides a better fit and better predictive performances on various datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/benedetto20a/benedetto20a.pdf",
        "supp": "",
        "pdf_size": 1392685,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2693678840442602920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e96585a668",
        "title": "Nonmyopic Gaussian Process Optimization with Macro-Actions",
        "site": "https://proceedings.mlr.press/v108/kharkovskii20a.html",
        "author": "Dmitrii Kharkovskii; Chun Kai Ling; Bryan Kian Hsiang Low",
        "abstract": "This paper presents a multi-staged approach to nonmyopic adaptive Gaussian process optimization (GPO) for Bayesian optimization (BO) of unknown, highly complex objective functions that, in contrast to existing nonmyopic adaptive BO algorithms, exploits the notion of macro-actions for scaling up to a further lookahead to match up to a larger available budget. To achieve this, we generalize GP upper confidence bound to a new acquisition function defined w.r.t. a nonmyopic adaptive macro-action policy, which is intractable to be optimized exactly due to an uncountable set of candidate outputs. The contribution of our work here is thus to derive a nonmyopic adaptive epsilon-Bayes-optimal macro-action GPO (epsilon-Macro-GPO) policy. To perform nonmyopic adaptive BO in real time, we then propose an asymptotically optimal anytime variant of our epsilon-Macro-GPO policy with a performance guarantee. We empirically evaluate the performance of our epsilon-Macro-GPO policy and its anytime variant in BO with synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v108-kharkovskii20a,\n  title = \t {Nonmyopic Gaussian Process Optimization with Macro-Actions},\n  author =       {Kharkovskii, Dmitrii and Ling, Chun Kai and Low, Bryan Kian Hsiang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4593--4604},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kharkovskii20a/kharkovskii20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kharkovskii20a.html},\n  abstract = \t {This paper presents a multi-staged approach to nonmyopic adaptive Gaussian process optimization (GPO) for Bayesian optimization (BO) of unknown, highly complex objective functions that, in contrast to existing nonmyopic adaptive BO algorithms, exploits the notion of macro-actions for scaling up to a further lookahead to match up to a larger available budget. To achieve this, we generalize GP upper confidence bound to a new acquisition function defined w.r.t. a nonmyopic adaptive macro-action policy, which is intractable to be optimized exactly due to an uncountable set of candidate outputs. The contribution of our work here is thus to derive a nonmyopic adaptive epsilon-Bayes-optimal macro-action GPO (epsilon-Macro-GPO) policy. To perform nonmyopic adaptive BO in real time, we then propose an asymptotically optimal anytime variant of our epsilon-Macro-GPO policy with a performance guarantee. We empirically evaluate the performance of our epsilon-Macro-GPO policy and its anytime variant in BO with synthetic and real-world datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kharkovskii20a/kharkovskii20a.pdf",
        "supp": "",
        "pdf_size": 2494241,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9746069582382722283&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8794493238",
        "title": "Nonparametric Estimation in the Dynamic Bradley-Terry Model",
        "site": "https://proceedings.mlr.press/v108/bong20a.html",
        "author": "Heejong Bong; Wanshan Li; Shamindra Shrotriya; Alessandro Rinaldo",
        "abstract": "We propose a time-varying generalization of the Bradley-Terry model that allows for nonparametric modeling of dynamic global rankings of distinct teams. We develop a novel estimator that relies on kernel smoothing to pre-process the pairwise comparisons over time and is applicable in sparse settings where the Bradley-Terry may not be fit. We obtain  necessary and sufficient conditions for the existence and uniqueness of our estimator. We also derive time-varying oracle bounds for both the estimation error and the excess risk in the model-agnostic setting where the Bradley-Terry model is not necessarily the true data generating process.  We thoroughly test the practical effectiveness of our model using both simulated and real world data and suggest an efficient data-driven approach for bandwidth tuning.",
        "bibtex": "@InProceedings{pmlr-v108-bong20a,\n  title = \t {Nonparametric Estimation in the Dynamic Bradley-Terry Model},\n  author =       {Bong, Heejong and Li, Wanshan and Shrotriya, Shamindra and Rinaldo, Alessandro},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3317--3326},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bong20a/bong20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bong20a.html},\n  abstract = \t {We propose a time-varying generalization of the Bradley-Terry model that allows for nonparametric modeling of dynamic global rankings of distinct teams. We develop a novel estimator that relies on kernel smoothing to pre-process the pairwise comparisons over time and is applicable in sparse settings where the Bradley-Terry may not be fit. We obtain  necessary and sufficient conditions for the existence and uniqueness of our estimator. We also derive time-varying oracle bounds for both the estimation error and the excess risk in the model-agnostic setting where the Bradley-Terry model is not necessarily the true data generating process.  We thoroughly test the practical effectiveness of our model using both simulated and real world data and suggest an efficient data-driven approach for bandwidth tuning.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bong20a/bong20a.pdf",
        "supp": "",
        "pdf_size": 1787908,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14325732525768719117&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "798c738db6",
        "title": "Nonparametric Sequential Prediction While Deep Learning the Kernel",
        "site": "https://proceedings.mlr.press/v108/uziel20b.html",
        "author": "Guy Uziel",
        "abstract": "The research on online learning under stationary and ergodic processes has been mainly focused on achieving asymptotic guarantees. Although all the methods pursue the same asymptotic goal, their performance varies when handling finite sample datasets and depends heavily on which predefined density estimation method is chosen. In this paper, therefore, we propose a novel algorithm that simultaneously satisfies a short-term goal, to perform as good as the best choice in hindsight of a  data-adaptive kernel, learned using a deep neural network, and a long-term goal,  to achieve the same theoretical asymptotic guarantee. We present theoretical proofs for our algorithms and demonstrate the validity of our method on the online portfolio selection problem.",
        "bibtex": "@InProceedings{pmlr-v108-uziel20b,\n  title = \t {Nonparametric Sequential Prediction While Deep Learning the Kernel},\n  author =       {Uziel, Guy},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {111--121},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/uziel20b/uziel20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/uziel20b.html},\n  abstract = \t {The research on online learning under stationary and ergodic processes has been mainly focused on achieving asymptotic guarantees. Although all the methods pursue the same asymptotic goal, their performance varies when handling finite sample datasets and depends heavily on which predefined density estimation method is chosen. In this paper, therefore, we propose a novel algorithm that simultaneously satisfies a short-term goal, to perform as good as the best choice in hindsight of a  data-adaptive kernel, learned using a deep neural network, and a long-term goal,  to achieve the same theoretical asymptotic guarantee. We present theoretical proofs for our algorithms and demonstrate the validity of our method on the online portfolio selection problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/uziel20b/uziel20b.pdf",
        "supp": "",
        "pdf_size": 529332,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:AbfkP3xhlJUJ:scholar.google.com/&scioq=Nonparametric+Sequential+Prediction+While+Deep+Learning+the+Kernel&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Technion - Israel Institute of Technology, Haifa, Israel",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "f6c2039e3e",
        "title": "OSOM: A simultaneously optimal algorithm for multi-armed and linear contextual bandits",
        "site": "https://proceedings.mlr.press/v108/chatterji20b.html",
        "author": "Niladri Chatterji; Vidya Muthukumar; Peter Bartlett",
        "abstract": "We consider the stochastic linear (multi-armed) contextual bandit problem with the possibility of hidden simple multi-armed bandit structure in which the rewards are independent of the contextual information. Algorithms that are designed solely for one of the regimes are known to be sub-optimal for their alternate regime. We design a single computationally efficient algorithm that simultaneously obtains problem-dependent optimal regret rates in the simple multi-armed bandit regime and minimax optimal regret rates in the linear contextual bandit regime, without knowing a priori which of the two models generates the rewards. These results are proved under the condition of stochasticity of contextual information over multiple rounds. Our results should be viewed as a step towards principled data-dependent policy class selection for contextual bandits.",
        "bibtex": "@InProceedings{pmlr-v108-chatterji20b,\n  title = \t {OSOM: A simultaneously optimal algorithm for multi-armed and linear contextual bandits},\n  author =       {Chatterji, Niladri and Muthukumar, Vidya and Bartlett, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1844--1854},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chatterji20b/chatterji20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chatterji20b.html},\n  abstract = \t {We consider the stochastic linear (multi-armed) contextual bandit problem with the possibility of hidden simple multi-armed bandit structure in which the rewards are independent of the contextual information. Algorithms that are designed solely for one of the regimes are known to be sub-optimal for their alternate regime. We design a single computationally efficient algorithm that simultaneously obtains problem-dependent optimal regret rates in the simple multi-armed bandit regime and minimax optimal regret rates in the linear contextual bandit regime, without knowing a priori which of the two models generates the rewards. These results are proved under the condition of stochasticity of contextual information over multiple rounds. Our results should be viewed as a step towards principled data-dependent policy class selection for contextual bandits.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chatterji20b/chatterji20b.pdf",
        "supp": "",
        "pdf_size": 928866,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3009075220640280903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "772f063314",
        "title": "Obfuscation via Information Density Estimation",
        "site": "https://proceedings.mlr.press/v108/hsu20a.html",
        "author": "Hsiang Hsu; Shahab Asoodeh; Flavio Calmon",
        "abstract": "Identifying features that leak information about sensitive attributes is a key challenge in the design of information obfuscation mechanisms. In this paper, we propose a framework to identify information-leaking features via information density estimation. Here, features whose information densities exceed a pre-defined threshold are deemed information-leaking features. Once these features are identified, we sequentially pass them through a targeted obfuscation mechanism with a provable leakage guarantee in terms of $\\mathsf{E}_\\gamma$-divergence. The core of this mechanism relies on a data-driven estimate of the trimmed information density for which we propose a novel estimator, named the \\textit{trimmed information density estimator} (TIDE). We then use TIDE to implement our mechanism on three real-world datasets. Our approach can be used as a data-driven pipeline for designing obfuscation mechanisms targeting specific features.",
        "bibtex": "@InProceedings{pmlr-v108-hsu20a,\n  title = \t {Obfuscation via Information Density Estimation},\n  author =       {Hsu, Hsiang and Asoodeh, Shahab and Calmon, Flavio},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {906--917},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hsu20a/hsu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hsu20a.html},\n  abstract = \t {Identifying features that leak information about sensitive attributes is a key challenge in the design of information obfuscation mechanisms. In this paper, we propose a framework to identify information-leaking features via information density estimation. Here, features whose information densities exceed a pre-defined threshold are deemed information-leaking features. Once these features are identified, we sequentially pass them through a targeted obfuscation mechanism with a provable leakage guarantee in terms of $\\mathsf{E}_\\gamma$-divergence. The core of this mechanism relies on a data-driven estimate of the trimmed information density for which we propose a novel estimator, named the \\textit{trimmed information density estimator} (TIDE). We then use TIDE to implement our mechanism on three real-world datasets. Our approach can be used as a data-driven pipeline for designing obfuscation mechanisms targeting specific features.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hsu20a/hsu20a.pdf",
        "supp": "",
        "pdf_size": 2376326,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=456567160529929977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Harvard University; Harvard University; Harvard University",
        "aff_domain": "g.harvard.edu;seas.harvard.edu;seas.harvard.edu",
        "email": "g.harvard.edu;seas.harvard.edu;seas.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bca5879257",
        "title": "Old Dog Learns New Tricks: Randomized UCB for Bandit Problems",
        "site": "https://proceedings.mlr.press/v108/vaswani20a.html",
        "author": "Sharan Vaswani; Abbas Mehrabian; Audrey Durand; Branislav Kveton",
        "abstract": "We propose RandUCB, a bandit strategy that uses theoretically derived confidence intervals similar to upper confidence bound (UCB) algorithms, but akin to Thompson sampling (TS), uses randomization to trade off exploration and exploitation. In the $K$-armed bandit setting, we show that there are infinitely many variants of RandUCB, all of which achieve the minimax-optimal $\\widetilde{O}(\\sqrt{K T})$ regret after $T$ rounds. Moreover, in a specific multi-armed bandit setting, we show that both  UCB and TS can be recovered as special cases of RandUCB. For structured bandits, where each arm is associated with a $d$-dimensional feature vector and rewards are distributed according to a linear or generalized linear model, we prove that RandUCB achieves the minimax-optimal $\\widetilde{O}(d \\sqrt{T})$ regret even in the case of infinite arms. We demonstrate the practical effectiveness of RandUCB with experiments in both multi-armed and structured bandit settings. We show that RandUCB matches the empirical performance of TS while matching the theoretically optimal bounds of UCB algorithms, thus achieving the best of both worlds.",
        "bibtex": "@InProceedings{pmlr-v108-vaswani20a,\n  title = \t {Old Dog Learns New Tricks: Randomized UCB for Bandit Problems},\n  author =       {Vaswani, Sharan and Mehrabian, Abbas and Durand, Audrey and Kveton, Branislav},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1988--1998},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/vaswani20a/vaswani20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/vaswani20a.html},\n  abstract = \t {We propose RandUCB, a bandit strategy that uses theoretically derived confidence intervals similar to upper confidence bound (UCB) algorithms, but akin to Thompson sampling (TS), uses randomization to trade off exploration and exploitation. In the $K$-armed bandit setting, we show that there are infinitely many variants of RandUCB, all of which achieve the minimax-optimal $\\widetilde{O}(\\sqrt{K T})$ regret after $T$ rounds. Moreover, in a specific multi-armed bandit setting, we show that both  UCB and TS can be recovered as special cases of RandUCB. For structured bandits, where each arm is associated with a $d$-dimensional feature vector and rewards are distributed according to a linear or generalized linear model, we prove that RandUCB achieves the minimax-optimal $\\widetilde{O}(d \\sqrt{T})$ regret even in the case of infinite arms. We demonstrate the practical effectiveness of RandUCB with experiments in both multi-armed and structured bandit settings. We show that RandUCB matches the empirical performance of TS while matching the theoretically optimal bounds of UCB algorithms, thus achieving the best of both worlds. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/vaswani20a/vaswani20a.pdf",
        "supp": "",
        "pdf_size": 8380950,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11608681385169970981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2fe5f76fde",
        "title": "On Generalization Bounds of a Family of Recurrent Neural Networks",
        "site": "https://proceedings.mlr.press/v108/chen20d.html",
        "author": "Minshuo Chen; Xingguo Li; Tuo Zhao",
        "abstract": "Recurrent Neural Networks (RNNs) have been widely applied to sequential data analysis. Due to their complicated modeling structures, however, the theory behind is still largely missing. To connect theory and practice, we study the generalization properties of vanilla RNNs as well as their variants, including Minimal Gated Unit (MGU), Long Short Term Memory (LSTM), and Convolutional (Conv) RNNs. Specifically, our theory is established under the PAC-Learning framework. The generalization bound is presented in terms of the spectral norms of the weight matrices and the total number of parameters. We also establish refined generalization bounds with additional norm assumptions, and draw a comparison among these bounds. We remark: (1) Our generalization bound for vanilla RNNs is significantly tighter than the best of existing results; (2) We are not aware of any other generalization bounds for MGU and LSTM RNNs in the exiting literature; (3) We demonstrate the advantages of these variants in generalization.",
        "bibtex": "@InProceedings{pmlr-v108-chen20d,\n  title = \t {On Generalization Bounds of a Family of Recurrent Neural Networks},\n  author =       {Chen, Minshuo and Li, Xingguo and Zhao, Tuo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1233--1243},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chen20d/chen20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chen20d.html},\n  abstract = \t {Recurrent Neural Networks (RNNs) have been widely applied to sequential data analysis. Due to their complicated modeling structures, however, the theory behind is still largely missing. To connect theory and practice, we study the generalization properties of vanilla RNNs as well as their variants, including Minimal Gated Unit (MGU), Long Short Term Memory (LSTM), and Convolutional (Conv) RNNs. Specifically, our theory is established under the PAC-Learning framework. The generalization bound is presented in terms of the spectral norms of the weight matrices and the total number of parameters. We also establish refined generalization bounds with additional norm assumptions, and draw a comparison among these bounds. We remark: (1) Our generalization bound for vanilla RNNs is significantly tighter than the best of existing results; (2) We are not aware of any other generalization bounds for MGU and LSTM RNNs in the exiting literature; (3) We demonstrate the advantages of these variants in generalization.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chen20d/chen20d.pdf",
        "supp": "",
        "pdf_size": 8324951,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Georgia Tech; Princeton University; Georgia Tech",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Princeton University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.princeton.edu",
        "aff_unique_abbr": "Georgia Tech;Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "47554ce92c",
        "title": "On Maximization of Weakly Modular Functions: Guarantees of Multi-stage Algorithms, Tractability, and Hardness",
        "site": "https://proceedings.mlr.press/v108/sakaue20b.html",
        "author": "Shinsaku Sakaue",
        "abstract": "Maximization of {\\it non-submodular} functions appears in various scenarios, and many previous works studied it based on some measures that quantify the closeness to being submodular. On the other hand, some practical non-submodular functions are actually close to being {\\it modular}, which has been utilized in few studies. In this paper, we study cardinality-constrained maximization of {\\it weakly modular} functions, whose closeness to being modular is measured by {\\it submodularity} and {\\it supermodularity ratios}, and reveal what we can and cannot do by using the weak modularity. We first show that guarantees of multi-stage algorithms can be proved with the weak modularity, which generalize and improve some existing results, and experiments confirm their effectiveness. We then show that weakly modular maximization is {\\it fixed-parameter tractable} under certain conditions; as a byproduct, we provide a new time\u2013accuracy trade-off for $\\ell_0$-constrained minimization. We finally prove that, even if objective functions are weakly modular, no polynomial-time algorithms can improve the existing approximation guarantee achieved by the greedy algorithm in general.",
        "bibtex": "@InProceedings{pmlr-v108-sakaue20b,\n  title = \t {On Maximization of Weakly Modular Functions: Guarantees of Multi-stage Algorithms, Tractability, and Hardness},\n  author =       {Sakaue, Shinsaku},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {22--33},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sakaue20b/sakaue20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sakaue20b.html},\n  abstract = \t {Maximization of {\\it non-submodular} functions appears in various scenarios, and many previous works studied it based on some measures that quantify the closeness to being submodular. On the other hand, some practical non-submodular functions are actually close to being {\\it modular}, which has been utilized in few studies. In this paper, we study cardinality-constrained maximization of {\\it weakly modular} functions, whose closeness to being modular is measured by {\\it submodularity} and {\\it supermodularity ratios}, and reveal what we can and cannot do by using the weak modularity. We first show that guarantees of multi-stage algorithms can be proved with the weak modularity, which generalize and improve some existing results, and experiments confirm their effectiveness. We then show that weakly modular maximization is {\\it fixed-parameter tractable} under certain conditions; as a byproduct, we provide a new time\u2013accuracy trade-off for $\\ell_0$-constrained minimization. We finally prove that, even if objective functions are weakly modular, no polynomial-time algorithms can improve the existing approximation guarantee achieved by the greedy algorithm in general.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sakaue20b/sakaue20b.pdf",
        "supp": "",
        "pdf_size": 879491,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Cv9YIhUV_40J:scholar.google.com/&scioq=On+Maximization+of+Weakly+Modular+Functions:+Guarantees+of+Multi-stage+Algorithms,+Tractability,+and+Hardness&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": "NTT Communication Science Laboratories",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "NTT Communication Science Laboratories",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ntt-csl.com",
        "aff_unique_abbr": "NTT CSL",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "3a4c187b70",
        "title": "On Minimax Optimality of GANs for Robust Mean Estimation",
        "site": "https://proceedings.mlr.press/v108/wu20d.html",
        "author": "Kaiwen Wu; Gavin Weiguang Ding; Ruitong Huang; Yaoliang Yu",
        "abstract": "Generative adversarial networks (GANs) have become one of the most popular generative modeling techniques in machine learning. In this work, we study the statistical and robust properties of GANs for Gaussian mean estimation under Huber\u2019s contamination model, where an epsilon proportion of training data may be arbitrarily corrupted. We prove that f-GAN, when equipped with appropriate discriminators, achieve optimal minimax rate, hence extending the recent result of Gao et al. (2019a). In contrast, we show that other GAN variants such as MMD-GAN (with Gaussian kernel) and W-GAN may fail to achieve minimax optimality. We further adapt f-GAN to the sparse and the unknown covariance settings. We perform numerical simulations to confirm our theoretical findings and reveal new insights on the importance of discriminators.",
        "bibtex": "@InProceedings{pmlr-v108-wu20d,\n  title = \t {On Minimax Optimality of GANs for Robust Mean Estimation},\n  author =       {Wu, Kaiwen and Ding, Gavin Weiguang and Huang, Ruitong and Yu, Yaoliang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4541--4551},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wu20d/wu20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wu20d.html},\n  abstract = \t {Generative adversarial networks (GANs) have become one of the most popular generative modeling techniques in machine learning. In this work, we study the statistical and robust properties of GANs for Gaussian mean estimation under Huber\u2019s contamination model, where an epsilon proportion of training data may be arbitrarily corrupted. We prove that f-GAN, when equipped with appropriate discriminators, achieve optimal minimax rate, hence extending the recent result of Gao et al. (2019a). In contrast, we show that other GAN variants such as MMD-GAN (with Gaussian kernel) and W-GAN may fail to achieve minimax optimality. We further adapt f-GAN to the sparse and the unknown covariance settings. We perform numerical simulations to confirm our theoretical findings and reveal new insights on the importance of discriminators.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wu20d/wu20d.pdf",
        "supp": "",
        "pdf_size": 498882,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10605593826667160514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e753b3f80c",
        "title": "On Pruning for Score-Based Bayesian Network Structure Learning",
        "site": "https://proceedings.mlr.press/v108/correia20a.html",
        "author": "Alvaro Henrique Chaim Correia; James Cussens; Cassio de Campos",
        "abstract": "Many algorithms for score-based Bayesian network structure learning (BNSL), in particular exact ones, take as input a collection of potentially optimal parent sets for each variable in the data. Constructing such collections naively is computationally intensive since the number of parent sets grows exponentially with the number of variables. Thus, pruning techniques are not only desirable but essential. While good pruning rules exist for the Bayesian Information Criterion (BIC), current results for the Bayesian Dirichlet equivalent uniform (BDeu) score reduce the search space very modestly, hampering the use of the (often preferred) BDeu. We derive new non-trivial theoretical upper bounds for the BDeu score that considerably improve on the state-of-the-art. Since the new bounds are mathematically proven to be tighter than previous ones and at little extra computational cost, they are a promising addition to BNSL methods.",
        "bibtex": "@InProceedings{pmlr-v108-correia20a,\n  title = \t {On Pruning for Score-Based Bayesian Network Structure Learning},\n  author =       {Correia, Alvaro Henrique Chaim and Cussens, James and de Campos, Cassio},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2709--2718},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/correia20a/correia20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/correia20a.html},\n  abstract = \t {Many algorithms for score-based Bayesian network structure learning (BNSL), in particular exact ones, take as input a collection of potentially optimal parent sets for each variable in the data. Constructing such collections naively is computationally intensive since the number of parent sets grows exponentially with the number of variables. Thus, pruning techniques are not only desirable but essential. While good pruning rules exist for the Bayesian Information Criterion (BIC), current results for the Bayesian Dirichlet equivalent uniform (BDeu) score reduce the search space very modestly, hampering the use of the (often preferred) BDeu. We derive new non-trivial theoretical upper bounds for the BDeu score that considerably improve on the state-of-the-art. Since the new bounds are mathematically proven to be tighter than previous ones and at little extra computational cost, they are a promising addition to BNSL methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/correia20a/correia20a.pdf",
        "supp": "",
        "pdf_size": 337548,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4806272012071396741&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "56aa997493",
        "title": "On Random Subsampling of Gaussian Process Regression: A Graphon-Based Analysis",
        "site": "https://proceedings.mlr.press/v108/hayashi20a.html",
        "author": "Kohei Hayashi; Masaaki Imaizumi; Yuichi Yoshida",
        "abstract": "In this paper, we study random subsampling of Gaussian process regression, one of the simplest approximation baselines, from a theoretical perspective. Although subsampling discards a large part of training data, we show provable guarantees on the accuracy of the predictive mean/variance and its generalization ability.For analysis, we consider embedding kernel matrices into graphons, which encapsulate the difference of the sample size and enables us to evaluate the approximation and generalization errors in a unified manner. The experimental results show that the subsampling approximation achieves a better trade-off regarding accuracy and runtime than the ystrom and random Fourier expansion methods.",
        "bibtex": "@InProceedings{pmlr-v108-hayashi20a,\n  title = \t {On Random Subsampling of Gaussian Process Regression: A Graphon-Based Analysis},\n  author =       {Hayashi, Kohei and Imaizumi, Masaaki and Yoshida, Yuichi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2055--2065},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hayashi20a/hayashi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hayashi20a.html},\n  abstract = \t {In this paper, we study random subsampling of Gaussian process regression, one of the simplest approximation baselines, from a theoretical perspective. Although subsampling discards a large part of training data, we show provable guarantees on the accuracy of the predictive mean/variance and its generalization ability.For analysis, we consider embedding kernel matrices into graphons, which encapsulate the difference of the sample size and enables us to evaluate the approximation and generalization errors in a unified manner. The experimental results show that the subsampling approximation achieves a better trade-off regarding accuracy and runtime than the ystrom and random Fourier expansion methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hayashi20a/hayashi20a.pdf",
        "supp": "",
        "pdf_size": 443959,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1161142425850634882&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6587dca110",
        "title": "On Thompson Sampling for Smoother-than-Lipschitz Bandits",
        "site": "https://proceedings.mlr.press/v108/grant20a.html",
        "author": "James Grant; David Leslie",
        "abstract": "Thompson Sampling is a well established approach to bandit and reinforcement learning problems. However its use in continuum armed bandit problems has received relatively little attention. We  provide the first bounds on the regret of Thompson Sampling for continuum armed bandits under weak conditions on the function class containing the true function and sub-exponential observation noise. The eluder dimension is a recently proposed measure of the complexity of a function class, which has been demonstrated to be useful in bounding the Bayesian regret of Thompson Sampling for simpler bandit problems under sub-Gaussian observation noise. We derive a new bound on the eluder dimension for classes of functions with Lipschitz derivatives, and generalise previous analyses in multiple regards.",
        "bibtex": "@InProceedings{pmlr-v108-grant20a,\n  title = \t {On Thompson Sampling for Smoother-than-Lipschitz Bandits},\n  author =       {Grant, James and Leslie, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2612--2622},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/grant20a/grant20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/grant20a.html},\n  abstract = \t {Thompson Sampling is a well established approach to bandit and reinforcement learning problems. However its use in continuum armed bandit problems has received relatively little attention. We  provide the first bounds on the regret of Thompson Sampling for continuum armed bandits under weak conditions on the function class containing the true function and sub-exponential observation noise. The eluder dimension is a recently proposed measure of the complexity of a function class, which has been demonstrated to be useful in bounding the Bayesian regret of Thompson Sampling for simpler bandit problems under sub-Gaussian observation noise. We derive a new bound on the eluder dimension for classes of functions with Lipschitz derivatives, and generalise previous analyses in multiple regards. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/grant20a/grant20a.pdf",
        "supp": "",
        "pdf_size": 512341,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6344840357778912165&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "STOR-i Centre for Doctoral Training, Lancaster University + Department of Mathematics and Statistics, Lancaster University and PROWLER.io; STOR-i Centre for Doctoral Training, Lancaster University + Department of Mathematics and Statistics, Lancaster University and PROWLER.io",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "Lancaster University",
        "aff_unique_dep": "STOR-i Centre for Doctoral Training",
        "aff_unique_url": "https://www.lancaster.ac.uk",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "d35fda7379",
        "title": "On casting importance weighted autoencoder to an EM algorithm to learn deep generative models",
        "site": "https://proceedings.mlr.press/v108/kim20b.html",
        "author": "Dongha Kim; Jaesung Hwang; Yongdai Kim",
        "abstract": "We propose a new and general approach to learn deep generative models. Our approach is based on a new observation that the importance weighted autoencoders (IWAE, Burda et al. (2015)) can be understood as a procedure of estimating the MLE with an EM algorithm. Utilizing this interpretation, we develop a new learning algorithm called importance weighted EM algorithm (IWEM). IWEM is an EM algorithm with self-normalized importance sampling (snIS) where the proposal distribution is carefully selected to reduce the variance due to snIS. In addition, we devise an annealing strategy to stabilize the learning algorithm. For missing data problems, we propose a modified IWEM algorithm called miss-IWEM. Using multiple benchmark datasets, we demonstrate empirically that our proposed methods outperform IWAE with significant margins for both fully-observed and missing data cases.",
        "bibtex": "@InProceedings{pmlr-v108-kim20b,\n  title = \t {On casting importance weighted autoencoder to an EM algorithm to learn deep generative models},\n  author =       {Kim, Dongha and Hwang, Jaesung and Kim, Yongdai},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2153--2163},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kim20b/kim20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kim20b.html},\n  abstract = \t {We propose a new and general approach to learn deep generative models. Our approach is based on a new observation that the importance weighted autoencoders (IWAE, Burda et al. (2015)) can be understood as a procedure of estimating the MLE with an EM algorithm. Utilizing this interpretation, we develop a new learning algorithm called importance weighted EM algorithm (IWEM). IWEM is an EM algorithm with self-normalized importance sampling (snIS) where the proposal distribution is carefully selected to reduce the variance due to snIS. In addition, we devise an annealing strategy to stabilize the learning algorithm. For missing data problems, we propose a modified IWEM algorithm called miss-IWEM. Using multiple benchmark datasets, we demonstrate empirically that our proposed methods outperform IWAE with significant margins for both fully-observed and missing data cases.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kim20b/kim20b.pdf",
        "supp": "",
        "pdf_size": 496742,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7551459946803731442&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "29f53671c0",
        "title": "On the Completeness of Causal Discovery in the Presence of Latent Confounding with Tiered Background Knowledge",
        "site": "https://proceedings.mlr.press/v108/andrews20a.html",
        "author": "Bryan Andrews; Peter Spirtes; Gregory F. Cooper",
        "abstract": "The discovery of causal relationships is a core part of scientific research. Accordingly, over the past several decades, algorithms have been developed to discover the causal structure for a system of variables from observational data. Learning ancestral graphs is of particular interest due to their ability to represent latent confounding implicitly with bi-directed edges. The well-known FCI algorithm provably recovers an ancestral graph for a system of variables encoding the sound and complete set of causal relationships identifiable from observational data. Additional causal relationships become identifiable with the incorporation of background knowledge; however, it is not known for what types of knowledge FCI remains complete. In this paper, we define tiered background knowledge and show that FCI is sound and complete with the incorporation of this knowledge.",
        "bibtex": "@InProceedings{pmlr-v108-andrews20a,\n  title = \t {On the Completeness of Causal Discovery in the Presence of Latent Confounding with Tiered Background Knowledge},\n  author =       {Andrews, Bryan and Spirtes, Peter and Cooper, Gregory F.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4002--4011},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/andrews20a/andrews20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/andrews20a.html},\n  abstract = \t {The discovery of causal relationships is a core part of scientific research. Accordingly, over the past several decades, algorithms have been developed to discover the causal structure for a system of variables from observational data. Learning ancestral graphs is of particular interest due to their ability to represent latent confounding implicitly with bi-directed edges. The well-known FCI algorithm provably recovers an ancestral graph for a system of variables encoding the sound and complete set of causal relationships identifiable from observational data. Additional causal relationships become identifiable with the incorporation of background knowledge; however, it is not known for what types of knowledge FCI remains complete. In this paper, we define tiered background knowledge and show that FCI is sound and complete with the incorporation of this knowledge.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/andrews20a/andrews20a.pdf",
        "supp": "",
        "pdf_size": 314888,
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=358145189740766269&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ae2960417f",
        "title": "On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning Algorithms",
        "site": "https://proceedings.mlr.press/v108/fallah20a.html",
        "author": "Alireza Fallah; Aryan Mokhtari; Asuman Ozdaglar",
        "abstract": "We study the convergence of a class of gradient-based Model-Agnostic Meta-Learning (MAML) methods and characterize their overall complexity as well as their best achievable accuracy in terms of gradient norm for nonconvex loss functions. We start with the MAML method and its first-order approximation (FO-MAML) and highlight the challenges that emerge in their analysis. By overcoming these challenges not only we provide the first theoretical guarantees for MAML and FO-MAML in nonconvex settings, but also we answer some of the unanswered questions for the implementation of these algorithms including how to choose their learning rate and the batch size for both tasks and  datasets corresponding to tasks. In particular, we show that MAML can find an ?-first-order stationary point ( ?-FOSP) for any positive  ? after at most O(1/?^2) iterations at the expense of requiring second-order information. We also show that FO-MAML which ignores the second-order information required in the update of MAML cannot achieve any small desired level of accuracy, i.e., FO-MAML cannot find an  ?-FOSP for any  ?>0. We  further propose a new variant of the MAML algorithm called Hessian-free MAML which preserves all theoretical guarantees of MAML, without requiring access to second-order information.",
        "bibtex": "@InProceedings{pmlr-v108-fallah20a,\n  title = \t {On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning Algorithms},\n  author =       {Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1082--1092},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fallah20a/fallah20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fallah20a.html},\n  abstract = \t {We study the convergence of a class of gradient-based Model-Agnostic Meta-Learning (MAML) methods and characterize their overall complexity as well as their best achievable accuracy in terms of gradient norm for nonconvex loss functions. We start with the MAML method and its first-order approximation (FO-MAML) and highlight the challenges that emerge in their analysis. By overcoming these challenges not only we provide the first theoretical guarantees for MAML and FO-MAML in nonconvex settings, but also we answer some of the unanswered questions for the implementation of these algorithms including how to choose their learning rate and the batch size for both tasks and  datasets corresponding to tasks. In particular, we show that MAML can find an ?-first-order stationary point ( ?-FOSP) for any positive  ? after at most O(1/?^2) iterations at the expense of requiring second-order information. We also show that FO-MAML which ignores the second-order information required in the update of MAML cannot achieve any small desired level of accuracy, i.e., FO-MAML cannot find an  ?-FOSP for any  ?>0. We  further propose a new variant of the MAML algorithm called Hessian-free MAML which preserves all theoretical guarantees of MAML, without requiring access to second-order information.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fallah20a/fallah20a.pdf",
        "supp": "",
        "pdf_size": 4086000,
        "gs_citation": 287,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3532055573528519216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f9ef9aa4a4",
        "title": "On the Convergence of SARAH and Beyond",
        "site": "https://proceedings.mlr.press/v108/li20a.html",
        "author": "Bingcong Li; Meng Ma; Georgios B. Giannakis",
        "abstract": "The main theme of this work is a unifying algorithm, \\textbf{L}oop\\textbf{L}ess \\textbf{S}ARAH (L2S) for problems formulated as summation of $n$ individual loss functions. L2S broadens a recently developed variance reduction method known as SARAH. To find an $\\epsilon$-accurate solution, L2S enjoys a complexity of ${\\cal O}\\big( (n+\\kappa) \\ln (1/\\epsilon)\\big)$ for strongly convex problems. For convex problems, when adopting an $n$-dependent step size, the complexity of L2S is ${\\cal O}(n+ \\sqrt{n}/\\epsilon)$; while for more frequently adopted $n$-independent step size, the complexity is ${\\cal O}(n+ n/\\epsilon)$. Distinct from SARAH, our theoretical findings support an $n$-independent step size in convex problems without extra assumptions. For nonconvex problems, the complexity of L2S is ${\\cal O}(n+ \\sqrt{n}/\\epsilon)$. Our numerical tests on neural networks suggest that L2S can have better generalization properties than SARAH. Along with L2S, our side results include the linear convergence of the last iteration for SARAH in strongly convex problems.",
        "bibtex": "@InProceedings{pmlr-v108-li20a,\n  title = \t {On the Convergence of SARAH and Beyond},\n  author =       {Li, Bingcong and Ma, Meng and Giannakis, Georgios B.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {223--233},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20a/li20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20a.html},\n  abstract = \t {The main theme of this work is a unifying algorithm, \\textbf{L}oop\\textbf{L}ess \\textbf{S}ARAH (L2S) for problems formulated as summation of $n$ individual loss functions. L2S broadens a recently developed variance reduction method known as SARAH. To find an $\\epsilon$-accurate solution, L2S enjoys a complexity of ${\\cal O}\\big( (n+\\kappa) \\ln (1/\\epsilon)\\big)$ for strongly convex problems. For convex problems, when adopting an $n$-dependent step size, the complexity of L2S is ${\\cal O}(n+ \\sqrt{n}/\\epsilon)$; while for more frequently adopted $n$-independent step size, the complexity is ${\\cal O}(n+ n/\\epsilon)$. Distinct from SARAH, our theoretical findings support an $n$-independent step size in convex problems without extra assumptions. For nonconvex problems, the complexity of L2S is ${\\cal O}(n+ \\sqrt{n}/\\epsilon)$. Our numerical tests on neural networks suggest that L2S can have better generalization properties than SARAH. Along with L2S, our side results include the linear convergence of the last iteration for SARAH in strongly convex problems. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20a/li20a.pdf",
        "supp": "",
        "pdf_size": 517309,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2292137377906675540&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3f801b4848",
        "title": "On the Sample Complexity of Learning Sum-Product Networks",
        "site": "https://proceedings.mlr.press/v108/aden-ali20a.html",
        "author": "Ishaq Aden-Ali; Hassan Ashtiani",
        "abstract": "Sum-Product Networks (SPNs) can be regarded as a form of deep graphical models that compactly represent deeply factored and mixed distributions. An SPN is a rooted directed acyclic graph (DAG) consisting of a set of leaves (corresponding to base distributions), a set of sum nodes (which represent mixtures of their children distributions) and a set of product nodes (representing the products of its children distributions). In this work, we initiate the study of the sample complexity of PAC-learning the set of distributions that correspond to SPNs. We show that the sample complexity of learning tree structured SPNs with the usual type of leaves (i.e., Gaussian or discrete) grows at most linearly (up to logarithmic factors) with the number of parameters of the SPN.More specifically, we show that the class of distributions that corresponds to tree structured Gaussian SPNs with $k$ mixing weights and $e$ ($d$-dimensional Gaussian) leaves can be learned within Total Variation error $\\epsilon$ using at most $\\widetilde{O}(\\frac{ed^2+k}{\\epsilon^2})$ samples. A similar result holds for tree structured SPNs with discrete leaves. We obtain the upper bounds based on the recently proposed notion of distribution compression schemes. More specifically, we show that if a (base) class of distributions $\\cF$ admits an \u201cefficient\u201d compression, then the class of tree structured SPNs with leaves from $\\cF$ also admits an efficient compression.",
        "bibtex": "@InProceedings{pmlr-v108-aden-ali20a,\n  title = \t {On the Sample Complexity of Learning Sum-Product Networks},\n  author =       {Aden-Ali, Ishaq and Ashtiani, Hassan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4508--4518},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/aden-ali20a/aden-ali20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/aden-ali20a.html},\n  abstract = \t {Sum-Product Networks (SPNs) can be regarded as a form of deep graphical models that compactly represent deeply factored and mixed distributions. An SPN is a rooted directed acyclic graph (DAG) consisting of a set of leaves (corresponding to base distributions), a set of sum nodes (which represent mixtures of their children distributions) and a set of product nodes (representing the products of its children distributions). In this work, we initiate the study of the sample complexity of PAC-learning the set of distributions that correspond to SPNs. We show that the sample complexity of learning tree structured SPNs with the usual type of leaves (i.e., Gaussian or discrete) grows at most linearly (up to logarithmic factors) with the number of parameters of the SPN.More specifically, we show that the class of distributions that corresponds to tree structured Gaussian SPNs with $k$ mixing weights and $e$ ($d$-dimensional Gaussian) leaves can be learned within Total Variation error $\\epsilon$ using at most $\\widetilde{O}(\\frac{ed^2+k}{\\epsilon^2})$ samples. A similar result holds for tree structured SPNs with discrete leaves. We obtain the upper bounds based on the recently proposed notion of distribution compression schemes. More specifically, we show that if a (base) class of distributions $\\cF$ admits an \u201cefficient\u201d compression, then the class of tree structured SPNs with leaves from $\\cF$ also admits an efficient compression.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/aden-ali20a/aden-ali20a.pdf",
        "supp": "",
        "pdf_size": 327338,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7854424187397406758&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "McMaster University; McMaster University",
        "aff_domain": "mcmaster.ca;mcmaster.ca",
        "email": "mcmaster.ca;mcmaster.ca",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McMaster University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mcmaster.ca",
        "aff_unique_abbr": "McMaster",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "09da4ae240",
        "title": "On the interplay between noise and curvature and its effect on optimization and generalization",
        "site": "https://proceedings.mlr.press/v108/thomas20a.html",
        "author": "Valentin Thomas; Fabian Pedregosa; Bart Merri\u00ebnboer; Pierre-Antoine Manzagol; Yoshua Bengio; Nicolas Le Roux",
        "abstract": "The speed at which one can minimize an expected loss using stochastic methods depends on two properties: the curvature of the loss and the variance of the gradients. While most previous works focus on one or the other of these properties, we explore how their interaction affects optimization speed. Further, as the ultimate goal is good generalization performance, we clarify how both curvature and noise are relevant to properly estimate the generalization gap. Realizing that the limitations of some existing works stems from a confusion between these matrices, we also clarify the distinction between the Fisher matrix, the Hessian, and the covariance matrix of the gradients.",
        "bibtex": "@InProceedings{pmlr-v108-thomas20a,\n  title = \t {On the interplay between noise and curvature and its effect on optimization and generalization},\n  author =       {Thomas, Valentin and Pedregosa, Fabian and van Merri\\\"enboer, Bart and Manzagol, Pierre-Antoine and Bengio, Yoshua and Roux, Nicolas Le},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3503--3513},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/thomas20a/thomas20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/thomas20a.html},\n  abstract = \t { The speed at which one can minimize an expected loss using stochastic methods depends on two properties: the curvature of the loss and the variance of the gradients. While most previous works focus on one or the other of these properties, we explore how their interaction affects optimization speed. Further, as the ultimate goal is good generalization performance, we clarify how both curvature and noise are relevant to properly estimate the generalization gap. Realizing that the limitations of some existing works stems from a confusion between these matrices, we also clarify the distinction between the Fisher matrix, the Hessian, and the covariance matrix of the gradients.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/thomas20a/thomas20a.pdf",
        "supp": "",
        "pdf_size": 5711686,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10248413863436507228&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Google Research, Brain Team; Google Research, Brain Team; Google Research, Brain Team; Mila, Universit\u00e9 de Montr\u00e9al CIFAR Senior Fellow; Google Research, Brain Team Mila, McGill University",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;Google",
        "aff_unique_dep": "Mila;Google Research",
        "aff_unique_url": "https://umontreal.ca;https://research.google",
        "aff_unique_abbr": "UdeM;Google",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Montr\u00e9al;Mountain View;Montreal;",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "bd2d67fa74",
        "title": "On the optimality of kernels for high-dimensional clustering",
        "site": "https://proceedings.mlr.press/v108/vankadara20a.html",
        "author": "Leena C Vankadara; Debarghya Ghoshdastidar",
        "abstract": "This paper studies the optimality of kernel methods in high dimensional data clustering. Recent works have studied the large sample performance of kernel clustering in the high dimensional regime, where Euclidean distance becomes less informative. However, it is unknown whether popular methods, such as kernel k-means, are optimal in this regime.   We consider the problem of high dimensional Gaussian clustering and show that, with the exponential kernel function, the sufficient conditions for partial recovery of clusters using the NP-hard kernel k-means objective matches the known information-theoretic limit up to a factor of $\\sqrt{2}$. It also exactly matches the known upper bounds for the non-kernel setting. We also show that a semi-definite relaxation of the kernel k-means procedure matches up to constant factors, the spectral threshold, below which no polynomial-time algorithm is known to succeed. This is the first work that provides such optimality guarantees for the kernel k-means as well as its convex relaxation. Our proofs demonstrate the utility of the less known polynomial concentration results for random variables with exponentially decaying tails in the higher-order analysis of kernel methods.",
        "bibtex": "@InProceedings{pmlr-v108-vankadara20a,\n  title = \t {On the optimality of kernels for high-dimensional clustering},\n  author =       {Vankadara, Leena C and Ghoshdastidar, Debarghya},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2185--2195},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/vankadara20a/vankadara20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/vankadara20a.html},\n  abstract = \t { This paper studies the optimality of kernel methods in high dimensional data clustering. Recent works have studied the large sample performance of kernel clustering in the high dimensional regime, where Euclidean distance becomes less informative. However, it is unknown whether popular methods, such as kernel k-means, are optimal in this regime.   We consider the problem of high dimensional Gaussian clustering and show that, with the exponential kernel function, the sufficient conditions for partial recovery of clusters using the NP-hard kernel k-means objective matches the known information-theoretic limit up to a factor of $\\sqrt{2}$. It also exactly matches the known upper bounds for the non-kernel setting. We also show that a semi-definite relaxation of the kernel k-means procedure matches up to constant factors, the spectral threshold, below which no polynomial-time algorithm is known to succeed. This is the first work that provides such optimality guarantees for the kernel k-means as well as its convex relaxation. Our proofs demonstrate the utility of the less known polynomial concentration results for random variables with exponentially decaying tails in the higher-order analysis of kernel methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/vankadara20a/vankadara20a.pdf",
        "supp": "",
        "pdf_size": 377627,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14671314897639287247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of T\u00fcbingen, IMPRS-IS; Technical University of Munich",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of T\u00fcbingen;Technical University of Munich",
        "aff_unique_dep": "IMPRS-IS;",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.tum.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "86747f06ae",
        "title": "One Sample Stochastic Frank-Wolfe",
        "site": "https://proceedings.mlr.press/v108/zhang20i.html",
        "author": "Mingrui Zhang; Zebang Shen; Aryan Mokhtari; Hamed Hassani; Amin Karbasi",
        "abstract": "One of the beauties of the projected gradient descent method lies in its rather simple mechanism and yet stable  behavior with inexact, stochastic  gradients, which has led to its wide-spread use in many machine learning applications. However, once we replace the projection operator with a simpler linear program, as is done in the Frank-Wolfe method, both simplicity and  stability take a serious hit. The aim of this paper is to bring them back without sacrificing the efficiency.  In this paper, we propose the first one-sample stochastic Frank-Wolfe algorithm, called 1-SFW,  that avoids the need to carefully tune the batch size, step size, learning rate, and other complicated hyper parameters. In particular, 1-SFW achieves the optimal  convergence rate  of $\\mathcal{O}(1/\\epsilon^2)$  for reaching an  $\\epsilon$-suboptimal solution in the stochastic convex setting, and a $(1-1/e)-\\epsilon$ approximate solution for a stochastic  monotone DR-submodular maximization problem. Moreover, in a general non-convex setting, 1-SFW finds an $\\epsilon$-first-order stationary point after at most $\\mathcal{O}(1/\\epsilon^3)$ iterations, achieving the current best known convergence rate. All of this is possible by designing a novel unbiased momentum estimator that governs the stability of the optimization process while using a single sample at each iteration.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20i,\n  title = \t {One Sample Stochastic Frank-Wolfe},\n  author =       {Zhang, Mingrui and Shen, Zebang and Mokhtari, Aryan and Hassani, Hamed and Karbasi, Amin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4012--4023},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20i/zhang20i.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20i.html},\n  abstract = \t {One of the beauties of the projected gradient descent method lies in its rather simple mechanism and yet stable  behavior with inexact, stochastic  gradients, which has led to its wide-spread use in many machine learning applications. However, once we replace the projection operator with a simpler linear program, as is done in the Frank-Wolfe method, both simplicity and  stability take a serious hit. The aim of this paper is to bring them back without sacrificing the efficiency.  In this paper, we propose the first one-sample stochastic Frank-Wolfe algorithm, called 1-SFW,  that avoids the need to carefully tune the batch size, step size, learning rate, and other complicated hyper parameters. In particular, 1-SFW achieves the optimal  convergence rate  of $\\mathcal{O}(1/\\epsilon^2)$  for reaching an  $\\epsilon$-suboptimal solution in the stochastic convex setting, and a $(1-1/e)-\\epsilon$ approximate solution for a stochastic  monotone DR-submodular maximization problem. Moreover, in a general non-convex setting, 1-SFW finds an $\\epsilon$-first-order stationary point after at most $\\mathcal{O}(1/\\epsilon^3)$ iterations, achieving the current best known convergence rate. All of this is possible by designing a novel unbiased momentum estimator that governs the stability of the optimization process while using a single sample at each iteration.  }\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20i/zhang20i.pdf",
        "supp": "",
        "pdf_size": 568285,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9509007533883895611&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Yale University; University of Pennsylvania; University of Texas at Austin; University of Pennsylvania; Yale University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Yale University;University of Pennsylvania;University of Texas at Austin",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.yale.edu;https://www.upenn.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Yale;UPenn;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "93546930b3",
        "title": "Online Batch Decision-Making with High-Dimensional Covariates",
        "site": "https://proceedings.mlr.press/v108/wang20k.html",
        "author": "Chi-Hua Wang; Guang Cheng",
        "abstract": "We propose and investigate a class of new algorithms for sequential decision making that interacts with a batch of users simultaneously instead of a user at each decision epoch. This type of batch models is motivated by interactive marketing and clinical trial, where a group of people are treated simultaneously and the outcomes of the whole group are collected before the next stage of decision. In such a scenario, our goal is to allocate a batch of treatments to maximize treatment efficacy based on observed high-dimensional user covariates. We deliver a solution, named Teamwork LASSO Bandit algorithm, that resolves a batch version of explore-exploit dilemma via switching between teamwork stage and selfish stage during the whole decision process. This is made possible based on statistical properties of LASSO estimate of treatment efficacy that adapts to a sequence of batch observations. In general, a rate of optimal allocation condition is proposed to delineate the exploration and exploitation trade-off on the data collection scheme, which is sufficient for LASSO to identify the optimal treatment for observed user covariates. An upper bound on expected cumulative regret of the proposed algorithm is provided.",
        "bibtex": "@InProceedings{pmlr-v108-wang20k,\n  title = \t {Online Batch Decision-Making with High-Dimensional Covariates},\n  author =       {Wang, Chi-Hua and Cheng, Guang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3848--3857},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20k/wang20k.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20k.html},\n  abstract = \t {We propose and investigate a class of new algorithms for sequential decision making that interacts with a batch of users simultaneously instead of a user at each decision epoch. This type of batch models is motivated by interactive marketing and clinical trial, where a group of people are treated simultaneously and the outcomes of the whole group are collected before the next stage of decision. In such a scenario, our goal is to allocate a batch of treatments to maximize treatment efficacy based on observed high-dimensional user covariates. We deliver a solution, named Teamwork LASSO Bandit algorithm, that resolves a batch version of explore-exploit dilemma via switching between teamwork stage and selfish stage during the whole decision process. This is made possible based on statistical properties of LASSO estimate of treatment efficacy that adapts to a sequence of batch observations. In general, a rate of optimal allocation condition is proposed to delineate the exploration and exploitation trade-off on the data collection scheme, which is sufficient for LASSO to identify the optimal treatment for observed user covariates. An upper bound on expected cumulative regret of the proposed algorithm is provided.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20k/wang20k.pdf",
        "supp": "",
        "pdf_size": 958128,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8175252742309310871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Purdue University; Purdue University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5f806f018c",
        "title": "Online Binary Space Partitioning Forests",
        "site": "https://proceedings.mlr.press/v108/fan20a.html",
        "author": "Xuhui Fan; Bin Li; Scott SIsson",
        "abstract": "The Binary Space Partitioning-Tree\u00a0(BSP-Tree) process was recently proposed as an efficient strategy for space partitioning tasks. Because it uses more than one dimension to partition the space, the BSP-Tree process is more efficient and flexible than conventional axis-aligned cut strategies. However, due to its batch learning setting, it is not well suited to large-scale classification and regression problems. In this paper, we develop an online BSP-Forest framework to address this limitation. With the arrival of new data, the resulting online algorithm can simultaneously expand the space coverage and refine the partition structure, with guaranteed universal consistency for classification problems. The effectiveness and competitive performance of the online BSP-Forest is verified via simulations.",
        "bibtex": "@InProceedings{pmlr-v108-fan20a,\n  title = \t {Online Binary Space Partitioning Forests},\n  author =       {Fan, Xuhui and Li, Bin and SIsson, Scott},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {527--537},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/fan20a/fan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/fan20a.html},\n  abstract = \t {The Binary Space Partitioning-Tree\u00a0(BSP-Tree) process was recently proposed as an efficient strategy for space partitioning tasks. Because it uses more than one dimension to partition the space, the BSP-Tree process is more efficient and flexible than conventional axis-aligned cut strategies. However, due to its batch learning setting, it is not well suited to large-scale classification and regression problems. In this paper, we develop an online BSP-Forest framework to address this limitation. With the arrival of new data, the resulting online algorithm can simultaneously expand the space coverage and refine the partition structure, with guaranteed universal consistency for classification problems. The effectiveness and competitive performance of the online BSP-Forest is verified via simulations.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/fan20a/fan20a.pdf",
        "supp": "",
        "pdf_size": 843222,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14696262057357748389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "School of Mathematics and Statistics, University of New South Wales; School of Computer Science, Fudan University; School of Mathematics and Statistics, University of New South Wales",
        "aff_domain": "unsw.edu.au;fudan.edu.cn;unsw.edu.au",
        "email": "unsw.edu.au;fudan.edu.cn;unsw.edu.au",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of New South Wales;Fudan University",
        "aff_unique_dep": "School of Mathematics and Statistics;School of Computer Science",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.fudan.edu.cn",
        "aff_unique_abbr": "UNSW;Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "f753cae7ab",
        "title": "Online Continuous DR-Submodular Maximization with Long-Term Budget Constraints",
        "site": "https://proceedings.mlr.press/v108/sadeghi20a.html",
        "author": "Omid Sadeghi; Maryam Fazel",
        "abstract": "In this paper, we study a class of online optimization problems with long-term budget constraints where the objective functions are not necessarily concave (nor convex), but they instead satisfy the Diminishing Returns (DR) property. In this online setting, a sequence of monotone DR-submodular objective functions and linear budget functions arrive over time and assuming a limited total budget, the goal is to take actions at each time, before observing the utility and budget function arriving at that round, to achieve sub-linear regret bound while the total budget violation is sub-linear as well. Prior work has shown that achieving sub-linear regret and total budget violation simultaneously is impossible if the utility and budget functions are chosen adversarially. Therefore, we modify the notion of regret by comparing the agent against the best fixed decision in hindsight which satisfies the budget constraint proportionally over any window of length $W$. We propose the Online Saddle Point Hybrid Gradient (OSPHG) algorithm to solve this class of online problems. For $W=T$, we recover the aforementioned impossibility result. However, if $W$ is sub-linear in $T$, we show that it is possible to obtain sub-linear bounds for both the regret and the total budget violation.",
        "bibtex": "@InProceedings{pmlr-v108-sadeghi20a,\n  title = \t {Online Continuous DR-Submodular Maximization with Long-Term Budget Constraints},\n  author =       {Sadeghi, Omid and Fazel, Maryam},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4410--4419},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sadeghi20a/sadeghi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sadeghi20a.html},\n  abstract = \t {In this paper, we study a class of online optimization problems with long-term budget constraints where the objective functions are not necessarily concave (nor convex), but they instead satisfy the Diminishing Returns (DR) property. In this online setting, a sequence of monotone DR-submodular objective functions and linear budget functions arrive over time and assuming a limited total budget, the goal is to take actions at each time, before observing the utility and budget function arriving at that round, to achieve sub-linear regret bound while the total budget violation is sub-linear as well. Prior work has shown that achieving sub-linear regret and total budget violation simultaneously is impossible if the utility and budget functions are chosen adversarially. Therefore, we modify the notion of regret by comparing the agent against the best fixed decision in hindsight which satisfies the budget constraint proportionally over any window of length $W$. We propose the Online Saddle Point Hybrid Gradient (OSPHG) algorithm to solve this class of online problems. For $W=T$, we recover the aforementioned impossibility result. However, if $W$ is sub-linear in $T$, we show that it is possible to obtain sub-linear bounds for both the regret and the total budget violation.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sadeghi20a/sadeghi20a.pdf",
        "supp": "",
        "pdf_size": 433635,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7398975070379716581&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "University of Washington; University of Washington",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d9fbd68770",
        "title": "Online Convex Optimization with Perturbed Constraints: Optimal Rates against Stronger Benchmarks",
        "site": "https://proceedings.mlr.press/v108/valls20a.html",
        "author": "Victor Valls; George Iosifidis; Douglas Leith; Leandros Tassiulas",
        "abstract": "This paper studies Online Convex Optimization (OCO) problems where the constraints have additive perturbations that (i) vary over time and (ii) are not known at the time to make a decision. Perturbations may not be i.i.d. generated and can be used, for example, to model a time-varying budget or time-varying requests in resource allocation problems. Our goal is to design a policy that obtains sublinear regret and satisfies the constraints in the long-term. To this end, we present an online primal-dual proximal gradient algorithm that has $O(T^\\epsilon \\vee T^{1-\\epsilon})$ regret and $O(T^\\epsilon)$ constraint violation, where $\\epsilon \\in [0,1)$ is a parameter in the learning rate. The proposed algorithm obtains optimal rates when $\\epsilon = 1/2$, and can compare against a stronger comparator (the set of fixed decisions in hindsight) than previous work.",
        "bibtex": "@InProceedings{pmlr-v108-valls20a,\n  title = \t {Online Convex Optimization with Perturbed Constraints: Optimal Rates against Stronger Benchmarks},\n  author =       {Valls, Victor and Iosifidis, George and Leith, Douglas and Tassiulas, Leandros},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2885--2895},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/valls20a/valls20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/valls20a.html},\n  abstract = \t {This paper studies Online Convex Optimization (OCO) problems where the constraints have additive perturbations that (i) vary over time and (ii) are not known at the time to make a decision. Perturbations may not be i.i.d. generated and can be used, for example, to model a time-varying budget or time-varying requests in resource allocation problems. Our goal is to design a policy that obtains sublinear regret and satisfies the constraints in the long-term. To this end, we present an online primal-dual proximal gradient algorithm that has $O(T^\\epsilon \\vee T^{1-\\epsilon})$ regret and $O(T^\\epsilon)$ constraint violation, where $\\epsilon \\in [0,1)$ is a parameter in the learning rate. The proposed algorithm obtains optimal rates when $\\epsilon = 1/2$, and can compare against a stronger comparator (the set of fixed decisions in hindsight) than previous work. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/valls20a/valls20a.pdf",
        "supp": "",
        "pdf_size": 592437,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f18c2d472a",
        "title": "Online Learning Using Only Peer Prediction",
        "site": "https://proceedings.mlr.press/v108/liu20d.html",
        "author": "Yang Liu; Dave Helmbold",
        "abstract": "This paper considers a variant of the classical online learning problem with expert predictions. Our model\u2019s differences and challenges are due to lacking any direct feedback on the loss each expert incurs at each time step $t$. We propose an approach that uses peer prediction and identify conditions where it succeeds. Our techniques revolve around a carefully designed peer score function $s()$ that scores experts\u2019 predictions based on the peer consensus. We show a sufficient condition, that we call \\emph{peer calibration}, under which standard online learning algorithms using loss feedback computed by the carefully crafted $s()$ have bounded regret with respect to the unrevealed ground truth values. We then demonstrate how suitable $s()$ functions can be derived for different assumptions and models.",
        "bibtex": "@InProceedings{pmlr-v108-liu20d,\n  title = \t {Online Learning Using Only Peer Prediction},\n  author =       {Liu, Yang and Helmbold, Dave},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2032--2042},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/liu20d/liu20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/liu20d.html},\n  abstract = \t {This paper considers a variant of the classical online learning problem with expert predictions. Our model\u2019s differences and challenges are due to lacking any direct feedback on the loss each expert incurs at each time step $t$. We propose an approach that uses peer prediction and identify conditions where it succeeds. Our techniques revolve around a carefully designed peer score function $s()$ that scores experts\u2019 predictions based on the peer consensus. We show a sufficient condition, that we call \\emph{peer calibration}, under which standard online learning algorithms using loss feedback computed by the carefully crafted $s()$ have bounded regret with respect to the unrevealed ground truth values. We then demonstrate how suitable $s()$ functions can be derived for different assumptions and models.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/liu20d/liu20d.pdf",
        "supp": "",
        "pdf_size": 142316,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17054311653089366855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Computer Science and Engineering, University of California, Santa Cruz; Computer Science and Engineering, University of California, Santa Cruz",
        "aff_domain": "ucsc.edu;soe.ucsc.edu",
        "email": "ucsc.edu;soe.ucsc.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Santa Cruz",
        "aff_unique_dep": "Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsc.edu",
        "aff_unique_abbr": "UCSC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Cruz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "92ce68f6f4",
        "title": "Online Learning with Continuous Variations: Dynamic Regret and Reductions",
        "site": "https://proceedings.mlr.press/v108/cheng20a.html",
        "author": "Ching-An Cheng; Jonathan Lee; Ken Goldberg; Byron Boots",
        "abstract": "Online learning is a powerful tool for analyzing iterative algorithms. However, the classic adversarial setup fails to capture regularity  that can exist in practice. Motivated by this observation, we establish a new setup, called Continuous Online Learning (COL), where the gradient of online loss function changes continuously across rounds with respect to the learner\u2019s decisions. We show that COL appropriately describes many interesting applications, from general equilibrium problems (EPs) to optimization in episodic MDPs. Using this new setup, we revisit the difficulty of sublinear dynamic regret. We prove a fundamental equivalence between achieving sublinear dynamic regret in COL and solving certain EPs. With this insight, we offer conditions for efficient algorithms that achieve sublinear dynamic regret, even when the losses are chosen adaptively without any a priori variation budget. Furthermore, we show for COL a reduction from dynamic regret to both static regret and convergence in the associated EP, allowing us to analyze the dynamic regret of many existing algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-cheng20a,\n  title = \t {Online Learning with Continuous Variations: Dynamic Regret and Reductions},\n  author =       {Cheng, Ching-An and Lee, Jonathan and Goldberg, Ken and Boots, Byron},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2218--2228},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cheng20a/cheng20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cheng20a.html},\n  abstract = \t {Online learning is a powerful tool for analyzing iterative algorithms. However, the classic adversarial setup fails to capture regularity  that can exist in practice. Motivated by this observation, we establish a new setup, called Continuous Online Learning (COL), where the gradient of online loss function changes continuously across rounds with respect to the learner\u2019s decisions. We show that COL appropriately describes many interesting applications, from general equilibrium problems (EPs) to optimization in episodic MDPs. Using this new setup, we revisit the difficulty of sublinear dynamic regret. We prove a fundamental equivalence between achieving sublinear dynamic regret in COL and solving certain EPs. With this insight, we offer conditions for efficient algorithms that achieve sublinear dynamic regret, even when the losses are chosen adaptively without any a priori variation budget. Furthermore, we show for COL a reduction from dynamic regret to both static regret and convergence in the associated EP, allowing us to analyze the dynamic regret of many existing algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cheng20a/cheng20a.pdf",
        "supp": "",
        "pdf_size": 341873,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3548002543785302014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5eb5a5147b",
        "title": "Optimal Algorithms for Multiplayer Multi-Armed Bandits",
        "site": "https://proceedings.mlr.press/v108/wang20m.html",
        "author": "PO-AN WANG; Alexandre Proutiere; Kaito Ariu; Yassir Jedra; Alessio Russo",
        "abstract": "The paper addresses various Multiplayer Multi-Armed Bandit (MMAB) problems, where M decision-makers, or players, collaborate to maximize their cumulative reward. We first investigate the MMAB problem where players selecting the same arms experience a collision (and are aware of it) and do not collect any reward. For this problem, we present DPE1 (Decentralized Parsimonious Exploration), a decentralized algorithm that achieves the same asymptotic regret as that obtained by an optimal centralized algorithm. DPE1 is simpler than the state-of-the-art algorithm SIC-MMAB Boursier and Perchet (2019), and yet offers better performance guarantees. We then study the MMAB problem without collision, where players may select the same arm. Players sit on vertices of a graph, and in each round, they are able to send a message to their neighbours in the graph. We present DPE2, a simple and asymptotically optimal algorithm that outperforms the state-of-the-art algorithm DD- UCB Martinez-Rubio et al. (2019). Besides, under DPE2, the expected number of bits transmitted by the players in the graph is finite.",
        "bibtex": "@InProceedings{pmlr-v108-wang20m,\n  title = \t {Optimal Algorithms for Multiplayer Multi-Armed Bandits},\n  author =       {WANG, PO-AN and Proutiere, Alexandre and Ariu, Kaito and Jedra, Yassir and Russo, Alessio},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4120--4129},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20m/wang20m.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20m.html},\n  abstract = \t {The paper addresses various Multiplayer Multi-Armed Bandit (MMAB) problems, where M decision-makers, or players, collaborate to maximize their cumulative reward. We first investigate the MMAB problem where players selecting the same arms experience a collision (and are aware of it) and do not collect any reward. For this problem, we present DPE1 (Decentralized Parsimonious Exploration), a decentralized algorithm that achieves the same asymptotic regret as that obtained by an optimal centralized algorithm. DPE1 is simpler than the state-of-the-art algorithm SIC-MMAB Boursier and Perchet (2019), and yet offers better performance guarantees. We then study the MMAB problem without collision, where players may select the same arm. Players sit on vertices of a graph, and in each round, they are able to send a message to their neighbours in the graph. We present DPE2, a simple and asymptotically optimal algorithm that outperforms the state-of-the-art algorithm DD- UCB Martinez-Rubio et al. (2019). Besides, under DPE2, the expected number of bits transmitted by the players in the graph is finite.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20m/wang20m.pdf",
        "supp": "",
        "pdf_size": 477088,
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3844710123801831565&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "KTH, Royal Institute of Technology; KTH, Royal Institute of Technology; KTH, Royal Institute of Technology; KTH, Royal Institute of Technology; KTH, Royal Institute of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Royal Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "d92e397efa",
        "title": "Optimal Approximation of Doubly Stochastic Matrices",
        "site": "https://proceedings.mlr.press/v108/rontsis20a.html",
        "author": "Nikitas Rontsis; Paul Goulart",
        "abstract": "We consider the least-squares approximation of a matrix C in the set of doubly stochastic matrices with the same sparsity pattern as C. Our approach is based on applying the well-known Alternating Direction Method of Multipliers (ADMM) to a reformulation of the original problem. Our resulting algorithm requires an initial Cholesky factorization of a positive definite matrix that has the same sparsity pattern as C + I followed by simple iterations whose complexity is linear in the number of nonzeros in C, thus ensuring excellent scalability and speed. We demonstrate the advantages of our approach in a series of experiments on problems with up to 82 million nonzeros; these include normalizing large scale matrices arising from the 3D structure of the human genome, clustering applications, and the SuiteSparse matrix library. Overall, our experiments illustrate the outstanding scalability of our algorithm; matrices with millions of nonzeros can be approximated in a few seconds on modest desktop computing hardware.",
        "bibtex": "@InProceedings{pmlr-v108-rontsis20a,\n  title = \t {Optimal Approximation of Doubly Stochastic Matrices},\n  author =       {Rontsis, Nikitas and Goulart, Paul},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3589--3598},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rontsis20a/rontsis20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rontsis20a.html},\n  abstract = \t {We consider the least-squares approximation of a matrix C in the set of doubly stochastic matrices with the same sparsity pattern as C. Our approach is based on applying the well-known Alternating Direction Method of Multipliers (ADMM) to a reformulation of the original problem. Our resulting algorithm requires an initial Cholesky factorization of a positive definite matrix that has the same sparsity pattern as C + I followed by simple iterations whose complexity is linear in the number of nonzeros in C, thus ensuring excellent scalability and speed. We demonstrate the advantages of our approach in a series of experiments on problems with up to 82 million nonzeros; these include normalizing large scale matrices arising from the 3D structure of the human genome, clustering applications, and the SuiteSparse matrix library. Overall, our experiments illustrate the outstanding scalability of our algorithm; matrices with millions of nonzeros can be approximated in a few seconds on modest desktop computing hardware.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rontsis20a/rontsis20a.pdf",
        "supp": "",
        "pdf_size": 636929,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9484313079898344309&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Engineering Science, University of Oxford, OX1 3PJ, UK; Department of Engineering Science, University of Oxford, OX1 3PJ, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "3f99d334a3",
        "title": "Optimal Deterministic Coresets for Ridge Regression",
        "site": "https://proceedings.mlr.press/v108/kacham20a.html",
        "author": "Praneeth Kacham; David Woodruff",
        "abstract": "We consider the ridge regression problem, for which we are given an nxd matrix A of examples and a corresponding nxd\u2019 matrix B of labels, as well as a ridge parameter $\\lambda \\geq 0$, and would like to output an $X\u2019 \\in R^{d \\times d\u2019}$ for which $$\\|AX\u2019-B\\|_F^2 + \\lambda \\|X\u2019\\|_F^2 \\leq (1+\\epsilon)OPT,$$ where ${OPT} = \\min_{Y \\in \\mathbb{R}^{d \\times d\u2019}} \\|AY-B\\|_F^2 + \\lambda \\|Y\\|_F^2.$ In the special case of $\\lambda = 0$, this is ordinary multi-response linear regression. Our focus is on deterministically constructing coresets for this problem. Here the goal is to select and re-weight a small subset of rows of $A$ and corresponding labels of $B$, denoted by $SA$ and $SB$, so that if $X\u2019$ is the minimizer to $\\min_{X\u2019} \\|SAX\u2019-SB\\|_F^2 + \\lambda \\|X\u2019\\|_F^2$, then $\\|AX\u2019-B\\|_F^2 + \\lambda \\|X\u2019\\|_F^2 \\leq (1+\\epsilon)OPT$.         We show how to efficiently(poly(n,d,1/\\epsilon) time) and deterministically select $O({sd}_{\\lambda}/\\epsilon)$ rows of $A$ and $B$ to achieve this property, and prove a matching lower bound, showing that it is necessary to select $\\Omega({sd}_{\\lambda}/\\epsilon)$ rows no matter what the weights are, for any $1 < 1/\\epsilon \\leq sd_{\\lambda}$. Here ${sd}_{\\lambda}$ is the statistical dimension of the input, and we assume $d\u2019 = O({sd}_{\\lambda}) \\leq d$. In the case of ordinary regression, this gives a deterministic algorithm achieving $O(d/\\epsilon)$ rows and a matching lower bound for any $1 \\leq 1/\\epsilon \\leq d$; for $1/\\epsilon > d$ we show $\\Theta(d^2)$ rows are sufficient. Finally we show our new coresets are mergeable, giving a deterministic protocol for ridge regression with $O({sd}_{\\lambda}/\\epsilon)$ words of communication per server, in the important case when the rows of $A$ and $B$ have a constant number of non-zero entries and there are a constant number of servers. Prior to our work the best deterministic protocols in this setting required $\\Omega(min({sd}_{\\lambda}^2,{sd}_{\\lambda}/\\epsilon^2))$ communication.",
        "bibtex": "@InProceedings{pmlr-v108-kacham20a,\n  title = \t {Optimal Deterministic Coresets for Ridge Regression},\n  author =       {Kacham, Praneeth and Woodruff, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4141--4150},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kacham20a/kacham20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kacham20a.html},\n  abstract = \t {We consider the ridge regression problem, for which we are given an nxd matrix A of examples and a corresponding nxd\u2019 matrix B of labels, as well as a ridge parameter $\\lambda \\geq 0$, and would like to output an $X\u2019 \\in R^{d \\times d\u2019}$ for which $$\\|AX\u2019-B\\|_F^2 + \\lambda \\|X\u2019\\|_F^2 \\leq (1+\\epsilon)OPT,$$ where ${OPT} = \\min_{Y \\in \\mathbb{R}^{d \\times d\u2019}} \\|AY-B\\|_F^2 + \\lambda \\|Y\\|_F^2.$ In the special case of $\\lambda = 0$, this is ordinary multi-response linear regression. Our focus is on deterministically constructing coresets for this problem. Here the goal is to select and re-weight a small subset of rows of $A$ and corresponding labels of $B$, denoted by $SA$ and $SB$, so that if $X\u2019$ is the minimizer to $\\min_{X\u2019} \\|SAX\u2019-SB\\|_F^2 + \\lambda \\|X\u2019\\|_F^2$, then $\\|AX\u2019-B\\|_F^2 + \\lambda \\|X\u2019\\|_F^2 \\leq (1+\\epsilon)OPT$.         We show how to efficiently(poly(n,d,1/\\epsilon) time) and deterministically select $O({sd}_{\\lambda}/\\epsilon)$ rows of $A$ and $B$ to achieve this property, and prove a matching lower bound, showing that it is necessary to select $\\Omega({sd}_{\\lambda}/\\epsilon)$ rows no matter what the weights are, for any $1 < 1/\\epsilon \\leq sd_{\\lambda}$. Here ${sd}_{\\lambda}$ is the statistical dimension of the input, and we assume $d\u2019 = O({sd}_{\\lambda}) \\leq d$. In the case of ordinary regression, this gives a deterministic algorithm achieving $O(d/\\epsilon)$ rows and a matching lower bound for any $1 \\leq 1/\\epsilon \\leq d$; for $1/\\epsilon > d$ we show $\\Theta(d^2)$ rows are sufficient. Finally we show our new coresets are mergeable, giving a deterministic protocol for ridge regression with $O({sd}_{\\lambda}/\\epsilon)$ words of communication per server, in the important case when the rows of $A$ and $B$ have a constant number of non-zero entries and there are a constant number of servers. Prior to our work the best deterministic protocols in this setting required $\\Omega(min({sd}_{\\lambda}^2,{sd}_{\\lambda}/\\epsilon^2))$ communication. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/kacham20a/kacham20a.pdf",
        "supp": "",
        "pdf_size": 306651,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4790185850335077367&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "90640c819f",
        "title": "Optimal sampling in unbiased active learning",
        "site": "https://proceedings.mlr.press/v108/imberg20a.html",
        "author": "Henrik Imberg; Johan Jonasson; Marina Axelson-Fisk",
        "abstract": "A common belief in unbiased active learning is that, in order to capture the most informative instances, the sampling probabilities should be proportional to the uncertainty of the class labels. We argue that this produces suboptimal predictions and present sampling schemes for unbiased pool-based active learning that minimise the actual prediction error, and demonstrate a better predictive performance than competing methods on a number of benchmark datasets. In contrast, both probabilistic and deterministic uncertainty sampling performed worse than simple random sampling on some of the datasets.",
        "bibtex": "@InProceedings{pmlr-v108-imberg20a,\n  title = \t {Optimal sampling in unbiased active learning},\n  author =       {Imberg, Henrik and Jonasson, Johan and Axelson-Fisk, Marina},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {559--569},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/imberg20a/imberg20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/imberg20a.html},\n  abstract = \t {A common belief in unbiased active learning is that, in order to capture the most informative instances, the sampling probabilities should be proportional to the uncertainty of the class labels. We argue that this produces suboptimal predictions and present sampling schemes for unbiased pool-based active learning that minimise the actual prediction error, and demonstrate a better predictive performance than competing methods on a number of benchmark datasets. In contrast, both probabilistic and deterministic uncertainty sampling performed worse than simple random sampling on some of the datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/imberg20a/imberg20a.pdf",
        "supp": "",
        "pdf_size": 380811,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15718912207779499594&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e5113bd2a1",
        "title": "Optimization Methods for Interpretable Differentiable Decision Trees Applied to Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v108/silva20a.html",
        "author": "Andrew Silva; Matthew Gombolay; Taylor Killian; Ivan Jimenez; Sung-Hyun Son",
        "abstract": "Decision trees are ubiquitous in machine learning for their ease of use and interpretability. Yet, these models are not typically employed in reinforcement learning as they cannot be updated online via stochastic gradient descent. We overcome this limitation by allowing for a gradient update over the entire tree that improves sample complexity affords interpretable policy extraction. First, we include theoretical motivation on the need for policy-gradient learning by examining the properties of gradient descent over differentiable decision trees. Second, we demonstrate that our approach equals or outperforms a neural network on all domains and can learn discrete decision trees online with average rewards up to 7x higher than a batch-trained decision tree. Third, we conduct a user study to quantify the interpretability of a decision tree, rule list, and a neural network with statistically significant results (p < 0.001).",
        "bibtex": "@InProceedings{pmlr-v108-silva20a,\n  title = \t {Optimization Methods for Interpretable Differentiable Decision Trees Applied to Reinforcement Learning},\n  author =       {Silva, Andrew and Gombolay, Matthew and Killian, Taylor and Jimenez, Ivan and Son, Sung-Hyun},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1855--1865},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/silva20a/silva20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/silva20a.html},\n  abstract = \t { Decision trees are ubiquitous in machine learning for their ease of use and interpretability. Yet, these models are not typically employed in reinforcement learning as they cannot be updated online via stochastic gradient descent. We overcome this limitation by allowing for a gradient update over the entire tree that improves sample complexity affords interpretable policy extraction. First, we include theoretical motivation on the need for policy-gradient learning by examining the properties of gradient descent over differentiable decision trees. Second, we demonstrate that our approach equals or outperforms a neural network on all domains and can learn discrete decision trees online with average rewards up to 7x higher than a batch-trained decision tree. Third, we conduct a user study to quantify the interpretability of a decision tree, rule list, and a neural network with statistically significant results (p < 0.001).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/silva20a/silva20a.pdf",
        "supp": "",
        "pdf_size": 1009455,
        "gs_citation": 172,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9190267355182779549&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Georgia Institute of Technology; University of Toronto; Georgia Institute of Technology; MIT Lincoln Laboratory; Georgia Institute of Technology",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of Toronto;Massachusetts Institute of Technology Lincoln Laboratory",
        "aff_unique_dep": ";;Lincoln Laboratory",
        "aff_unique_url": "https://www.gatech.edu;https://www.utoronto.ca;https://www.ll.mit.edu",
        "aff_unique_abbr": "Georgia Tech;U of T;MIT LL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Lexington",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "25a102ea7e",
        "title": "Optimization of Graph Total Variation via Active-Set-based Combinatorial Reconditioning",
        "site": "https://proceedings.mlr.press/v108/ye20a.html",
        "author": "Zhenzhang Ye; Thomas M\u00f6llenhoff; Tao Wu; Daniel Cremers",
        "abstract": "Structured convex optimization on weighted graphs finds numerous applications in machine learning and computer vision. In this work, we propose a novel adaptive preconditioning strategy for proximal algorithms on this problem class. Our preconditioner is driven by a sharp analysis of the local linear convergence rate depending on the \"active set\" at the current iterate. We show that nested-forest decomposition of the inactive edges yields a guaranteed local linear convergence rate. Further, we propose a practical greedy heuristic which realizes such nested decompositions and show in several numerical experiments that our reconditioning strategy, when applied to proximal gradient or primal-dual hybrid gradient algorithm, achieves competitive performances. Our results suggest that local convergence analysis can serve as a guideline for selecting variable metrics in proximal algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-ye20a,\n  title = \t {Optimization of Graph Total Variation via Active-Set-based Combinatorial Reconditioning},\n  author =       {Ye, Zhenzhang and M\\\"ollenhoff, Thomas and Wu, Tao and Cremers, Daniel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {657--668},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ye20a/ye20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ye20a.html},\n  abstract = \t {Structured convex optimization on weighted graphs finds numerous applications in machine learning and computer vision. In this work, we propose a novel adaptive preconditioning strategy for proximal algorithms on this problem class. Our preconditioner is driven by a sharp analysis of the local linear convergence rate depending on the \"active set\" at the current iterate. We show that nested-forest decomposition of the inactive edges yields a guaranteed local linear convergence rate. Further, we propose a practical greedy heuristic which realizes such nested decompositions and show in several numerical experiments that our reconditioning strategy, when applied to proximal gradient or primal-dual hybrid gradient algorithm, achieves competitive performances. Our results suggest that local convergence analysis can serve as a guideline for selecting variable metrics in proximal algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ye20a/ye20a.pdf",
        "supp": "",
        "pdf_size": 484810,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13835349006956921641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "TU Munich; TU Munich; TU Munich; TU Munich",
        "aff_domain": "tum.de;tum.de;tum.de;tum.de",
        "email": "tum.de;tum.de;tum.de;tum.de",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "830cd25940",
        "title": "Optimized Score Transformation for Fair Classification",
        "site": "https://proceedings.mlr.press/v108/wei20a.html",
        "author": "Dennis Wei; Karthikeyan Natesan Ramamurthy; Flavio Calmon",
        "abstract": "This paper considers fair probabilistic classification where the outputs of primary interest are predicted probabilities, commonly referred to as scores. We formulate the problem of transforming scores to satisfy fairness constraints while minimizing the loss in utility. The formulation can be applied either to post-process classifier outputs or to pre-process training data, thus allowing maximum freedom in selecting a classification algorithm. We derive a closed-form expression for the optimal transformed scores and a convex optimization problem for the transformation parameters. In the population limit, the transformed score function is the fairness-constrained minimizer of cross-entropy with respect to the optimal unconstrained scores. In the finite sample setting, we propose to approach this solution using a combination of standard probabilistic classifiers and ADMM. Comprehensive experiments comparing to 10 existing methods show that the proposed FairScoreTransformer has advantages for score-based metrics such as Brier score and AUC while remaining competitive for binary label-based metrics such as accuracy.",
        "bibtex": "@InProceedings{pmlr-v108-wei20a,\n  title = \t {Optimized Score Transformation for Fair Classification},\n  author =       {Wei, Dennis and Ramamurthy, Karthikeyan Natesan and Calmon, Flavio},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1673--1683},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wei20a/wei20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wei20a.html},\n  abstract = \t {This paper considers fair probabilistic classification where the outputs of primary interest are predicted probabilities, commonly referred to as scores. We formulate the problem of transforming scores to satisfy fairness constraints while minimizing the loss in utility. The formulation can be applied either to post-process classifier outputs or to pre-process training data, thus allowing maximum freedom in selecting a classification algorithm. We derive a closed-form expression for the optimal transformed scores and a convex optimization problem for the transformation parameters. In the population limit, the transformed score function is the fairness-constrained minimizer of cross-entropy with respect to the optimal unconstrained scores. In the finite sample setting, we propose to approach this solution using a combination of standard probabilistic classifiers and ADMM. Comprehensive experiments comparing to 10 existing methods show that the proposed FairScoreTransformer has advantages for score-based metrics such as Brier score and AUC while remaining competitive for binary label-based metrics such as accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wei20a/wei20a.pdf",
        "supp": "",
        "pdf_size": 9614356,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9544458198578420075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "26c24d78aa",
        "title": "Optimizing Millions of Hyperparameters by Implicit Differentiation",
        "site": "https://proceedings.mlr.press/v108/lorraine20a.html",
        "author": "Jonathan Lorraine; Paul Vicol; David Duvenaud",
        "abstract": "We propose an algorithm for inexpensive gradient-based hyperparameter optimization that combines the implicit function theorem (IFT) with efficient inverse Hessian approximations. We present results about the relationship between the IFT and differentiating through optimization, motivating our algorithm.  We use the proposed approach to train modern network architectures with millions of weights and millions of hyper-parameters. For example, we learn a data-augmentation network\u2014where every weight is a hyperparameter tuned for validation performance\u2014outputting augmented training examples. Jointly tuning weights and hyper-parameters is only a few times more costly in memory and compute than standard training.",
        "bibtex": "@InProceedings{pmlr-v108-lorraine20a,\n  title = \t {Optimizing Millions of Hyperparameters by Implicit Differentiation},\n  author =       {Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1540--1552},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lorraine20a/lorraine20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lorraine20a.html},\n  abstract = \t {We propose an algorithm for inexpensive gradient-based hyperparameter optimization that combines the implicit function theorem (IFT) with efficient inverse Hessian approximations. We present results about the relationship between the IFT and differentiating through optimization, motivating our algorithm.  We use the proposed approach to train modern network architectures with millions of weights and millions of hyper-parameters. For example, we learn a data-augmentation network\u2014where every weight is a hyperparameter tuned for validation performance\u2014outputting augmented training examples. Jointly tuning weights and hyper-parameters is only a few times more costly in memory and compute than standard training.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lorraine20a/lorraine20a.pdf",
        "supp": "",
        "pdf_size": 1597336,
        "gs_citation": 508,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4709850054607497307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Toronto, Vector Institute; University of Toronto, Vector Institute; University of Toronto, Vector Institute",
        "aff_domain": "cs.toronto.edu;cs.toronto.edu;cs.toronto.edu",
        "email": "cs.toronto.edu;cs.toronto.edu;cs.toronto.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "d1c9914059",
        "title": "Ordered SGD: A New Stochastic Optimization Framework for Empirical Risk Minimization",
        "site": "https://proceedings.mlr.press/v108/kawaguchi20a.html",
        "author": "Kenji Kawaguchi; Haihao Lu",
        "abstract": "We propose a new stochastic optimization framework for empirical risk minimization problems such as those that arise in machine learning. The traditional approaches, such as (mini-batch) stochastic gradient descent (SGD), utilize an unbiased gradient estimator of the empirical average loss. In contrast, we develop a computationally efficient method to construct a gradient estimator that is purposely biased toward those observations with higher current losses. On the theory side, we show that the proposed method minimizes a new ordered modification of the empirical average loss, and is guaranteed to converge at a sublinear rate to a global optimum for convex loss and to a critical point for weakly convex (non-convex) loss. Furthermore, we prove a new generalization bound for the proposed algorithm. On the empirical side, the numerical experiments show that our proposed method consistently improves the test errors compared with the standard mini-batch SGD in various models including SVM, logistic regression, and deep learning problems.",
        "bibtex": "@InProceedings{pmlr-v108-kawaguchi20a,\n  title = \t {Ordered SGD: A New Stochastic Optimization Framework for Empirical Risk Minimization},\n  author =       {Kawaguchi, Kenji and Lu, Haihao},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {669--679},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kawaguchi20a/kawaguchi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kawaguchi20a.html},\n  abstract = \t {We propose a new stochastic optimization framework for empirical risk minimization problems such as those that arise in machine learning. The traditional approaches, such as (mini-batch) stochastic gradient descent (SGD), utilize an unbiased gradient estimator of the empirical average loss. In contrast, we develop a computationally efficient method to construct a gradient estimator that is purposely biased toward those observations with higher current losses. On the theory side, we show that the proposed method minimizes a new ordered modification of the empirical average loss, and is guaranteed to converge at a sublinear rate to a global optimum for convex loss and to a critical point for weakly convex (non-convex) loss. Furthermore, we prove a new generalization bound for the proposed algorithm. On the empirical side, the numerical experiments show that our proposed method consistently improves the test errors compared with the standard mini-batch SGD in various models including SVM, logistic regression, and deep learning problems.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kawaguchi20a/kawaguchi20a.pdf",
        "supp": "",
        "pdf_size": 1505872,
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15308788340793165433&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "MIT; Google Research + University of Chicago",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google;University of Chicago",
        "aff_unique_dep": ";Google Research;",
        "aff_unique_url": "https://web.mit.edu;https://research.google;https://www.uchicago.edu",
        "aff_unique_abbr": "MIT;Google Research;UChicago",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1437f440a6",
        "title": "Ordering-Based Causal Structure Learning in the Presence of Latent Variables",
        "site": "https://proceedings.mlr.press/v108/bernstein20a.html",
        "author": "Daniel Bernstein; Basil Saeed; Chandler Squires; Caroline Uhler",
        "abstract": "We consider the task of learning a causal graph in the presence of latent confounders given i.i.d.samples from the model. While current algorithms for causal structure discovery in the presence of latent confounders are constraint-based, we here propose a hybrid approach. We prove that under assumptions weaker than faithfulness, any sparsest independence map (IMAP) of the distribution belongs to the Markov equivalence class of the true model. This motivates the Sparsest Poset formulation - that posets can be mapped to minimal IMAPs of the true model such that the sparsest of these IMAPs is Markov equivalent to the true model. Motivated by this result, we propose a greedy algorithm over the space of posets for causal structure discovery in the presence of latent confounders and compare its performance to the current state-of-the-art algorithms FCI and FCI+ on synthetic data.",
        "bibtex": "@InProceedings{pmlr-v108-bernstein20a,\n  title = \t {Ordering-Based Causal Structure Learning in the Presence of Latent Variables},\n  author =       {Bernstein, Daniel and Saeed, Basil and Squires, Chandler and Uhler, Caroline},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4098--4108},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bernstein20a/bernstein20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bernstein20a.html},\n  abstract = \t {We consider the task of learning a causal graph in the presence of latent confounders given i.i.d.samples from the model. While current algorithms for causal structure discovery in the presence of latent confounders are constraint-based, we here propose a hybrid approach. We prove that under assumptions weaker than faithfulness, any sparsest independence map (IMAP) of the distribution belongs to the Markov equivalence class of the true model. This motivates the Sparsest Poset formulation - that posets can be mapped to minimal IMAPs of the true model such that the sparsest of these IMAPs is Markov equivalent to the true model. Motivated by this result, we propose a greedy algorithm over the space of posets for causal structure discovery in the presence of latent confounders and compare its performance to the current state-of-the-art algorithms FCI and FCI+ on synthetic data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bernstein20a/bernstein20a.pdf",
        "supp": "",
        "pdf_size": 1222151,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11390331077749688373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "28376c5c9d",
        "title": "Orthogonal Gradient Descent for Continual Learning",
        "site": "https://proceedings.mlr.press/v108/farajtabar20a.html",
        "author": "Mehrdad Farajtabar; Navid Azizan; Alex Mott; Ang Li",
        "abstract": "Neural networks are achieving state of the art and sometimes super-human performance on learning tasks across a variety of domains. Whenever these problems require learning in a continual or sequential manner, however, neural networks suffer from the problem of catastrophic forgetting; they forget how to solve previous tasks after being trained on a new task, despite having the essential capacity to solve both tasks if they were trained on both simultaneously. In this paper, we propose to address this issue from a parameter space perspective and study an approach to restrict the direction of the gradient updates to avoid forgetting previously-learned data. We present the Orthogonal Gradient Descent (OGD) method, which accomplishes this goal by projecting the gradients from new tasks onto a subspace in which the neural network output on previous task does not change and the projected gradient is still in a useful direction for learning the new task. Our approach utilizes the high capacity of a neural network more efficiently and does not require storing the previously learned data that might raise privacy concerns. Experiments on common benchmarks reveal the effectiveness of the proposed OGD method.",
        "bibtex": "@InProceedings{pmlr-v108-farajtabar20a,\n  title = \t {Orthogonal Gradient Descent for Continual Learning},\n  author =       {Farajtabar, Mehrdad and Azizan, Navid and Mott, Alex and Li, Ang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3762--3773},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/farajtabar20a/farajtabar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/farajtabar20a.html},\n  abstract = \t {Neural networks are achieving state of the art and sometimes super-human performance on learning tasks across a variety of domains. Whenever these problems require learning in a continual or sequential manner, however, neural networks suffer from the problem of catastrophic forgetting; they forget how to solve previous tasks after being trained on a new task, despite having the essential capacity to solve both tasks if they were trained on both simultaneously. In this paper, we propose to address this issue from a parameter space perspective and study an approach to restrict the direction of the gradient updates to avoid forgetting previously-learned data. We present the Orthogonal Gradient Descent (OGD) method, which accomplishes this goal by projecting the gradients from new tasks onto a subspace in which the neural network output on previous task does not change and the projected gradient is still in a useful direction for learning the new task. Our approach utilizes the high capacity of a neural network more efficiently and does not require storing the previously learned data that might raise privacy concerns. Experiments on common benchmarks reveal the effectiveness of the proposed OGD method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/farajtabar20a/farajtabar20a.pdf",
        "supp": "",
        "pdf_size": 838966,
        "gs_citation": 448,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1997970328830427457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "DeepMind; CalTech; DeepMind; DeepMind",
        "aff_domain": "google.com; ; ; ",
        "email": "google.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "DeepMind;California Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://deepmind.com;https://www.caltech.edu",
        "aff_unique_abbr": "DeepMind;CalTech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9bea094694",
        "title": "POPCORN: Partially Observed Prediction Constrained Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v108/futoma20a.html",
        "author": "Joseph Futoma; Michael Hughes; Finale Doshi-Velez",
        "abstract": "Many medical decision-making tasks can be framed as partially observed Markov decision processes (POMDPs). However, prevailing two-stage approaches that first learn a POMDP and then solve it often fail because the model that best fits the data may not be well suited for planning. We introduce a new optimization objective that (a) produces both high-performing policies and high-quality generative models, even when some observations are irrelevant for planning, and (b) does so in batch off-policy settings that are typical in healthcare, when only retrospective data is available. We demonstrate our approach on synthetic examples and a challenging medical decision-making problem.",
        "bibtex": "@InProceedings{pmlr-v108-futoma20a,\n  title = \t {POPCORN: Partially Observed Prediction Constrained Reinforcement Learning},\n  author =       {Futoma, Joseph and Hughes, Michael and Doshi-Velez, Finale},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3578--3588},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/futoma20a/futoma20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/futoma20a.html},\n  abstract = \t {Many medical decision-making tasks can be framed as partially observed Markov decision processes (POMDPs). However, prevailing two-stage approaches that first learn a POMDP and then solve it often fail because the model that best fits the data may not be well suited for planning. We introduce a new optimization objective that (a) produces both high-performing policies and high-quality generative models, even when some observations are irrelevant for planning, and (b) does so in batch off-policy settings that are typical in healthcare, when only retrospective data is available. We demonstrate our approach on synthetic examples and a challenging medical decision-making problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/futoma20a/futoma20a.pdf",
        "supp": "",
        "pdf_size": 8625459,
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2544924681479461357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e877ee4e98",
        "title": "Patient-Specific Effects of Medication Using Latent Force Models with Gaussian Processes",
        "site": "https://proceedings.mlr.press/v108/cheng20c.html",
        "author": "Li-Fang Cheng; Bianca Dumitrascu; Michael Zhang; Corey Chivers; Michael Draugelis; Kai Li; Barbara Engelhardt",
        "abstract": "A multi-output Gaussian process (GP) is a flexible Bayesian nonparametric framework that has proven useful in jointly modeling the physiological states of patients in medical time series data. However, capturing the short-term effects of drugs and therapeutic interventions on patient physiological state remains challenging. We propose a novel approach that models the effect of interventions as a hybrid Gaussian process composed of a GP capturing patient baseline physiology convolved with a latent force model capturing effects of treatments on specific physiological features. The combination of a multi-output GP with a time-marked kernel GP leads to a well-characterized model of patients\u2019 physiological state across a hospital stay, including response to interventions. Our model leads to analytically tractable cross-covariance functions that allow for scalable inference. Our hierarchical model includes estimates of patient-specific effects but allows sharing of support across patients. Our approach achieves competitive predictive performance on challenging hospital data, where we recover patient-specific response to the administration of three common drugs: one antihypertensive drug and two anticoagulants.",
        "bibtex": "@InProceedings{pmlr-v108-cheng20c,\n  title = \t {Patient-Specific Effects of Medication Using Latent Force Models with Gaussian Processes},\n  author =       {Cheng, Li-Fang and Dumitrascu, Bianca and Zhang, Michael and Chivers, Corey and Draugelis, Michael and Li, Kai and Engelhardt, Barbara},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4045--4055},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cheng20c/cheng20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cheng20c.html},\n  abstract = \t {A multi-output Gaussian process (GP) is a flexible Bayesian nonparametric framework that has proven useful in jointly modeling the physiological states of patients in medical time series data. However, capturing the short-term effects of drugs and therapeutic interventions on patient physiological state remains challenging. We propose a novel approach that models the effect of interventions as a hybrid Gaussian process composed of a GP capturing patient baseline physiology convolved with a latent force model capturing effects of treatments on specific physiological features. The combination of a multi-output GP with a time-marked kernel GP leads to a well-characterized model of patients\u2019 physiological state across a hospital stay, including response to interventions. Our model leads to analytically tractable cross-covariance functions that allow for scalable inference. Our hierarchical model includes estimates of patient-specific effects but allows sharing of support across patients. Our approach achieves competitive predictive performance on challenging hospital data, where we recover patient-specific response to the administration of three common drugs: one antihypertensive drug and two anticoagulants.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cheng20c/cheng20c.pdf",
        "supp": "",
        "pdf_size": 805406,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18277882020401885442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Princeton University; Institute for Advanced Study; Princeton University; University of Pennsylvania Health System; University of Pennsylvania Health System; Princeton University; Princeton University",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;2;0;0",
        "aff_unique_norm": "Princeton University;Institute for Advanced Study;University of Pennsylvania Health System",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.princeton.edu;https://ias.edu;https://www.pennmedicine.org",
        "aff_unique_abbr": "Princeton;IAS;UPHS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "19d7f37144",
        "title": "Permutation Invariant Graph Generation via Score-Based Generative Modeling",
        "site": "https://proceedings.mlr.press/v108/niu20a.html",
        "author": "Chenhao Niu; Yang Song; Jiaming Song; Shengjia Zhao; Aditya Grover; Stefano Ermon",
        "abstract": "Learning generative models for graph-structured data is challenging because graphs are discrete, combinatorial, and the underlying data distribution is invariant to the ordering of nodes. However, most of the existing generative models for graphs are not invariant to the chosen ordering, which might lead to an undesirable bias in the learned distribution. To address this difficulty, we propose a permutation invariant approach to modeling graphs, using the recent framework of score-based generative modeling. In particular, we design a permutation equivariant, multi-channel graph neural network to model the gradient of the data distribution at the input graph (a.k.a., the score function). This permutation equivariant model of gradients implicitly defines a permutation invariant distribution for graphs. We train this graph neural network with score matching and sample from it with annealed Langevin dynamics. In our experiments, we first demonstrate the capacity of this new architecture in learning discrete graph algorithms. For graph generation, we find that our learning approach achieves better or comparable results to existing models on benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v108-niu20a,\n  title = \t {Permutation Invariant Graph Generation via Score-Based Generative Modeling},\n  author =       {Niu, Chenhao and Song, Yang and Song, Jiaming and Zhao, Shengjia and Grover, Aditya and Ermon, Stefano},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4474--4484},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/niu20a/niu20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/niu20a.html},\n  abstract = \t {Learning generative models for graph-structured data is challenging because graphs are discrete, combinatorial, and the underlying data distribution is invariant to the ordering of nodes. However, most of the existing generative models for graphs are not invariant to the chosen ordering, which might lead to an undesirable bias in the learned distribution. To address this difficulty, we propose a permutation invariant approach to modeling graphs, using the recent framework of score-based generative modeling. In particular, we design a permutation equivariant, multi-channel graph neural network to model the gradient of the data distribution at the input graph (a.k.a., the score function). This permutation equivariant model of gradients implicitly defines a permutation invariant distribution for graphs. We train this graph neural network with score matching and sample from it with annealed Langevin dynamics. In our experiments, we first demonstrate the capacity of this new architecture in learning discrete graph algorithms. For graph generation, we find that our learning approach achieves better or comparable results to existing models on benchmark datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/niu20a/niu20a.pdf",
        "supp": "",
        "pdf_size": 852413,
        "gs_citation": 298,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8467212240960552669&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Tsinghua University; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Tsinghua University;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.stanford.edu",
        "aff_unique_abbr": "THU;Stanford",
        "aff_campus_unique_index": "1;1;1;1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "83d91877ef",
        "title": "PersLay: A Neural Network Layer for Persistence Diagrams and New Graph Topological Signatures",
        "site": "https://proceedings.mlr.press/v108/carriere20a.html",
        "author": "Mathieu Carriere; Frederic Chazal; Yuichi Ike; Theo Lacombe; Martin Royer; Yuhei Umeda",
        "abstract": "Persistence diagrams, the most common descriptors of Topological Data Analysis, encode topological properties of data and have already proved pivotal in many different applications of data science. However, since the metric space of persistence diagrams is not Hilbert, they end up being difficult inputs for most Machine Learning techniques. To address this concern, several vectorization methods have been put forward that embed persistence diagrams into either finite-dimensional Euclidean space or implicit infinite dimensional Hilbert space with kernels. In this work, we focus on persistence diagrams built on top of graphs. Relying on extended persistence theory and the so-called heat kernel signature, we show how graphs can be encoded by (extended) persistence diagrams in a provably stable way. We then propose a general and versatile framework for learning vectorizations of persistence diagrams, which encompasses most of the vectorization techniques used in the literature. We finally showcase the experimental strength of our setup by achieving competitive scores on classification tasks on real-life graph datasets.",
        "bibtex": "@InProceedings{pmlr-v108-carriere20a,\n  title = \t {PersLay: A Neural Network Layer for Persistence Diagrams and New Graph Topological Signatures},\n  author =       {Carriere, Mathieu and Chazal, Frederic and Ike, Yuichi and Lacombe, Theo and Royer, Martin and Umeda, Yuhei},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2786--2796},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/carriere20a/carriere20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/carriere20a.html},\n  abstract = \t {Persistence diagrams, the most common descriptors of Topological Data Analysis, encode topological properties of data and have already proved pivotal in many different applications of data science. However, since the metric space of persistence diagrams is not Hilbert, they end up being difficult inputs for most Machine Learning techniques. To address this concern, several vectorization methods have been put forward that embed persistence diagrams into either finite-dimensional Euclidean space or implicit infinite dimensional Hilbert space with kernels. In this work, we focus on persistence diagrams built on top of graphs. Relying on extended persistence theory and the so-called heat kernel signature, we show how graphs can be encoded by (extended) persistence diagrams in a provably stable way. We then propose a general and versatile framework for learning vectorizations of persistence diagrams, which encompasses most of the vectorization techniques used in the literature. We finally showcase the experimental strength of our setup by achieving competitive scores on classification tasks on real-life graph datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/carriere20a/carriere20a.pdf",
        "supp": "",
        "pdf_size": 798689,
        "gs_citation": 242,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8091964741630296986&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f8d2f4cc94",
        "title": "Persistence Enhanced Graph Neural Network",
        "site": "https://proceedings.mlr.press/v108/zhao20d.html",
        "author": "Qi Zhao; Ze Ye; Chao Chen; Yusu Wang",
        "abstract": "Local structural information can increase the adaptability of graph convolutional networks to large graphs with heterogeneous topology. Existing methods only use relatively simplistic topological information, such as node degrees.We present a novel approach leveraging advanced topological information, i.e., persistent homology, which measures the information flow efficiency at different parts of the graph. To fully exploit such structural information in real world graphs, we propose a new network architecture which learns to use persistent homology information to reweight messages passed between graph nodes during convolution. For node classification tasks, our network outperforms existing ones on a broad spectrum of graph benchmarks.",
        "bibtex": "@InProceedings{pmlr-v108-zhao20d,\n  title = \t {Persistence Enhanced Graph Neural Network},\n  author =       {Zhao, Qi and Ye, Ze and Chen, Chao and Wang, Yusu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2896--2906},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhao20d/zhao20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhao20d.html},\n  abstract = \t {Local structural information can increase the adaptability of graph convolutional networks to large graphs with heterogeneous topology. Existing methods only use relatively simplistic topological information, such as node degrees.We present a novel approach leveraging advanced topological information, i.e., persistent homology, which measures the information flow efficiency at different parts of the graph. To fully exploit such structural information in real world graphs, we propose a new network architecture which learns to use persistent homology information to reweight messages passed between graph nodes during convolution. For node classification tasks, our network outperforms existing ones on a broad spectrum of graph benchmarks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhao20d/zhao20d.pdf",
        "supp": "",
        "pdf_size": 706657,
        "gs_citation": 101,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9457892377498387303&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d80ce6ec93",
        "title": "Post-Estimation Smoothing: A Simple Baseline for Learning with Side Information",
        "site": "https://proceedings.mlr.press/v108/rolf20a.html",
        "author": "Esther Rolf; Michael I. Jordan; Benjamin Recht",
        "abstract": "Observational data are often accompanied by natural structural indices, such as time stamps or geographic locations, which are meaningful to prediction tasks but are often discarded. We leverage semantically meaningful indexing data while ensuring robustness to potentially uninformative or misleading indices. We propose a post-estimation smoothing operator as a fast and effective method for incorporating structural index data into prediction. Because the smoothing step is separate from the original predictor, it applies to a broad class of machine learning tasks, with no need to retrain models. Our theoretical analysis details simple conditions under which post-estimation smoothing will improve accuracy over that of the original predictor. Our experiments on large scale spatial and temporal datasets highlight the speed and accuracy of post-estimation smoothing in practice. Together, these results illuminate a novel way to consider and incorporate the natural structure of index variables in machine learning.",
        "bibtex": "@InProceedings{pmlr-v108-rolf20a,\n  title = \t {Post-Estimation Smoothing: A Simple Baseline for Learning with Side Information},\n  author =       {Rolf, Esther and Jordan, Michael I. and Recht, Benjamin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1759--1769},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rolf20a/rolf20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rolf20a.html},\n  abstract = \t {Observational data are often accompanied by natural structural indices, such as time stamps or geographic locations, which are meaningful to prediction tasks but are often discarded. We leverage semantically meaningful indexing data while ensuring robustness to potentially uninformative or misleading indices. We propose a post-estimation smoothing operator as a fast and effective method for incorporating structural index data into prediction. Because the smoothing step is separate from the original predictor, it applies to a broad class of machine learning tasks, with no need to retrain models. Our theoretical analysis details simple conditions under which post-estimation smoothing will improve accuracy over that of the original predictor. Our experiments on large scale spatial and temporal datasets highlight the speed and accuracy of post-estimation smoothing in practice. Together, these results illuminate a novel way to consider and incorporate the natural structure of index variables in machine learning. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/rolf20a/rolf20a.pdf",
        "supp": "",
        "pdf_size": 2082834,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17421622003559503560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bb2bbf967e",
        "title": "Practical Nonisotropic Monte Carlo Sampling in High Dimensions via Determinantal Point Processes",
        "site": "https://proceedings.mlr.press/v108/choromanski20a.html",
        "author": "Krzysztof Choromanski; Aldo Pacchiano; Jack Parker-Holder; Yunhao Tang",
        "abstract": "We propose a new class of practical structured methods for nonisotropic Monte Carlo (MC) sampling, called DPPMC, designed for high-dimensional nonisotropic distributions where samples are correlated to reduce the variance of the estimator via determinantal point processes. We successfully apply DPPMCs to high-dimensional problems involving nonisotropic distributions arising in guided evolution strategy (GES) methods for reinforcement learning (RL), CMA-ES techniques and trust region algorithms for blackbox optimization, improving state-of-the-art in all these settings. In particular, we show that DPPMCs drastically improve exploration profiles of the existing evolution strategy algorithms. We further confirm our results, analyzing random feature map estimators for Gaussian mixture kernels. We provide theoretical justification of our empirical results, showing a connection between DPPMCs and recently introduced structured orthogonal MC methods for isotropic distributions.",
        "bibtex": "@InProceedings{pmlr-v108-choromanski20a,\n  title = \t {Practical Nonisotropic Monte Carlo Sampling in High Dimensions via Determinantal Point Processes},\n  author =       {Choromanski, Krzysztof and Pacchiano, Aldo and Parker-Holder, Jack and Tang, Yunhao},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1363--1374},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/choromanski20a/choromanski20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/choromanski20a.html},\n  abstract = \t {We propose a new class of practical structured methods for nonisotropic Monte Carlo (MC) sampling, called DPPMC, designed for high-dimensional nonisotropic distributions where samples are correlated to reduce the variance of the estimator via determinantal point processes. We successfully apply DPPMCs to high-dimensional problems involving nonisotropic distributions arising in guided evolution strategy (GES) methods for reinforcement learning (RL), CMA-ES techniques and trust region algorithms for blackbox optimization, improving state-of-the-art in all these settings. In particular, we show that DPPMCs drastically improve exploration profiles of the existing evolution strategy algorithms. We further confirm our results, analyzing random feature map estimators for Gaussian mixture kernels. We provide theoretical justification of our empirical results, showing a connection between DPPMCs and recently introduced structured orthogonal MC methods for isotropic distributions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/choromanski20a/choromanski20a.pdf",
        "supp": "",
        "pdf_size": 883124,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3017354619410200975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ef390fb65a",
        "title": "Precision-Recall Curves Using Information Divergence Frontiers",
        "site": "https://proceedings.mlr.press/v108/djolonga20a.html",
        "author": "Josip Djolonga; Mario Lucic; Marco Cuturi; Olivier Bachem; Olivier Bousquet; Sylvain Gelly",
        "abstract": "Despite the tremendous progress in the estimation of generative models, the development of tools for diagnosing their failures and assessing their performance has advanced at a much slower pace. Recent developments have investigated metrics that quantify which parts of the true distribution is modeled well, and, on the contrary, what the model fails to capture, akin to precision and recall in information retrieval. In this paper, we present a general evaluation framework for generative models that measures the trade-off between precision and recall using Renyi divergences. Our framework provides a novel perspective on existing techniques and extends them to more general domains. As a key advantage, this formulation encompasses both continuous and discrete models and allows for the design of efficient algorithms that do not have to quantize the data. We further analyze the biases of the approximations used in practice.",
        "bibtex": "@InProceedings{pmlr-v108-djolonga20a,\n  title = \t {Precision-Recall Curves Using Information Divergence Frontiers},\n  author =       {Djolonga, Josip and Lucic, Mario and Cuturi, Marco and Bachem, Olivier and Bousquet, Olivier and Gelly, Sylvain},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2550--2559},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/djolonga20a/djolonga20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/djolonga20a.html},\n  abstract = \t {Despite the tremendous progress in the estimation of generative models, the development of tools for diagnosing their failures and assessing their performance has advanced at a much slower pace. Recent developments have investigated metrics that quantify which parts of the true distribution is modeled well, and, on the contrary, what the model fails to capture, akin to precision and recall in information retrieval. In this paper, we present a general evaluation framework for generative models that measures the trade-off between precision and recall using Renyi divergences. Our framework provides a novel perspective on existing techniques and extends them to more general domains. As a key advantage, this formulation encompasses both continuous and discrete models and allows for the design of efficient algorithms that do not have to quantize the data. We further analyze the biases of the approximations used in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/djolonga20a/djolonga20a.pdf",
        "supp": "",
        "pdf_size": 1050459,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1030909476885956392&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4ad630503f",
        "title": "Prediction Focused Topic Models via Feature Selection",
        "site": "https://proceedings.mlr.press/v108/ren20a.html",
        "author": "Jason Ren; Russell Kunes; Finale Doshi-Velez",
        "abstract": "Supervised topic models are often sought to balance prediction quality and interpretability.  However, when models are (inevitably) misspecified, standard approaches rarely deliver on both.  We introduce a novel approach, the prediction-focused topic model, that uses the supervisory signal to retain only vocabulary terms that improve, or at least do not hinder, prediction performance.  By removing terms with irrelevant signal, the topic model is able to learn task-relevant, coherent topics.  We demonstrate on several data sets that compared to existing approaches, prediction-focused topic models learn much more coherent topics while maintaining competitive predictions.",
        "bibtex": "@InProceedings{pmlr-v108-ren20a,\n  title = \t {Prediction Focused Topic Models via Feature Selection},\n  author =       {Ren, Jason and Kunes, Russell and Doshi-Velez, Finale},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4420--4429},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ren20a/ren20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ren20a.html},\n  abstract = \t {Supervised topic models are often sought to balance prediction quality and interpretability.  However, when models are (inevitably) misspecified, standard approaches rarely deliver on both.  We introduce a novel approach, the prediction-focused topic model, that uses the supervisory signal to retain only vocabulary terms that improve, or at least do not hinder, prediction performance.  By removing terms with irrelevant signal, the topic model is able to learn task-relevant, coherent topics.  We demonstrate on several data sets that compared to existing approaches, prediction-focused topic models learn much more coherent topics while maintaining competitive predictions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ren20a/ren20a.pdf",
        "supp": "",
        "pdf_size": 3117772,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11979491999342264807&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Harvard University; Columbia University; Harvard University",
        "aff_domain": "college.harvard.edu;columbia.edu;seas.harvard.edu",
        "email": "college.harvard.edu;columbia.edu;seas.harvard.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Harvard University;Columbia University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.harvard.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Harvard;Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "975f817c47",
        "title": "Prior-aware Composition Inference for Spectral Topic Models",
        "site": "https://proceedings.mlr.press/v108/lee20c.html",
        "author": "Moontae Lee; David Bindel; David Mimno",
        "abstract": "Spectral algorithms operate on matrices or tensors of word co-occurrence to learn latent topics. These approaches remove the dependence on the original documents and produce substantial gains in efficiency with provable inference, but at a cost: the models can no longer infer any information about individual documents. Thresholded Linear Inverse is developed to learn document-specific topic compositions, but its linear characteristics limit the inference quality without considering any prior information on topic distributions. We propose two novel estimation methods that respect previously unclear prior structures of spectral topic models. Experiments on a variety of synthetic to real collections demonstrate that our Prior-Aware Dual Decomposition outperforms the baseline method, whereas our Prior-Aware Manifold Iteration performs even better on short realistic data.",
        "bibtex": "@InProceedings{pmlr-v108-lee20c,\n  title = \t {Prior-aware Composition Inference for Spectral Topic Models},\n  author =       {Lee, Moontae and Bindel, David and Mimno, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4258--4268},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lee20c/lee20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lee20c.html},\n  abstract = \t {Spectral algorithms operate on matrices or tensors of word co-occurrence to learn latent topics. These approaches remove the dependence on the original documents and produce substantial gains in efficiency with provable inference, but at a cost: the models can no longer infer any information about individual documents. Thresholded Linear Inverse is developed to learn document-specific topic compositions, but its linear characteristics limit the inference quality without considering any prior information on topic distributions. We propose two novel estimation methods that respect previously unclear prior structures of spectral topic models. Experiments on a variety of synthetic to real collections demonstrate that our Prior-Aware Dual Decomposition outperforms the baseline method, whereas our Prior-Aware Manifold Iteration performs even better on short realistic data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lee20c/lee20c.pdf",
        "supp": "",
        "pdf_size": 587283,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9687065463536139782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7e5d4b1751",
        "title": "Private Protocols for U-Statistics in the Local Model and Beyond",
        "site": "https://proceedings.mlr.press/v108/bell20a.html",
        "author": "James Bell; Aur\u00e9lien Bellet; Adria Gascon; Tejas Kulkarni",
        "abstract": "In this paper, we study the problem of computing $U$-statistics of degree $2$, i.e., quantities that come in the form of averages over pairs of data points, in the local model of differential privacy (LDP). The class of $U$-statistics covers many statistical estimates of interest, including Gini mean difference, Kendall\u2019s tau coefficient and Area under the ROC Curve (AUC), as well as empirical risk measures for machine learning problems such as ranking, clustering and metric learning. We first introduce an LDP protocol based on quantizing the data into bins and applying randomized response, which guarantees an $\\epsilon$-LDP estimate with a Mean Squared Error (MSE) of $O(1/\\sqrt{n}\\epsilon)$ under regularity assumptions on the $U$-statistic or the data distribution. We then propose a specialized protocol for AUC based on a novel use of hierarchical histograms that achieves MSE of $O(\\alpha^3/n\\epsilon^2)$ for arbitrary data distribution. We also show that 2-party secure computation allows to design a protocol with MSE of $O(1/n\\epsilon^2)$, without any assumption on the kernel function or data distribution and with total communication linear in the number of users $n$. Finally, we evaluate the performance of our protocols through experiments on synthetic and real datasets.",
        "bibtex": "@InProceedings{pmlr-v108-bell20a,\n  title = \t {Private Protocols for U-Statistics in the Local Model and Beyond},\n  author =       {Bell, James and Bellet, Aur\\'elien and Gascon, Adria and Kulkarni, Tejas},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1573--1583},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bell20a/bell20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bell20a.html},\n  abstract = \t {In this paper, we study the problem of computing $U$-statistics of degree $2$, i.e., quantities that come in the form of averages over pairs of data points, in the local model of differential privacy (LDP). The class of $U$-statistics covers many statistical estimates of interest, including Gini mean difference, Kendall\u2019s tau coefficient and Area under the ROC Curve (AUC), as well as empirical risk measures for machine learning problems such as ranking, clustering and metric learning. We first introduce an LDP protocol based on quantizing the data into bins and applying randomized response, which guarantees an $\\epsilon$-LDP estimate with a Mean Squared Error (MSE) of $O(1/\\sqrt{n}\\epsilon)$ under regularity assumptions on the $U$-statistic or the data distribution. We then propose a specialized protocol for AUC based on a novel use of hierarchical histograms that achieves MSE of $O(\\alpha^3/n\\epsilon^2)$ for arbitrary data distribution. We also show that 2-party secure computation allows to design a protocol with MSE of $O(1/n\\epsilon^2)$, without any assumption on the kernel function or data distribution and with total communication linear in the number of users $n$. Finally, we evaluate the performance of our protocols through experiments on synthetic and real datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bell20a/bell20a.pdf",
        "supp": "",
        "pdf_size": 543607,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17752116443234020999&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bcd774564e",
        "title": "Private k-Means Clustering with Stability Assumptions",
        "site": "https://proceedings.mlr.press/v108/shechner20a.html",
        "author": "Moshe Shechner; Or Sheffet; Uri Stemmer",
        "abstract": "We study the problem of differentially private clustering under input-stability assumptions. Despite the ever-growing volume of works on differential privacy in general and differentially private clustering in particular, only three works (Nissim et al., 2007; Wang et al., 2015; Huang and Liu, 2018) looked at the problem of privately clustering \"nice\" k-means instances, all three relying on the sample-and-aggregate framework and all three measuring utility in terms of Wasserstein distance between the true cluster centers and the centers returned by the private algorithm. In this work we improve upon this line of works on multiple axes. We present a simpler algorithm for clustering stable inputs (not relying on the sample-and-aggregate framework), and analyze its utility in both the Wasserstein distance and the k-means cost. Moreover, our algorithm has straight-forward analogues for \"nice\" k-median instances and for the local-model of differential privacy.",
        "bibtex": "@InProceedings{pmlr-v108-shechner20a,\n  title = \t {Private k-Means Clustering with Stability Assumptions},\n  author =       {Shechner, Moshe and Sheffet, Or and Stemmer, Uri},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2518--2528},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shechner20a/shechner20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shechner20a.html},\n  abstract = \t {We study the problem of differentially private clustering under input-stability assumptions. Despite the ever-growing volume of works on differential privacy in general and differentially private clustering in particular, only three works (Nissim et al., 2007; Wang et al., 2015; Huang and Liu, 2018) looked at the problem of privately clustering \"nice\" k-means instances, all three relying on the sample-and-aggregate framework and all three measuring utility in terms of Wasserstein distance between the true cluster centers and the centers returned by the private algorithm. In this work we improve upon this line of works on multiple axes. We present a simpler algorithm for clustering stable inputs (not relying on the sample-and-aggregate framework), and analyze its utility in both the Wasserstein distance and the k-means cost. Moreover, our algorithm has straight-forward analogues for \"nice\" k-median instances and for the local-model of differential privacy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shechner20a/shechner20a.pdf",
        "supp": "",
        "pdf_size": 353968,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2659212611285141653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "76cb5403bd",
        "title": "Prophets, Secretaries, and Maximizing the Probability of Choosing the Best",
        "site": "https://proceedings.mlr.press/v108/esfandiari20a.html",
        "author": "Hossein Esfandiari; MohammadTaghi Hajiaghayi; Brendan Lucier; Michael Mitzenmacher",
        "abstract": "Suppose a customer is faced with a sequence of fluctuating prices, such as for airfare or a product sold by a large online retailer. Given distributional information about what price they might face each day, how should they choose when to purchase in order to maximize the likelihood of getting the best price in retrospect? This is related to the classical secretary problem, but with values drawn from known distributions. In their pioneering work, Gilbert and Mosteller [\\textit{J. Amer. Statist. Assoc. 1966}] showed that when the values are drawn i.i.d., there is a thresholding algorithm that selects the best value with probability approximately 0.58010.5801. However, the more general problem with non-identical distributions has remained unsolved.In this paper, we provide an algorithm for the case of non-identical distributions that selects the maximum element with probability 1/e1/e, and we show that this is tight. We further show that if the observations arrive in a random order, this barrier of 1/e1/e can be broken using a static threshold algorithm, and we show that our success probability is the best possible for any single-threshold algorithm under random observation order. Moreover, we prove that one can achieve a strictly better success probability using more general multi-threshold algorithms, unlike the non-random-order case. Along the way, we show that the best achievable success probability for the random-order case matches that of the i.i.d. case, which is approximately 0.58010.5801, under a \u201cno-superstars\u201d condition that no single distribution is very likely ex ante to generate the maximum value. We also extend our results to the problem of selecting one of the kk best values.One of the main tools in our analysis is a suitable \u201cPoissonization\u201d of random order distributions, which uses Le Cam\u2019s theorem to connect the Poisson binomial distribution with the discrete Poisson distribution. This approach may be of independent interest.",
        "bibtex": "@InProceedings{pmlr-v108-esfandiari20a,\n  title = \t {Prophets, Secretaries, and Maximizing the Probability of Choosing the Best},\n  author =       {Esfandiari, Hossein and Hajiaghayi, MohammadTaghi and Lucier, Brendan and Mitzenmacher, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3717--3727},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/esfandiari20a/esfandiari20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/esfandiari20a.html},\n  abstract = \t {Suppose a customer is faced with a sequence of fluctuating prices, such as for airfare or a product sold by a large online retailer. Given distributional information about what price they might face each day, how should they choose when to purchase in order to maximize the likelihood of getting the best price in retrospect? This is related to the classical secretary problem, but with values drawn from known distributions. In their pioneering work, Gilbert and Mosteller [\\textit{J. Amer. Statist. Assoc. 1966}] showed that when the values are drawn i.i.d., there is a thresholding algorithm that selects the best value with probability approximately 0.58010.5801. However, the more general problem with non-identical distributions has remained unsolved.In this paper, we provide an algorithm for the case of non-identical distributions that selects the maximum element with probability 1/e1/e, and we show that this is tight. We further show that if the observations arrive in a random order, this barrier of 1/e1/e can be broken using a static threshold algorithm, and we show that our success probability is the best possible for any single-threshold algorithm under random observation order. Moreover, we prove that one can achieve a strictly better success probability using more general multi-threshold algorithms, unlike the non-random-order case. Along the way, we show that the best achievable success probability for the random-order case matches that of the i.i.d. case, which is approximately 0.58010.5801, under a \u201cno-superstars\u201d condition that no single distribution is very likely ex ante to generate the maximum value. We also extend our results to the problem of selecting one of the kk best values.One of the main tools in our analysis is a suitable \u201cPoissonization\u201d of random order distributions, which uses Le Cam\u2019s theorem to connect the Poisson binomial distribution with the discrete Poisson distribution. This approach may be of independent interest.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/esfandiari20a/esfandiari20a.pdf",
        "supp": "",
        "pdf_size": 333916,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=130269227760405911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a6bc307402",
        "title": "Purifying Interaction Effects with the Functional ANOVA: An Efficient Algorithm for Recovering Identifiable Additive Models",
        "site": "https://proceedings.mlr.press/v108/lengerich20a.html",
        "author": "Benjamin Lengerich; Sarah Tan; Chun-Hao Chang; Giles Hooker; Rich Caruana",
        "abstract": "Models which estimate main effects of individual variables alongside interaction effects have an identifiability challenge: effects can be freely moved between main effects and interaction effects without changing the model prediction. This is a critical problem for interpretability because it permits \u201ccontradictory\" models to represent the same function. To solve this problem, we propose pure interaction effects: variance in the outcome which cannot be represented by any subset of features. This definition has an equivalence with the Functional ANOVA decomposition. To compute this decomposition, we present a fast, exact algorithm that transforms any piecewise-constant function (such as a tree-based model) into a purified, canonical representation. We apply this algorithm to Generalized Additive Models with interactions trained on several datasets and show large disparity, including contradictions, between the apparent and the purified effects. These results underscore the need to specify data distributions and ensure identifiability before interpreting model parameters.",
        "bibtex": "@InProceedings{pmlr-v108-lengerich20a,\n  title = \t {Purifying Interaction Effects with the Functional ANOVA: An Efficient Algorithm for Recovering Identifiable Additive Models},\n  author =       {Lengerich, Benjamin and Tan, Sarah and Chang, Chun-Hao and Hooker, Giles and Caruana, Rich},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2402--2412},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lengerich20a/lengerich20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lengerich20a.html},\n  abstract = \t {Models which estimate main effects of individual variables alongside interaction effects have an identifiability challenge: effects can be freely moved between main effects and interaction effects without changing the model prediction. This is a critical problem for interpretability because it permits \u201ccontradictory\" models to represent the same function. To solve this problem, we propose pure interaction effects: variance in the outcome which cannot be represented by any subset of features. This definition has an equivalence with the Functional ANOVA decomposition. To compute this decomposition, we present a fast, exact algorithm that transforms any piecewise-constant function (such as a tree-based model) into a purified, canonical representation. We apply this algorithm to Generalized Additive Models with interactions trained on several datasets and show large disparity, including contradictions, between the apparent and the purified effects. These results underscore the need to specify data distributions and ensure identifiability before interpreting model parameters.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lengerich20a/lengerich20a.pdf",
        "supp": "",
        "pdf_size": 2330624,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14008556842635890912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Carnegie Mellon University; Cornell University; University of Toronto; Cornell University; Microsoft Research",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;3",
        "aff_unique_norm": "Carnegie Mellon University;Cornell University;University of Toronto;Microsoft",
        "aff_unique_dep": ";;;Microsoft Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.cornell.edu;https://www.utoronto.ca;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "CMU;Cornell;U of T;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "1fca5a7486",
        "title": "Quantitative stability of optimal transport maps and linearization of the 2-Wasserstein space",
        "site": "https://proceedings.mlr.press/v108/merigot20a.html",
        "author": "Quentin M\u00e9rigot; Alex Delalande; Frederic Chazal",
        "abstract": "This work studies an explicit embedding of the set of probability measures into a Hilbert space, defined using optimal transport maps from a reference probability density. This embedding linearizes to some extent the 2-Wasserstein space and is shown to be bi-H\u00f6lder continuous. It enables the direct use of generic supervised and unsupervised learning algorithms on measure data consistently w.r.t. the Wasserstein geometry.",
        "bibtex": "@InProceedings{pmlr-v108-merigot20a,\n  title = \t {Quantitative stability of optimal transport maps and linearization of the 2-Wasserstein space},\n  author =       {M\\'erigot, Quentin and Delalande, Alex and Chazal, Frederic},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3186--3196},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/merigot20a/merigot20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/merigot20a.html},\n  abstract = \t {This work studies an explicit embedding of the set of probability measures into a Hilbert space, defined using optimal transport maps from a reference probability density. This embedding linearizes to some extent the 2-Wasserstein space and is shown to be bi-H\u00f6lder continuous. It enables the direct use of generic supervised and unsupervised learning algorithms on measure data consistently w.r.t. the Wasserstein geometry.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/merigot20a/merigot20a.pdf",
        "supp": "",
        "pdf_size": 4225377,
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14435765504450074206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7112b74c50",
        "title": "Quantized Frank-Wolfe: Faster Optimization, Lower Communication,  and Projection Free",
        "site": "https://proceedings.mlr.press/v108/zhang20g.html",
        "author": "Mingrui Zhang; Lin Chen; Aryan Mokhtari; Hamed Hassani; Amin Karbasi",
        "abstract": "How can we efficiently mitigate the overhead of gradient communications in distributed optimization? This problem is at the heart of training scalable machine learning models and has been mainly studied in the unconstrained setting. In this paper, we propose Quantised Frank-Wolfe (QFW), the first projection free and communication-efficient algorithm for solving constrained optimization problems at scale. We consider both convex and non-convex objective functions, expressed as a finite-sum or more generally a stochastic optimization problem, and provide strong theoretical guarantees on the convergence rate of QFW. This is accomplished by proposing novel quantization schemes that efficiently compress gradients while controlling the noise variance intduced during this process. Finally, we empirically validate the efficiency of QFW in terms of communication and the quality of returned solution against natural baselines.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20g,\n  title = \t {Quantized Frank-Wolfe: Faster Optimization, Lower Communication,  and Projection Free},\n  author =       {Zhang, Mingrui and Chen, Lin and Mokhtari, Aryan and Hassani, Hamed and Karbasi, Amin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3696--3706},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20g/zhang20g.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20g.html},\n  abstract = \t {How can we efficiently mitigate the overhead of gradient communications in distributed optimization? This problem is at the heart of training scalable machine learning models and has been mainly studied in the unconstrained setting. In this paper, we propose Quantised Frank-Wolfe (QFW), the first projection free and communication-efficient algorithm for solving constrained optimization problems at scale. We consider both convex and non-convex objective functions, expressed as a finite-sum or more generally a stochastic optimization problem, and provide strong theoretical guarantees on the convergence rate of QFW. This is accomplished by proposing novel quantization schemes that efficiently compress gradients while controlling the noise variance intduced during this process. Finally, we empirically validate the efficiency of QFW in terms of communication and the quality of returned solution against natural baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20g/zhang20g.pdf",
        "supp": "",
        "pdf_size": 2159466,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18262074398649009195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Yale University; Yale University; University of Texas at Austin; University of Pennsylvania; Yale University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Yale University;University of Texas at Austin;University of Pennsylvania",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.yale.edu;https://www.utexas.edu;https://www.upenn.edu",
        "aff_unique_abbr": "Yale;UT Austin;UPenn",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "073c5079ab",
        "title": "RATQ: A Universal Fixed-Length Quantizer for Stochastic Optimization",
        "site": "https://proceedings.mlr.press/v108/mayekar20a.html",
        "author": "Prathamesh Mayekar; Himanshu Tyagi",
        "abstract": "We present Rotated Adaptive Tetra-iterated Quantizer (RATQ), afixed-length quantizer for gradients in first order stochasticoptimization.  RATQ is easy to implement and involves only a Hadamard transform computation and adaptive uniform quantization with appropriately chosen dynamic ranges. For noisy gradients with almost surely bounded Euclidean norms, we establish an informationtheoretic lower bound for optimization accuracy using finite precisiongradients and show that RATQ almost attains this lower bound.  For mean square bounded noisy gradients, we use a                                                             gain-shape quantizer which separately quantizes the Euclidean norm and uses RATQ to quantize the normalized unit norm vector. We establish lower bounds for performance of any optimization procedure and shape quantizer, when used with a uniform gain quantizer. Finally, we propose an adaptive quantizer for gain which when used with RATQ for shape quantizer outperforms uniform gain quantization and is, in fact, close to optimal.",
        "bibtex": "@InProceedings{pmlr-v108-mayekar20a,\n  title = \t {RATQ: A Universal Fixed-Length Quantizer for Stochastic Optimization},\n  author =       {Mayekar, Prathamesh and Tyagi, Himanshu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1399--1409},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mayekar20a/mayekar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mayekar20a.html},\n  abstract = \t {We present Rotated Adaptive Tetra-iterated Quantizer (RATQ), afixed-length quantizer for gradients in first order stochasticoptimization.  RATQ is easy to implement and involves only a Hadamard transform computation and adaptive uniform quantization with appropriately chosen dynamic ranges. For noisy gradients with almost surely bounded Euclidean norms, we establish an informationtheoretic lower bound for optimization accuracy using finite precisiongradients and show that RATQ almost attains this lower bound.  For mean square bounded noisy gradients, we use a                                                             gain-shape quantizer which separately quantizes the Euclidean norm and uses RATQ to quantize the normalized unit norm vector. We establish lower bounds for performance of any optimization procedure and shape quantizer, when used with a uniform gain quantizer. Finally, we propose an adaptive quantizer for gain which when used with RATQ for shape quantizer outperforms uniform gain quantization and is, in fact, close to optimal. \u00a0}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mayekar20a/mayekar20a.pdf",
        "supp": "",
        "pdf_size": 508975,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12854569227152717680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Indian Institute of Science; Indian Institute of Science",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "c0048d6149",
        "title": "RCD: Repetitive causal discovery of linear non-Gaussian acyclic models with latent confounders",
        "site": "https://proceedings.mlr.press/v108/maeda20a.html",
        "author": "Takashi Nicholas Maeda; Shohei Shimizu",
        "abstract": "Causal discovery from data affected by latent confounders is an important and difficult challenge. Causal functional model-based approaches have not been used to present variables whose relationships are affected by latent confounders, while some constraint-based methods can present them. This paper proposes a causal functional model-based method called repetitive causal discovery (RCD) to discover the causal structure of observed variables affected by latent confounders. RCD repeats inferring the causal directions between a small number of observed variables and determines whether the relationships are affected by latent confounders. RCD finally produces a causal graph where a bi-directed arrow indicates the pair of variables that have the same latent confounders, and a directed arrow indicates the causal direction of a pair of variables that are not affected by the same latent confounder. The results of experimental validation using simulated data and real-world data confirmed that RCD is effective in identifying latent confounders and causal directions between observed variables.",
        "bibtex": "@InProceedings{pmlr-v108-maeda20a,\n  title = \t {RCD: Repetitive causal discovery of linear non-Gaussian acyclic models with latent confounders},\n  author =       {Maeda, Takashi Nicholas and Shimizu, Shohei},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {735--745},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/maeda20a/maeda20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/maeda20a.html},\n  abstract = \t {Causal discovery from data affected by latent confounders is an important and difficult challenge. Causal functional model-based approaches have not been used to present variables whose relationships are affected by latent confounders, while some constraint-based methods can present them. This paper proposes a causal functional model-based method called repetitive causal discovery (RCD) to discover the causal structure of observed variables affected by latent confounders. RCD repeats inferring the causal directions between a small number of observed variables and determines whether the relationships are affected by latent confounders. RCD finally produces a causal graph where a bi-directed arrow indicates the pair of variables that have the same latent confounders, and a directed arrow indicates the causal direction of a pair of variables that are not affected by the same latent confounder. The results of experimental validation using simulated data and real-world data confirmed that RCD is effective in identifying latent confounders and causal directions between observed variables.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/maeda20a/maeda20a.pdf",
        "supp": "",
        "pdf_size": 911361,
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11614218924941644902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "RIKEN Center for Advanced Intelligence Project; Shiga University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "RIKEN;Shiga University",
        "aff_unique_dep": "Center for Advanced Intelligence Project;",
        "aff_unique_url": "https://www.riken.jp/en/;https://www.shiga-u.ac.jp",
        "aff_unique_abbr": "RIKEN;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "dcade11ab5",
        "title": "Radial Bayesian Neural Networks: Beyond Discrete Support In Large-Scale Bayesian Deep Learning",
        "site": "https://proceedings.mlr.press/v108/farquhar20a.html",
        "author": "Sebastian Farquhar; Michael A. Osborne; Yarin Gal",
        "abstract": "We propose Radial Bayesian Neural Networks (BNNs): a variational approximate posterior for BNNs which scales well to large models.  Unlike scalable Bayesian deep learning methods like deep ensembles that have discrete support (assign exactly zero probability almost everywhere in weight-space) Radial BNNs maintain full support; letting them act as a prior for continual learning and avoiding the a priori implausibility of discrete support.  Our method avoids a sampling problem in mean-field variational inference (MFVI) caused by the so-called \u2019soap-bubble\u2019 pathology of multivariate Gaussians.  We show that, unlike MFVI, Radial BNNs are robust to hyperparameters and can be efficiently applied to challenging real-world tasks without needing ad-hoc tweaks and intensive tuning: on a real-world medical imaging task Radial BNNs outperform MC dropout and deep ensembles.",
        "bibtex": "@InProceedings{pmlr-v108-farquhar20a,\n  title = \t {Radial Bayesian Neural Networks: Beyond Discrete Support In Large-Scale Bayesian Deep Learning},\n  author =       {Farquhar, Sebastian and Osborne, Michael A. and Gal, Yarin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1352--1362},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/farquhar20a/farquhar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/farquhar20a.html},\n  abstract = \t {We propose Radial Bayesian Neural Networks (BNNs): a variational approximate posterior for BNNs which scales well to large models.  Unlike scalable Bayesian deep learning methods like deep ensembles that have discrete support (assign exactly zero probability almost everywhere in weight-space) Radial BNNs maintain full support; letting them act as a prior for continual learning and avoiding the a priori implausibility of discrete support.  Our method avoids a sampling problem in mean-field variational inference (MFVI) caused by the so-called \u2019soap-bubble\u2019 pathology of multivariate Gaussians.  We show that, unlike MFVI, Radial BNNs are robust to hyperparameters and can be efficiently applied to challenging real-world tasks without needing ad-hoc tweaks and intensive tuning: on a real-world medical imaging task Radial BNNs outperform MC dropout and deep ensembles.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/farquhar20a/farquhar20a.pdf",
        "supp": "",
        "pdf_size": 2145652,
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13410734264891373824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "316962688d",
        "title": "Randomized Exploration in Generalized Linear Bandits",
        "site": "https://proceedings.mlr.press/v108/kveton20a.html",
        "author": "Branislav Kveton; Manzil Zaheer; Csaba Szepesvari; Lihong Li; Mohammad Ghavamzadeh; Craig Boutilier",
        "abstract": "We study two randomized algorithms for generalized linear bandits. The first, GLM-TSL, samples a generalized linear model (GLM) from the Laplace approximation to the posterior distribution. The second, GLM-FPL, fits a GLM to a randomly perturbed history of past rewards. We analyze both algorithms and derive $\\tilde{O}(d \\sqrt{n \\log K})$ upper bounds on their $n$-round regret, where $d$ is the number of features and $K$ is the number of arms. The former improves on prior work while the latter is the first for Gaussian noise perturbations in non-linear models. We empirically evaluate both GLM-TSL and GLM-FPL in logistic bandits, and apply GLM-FPL to neural network bandits. Our work showcases the role of randomization, beyond posterior sampling, in exploration.",
        "bibtex": "@InProceedings{pmlr-v108-kveton20a,\n  title = \t {Randomized Exploration in Generalized Linear Bandits},\n  author =       {Kveton, Branislav and Zaheer, Manzil and Szepesvari, Csaba and Li, Lihong and Ghavamzadeh, Mohammad and Boutilier, Craig},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2066--2076},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kveton20a/kveton20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kveton20a.html},\n  abstract = \t {We study two randomized algorithms for generalized linear bandits. The first, GLM-TSL, samples a generalized linear model (GLM) from the Laplace approximation to the posterior distribution. The second, GLM-FPL, fits a GLM to a randomly perturbed history of past rewards. We analyze both algorithms and derive $\\tilde{O}(d \\sqrt{n \\log K})$ upper bounds on their $n$-round regret, where $d$ is the number of features and $K$ is the number of arms. The former improves on prior work while the latter is the first for Gaussian noise perturbations in non-linear models. We empirically evaluate both GLM-TSL and GLM-FPL in logistic bandits, and apply GLM-FPL to neural network bandits. Our work showcases the role of randomization, beyond posterior sampling, in exploration.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kveton20a/kveton20a.pdf",
        "supp": "",
        "pdf_size": 2596458,
        "gs_citation": 138,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12395651946752730943&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fa4d8c77a9",
        "title": "Recommendation on a Budget: Column Space Recovery from Partially Observed Entries with Random or Active Sampling",
        "site": "https://proceedings.mlr.press/v108/kim20a.html",
        "author": "Carolyn Kim; Mohsen Bayati",
        "abstract": "We analyze alternating minimization for column space recovery of a partially observed, approximately low rank matrix with a growing number of columns and a fixed budget of observations per column. We prove that if the budget is greater than the rank of the matrix, column space recovery succeeds \u2013 as the number of columns grows, the estimate from alternating minimization converges to the true column space with probability tending to one. From our proof techniques, we naturally formulate an active sampling strategy for choosing entries of a column that is theoretically and empirically (on synthetic and real data) better than the commonly studied uniformly  random sampling strategy.",
        "bibtex": "@InProceedings{pmlr-v108-kim20a,\n  title = \t {Recommendation on a Budget: Column Space Recovery from Partially Observed Entries with Random or Active Sampling},\n  author =       {Kim, Carolyn and Bayati, Mohsen},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {445--455},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kim20a/kim20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kim20a.html},\n  abstract = \t {We analyze alternating minimization for column space recovery of a partially observed, approximately low rank matrix with a growing number of columns and a fixed budget of observations per column. We prove that if the budget is greater than the rank of the matrix, column space recovery succeeds \u2013 as the number of columns grows, the estimate from alternating minimization converges to the true column space with probability tending to one. From our proof techniques, we naturally formulate an active sampling strategy for choosing entries of a column that is theoretically and empirically (on synthetic and real data) better than the commonly studied uniformly  random sampling strategy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kim20a/kim20a.pdf",
        "supp": "",
        "pdf_size": 1299612,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3820068609969537948&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Stanford University; Stanford University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "113b75146f",
        "title": "Regularity as Regularization: Smooth and Strongly Convex Brenier Potentials in Optimal Transport",
        "site": "https://proceedings.mlr.press/v108/paty20a.html",
        "author": "Fran\u00e7ois-Pierre Paty; Alexandre d\u2019Aspremont; Marco Cuturi",
        "abstract": "Estimating Wasserstein distances between two high-dimensional densities suffers from the curse of dimensionality: one needs an exponential (wrt dimension) number of samples to ensure that the distance between two empirical measures is comparable to the distance between the original densities. Therefore, optimal transport (OT) can only be used in machine learning if it is substantially regularized. On the other hand, one of the greatest achievements of the OT literature in recent years lies in regularity theory: Caffarelli showed that the OT map between two well behaved measures is Lipschitz, or equivalently when considering 2-Wasserstein distances, that Brenier convex potentials (whose gradient yields an optimal map) are smooth. We propose in this work to draw inspiration from this theory and use regularity as a regularization tool. We give algorithms operating on two discrete measures that can recover nearly optimal transport maps with small distortion, or equivalently, nearly optimal Brenier potentials that are strongly convex and smooth. The problem boils down to solving alternatively a convex QCQP and a discrete OT problem, granting access to the values and gradients of the Brenier potential not only on sampled points, but also out of sample at the cost of solving a simpler QCQP for each evaluation. We propose algorithms to estimate and evaluate transport maps with desired regularity properties, benchmark their statistical performance, apply them to domain adaptation and visualize their action on a color transfer task.",
        "bibtex": "@InProceedings{pmlr-v108-paty20a,\n  title = \t {Regularity as Regularization: Smooth and Strongly Convex Brenier Potentials in Optimal Transport},\n  author =       {Paty, Fran{\\c}ois-Pierre and d'Aspremont, Alexandre and Cuturi, Marco},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1222--1232},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/paty20a/paty20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/paty20a.html},\n  abstract = \t {Estimating Wasserstein distances between two high-dimensional densities suffers from the curse of dimensionality: one needs an exponential (wrt dimension) number of samples to ensure that the distance between two empirical measures is comparable to the distance between the original densities. Therefore, optimal transport (OT) can only be used in machine learning if it is substantially regularized. On the other hand, one of the greatest achievements of the OT literature in recent years lies in regularity theory: Caffarelli showed that the OT map between two well behaved measures is Lipschitz, or equivalently when considering 2-Wasserstein distances, that Brenier convex potentials (whose gradient yields an optimal map) are smooth. We propose in this work to draw inspiration from this theory and use regularity as a regularization tool. We give algorithms operating on two discrete measures that can recover nearly optimal transport maps with small distortion, or equivalently, nearly optimal Brenier potentials that are strongly convex and smooth. The problem boils down to solving alternatively a convex QCQP and a discrete OT problem, granting access to the values and gradients of the Brenier potential not only on sampled points, but also out of sample at the cost of solving a simpler QCQP for each evaluation. We propose algorithms to estimate and evaluate transport maps with desired regularity properties, benchmark their statistical performance, apply them to domain adaptation and visualize their action on a color transfer task.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/paty20a/paty20a.pdf",
        "supp": "",
        "pdf_size": 5470895,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8836117888506329825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "CREST, ENSAE, Institut Polytechnique de Paris; CNRS, ENS, PSL Research University; Google Brain, CREST, ENSAE",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Institut Polytechnique de Paris;CNRS;Google",
        "aff_unique_dep": "CREST;;Google Brain",
        "aff_unique_url": "https://www.ipparis.fr;https://www.cnrs.fr;https://brain.google.com",
        "aff_unique_abbr": "IP Paris;CNRS;Google Brain",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "2406e90a04",
        "title": "Regularization via Structural Label Smoothing",
        "site": "https://proceedings.mlr.press/v108/li20e.html",
        "author": "Weizhi Li; Gautam Dasarathy; Visar Berisha",
        "abstract": "Regularization is an effective way to promote the generalization performance of machine learning models. In this paper, we focus on label smoothing, a form of output distribution regularization that prevents overfitting of a neural network by softening the ground-truth labels in the training data in an attempt to penalize overconfident outputs. Existing approaches typically use cross-validation to impose this smoothing, which is uniform across all training data. In this paper, we show that such label smoothing imposes a quantifiable bias in the Bayes error rate of the training data, with regions of the feature space with high overlap and low marginal likelihood having a lower bias and regions of low overlap and high marginal likelihood having a higher bias. These theoretical results motivate a simple objective function for data-dependent smoothing to mitigate the potential negative consequences of the operation while maintaining its desirable properties as a regularizer. We call this approach Structural Label Smoothing (SLS). We implement SLS and empirically validate on synthetic, Higgs, SVHN, CIFAR-10, and CIFAR-100 datasets. The results confirm our theoretical insights and demonstrate the effectiveness of the proposed method in comparison to traditional label smoothing.",
        "bibtex": "@InProceedings{pmlr-v108-li20e,\n  title = \t {Regularization via Structural Label Smoothing},\n  author =       {Li, Weizhi and Dasarathy, Gautam and Berisha, Visar},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1453--1463},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20e/li20e.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20e.html},\n  abstract = \t {Regularization is an effective way to promote the generalization performance of machine learning models. In this paper, we focus on label smoothing, a form of output distribution regularization that prevents overfitting of a neural network by softening the ground-truth labels in the training data in an attempt to penalize overconfident outputs. Existing approaches typically use cross-validation to impose this smoothing, which is uniform across all training data. In this paper, we show that such label smoothing imposes a quantifiable bias in the Bayes error rate of the training data, with regions of the feature space with high overlap and low marginal likelihood having a lower bias and regions of low overlap and high marginal likelihood having a higher bias. These theoretical results motivate a simple objective function for data-dependent smoothing to mitigate the potential negative consequences of the operation while maintaining its desirable properties as a regularizer. We call this approach Structural Label Smoothing (SLS). We implement SLS and empirically validate on synthetic, Higgs, SVHN, CIFAR-10, and CIFAR-100 datasets. The results confirm our theoretical insights and demonstrate the effectiveness of the proposed method in comparison to traditional label smoothing.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20e/li20e.pdf",
        "supp": "",
        "pdf_size": 1177842,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1658395646823943781&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a3866027e1",
        "title": "Regularized Autoencoders via Relaxed Injective Probability Flow",
        "site": "https://proceedings.mlr.press/v108/kumar20a.html",
        "author": "Abhishek Kumar; Ben Poole; Kevin Murphy",
        "abstract": "Invertible flow-based generative models are an effective method for learning to generate samples, while allowing for tractable likelihood computation and inference. However, the invertibility requirement restricts models to have the same latent dimensionality as the inputs. This imposes significant architectural, memory, and computational costs,  making them more challenging to scale than other classes of generative models such as Variational Autoencoders (VAEs). We propose a generative model based on probability flows that does away with the bijectivity requirement on the model and only assumes injectivity. This also provides another perspective on regularized autoencoders (RAEs), with our final objectives resembling RAEs with specific regularizers that are derived by lower bounding the probability flow objective. We empirically demonstrate the promise of the proposed model, improving over VAEs and AEs in terms of sample quality.",
        "bibtex": "@InProceedings{pmlr-v108-kumar20a,\n  title = \t {Regularized Autoencoders via Relaxed Injective Probability Flow},\n  author =       {Kumar, Abhishek and Poole, Ben and Murphy, Kevin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4292--4301},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kumar20a/kumar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kumar20a.html},\n  abstract = \t {Invertible flow-based generative models are an effective method for learning to generate samples, while allowing for tractable likelihood computation and inference. However, the invertibility requirement restricts models to have the same latent dimensionality as the inputs. This imposes significant architectural, memory, and computational costs,  making them more challenging to scale than other classes of generative models such as Variational Autoencoders (VAEs). We propose a generative model based on probability flows that does away with the bijectivity requirement on the model and only assumes injectivity. This also provides another perspective on regularized autoencoders (RAEs), with our final objectives resembling RAEs with specific regularizers that are derived by lower bounding the probability flow objective. We empirically demonstrate the promise of the proposed model, improving over VAEs and AEs in terms of sample quality.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kumar20a/kumar20a.pdf",
        "supp": "",
        "pdf_size": 3728585,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11853504008461106718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6d5b21c354",
        "title": "RelatIF: Identifying Explanatory Training Samples via Relative Influence",
        "site": "https://proceedings.mlr.press/v108/barshan20a.html",
        "author": "Elnaz Barshan; Marc-Etienne Brunet; Gintare Karolina Dziugaite",
        "abstract": "In this work, we focus on the use of influence functions to identify relevant training examples that one might hope \u201cexplain\u201d the predictions of a machine learning model. One shortcoming of influence functions is that the training examples deemed most \u201cinfluential\u201d are often outliers or mislabelled, making them poor choices for explanation. In order to address this shortcoming, we separate the role of global versus local influence. We introduce RelatIF, a new class of criteria for choosing relevant training examples by way of an optimization objective that places a constraint on global influence. RelatIF considers the local influence that an explanatory example has on a prediction relative to its global effects on the model. In empirical evaluations, we find that the examples returned by RelatIF are more intuitive when compared to those found using influence functions.",
        "bibtex": "@InProceedings{pmlr-v108-barshan20a,\n  title = \t {RelatIF: Identifying Explanatory Training Samples via Relative Influence},\n  author =       {Barshan, Elnaz and Brunet, Marc-Etienne and Dziugaite, Gintare Karolina},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1899--1909},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/barshan20a/barshan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/barshan20a.html},\n  abstract = \t {In this work, we focus on the use of influence functions to identify relevant training examples that one might hope \u201cexplain\u201d the predictions of a machine learning model. One shortcoming of influence functions is that the training examples deemed most \u201cinfluential\u201d are often outliers or mislabelled, making them poor choices for explanation. In order to address this shortcoming, we separate the role of global versus local influence. We introduce RelatIF, a new class of criteria for choosing relevant training examples by way of an optimization objective that places a constraint on global influence. RelatIF considers the local influence that an explanatory example has on a prediction relative to its global effects on the model. In empirical evaluations, we find that the examples returned by RelatIF are more intuitive when compared to those found using influence functions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/barshan20a/barshan20a.pdf",
        "supp": "",
        "pdf_size": 1836775,
        "gs_citation": 133,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10007846691829314610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "00ed06a7dd",
        "title": "Rep the Set: Neural Networks for Learning Set Representations",
        "site": "https://proceedings.mlr.press/v108/skianis20a.html",
        "author": "Konstantinos Skianis; Giannis Nikolentzos; Stratis Limnios; Michalis Vazirgiannis",
        "abstract": "In several domains, data objects can be decomposed into sets of simpler objects. It is then natural to represent each object as the set of its components or parts. Many conventional machine learning algorithms are unable to process this kind of representations, since sets may vary in cardinality and elements lack a meaningful ordering. In this paper, we present a new neural network architecture, called RepSet, that can handle examples that are represented as sets of vectors. The proposed model computes the correspondences between an input set and some hidden sets by solving a series of network flow problems. This representation is then fed to a standard neural network architecture to produce the output. The architecture allows end-to-end gradient-based learning. We demonstrate RepSet on classification tasks, including text categorization, and graph classification, and we show that the proposed neural network achieves performance better or comparable to state-of-the-art algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-skianis20a,\n  title = \t {Rep the Set: Neural Networks for Learning Set Representations},\n  author =       {Skianis, Konstantinos and Nikolentzos, Giannis and Limnios, Stratis and Vazirgiannis, Michalis},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1410--1420},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/skianis20a/skianis20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/skianis20a.html},\n  abstract = \t {In several domains, data objects can be decomposed into sets of simpler objects. It is then natural to represent each object as the set of its components or parts. Many conventional machine learning algorithms are unable to process this kind of representations, since sets may vary in cardinality and elements lack a meaningful ordering. In this paper, we present a new neural network architecture, called RepSet, that can handle examples that are represented as sets of vectors. The proposed model computes the correspondences between an input set and some hidden sets by solving a series of network flow problems. This representation is then fed to a standard neural network architecture to produce the output. The architecture allows end-to-end gradient-based learning. We demonstrate RepSet on classification tasks, including text categorization, and graph classification, and we show that the proposed neural network achieves performance better or comparable to state-of-the-art algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/skianis20a/skianis20a.pdf",
        "supp": "",
        "pdf_size": 660661,
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5613078893268975518&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "53c7e6c629",
        "title": "Revisiting Stochastic Extragradient",
        "site": "https://proceedings.mlr.press/v108/mishchenko20a.html",
        "author": "Konstantin Mishchenko; Dmitry Kovalev; Egor Shulgin; Peter Richtarik; Yura Malitsky",
        "abstract": "We fix a fundamental issue in the stochastic extragradient method by providing a new sampling strategy that is motivated by approximating implicit updates. Since the existing stochastic extragradient algorithm, called Mirror-Prox, of (Juditsky, 2011) diverges on a simple bilinear problem when the domain is not bounded, we prove guarantees for solving variational inequality that go beyond existing settings. Furthermore, we illustrate numerically that the proposed variant converges faster than many other methods on several convex-concave saddle-point problems. We also discuss how extragradient can be applied to training Generative Adversarial Networks (GANs) and how it compares to other methods. Our experiments on GANs demonstrate that the introduced approach may make the training faster in terms of data passes, while its higher iteration complexity makes the advantage smaller.",
        "bibtex": "@InProceedings{pmlr-v108-mishchenko20a,\n  title = \t {Revisiting Stochastic Extragradient},\n  author =       {Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richtarik, Peter and Malitsky, Yura},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4573--4582},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mishchenko20a/mishchenko20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mishchenko20a.html},\n  abstract = \t {We fix a fundamental issue in the stochastic extragradient method by providing a new sampling strategy that is motivated by approximating implicit updates. Since the existing stochastic extragradient algorithm, called Mirror-Prox, of (Juditsky, 2011) diverges on a simple bilinear problem when the domain is not bounded, we prove guarantees for solving variational inequality that go beyond existing settings. Furthermore, we illustrate numerically that the proposed variant converges faster than many other methods on several convex-concave saddle-point problems. We also discuss how extragradient can be applied to training Generative Adversarial Networks (GANs) and how it compares to other methods. Our experiments on GANs demonstrate that the introduced approach may make the training faster in terms of data passes, while its higher iteration complexity makes the advantage smaller.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mishchenko20a/mishchenko20a.pdf",
        "supp": "",
        "pdf_size": 4952022,
        "gs_citation": 101,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8653605232017703121&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "KAUST; KAUST; KAUST+MIPT; KAUST; EPFL",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0;2",
        "aff_unique_norm": "King Abdullah University of Science and Technology;Moscow Institute of Physics and Technology;EPFL",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.kaust.edu.sa;https://mipt.ru;https://www.epfl.ch",
        "aff_unique_abbr": "KAUST;MIPT;EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1;0;2",
        "aff_country_unique": "Saudi Arabia;Russian Federation;Switzerland"
    },
    {
        "id": "ebc817933d",
        "title": "Revisiting the Landscape of Matrix Factorization",
        "site": "https://proceedings.mlr.press/v108/valavi20a.html",
        "author": "Hossein Valavi; Sulin Liu; Peter Ramadge",
        "abstract": "Prior work has shown that low-rank matrix factorization has infinitely many critical points, each of which is either a global minimum or a (strict) saddle point. We revisit this problem and provide simple, intuitive proofs of a set of extended results for low-rank and general-rank problems. We couple our investigation with a known invariant manifold M0 of gradient flow. This restriction admits a uniform negative upper bound on the least eigenvalue of the Hessian map at all strict saddles in M0. The bound depends on the size of the nonzero singular values and the separation between distinct singular values of the matrix to be factorized.",
        "bibtex": "@InProceedings{pmlr-v108-valavi20a,\n  title = \t {Revisiting the Landscape of Matrix Factorization},\n  author =       {Valavi, Hossein and Liu, Sulin and Ramadge, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1629--1638},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/valavi20a/valavi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/valavi20a.html},\n  abstract = \t {Prior work has shown that low-rank matrix factorization has infinitely many critical points, each of which is either a global minimum or a (strict) saddle point. We revisit this problem and provide simple, intuitive proofs of a set of extended results for low-rank and general-rank problems. We couple our investigation with a known invariant manifold M0 of gradient flow. This restriction admits a uniform negative upper bound on the least eigenvalue of the Hessian map at all strict saddles in M0. The bound depends on the size of the nonzero singular values and the separation between distinct singular values of the matrix to be factorized.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/valavi20a/valavi20a.pdf",
        "supp": "",
        "pdf_size": 474472,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1526142208721944984&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering, Princeton University; Department of Electrical Engineering, Princeton University; Department of Electrical Engineering, Princeton University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "721724d617",
        "title": "Risk Bounds for Learning Multiple Components with Permutation-Invariant Losses",
        "site": "https://proceedings.mlr.press/v108/lauer20a.html",
        "author": "Fabien Lauer",
        "abstract": "This paper proposes a simple approach to derive efficient error bounds for learning multiple components with sparsity-inducing regularization. We show that for such regularization schemes, known decompositions of the Rademacher complexity over the components can be used in a more efficient manner to result in tighter bounds without too much effort. We give examples of application to switching regression and center-based clustering/vector quantization. Then, the complete workflow is illustrated on the problem of subspace clustering, for which decomposition results were not previously available. For all these problems, the proposed approach yields risk bounds with mild dependencies on the number of components and completely removes this dependence for nonconvex regularization schemes that could not be handled by previous methods.",
        "bibtex": "@InProceedings{pmlr-v108-lauer20a,\n  title = \t {Risk Bounds for Learning Multiple Components with Permutation-Invariant Losses},\n  author =       {Lauer, Fabien},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1178--1187},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lauer20a/lauer20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lauer20a.html},\n  abstract = \t {This paper proposes a simple approach to derive efficient error bounds for learning multiple components with sparsity-inducing regularization. We show that for such regularization schemes, known decompositions of the Rademacher complexity over the components can be used in a more efficient manner to result in tighter bounds without too much effort. We give examples of application to switching regression and center-based clustering/vector quantization. Then, the complete workflow is illustrated on the problem of subspace clustering, for which decomposition results were not previously available. For all these problems, the proposed approach yields risk bounds with mild dependencies on the number of components and completely removes this dependence for nonconvex regularization schemes that could not be handled by previous methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lauer20a/lauer20a.pdf",
        "supp": "",
        "pdf_size": 271253,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17043758081996452653&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Universit\u00e9 de Lorraine, CNRS, LORIA, F-54000 Nancy, France",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Universit\u00e9 de Lorraine",
        "aff_unique_dep": "LORIA",
        "aff_unique_url": "https://www.univ-lorraine.fr",
        "aff_unique_abbr": "UL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Nancy",
        "aff_country_unique_index": "0",
        "aff_country_unique": "France"
    },
    {
        "id": "bafcf5ff65",
        "title": "Rk-means: Fast Clustering for Relational Data",
        "site": "https://proceedings.mlr.press/v108/curtin20a.html",
        "author": "Ryan Curtin; Benjamin Moseley; Hung Ngo; XuanLong Nguyen; Dan Olteanu; Maximilian Schleich",
        "abstract": "Conventional machine learning algorithms cannot be applied until a data matrix is available to process. When the data matrix needs to be obtained from a relational database via a feature extraction query, the computation cost can be prohibitive, as the data matrix may be (much) larger than the total input relation size.  This paper introduces Rk-means, or relational k-means algorithm, for clustering relational data tuples without having to access the full data matrix. As such, we avoid having to run the expensive feature extraction query and storing its output. Our algorithm leverages the underlying structures in relational data. It involves construction of a small grid coreset of the data matrix for subsequent cluster construction.  This gives a constant approximation for the k-means objective, while having asymptotic runtime improvements over standard approaches of first running the database query and then clustering. Empirical results show orders-of-magnitude speedup, and Rk-means can run faster on the database than even just computing the data matrix.",
        "bibtex": "@InProceedings{pmlr-v108-curtin20a,\n  title = \t {Rk-means: Fast Clustering for Relational Data},\n  author =       {Curtin, Ryan and Moseley, Benjamin and Ngo, Hung and Nguyen, XuanLong and Olteanu, Dan and Schleich, Maximilian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2742--2752},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/curtin20a/curtin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/curtin20a.html},\n  abstract = \t {Conventional machine learning algorithms cannot be applied until a data matrix is available to process. When the data matrix needs to be obtained from a relational database via a feature extraction query, the computation cost can be prohibitive, as the data matrix may be (much) larger than the total input relation size.  This paper introduces Rk-means, or relational k-means algorithm, for clustering relational data tuples without having to access the full data matrix. As such, we avoid having to run the expensive feature extraction query and storing its output. Our algorithm leverages the underlying structures in relational data. It involves construction of a small grid coreset of the data matrix for subsequent cluster construction.  This gives a constant approximation for the k-means objective, while having asymptotic runtime improvements over standard approaches of first running the database query and then clustering. Empirical results show orders-of-magnitude speedup, and Rk-means can run faster on the database than even just computing the data matrix.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/curtin20a/curtin20a.pdf",
        "supp": "",
        "pdf_size": 766471,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15725454787727428978&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "RelationalAI; Tepper School of Business, Carnegie Mellon University + RelationalAI; RelationalAI; Department of Statistics, University of Michigan; University of Oxford; University of Oxford",
        "aff_domain": "ratml.org;andrew.cmu.edu;relational.ai;umich.edu;cs.ox.ac.uk;cs.ox.ac.uk",
        "email": "ratml.org;andrew.cmu.edu;relational.ai;umich.edu;cs.ox.ac.uk;cs.ox.ac.uk",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;2;3;3",
        "aff_unique_norm": "RelationalAI;Carnegie Mellon University;University of Michigan;University of Oxford",
        "aff_unique_dep": ";Tepper School of Business;Department of Statistics;",
        "aff_unique_url": "https://www.relationalai.com;https://www.cmu.edu;https://www.umich.edu;https://www.ox.ac.uk",
        "aff_unique_abbr": "RelationalAI;CMU;UM;Oxford",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Ann Arbor",
        "aff_country_unique_index": "0;0+0;0;0;1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "098a923d69",
        "title": "Robust Importance Weighting for  Covariate Shift",
        "site": "https://proceedings.mlr.press/v108/li20b.html",
        "author": "Fengpei Li; Henry Lam; Siddharth Prusty",
        "abstract": "In many learning problems, the training and testing data follow different distributions and a particularly common situation is the \\textit{covariate shift}. To correct for sampling biases, most approaches, including the popular kernel mean matching (KMM), focus on estimating the importance weights between the two distributions. Reweighting-based methods, however, are exposed to high variance when the distributional discrepancy is large. On the other hand, the alternate approach of using nonparametric regression (NR) incurs high bias when the training size is limited. In this paper, we propose and analyze a new estimator that systematically integrates the residuals of NR with KMM reweighting, based on a  control-variate perspective. The proposed estimator can be shown to either strictly outperform or match the best-known existing rates for both KMM and NR, and thus is a robust combination of both estimators. The experiments shows the estimator works well in practice.",
        "bibtex": "@InProceedings{pmlr-v108-li20b,\n  title = \t {Robust Importance Weighting for  Covariate Shift},\n  author =       {Li, Fengpei and Lam, Henry and Prusty, Siddharth},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {352--362},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20b/li20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20b.html},\n  abstract = \t {In many learning problems, the training and testing data follow different distributions and a particularly common situation is the \\textit{covariate shift}. To correct for sampling biases, most approaches, including the popular kernel mean matching (KMM), focus on estimating the importance weights between the two distributions. Reweighting-based methods, however, are exposed to high variance when the distributional discrepancy is large. On the other hand, the alternate approach of using nonparametric regression (NR) incurs high bias when the training size is limited. In this paper, we propose and analyze a new estimator that systematically integrates the residuals of NR with KMM reweighting, based on a  control-variate perspective. The proposed estimator can be shown to either strictly outperform or match the best-known existing rates for both KMM and NR, and thus is a robust combination of both estimators. The experiments shows the estimator works well in practice.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20b/li20b.pdf",
        "supp": "",
        "pdf_size": 1039488,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3600477892788431283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Columbia University; Columbia University; Columbia University",
        "aff_domain": "columbia.edu;columbia.edu;columbia.edu",
        "email": "columbia.edu;columbia.edu;columbia.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fcb1b80415",
        "title": "Robust Learning from Discriminative Feature Feedback",
        "site": "https://proceedings.mlr.press/v108/dasgupta20a.html",
        "author": "Sanjoy Dasgupta; Sivan Sabato",
        "abstract": "Recent work introduced the model of \"learning from discriminative feature feedback\", in which a human annotator not only provides labels of instances, but also identifies discriminative features that highlight important differences between pairs of instances. It was shown that such feedback can be conducive to learning, and makes it possible to efficiently learn some concept classes that would otherwise be intractable. However, these results all relied upon *perfect* annotator feedback. In this paper, we introduce a more realistic, *robust* version of the framework, in which the annotator is allowed to make mistakes. We show how such errors can be handled algorithmically, in both an adversarial and a stochastic setting. In particular, we derive regret bounds in both settings that, as in the case of a perfect annotator, are independent of the number of features. We show that this result cannot be obtained by a naive reduction from the robust setting to the non-robust setting.",
        "bibtex": "@InProceedings{pmlr-v108-dasgupta20a,\n  title = \t {Robust Learning from Discriminative Feature Feedback},\n  author =       {Dasgupta, Sanjoy and Sabato, Sivan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {973--982},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dasgupta20a/dasgupta20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dasgupta20a.html},\n  abstract = \t {Recent work introduced the model of \"learning from discriminative feature feedback\", in which a human annotator not only provides labels of instances, but also identifies discriminative features that highlight important differences between pairs of instances. It was shown that such feedback can be conducive to learning, and makes it possible to efficiently learn some concept classes that would otherwise be intractable. However, these results all relied upon *perfect* annotator feedback. In this paper, we introduce a more realistic, *robust* version of the framework, in which the annotator is allowed to make mistakes. We show how such errors can be handled algorithmically, in both an adversarial and a stochastic setting. In particular, we derive regret bounds in both settings that, as in the case of a perfect annotator, are independent of the number of features. We show that this result cannot be obtained by a naive reduction from the robust setting to the non-robust setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/dasgupta20a/dasgupta20a.pdf",
        "supp": "",
        "pdf_size": 302976,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15393941807034804525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science and Engineering, University of California, San Diego, California, USA; Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of California, San Diego;Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.ucsd.edu;https://www.bgu.ac.il",
        "aff_unique_abbr": "UCSD;BGU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "San Diego;Beer Sheva",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "3111f2033d",
        "title": "Robust Optimisation Monte Carlo",
        "site": "https://proceedings.mlr.press/v108/ikonomov20a.html",
        "author": "Borislav Ikonomov; Michael U. Gutmann",
        "abstract": "This paper is on Bayesian inference for parametric statistical models that are defined by a stochastic simulator which specifies how data is generated. Exact sampling is then possible but evaluating the likelihood function is typically prohibitively expensive. Approximate Bayesian Computation (ABC) is a framework to perform approximate inference in such situations. While basic ABC algorithms are widely applicable, they are notoriously slow and much research has focused on increasing their efficiency. Optimisation Monte Carlo (OMC) has recently been proposed as an efficient and embarrassingly parallel method that leverages optimisation to accelerate the inference. In this paper, we demonstrate an important previously unrecognised failure mode of OMC: It generates strongly overconfident approximations by collapsing regions of similar or near-constant likelihood into a single point. We propose an efficient, robust generalisation of OMC that corrects this. It makes fewer assumptions, retains the main benefits of OMC, and can be performed either as post-processing to OMC or as a stand-alone computation. We demonstrate the effectiveness of the proposed Robust OMC on toy examples and tasks in inverse-graphics where we perform Bayesian inference with a complex image renderer.",
        "bibtex": "@InProceedings{pmlr-v108-ikonomov20a,\n  title = \t {Robust Optimisation Monte Carlo},\n  author =       {Ikonomov, Borislav and Gutmann, Michael U.},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2819--2829},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ikonomov20a/ikonomov20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ikonomov20a.html},\n  abstract = \t {This paper is on Bayesian inference for parametric statistical models that are defined by a stochastic simulator which specifies how data is generated. Exact sampling is then possible but evaluating the likelihood function is typically prohibitively expensive. Approximate Bayesian Computation (ABC) is a framework to perform approximate inference in such situations. While basic ABC algorithms are widely applicable, they are notoriously slow and much research has focused on increasing their efficiency. Optimisation Monte Carlo (OMC) has recently been proposed as an efficient and embarrassingly parallel method that leverages optimisation to accelerate the inference. In this paper, we demonstrate an important previously unrecognised failure mode of OMC: It generates strongly overconfident approximations by collapsing regions of similar or near-constant likelihood into a single point. We propose an efficient, robust generalisation of OMC that corrects this. It makes fewer assumptions, retains the main benefits of OMC, and can be performed either as post-processing to OMC or as a stand-alone computation. We demonstrate the effectiveness of the proposed Robust OMC on toy examples and tasks in inverse-graphics where we perform Bayesian inference with a complex image renderer.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ikonomov20a/ikonomov20a.pdf",
        "supp": "",
        "pdf_size": 971058,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8241438753704437342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "030b5ec48c",
        "title": "Robust Stackelberg buyers in repeated auctions",
        "site": "https://proceedings.mlr.press/v108/nedelec20a.html",
        "author": "Thomas Nedelec; Clement Calauzenes; Vianney Perchet; Noureddine El Karoui",
        "abstract": "We consider the practical and classical setting where the seller is using an exploration stage to learn the value distributions of the bidders before running a revenue-maximizing auction in a exploitation phase. In this two-stage process, we exhibit practical, simple and robust strategies with large utility uplifts for the bidders. We quantify precisely the seller revenue against non-discounted buyers, complementing recent studies that had focused on impatient/heavily discounted buyers. We also prove the robustness of these shading strategies to sample approximation error of the seller, to bidder\u2019s approximation error of the competition and to possible change of the mechanisms.",
        "bibtex": "@InProceedings{pmlr-v108-nedelec20a,\n  title = \t {Robust Stackelberg buyers in repeated auctions},\n  author =       {Nedelec, Thomas and Calauzenes, Clement and Perchet, Vianney and Karoui, Noureddine El},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1342--1351},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/nedelec20a/nedelec20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/nedelec20a.html},\n  abstract = \t {We consider the practical and classical setting where the seller is using an exploration stage to learn the value distributions of the bidders before running a revenue-maximizing auction in a exploitation phase. In this two-stage process, we exhibit practical, simple and robust strategies with large utility uplifts for the bidders. We quantify precisely the seller revenue against non-discounted buyers, complementing recent studies that had focused on impatient/heavily discounted buyers. We also prove the robustness of these shading strategies to sample approximation error of the seller, to bidder\u2019s approximation error of the competition and to possible change of the mechanisms.   }\n}",
        "pdf": "http://proceedings.mlr.press/v108/nedelec20a/nedelec20a.pdf",
        "supp": "",
        "pdf_size": 988661,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13204536903325475966&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "76e88a9b7d",
        "title": "Robust Variational Autoencoders for Outlier Detection and Repair of Mixed-Type Data",
        "site": "https://proceedings.mlr.press/v108/eduardo20a.html",
        "author": "Simao Eduardo; Alfredo Nazabal; Christopher K. I. Williams; Charles Sutton",
        "abstract": "We focus on the problem of unsupervised cell outlier detection and repair inmixed-type tabular data. Traditional methods are concerned only with detecting which rows in the dataset areoutliers. However, identifying which cells are corrupted in aspecific row is an important problem in practice, and the very first steptowards repairing them. We introduce the Robust VariationalAutoencoder (RVAE), a deep generative model that learns the jointdistribution of the clean data while identifying the outlier cells, allowing their imputation (repair). RVAE explicitly learns the probability of each cell being an outlier, balancing differentlikelihood models in the row outlier score, making the method suitablefor outlier detection in mixed-type datasets.We show experimentallythat not only RVAE performs better than several state-of-the-art methods incell outlier detection and repair for tabular data, but also that is robust against theinitial hyper-parameter selection.",
        "bibtex": "@InProceedings{pmlr-v108-eduardo20a,\n  title = \t {Robust Variational Autoencoders for Outlier Detection and Repair of Mixed-Type Data},\n  author =       {Eduardo, Simao and Nazabal, Alfredo and Williams, Christopher K. I. and Sutton, Charles},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4056--4066},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/eduardo20a/eduardo20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/eduardo20a.html},\n  abstract = \t {We focus on the problem of unsupervised cell outlier detection and repair inmixed-type tabular data. Traditional methods are concerned only with detecting which rows in the dataset areoutliers. However, identifying which cells are corrupted in aspecific row is an important problem in practice, and the very first steptowards repairing them. We introduce the Robust VariationalAutoencoder (RVAE), a deep generative model that learns the jointdistribution of the clean data while identifying the outlier cells, allowing their imputation (repair). RVAE explicitly learns the probability of each cell being an outlier, balancing differentlikelihood models in the row outlier score, making the method suitablefor outlier detection in mixed-type datasets.We show experimentallythat not only RVAE performs better than several state-of-the-art methods incell outlier detection and repair for tabular data, but also that is robust against theinitial hyper-parameter selection.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/eduardo20a/eduardo20a.pdf",
        "supp": "",
        "pdf_size": 714623,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5091620532505065866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Informatics, University of Edinburgh, UK; The Alan Turing Institute, UK + Google Research; School of Informatics, University of Edinburgh, UK + The Alan Turing Institute, UK + Google Research; School of Informatics, University of Edinburgh, UK + The Alan Turing Institute, UK + Google Research",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;0+1+2;0+1+2",
        "aff_unique_norm": "University of Edinburgh;Alan Turing Institute;Google",
        "aff_unique_dep": "School of Informatics;;Google Research",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.turing.ac.uk;https://research.google",
        "aff_unique_abbr": "Edinburgh;ATI;Google Research",
        "aff_campus_unique_index": "0;2;0+2;0+2",
        "aff_campus_unique": "Edinburgh;;Mountain View",
        "aff_country_unique_index": "0;0+1;0+0+1;0+0+1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "60f091c65e",
        "title": "Robustness for Non-Parametric Classification: A Generic Attack and Defense",
        "site": "https://proceedings.mlr.press/v108/yang20b.html",
        "author": "Yao-Yuan Yang; Cyrus Rashtchian; Yizhen Wang; Kamalika Chaudhuri",
        "abstract": "Adversarially robust machine learning has received much recent attention. However, prior attacks and defenses for non-parametric classifiers have been developed in an ad-hoc or classifier-specific basis. In this work, we take a holistic look at adversarial examples for non-parametric classifiers, including nearest neighbors, decision trees, and random forests. We provide a general defense method, adversarial pruning, that works by preprocessing the dataset to become well-separated. To test our defense, we provide a novel attack that applies to a wide  range of non-parametric classifiers. Theoretically, we derive an optimally robust classifier, which is analogous to the Bayes Optimal. We show that adversarial pruning can be viewed as a finite sample approximation to this optimal classifier. We empirically show that our defense and attack are either better than or competitive with prior work on non-parametric classifiers. Overall, our results provide a strong and broadly-applicable baseline for future work on robust non-parametrics.",
        "bibtex": "@InProceedings{pmlr-v108-yang20b,\n  title = \t {Robustness for Non-Parametric Classification: A Generic Attack and Defense},\n  author =       {Yang, Yao-Yuan and Rashtchian, Cyrus and Wang, Yizhen and Chaudhuri, Kamalika},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {941--951},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yang20b/yang20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yang20b.html},\n  abstract = \t {Adversarially robust machine learning has received much recent attention. However, prior attacks and defenses for non-parametric classifiers have been developed in an ad-hoc or classifier-specific basis. In this work, we take a holistic look at adversarial examples for non-parametric classifiers, including nearest neighbors, decision trees, and random forests. We provide a general defense method, adversarial pruning, that works by preprocessing the dataset to become well-separated. To test our defense, we provide a novel attack that applies to a wide  range of non-parametric classifiers. Theoretically, we derive an optimally robust classifier, which is analogous to the Bayes Optimal. We show that adversarial pruning can be viewed as a finite sample approximation to this optimal classifier. We empirically show that our defense and attack are either better than or competitive with prior work on non-parametric classifiers. Overall, our results provide a strong and broadly-applicable baseline for future work on robust non-parametrics.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yang20b/yang20b.pdf",
        "supp": "",
        "pdf_size": 638603,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8990912135063621215&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, San Diego, Computer Science & Engineering; University of California, San Diego, Computer Science & Engineering; University of California, San Diego, Computer Science & Engineering; University of California, San Diego, Computer Science & Engineering",
        "aff_domain": "eng.ucsd.edu;eng.ucsd.edu;eng.ucsd.edu;eng.ucsd.edu",
        "email": "eng.ucsd.edu;eng.ucsd.edu;eng.ucsd.edu;eng.ucsd.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Computer Science & Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3102896bbc",
        "title": "Safe-Bayesian Generalized Linear Regression",
        "site": "https://proceedings.mlr.press/v108/heide20a.html",
        "author": "Rianne Heide; Alisa Kirichenko; Peter Grunwald; Nishant Mehta",
        "abstract": "We study generalized Bayesian inference under misspecification,  i.e. when the model is \u2018wrong but useful\u2019. Generalized Bayes equips  the likelihood with a learning rate $\\eta$. We show that for  generalized linear models (GLMs), $\\eta$-generalized Bayes  concentrates around the best approximation of the truth within the  model for specific $\\eta eq 1$, even under severely misspecified  noise, as long as the tails of the true distribution are exponential. We  derive MCMC samplers for generalized Bayesian lasso and  logistic regression and give examples of both  simulated and real-world data in which generalized Bayes  substantially outperforms standard Bayes.",
        "bibtex": "@InProceedings{pmlr-v108-heide20a,\n  title = \t { Safe-Bayesian Generalized Linear Regression},\n  author =       {de Heide, Rianne and Kirichenko, Alisa and Grunwald, Peter and Mehta, Nishant},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2623--2633},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/heide20a/heide20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/heide20a.html},\n  abstract = \t {We study generalized Bayesian inference under misspecification,  i.e. when the model is \u2018wrong but useful\u2019. Generalized Bayes equips  the likelihood with a learning rate $\\eta$. We show that for  generalized linear models (GLMs), $\\eta$-generalized Bayes  concentrates around the best approximation of the truth within the  model for specific $\\eta eq 1$, even under severely misspecified  noise, as long as the tails of the true distribution are exponential. We  derive MCMC samplers for generalized Bayesian lasso and  logistic regression and give examples of both  simulated and real-world data in which generalized Bayes  substantially outperforms standard Bayes.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/heide20a/heide20a.pdf",
        "supp": "",
        "pdf_size": 1147590,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17789712450799656790&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1cd795ad53",
        "title": "Sample Complexity of Estimating the Policy Gradient for Nearly Deterministic Dynamical Systems",
        "site": "https://proceedings.mlr.press/v108/bastani20a.html",
        "author": "Osbert Bastani",
        "abstract": "Reinforcement learning is a promising approach to learning robotics controllers. It has recently been shown that algorithms based on finite-difference estimates of the policy gradient are competitive with algorithms based on the policy gradient theorem. We propose a theoretical framework for understanding this phenomenon. Our key insight is that many dynamical systems (especially those of interest in robotics control tasks) are nearly deterministic\u2014i.e., they can be modeled as a deterministic system with a small stochastic perturbation. We show that for such systems, finite-difference estimates of the policy gradient can have substantially lower variance than estimates based on the policy gradient theorem. Finally, we empirically evaluate our insights in an experiment on the inverted pendulum.",
        "bibtex": "@InProceedings{pmlr-v108-bastani20a,\n  title = \t {Sample Complexity of Estimating the Policy Gradient for Nearly Deterministic Dynamical Systems},\n  author =       {Bastani, Osbert},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3858--3869},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bastani20a/bastani20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bastani20a.html},\n  abstract = \t {Reinforcement learning is a promising approach to learning robotics controllers. It has recently been shown that algorithms based on finite-difference estimates of the policy gradient are competitive with algorithms based on the policy gradient theorem. We propose a theoretical framework for understanding this phenomenon. Our key insight is that many dynamical systems (especially those of interest in robotics control tasks) are nearly deterministic\u2014i.e., they can be modeled as a deterministic system with a small stochastic perturbation. We show that for such systems, finite-difference estimates of the policy gradient can have substantially lower variance than estimates based on the policy gradient theorem. Finally, we empirically evaluate our insights in an experiment on the inverted pendulum.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bastani20a/bastani20a.pdf",
        "supp": "",
        "pdf_size": 702454,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2821430223102578423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Pennsylvania, USA",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3f1c02d7e9",
        "title": "Sample Complexity of Reinforcement Learning using Linearly Combined Model Ensembles",
        "site": "https://proceedings.mlr.press/v108/modi20a.html",
        "author": "Aditya Modi; Nan Jiang; Ambuj Tewari; Satinder Singh",
        "abstract": "Reinforcement learning (RL) methods have been shown to be capable of learning intelligent behavior in rich domains. However, this has largely been done in simulated domains without adequate focus on the process of building the simulator. In this paper, we consider a setting where we have access to an ensemble of pre-trained and possibly inaccurate simulators (models). We approximate the real environment using a state-dependent linear combination of the ensemble, where the coefficients are determined by the given state features and some unknown parameters. Our proposed algorithm provably learns a near-optimal policy with a sample complexity polynomial in the number of unknown parameters, and incurs no dependence on the size of the state (or action) space. As an extension, we also consider the more challenging problem of model selection, where the state features are unknown and can be chosen from a large candidate set. We provide exponential lower bounds that illustrate the fundamental hardness of this problem, and develop a provably efficient algorithm under additional natural assumptions.",
        "bibtex": "@InProceedings{pmlr-v108-modi20a,\n  title = \t {Sample Complexity of Reinforcement Learning using Linearly Combined Model Ensembles},\n  author =       {Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2010--2020},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/modi20a/modi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/modi20a.html},\n  abstract = \t {Reinforcement learning (RL) methods have been shown to be capable of learning intelligent behavior in rich domains. However, this has largely been done in simulated domains without adequate focus on the process of building the simulator. In this paper, we consider a setting where we have access to an ensemble of pre-trained and possibly inaccurate simulators (models). We approximate the real environment using a state-dependent linear combination of the ensemble, where the coefficients are determined by the given state features and some unknown parameters. Our proposed algorithm provably learns a near-optimal policy with a sample complexity polynomial in the number of unknown parameters, and incurs no dependence on the size of the state (or action) space. As an extension, we also consider the more challenging problem of model selection, where the state features are unknown and can be chosen from a large candidate set. We provide exponential lower bounds that illustrate the fundamental hardness of this problem, and develop a provably efficient algorithm under additional natural assumptions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/modi20a/modi20a.pdf",
        "supp": "",
        "pdf_size": 394497,
        "gs_citation": 169,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18355739951018418817&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1335745a95",
        "title": "Sample complexity bounds for localized sketching",
        "site": "https://proceedings.mlr.press/v108/srinivasa20a.html",
        "author": "Rakshith Sharma Srinivasa; Mark Davenport; Justin Romberg",
        "abstract": "We consider sketched approximate matrix multiplication and ridge regression in the novel setting of localized sketching, where at any given point, only part of the data matrix is available. This corresponds to a block diagonal structure on the sketching matrix. We show that, under mild conditions, block diagonal sketching matrices require only $O(\\sr / \\epsilon^2)$ and $O(\\sd_{\\lambda}/\\epsilon)$ total sample complexity for matrix multiplication and ridge regression, respectively. This matches the state-of-the-art bounds that are obtained using global sketching matrices. The localized nature of sketching considered allows for different parts of the data matrix to be sketched independently and hence is more amenable to computation in distributed and streaming settings and results in a smaller memory and computational footprint.",
        "bibtex": "@InProceedings{pmlr-v108-srinivasa20a,\n  title = \t {Sample complexity bounds for localized sketching},\n  author =       {Srinivasa, Rakshith Sharma and Davenport, Mark and Romberg, Justin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3275--3284},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/srinivasa20a/srinivasa20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/srinivasa20a.html},\n  abstract = \t { We consider sketched approximate matrix multiplication and ridge regression in the novel setting of localized sketching, where at any given point, only part of the data matrix is available. This corresponds to a block diagonal structure on the sketching matrix. We show that, under mild conditions, block diagonal sketching matrices require only $O(\\sr / \\epsilon^2)$ and $O(\\sd_{\\lambda}/\\epsilon)$ total sample complexity for matrix multiplication and ridge regression, respectively. This matches the state-of-the-art bounds that are obtained using global sketching matrices. The localized nature of sketching considered allows for different parts of the data matrix to be sketched independently and hence is more amenable to computation in distributed and streaming settings and results in a smaller memory and computational footprint.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/srinivasa20a/srinivasa20a.pdf",
        "supp": "",
        "pdf_size": 544231,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17349055868106725037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ae669d71cb",
        "title": "Scalable Feature Selection for (Multitask) Gradient Boosted Trees",
        "site": "https://proceedings.mlr.press/v108/han20a.html",
        "author": "Cuize Han; Nikhil Rao; Daria Sorokina; Karthik Subbian",
        "abstract": "Gradient Boosted Decision Trees (GBDTs) are widely used for building ranking and relevance models in search and recommendation. Considerations such as latency and interpretability dictate the use of as few features as possible to train these models. Feature selection in GBDT models typically involves heuristically ranking the features by importance and selecting the top few, or by per- forming a full backward feature elimination routine. On-the-fly feature selection methods proposed previously scale suboptimally with the number of features, which can be daunt- ing in high dimensional settings. We develop a scalable forward feature selection variant for GBDT, via a novel group testing procedure that works well in high dimensions, and enjoys favorable theoretical performance and computational guarantees. We show via ex- tensive experiments on both public and proprietary datasets that the proposed method offers significant speedups in training time, while being as competitive as existing GBDT methods in terms of model performance metrics. We also extend the method to the multitask setting, allowing the practitioner to select common features across tasks, as well as selecting task-specific features.",
        "bibtex": "@InProceedings{pmlr-v108-han20a,\n  title = \t {Scalable Feature Selection for (Multitask) Gradient Boosted Trees},\n  author =       {Han, Cuize and Rao, Nikhil and Sorokina, Daria and Subbian, Karthik},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {885--894},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/han20a/han20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/han20a.html},\n  abstract = \t {Gradient Boosted Decision Trees (GBDTs) are widely used for building ranking and relevance models in search and recommendation. Considerations such as latency and interpretability dictate the use of as few features as possible to train these models. Feature selection in GBDT models typically involves heuristically ranking the features by importance and selecting the top few, or by per- forming a full backward feature elimination routine. On-the-fly feature selection methods proposed previously scale suboptimally with the number of features, which can be daunt- ing in high dimensional settings. We develop a scalable forward feature selection variant for GBDT, via a novel group testing procedure that works well in high dimensions, and enjoys favorable theoretical performance and computational guarantees. We show via ex- tensive experiments on both public and proprietary datasets that the proposed method offers significant speedups in training time, while being as competitive as existing GBDT methods in terms of model performance metrics. We also extend the method to the multitask setting, allowing the practitioner to select common features across tasks, as well as selecting task-specific features.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/han20a/han20a.pdf",
        "supp": "",
        "pdf_size": 689211,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11451833098758043621&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3d9bb6c17c",
        "title": "Scalable Gradients for Stochastic Differential Equations",
        "site": "https://proceedings.mlr.press/v108/li20i.html",
        "author": "Xuechen Li; Ting-Kam Leonard Wong; Ricky T. Q. Chen; David Duvenaud",
        "abstract": "The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differentialequation whose solution is the gradient, a memory-efficient algorithm for cachingnoise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance ona 50-dimensional motion capture dataset.",
        "bibtex": "@InProceedings{pmlr-v108-li20i,\n  title = \t {Scalable Gradients for Stochastic Differential Equations},\n  author =       {Li, Xuechen and Wong, Ting-Kam Leonard and Chen, Ricky T. Q. and Duvenaud, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3870--3882},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20i/li20i.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20i.html},\n  abstract = \t {The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differentialequation whose solution is the gradient, a memory-efficient algorithm for cachingnoise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance ona 50-dimensional motion capture dataset.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20i/li20i.pdf",
        "supp": "",
        "pdf_size": 3758982,
        "gs_citation": 384,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11746673969693415245&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ad978621e5",
        "title": "Scalable Nonparametric Factorization for High-Order Interaction Events",
        "site": "https://proceedings.mlr.press/v108/pan20b.html",
        "author": "Zhimeng Pan; Zheng Wang; Shandian Zhe",
        "abstract": "Interaction events among multiple entities are ubiquitous in real-world applications. Although these interactions can be naturally represented by tensors and analyzed by tensor decomposition, most existing approaches are limited to multilinear decomposition forms, and cannot estimate complex, nonlinear relationships in data. More importantly, the existing approaches severely underexploit the time stamps information. They either drop/discretize the time stamps or set a local window to ignore the long-term dependency between the events. To address these issues, we propose a Bayesian nonparametric factorization model for high-order interaction events, which can flexibly estimate/embed the static, nonlinear relationships and capture various long-term and short-term excitations effects, encoding these effects and their decaying patterns into the latent factors.  Specifically, we use the latent factors to construct a set of mutually excited Hawkes processes, where we place a Gaussian process prior over the background rates to estimate the static, nonlinear relationships of the entities and propose novel triggering kernels to embed the excitation strengths and their time decaying rates among the interactions. For scalable inference, we derive a fully-decomposed model evidence lower bound to dispose of the huge covariance matrix and expensive log summation terms. Then we develop an efficient stochastic optimization algorithm. We show the advantage of our approach in four real-world applications.",
        "bibtex": "@InProceedings{pmlr-v108-pan20b,\n  title = \t {Scalable Nonparametric Factorization for High-Order Interaction Events},\n  author =       {Pan, Zhimeng and Wang, Zheng and Zhe, Shandian},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4325--4335},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pan20b/pan20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pan20b.html},\n  abstract = \t {Interaction events among multiple entities are ubiquitous in real-world applications. Although these interactions can be naturally represented by tensors and analyzed by tensor decomposition, most existing approaches are limited to multilinear decomposition forms, and cannot estimate complex, nonlinear relationships in data. More importantly, the existing approaches severely underexploit the time stamps information. They either drop/discretize the time stamps or set a local window to ignore the long-term dependency between the events. To address these issues, we propose a Bayesian nonparametric factorization model for high-order interaction events, which can flexibly estimate/embed the static, nonlinear relationships and capture various long-term and short-term excitations effects, encoding these effects and their decaying patterns into the latent factors.  Specifically, we use the latent factors to construct a set of mutually excited Hawkes processes, where we place a Gaussian process prior over the background rates to estimate the static, nonlinear relationships of the entities and propose novel triggering kernels to embed the excitation strengths and their time decaying rates among the interactions. For scalable inference, we derive a fully-decomposed model evidence lower bound to dispose of the huge covariance matrix and expensive log summation terms. Then we develop an efficient stochastic optimization algorithm. We show the advantage of our approach in four real-world applications.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pan20b/pan20b.pdf",
        "supp": "",
        "pdf_size": 1626409,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1979230841895456650&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Computing, University of Utah; School of Computing, University of Utah; School of Computing, University of Utah",
        "aff_domain": "utah.edu;cs.utah.edu;cs.utah.edu",
        "email": "utah.edu;cs.utah.edu;cs.utah.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Utah",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d8689c9899",
        "title": "Scaling up Kernel Ridge Regression via Locality Sensitive Hashing",
        "site": "https://proceedings.mlr.press/v108/zandieh20a.html",
        "author": "Amir Zandieh; Navid Nouri; Ameya Velingker; Michael Kapralov; Ilya Razenshteyn",
        "abstract": "Random binning features, introduced in the seminal paper of Rahimi and Recht \u201907, are an efficient method for approximating a kernel matrix using locality sensitive hashing. Random binning features provide a very simple and efficient way to approximate the Laplace kernel but unfortunately do not apply to many important classes of kernels, notably ones that generate smooth Gaussian processes, such as the Gaussian kernel and Matern kernel. In this paper we introduce a simple weighted version of random binning features, and show that the corresponding kernel function generates Gaussian processes of any desired smoothness. We show that our weighted random binning features provide a spectral approximation to the corresponding kernel matrix, leading to efficient algorithms for kernel ridge regression. Experiments on large scale regression datasets show that our method outperforms the accuracy of random Fourier features method.",
        "bibtex": "@InProceedings{pmlr-v108-zandieh20a,\n  title = \t {Scaling up Kernel Ridge Regression via Locality Sensitive Hashing },\n  author =       {Zandieh, Amir and Nouri, Navid and Velingker, Ameya and Kapralov, Michael and Razenshteyn, Ilya},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4088--4097},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zandieh20a/zandieh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zandieh20a.html},\n  abstract = \t {Random binning features, introduced in the seminal paper of Rahimi and Recht \u201907, are an efficient method for approximating a kernel matrix using locality sensitive hashing. Random binning features provide a very simple and efficient way to approximate the Laplace kernel but unfortunately do not apply to many important classes of kernels, notably ones that generate smooth Gaussian processes, such as the Gaussian kernel and Matern kernel. In this paper we introduce a simple weighted version of random binning features, and show that the corresponding kernel function generates Gaussian processes of any desired smoothness. We show that our weighted random binning features provide a spectral approximation to the corresponding kernel matrix, leading to efficient algorithms for kernel ridge regression. Experiments on large scale regression datasets show that our method outperforms the accuracy of random Fourier features method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zandieh20a/zandieh20a.pdf",
        "supp": "",
        "pdf_size": 213809,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15776016585329724566&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "EPFL; EPFL; Microsoft Research; Google Research; EPFL",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "EPFL;Microsoft;Google",
        "aff_unique_dep": ";Microsoft Research;Google Research",
        "aff_unique_url": "https://www.epfl.ch;https://www.microsoft.com/en-us/research;https://research.google",
        "aff_unique_abbr": "EPFL;MSR;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "ed626b65d8",
        "title": "Screening Data Points in Empirical Risk Minimization via Ellipsoidal Regions and Safe Loss Functions",
        "site": "https://proceedings.mlr.press/v108/mialon20a.html",
        "author": "Gr\u00e9goire Mialon; Julien Mairal; Alexandre d\u2019Aspremont",
        "abstract": "We design simple screening tests to automatically discard data samples in empirical risk minimization withoutlosing optimization guarantees. We derive loss functions that produce dual objectives with a sparse solution. We also show how to regularize convex losses to ensure such a dual sparsity-inducing property, andpropose a general method to design screening tests for classification or regression based on ellipsoidal approximations of the optimal set. In addition to producing computational gains, our approach also allows us to compress a dataset into a subset of representative points.",
        "bibtex": "@InProceedings{pmlr-v108-mialon20a,\n  title = \t {Screening Data Points in Empirical Risk Minimization via Ellipsoidal Regions and Safe Loss Functions},\n  author =       {Mialon, Gr\\'egoire and Mairal, Julien and d'Aspremont, Alexandre},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3610--3620},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mialon20a/mialon20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mialon20a.html},\n  abstract = \t {We design simple screening tests to automatically discard data samples in empirical risk minimization withoutlosing optimization guarantees. We derive loss functions that produce dual objectives with a sparse solution. We also show how to regularize convex losses to ensure such a dual sparsity-inducing property, andpropose a general method to design screening tests for classification or regression based on ellipsoidal approximations of the optimal set. In addition to producing computational gains, our approach also allows us to compress a dataset into a subset of representative points.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mialon20a/mialon20a.pdf",
        "supp": "",
        "pdf_size": 774712,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2369228531934316207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Univ. GrenobleAlpes, Inria, CNRS, GrenobleINP, LJK, 38000 Grenoble, France; D\u00e9partement d\u2019informatique de l\u2019ENS, CNRS, Inria, PSL, 75005 Paris, France; Univ. GrenobleAlpes, Inria, CNRS, GrenobleINP, LJK, 38000 Grenoble, France",
        "aff_domain": "inria.fr;ens.fr;inria.fr",
        "email": "inria.fr;ens.fr;inria.fr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universite Grenoble Alpes;\u00c9cole Normale Sup\u00e9rieure",
        "aff_unique_dep": ";D\u00e9partement d\u2019informatique",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://www.ens.fr",
        "aff_unique_abbr": "UGA;ENS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Grenoble;Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "230baa79a7",
        "title": "Semi-Modular Inference: enhanced learning in multi-modular models by tempering the influence of components",
        "site": "https://proceedings.mlr.press/v108/carmona20a.html",
        "author": "Christian Carmona; Geoff Nicholls",
        "abstract": "Bayesian statistical inference loses predictive optimality when generative models are misspecified.Working within an existing coherent loss-based generalisation of Bayesian inference, we show existing Modular/Cut-model inference is coherent, and write down a new family of Semi-Modular Inference (SMI) schemes, indexed by an influence parameter, with Bayesian inference and Cut-models as special cases. We give a meta-learning criterion and estimation procedure to choose the inference scheme. This returns Bayesian inference when there is no misspecification.The framework applies naturally to Multi-modular models. Cut-model inference allows directed information flow from well-specified modules to misspecified modules, but not vice versa. An existing alternative power posterior method gives tunable but undirected control of information flow, improving prediction in some settings. In contrast, SMI allows \\emph{tunable and directed} information flow between modules.We illustrate our methods on two standard test cases from the literature and a motivating archaeological data set.",
        "bibtex": "@InProceedings{pmlr-v108-carmona20a,\n  title = \t {Semi-Modular Inference: enhanced learning in multi-modular models by tempering the influence of components},\n  author =       {Carmona, Christian and Nicholls, Geoff},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4226--4235},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/carmona20a/carmona20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/carmona20a.html},\n  abstract = \t {Bayesian statistical inference loses predictive optimality when generative models are misspecified.Working within an existing coherent loss-based generalisation of Bayesian inference, we show existing Modular/Cut-model inference is coherent, and write down a new family of Semi-Modular Inference (SMI) schemes, indexed by an influence parameter, with Bayesian inference and Cut-models as special cases. We give a meta-learning criterion and estimation procedure to choose the inference scheme. This returns Bayesian inference when there is no misspecification.The framework applies naturally to Multi-modular models. Cut-model inference allows directed information flow from well-specified modules to misspecified modules, but not vice versa. An existing alternative power posterior method gives tunable but undirected control of information flow, improving prediction in some settings. In contrast, SMI allows \\emph{tunable and directed} information flow between modules.We illustrate our methods on two standard test cases from the literature and a motivating archaeological data set.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/carmona20a/carmona20a.pdf",
        "supp": "",
        "pdf_size": 2369208,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9355232258246348376&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, University of Oxford, Oxford, UK; Department of Statistics, University of Oxford, Oxford, UK",
        "aff_domain": "stats.ox.ac.uk;stats.ox.ac.uk",
        "email": "stats.ox.ac.uk;stats.ox.ac.uk",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "2169797019",
        "title": "Sequential no-Substitution k-Median-Clustering",
        "site": "https://proceedings.mlr.press/v108/hess20a.html",
        "author": "Tom Hess; Sivan Sabato",
        "abstract": "We study the sample-based k-median clustering objective under a sequential setting without substitutions. In this setting, an i.i.d. sequence of examples is observed. An example can be selected as a center only immediately after it is observed, and it cannot be substituted later. The goal is to select a set of centers with a good k-median cost on the distribution which generated the sequence. We provide an efficient algorithm for this setting, and show that its multiplicative approximation factor is twice the approximation factor of an efficient offline algorithm. In addition, we show that if efficiency requirements are removed, there is an algorithm that can obtain the same approximation factor as the best offline algorithm. We demonstrate in experiments the performance of the efficient algorithm on real data sets. Our code is available at https://github.com/tomhess/No_Substitution_K_Median.",
        "bibtex": "@InProceedings{pmlr-v108-hess20a,\n  title = \t {Sequential no-Substitution k-Median-Clustering},\n  author =       {Hess, Tom and Sabato, Sivan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {962--972},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hess20a/hess20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hess20a.html},\n  abstract = \t {We study the sample-based k-median clustering objective under a sequential setting without substitutions. In this setting, an i.i.d. sequence of examples is observed. An example can be selected as a center only immediately after it is observed, and it cannot be substituted later. The goal is to select a set of centers with a good k-median cost on the distribution which generated the sequence. We provide an efficient algorithm for this setting, and show that its multiplicative approximation factor is twice the approximation factor of an efficient offline algorithm. In addition, we show that if efficiency requirements are removed, there is an algorithm that can obtain the same approximation factor as the best offline algorithm. We demonstrate in experiments the performance of the efficient algorithm on real data sets. Our code is available at https://github.com/tomhess/No_Substitution_K_Median.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hess20a/hess20a.pdf",
        "supp": "",
        "pdf_size": 433418,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10955977566213587566&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel; Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva 8410501, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/tomhess/No_Substitution_K_Median",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beer Sheva",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "2b1b6c15b5",
        "title": "Sharp Analysis of Expectation-Maximization for Weakly Identifiable Models",
        "site": "https://proceedings.mlr.press/v108/dwivedi20a.html",
        "author": "Raaz Dwivedi; Nhat Ho; Koulik Khamaru; Martin Wainwright; Michael Jordan; Bin Yu",
        "abstract": "We study a class of weakly identifiable location-scale mixture models for which the maximum likelihood estimates based on $n$ i.i.d. samples are known to have lower accuracy than the classical $n^{- \\frac{1}{2}}$ error. We investigate whether the Expectation-Maximization (EM) algorithm also converges slowly for these models. We provide a rigorous characterization of EM for fitting a weakly identifiable Gaussian mixture in a univariate setting where we prove that the EM algorithm converges in order $n^{\\frac{3}{4}}$ steps and returns estimates that are at a Euclidean distance of order ${ n^{- \\frac{1}{8}}}$ and ${ n^{-\\frac{1} {4}}}$ from the true location and scale parameter respectively. Establishing the slow rates in the univariate setting requires a novel localization argument with two stages, with each stage involving an epoch-based argument applied to a different surrogate EM operator at the population level.  We demonstrate several multivariate ($d \\geq 2$) examples that exhibit the same slow rates as the univariate case. We also prove slow statistical rates in higher dimensions in a special case, when the fitted covariance is constrained to be a multiple of identity.",
        "bibtex": "@InProceedings{pmlr-v108-dwivedi20a,\n  title = \t {Sharp Analysis of Expectation-Maximization for Weakly Identifiable Models},\n  author =       {Dwivedi, Raaz and Ho, Nhat and Khamaru, Koulik and Wainwright, Martin and Jordan, Michael and Yu, Bin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1866--1876},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dwivedi20a/dwivedi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dwivedi20a.html},\n  abstract = \t {We study a class of weakly identifiable location-scale mixture models for which the maximum likelihood estimates based on $n$ i.i.d. samples are known to have lower accuracy than the classical $n^{- \\frac{1}{2}}$ error. We investigate whether the Expectation-Maximization (EM) algorithm also converges slowly for these models. We provide a rigorous characterization of EM for fitting a weakly identifiable Gaussian mixture in a univariate setting where we prove that the EM algorithm converges in order $n^{\\frac{3}{4}}$ steps and returns estimates that are at a Euclidean distance of order ${ n^{- \\frac{1}{8}}}$ and ${ n^{-\\frac{1} {4}}}$ from the true location and scale parameter respectively. Establishing the slow rates in the univariate setting requires a novel localization argument with two stages, with each stage involving an epoch-based argument applied to a different surrogate EM operator at the population level.  We demonstrate several multivariate ($d \\geq 2$) examples that exhibit the same slow rates as the univariate case. We also prove slow statistical rates in higher dimensions in a special case, when the fitted covariance is constrained to be a multiple of identity.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/dwivedi20a/dwivedi20a.pdf",
        "supp": "",
        "pdf_size": 1941491,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5046121326775465529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "af2393cc48",
        "title": "Sharp Asymptotics and Optimal Performance for Inference in Binary Models",
        "site": "https://proceedings.mlr.press/v108/taheri20a.html",
        "author": "Hossein Taheri; Ramtin Pedarsani; Christos Thrampoulidis",
        "abstract": "We study convex empirical risk minimization for high-dimensional inference in binary models. Our first result sharply predicts the statistical performance of such estimators in the linear asymptotic regime under isotropic Gaussian features. Importantly, the predictions hold for a wide class of convex loss functions, which we exploit in order to prove a bound on the best achievable performance among them. Notably, we show that the proposed bound is tight for popular binary models (such as Signed, Logistic or Probit), by constructing appropriate loss functions that achieve it. More interestingly, for binary linear classification under the Logistic and Probit models, we prove that the performance of least-squares is no worse than 0.997 and 0.98 times the optimal one. Numerical simulations corroborate our theoretical findings and suggest they are accurate even for relatively small problem dimensions.",
        "bibtex": "@InProceedings{pmlr-v108-taheri20a,\n  title = \t {Sharp Asymptotics and Optimal Performance for Inference in Binary Models},\n  author =       {Taheri, Hossein and Pedarsani, Ramtin and Thrampoulidis, Christos},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3739--3749},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/taheri20a/taheri20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/taheri20a.html},\n  abstract = \t {We study convex empirical risk minimization for high-dimensional inference in binary models. Our first result sharply predicts the statistical performance of such estimators in the linear asymptotic regime under isotropic Gaussian features. Importantly, the predictions hold for a wide class of convex loss functions, which we exploit in order to prove a bound on the best achievable performance among them. Notably, we show that the proposed bound is tight for popular binary models (such as Signed, Logistic or Probit), by constructing appropriate loss functions that achieve it. More interestingly, for binary linear classification under the Logistic and Probit models, we prove that the performance of least-squares is no worse than 0.997 and 0.98 times the optimal one. Numerical simulations corroborate our theoretical findings and suggest they are accurate even for relatively small problem dimensions. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/taheri20a/taheri20a.pdf",
        "supp": "",
        "pdf_size": 942433,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15298944932712804643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "27754f7146",
        "title": "Sharp Thresholds of the Information Cascade Fragility Under a Mismatched Model",
        "site": "https://proceedings.mlr.press/v108/huleihel20a.html",
        "author": "Wasim Huleihel; Ofer Shayevitz",
        "abstract": "We analyze a sequential decision making model in which decision makers (or, players) take their decisions based on their own private information as well as the actions of previous decision makers. Such decision making processes often lead to what is known as the \\emph{information cascade} or \\emph{herding} phenomenon. Specifically, a cascade develops when it seems rational for some players to abandon their own private information and imitate the actions of earlier players. The risk, however, is that if the initial decisions were wrong, then the whole cascade will be wrong. Nonetheless, information cascade are known to be fragile: there exists a sequence of \\emph{revealing} probabilities $\\{p_{\\ell}\\}_{\\ell\\geq1}$, such that if with probability $p_{\\ell}$ player $\\ell$ ignores the decisions of previous players, and rely on his private information only, then wrong cascades can be avoided. Previous related papers which study the fragility of information cascades always assume that the revealing probabilities are known to all players perfectly, which might be unrealistic in practice. Accordingly, in this paper we study a mismatch model where players believe that the revealing probabilities are $\\{q_\\ell\\}_{\\ell\\in\\mathbb{N}}$ when they truly are $\\{p_\\ell\\}_{\\ell\\in\\mathbb{N}}$, and study the effect of this mismatch on information cascades. We consider both adversarial and probabilistic sequential decision making models, and derive closed-form expressions for the optimal learning rates at which the error probability associated with a certain decision maker goes to zero. We prove several novel phase transitions in the behaviour of the asymptotic learning rate.",
        "bibtex": "@InProceedings{pmlr-v108-huleihel20a,\n  title = \t {Sharp Thresholds of the Information Cascade Fragility Under a Mismatched Model},\n  author =       {Huleihel, Wasim and Shayevitz, Ofer},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {549--558},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/huleihel20a/huleihel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/huleihel20a.html},\n  abstract = \t {We analyze a sequential decision making model in which decision makers (or, players) take their decisions based on their own private information as well as the actions of previous decision makers. Such decision making processes often lead to what is known as the \\emph{information cascade} or \\emph{herding} phenomenon. Specifically, a cascade develops when it seems rational for some players to abandon their own private information and imitate the actions of earlier players. The risk, however, is that if the initial decisions were wrong, then the whole cascade will be wrong. Nonetheless, information cascade are known to be fragile: there exists a sequence of \\emph{revealing} probabilities $\\{p_{\\ell}\\}_{\\ell\\geq1}$, such that if with probability $p_{\\ell}$ player $\\ell$ ignores the decisions of previous players, and rely on his private information only, then wrong cascades can be avoided. Previous related papers which study the fragility of information cascades always assume that the revealing probabilities are known to all players perfectly, which might be unrealistic in practice. Accordingly, in this paper we study a mismatch model where players believe that the revealing probabilities are $\\{q_\\ell\\}_{\\ell\\in\\mathbb{N}}$ when they truly are $\\{p_\\ell\\}_{\\ell\\in\\mathbb{N}}$, and study the effect of this mismatch on information cascades. We consider both adversarial and probabilistic sequential decision making models, and derive closed-form expressions for the optimal learning rates at which the error probability associated with a certain decision maker goes to zero. We prove several novel phase transitions in the behaviour of the asymptotic learning rate.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/huleihel20a/huleihel20a.pdf",
        "supp": "",
        "pdf_size": 346086,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:tgOKhMkdXCUJ:scholar.google.com/&scioq=Sharp+Thresholds+of+the+Information+Cascade+Fragility+Under+a+Mismatched+Model&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": "Tel-Aviv University; Tel-Aviv University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tel Aviv University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tau.ac.il",
        "aff_unique_abbr": "TAU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "dc729f7cd0",
        "title": "Simulator Calibration under Covariate Shift with Kernels",
        "site": "https://proceedings.mlr.press/v108/kisamori20a.html",
        "author": "Keiichi Kisamori; Motonobu Kanagawa; Keisuke Yamazaki",
        "abstract": "We propose a novel calibration method for computer simulators, dealing with the problem of covariate shift.Covariate shift is the situation where input distributions for training and test are different, and ubiquitous in applications of simulations. Our approach is based on Bayesian inference with kernel mean embedding of distributions, and on the use of an importance-weighted reproducing kernel for covariate shift adaptation.We provide a theoretical analysis for the proposed method, including a novel theoretical result for conditional mean embedding, as well as empirical investigations suggesting its effectiveness in practice.The experiments include calibration of a widely used simulator for industrial manufacturing processes, where we also demonstrate how the proposed method may be useful for sensitivity analysis of model parameters.",
        "bibtex": "@InProceedings{pmlr-v108-kisamori20a,\n  title = \t {Simulator Calibration under Covariate Shift with Kernels},\n  author =       {Kisamori, Keiichi and Kanagawa, Motonobu and Yamazaki, Keisuke},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1244--1253},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kisamori20a/kisamori20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kisamori20a.html},\n  abstract = \t {We propose a novel calibration method for computer simulators, dealing with the problem of covariate shift.Covariate shift is the situation where input distributions for training and test are different, and ubiquitous in applications of simulations. Our approach is based on Bayesian inference with kernel mean embedding of distributions, and on the use of an importance-weighted reproducing kernel for covariate shift adaptation.We provide a theoretical analysis for the proposed method, including a novel theoretical result for conditional mean embedding, as well as empirical investigations suggesting its effectiveness in practice.The experiments include calibration of a widely used simulator for industrial manufacturing processes, where we also demonstrate how the proposed method may be useful for sensitivity analysis of model parameters.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kisamori20a/kisamori20a.pdf",
        "supp": "",
        "pdf_size": 737191,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1514289046421812379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "NEC and AIST, Japan; EURECOM, France; AIST, Japan",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "NEC;EURECOM;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nec.com;https://www.eurecom.fr;https://www.aist.go.jp",
        "aff_unique_abbr": "NEC;EURECOM;AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;France"
    },
    {
        "id": "d753b52ae3",
        "title": "Sketching Transformed Matrices with Applications to Natural Language Processing",
        "site": "https://proceedings.mlr.press/v108/liang20a.html",
        "author": "Yingyu Liang; Zhao Song; Mengdi Wang; Lin Yang; Xin Yang",
        "abstract": "Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in memory but is in a disk or is presented in a data stream. However, we need to compute a matrix decomposition of the entry-wisely transformed matrix, $f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space efficient way? Many machine learning applications indeed need to deal with such large transformed matrices, for example word embedding method in NLP needs to work with the pointwise mutual information (PMI) matrix, while the entrywise transformation makes it difficult to apply known linear algebraic tools. Existing approaches for this problem either need to store the whole matrix and perform the entry-wise transformation afterwards, which is space consuming or infeasible, or need to redesign the learning method, which is application specific and requires substantial remodeling.In this paper, we first propose a space-efficient sketching algorithm for computing the product of a given small matrix with the transformed matrix. It works for a general family of transformations with provable small error bounds and thus can be used as a primitive in downstream learning tasks. We then apply this primitive to two concrete applications: low-rank approximation and linear regressions. We show that our approach obtains small error and is efficient in both space and time. For instance, for a large $n\\times n$ matrix $A$, we show that only $\\tilde{O}(nk^3)$ space and a few scans over the matrix $A$ are needed to compute a rank-$k$ approximation of $\\log(|A|+1)$ to a fixed accuracy. This is a nearly quadratic space improvement for small $k$. We complement our theoretical results with experiments of low-rank approximation on synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v108-liang20a,\n  title = \t {Sketching Transformed Matrices with Applications to Natural Language Processing},\n  author =       {Liang, Yingyu and Song, Zhao and Wang, Mengdi and Yang, Lin and Yang, Xin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {467--481},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/liang20a/liang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/liang20a.html},\n  abstract = \t {Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in memory but is in a disk or is presented in a data stream. However, we need to compute a matrix decomposition of the entry-wisely transformed matrix, $f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space efficient way? Many machine learning applications indeed need to deal with such large transformed matrices, for example word embedding method in NLP needs to work with the pointwise mutual information (PMI) matrix, while the entrywise transformation makes it difficult to apply known linear algebraic tools. Existing approaches for this problem either need to store the whole matrix and perform the entry-wise transformation afterwards, which is space consuming or infeasible, or need to redesign the learning method, which is application specific and requires substantial remodeling.In this paper, we first propose a space-efficient sketching algorithm for computing the product of a given small matrix with the transformed matrix. It works for a general family of transformations with provable small error bounds and thus can be used as a primitive in downstream learning tasks. We then apply this primitive to two concrete applications: low-rank approximation and linear regressions. We show that our approach obtains small error and is efficient in both space and time. For instance, for a large $n\\times n$ matrix $A$, we show that only $\\tilde{O}(nk^3)$ space and a few scans over the matrix $A$ are needed to compute a rank-$k$ approximation of $\\log(|A|+1)$ to a fixed accuracy. This is a nearly quadratic space improvement for small $k$. We complement our theoretical results with experiments of low-rank approximation on synthetic and real data. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/liang20a/liang20a.pdf",
        "supp": "",
        "pdf_size": 510945,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9659194869755547524&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Wisconsin-Madison; IAS Princeton University; University of Wisconsin-Madison; UCLA; University of Washington",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "University of Wisconsin-Madison;Institute for Advanced Study;University of California, Los Angeles;University of Washington",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.wisc.edu;https://www.ias.edu;https://www.ucla.edu;https://www.washington.edu",
        "aff_unique_abbr": "UW-Madison;IAS;UCLA;UW",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Madison;Princeton;Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e9a9aa28af",
        "title": "Solving Discounted Stochastic Two-Player Games with Near-Optimal Time and Sample Complexity",
        "site": "https://proceedings.mlr.press/v108/sidford20a.html",
        "author": "Aaron Sidford; Mengdi Wang; Lin Yang; Yinyu Ye",
        "abstract": "In this paper we settle  the sampling complexity of solving discounted two-player turn-based zero-sum stochastic games up to polylogarithmic factors. Given a stochastic game with discount factor $\\gamma\\in(0,1)$ we provide an algorithm that computes an $\\epsilon$-optimal strategy with high-probability given $\\tilde{O}((1 - \\gamma)^{-3} \\epsilon^{-2})$ samples from the transition function for each state-action-pair. Our algorithm runs in time nearly linear in the number of samples and uses space nearly linear in the number of state-action pairs. As stochastic games generalize Markov decision processes (MDPs) our runtime and sample complexities are optimal due to \\cite{azar2013minimax}. We achieve our results by showing how to generalize a near-optimal Q-learning based algorithms for MDP,  in particular \\cite{sidford2018near},  to two-player strategy computation algorithms. This overcomes limitations of standard Q-learning and strategy iteration or alternating minimization based approaches and we hope will pave the way for future reinforcement learning results by facilitating the extension of MDP results to multi-agent settings with little loss.",
        "bibtex": "@InProceedings{pmlr-v108-sidford20a,\n  title = \t {Solving Discounted Stochastic Two-Player Games with Near-Optimal Time and Sample Complexity},\n  author =       {Sidford, Aaron and Wang, Mengdi and Yang, Lin and Ye, Yinyu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2992--3002},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/sidford20a/sidford20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/sidford20a.html},\n  abstract = \t {In this paper we settle  the sampling complexity of solving discounted two-player turn-based zero-sum stochastic games up to polylogarithmic factors. Given a stochastic game with discount factor $\\gamma\\in(0,1)$ we provide an algorithm that computes an $\\epsilon$-optimal strategy with high-probability given $\\tilde{O}((1 - \\gamma)^{-3} \\epsilon^{-2})$ samples from the transition function for each state-action-pair. Our algorithm runs in time nearly linear in the number of samples and uses space nearly linear in the number of state-action pairs. As stochastic games generalize Markov decision processes (MDPs) our runtime and sample complexities are optimal due to \\cite{azar2013minimax}. We achieve our results by showing how to generalize a near-optimal Q-learning based algorithms for MDP,  in particular \\cite{sidford2018near},  to two-player strategy computation algorithms. This overcomes limitations of standard Q-learning and strategy iteration or alternating minimization based approaches and we hope will pave the way for future reinforcement learning results by facilitating the extension of MDP results to multi-agent settings with little loss.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/sidford20a/sidford20a.pdf",
        "supp": "",
        "pdf_size": 308882,
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16300127176313200896&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Stanford University; Princeton University; UCLA; Stanford University",
        "aff_domain": "stanford.edu;princeton.edu;ee.ucla.edu;stanford.edu",
        "email": "stanford.edu;princeton.edu;ee.ucla.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Stanford University;Princeton University;University of California, Los Angeles",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.princeton.edu;https://www.ucla.edu",
        "aff_unique_abbr": "Stanford;Princeton;UCLA",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Stanford;;Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4c82baddae",
        "title": "Solving the Robust Matrix Completion Problem via  a System of Nonlinear Equations",
        "site": "https://proceedings.mlr.press/v108/cai20b.html",
        "author": "Yunfeng Cai; Ping Li",
        "abstract": "We consider the problem of robust matrix completion, which aims to recover a low rank matrix $L_*$ and a sparse matrix $S_*$ from incomplete observations of their sum $M=L_*+S_*\\in\\mathbb{R}^{m\\times n}$.Algorithmically, the robust matrix completion problem is transformed into a problem of solving a system of nonlinear equations,and the alternative direction method is then used to solve the nonlinear equations.In addition, the algorithm is highly parallelizable and suitable for large scale problems.Theoretically, we characterize the sufficient conditions for when $L_*$ can be approximated by a low rank approximation of the observed $M_*$.And under proper assumptions, it is shown that the algorithm converges to the true solution linearly.Numerical simulations show that the simple method works as expected and is comparable with state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v108-cai20b,\n  title = \t {Solving the Robust Matrix Completion Problem via  a System of Nonlinear Equations},\n  author =       {Cai, Yunfeng and Li, Ping},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4162--4172},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cai20b/cai20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cai20b.html},\n  abstract = \t {We consider the problem of robust matrix completion, which aims to recover a low rank matrix $L_*$ and a sparse matrix $S_*$ from incomplete observations of their sum $M=L_*+S_*\\in\\mathbb{R}^{m\\times n}$.Algorithmically, the robust matrix completion problem is transformed into a problem of solving a system of nonlinear equations,and the alternative direction method is then used to solve the nonlinear equations.In addition, the algorithm is highly parallelizable and suitable for large scale problems.Theoretically, we characterize the sufficient conditions for when $L_*$ can be approximated by a low rank approximation of the observed $M_*$.And under proper assumptions, it is shown that the algorithm converges to the true solution linearly.Numerical simulations show that the simple method works as expected and is comparable with state-of-the-art methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cai20b/cai20b.pdf",
        "supp": "",
        "pdf_size": 541125,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6464795561180583809&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Cognitive Computing Lab, Baidu Research, No. 10 Xibeiwang East Road, Beijing 100085, China + 10900 NE 8th St. Bellevue, WA 98004, USA; Cognitive Computing Lab, Baidu Research, No. 10 Xibeiwang East Road, Beijing 100085, China + 10900 NE 8th St. Bellevue, WA 98004, USA",
        "aff_domain": "baidu.com;baidu.com",
        "email": "baidu.com;baidu.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "Baidu;Unknown Institution",
        "aff_unique_dep": "Cognitive Computing Lab;",
        "aff_unique_url": "https://research.baidu.com;",
        "aff_unique_abbr": "Baidu;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0+1;0+1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9ecaebf1c6",
        "title": "Sparse Hilbert-Schmidt Independence Criterion Regression",
        "site": "https://proceedings.mlr.press/v108/poignard20a.html",
        "author": "Benjamin Poignard; Makoto Yamada",
        "abstract": "Feature selection is a fundamental problem for machine learning and statistics, and it has been widely studied over the past decades. However, the majority of feature selection algorithms are based on linear models, and the nonlinear feature selection problem has not been well studied compared to linear models, in particular for the high-dimensional case. In this paper, we propose the sparse Hilbert\u2013Schmidt Independence Criterion (SpHSIC) regression, which is a versatile nonlinear feature selection algorithm based on the HSIC and is a continuous optimization variant of the well-known minimum redundancy maximum relevance (mRMR) feature selection algorithm. More specifically, the SpHSIC consists of two parts: the convex HSIC loss function on the one hand and the regularization term on the other hand, where we consider the Lasso, Bridge, MCP, and SCAD penalties. We prove that the sparsity based HSIC regression estimator satisfies the oracle property; that is, the sparsity-based estimator recovers the true underlying sparse model and is asymptotically normally distributed. On the basis of synthetic and real-world experiments, we illustrate this theoretical property and highlight the fact that the proposed algorithm performs well in the high-dimensional setting.",
        "bibtex": "@InProceedings{pmlr-v108-poignard20a,\n  title = \t {Sparse Hilbert-Schmidt Independence Criterion Regression},\n  author =       {Poignard, Benjamin and Yamada, Makoto},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {538--548},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/poignard20a/poignard20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/poignard20a.html},\n  abstract = \t {Feature selection is a fundamental problem for machine learning and statistics, and it has been widely studied over the past decades. However, the majority of feature selection algorithms are based on linear models, and the nonlinear feature selection problem has not been well studied compared to linear models, in particular for the high-dimensional case. In this paper, we propose the sparse Hilbert\u2013Schmidt Independence Criterion (SpHSIC) regression, which is a versatile nonlinear feature selection algorithm based on the HSIC and is a continuous optimization variant of the well-known minimum redundancy maximum relevance (mRMR) feature selection algorithm. More specifically, the SpHSIC consists of two parts: the convex HSIC loss function on the one hand and the regularization term on the other hand, where we consider the Lasso, Bridge, MCP, and SCAD penalties. We prove that the sparsity based HSIC regression estimator satisfies the oracle property; that is, the sparsity-based estimator recovers the true underlying sparse model and is asymptotically normally distributed. On the basis of synthetic and real-world experiments, we illustrate this theoretical property and highlight the fact that the proposed algorithm performs well in the high-dimensional setting.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/poignard20a/poignard20a.pdf",
        "supp": "",
        "pdf_size": 330733,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7235341688008708233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Osaka University/RIKEN AIP; RIKEN AIP/Kyoto University/JST PRESTO",
        "aff_domain": "econ.osaka-u.ac.jp;riken.jp",
        "email": "econ.osaka-u.ac.jp;riken.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Osaka University;RIKEN",
        "aff_unique_dep": ";AIP",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "Osaka U;RIKEN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "22672e8e8e",
        "title": "Sparse Orthogonal Variational Inference for Gaussian Processes",
        "site": "https://proceedings.mlr.press/v108/shi20b.html",
        "author": "Jiaxin Shi; Michalis Titsias; Andriy Mnih",
        "abstract": "We introduce a new interpretation of sparse variational approximations for Gaussian processes using inducing points, which can lead to more scalable algorithms than previous methods. It is based on decomposing a Gaussian process as a sum of two independent processes: one spanned by a finite basis of inducing points and the other capturing the remaining variation. We show that this formulation recovers existing approximations and at the same time allows to obtain tighter lower bounds on the marginal likelihood and new stochastic variational inference algorithms. We demonstrate the efficiency of these algorithms in several Gaussian process models ranging from standard regression to multi-class classification using (deep) convolutional Gaussian processes and report state-of-the-art results on CIFAR-10 among purely GP-based models.",
        "bibtex": "@InProceedings{pmlr-v108-shi20b,\n  title = \t {Sparse Orthogonal Variational Inference for Gaussian Processes},\n  author =       {Shi, Jiaxin and Titsias, Michalis and Mnih, Andriy},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1932--1942},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/shi20b/shi20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/shi20b.html},\n  abstract = \t {We introduce a new interpretation of sparse variational approximations for Gaussian processes using inducing points, which can lead to more scalable algorithms than previous methods. It is based on decomposing a Gaussian process as a sum of two independent processes: one spanned by a finite basis of inducing points and the other capturing the remaining variation. We show that this formulation recovers existing approximations and at the same time allows to obtain tighter lower bounds on the marginal likelihood and new stochastic variational inference algorithms. We demonstrate the efficiency of these algorithms in several Gaussian process models ranging from standard regression to multi-class classification using (deep) convolutional Gaussian processes and report state-of-the-art results on CIFAR-10 among purely GP-based models.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/shi20b/shi20b.pdf",
        "supp": "",
        "pdf_size": 2154101,
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8252408479807021685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Tsinghua University; DeepMind; DeepMind",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tsinghua University;DeepMind",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://deepmind.com",
        "aff_unique_abbr": "THU;DeepMind",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "77b1d60ae1",
        "title": "Sparse and Low-rank Tensor Estimation via Cubic Sketchings",
        "site": "https://proceedings.mlr.press/v108/hao20a.html",
        "author": "Botao Hao; Anru R. Zhang; Guang Cheng",
        "abstract": "In this paper, we propose a general framework for sparse and low-rank tensor estimation from cubic sketchings. A two-stage non-convex implementation is developed based on sparse tensor decomposition and thresholded gradient descent, which ensures exact recovery in the noiseless case and stable recovery in the noisy case with high probability. The non-asymptotic analysis sheds light on an interplay between optimization error and statistical error. The proposed procedure is shown to be rate-optimal under certain conditions. As a technical by-product, novel high-order concentration inequalities are derived for studying high-moment sub-Gaussian tensors. An interesting tensor formulation illustrates the potential application to high-order interaction pursuit in high-dimensional linear regression.",
        "bibtex": "@InProceedings{pmlr-v108-hao20a,\n  title = \t {Sparse and Low-rank Tensor Estimation via Cubic Sketchings},\n  author =       {Hao, Botao and Zhang, Anru R. and Cheng, Guang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1319--1330},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/hao20a/hao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/hao20a.html},\n  abstract = \t { In this paper, we propose a general framework for sparse and low-rank tensor estimation from cubic sketchings. A two-stage non-convex implementation is developed based on sparse tensor decomposition and thresholded gradient descent, which ensures exact recovery in the noiseless case and stable recovery in the noisy case with high probability. The non-asymptotic analysis sheds light on an interplay between optimization error and statistical error. The proposed procedure is shown to be rate-optimal under certain conditions. As a technical by-product, novel high-order concentration inequalities are derived for studying high-moment sub-Gaussian tensors. An interesting tensor formulation illustrates the potential application to high-order interaction pursuit in high-dimensional linear regression.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/hao20a/hao20a.pdf",
        "supp": "",
        "pdf_size": 499581,
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6952451798616026794&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "501ce03e7c",
        "title": "Spatio-temporal alignments: Optimal transport through space and time",
        "site": "https://proceedings.mlr.press/v108/janati20a.html",
        "author": "Hicham Janati; Marco Cuturi; Alexandre Gramfort",
        "abstract": "Comparing data defined over space and time is notoriously hard. It involves quantifying both spatial and temporal variability while taking into account the chronological structure of the data. Dynamic Time Warping (DTW) computes a minimal cost alignment between time series that preserves the chronological order but is inherently blind to spatio-temporal shifts. In this paper, we propose Spatio-Temporal Alignments (STA), a new differentiable formulation of DTW that captures spatial and temporal variability. Spatial differences between time samples are captured using regularized Optimal transport. While temporal alignment cost exploits a smooth variant of DTW called soft-DTW. We show how smoothing DTW leads to alignment costs that increase quadratically with time shifts. The costs are expressed using an unbalanced Wasserstein distance to cope with observations that are not probabilities. Experiments on handwritten letters and brain imaging data confirm our theoretical findings and illustrate the effectiveness of STA as a dissimilarity for spatio-temporal data.",
        "bibtex": "@InProceedings{pmlr-v108-janati20a,\n  title = \t {Spatio-temporal alignments: Optimal transport through space and time},\n  author =       {Janati, Hicham and Cuturi, Marco and Gramfort, Alexandre},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1695--1704},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/janati20a/janati20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/janati20a.html},\n  abstract = \t {    Comparing data defined over space and time is notoriously hard. It involves quantifying both spatial and temporal variability while taking into account the chronological structure of the data. Dynamic Time Warping (DTW) computes a minimal cost alignment between time series that preserves the chronological order but is inherently blind to spatio-temporal shifts. In this paper, we propose Spatio-Temporal Alignments (STA), a new differentiable formulation of DTW that captures spatial and temporal variability. Spatial differences between time samples are captured using regularized Optimal transport. While temporal alignment cost exploits a smooth variant of DTW called soft-DTW. We show how smoothing DTW leads to alignment costs that increase quadratically with time shifts. The costs are expressed using an unbalanced Wasserstein distance to cope with observations that are not probabilities. Experiments on handwritten letters and brain imaging data confirm our theoretical findings and illustrate the effectiveness of STA as a dissimilarity for spatio-temporal data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/janati20a/janati20a.pdf",
        "supp": "",
        "pdf_size": 3665465,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3415015642603974981&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7b6fcec71a",
        "title": "Stable behaviour of infinitely wide deep neural networks",
        "site": "https://proceedings.mlr.press/v108/peluchetti20b.html",
        "author": "Stefano Peluchetti; Stefano Favaro; Sandra Fortini",
        "abstract": "We consider fully connected feed-forward deep neural networks (NNs) where weights and biases are independent and identically distributed as symmetric centered stable distributions. Then, we show that the infinite wide limit of the NN, under suitable scaling on the weights, is a stochastic process whose finite-dimensional distributions are multivariate stable distributions. The limiting process is referred to as the stable process, and it generalizes the class of Gaussian processes recently obtained as infinite wide limits of NNs (Matthews at al., 2018b). Parameters of the stable process can be computed via an explicit recursion over the layers of the network. Our result contributes to the theory of fully connected feed-forward deep NNs, and it paves the way to expand recent lines of research that rely on Gaussian infinite wide limits.",
        "bibtex": "@InProceedings{pmlr-v108-peluchetti20b,\n  title = \t {Stable behaviour of infinitely wide deep neural networks},\n  author =       {Peluchetti, Stefano and Favaro, Stefano and Fortini, Sandra},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1137--1146},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/peluchetti20b/peluchetti20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/peluchetti20b.html},\n  abstract = \t {We consider fully connected feed-forward deep neural networks (NNs) where weights and biases are independent and identically distributed as symmetric centered stable distributions. Then, we show that the infinite wide limit of the NN, under suitable scaling on the weights, is a stochastic process whose finite-dimensional distributions are multivariate stable distributions. The limiting process is referred to as the stable process, and it generalizes the class of Gaussian processes recently obtained as infinite wide limits of NNs (Matthews at al., 2018b). Parameters of the stable process can be computed via an explicit recursion over the layers of the network. Our result contributes to the theory of fully connected feed-forward deep NNs, and it paves the way to expand recent lines of research that rely on Gaussian infinite wide limits.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/peluchetti20b/peluchetti20b.pdf",
        "supp": "",
        "pdf_size": 699491,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4752685066049494833&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department ESOMAS, University of Torino and Collegio Carlo Alberto; Department of Decision Sciences, Bocconi University; Cogent Labs",
        "aff_domain": "unito.it;unibocconi.it;cogent.co.jp",
        "email": "unito.it;unibocconi.it;cogent.co.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Torino;Bocconi University;Cogent Labs",
        "aff_unique_dep": "Department ESOMAS;Department of Decision Sciences;",
        "aff_unique_url": "https://www.unito.it;https://www.bocconi.edu;https://www.cogentlabs.com",
        "aff_unique_abbr": "Unito;Bocconi;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Torino;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "bbf33897d1",
        "title": "Statistical Estimation of the Poincar\u00e9 constant and Application to Sampling Multimodal Distributions",
        "site": "https://proceedings.mlr.press/v108/pillaud-vivien20a.html",
        "author": "Loucas Pillaud-Vivien; Francis Bach; Tony Leli\u00e8vre; Alessandro Rudi; Gabriel Stoltz",
        "abstract": "Poincar\u00e9 inequalities are ubiquitous in probability and analysis and have various applications in statistics (concentration of measure, rate of convergence of Markov chains). The Poincar\u00e9 constant, for which the inequality is tight, is related to the typical convergence rate of diffusions to their equilibrium measure. In this paper, we show both theoretically and experimentally that, given sufficiently many samples of a measure, we can estimate its Poincar\u00e9 constant. As a by-product of the estimation of the Poincar\u00e9 constant, we derive an algorithm that captures a low dimensional representation of the data by finding directions which are difficult to sample. These directions are of crucial importance for sampling or in fields like molecular dynamics, where they are called reaction coordinates. Their knowledge can leverage, with a simple conditioning step, computational bottlenecks by using importance sampling techniques.",
        "bibtex": "@InProceedings{pmlr-v108-pillaud-vivien20a,\n  title = \t {Statistical Estimation of the Poincar\u00e9 constant and Application to Sampling Multimodal Distributions},\n  author =       {Pillaud-Vivien, Loucas and Bach, Francis and Leli\u00e8vre, Tony and Rudi, Alessandro and Stoltz, Gabriel},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2753--2763},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pillaud-vivien20a/pillaud-vivien20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pillaud-vivien20a.html},\n  abstract = \t {Poincar\u00e9 inequalities are ubiquitous in probability and analysis and have various applications in statistics (concentration of measure, rate of convergence of Markov chains). The Poincar\u00e9 constant, for which the inequality is tight, is related to the typical convergence rate of diffusions to their equilibrium measure. In this paper, we show both theoretically and experimentally that, given sufficiently many samples of a measure, we can estimate its Poincar\u00e9 constant. As a by-product of the estimation of the Poincar\u00e9 constant, we derive an algorithm that captures a low dimensional representation of the data by finding directions which are difficult to sample. These directions are of crucial importance for sampling or in fields like molecular dynamics, where they are called reaction coordinates. Their knowledge can leverage, with a simple conditioning step, computational bottlenecks by using importance sampling techniques.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pillaud-vivien20a/pillaud-vivien20a.pdf",
        "supp": "",
        "pdf_size": 1189757,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12157162118527070891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "INRIA - Ecole Normale Sup\u00e9rieure - PSL Research University; INRIA - Ecole Normale Sup\u00e9rieure - PSL Research University; Universit\u00e9 Paris-Est - CERMICS (ENPC) - INRIA; INRIA - Ecole Normale Sup\u00e9rieure - PSL Research University; Universit\u00e9 Paris-Est - CERMICS (ENPC) - INRIA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "INRIA;Universit\u00e9 Paris-Est",
        "aff_unique_dep": ";CERMICS (ENPC)",
        "aff_unique_url": "https://www.inria.fr;https://www.univ-mlv.fr",
        "aff_unique_abbr": "INRIA;UPE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "c9aec5a24a",
        "title": "Statistical and Computational Rates in Graph Logistic Regression",
        "site": "https://proceedings.mlr.press/v108/berthet20a.html",
        "author": "Quentin Berthet; Nicolai Baldin",
        "abstract": "We consider the problem of graph logistic regression, based on partial observation of a large network, and on side information associated to its vertices. The generative model is formulated as a matrix logistic regression. The performance of the model is analyzed in a high-dimensional regime under a structural assumption. The optimal statistical rates are derived, and an estimator based on penalized maximum likelihood is shown to attain it. The algorithmic aspects of this problem are also studied, and optimal rates under computational constraints are derived, and shown to differ from the information-theoretic rates - under a complexity assumption.",
        "bibtex": "@InProceedings{pmlr-v108-berthet20a,\n  title = \t {Statistical and Computational Rates in Graph Logistic Regression},\n  author =       {Berthet, Quentin and Baldin, Nicolai},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2719--2730},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/berthet20a/berthet20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/berthet20a.html},\n  abstract = \t {We consider the problem of graph logistic regression, based on partial observation of a large network, and on side information associated to its vertices. The generative model is formulated as a matrix logistic regression. The performance of the model is analyzed in a high-dimensional regime under a structural assumption. The optimal statistical rates are derived, and an estimator based on penalized maximum likelihood is shown to attain it. The algorithmic aspects of this problem are also studied, and optimal rates under computational constraints are derived, and shown to differ from the information-theoretic rates - under a complexity assumption.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/berthet20a/berthet20a.pdf",
        "supp": "",
        "pdf_size": 319387,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11235240488962760101&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "University of Cambridge; Google Research, Brain Team",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Cambridge;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.cam.ac.uk;https://research.google",
        "aff_unique_abbr": "Cambridge;Google",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Cambridge;Mountain View",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "2050059ae4",
        "title": "Statistical guarantees for local graph clustering",
        "site": "https://proceedings.mlr.press/v108/ha20a.html",
        "author": "Wooseok Ha; Kimon Fountoulakis; Michael Mahoney",
        "abstract": "Local graph clustering methods aim to find small clusters in very large graphs. These methods take as input a graph and a seed node, and they return as output a good cluster in a running time that depends on the size of the output cluster but that is independent of the size of the input graph. In this paper, we adopt a statistical perspective on local graph clustering, and we analyze the performance of the l1-regularized PageRank method for the recovery of a single target cluster, given a seed node inside the cluster. Assuming the target cluster has been generated by a random model, we present two results. In the first, we show that the optimal support of l1-regularized PageRank recovers the full target cluster, with bounded false positives. In the second, we show that if the seed node is connected solely to the target cluster then the optimal support of l1-regularized PageRank recovers exactly the target cluster. We also show empirically that l1-regularized PageRank has a state-of-the-art performance on many real graphs, demonstrating the superiority of the method.",
        "bibtex": "@InProceedings{pmlr-v108-ha20a,\n  title = \t {Statistical guarantees for local graph clustering},\n  author =       {Ha, Wooseok and Fountoulakis, Kimon and Mahoney, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2687--2697},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ha20a/ha20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ha20a.html},\n  abstract = \t {Local graph clustering methods aim to find small clusters in very large graphs. These methods take as input a graph and a seed node, and they return as output a good cluster in a running time that depends on the size of the output cluster but that is independent of the size of the input graph. In this paper, we adopt a statistical perspective on local graph clustering, and we analyze the performance of the l1-regularized PageRank method for the recovery of a single target cluster, given a seed node inside the cluster. Assuming the target cluster has been generated by a random model, we present two results. In the first, we show that the optimal support of l1-regularized PageRank recovers the full target cluster, with bounded false positives. In the second, we show that if the seed node is connected solely to the target cluster then the optimal support of l1-regularized PageRank recovers exactly the target cluster. We also show empirically that l1-regularized PageRank has a state-of-the-art performance on many real graphs, demonstrating the superiority of the method.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ha20a/ha20a.pdf",
        "supp": "",
        "pdf_size": 777867,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1861207299535822945&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1acfc03069",
        "title": "Stein Variational Inference for Discrete Distributions",
        "site": "https://proceedings.mlr.press/v108/han20c.html",
        "author": "Jun Han; Fan Ding; Xianglong Liu; Lorenzo Torresani; Jian Peng; Qiang Liu",
        "abstract": "Gradient-based approximate inference methods, such as Stein variational gradient descent (SVGD) \\cite{liu2016stein}, provide simple and general-purpose inference engines for differentiable continuous distributions. However, existing forms of SVGD can not be directly applied to discrete distributions. In this work, we fill this gap by proposing a simple general-purpose framework that transforms discrete distributions to equivalent piecewise continuous distribution, on which we apply gradient-free Stein variational gradient descent to perform efficient approximate inference.  Our empirical results show that our method outperforms traditional algorithms such as Gibbs sampling and discontinuous Hamiltonian Monte Carlo on various challenging benchmarks of discrete graphical models. We demonstrate that our method provides a promising tool for learning ensembles of binarized neural network (BNN), outperforming other widely used ensemble methods on learning binarized AlexNet on CIFAR-10. In addition, such transform can be straightforwardly employed in gradient-free kernelized Stein discrepancy to perform goodness-of-fit (GOF) test on discrete distributions. Our proposed method outperforms existing GOF test methods for intractable discrete distributions.",
        "bibtex": "@InProceedings{pmlr-v108-han20c,\n  title = \t {Stein Variational Inference for Discrete Distributions},\n  author =       {Han, Jun and Ding, Fan and Liu, Xianglong and Torresani, Lorenzo and Peng, Jian and Liu, Qiang},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4563--4572},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/han20c/han20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/han20c.html},\n  abstract = \t {Gradient-based approximate inference methods, such as Stein variational gradient descent (SVGD) \\cite{liu2016stein}, provide simple and general-purpose inference engines for differentiable continuous distributions. However, existing forms of SVGD can not be directly applied to discrete distributions. In this work, we fill this gap by proposing a simple general-purpose framework that transforms discrete distributions to equivalent piecewise continuous distribution, on which we apply gradient-free Stein variational gradient descent to perform efficient approximate inference.  Our empirical results show that our method outperforms traditional algorithms such as Gibbs sampling and discontinuous Hamiltonian Monte Carlo on various challenging benchmarks of discrete graphical models. We demonstrate that our method provides a promising tool for learning ensembles of binarized neural network (BNN), outperforming other widely used ensemble methods on learning binarized AlexNet on CIFAR-10. In addition, such transform can be straightforwardly employed in gradient-free kernelized Stein discrepancy to perform goodness-of-fit (GOF) test on discrete distributions. Our proposed method outperforms existing GOF test methods for intractable discrete distributions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/han20c/han20c.pdf",
        "supp": "",
        "pdf_size": 1423402,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14802257686213172827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ce6d5b5b01",
        "title": "Stepwise Model Selection for Sequence Prediction via Deep Kernel Learning",
        "site": "https://proceedings.mlr.press/v108/zhang20f.html",
        "author": "Yao Zhang; Daniel Jarrett; Mihaela Schaar",
        "abstract": "An essential problem in automated machine learning (AutoML) is that of model selection. A unique challenge in the sequential setting is the fact that the optimal model itself may vary over time, depending on the distribution of features and labels available up to each point in time. In this paper, we propose a novel Bayesian optimization (BO) algorithm to tackle the challenge of model selection in this setting. This is accomplished by treating the performance at each time step as its own black-box function. In order to solve the resulting multiple black-box function optimization problem jointly and efficiently, we exploit potential correlations among black-box functions using deep kernel learning (DKL). To the best of our knowledge, we are the first to formulate the problem of stepwise model selection (SMS) for sequence prediction, and to design and demonstrate an efficient joint-learning algorithm for this purpose. Using multiple real-world datasets, we verify that our proposed method outperforms both standard BO and multi-objective BO algorithms on a variety of sequence prediction tasks.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20f,\n  title = \t {Stepwise Model Selection for Sequence Prediction via Deep Kernel Learning},\n  author =       {Zhang, Yao and Jarrett, Daniel and van der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2304--2314},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20f/zhang20f.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20f.html},\n  abstract = \t {An essential problem in automated machine learning (AutoML) is that of model selection. A unique challenge in the sequential setting is the fact that the optimal model itself may vary over time, depending on the distribution of features and labels available up to each point in time. In this paper, we propose a novel Bayesian optimization (BO) algorithm to tackle the challenge of model selection in this setting. This is accomplished by treating the performance at each time step as its own black-box function. In order to solve the resulting multiple black-box function optimization problem jointly and efficiently, we exploit potential correlations among black-box functions using deep kernel learning (DKL). To the best of our knowledge, we are the first to formulate the problem of stepwise model selection (SMS) for sequence prediction, and to design and demonstrate an efficient joint-learning algorithm for this purpose. Using multiple real-world datasets, we verify that our proposed method outperforms both standard BO and multi-objective BO algorithms on a variety of sequence prediction tasks.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20f/zhang20f.pdf",
        "supp": "",
        "pdf_size": 7230889,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11896599529613347651&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d530aa1ee1",
        "title": "Stochastic Bandits with Delay-Dependent Payoffs",
        "site": "https://proceedings.mlr.press/v108/cella20a.html",
        "author": "Leonardo Cella; Nicol\u00f3 Cesa-Bianchi",
        "abstract": "Motivated by recommendation problems in music streaming platforms, we propose a nonstationary stochastic bandit model in which the expected reward of an arm depends on the number of rounds that have passed since the arm was last pulled. After proving that finding an optimal policy is NP-hard even when all model parameters are known, we introduce a class of ranking policies provably approximating, to within a constant factor, the expected reward of the optimal policy. We show an algorithm whose regret with respect to the best ranking policy is bounded by $\\widetilde{\\scO}\\big(\\!\\sqrt{kT}\\big)$, where $k$ is the number of arms and $T$ is time. Our algorithm uses only $\\scO\\big(k\\ln\\ln T)$ switches, which helps when switching between policies is costly. As constructing the class of learning policies requires ordering the arms according to their expectations, we also bound the number of pulls required to do so. Finally, we run experiments to compare our algorithm against UCB on different problem instances.",
        "bibtex": "@InProceedings{pmlr-v108-cella20a,\n  title = \t {Stochastic Bandits with Delay-Dependent Payoffs},\n  author =       {Cella, Leonardo and Cesa-Bianchi, Nicol\\'o},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1168--1177},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/cella20a/cella20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/cella20a.html},\n  abstract = \t {Motivated by recommendation problems in music streaming platforms, we propose a nonstationary stochastic bandit model in which the expected reward of an arm depends on the number of rounds that have passed since the arm was last pulled. After proving that finding an optimal policy is NP-hard even when all model parameters are known, we introduce a class of ranking policies provably approximating, to within a constant factor, the expected reward of the optimal policy. We show an algorithm whose regret with respect to the best ranking policy is bounded by $\\widetilde{\\scO}\\big(\\!\\sqrt{kT}\\big)$, where $k$ is the number of arms and $T$ is time. Our algorithm uses only $\\scO\\big(k\\ln\\ln T)$ switches, which helps when switching between policies is costly. As constructing the class of learning policies requires ordering the arms according to their expectations, we also bound the number of pulls required to do so. Finally, we run experiments to compare our algorithm against UCB on different problem instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/cella20a/cella20a.pdf",
        "supp": "",
        "pdf_size": 356324,
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5058801310258784398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "DSRC & Dept. of Computer Science, Universit` a degli Studi di Milano, Italy; DSRC & Dept. of Computer Science, Universit` a degli Studi di Milano, Italy",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Milano",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.unimi.it",
        "aff_unique_abbr": "UniMi",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "d5c2857833",
        "title": "Stochastic Linear Contextual Bandits with Diverse Contexts",
        "site": "https://proceedings.mlr.press/v108/wu20c.html",
        "author": "Weiqiang Wu; Jing Yang; Cong Shen",
        "abstract": "In this paper, we investigate the impact of context diversity on stochastic linear contextual bandits. As opposed to the previous view that contexts lead to more difficult bandit learning, we show that when the contexts are sufficiently diverse, the learner is able to utilize the information obtained during exploitation to shorten the exploration process, thus achieving reduced regret. We design the LinUCB-d algorithm, and propose a novel approach to analyze its regret performance. The main theoretical result is that under the diverse context assumption, the cumulative expected regret of LinUCB-d is bounded by a constant. As a by-product, our results improve the previous understanding of LinUCB and strengthen its performance guarantee.",
        "bibtex": "@InProceedings{pmlr-v108-wu20c,\n  title = \t {Stochastic Linear Contextual Bandits with Diverse Contexts},\n  author =       {Wu, Weiqiang and Yang, Jing and Shen, Cong},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2392--2401},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wu20c/wu20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wu20c.html},\n  abstract = \t {In this paper, we investigate the impact of context diversity on stochastic linear contextual bandits. As opposed to the previous view that contexts lead to more difficult bandit learning, we show that when the contexts are sufficiently diverse, the learner is able to utilize the information obtained during exploitation to shorten the exploration process, thus achieving reduced regret. We design the LinUCB-d algorithm, and propose a novel approach to analyze its regret performance. The main theoretical result is that under the diverse context assumption, the cumulative expected regret of LinUCB-d is bounded by a constant. As a by-product, our results improve the previous understanding of LinUCB and strengthen its performance guarantee. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/wu20c/wu20c.pdf",
        "supp": "",
        "pdf_size": 1050628,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6646112970280108351&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "London Stock Exchange; The Pennsylvania State University; University of Virginia",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "London Stock Exchange;Pennsylvania State University;University of Virginia",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.lse.co.uk;https://www.psu.edu;https://www.virginia.edu",
        "aff_unique_abbr": "LSE;PSU;UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "ad82e70e9e",
        "title": "Stochastic Neural Network with Kronecker Flow",
        "site": "https://proceedings.mlr.press/v108/huang20a.html",
        "author": "Chin-Wei Huang; Ahmed Touati; Pascal Vincent; Gintare Karolina Dziugaite; Alexandre Lacoste; Aaron Courville",
        "abstract": "Recent advances in variational inference enable the modelling of highly structured joint distributions, but are limited in their capacity to scale to the high-dimensional setting of stochastic neural networks. This limitation motivates a need for scalable parameterizations of the noise generation process, in a manner that adequately captures the dependencies among the various parameters.  In this work, we address this need and present the Kronecker Flow, a generalization of the Kronecker product to invertible mappings designed for stochastic neural networks.  We apply our method to variational Bayesian neural networks on predictive tasks, PAC-Bayes generalization bound estimation, and approximate Thompson sampling in contextual bandits. In all setups, our methods prove to be competitive with existing methods and betterthan the baselines.",
        "bibtex": "@InProceedings{pmlr-v108-huang20a,\n  title = \t {Stochastic Neural Network with Kronecker Flow},\n  author =       {Huang, Chin-Wei and Touati, Ahmed and Vincent, Pascal and Dziugaite, Gintare Karolina and Lacoste, Alexandre and Courville, Aaron},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4184--4194},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/huang20a/huang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/huang20a.html},\n  abstract = \t {Recent advances in variational inference enable the modelling of highly structured joint distributions, but are limited in their capacity to scale to the high-dimensional setting of stochastic neural networks. This limitation motivates a need for scalable parameterizations of the noise generation process, in a manner that adequately captures the dependencies among the various parameters.  In this work, we address this need and present the Kronecker Flow, a generalization of the Kronecker product to invertible mappings designed for stochastic neural networks.  We apply our method to variational Bayesian neural networks on predictive tasks, PAC-Bayes generalization bound estimation, and approximate Thompson sampling in contextual bandits. In all setups, our methods prove to be competitive with existing methods and betterthan the baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/huang20a/huang20a.pdf",
        "supp": "",
        "pdf_size": 969670,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4637003244009726721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Mila\u2020Mila\u2020Facebook AI Research; Mila\u2020Mila\u2020Facebook AI Research; Mila\u2020Mila\u2020Facebook AI Research; Element AI; Element AI; Mila, CIFAR Fellow",
        "aff_domain": "mila.quebec;fb.com;mila.quebec;elementai.com;elementai.com;mila.quebec",
        "email": "mila.quebec;fb.com;mila.quebec;elementai.com;elementai.com;mila.quebec",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Mila;Element AI",
        "aff_unique_dep": "Facebook AI Research;",
        "aff_unique_url": "https://mila.quebec;https://www.elementai.com",
        "aff_unique_abbr": "Mila;Element AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "30b57978f0",
        "title": "Stochastic Particle-Optimization Sampling and the Non-Asymptotic Convergence Theory",
        "site": "https://proceedings.mlr.press/v108/zhang20d.html",
        "author": "Jianyi Zhang; Ruiyi Zhang; Lawrence Carin; Changyou Chen",
        "abstract": "Particle-optimization-based sampling (POS) is a recently developed effective sampling technique that interactively updates a set of particles. A representative algorithm is the Stein variational gradient descent (SVGD). We prove,  under certain conditions, SVGD experiences a theoretical pitfall, {\\it i.e.}, particles tend to collapse. As a remedy, we generalize POS to a stochastic setting by injecting random noise into particle updates, thus termed stochastic particle-optimization sampling (SPOS). Notably, for the first time, we develop non-asymptotic convergence theory for the SPOS framework (related to SVGD), characterizing algorithm convergence in terms of the 1-Wasserstein distance w.r.t. the numbers of particles and iterations. Somewhat surprisingly, with the same number of updates (not too large) for each particle, our theory suggests adopting more particles does not necessarily lead to a better approximation of a target distribution, due to limited computational budget and numerical errors. This phenomenon is also observed in SVGD and verified via a synthetic experiment. Extensive experimental results verify our theory and demonstrate the effectiveness of our proposed framework.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20d,\n  title = \t {Stochastic Particle-Optimization Sampling and the Non-Asymptotic Convergence Theory},\n  author =       {Zhang, Jianyi and Zhang, Ruiyi and Carin, Lawrence and Chen, Changyou},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1877--1887},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20d/zhang20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20d.html},\n  abstract = \t {Particle-optimization-based sampling (POS) is a recently developed effective sampling technique that interactively updates a set of particles. A representative algorithm is the Stein variational gradient descent (SVGD). We prove,  under certain conditions, SVGD experiences a theoretical pitfall, {\\it i.e.}, particles tend to collapse. As a remedy, we generalize POS to a stochastic setting by injecting random noise into particle updates, thus termed stochastic particle-optimization sampling (SPOS). Notably, for the first time, we develop non-asymptotic convergence theory for the SPOS framework (related to SVGD), characterizing algorithm convergence in terms of the 1-Wasserstein distance w.r.t. the numbers of particles and iterations. Somewhat surprisingly, with the same number of updates (not too large) for each particle, our theory suggests adopting more particles does not necessarily lead to a better approximation of a target distribution, due to limited computational budget and numerical errors. This phenomenon is also observed in SVGD and verified via a synthetic experiment. Extensive experimental results verify our theory and demonstrate the effectiveness of our proposed framework.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20d/zhang20d.pdf",
        "supp": "",
        "pdf_size": 1405011,
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5252560148893823003&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3a824ffc12",
        "title": "Stochastic Recursive Variance-Reduced Cubic Regularization Methods",
        "site": "https://proceedings.mlr.press/v108/zhou20a.html",
        "author": "Dongruo Zhou; Quanquan Gu",
        "abstract": "Stochastic Variance-Reduced Cubic regularization (SVRC) algorithms have received increasing attention due to its improved gradient/Hessian complexities (i.e., number of queries to stochastic gradient/Hessian oracles)  to find local minima for nonconvex finite-sum optimization. However, it is unclear whether existing SVRC algorithms can be further improved. Moreover, the semi-stochastic Hessian estimator adopted in existing SVRC algorithms prevents the use of Hessian-vector product-based fast cubic subproblem solvers, which makes SVRC algorithms computationally intractable for high-dimensional problems. In this paper, we first present a Stochastic Recursive Variance-Reduced Cubic regularization method (SRVRC) using a recursively updated semi-stochastic gradient and Hessian estimators. It enjoys improved gradient and Hessian complexities to find an $(\\epsilon, \\sqrt{\\epsilon})$-approximate local minimum, and outperforms the state-of-the-art SVRC algorithms.  Built upon SRVRC, we further propose a Hessian-free SRVRC algorithm, namely SRVRC$_{\\text{free}}$, which only needs $\\tilde O(n\\epsilon^{-2} \\land \\epsilon^{-3})$ stochastic gradient and Hessian-vector product computations, where $n$ is the number of component functions in the finite-sum objective and $\\epsilon$ is the optimization precision. This outperforms the best-known result $\\tilde O(\\epsilon^{-3.5})$ achieved by stochastic cubic regularization algorithm proposed in \\cite{tripuraneni2018stochastic}.",
        "bibtex": "@InProceedings{pmlr-v108-zhou20a,\n  title = \t {Stochastic Recursive Variance-Reduced Cubic Regularization Methods},\n  author =       {Zhou, Dongruo and Gu, Quanquan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3980--3990},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhou20a/zhou20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhou20a.html},\n  abstract = \t {Stochastic Variance-Reduced Cubic regularization (SVRC) algorithms have received increasing attention due to its improved gradient/Hessian complexities (i.e., number of queries to stochastic gradient/Hessian oracles)  to find local minima for nonconvex finite-sum optimization. However, it is unclear whether existing SVRC algorithms can be further improved. Moreover, the semi-stochastic Hessian estimator adopted in existing SVRC algorithms prevents the use of Hessian-vector product-based fast cubic subproblem solvers, which makes SVRC algorithms computationally intractable for high-dimensional problems. In this paper, we first present a Stochastic Recursive Variance-Reduced Cubic regularization method (SRVRC) using a recursively updated semi-stochastic gradient and Hessian estimators. It enjoys improved gradient and Hessian complexities to find an $(\\epsilon, \\sqrt{\\epsilon})$-approximate local minimum, and outperforms the state-of-the-art SVRC algorithms.  Built upon SRVRC, we further propose a Hessian-free SRVRC algorithm, namely SRVRC$_{\\text{free}}$, which only needs $\\tilde O(n\\epsilon^{-2} \\land \\epsilon^{-3})$ stochastic gradient and Hessian-vector product computations, where $n$ is the number of component functions in the finite-sum objective and $\\epsilon$ is the optimization precision. This outperforms the best-known result $\\tilde O(\\epsilon^{-3.5})$ achieved by stochastic cubic regularization algorithm proposed in \\cite{tripuraneni2018stochastic}. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhou20a/zhou20a.pdf",
        "supp": "",
        "pdf_size": 349260,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2094492337402448029&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of California, Los Angeles; Department of Computer Science, University of California, Los Angeles",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f47f1cd815",
        "title": "Stochastic Variance-Reduced Algorithms for PCA with Arbitrary Mini-Batch Sizes",
        "site": "https://proceedings.mlr.press/v108/kim20e.html",
        "author": "Cheolmin Kim; Diego Klabjan",
        "abstract": "We present two stochastic variance-reduced PCA algorithms and their convergence analyses. By deriving explicit forms of step size, epoch length and batch size to ensure the optimal runtime, we show that the proposed algorithms can attain the optimal runtime with any batch sizes. Also, we establish global convergence of the algorithms based on a novel approach, which studies the optimality gap as a ratio of two expectation terms. The framework in our analysis is general and can be used to analyze other stochastic variance-reduced PCA algorithms and improve their analyses. Moreover, we introduce practical implementations of the algorithms which do not require hyper-parameters. The experimental results show that the proposed methodsd outperform other stochastic variance-reduced PCA algorithms regardless of the batch size.",
        "bibtex": "@InProceedings{pmlr-v108-kim20e,\n  title = \t {Stochastic Variance-Reduced Algorithms for PCA with Arbitrary Mini-Batch Sizes},\n  author =       {Kim, Cheolmin and Klabjan, Diego},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4302--4312},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kim20e/kim20e.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kim20e.html},\n  abstract = \t {We present two stochastic variance-reduced PCA algorithms and their convergence analyses. By deriving explicit forms of step size, epoch length and batch size to ensure the optimal runtime, we show that the proposed algorithms can attain the optimal runtime with any batch sizes. Also, we establish global convergence of the algorithms based on a novel approach, which studies the optimality gap as a ratio of two expectation terms. The framework in our analysis is general and can be used to analyze other stochastic variance-reduced PCA algorithms and improve their analyses. Moreover, we introduce practical implementations of the algorithms which do not require hyper-parameters. The experimental results show that the proposed methodsd outperform other stochastic variance-reduced PCA algorithms regardless of the batch size.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kim20e/kim20e.pdf",
        "supp": "",
        "pdf_size": 399995,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13382682877185238402&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": "Northwestern University; Northwestern University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e0a64ee01a",
        "title": "Stopping criterion for active learning based on deterministic generalization bounds",
        "site": "https://proceedings.mlr.press/v108/ishibashi20a.html",
        "author": "Hideaki Ishibashi; Hideitsu Hino",
        "abstract": "Active learning is a framework in which the learning machine can select the samples to be used for training. This technique is promising, particularly when the cost of data acquisition and labeling is high. In active learning, determining the timing at which learning should be stopped is a critical issue. In this study, we propose a criterion for automatically stopping active learning. The proposed stopping criterion is based on the difference in the expected generalization errors and hypothesis testing. We derive a novel upper bound for the difference in expected generalization errors before and after obtaining a new training datum based on PAC-Bayesian theory. Unlike ordinary PAC-Bayesian bounds, though, the proposed bound is deterministic; hence, there is no uncontrollable trade-off between the confidence and tightness of the inequality. We combine the upper bound with a statistical test to derive a stopping criterion for active learning. We demonstrate the effectiveness of the proposed method via experiments with both artificial and real datasets.",
        "bibtex": "@InProceedings{pmlr-v108-ishibashi20a,\n  title = \t {Stopping criterion for active learning based on deterministic generalization bounds},\n  author =       {Ishibashi, Hideaki and Hino, Hideitsu},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {386--397},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ishibashi20a/ishibashi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ishibashi20a.html},\n  abstract = \t {Active learning is a framework in which the learning machine can select the samples to be used for training. This technique is promising, particularly when the cost of data acquisition and labeling is high. In active learning, determining the timing at which learning should be stopped is a critical issue. In this study, we propose a criterion for automatically stopping active learning. The proposed stopping criterion is based on the difference in the expected generalization errors and hypothesis testing. We derive a novel upper bound for the difference in expected generalization errors before and after obtaining a new training datum based on PAC-Bayesian theory. Unlike ordinary PAC-Bayesian bounds, though, the proposed bound is deterministic; hence, there is no uncontrollable trade-off between the confidence and tightness of the inequality. We combine the upper bound with a statistical test to derive a stopping criterion for active learning. We demonstrate the effectiveness of the proposed method via experiments with both artificial and real datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ishibashi20a/ishibashi20a.pdf",
        "supp": "",
        "pdf_size": 504104,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9043769887686925134&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Kyushu Institute of Technology; The Institute of Statistical Mathematics/RIKEN AIP",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Kyushu Institute of Technology;Institute of Statistical Mathematics",
        "aff_unique_dep": ";Statistics",
        "aff_unique_url": "https://www.kyutech.ac.jp;https://www.ism.ac.jp",
        "aff_unique_abbr": "Kyutech;ISM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "cbbbe6d6da",
        "title": "Stretching the Effectiveness of MLE from Accuracy to Bias for Pairwise Comparisons",
        "site": "https://proceedings.mlr.press/v108/wang20a.html",
        "author": "Jingyan Wang; Nihar Shah; R Ravi",
        "abstract": "A number of applications (e.g., AI bot tournaments, sports, peer grading, crowdsourcing) use pairwise comparison data and the Bradley-Terry-Luce (BTL) model to evaluate a given collection of items (e.g., bots, teams, students, search results). Past work has shown that under the BTL model, the widely-used maximum-likelihood estimator (MLE) is minimax-optimal in estimating the item parameters, in terms of the mean squared error. However, another important desideratum for designing estimators is fairness. In this work, we consider one specific type of fairness, which is the notion of bias in statistics. We show that the MLE incurs a suboptimal rate in terms of bias. We then propose a simple modification to the MLE, which \"stretches\" the bounding box of the maximum-likelihood optimizer by a small constant factor from the underlying ground truth domain. We show that this simple modification leads to an improved rate in bias, while maintaining minimax-optimality in the mean squared error. In this manner, our proposed class of estimators provably improves fairness in the sense of bias without loss in accuracy.",
        "bibtex": "@InProceedings{pmlr-v108-wang20a,\n  title = \t {Stretching the Effectiveness of MLE from Accuracy to Bias for Pairwise Comparisons},\n  author =       {Wang, Jingyan and Shah, Nihar and Ravi, R},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {66--76},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20a/wang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20a.html},\n  abstract = \t {A number of applications (e.g., AI bot tournaments, sports, peer grading, crowdsourcing) use pairwise comparison data and the Bradley-Terry-Luce (BTL) model to evaluate a given collection of items (e.g., bots, teams, students, search results). Past work has shown that under the BTL model, the widely-used maximum-likelihood estimator (MLE) is minimax-optimal in estimating the item parameters, in terms of the mean squared error. However, another important desideratum for designing estimators is fairness. In this work, we consider one specific type of fairness, which is the notion of bias in statistics. We show that the MLE incurs a suboptimal rate in terms of bias. We then propose a simple modification to the MLE, which \"stretches\" the bounding box of the maximum-likelihood optimizer by a small constant factor from the underlying ground truth domain. We show that this simple modification leads to an improved rate in bias, while maintaining minimax-optimality in the mean squared error. In this manner, our proposed class of estimators provably improves fairness in the sense of bias without loss in accuracy.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20a/wang20a.pdf",
        "supp": "",
        "pdf_size": 2414573,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9095905254502639502&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "40b99eaea9",
        "title": "Structured Conditional Continuous Normalizing Flows for Efficient Amortized Inference in Graphical Models",
        "site": "https://proceedings.mlr.press/v108/weilbach20a.html",
        "author": "Christian Weilbach; Boyan Beronov; Frank Wood; William Harvey",
        "abstract": "We exploit minimally faithful inversion of graphical model structures to specify sparse continuous normalizing flows (CNFs) for amortized inference. We find that the sparsity of this factorization can be exploited to reduce the numbers of parameters in the neural network, adaptive integration steps of the flow, and consequently FLOPs at both training and inference time without decreasing performance in comparison to unconstrained flows. By expressing the structure inversion as a compilation pass in a probabilistic programming language, we are able to apply it in a novel way to models as complex as convolutional neural networks. Furthermore, we extend the training objective for CNFs in the context of inference amortization to the symmetric Kullback-Leibler divergence, and demonstrate its theoretical and practical advantages.",
        "bibtex": "@InProceedings{pmlr-v108-weilbach20a,\n  title = \t {Structured Conditional Continuous Normalizing Flows for Efficient Amortized Inference in Graphical Models},\n  author =       {Weilbach, Christian and Beronov, Boyan and Wood, Frank and Harvey, William},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4441--4451},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/weilbach20a/weilbach20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/weilbach20a.html},\n  abstract = \t {We exploit minimally faithful inversion of graphical model structures to specify sparse continuous normalizing flows (CNFs) for amortized inference. We find that the sparsity of this factorization can be exploited to reduce the numbers of parameters in the neural network, adaptive integration steps of the flow, and consequently FLOPs at both training and inference time without decreasing performance in comparison to unconstrained flows. By expressing the structure inversion as a compilation pass in a probabilistic programming language, we are able to apply it in a novel way to models as complex as convolutional neural networks. Furthermore, we extend the training objective for CNFs in the context of inference amortization to the symmetric Kullback-Leibler divergence, and demonstrate its theoretical and practical advantages.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/weilbach20a/weilbach20a.pdf",
        "supp": "",
        "pdf_size": 1739540,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16356306027081884981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "713a0a4b8a",
        "title": "Sublinear Optimal Policy Value Estimation in Contextual Bandits",
        "site": "https://proceedings.mlr.press/v108/kong20b.html",
        "author": "Weihao Kong; Emma Brunskill; Gregory Valiant",
        "abstract": "We study the problem of estimating the expected reward of the optimal policy in the stochastic disjoint linear bandit setting. We prove that for certain settings it is possible to obtain an accurate estimate of the optimal policy value even with a sublinear number of samples, where a linear set would be needed to reliably estimate the reward that can be obtained by any policy. We establish near matching information theoretic lower bounds, showing that our algorithm achieves near optimal estimation error. Finally, we demonstrate the effectiveness of our algorithm on joke recommendation and cancer inhibition dosage selection problems using real datasets.",
        "bibtex": "@InProceedings{pmlr-v108-kong20b,\n  title = \t {Sublinear Optimal Policy Value Estimation in Contextual Bandits},\n  author =       {Kong, Weihao and Brunskill, Emma and Valiant, Gregory},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4377--4387},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kong20b/kong20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kong20b.html},\n  abstract = \t {We study the problem of estimating the expected reward of the optimal policy in the stochastic disjoint linear bandit setting. We prove that for certain settings it is possible to obtain an accurate estimate of the optimal policy value even with a sublinear number of samples, where a linear set would be needed to reliably estimate the reward that can be obtained by any policy. We establish near matching information theoretic lower bounds, showing that our algorithm achieves near optimal estimation error. Finally, we demonstrate the effectiveness of our algorithm on joke recommendation and cancer inhibition dosage selection problems using real datasets. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/kong20b/kong20b.pdf",
        "supp": "",
        "pdf_size": 537125,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6265272749787694084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Washington; Stanford University; Stanford University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Washington;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.washington.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UW;Stanford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "19de403feb",
        "title": "Support recovery and sup-norm convergence rates for sparse pivotal estimation",
        "site": "https://proceedings.mlr.press/v108/massias20a.html",
        "author": "Mathurin Massias; Quentin Bertrand; Alexandre Gramfort; Joseph Salmon",
        "abstract": "In high dimensional sparse regression, pivotal estimators are estimators for which the optimal regularization parameter is independent of the noise level. The canonical pivotal estimator is the square-root Lasso, formulated along with its derivatives as a \u201cnon-smooth + non-smooth\u201d optimization problem. Modern techniques to solve these include smoothing the datafitting term, to benefit from fast efficient proximal algorithms. In this work we show minimax sup-norm convergence rates for non smoothed and smoothed, single task and multitask square-root Lasso-type estimators. Thanks to our theoretical analysis, we provide some guidelines on how to set the smoothing hyperparameter, and illustrate on synthetic data the interest of such guidelines.",
        "bibtex": "@InProceedings{pmlr-v108-massias20a,\n  title = \t {Support recovery and sup-norm convergence rates for sparse pivotal estimation},\n  author =       {Massias, Mathurin and Bertrand, Quentin and Gramfort, Alexandre and Salmon, Joseph},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2655--2665},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/massias20a/massias20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/massias20a.html},\n  abstract = \t {In high dimensional sparse regression, pivotal estimators are estimators for which the optimal regularization parameter is independent of the noise level. The canonical pivotal estimator is the square-root Lasso, formulated along with its derivatives as a \u201cnon-smooth + non-smooth\u201d optimization problem. Modern techniques to solve these include smoothing the datafitting term, to benefit from fast efficient proximal algorithms. In this work we show minimax sup-norm convergence rates for non smoothed and smoothed, single task and multitask square-root Lasso-type estimators. Thanks to our theoretical analysis, we provide some guidelines on how to set the smoothing hyperparameter, and illustrate on synthetic data the interest of such guidelines.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/massias20a/massias20a.pdf",
        "supp": "",
        "pdf_size": 876961,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10256544252045252325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, France; Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, France; Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, France; IMAG, Univ. Montpellier, CNRS, Montpellier, France",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Universit\u00e9 Paris-Saclay;University of Montpellier",
        "aff_unique_dep": ";IMAG",
        "aff_unique_url": "https://www.universite-paris-saclay.fr;https://www.univ-montp.fr",
        "aff_unique_abbr": "UPS;Univ. Montpellier",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Palaiseau;Montpellier",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "0d5fb0b6e1",
        "title": "Taxonomy of Dual Block-Coordinate Ascent Methods for Discrete Energy Minimization",
        "site": "https://proceedings.mlr.press/v108/tourani20a.html",
        "author": "Siddharth Tourani; Alexander Shekhovtsov; Carsten Rother; Bogdan Savchynskyy",
        "abstract": "We consider the maximum-a-posteriori inference problem in discrete graphical models and study solvers based on the dual block-coordinate ascent rule. We map all existing solvers in a single framework, allowing for a better understanding of their design principles. We theoretically show that some block-optimizing updates are sub-optimal and how to strictly improve them. On a wide range of problem instances of varying graph connectivity, we study the performance of existingsolvers as well as new variants that can be obtained within the framework. As a result of this exploration we build a new state-of-the art solver, performing uniformly better on the whole range of test instances.",
        "bibtex": "@InProceedings{pmlr-v108-tourani20a,\n  title = \t {Taxonomy of Dual Block-Coordinate Ascent Methods for Discrete Energy Minimization},\n  author =       {Tourani, Siddharth and Shekhovtsov, Alexander and Rother, Carsten and Savchynskyy, Bogdan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2775--2785},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tourani20a/tourani20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tourani20a.html},\n  abstract = \t {We consider the maximum-a-posteriori inference problem in discrete graphical models and study solvers based on the dual block-coordinate ascent rule. We map all existing solvers in a single framework, allowing for a better understanding of their design principles. We theoretically show that some block-optimizing updates are sub-optimal and how to strictly improve them. On a wide range of problem instances of varying graph connectivity, we study the performance of existingsolvers as well as new variants that can be obtained within the framework. As a result of this exploration we build a new state-of-the art solver, performing uniformly better on the whole range of test instances.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tourani20a/tourani20a.pdf",
        "supp": "",
        "pdf_size": 1051773,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7415026927720032701&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9679306725",
        "title": "Tensorized Random Projections",
        "site": "https://proceedings.mlr.press/v108/rakhshan20a.html",
        "author": "Beheshteh Rakhshan; Guillaume Rabusseau",
        "abstract": "We introduce a novel random projection technique for efficiently reducing the dimension of very high-dimensional tensors. Building upon classical results on Gaussian random projections and Johnson-Lindenstrauss transforms\u00a0(JLT), we propose two tensorized random projection maps relying on the tensor train\u00a0(TT) and CP decomposition format, respectively. The two maps offer  very low  memory requirements and can be applied efficiently when the inputs are low rank tensors given in the CP or TT format.Our theoretical analysis shows that the dense Gaussian matrix in JLT can be replaced by a low-rank tensor implicitly represented in compressed form with random factors, while still approximately preserving the Euclidean distance of the projected inputs. In addition, our results reveal that the TT format is substantially superior to CP in terms of the size of the random projection needed to achieve the same distortion ratio. Experiments on synthetic data validate our theoretical analysis and demonstrate the superiority of the TT decomposition.",
        "bibtex": "@InProceedings{pmlr-v108-rakhshan20a,\n  title = \t {Tensorized Random Projections},\n  author =       {Rakhshan, Beheshteh and Rabusseau, Guillaume},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3306--3316},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/rakhshan20a/rakhshan20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/rakhshan20a.html},\n  abstract = \t {We introduce a novel random projection technique for efficiently reducing the dimension of very high-dimensional tensors. Building upon classical results on Gaussian random projections and Johnson-Lindenstrauss transforms\u00a0(JLT), we propose two tensorized random projection maps relying on the tensor train\u00a0(TT) and CP decomposition format, respectively. The two maps offer  very low  memory requirements and can be applied efficiently when the inputs are low rank tensors given in the CP or TT format.Our theoretical analysis shows that the dense Gaussian matrix in JLT can be replaced by a low-rank tensor implicitly represented in compressed form with random factors, while still approximately preserving the Euclidean distance of the projected inputs. In addition, our results reveal that the TT format is substantially superior to CP in terms of the size of the random projection needed to achieve the same distortion ratio. Experiments on synthetic data validate our theoretical analysis and demonstrate the superiority of the TT decomposition.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/rakhshan20a/rakhshan20a.pdf",
        "supp": "",
        "pdf_size": 537921,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8113195653747674300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mathematics, Purdue University; DIRO and Mila, Universit\u00e9 de Montr\u00e9al",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Purdue University;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": "Department of Mathematics;DIRO and Mila",
        "aff_unique_url": "https://www.purdue.edu;https://www.umontreal.ca",
        "aff_unique_abbr": "Purdue;UdeM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Montr\u00e9al",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "d62f0558f3",
        "title": "The Area of the Convex Hull of Sampled Curves: a Robust Functional Statistical Depth measure",
        "site": "https://proceedings.mlr.press/v108/staerman20a.html",
        "author": "Guillaume Staerman; Pavlo Mozharovskyi; St\u00e9phan Cl\u00e9men\\con",
        "abstract": "With the ubiquity of sensors in the IoT era, statistical observations are becoming increasingly available in the form of massive (multivariate) time-series. Formulated as unsupervised anomaly detection tasks, an abundance of applications like aviation safety management, the health monitoring of complex infrastructures or fraud detection can now rely on such functional data, acquired and stored with an ever finer granularity. The concept of \\textit{statistical depth}, which reflects centrality of an arbitrary observation w.r.t. a statistical population may play a crucial role in this regard, anomalies corresponding to observations with \u2019small\u2019 depth. Supported by sound theoretical and computational developments in the recent decades, it has proven to be extremely useful, in particular in functional spaces. However, most approaches documented in the literature consist in evaluating independently the centrality of each point forming the time series and consequently exhibit a certain insensitivity to possible shape changes.In this paper, we propose a novel notion of functional depth based on the area of the convex hull of sampled curves, capturing gradual departures from centrality, even beyond the envelope of the data, in a natural fashion.We discuss practical relevance of commonly imposed axioms on functional depths and investigate which of them are satisfied by the notion of depth we promote here. Estimation and computational issues are also adressed and various numerical experiments provide empirical evidence of the relevance of the approach proposed.",
        "bibtex": "@InProceedings{pmlr-v108-staerman20a,\n  title = \t {The Area of the Convex Hull of Sampled Curves: a Robust Functional Statistical Depth measure},\n  author =       {Staerman, Guillaume and Mozharovskyi, Pavlo and Cl\\'emen{\\c}on, St\\'ephan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {570--579},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/staerman20a/staerman20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/staerman20a.html},\n  abstract = \t {With the ubiquity of sensors in the IoT era, statistical observations are becoming increasingly available in the form of massive (multivariate) time-series. Formulated as unsupervised anomaly detection tasks, an abundance of applications like aviation safety management, the health monitoring of complex infrastructures or fraud detection can now rely on such functional data, acquired and stored with an ever finer granularity. The concept of \\textit{statistical depth}, which reflects centrality of an arbitrary observation w.r.t. a statistical population may play a crucial role in this regard, anomalies corresponding to observations with \u2019small\u2019 depth. Supported by sound theoretical and computational developments in the recent decades, it has proven to be extremely useful, in particular in functional spaces. However, most approaches documented in the literature consist in evaluating independently the centrality of each point forming the time series and consequently exhibit a certain insensitivity to possible shape changes.In this paper, we propose a novel notion of functional depth based on the area of the convex hull of sampled curves, capturing gradual departures from centrality, even beyond the envelope of the data, in a natural fashion.We discuss practical relevance of commonly imposed axioms on functional depths and investigate which of them are satisfied by the notion of depth we promote here. Estimation and computational issues are also adressed and various numerical experiments provide empirical evidence of the relevance of the approach proposed.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/staerman20a/staerman20a.pdf",
        "supp": "",
        "pdf_size": 2606229,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11629305265385585255&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7bd57f5377",
        "title": "The Expressive Power of a Class of Normalizing Flow Models",
        "site": "https://proceedings.mlr.press/v108/kong20a.html",
        "author": "Zhifeng Kong; Kamalika Chaudhuri",
        "abstract": "Normalizing flows have received a great deal of recent attention as they allow flexible generative modeling as well as easy likelihood computation. While a wide variety of flow models have been proposed, there is little formal understanding of the representation power of these models. In this work, we study some basic normalizing flows and rigorously establish bounds on their expressive power. Our results indicate that while these flows are highly expressive in one dimension, in higher dimensions their representation power may be limited, especially when the flows have moderate depth.",
        "bibtex": "@InProceedings{pmlr-v108-kong20a,\n  title = \t {The Expressive Power of a Class of Normalizing Flow Models},\n  author =       {Kong, Zhifeng and Chaudhuri, Kamalika},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3599--3609},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kong20a/kong20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kong20a.html},\n  abstract = \t {Normalizing flows have received a great deal of recent attention as they allow flexible generative modeling as well as easy likelihood computation. While a wide variety of flow models have been proposed, there is little formal understanding of the representation power of these models. In this work, we study some basic normalizing flows and rigorously establish bounds on their expressive power. Our results indicate that while these flows are highly expressive in one dimension, in higher dimensions their representation power may be limited, especially when the flows have moderate depth. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/kong20a/kong20a.pdf",
        "supp": "",
        "pdf_size": 426640,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2571063063564643178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of California San Diego; University of California San Diego",
        "aff_domain": "eng.ucsd.edu;cs.ucsd.edu",
        "email": "eng.ucsd.edu;cs.ucsd.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0ddcb6e870",
        "title": "The Fast Loaded Dice Roller: A Near-Optimal Exact Sampler for Discrete Probability Distributions",
        "site": "https://proceedings.mlr.press/v108/saad20a.html",
        "author": "Feras Saad; Cameron Freer; Martin Rinard; Vikash Mansinghka",
        "abstract": "This paper introduces a new algorithm for the fundamental problem of generating a random integer from a discrete probability distribution using a source of independent and unbiased random coin flips.  We prove that this algorithm, which we call the Fast Loaded Dice Roller (FLDR), is highly efficient in both space and time: (i) the size of the sampler is guaranteed to be linear in the number of bits needed to encode the input distribution; and (ii) the expected number of bits of entropy it consumes per sample is at most 6 bits more than the information-theoretically optimal rate.  We present fast implementations of the linear-time preprocessing and near-optimal sampling algorithms using unsigned integer arithmetic.  Empirical evaluations on a broad set of probability distributions establish that FLDR is 2x-10x faster in both preprocessing and sampling than multiple baseline algorithms, including the widely-used alias and interval samplers.  It also uses up to 10000x less space than the information-theoretically optimal sampler, at the expense of less than 1.5x runtime overhead.",
        "bibtex": "@InProceedings{pmlr-v108-saad20a,\n  title = \t {The Fast Loaded Dice Roller: A Near-Optimal Exact Sampler for Discrete Probability Distributions},\n  author =       {Saad, Feras and Freer, Cameron and Rinard, Martin and Mansinghka, Vikash},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1036--1046},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/saad20a/saad20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/saad20a.html},\n  abstract = \t {This paper introduces a new algorithm for the fundamental problem of generating a random integer from a discrete probability distribution using a source of independent and unbiased random coin flips.  We prove that this algorithm, which we call the Fast Loaded Dice Roller (FLDR), is highly efficient in both space and time: (i) the size of the sampler is guaranteed to be linear in the number of bits needed to encode the input distribution; and (ii) the expected number of bits of entropy it consumes per sample is at most 6 bits more than the information-theoretically optimal rate.  We present fast implementations of the linear-time preprocessing and near-optimal sampling algorithms using unsigned integer arithmetic.  Empirical evaluations on a broad set of probability distributions establish that FLDR is 2x-10x faster in both preprocessing and sampling than multiple baseline algorithms, including the widely-used alias and interval samplers.  It also uses up to 10000x less space than the information-theoretically optimal sampler, at the expense of less than 1.5x runtime overhead.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/saad20a/saad20a.pdf",
        "supp": "",
        "pdf_size": 1285651,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14059415248751320786&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cda3729933",
        "title": "The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits",
        "site": "https://proceedings.mlr.press/v108/chawla20a.html",
        "author": "Ronshee Chawla; Abishek Sankararaman; Ayalvadi Ganesh; Sanjay Shakkottai",
        "abstract": "We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup consisting of $N$ agents, solving the same MAB instance to minimize individual cumulative regret. In our model, agents collaborate by exchanging messages through pairwise gossip style communications. We develop two novel algorithms, where each agent only plays from a subset of all the arms. Agents use the communication medium to recommend only arm-IDs (not samples), and thus update the set of arms from which they play. We establish that, if agents communicate $\\Omega(\\log(T))$ times through any connected pairwise gossip mechanism, then every agent\u2019s regret is a factor of order $N$ smaller compared to the case of no collaborations.  Furthermore, we show that the communication constraints only have a second order effect on the regret of our algorithm. We then analyze this second order term of the regret to derive bounds on the regret-communication tradeoffs. Finally, we empirically evaluate our algorithm and conclude that the insights are fundamental and not artifacts of our bounds. We also show a lower bound which gives that the regret scaling obtained by our algorithm cannot be improved even in the absence of any communication constraints. Our results demonstrate that even a minimal level of collaboration among agents greatly reduces regret for all agents.",
        "bibtex": "@InProceedings{pmlr-v108-chawla20a,\n  title = \t {The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits},\n  author =       {Chawla, Ronshee and Sankararaman, Abishek and Ganesh, Ayalvadi and Shakkottai, Sanjay},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3471--3481},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/chawla20a/chawla20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/chawla20a.html},\n  abstract = \t {We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup consisting of $N$ agents, solving the same MAB instance to minimize individual cumulative regret. In our model, agents collaborate by exchanging messages through pairwise gossip style communications. We develop two novel algorithms, where each agent only plays from a subset of all the arms. Agents use the communication medium to recommend only arm-IDs (not samples), and thus update the set of arms from which they play. We establish that, if agents communicate $\\Omega(\\log(T))$ times through any connected pairwise gossip mechanism, then every agent\u2019s regret is a factor of order $N$ smaller compared to the case of no collaborations.  Furthermore, we show that the communication constraints only have a second order effect on the regret of our algorithm. We then analyze this second order term of the regret to derive bounds on the regret-communication tradeoffs. Finally, we empirically evaluate our algorithm and conclude that the insights are fundamental and not artifacts of our bounds. We also show a lower bound which gives that the regret scaling obtained by our algorithm cannot be improved even in the absence of any communication constraints. Our results demonstrate that even a minimal level of collaboration among agents greatly reduces regret for all agents.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/chawla20a/chawla20a.pdf",
        "supp": "",
        "pdf_size": 1554396,
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=822400249239706504&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3b147b5a3c",
        "title": "The Implicit Regularization of Ordinary Least Squares Ensembles",
        "site": "https://proceedings.mlr.press/v108/lejeune20b.html",
        "author": "Daniel LeJeune; Hamid Javadi; Richard Baraniuk",
        "abstract": "Ensemble methods that average over a collection of independent predictors that are each limited to a subsampling of both the examples and features of the training data command a significant presence in machine learning, such as the ever-popular random forest, yet the nature of the subsampling effect, particularly of the features, is not well understood. We study the case of an ensemble of linear predictors, where each individual predictor is fit using ordinary least squares on a random submatrix of the data matrix. We show that, under standard Gaussianity assumptions, when the number of features selected for each predictor is optimally tuned, the asymptotic risk of a large ensemble is equal to the asymptotic ridge regression risk, which is known to be optimal among linear predictors in this setting. In addition to eliciting this implicit regularization that results from subsampling, we also connect this ensemble to the dropout technique used in training deep (neural) networks, another strategy that has been shown to have a ridge-like regularizing effect.",
        "bibtex": "@InProceedings{pmlr-v108-lejeune20b,\n  title = \t {The Implicit Regularization of Ordinary Least Squares Ensembles},\n  author =       {LeJeune, Daniel and Javadi, Hamid and Baraniuk, Richard},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3525--3535},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lejeune20b/lejeune20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lejeune20b.html},\n  abstract = \t {Ensemble methods that average over a collection of independent predictors that are each limited to a subsampling of both the examples and features of the training data command a significant presence in machine learning, such as the ever-popular random forest, yet the nature of the subsampling effect, particularly of the features, is not well understood. We study the case of an ensemble of linear predictors, where each individual predictor is fit using ordinary least squares on a random submatrix of the data matrix. We show that, under standard Gaussianity assumptions, when the number of features selected for each predictor is optimally tuned, the asymptotic risk of a large ensemble is equal to the asymptotic ridge regression risk, which is known to be optimal among linear predictors in this setting. In addition to eliciting this implicit regularization that results from subsampling, we also connect this ensemble to the dropout technique used in training deep (neural) networks, another strategy that has been shown to have a ridge-like regularizing effect.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lejeune20b/lejeune20b.pdf",
        "supp": "",
        "pdf_size": 660896,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1324564899458844154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8a0285b42c",
        "title": "The Power of Batching in Multiple Hypothesis Testing",
        "site": "https://proceedings.mlr.press/v108/zrnic20a.html",
        "author": "Tijana Zrnic; Daniel Jiang; Aaditya Ramdas; Michael Jordan",
        "abstract": "One important partition of algorithms for controlling the false discovery rate (FDR) in multiple testing is into offline and online algorithms. The first generally achieve significantly higher power of discovery, while the latter allow making decisions sequentially as well as adaptively formulating hypotheses based on past observations. Using existing methodology, it is unclear how one could trade off the benefits of these two broad families of algorithms, all the while preserving their formal FDR guarantees. To this end, we introduce Batch-BH and Batch-St-BH, algorithms for controlling the FDR when a possibly infinite sequence of batches of hypotheses is tested by repeated application of one of the most widely used offline algorithms, the Benjamini-Hochberg (BH) method or Storey\u2019s improvement of the BH method. We show that our algorithms interpolate between existing online and offline methodology, thus trading off the best of both worlds.",
        "bibtex": "@InProceedings{pmlr-v108-zrnic20a,\n  title = \t {The Power of Batching in Multiple Hypothesis Testing},\n  author =       {Zrnic, Tijana and Jiang, Daniel and Ramdas, Aaditya and Jordan, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3806--3815},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zrnic20a/zrnic20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zrnic20a.html},\n  abstract = \t {One important partition of algorithms for controlling the false discovery rate (FDR) in multiple testing is into offline and online algorithms. The first generally achieve significantly higher power of discovery, while the latter allow making decisions sequentially as well as adaptively formulating hypotheses based on past observations. Using existing methodology, it is unclear how one could trade off the benefits of these two broad families of algorithms, all the while preserving their formal FDR guarantees. To this end, we introduce Batch-BH and Batch-St-BH, algorithms for controlling the FDR when a possibly infinite sequence of batches of hypotheses is tested by repeated application of one of the most widely used offline algorithms, the Benjamini-Hochberg (BH) method or Storey\u2019s improvement of the BH method. We show that our algorithms interpolate between existing online and offline methodology, thus trading off the best of both worlds.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zrnic20a/zrnic20a.pdf",
        "supp": "",
        "pdf_size": 1591390,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11466201649019487526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e266bfce81",
        "title": "The Quantile Snapshot Scan: Comparing Quantiles of Spatial Data from Two Snapshots in Time",
        "site": "https://proceedings.mlr.press/v108/moore20a.html",
        "author": "Travis Moore; Wong Weng-Keen",
        "abstract": "We introduce the Quantile Snapshot Scan (Qsnap), a spatial scan algorithm which identifies spatial regions that differ the most between two snapshots in time. Qsnap is designed for spatial data with a numeric response and a vector of associated covariates for each spatial data point. Qsnap focuses on differences involving a specific quantile of the data distribution. A naive implementation of Qsnap is too computationally expensive for large datasets but our novel incremental update provides an order of magnitude speedup. We demonstrate Qsnap\u2019s effectiveness over an extensive set of experiments on simulated data. In addition, we apply Qsnap to two real-world problems: discovering bird migration paths and identifying regions with dramatic changes in drought conditions.",
        "bibtex": "@InProceedings{pmlr-v108-moore20a,\n  title = \t {The Quantile Snapshot Scan: Comparing Quantiles of Spatial Data from Two Snapshots in Time},\n  author =       {Moore, Travis and Weng-Keen, Wong},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2677--2686},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/moore20a/moore20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/moore20a.html},\n  abstract = \t {We introduce the Quantile Snapshot Scan (Qsnap), a spatial scan algorithm which identifies spatial regions that differ the most between two snapshots in time. Qsnap is designed for spatial data with a numeric response and a vector of associated covariates for each spatial data point. Qsnap focuses on differences involving a specific quantile of the data distribution. A naive implementation of Qsnap is too computationally expensive for large datasets but our novel incremental update provides an order of magnitude speedup. We demonstrate Qsnap\u2019s effectiveness over an extensive set of experiments on simulated data. In addition, we apply Qsnap to two real-world problems: discovering bird migration paths and identifying regions with dramatic changes in drought conditions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/moore20a/moore20a.pdf",
        "supp": "",
        "pdf_size": 1184749,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3932461848910813500&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of EECS, Oregon State University; School of EECS, Oregon State University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://eecs.oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "326f4c874c",
        "title": "The Sylvester Graphical Lasso (SyGlasso)",
        "site": "https://proceedings.mlr.press/v108/wang20d.html",
        "author": "Yu Wang; Byoungwook Jang; Alfred Hero",
        "abstract": "This paper introduces the Sylvester graphical lasso (SyGlasso) that captures multiway dependencies present in tensor-valued data. The model is based on the Sylvester equation that defines a generative model. The proposed model complements the tensor graphical lasso (Greenewald et al., 2019) that imposes a Kronecker sum model for the inverse covariance matrix, by providing an alternative Kronecker sum model that is generative and interpretable. A nodewise regression approach is adopted for estimating the conditional independence relationships among variables. The statistical convergence of the method is established, and empirical studies are provided to demonstrate the recovery of meaningful conditional dependency graphs. We apply the SyGlasso to an electroencephalography (EEG) study to compare the brain connectivity of alcoholic and nonalcoholic subjects. We demonstrate that our model can simultaneously estimate both the brain connectivity and its temporal dependencies.",
        "bibtex": "@InProceedings{pmlr-v108-wang20d,\n  title = \t {The Sylvester Graphical Lasso (SyGlasso)},\n  author =       {Wang, Yu and Jang, Byoungwook and Hero, Alfred},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1943--1953},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20d/wang20d.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20d.html},\n  abstract = \t {This paper introduces the Sylvester graphical lasso (SyGlasso) that captures multiway dependencies present in tensor-valued data. The model is based on the Sylvester equation that defines a generative model. The proposed model complements the tensor graphical lasso (Greenewald et al., 2019) that imposes a Kronecker sum model for the inverse covariance matrix, by providing an alternative Kronecker sum model that is generative and interpretable. A nodewise regression approach is adopted for estimating the conditional independence relationships among variables. The statistical convergence of the method is established, and empirical studies are provided to demonstrate the recovery of meaningful conditional dependency graphs. We apply the SyGlasso to an electroencephalography (EEG) study to compare the brain connectivity of alcoholic and nonalcoholic subjects. We demonstrate that our model can simultaneously estimate both the brain connectivity and its temporal dependencies.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20d/wang20d.pdf",
        "supp": "",
        "pdf_size": 1006823,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4538654747929419291&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "University of Michigan; University of Michigan; University of Michigan",
        "aff_domain": "umich.edu;umich.edu;umich.edu",
        "email": "umich.edu;umich.edu;umich.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "60e09e37ed",
        "title": "The True Sample Complexity of Identifying Good Arms",
        "site": "https://proceedings.mlr.press/v108/katz-samuels20a.html",
        "author": "Julian Katz-Samuels; Kevin Jamieson",
        "abstract": "We consider two multi-armed bandit problems with $n$ arms: \\emph{(i)} given an $\\epsilon > 0$, identify an arm with mean that is within $\\epsilon$ of the largest mean and \\emph{(ii)} given a threshold $\\mu_0$ and integer $k$, identify $k$ arms with means larger than $\\mu_0$. Existing lower bounds and algorithms for the PAC framework suggest that both of these problems require $\\Omega(n)$ samples. However, we argue that the PAC framework not only conflicts with how these algorithms are used in practice, but also that these results disagree with intuition that says \\emph{(i)} requires only $\\Theta(\\frac{n}{m})$ samples where $m =  |\\{ i : \\mu_i > \\max_{j \\in [n]} \\mu_j - \\epsilon\\}|$ and \\emph{(ii)} requires $\\Theta(\\frac{n}{m}k)$ samples where $m =  |\\{ i : \\mu_i >  \\mu_0 \\}|$. We provide definitions that formalize these intuitions, obtain lower bounds that match the above sample complexities, and develop explicit, practical algorithms that achieve nearly matching upper bounds.",
        "bibtex": "@InProceedings{pmlr-v108-katz-samuels20a,\n  title = \t {The True Sample Complexity of Identifying Good Arms},\n  author =       {Katz-Samuels, Julian and Jamieson, Kevin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1781--1791},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/katz-samuels20a/katz-samuels20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/katz-samuels20a.html},\n  abstract = \t {We consider two multi-armed bandit problems with $n$ arms: \\emph{(i)} given an $\\epsilon > 0$, identify an arm with mean that is within $\\epsilon$ of the largest mean and \\emph{(ii)} given a threshold $\\mu_0$ and integer $k$, identify $k$ arms with means larger than $\\mu_0$. Existing lower bounds and algorithms for the PAC framework suggest that both of these problems require $\\Omega(n)$ samples. However, we argue that the PAC framework not only conflicts with how these algorithms are used in practice, but also that these results disagree with intuition that says \\emph{(i)} requires only $\\Theta(\\frac{n}{m})$ samples where $m =  |\\{ i : \\mu_i > \\max_{j \\in [n]} \\mu_j - \\epsilon\\}|$ and \\emph{(ii)} requires $\\Theta(\\frac{n}{m}k)$ samples where $m =  |\\{ i : \\mu_i >  \\mu_0 \\}|$. We provide definitions that formalize these intuitions, obtain lower bounds that match the above sample complexities, and develop explicit, practical algorithms that achieve nearly matching upper bounds.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/katz-samuels20a/katz-samuels20a.pdf",
        "supp": "",
        "pdf_size": 819664,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13827500462878931939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Washington; University of Washington",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "73a2e80235",
        "title": "Thompson Sampling for Linearly Constrained Bandits",
        "site": "https://proceedings.mlr.press/v108/saxena20a.html",
        "author": "Vidit Saxena; Joakim Jalden; Joseph Gonzalez",
        "abstract": "We address multi-armed bandits (MAB) where the objective is to maximize the cumulative reward under a probabilistic linear constraint. For a few real-world instances of this problem, constrained extensions of the well-known Thompson Sampling (TS) heuristic have recently been proposed. However, finite-time analysis of constrained TS is challenging; as a result, only O( sqrt( T ) ) bounds on the cumulative reward loss (i.e., the regret) are available. In this paper, we describe LinConTS, a TS-based algorithm for bandits that place a linear constraint on the probability of earning a reward in every round. We show that for LinConTS, the regret as well as the cumulative constraint violations are upper bounded by O( log ( T ) ). We develop a proof technique that relies on careful analysis of the dual problem and combine it with recent theoretical work on unconstrained TS. Through numerical experiments on two real-world datasets, we demonstrate that LinConTS outperforms an asymptotically optimal upper confidence bound (UCB) scheme in terms of simultaneously minimizing the regret and the violation.",
        "bibtex": "@InProceedings{pmlr-v108-saxena20a,\n  title = \t {Thompson Sampling for Linearly Constrained Bandits},\n  author =       {Saxena, Vidit and Jalden, Joakim and Gonzalez, Joseph},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1999--2009},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/saxena20a/saxena20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/saxena20a.html},\n  abstract = \t {We address multi-armed bandits (MAB) where the objective is to maximize the cumulative reward under a probabilistic linear constraint. For a few real-world instances of this problem, constrained extensions of the well-known Thompson Sampling (TS) heuristic have recently been proposed. However, finite-time analysis of constrained TS is challenging; as a result, only O( sqrt( T ) ) bounds on the cumulative reward loss (i.e., the regret) are available. In this paper, we describe LinConTS, a TS-based algorithm for bandits that place a linear constraint on the probability of earning a reward in every round. We show that for LinConTS, the regret as well as the cumulative constraint violations are upper bounded by O( log ( T ) ). We develop a proof technique that relies on careful analysis of the dual problem and combine it with recent theoretical work on unconstrained TS. Through numerical experiments on two real-world datasets, we demonstrate that LinConTS outperforms an asymptotically optimal upper confidence bound (UCB) scheme in terms of simultaneously minimizing the regret and the violation.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/saxena20a/saxena20a.pdf",
        "supp": "",
        "pdf_size": 611934,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5695592190345931082&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "KTH Royal Institute of Technology; University of California; KTH Royal Institute of Technology",
        "aff_domain": "kth.se;berkeley.edu;kth.se",
        "email": "kth.se;berkeley.edu;kth.se",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;University of California",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kth.se;https://www.universityofcalifornia.edu",
        "aff_unique_abbr": "KTH;UC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "ed88a1fedf",
        "title": "Thresholding Bandit Problem with Both Duels and Pulls",
        "site": "https://proceedings.mlr.press/v108/xu20c.html",
        "author": "Yichong Xu; Xi Chen; Aarti Singh; Artur Dubrawski",
        "abstract": "The Thresholding Bandit Problem (TBP) aims to find the set of arms with mean rewards greater than a given threshold. We consider a new setting of TBP, where in addition to pulling arms, one can also duel two arms and get the arm with a greater mean. In our motivating application from crowdsourcing,  dueling two arms can be more cost-effective and time-efficient than direct pulls. We refer to this problem as TBP with Dueling Choices (TBP-DC). This paper provides an algorithm called Rank-Search (RS) for solving TBP-DC by alternating between ranking and binary search. We prove theoretical guarantees for RS, and also give lower bounds to show the optimality of it. Experiments show that RS outperforms previous baseline algorithms that only use pulls or duels.",
        "bibtex": "@InProceedings{pmlr-v108-xu20c,\n  title = \t {Thresholding Bandit Problem with Both Duels and Pulls},\n  author =       {Xu, Yichong and Chen, Xi and Singh, Aarti and Dubrawski, Artur},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2591--2600},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/xu20c/xu20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/xu20c.html},\n  abstract = \t {The Thresholding Bandit Problem (TBP) aims to find the set of arms with mean rewards greater than a given threshold. We consider a new setting of TBP, where in addition to pulling arms, one can also duel two arms and get the arm with a greater mean. In our motivating application from crowdsourcing,  dueling two arms can be more cost-effective and time-efficient than direct pulls. We refer to this problem as TBP with Dueling Choices (TBP-DC). This paper provides an algorithm called Rank-Search (RS) for solving TBP-DC by alternating between ranking and binary search. We prove theoretical guarantees for RS, and also give lower bounds to show the optimality of it. Experiments show that RS outperforms previous baseline algorithms that only use pulls or duels.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/xu20c/xu20c.pdf",
        "supp": "",
        "pdf_size": 723358,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12762815408032868972&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f298c5da12",
        "title": "Thresholding Graph Bandits with GrAPL",
        "site": "https://proceedings.mlr.press/v108/lejeune20a.html",
        "author": "Daniel LeJeune; Gautam Dasarathy; Richard Baraniuk",
        "abstract": "In this paper, we introduce a new online decision making paradigm that we call Thresholding Graph Bandits. The main goal is to efficiently identify a subset of arms in a multi-armed bandit problem whose means are above a specified threshold. While traditionally in such problems, the arms are assumed to be independent, in our paradigm we further suppose that we have access to the similarity between the arms in the form of a graph, allowing us to gain information about the arm means with fewer samples. Such a feature is particularly relevant in modern decision making problems, where rapid decisions need to be made in spite of the large number of options available. We present GrAPL, a novel algorithm for the thresholding graph bandit problem. We demonstrate theoretically that this algorithm is effective in taking advantage of the graph structure when the structure is reflective of the distribution of the rewards. We confirm these theoretical findings via experiments on both synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v108-lejeune20a,\n  title = \t {Thresholding Graph Bandits with GrAPL},\n  author =       {LeJeune, Daniel and Dasarathy, Gautam and Baraniuk, Richard},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2476--2485},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/lejeune20a/lejeune20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/lejeune20a.html},\n  abstract = \t {In this paper, we introduce a new online decision making paradigm that we call Thresholding Graph Bandits. The main goal is to efficiently identify a subset of arms in a multi-armed bandit problem whose means are above a specified threshold. While traditionally in such problems, the arms are assumed to be independent, in our paradigm we further suppose that we have access to the similarity between the arms in the form of a graph, allowing us to gain information about the arm means with fewer samples. Such a feature is particularly relevant in modern decision making problems, where rapid decisions need to be made in spite of the large number of options available. We present GrAPL, a novel algorithm for the thresholding graph bandit problem. We demonstrate theoretically that this algorithm is effective in taking advantage of the graph structure when the structure is reflective of the distribution of the rewards. We confirm these theoretical findings via experiments on both synthetic and real data.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/lejeune20a/lejeune20a.pdf",
        "supp": "",
        "pdf_size": 1567226,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4480255031379174727&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b2289d6b47",
        "title": "Tight Analysis of Privacy and Utility Tradeoff in Approximate Differential Privacy",
        "site": "https://proceedings.mlr.press/v108/geng20a.html",
        "author": "Quan Geng; Wei Ding; Ruiqi Guo; Sanjiv Kumar",
        "abstract": "We characterize the minimum noise amplitude and power for noise-adding mechanisms in (epsilon, delta)-differential privacy for single real-valued query function. We derive new lower bounds using the duality of linear programming, and new upper bounds by analyzing a special class of (epsilon, delta)-differentially private mechanisms, the truncated Laplacian mechanisms. We show that the multiplicative gap of the lower bounds and upper bounds goes to zero in various high privacy regimes, proving the tightness of the lower and upper bounds. In particular, our results close the previous constant multiplicative gap in the discrete setting. Numeric experiments show the improvement of the truncated Laplacian mechanism over the optimal Gaussian mechanism in all privacy regimes.",
        "bibtex": "@InProceedings{pmlr-v108-geng20a,\n  title = \t {Tight Analysis of Privacy and Utility Tradeoff in Approximate Differential Privacy},\n  author =       {Geng, Quan and Ding, Wei and Guo, Ruiqi and Kumar, Sanjiv},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {89--99},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/geng20a/geng20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/geng20a.html},\n  abstract = \t {We characterize the minimum noise amplitude and power for noise-adding mechanisms in (epsilon, delta)-differential privacy for single real-valued query function. We derive new lower bounds using the duality of linear programming, and new upper bounds by analyzing a special class of (epsilon, delta)-differentially private mechanisms, the truncated Laplacian mechanisms. We show that the multiplicative gap of the lower bounds and upper bounds goes to zero in various high privacy regimes, proving the tightness of the lower and upper bounds. In particular, our results close the previous constant multiplicative gap in the discrete setting. Numeric experiments show the improvement of the truncated Laplacian mechanism over the optimal Gaussian mechanism in all privacy regimes.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/geng20a/geng20a.pdf",
        "supp": "",
        "pdf_size": 2351855,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8785839719320257830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7f61b5dfda",
        "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data",
        "site": "https://proceedings.mlr.press/v108/bayoumi20a.html",
        "author": "Ahmed Khaled; Konstantin Mishchenko; Peter Richtarik",
        "abstract": "We provide a new analysis of local SGD, removing unnecessary assumptions and elaborating on the difference between two data regimes: identical and heterogeneous. In both cases, we improve the existing theory and provide values of the optimal stepsize and optimal number of local iterations. Our bounds are based on a new notion of variance that is specific to local SGD methods with different data. The tightness of our results is guaranteed by recovering known statements when we plug $H=1$, where $H$ is the number of local steps. The empirical evidence further validates the severe impact of data  heterogeneity on the performance of local SGD.",
        "bibtex": "@InProceedings{pmlr-v108-bayoumi20a,\n  title = \t {Tighter Theory for Local SGD on Identical and Heterogeneous Data},\n  author =       {Khaled, Ahmed and Mishchenko, Konstantin and Richtarik, Peter},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4519--4529},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/bayoumi20a/bayoumi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/bayoumi20a.html},\n  abstract = \t {We provide a new analysis of local SGD, removing unnecessary assumptions and elaborating on the difference between two data regimes: identical and heterogeneous. In both cases, we improve the existing theory and provide values of the optimal stepsize and optimal number of local iterations. Our bounds are based on a new notion of variance that is specific to local SGD methods with different data. The tightness of our results is guaranteed by recovering known statements when we plug $H=1$, where $H$ is the number of local steps. The empirical evidence further validates the severe impact of data  heterogeneity on the performance of local SGD.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/bayoumi20a/bayoumi20a.pdf",
        "supp": "",
        "pdf_size": 4892013,
        "gs_citation": 539,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15523964477358129260&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Cairo University; KAUST+KAUST; KAUST",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+1;1",
        "aff_unique_norm": "Cairo University;King Abdullah University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cu.edu.eg;https://www.kaust.edu.sa",
        "aff_unique_abbr": "CU;KAUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1+1;1",
        "aff_country_unique": "Egypt;Saudi Arabia"
    },
    {
        "id": "635e4b6829",
        "title": "Towards Competitive N-gram Smoothing",
        "site": "https://proceedings.mlr.press/v108/falahatgar20a.html",
        "author": "Moein Falahatgar; Mesrob Ohannessian; Alon Orlitsky; Venkatadheeraj Pichapati",
        "abstract": "N-gram models remain a fundamental component of language modeling. In data-scarce regimes, they are a strong alternative to neural models. Even when not used as-is, recent work shows they can regularize neural models. Despite this success, the effectiveness of one of the best N-gram smoothing methods, the one suggested by Kneser and Ney (1995), is not fully understood. In the hopes of explaining this performance, we study it through the lens of competitive distribution estimation: the ability to perform as well as an oracle aware of further structure in the data. We first establish basic competitive properties of Kneser-Ney smoothing. We then investigate the nature of its backoff mechanism and show that it emerges from first principles, rather than being an assumption of the model. We do this by generalizing the Good-Turing estimator to the contextual setting. This exploration leads us to a powerful generalization of Kneser-Ney, which we conjecture to have even stronger competitive properties. Empirically, it significantly improves performance on language modeling, even matching feed-forward neural models. To show that the mechanisms at play are not restricted to language modeling, we demonstrate similar gains on the task of predicting attack types in the Global Terrorism Database.",
        "bibtex": "@InProceedings{pmlr-v108-falahatgar20a,\n  title = \t {Towards Competitive N-gram Smoothing},\n  author =       {Falahatgar, Moein and Ohannessian, Mesrob and Orlitsky, Alon and Pichapati, Venkatadheeraj},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4206--4215},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/falahatgar20a/falahatgar20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/falahatgar20a.html},\n  abstract = \t {N-gram models remain a fundamental component of language modeling. In data-scarce regimes, they are a strong alternative to neural models. Even when not used as-is, recent work shows they can regularize neural models. Despite this success, the effectiveness of one of the best N-gram smoothing methods, the one suggested by Kneser and Ney (1995), is not fully understood. In the hopes of explaining this performance, we study it through the lens of competitive distribution estimation: the ability to perform as well as an oracle aware of further structure in the data. We first establish basic competitive properties of Kneser-Ney smoothing. We then investigate the nature of its backoff mechanism and show that it emerges from first principles, rather than being an assumption of the model. We do this by generalizing the Good-Turing estimator to the contextual setting. This exploration leads us to a powerful generalization of Kneser-Ney, which we conjecture to have even stronger competitive properties. Empirically, it significantly improves performance on language modeling, even matching feed-forward neural models. To show that the mechanisms at play are not restricted to language modeling, we demonstrate similar gains on the task of predicting attack types in the Global Terrorism Database.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/falahatgar20a/falahatgar20a.pdf",
        "supp": "",
        "pdf_size": 565528,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17912542948232434970&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "UC San Diego; University of Illinois at Chicago; UC San Diego; UC San Diego",
        "aff_domain": "ucsd.edu;uic.edu;ucsd.edu;ucsd.edu",
        "email": "ucsd.edu;uic.edu;ucsd.edu;ucsd.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, San Diego;University of Illinois at Chicago",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ucsd.edu;https://www.uic.edu",
        "aff_unique_abbr": "UCSD;UIC",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "San Diego;Chicago",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "33829a1974",
        "title": "Truly Batch Model-Free Inverse Reinforcement Learning about Multiple Intentions",
        "site": "https://proceedings.mlr.press/v108/ramponi20a.html",
        "author": "Giorgia Ramponi; Amarildo Likmeta; Alberto Maria Metelli; Andrea Tirinzoni; Marcello Restelli",
        "abstract": "We consider Inverse Reinforcement Learning (IRL) about multiple intentions, \\ie the problem of estimating the unknown reward functions optimized by a group of experts that demonstrate optimal behaviors. Most of the existing algorithms either require access to a model of the environment or need to repeatedly compute the optimal policies for the hypothesized rewards. However, these requirements are rarely met in real-world applications, in which interacting with the environment can be expensive or even dangerous. In this paper, we address the IRL about multiple intentions in a fully model-free and batch setting. We first cast the single IRL problem as a constrained likelihood maximization and then we use this formulation to cluster agents based on the likelihood of the assignment. In this way, we can efficiently solve, without interactions with the environment, both the IRL and the clustering problem. Finally, we evaluate the proposed methodology on simulated domains and on a real-world social-network application.",
        "bibtex": "@InProceedings{pmlr-v108-ramponi20a,\n  title = \t {Truly Batch Model-Free Inverse Reinforcement Learning about Multiple Intentions},\n  author =       {Ramponi, Giorgia and Likmeta, Amarildo and Metelli, Alberto Maria and Tirinzoni, Andrea and Restelli, Marcello},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2359--2369},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/ramponi20a/ramponi20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/ramponi20a.html},\n  abstract = \t {We consider Inverse Reinforcement Learning (IRL) about multiple intentions, \\ie the problem of estimating the unknown reward functions optimized by a group of experts that demonstrate optimal behaviors. Most of the existing algorithms either require access to a model of the environment or need to repeatedly compute the optimal policies for the hypothesized rewards. However, these requirements are rarely met in real-world applications, in which interacting with the environment can be expensive or even dangerous. In this paper, we address the IRL about multiple intentions in a fully model-free and batch setting. We first cast the single IRL problem as a constrained likelihood maximization and then we use this formulation to cluster agents based on the likelihood of the assignment. In this way, we can efficiently solve, without interactions with the environment, both the IRL and the clustering problem. Finally, we evaluate the proposed methodology on simulated domains and on a real-world social-network application.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/ramponi20a/ramponi20a.pdf",
        "supp": "",
        "pdf_size": 1371656,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=37829586470675737&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "aff": "Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy+Universit\u00e0 di Bologna, Bologna, Italy; Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;0;0",
        "aff_unique_norm": "Politecnico di Milano;Universit\u00e0 di Bologna",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.polimi.it;https://www.unibo.it",
        "aff_unique_abbr": "Polimi;UNIBO",
        "aff_campus_unique_index": "0;0+1;0;0;0",
        "aff_campus_unique": "Milan;Bologna",
        "aff_country_unique_index": "0;0+0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "fa7837b73f",
        "title": "Two-sample Testing Using Deep Learning",
        "site": "https://proceedings.mlr.press/v108/kirchler20a.html",
        "author": "Matthias Kirchler; Shahryar Khorasani; Marius Kloft; Christoph Lippert",
        "abstract": "We propose a two-sample testing procedure based on learned deep neural network representations. To this end, we define two test statistics that perform an asymptotic location test on data samples mapped onto a hidden layer. The tests are consistent and asymptotically control the type-1 error rate. Their test statistics can be evaluated in linear time (in the sample size). Suitable data representations are obtained in a data-driven way, by solving a supervised or unsupervised transfer-learning task on an auxiliary (potentially distinct) data set. If no auxiliary data is available, we split the data into two chunks: one for learning representations and one for computing the test statistic. In experiments on audio samples, natural images and three-dimensional neuroimaging data our tests yield significant decreases in type-2 error rate (up to 35 percentage points) compared to state-of-the-art two-sample tests such as kernel-methods and classifier two-sample tests.",
        "bibtex": "@InProceedings{pmlr-v108-kirchler20a,\n  title = \t {Two-sample Testing Using Deep Learning},\n  author =       {Kirchler, Matthias and Khorasani, Shahryar and Kloft, Marius and Lippert, Christoph},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1387--1398},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/kirchler20a/kirchler20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/kirchler20a.html},\n  abstract = \t {We propose a two-sample testing procedure based on learned deep neural network representations. To this end, we define two test statistics that perform an asymptotic location test on data samples mapped onto a hidden layer. The tests are consistent and asymptotically control the type-1 error rate. Their test statistics can be evaluated in linear time (in the sample size). Suitable data representations are obtained in a data-driven way, by solving a supervised or unsupervised transfer-learning task on an auxiliary (potentially distinct) data set. If no auxiliary data is available, we split the data into two chunks: one for learning representations and one for computing the test statistic. In experiments on audio samples, natural images and three-dimensional neuroimaging data our tests yield significant decreases in type-2 error rate (up to 35 percentage points) compared to state-of-the-art two-sample tests such as kernel-methods and classifier two-sample tests.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/kirchler20a/kirchler20a.pdf",
        "supp": "",
        "pdf_size": 2399521,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2518905219379925403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Hasso Plattner Institute for Digital Engineering, University of Potsdam, Germany+Technical University of Kaiserslautern, Germany; Hasso Plattner Institute for Digital Engineering, University of Potsdam, Germany; Technical University of Kaiserslautern, Germany+University of Southern California, Los Angeles, United States; Hasso Plattner Institute for Digital Engineering, University of Potsdam, Germany+Hasso Plattner Institute for Digital Health at Mount Sinai, New York, United States",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/mkirchler/deep-2-sample-test",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;1+2;0+3",
        "aff_unique_norm": "Hasso Plattner Institute for Digital Engineering;Technical University of Kaiserslautern;University of Southern California;Hasso Plattner Institute for Digital Health",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.hpi.de;https://www.tu-kl.de;https://www.usc.edu;",
        "aff_unique_abbr": "HPI;TUK;USC;",
        "aff_campus_unique_index": ";1;2",
        "aff_campus_unique": ";Los Angeles;Mount Sinai",
        "aff_country_unique_index": "0+0;0;0+1;0+1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "8d26b311d9",
        "title": "Uncertainty Quantification for Deep Context-Aware Mobile Activity Recognition and Unknown Context Discovery",
        "site": "https://proceedings.mlr.press/v108/huo20a.html",
        "author": "Zepeng Huo; Arash PakBin; Xiaohan Chen; Nathan Hurley; Ye Yuan; Xiaoning Qian; Zhangyang Wang; Shuai Huang; Bobak Mortazavi",
        "abstract": "Activity recognition in wearable computing faces two key challenges: i) activity characteristics may be context-dependent and change under different contexts or situations; ii) unknown contexts and activities may occur from time to time, requiring flexibility and adaptability of the algorithm. We develop a context-aware mixture of deep models termed the $\\alpha$-$\\beta$ network coupled with uncertainty quantification (UQ) based upon maximum entropy to enhance human activity recognition performance. We improve accuracy and F score by 10% by identifying high-level contexts in a data-driven way to guide model development. In order to ensure training stability, we have used a clustering-based pre-training in both public and in-house datasets, demonstrating improved accuracy through unknown context discovery.",
        "bibtex": "@InProceedings{pmlr-v108-huo20a,\n  title = \t {Uncertainty Quantification for Deep Context-Aware Mobile Activity Recognition and Unknown Context Discovery},\n  author =       {Huo, Zepeng and PakBin, Arash and Chen, Xiaohan and Hurley, Nathan and Yuan, Ye and Qian, Xiaoning and Wang, Zhangyang and Huang, Shuai and Mortazavi, Bobak},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3894--3904},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/huo20a/huo20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/huo20a.html},\n  abstract = \t {Activity recognition in wearable computing faces two key challenges: i) activity characteristics may be context-dependent and change under different contexts or situations; ii) unknown contexts and activities may occur from time to time, requiring flexibility and adaptability of the algorithm. We develop a context-aware mixture of deep models termed the $\\alpha$-$\\beta$ network coupled with uncertainty quantification (UQ) based upon maximum entropy to enhance human activity recognition performance. We improve accuracy and F score by 10% by identifying high-level contexts in a data-driven way to guide model development. In order to ensure training stability, we have used a clustering-based pre-training in both public and in-house datasets, demonstrating improved accuracy through unknown context discovery.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/huo20a/huo20a.pdf",
        "supp": "",
        "pdf_size": 931269,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9239703038911724821&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University; University of Washington; Texas A&M University",
        "aff_domain": ";;;;;;;;",
        "email": ";;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 9,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Texas A&M University;University of Washington",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tamu.edu;https://www.washington.edu",
        "aff_unique_abbr": "TAMU;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f121192877",
        "title": "Uncertainty Quantification for Sparse Deep Learning",
        "site": "https://proceedings.mlr.press/v108/wang20b.html",
        "author": "Yuexi Wang; Veronika Rockova",
        "abstract": "Deep learning methods continue to have a decided impact on machine learning, both in theory and in practice. Statistical theoretical developments have been mostly concerned with approximability or rates of estimation when recovering infinite dimensional objects (curves or densities). Despite the impressive array of available theoretical results, the literature has been largely silent about uncertainty quantification for deep learning. This paper takes a step forward in this important direction by taking a Bayesian point of view. We study Gaussian approximability of certain aspects of posterior distributions of sparse deep ReLU architectures in non-parametric regression. Building on tools from Bayesian non-parametrics, we provide semi-parametric Bernstein-von Mises theorems for linear and quadratic functionals, which guarantee that implied Bayesian credible regions have valid frequentist coverage. Our results provide new theoretical justifications for (Bayesian) deep learning with ReLU activation functions, highlighting their inferential potential.",
        "bibtex": "@InProceedings{pmlr-v108-wang20b,\n  title = \t {Uncertainty Quantification for Sparse Deep Learning},\n  author =       {Wang, Yuexi and Rockova, Veronika},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {298--308},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/wang20b/wang20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/wang20b.html},\n  abstract = \t {Deep learning methods continue to have a decided impact on machine learning, both in theory and in practice. Statistical theoretical developments have been mostly concerned with approximability or rates of estimation when recovering infinite dimensional objects (curves or densities). Despite the impressive array of available theoretical results, the literature has been largely silent about uncertainty quantification for deep learning. This paper takes a step forward in this important direction by taking a Bayesian point of view. We study Gaussian approximability of certain aspects of posterior distributions of sparse deep ReLU architectures in non-parametric regression. Building on tools from Bayesian non-parametrics, we provide semi-parametric Bernstein-von Mises theorems for linear and quadratic functionals, which guarantee that implied Bayesian credible regions have valid frequentist coverage. Our results provide new theoretical justifications for (Bayesian) deep learning with ReLU activation functions, highlighting their inferential potential.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/wang20b/wang20b.pdf",
        "supp": "",
        "pdf_size": 708349,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7371693108679027131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Booth School of Business, University of Chicago; Booth School of Business, University of Chicago",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "Booth School of Business",
        "aff_unique_url": "https://www.chicagobooth.edu",
        "aff_unique_abbr": "Chicago Booth",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1b03365f62",
        "title": "Uncertainty in Neural Networks: Approximately Bayesian Ensembling",
        "site": "https://proceedings.mlr.press/v108/pearce20a.html",
        "author": "Tim Pearce; Felix Leibfried; Alexandra Brintrup",
        "abstract": "Understanding the uncertainty of a neural network\u2019s (NN) predictions is essential for many purposes. The Bayesian framework provides a principled approach to this, however applying it to NNs is challenging due to large numbers of parameters and data. Ensembling NNs provides an easily implementable, scalable method for uncertainty quantification, however, it has been criticised for not being Bayesian. This work proposes one modification to the usual process that we argue does result in approximate Bayesian inference; regularising parameters about values drawn from a distribution which can be set equal to the prior. A theoretical analysis of the procedure in a simplified setting suggests the recovered posterior is centred correctly but tends to have an underestimated marginal variance, and overestimated correlation. However, two conditions can lead to exact recovery. We argue that these conditions are partially present in NNs.  Empirical evaluations demonstrate it has an advantage over standard ensembling, and is competitive with variational methods.",
        "bibtex": "@InProceedings{pmlr-v108-pearce20a,\n  title = \t {Uncertainty in Neural Networks: Approximately Bayesian Ensembling},\n  author =       {Pearce, Tim and Leibfried, Felix and Brintrup, Alexandra},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {234--244},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/pearce20a.html},\n  abstract = \t {Understanding the uncertainty of a neural network\u2019s (NN) predictions is essential for many purposes. The Bayesian framework provides a principled approach to this, however applying it to NNs is challenging due to large numbers of parameters and data. Ensembling NNs provides an easily implementable, scalable method for uncertainty quantification, however, it has been criticised for not being Bayesian. This work proposes one modification to the usual process that we argue does result in approximate Bayesian inference; regularising parameters about values drawn from a distribution which can be set equal to the prior. A theoretical analysis of the procedure in a simplified setting suggests the recovered posterior is centred correctly but tends to have an underestimated marginal variance, and overestimated correlation. However, two conditions can lead to exact recovery. We argue that these conditions are partially present in NNs.  Empirical evaluations demonstrate it has an advantage over standard ensembling, and is competitive with variational methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf",
        "supp": "",
        "pdf_size": 3212401,
        "gs_citation": 281,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5227423193819611600&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "teapearce.github.io",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1dfe87176c",
        "title": "Unconditional Coresets for Regularized Loss Minimization",
        "site": "https://proceedings.mlr.press/v108/samadian20a.html",
        "author": "Alireza Samadian; Kirk Pruhs; Benjamin Moseley; Sungjin Im; Ryan Curtin",
        "abstract": "We design and mathematically analyze sampling-based algorithms for regularized loss minimization problems that are implementable in popular computational models for large data, in which the access to the data is restricted in some way. Our main result is that if the regularizer\u2019s effect does not become negligible as the norm of the hypothesis scales, and as the data scales, then a uniform sample of modest size is with high probability a coreset. In the case that the loss function is either logistic regression or soft-margin support vector machines, and the regularizer is one of the common recommended choices, this result implies that a uniform sample of size $O(d \\sqrt{n})$ is with high probability a coreset of $n$ points in $\\Re^d$. We contrast this upper bound with two lower bounds. The first lower bound shows that our analysis of uniform sampling is tight; that is,  a smaller uniform sample will likely not be a core set. The second lower bound shows that in some sense uniform sampling is close to optimal, as significantly smaller core sets do not generally exist.",
        "bibtex": "@InProceedings{pmlr-v108-samadian20a,\n  title = \t {Unconditional Coresets for Regularized Loss Minimization},\n  author =       {Samadian, Alireza and Pruhs, Kirk and Moseley, Benjamin and Im, Sungjin and Curtin, Ryan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {482--492},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/samadian20a/samadian20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/samadian20a.html},\n  abstract = \t {We design and mathematically analyze sampling-based algorithms for regularized loss minimization problems that are implementable in popular computational models for large data, in which the access to the data is restricted in some way. Our main result is that if the regularizer\u2019s effect does not become negligible as the norm of the hypothesis scales, and as the data scales, then a uniform sample of modest size is with high probability a coreset. In the case that the loss function is either logistic regression or soft-margin support vector machines, and the regularizer is one of the common recommended choices, this result implies that a uniform sample of size $O(d \\sqrt{n})$ is with high probability a coreset of $n$ points in $\\Re^d$. We contrast this upper bound with two lower bounds. The first lower bound shows that our analysis of uniform sampling is tight; that is,  a smaller uniform sample will likely not be a core set. The second lower bound shows that in some sense uniform sampling is close to optimal, as significantly smaller core sets do not generally exist.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/samadian20a/samadian20a.pdf",
        "supp": "",
        "pdf_size": 407660,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1419704789008378564&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "RelationalAI; University of California Merced; Carnegie Mellon University; University of Pittsburgh; University of Pittsburgh",
        "aff_domain": "ratml.org;ucmerced.edu;andrew.cmu.edu;cs.pitt.edu;cs.pitt.edu",
        "email": "ratml.org;ucmerced.edu;andrew.cmu.edu;cs.pitt.edu;cs.pitt.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;3",
        "aff_unique_norm": "RelationalAI;University of California, Merced;Carnegie Mellon University;University of Pittsburgh",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.relationalai.com;https://www.ucmerced.edu;https://www.cmu.edu;https://www.pitt.edu",
        "aff_unique_abbr": "RelationalAI;UC Merced;CMU;Pitt",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Merced",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "22c5ea159e",
        "title": "Understanding Generalization in Deep Learning via Tensor Methods",
        "site": "https://proceedings.mlr.press/v108/li20c.html",
        "author": "Jingling Li; Yanchao Sun; Jiahao Su; Taiji Suzuki; Furong Huang",
        "abstract": "Deep neural networks generalize well on unseen data though the number of parameters often far exceeds the number of training examples. Recently proposed complexity measures have provided insights to understanding the generalizability in neural networks from perspectives of PAC-Bayes, robustness, overparametrization, compression and so on. In this work, we advance the understanding of the relations between the network\u2019s architecture and its generalizability from the compression perspective. Using tensor analysis, we propose a series of intuitive, data-dependent and easily-measurable properties that tightly characterize the compressibility and generalizability of neural networks; thus, in practice, our generalization bound outperforms the previous compression-based ones, especially for neural networks using tensors as their weight kernels (e.g. CNNs). Moreover, these intuitive measurements provide further insights into designing neural network architectures with properties favorable for better/guaranteed generalizability. Our experimental results demonstrate that through the proposed measurable properties, our generalization error bound matches the trend of the test error well. Our theoretical analysis further provides justifications for the empirical success and limitations of some widely-used tensor-based compression approaches. We also discover the improvements to the compressibility and robustness of current neural networks when incorporating tensor operations via our proposed layer-wise structure.",
        "bibtex": "@InProceedings{pmlr-v108-li20c,\n  title = \t {Understanding Generalization in Deep Learning via Tensor Methods},\n  author =       {Li, Jingling and Sun, Yanchao and Su, Jiahao and Suzuki, Taiji and Huang, Furong},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {504--515},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/li20c/li20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/li20c.html},\n  abstract = \t {Deep neural networks generalize well on unseen data though the number of parameters often far exceeds the number of training examples. Recently proposed complexity measures have provided insights to understanding the generalizability in neural networks from perspectives of PAC-Bayes, robustness, overparametrization, compression and so on. In this work, we advance the understanding of the relations between the network\u2019s architecture and its generalizability from the compression perspective. Using tensor analysis, we propose a series of intuitive, data-dependent and easily-measurable properties that tightly characterize the compressibility and generalizability of neural networks; thus, in practice, our generalization bound outperforms the previous compression-based ones, especially for neural networks using tensors as their weight kernels (e.g. CNNs). Moreover, these intuitive measurements provide further insights into designing neural network architectures with properties favorable for better/guaranteed generalizability. Our experimental results demonstrate that through the proposed measurable properties, our generalization error bound matches the trend of the test error well. Our theoretical analysis further provides justifications for the empirical success and limitations of some widely-used tensor-based compression approaches. We also discover the improvements to the compressibility and robustness of current neural networks when incorporating tensor operations via our proposed layer-wise structure.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/li20c/li20c.pdf",
        "supp": "",
        "pdf_size": 907947,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11595875798767963912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Maryland, College Park + Center for Advanced Intelligence Project, RIKEN; Department of Computer Science, University of Maryland, College Park; Department of Electrical and Computer Engineering, University of Maryland, College Park; Graduate School of Information Science and Technology, The University of Tokyo + Center for Advanced Intelligence Project, RIKEN; Department of Computer Science, University of Maryland, College Park",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;2+1;0",
        "aff_unique_norm": "University of Maryland, College Park;RIKEN;University of Tokyo",
        "aff_unique_dep": "Department of Computer Science;Center for Advanced Intelligence Project;Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www/umd.edu;https://www.riken.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UMD;RIKEN;UTokyo",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "College Park;;Tokyo",
        "aff_country_unique_index": "0+1;0;0;1+1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "7235654d53",
        "title": "Understanding the Effects of Batching in Online Active Learning",
        "site": "https://proceedings.mlr.press/v108/amin20a.html",
        "author": "Kareem Amin; Corinna Cortes; Giulia DeSalvo; Afshin Rostamizadeh",
        "abstract": "Online active learning (AL) algorithms often assume immediate access to a label once a query has been made. However, due to practical constraints, the labels of these queried examples are generally only available in \u201cbatches\u201d.  In this work, we present an analysis for a generic class of batch online AL algorithms, which reveals that the effects of batching are in fact mild and only result in an additional label complexity term that is quasilinear in the batch size. To our knowledge, this provides the first theoretical justification for such algorithms and we show how they can be applied to batch variants of three canonical online AL algorithms: IWAL, ORIWAL, and DHM. Finally, we also present empirical results across several benchmark datasets that corroborate these theoretical insights.",
        "bibtex": "@InProceedings{pmlr-v108-amin20a,\n  title = \t {Understanding the Effects of Batching in Online Active Learning},\n  author =       {Amin, Kareem and Cortes, Corinna and DeSalvo, Giulia and Rostamizadeh, Afshin},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3482--3492},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/amin20a/amin20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/amin20a.html},\n  abstract = \t {Online active learning (AL) algorithms often assume immediate access to a label once a query has been made. However, due to practical constraints, the labels of these queried examples are generally only available in \u201cbatches\u201d.  In this work, we present an analysis for a generic class of batch online AL algorithms, which reveals that the effects of batching are in fact mild and only result in an additional label complexity term that is quasilinear in the batch size. To our knowledge, this provides the first theoretical justification for such algorithms and we show how they can be applied to batch variants of three canonical online AL algorithms: IWAL, ORIWAL, and DHM. Finally, we also present empirical results across several benchmark datasets that corroborate these theoretical insights.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/amin20a/amin20a.pdf",
        "supp": "",
        "pdf_size": 703803,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6133714029938972695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7c97c7aa0e",
        "title": "Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models",
        "site": "https://proceedings.mlr.press/v108/zhang20h.html",
        "author": "Xiao Zhang; Jinghui Chen; Quanquan Gu; David Evans",
        "abstract": "Starting with Gilmer et al. (2018), several works have demonstrated the inevitability of adversarial examples based on different assumptions about the underlying input probability space.  It remains unclear, however, whether these results apply to natural image distributions. In this work, we assume the underlying data distribution is captured by some conditional generative model, and prove intrinsic robustness bounds for a general class of classifiers, which solves an open problem in Fawzi et al. (2018). Building upon the state-of-the-art conditional generative models, we study the intrinsic robustness of two common image benchmarks under L2 perturbations, and show the existence of a large gap between the robustness limits implied by our theory and the adversarial robustness achieved by current state-of-the-art robust models.",
        "bibtex": "@InProceedings{pmlr-v108-zhang20h,\n  title = \t {Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models},\n  author =       {Zhang, Xiao and Chen, Jinghui and Gu, Quanquan and Evans, David},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3883--3893},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhang20h/zhang20h.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhang20h.html},\n  abstract = \t {Starting with Gilmer et al. (2018), several works have demonstrated the inevitability of adversarial examples based on different assumptions about the underlying input probability space.  It remains unclear, however, whether these results apply to natural image distributions. In this work, we assume the underlying data distribution is captured by some conditional generative model, and prove intrinsic robustness bounds for a general class of classifiers, which solves an open problem in Fawzi et al. (2018). Building upon the state-of-the-art conditional generative models, we study the intrinsic robustness of two common image benchmarks under L2 perturbations, and show the existence of a large gap between the robustness limits implied by our theory and the adversarial robustness achieved by current state-of-the-art robust models.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhang20h/zhang20h.pdf",
        "supp": "",
        "pdf_size": 998142,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=502034210024934146&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "646fab992a",
        "title": "Unsupervised Hierarchy Matching with Optimal Transport over Hyperbolic Spaces",
        "site": "https://proceedings.mlr.press/v108/alvarez-melis20a.html",
        "author": "David Alvarez-Melis; Youssef Mroueh; Tommi Jaakkola",
        "abstract": "This paper focuses on the problem of unsupervised alignment of hierarchical data such as ontologies or lexical databases. This problem arises across areas, from natural language processing to bioinformatics, and is typically solved by appeal to outside knowledge bases and label-textual similarity. In contrast, we approach the problem from a purely geometric perspective: given only a vector-space representation of the items in the two hierarchies, we seek to infer correspondences across them. Our work derives from and interweaves hyperbolic-space representations for hierarchical data, on one hand, and unsupervised word-alignment methods, on the other. We first provide a set of negative results showing how and why Euclidean methods fail in this hyperbolic setting. We then propose a novel approach based on optimal transport over hyperbolic spaces, and show that it outperforms standard embedding alignment techniques in various experiments on cross-lingual WordNet alignment and ontology matching tasks.",
        "bibtex": "@InProceedings{pmlr-v108-alvarez-melis20a,\n  title = \t {Unsupervised Hierarchy Matching with Optimal Transport over Hyperbolic Spaces},\n  author =       {Alvarez-Melis, David and Mroueh, Youssef and Jaakkola, Tommi},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1606--1617},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/alvarez-melis20a/alvarez-melis20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/alvarez-melis20a.html},\n  abstract = \t {This paper focuses on the problem of unsupervised alignment of hierarchical data such as ontologies or lexical databases. This problem arises across areas, from natural language processing to bioinformatics, and is typically solved by appeal to outside knowledge bases and label-textual similarity. In contrast, we approach the problem from a purely geometric perspective: given only a vector-space representation of the items in the two hierarchies, we seek to infer correspondences across them. Our work derives from and interweaves hyperbolic-space representations for hierarchical data, on one hand, and unsupervised word-alignment methods, on the other. We first provide a set of negative results showing how and why Euclidean methods fail in this hyperbolic setting. We then propose a novel approach based on optimal transport over hyperbolic spaces, and show that it outperforms standard embedding alignment techniques in various experiments on cross-lingual WordNet alignment and ontology matching tasks. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/alvarez-melis20a/alvarez-melis20a.pdf",
        "supp": "",
        "pdf_size": 1885674,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10762234255248227885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5155eb9f2a",
        "title": "Unsupervised Neural Universal Denoiser for Finite-Input General-Output Noisy Channel",
        "site": "https://proceedings.mlr.press/v108/park20a.html",
        "author": "Taeeon Park; Taesup Moon",
        "abstract": "We devise a novel neural network-based universal denoiser for the finite-input, general-output (FIGO) channel. Based on the assumption of known noisy channel densities, which is realistic in many practical scenarios, we train the network such that it can denoise as well as the best sliding window denoiser for any given underlying clean source data. Our algorithm, dubbed as Generalized CUDE (Gen-CUDE), enjoys several desirable properties; it can be trained in an unsupervised manner (solely based on the noisy observation data), has much smaller computational complexity compared to the previously developed universal denoiser for the same setting, and has much tighter upper bound on the denoising performance, which is obtained by a theoretical analysis. In our experiments, we show such tighter upper bound is also realized in practice by showing that Gen-CUDE achieves much better denoising results compared to other strong baselines for both synthetic and real underlying clean sequences.",
        "bibtex": "@InProceedings{pmlr-v108-park20a,\n  title = \t {Unsupervised Neural Universal Denoiser for Finite-Input General-Output Noisy Channel},\n  author =       {Park, Taeeon and Moon, Taesup},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {331--340},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/park20a/park20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/park20a.html},\n  abstract = \t {We devise a novel neural network-based universal denoiser for the finite-input, general-output (FIGO) channel. Based on the assumption of known noisy channel densities, which is realistic in many practical scenarios, we train the network such that it can denoise as well as the best sliding window denoiser for any given underlying clean source data. Our algorithm, dubbed as Generalized CUDE (Gen-CUDE), enjoys several desirable properties; it can be trained in an unsupervised manner (solely based on the noisy observation data), has much smaller computational complexity compared to the previously developed universal denoiser for the same setting, and has much tighter upper bound on the denoising performance, which is obtained by a theoretical analysis. In our experiments, we show such tighter upper bound is also realized in practice by showing that Gen-CUDE achieves much better denoising results compared to other strong baselines for both synthetic and real underlying clean sequences. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/park20a/park20a.pdf",
        "supp": "",
        "pdf_size": 1843406,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6354839044325109610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon, Korea 16419; Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon, Korea 16419",
        "aff_domain": "skku.edu;skku.edu",
        "email": "skku.edu;skku.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Sungkyunkwan University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.skku.edu",
        "aff_unique_abbr": "SKKU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Suwon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "6b9052a87c",
        "title": "Utility/Privacy Trade-off through the lens of Optimal Transport",
        "site": "https://proceedings.mlr.press/v108/boursier20a.html",
        "author": "Etienne Boursier; Vianney Perchet",
        "abstract": "Strategic information is valuable either by remaining private (for instance if it is sensitive) or, on the other hand, by being used publicly to increase some utility. These two objectives are antagonistic and leaking this information might be more rewarding than concealing it. Unlike classical solutions that focus on the first point, we consider instead agents that optimize a natural trade-off between both  objectives.We formalize this as an optimization problem where the objective mapping is regularized by the amount of information revealed to the adversary (measured as a divergence between the prior and posterior on the private knowledge). Quite surprisingly, when combined with the entropic regularization, the Sinkhorn loss naturally emerges in the optimization objective, making it efficiently solvable. We apply these techniques to preserve some privacy in online repeated auctions.",
        "bibtex": "@InProceedings{pmlr-v108-boursier20a,\n  title = \t {Utility/Privacy Trade-off through the lens of Optimal Transport},\n  author =       {Boursier, Etienne and Perchet, Vianney},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {591--601},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/boursier20a/boursier20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/boursier20a.html},\n  abstract = \t {Strategic information is valuable either by remaining private (for instance if it is sensitive) or, on the other hand, by being used publicly to increase some utility. These two objectives are antagonistic and leaking this information might be more rewarding than concealing it. Unlike classical solutions that focus on the first point, we consider instead agents that optimize a natural trade-off between both  objectives.We formalize this as an optimization problem where the objective mapping is regularized by the amount of information revealed to the adversary (measured as a divergence between the prior and posterior on the private knowledge). Quite surprisingly, when combined with the entropic regularization, the Sinkhorn loss naturally emerges in the optimization objective, making it efficiently solvable. We apply these techniques to preserve some privacy in online repeated auctions.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/boursier20a/boursier20a.pdf",
        "supp": "",
        "pdf_size": 718049,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2427890544946277209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Universit\u00e9 Paris-Saclay, ENS Paris-Saclay; CREST, ENSAE Paris, Palaiseau, France + Criteo AI Lab, Paris, France",
        "aff_domain": "ens-paris-saclay.fr;normalesup.org",
        "email": "ens-paris-saclay.fr;normalesup.org",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Universit\u00e9 Paris-Saclay;CREST;Criteo",
        "aff_unique_dep": "ENS Paris-Saclay;;Criteo AI Lab",
        "aff_unique_url": "https://www.universite-paris-saclay.fr;;https://www.criteo.com",
        "aff_unique_abbr": "UPS;;Criteo",
        "aff_campus_unique_index": "0;1+2",
        "aff_campus_unique": "Paris-Saclay;Palaiseau;Paris",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "France"
    },
    {
        "id": "b78014528f",
        "title": "Validated Variational Inference via Practical Posterior Error Bounds",
        "site": "https://proceedings.mlr.press/v108/huggins20a.html",
        "author": "Jonathan Huggins; Mikolaj Kasprzak; Trevor Campbell; Tamara Broderick",
        "abstract": "Variational inference has become an increasingly attractive fast alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, a major obstacle to the widespread use of variational methods is the lack of post-hoc accuracy measures that are both theoretically justified and computationally efficient. In this paper, we provide rigorous bounds on the error of posterior mean and uncertainty estimates that arise from full-distribution approximations, as in variational inference. Our bounds are widely applicable, as they require only that the approximating and exact posteriors have polynomial moments. Our bounds are also computationally efficient for variational inference because they require only standard values from variational objectives, straightforward analytic calculations, and simple Monte Carlo estimates. We show that our analysis naturally leads to a new and improved workflow for validated variational inference. Finally, we demonstrate the utility of our proposed workflow and error bounds on a robust regression problem and on a real-data example with a widely used multilevel hierarchical model.",
        "bibtex": "@InProceedings{pmlr-v108-huggins20a,\n  title = \t {Validated Variational Inference via Practical Posterior Error Bounds},\n  author =       {Huggins, Jonathan and Kasprzak, Mikolaj and Campbell, Trevor and Broderick, Tamara},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1792--1802},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/huggins20a/huggins20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/huggins20a.html},\n  abstract = \t {Variational inference has become an increasingly attractive fast alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, a major obstacle to the widespread use of variational methods is the lack of post-hoc accuracy measures that are both theoretically justified and computationally efficient. In this paper, we provide rigorous bounds on the error of posterior mean and uncertainty estimates that arise from full-distribution approximations, as in variational inference. Our bounds are widely applicable, as they require only that the approximating and exact posteriors have polynomial moments. Our bounds are also computationally efficient for variational inference because they require only standard values from variational objectives, straightforward analytic calculations, and simple Monte Carlo estimates. We show that our analysis naturally leads to a new and improved workflow for validated variational inference. Finally, we demonstrate the utility of our proposed workflow and error bounds on a robust regression problem and on a real-data example with a widely used multilevel hierarchical model.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/huggins20a/huggins20a.pdf",
        "supp": "",
        "pdf_size": 6108145,
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9920067449158078267&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b67950d536",
        "title": "Validation of Approximate Likelihood and Emulator Models for Computationally Intensive Simulations",
        "site": "https://proceedings.mlr.press/v108/dalmasso20a.html",
        "author": "Niccolo Dalmasso; Ann Lee; Rafael Izbicki; Taylor Pospisil; Ilmun Kim; Chieh-An Lin",
        "abstract": "Complex phenomena in engineering and the sciences are often modeled with computationally intensive feed-forward simulations for which a tractable analytic likelihood does not exist. In these cases, it is sometimes necessary to estimate an approximate likelihood or fit a fast emulator model for efficient statistical inference; such surrogate models include Gaussian synthetic likelihoods and more recently neural density estimators such as autoregressive models and normalizing flows.  To date, however, there is no consistent way of quantifying the quality of such a fit. Here we propose a statistical framework that can distinguish any arbitrary misspecified model from the target likelihood, and that in addition can identify with statistical confidence the regions of parameter as well as feature space where the fit is inadequate.  At the heart of our approach is a  two-sample test that quantifies the quality of the fit at fixed parameter values, and a global test that assesses goodness-of-fit across simulation parameters. While our general framework can incorporate any test statistic or distance metric, we specifically argue for a new two-sample test that can leverage any regression method to attain high power and provide diagnostics in complex data settings. Software for our approach is available on GitHub in Python and R.",
        "bibtex": "@InProceedings{pmlr-v108-dalmasso20a,\n  title = \t {Validation of Approximate Likelihood and Emulator Models for Computationally Intensive Simulations},\n  author =       {Dalmasso, Niccolo and Lee, Ann and Izbicki, Rafael and Pospisil, Taylor and Kim, Ilmun and Lin, Chieh-An},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3349--3361},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/dalmasso20a/dalmasso20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/dalmasso20a.html},\n  abstract = \t {Complex phenomena in engineering and the sciences are often modeled with computationally intensive feed-forward simulations for which a tractable analytic likelihood does not exist. In these cases, it is sometimes necessary to estimate an approximate likelihood or fit a fast emulator model for efficient statistical inference; such surrogate models include Gaussian synthetic likelihoods and more recently neural density estimators such as autoregressive models and normalizing flows.  To date, however, there is no consistent way of quantifying the quality of such a fit. Here we propose a statistical framework that can distinguish any arbitrary misspecified model from the target likelihood, and that in addition can identify with statistical confidence the regions of parameter as well as feature space where the fit is inadequate.  At the heart of our approach is a  two-sample test that quantifies the quality of the fit at fixed parameter values, and a global test that assesses goodness-of-fit across simulation parameters. While our general framework can incorporate any test statistic or distance metric, we specifically argue for a new two-sample test that can leverage any regression method to attain high power and provide diagnostics in complex data settings. Software for our approach is available on GitHub in Python and R. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/dalmasso20a/dalmasso20a.pdf",
        "supp": "",
        "pdf_size": 625094,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3445641725971989075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "764f30a139",
        "title": "Value Preserving State-Action Abstractions",
        "site": "https://proceedings.mlr.press/v108/abel20a.html",
        "author": "David Abel; Nate Umbanhowar; Khimya Khetarpal; Dilip Arumugam; Doina Precup; Michael Littman",
        "abstract": "Abstraction can improve the sample efficiency of reinforcement learning. However, the process of abstraction inherently discards information, potentially compromising an agent\u2019s ability to represent high-value policies. To mitigate this, we here introduce combinations of state abstractions and options that are guaranteed to preserve representation of near-optimal policies. We first define $\\phi$-relative options, a general formalism for analyzing the value loss of options paired with a state abstraction, and present necessary and sufficient conditions for $\\phi$-relative options to preserve near-optimal behavior in any finite Markov Decision Process. We further show that, under appropriate assumptions, $\\phi$-relative options can be composed to induce hierarchical abstractions that are also guaranteed to represent high-value policies.",
        "bibtex": "@InProceedings{pmlr-v108-abel20a,\n  title = \t {Value Preserving State-Action Abstractions},\n  author =       {Abel, David and Umbanhowar, Nate and Khetarpal, Khimya and Arumugam, Dilip and Precup, Doina and Littman, Michael},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1639--1650},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/abel20a/abel20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/abel20a.html},\n  abstract = \t {Abstraction can improve the sample efficiency of reinforcement learning. However, the process of abstraction inherently discards information, potentially compromising an agent\u2019s ability to represent high-value policies. To mitigate this, we here introduce combinations of state abstractions and options that are guaranteed to preserve representation of near-optimal policies. We first define $\\phi$-relative options, a general formalism for analyzing the value loss of options paired with a state abstraction, and present necessary and sufficient conditions for $\\phi$-relative options to preserve near-optimal behavior in any finite Markov Decision Process. We further show that, under appropriate assumptions, $\\phi$-relative options can be composed to induce hierarchical abstractions that are also guaranteed to represent high-value policies.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/abel20a/abel20a.pdf",
        "supp": "",
        "pdf_size": 4432293,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4046240235824862665&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cfb86dda14",
        "title": "Variance Reduction for Evolution Strategies via Structured Control Variates",
        "site": "https://proceedings.mlr.press/v108/tang20a.html",
        "author": "Yunhao Tang; Krzysztof Choromanski; Alp Kucukelbir",
        "abstract": "Evolution Strategies (ES) are a powerful class of blackbox optimization techniques that recently became a competitive alternative to state-of-the-art policy gradient (PG) algorithms for reinforcement learning (RL). We propose a new method for improving accuracy of the ES algorithms, that as opposed to recent approaches utilizing only Monte Carlo structure of the gradient estimator, takes advantage of the underlying MDP structure to reduce the variance. We observe that the gradient estimator of the ES objective can be alternatively computed using reparametrization and PG estimators, which leads to new control variate techniques for gradient estimation in ES optimization. We provide theoretical insights and show through extensive experiments that this RL-specific variance reduction approach outperforms general purpose variance reduction methods.",
        "bibtex": "@InProceedings{pmlr-v108-tang20a,\n  title = \t {Variance Reduction for Evolution Strategies via Structured Control Variates},\n  author =       {Tang, Yunhao and Choromanski, Krzysztof and Kucukelbir, Alp},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {646--656},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tang20a/tang20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tang20a.html},\n  abstract = \t {Evolution Strategies (ES) are a powerful class of blackbox optimization techniques that recently became a competitive alternative to state-of-the-art policy gradient (PG) algorithms for reinforcement learning (RL). We propose a new method for improving accuracy of the ES algorithms, that as opposed to recent approaches utilizing only Monte Carlo structure of the gradient estimator, takes advantage of the underlying MDP structure to reduce the variance. We observe that the gradient estimator of the ES objective can be alternatively computed using reparametrization and PG estimators, which leads to new control variate techniques for gradient estimation in ES optimization. We provide theoretical insights and show through extensive experiments that this RL-specific variance reduction approach outperforms general purpose variance reduction methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tang20a/tang20a.pdf",
        "supp": "",
        "pdf_size": 1540509,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12318135652904787326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "90a7d3fffa",
        "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework",
        "site": "https://proceedings.mlr.press/v108/khemakhem20a.html",
        "author": "Ilyes Khemakhem; Diederik Kingma; Ricardo Monti; Aapo Hyvarinen",
        "abstract": "The framework of variational autoencoders allows us to efficiently learn deep latent-variable models, such that the model\u2019s marginal distribution over observed variables fits the data. Often, we\u2019re interested in going a step further, and want to approximate the true joint distribution over observed and latent variables, including the true prior and posterior distributions over latent variables. This is known to be generally impossible due to unidentifiability of the model. We address this issue by showing that for a broad family of deep latent-variable models, identification of the true joint distribution over observed and latent variables is actually possible up to  very simple transformations, thus achieving a principled and powerful form of disentanglement. Our result requires a factorized prior distribution over the latent variables that is conditioned on an additionally observed variable, such as a class label or almost any other observation. We build on recent developments in nonlinear ICA, which we extend to the case with noisy, undercomplete or discrete observations, integrated in a maximum likelihood framework. The result also trivially contains identifiable flow-based generative models as a special case.",
        "bibtex": "@InProceedings{pmlr-v108-khemakhem20a,\n  title = \t {Variational Autoencoders and Nonlinear ICA: A Unifying Framework},\n  author =       {Khemakhem, Ilyes and Kingma, Diederik and Monti, Ricardo and Hyvarinen, Aapo},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2207--2217},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/khemakhem20a/khemakhem20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/khemakhem20a.html},\n  abstract = \t {The framework of variational autoencoders allows us to efficiently learn deep latent-variable models, such that the model\u2019s marginal distribution over observed variables fits the data. Often, we\u2019re interested in going a step further, and want to approximate the true joint distribution over observed and latent variables, including the true prior and posterior distributions over latent variables. This is known to be generally impossible due to unidentifiability of the model. We address this issue by showing that for a broad family of deep latent-variable models, identification of the true joint distribution over observed and latent variables is actually possible up to  very simple transformations, thus achieving a principled and powerful form of disentanglement. Our result requires a factorized prior distribution over the latent variables that is conditioned on an additionally observed variable, such as a class label or almost any other observation. We build on recent developments in nonlinear ICA, which we extend to the case with noisy, undercomplete or discrete observations, integrated in a maximum likelihood framework. The result also trivially contains identifiable flow-based generative models as a special case. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/khemakhem20a/khemakhem20a.pdf",
        "supp": "",
        "pdf_size": 2888778,
        "gs_citation": 708,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16728816603551563431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ff01fec68f",
        "title": "Variational Autoencoders for Sparse and Overdispersed Discrete Data",
        "site": "https://proceedings.mlr.press/v108/zhao20c.html",
        "author": "He Zhao; Piyush Rai; Lan Du; Wray Buntine; Dinh Phung; Mingyuan Zhou",
        "abstract": "Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-\u00e0-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.",
        "bibtex": "@InProceedings{pmlr-v108-zhao20c,\n  title = \t {Variational Autoencoders for Sparse and Overdispersed Discrete Data},\n  author =       {Zhao, He and Rai, Piyush and Du, Lan and Buntine, Wray and Phung, Dinh and Zhou, Mingyuan},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1684--1694},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/zhao20c/zhao20c.pdf},\n  url = \t {https://proceedings.mlr.press/v108/zhao20c.html},\n  abstract = \t {Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-\u00e0-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/zhao20c/zhao20c.pdf",
        "supp": "",
        "pdf_size": 405101,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16781509138658694256&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Faculty of Information Technology, Monash University, Australia; Department of Computer Science and Engineering, IIT Kanpur, India; Faculty of Information Technology, Monash University, Australia; Faculty of Information Technology, Monash University, Australia; Faculty of Information Technology, Monash University, Australia; McCombs School of Business, The University of Texas at Austin, USA",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "https://github.com/ethanhezhao/NBVAE",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0;2",
        "aff_unique_norm": "Monash University;Indian Institute of Technology Kanpur;University of Texas at Austin",
        "aff_unique_dep": "Faculty of Information Technology;Department of Computer Science and Engineering;McCombs School of Business",
        "aff_unique_url": "https://www.monash.edu;https://www.iitk.ac.in;https://www.mccombs.utexas.edu",
        "aff_unique_abbr": "Monash;IIT Kanpur;UT Austin",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Kanpur;Austin",
        "aff_country_unique_index": "0;1;0;0;0;2",
        "aff_country_unique": "Australia;India;United States"
    },
    {
        "id": "785cd31ee8",
        "title": "Variational Integrator Networks for Physically Structured Embeddings",
        "site": "https://proceedings.mlr.press/v108/saemundsson20a.html",
        "author": "Steindor Saemundsson; Alexander Terenin; Katja Hofmann; Marc Deisenroth",
        "abstract": "Learning workable representations of dynamical systems is becoming an increasingly important problem in a number of application areas. By leveraging recent work connecting deep neural networks to systems of differential equations, we propose \\emph{variational integrator networks}, a class of neural network architectures designed to preserve the geometric structure of physical systems. This class of network architectures facilitates accurate long-term prediction, interpretability, and data-efficient learning, while still remaining highly flexible and capable of modeling complex behavior. We demonstrate that they can accurately learn dynamical systems from both noisy observations in phase space and from image pixels within which the unknown dynamics are embedded.",
        "bibtex": "@InProceedings{pmlr-v108-saemundsson20a,\n  title = \t {Variational Integrator Networks for Physically Structured Embeddings},\n  author =       {Saemundsson, Steindor and Terenin, Alexander and Hofmann, Katja and Deisenroth, Marc},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3078--3087},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/saemundsson20a/saemundsson20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/saemundsson20a.html},\n  abstract = \t {Learning workable representations of dynamical systems is becoming an increasingly important problem in a number of application areas. By leveraging recent work connecting deep neural networks to systems of differential equations, we propose \\emph{variational integrator networks}, a class of neural network architectures designed to preserve the geometric structure of physical systems. This class of network architectures facilitates accurate long-term prediction, interpretability, and data-efficient learning, while still remaining highly flexible and capable of modeling complex behavior. We demonstrate that they can accurately learn dynamical systems from both noisy observations in phase space and from image pixels within which the unknown dynamics are embedded.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/saemundsson20a/saemundsson20a.pdf",
        "supp": "",
        "pdf_size": 305576,
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8634441918370096014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "02c3c1507a",
        "title": "Variational Optimization on Lie Groups, with Examples of Leading (Generalized) Eigenvalue Problems",
        "site": "https://proceedings.mlr.press/v108/tao20a.html",
        "author": "Molei Tao; Tomoki Ohsawa",
        "abstract": "The article considers smooth optimization of functions on Lie groups. By generalizing NAG variational principle in vector space (Wibisono et al., 2016) to general Lie groups, continuous Lie-NAG dynamics which are guaranteed to converge to local optimum are obtained. They correspond to momentum versions of gradient flow on Lie groups. A particular case of $\\SO(n)$ is then studied in details, with objective functions corresponding to leading Generalized EigenValue problems: the Lie-NAG dynamics are first made explicit in coordinates, and then discretized in structure preserving fashions, resulting in optimization algorithms with faithful energy behavior (due to conformal symplecticity) and exactly remaining on the Lie group. Stochastic gradient versions are also investigated. Numerical experiments on both synthetic data and practical problem (LDA for MNIST) demonstrate the effectiveness of the proposed methods as optimization algorithms (\\emph{not} as a classification method).",
        "bibtex": "@InProceedings{pmlr-v108-tao20a,\n  title = \t {Variational Optimization on Lie Groups, with Examples of Leading (Generalized) Eigenvalue Problems},\n  author =       {Tao, Molei and Ohsawa, Tomoki},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {4269--4280},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/tao20a/tao20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/tao20a.html},\n  abstract = \t {The article considers smooth optimization of functions on Lie groups. By generalizing NAG variational principle in vector space (Wibisono et al., 2016) to general Lie groups, continuous Lie-NAG dynamics which are guaranteed to converge to local optimum are obtained. They correspond to momentum versions of gradient flow on Lie groups. A particular case of $\\SO(n)$ is then studied in details, with objective functions corresponding to leading Generalized EigenValue problems: the Lie-NAG dynamics are first made explicit in coordinates, and then discretized in structure preserving fashions, resulting in optimization algorithms with faithful energy behavior (due to conformal symplecticity) and exactly remaining on the Lie group. Stochastic gradient versions are also investigated. Numerical experiments on both synthetic data and practical problem (LDA for MNIST) demonstrate the effectiveness of the proposed methods as optimization algorithms (\\emph{not} as a classification method).}\n}",
        "pdf": "http://proceedings.mlr.press/v108/tao20a/tao20a.pdf",
        "supp": "",
        "pdf_size": 1144660,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9496337124207052476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Georgia Institute of Technology; University of Texas at Dallas",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Georgia Institute of Technology;University of Texas at Dallas",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.utdallas.edu",
        "aff_unique_abbr": "Georgia Tech;UT Dallas",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Dallas",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9d2895c970",
        "title": "Wasserstein Smoothing: Certified Robustness against Wasserstein Adversarial Attacks",
        "site": "https://proceedings.mlr.press/v108/levine20a.html",
        "author": "Alexander Levine; Soheil Feizi",
        "abstract": "In the last couple of years, several adversarial attack methods based on different threat models have been proposed for the image classification problem. Most existing defenses consider additive threat models in which sample perturbations have bounded L_p norms. These defenses, however, can be vulnerable against adversarial attacks under non-additive threat models. An example of an attack method based on a non-additive threat model is the Wasserstein adversarial attack proposed by Wong et al. (2019), where the distance between an image and its adversarial example is determined by the Wasserstein metric (\"earth-mover distance\") between their normalized pixel intensities. Until now, there has been no certifiable defense against this type of attack. In this work, we propose the first defense with certified robustness against Wasserstein adversarial attacks using randomized smoothing. We develop this certificate by considering the space of possible flows between images, and representing this space such that Wasserstein distance between images is upper-bounded by L_1 distance in this flow-space. We can then apply existing randomized smoothing certificates for the L_1 metric.  In MNIST and CIFAR-10 datasets, we find that our proposed defense is also practically effective, demonstrating significantly improved accuracy under Wasserstein adversarial attack compared to unprotected models.",
        "bibtex": "@InProceedings{pmlr-v108-levine20a,\n  title = \t {Wasserstein Smoothing: Certified Robustness against Wasserstein Adversarial Attacks},\n  author =       {Levine, Alexander and Feizi, Soheil},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3938--3947},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/levine20a/levine20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/levine20a.html},\n  abstract = \t {In the last couple of years, several adversarial attack methods based on different threat models have been proposed for the image classification problem. Most existing defenses consider additive threat models in which sample perturbations have bounded L_p norms. These defenses, however, can be vulnerable against adversarial attacks under non-additive threat models. An example of an attack method based on a non-additive threat model is the Wasserstein adversarial attack proposed by Wong et al. (2019), where the distance between an image and its adversarial example is determined by the Wasserstein metric (\"earth-mover distance\") between their normalized pixel intensities. Until now, there has been no certifiable defense against this type of attack. In this work, we propose the first defense with certified robustness against Wasserstein adversarial attacks using randomized smoothing. We develop this certificate by considering the space of possible flows between images, and representing this space such that Wasserstein distance between images is upper-bounded by L_1 distance in this flow-space. We can then apply existing randomized smoothing certificates for the L_1 metric.  In MNIST and CIFAR-10 datasets, we find that our proposed defense is also practically effective, demonstrating significantly improved accuracy under Wasserstein adversarial attack compared to unprotected models. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/levine20a/levine20a.pdf",
        "supp": "",
        "pdf_size": 599985,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2039950592109522997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of Maryland, College Park; Department of Computer Science, University of Maryland, College Park",
        "aff_domain": "cs.umd.edu;cs.umd.edu",
        "email": "cs.umd.edu;cs.umd.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Maryland, College Park",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "595cc06100",
        "title": "Wasserstein Style Transfer",
        "site": "https://proceedings.mlr.press/v108/mroueh20a.html",
        "author": "Youssef Mroueh",
        "abstract": "We propose Gaussian optimal transport for image style transfer in an Encoder/Decoder framework. Optimal transport for Gaussian measures has closed forms Monge mappings from source to target distributions. Moreover, interpolating between a content and a style image can be seen as geodesics in the  Wasserstein Geometry. Using this insight, we show how to mix different target styles , using Wasserstein barycenter of Gaussian measures. Since Gaussians are closed under Wasserstein barycenter, this allows us a simple style transfer and style mixing and interpolation. Moreover we show how mixing different styles can be achieved using other geodesic metrics between gaussians such as the Fisher Rao metric, while the transport of the content to the new interpolate style is still performed with Gaussian OT maps. Our simple methodology allows to generate new stylized content interpolating between many artistic styles. The metric used in the interpolation results in different stylizations. A demo is available on https: //wasserstein-transfer.github.io.",
        "bibtex": "@InProceedings{pmlr-v108-mroueh20a,\n  title = \t {Wasserstein Style Transfer},\n  author =       {Mroueh, Youssef},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {842--852},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/mroueh20a/mroueh20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/mroueh20a.html},\n  abstract = \t {We propose Gaussian optimal transport for image style transfer in an Encoder/Decoder framework. Optimal transport for Gaussian measures has closed forms Monge mappings from source to target distributions. Moreover, interpolating between a content and a style image can be seen as geodesics in the  Wasserstein Geometry. Using this insight, we show how to mix different target styles , using Wasserstein barycenter of Gaussian measures. Since Gaussians are closed under Wasserstein barycenter, this allows us a simple style transfer and style mixing and interpolation. Moreover we show how mixing different styles can be achieved using other geodesic metrics between gaussians such as the Fisher Rao metric, while the transport of the content to the new interpolate style is still performed with Gaussian OT maps. Our simple methodology allows to generate new stylized content interpolating between many artistic styles. The metric used in the interpolation results in different stylizations. A demo is available on https: //wasserstein-transfer.github.io.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/mroueh20a/mroueh20a.pdf",
        "supp": "",
        "pdf_size": 23616303,
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1010136456883825464&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "https://wasserstein-transfer.github.io",
        "author_num": 1,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5337aece07",
        "title": "Why Non-myopic Bayesian Optimization is Promising and How Far Should We Look-ahead? A Study via Rollout",
        "site": "https://proceedings.mlr.press/v108/yue20b.html",
        "author": "Xubo Yue; Raed AL Kontar",
        "abstract": "Lookahead, also known as non-myopic, Bayesian optimization (BO) aims to find optimal sampling policies through solving a dynamic programming (DP) formulation that maximizes a long-term reward over a rolling horizon. Though promising, lookahead BO faces the risk of error propagation through its increased dependence on a possibly mis-specified model. In this work we focus on the rollout approximation for solving the intractable DP. We first prove the improving nature of rollout in tackling lookahead BO and provide a sufficient condition for the used heuristic to be rollout improving. We then provide both a theoretical and practical guideline to decide on the rolling horizon stagewise. This guideline is built on quantifying the negative effect of a mis-specified model. To illustrate our idea, we provide case studies on both single and multi-information source BO. Empirical results show the advantageous properties of our method over several myopic and non-myopic BO algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-yue20b,\n  title = \t {Why Non-myopic Bayesian Optimization is Promising and How Far Should We Look-ahead? A Study via Rollout},\n  author =       {Yue, Xubo and Kontar, Raed AL},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {2808--2818},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yue20b/yue20b.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yue20b.html},\n  abstract = \t {Lookahead, also known as non-myopic, Bayesian optimization (BO) aims to find optimal sampling policies through solving a dynamic programming (DP) formulation that maximizes a long-term reward over a rolling horizon. Though promising, lookahead BO faces the risk of error propagation through its increased dependence on a possibly mis-specified model. In this work we focus on the rollout approximation for solving the intractable DP. We first prove the improving nature of rollout in tackling lookahead BO and provide a sufficient condition for the used heuristic to be rollout improving. We then provide both a theoretical and practical guideline to decide on the rolling horizon stagewise. This guideline is built on quantifying the negative effect of a mis-specified model. To illustrate our idea, we provide case studies on both single and multi-information source BO. Empirical results show the advantageous properties of our method over several myopic and non-myopic BO algorithms. }\n}",
        "pdf": "http://proceedings.mlr.press/v108/yue20b/yue20b.pdf",
        "supp": "",
        "pdf_size": 418411,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8886079294815648852&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "University of Michigan; University of Michigan",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fa2894fd88",
        "title": "\u201cBring Your Own Greedy\u201d+Max: Near-Optimal 1/2-Approximations for Submodular Knapsack",
        "site": "https://proceedings.mlr.press/v108/yaroslavtsev20a.html",
        "author": "Grigory Yaroslavtsev; Samson Zhou; Dmitrii Avdiukhin",
        "abstract": "The problem of selecting a small-size representative summary of a large dataset is a cornerstone of machine learning, optimization and data science. Motivated by applications to recommendation systems and other scenarios with query-limited access to vast amounts of data, we propose a new rigorous algorithmic framework for a standard formulation of this problem as a submodular maximization subject to a linear (knapsack) constraint. Our framework is based on augmenting all partial Greedy solutions with the best additional item. It can be instantiated with negligible overhead in any model of computation, which allows the classic greedy algorithm and its variants to be implemented. We give such instantiations in the offline Gready+Max, multi-pass streaming Sieve+Max and distributed Distributed Sieve+Max settings. Our algorithms give ($1/2-\\eps$)-approximation with most other key parameters of interest being near-optimal. Our analysis is based on a new set of first-order linear differential inequalities and their robust approximate versions. Experiments on typical datasets (movie recommendations, influence maximization) confirm scalability and high quality of solutions obtained via our framework. Instance-specific approximations are typically in the 0.6-0.7 range and frequently beat even the $(1-1/e) \\approx 0.63$ worst-case barrier for polynomial-time algorithms.",
        "bibtex": "@InProceedings{pmlr-v108-yaroslavtsev20a,\n  title = \t {\u201cBring Your Own Greedy\u201d+Max: Near-Optimal 1/2-Approximations for Submodular Knapsack},\n  author =       {Yaroslavtsev, Grigory and Zhou, Samson and Avdiukhin, Dmitrii},\n  booktitle = \t {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},\n  pages = \t {3263--3274},\n  year = \t {2020},\n  editor = \t {Chiappa, Silvia and Calandra, Roberto},\n  volume = \t {108},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {26--28 Aug},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v108/yaroslavtsev20a/yaroslavtsev20a.pdf},\n  url = \t {https://proceedings.mlr.press/v108/yaroslavtsev20a.html},\n  abstract = \t {The problem of selecting a small-size representative summary of a large dataset is a cornerstone of machine learning, optimization and data science. Motivated by applications to recommendation systems and other scenarios with query-limited access to vast amounts of data, we propose a new rigorous algorithmic framework for a standard formulation of this problem as a submodular maximization subject to a linear (knapsack) constraint. Our framework is based on augmenting all partial Greedy solutions with the best additional item. It can be instantiated with negligible overhead in any model of computation, which allows the classic greedy algorithm and its variants to be implemented. We give such instantiations in the offline Gready+Max, multi-pass streaming Sieve+Max and distributed Distributed Sieve+Max settings. Our algorithms give ($1/2-\\eps$)-approximation with most other key parameters of interest being near-optimal. Our analysis is based on a new set of first-order linear differential inequalities and their robust approximate versions. Experiments on typical datasets (movie recommendations, influence maximization) confirm scalability and high quality of solutions obtained via our framework. Instance-specific approximations are typically in the 0.6-0.7 range and frequently beat even the $(1-1/e) \\approx 0.63$ worst-case barrier for polynomial-time algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v108/yaroslavtsev20a/yaroslavtsev20a.pdf",
        "supp": "",
        "pdf_size": 696861,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=548350070102059793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    }
]